[
    {
        "id": "9636709",
        "title": "\"Pretending to be Okay in a Sad Voice\": Social Robot\u2019s Usage of Verbal and Nonverbal Cue Combination and its Effect on Human Empathy and Behavior Inducement",
        "track": "main",
        "status": "Poster",
        "abstract": "Inducing a user\u2019s behavior through social interaction is a goal that a social robot aims to achieve. It has been argued that empathy has a strong effect on behavior inducement. In human-human interaction, it has been verified that the influence of a nonverbal cue on empathy outweighs that of a verbal cue when those are used in a combined way. The objectives of this study are to explore if such outweighing effect of nonverbal cues is maintained in human-robot interaction (HRI) and to investigate the mechanism of communication cues\u2019 effects by analyzing the mediation structure with the following mediator variables: perceived emotion, perceived intentionality, perceived malfunction, and empathy inducement. To this end, we conducted 2 (verbal type: positive verbal cue vs. negative verbal cue) \u00d7 2 (nonverbal type: positive nonverbal cue vs. negative nonverbal cue) within-participant experiment (N = 48). The experiment created a situation in which the social robot was harshly criticized during a conversation. The analysis of experiment results showed the outweighing effect of a nonverbal cue was maintained. When a nonverbal cue conveyed a negative, situation-accordant emotion, it had a decisive effect on perceived emotion, empathy, and behavior inducement. In contrast, a verbal cue induced participants\u2019 empathy and behavior when it conveyed a positive, situation-discordant emotion. This inconsistency between verbal cue and nonverbal cue made the combination of positive verbal cue and negative nonverbal cue have the strongest effect. It implies that participants had different expectations for each of the two communication cues, just as they did in social interactions with human beings. It implies that participants might have applied normative expectations for social interaction with human beings to the social robot.",
        "primary_area": "",
        "author": "Byeong June Moon;JongSuk Choi;Sonya S. Kwak;Byeong June Moon;JongSuk Choi;Sonya S. Kwak",
        "authorids": "/37088528280;/37292544300;/37398989100;/37088528280;/37292544300;/37398989100",
        "aff": "Department of Sociology, Seoul National University, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636709/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6314672058641980707&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Seoul National University;Korea Institute of Science and Technology",
        "aff_unique_dep": "Department of Sociology;Center for Intelligent and Interactive Robotics",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.kist.re.kr",
        "aff_unique_abbr": "SNU;KIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636308",
        "title": "\"Safe Skin\" - A Low-Cost Capacitive Proximity-Force-Fusion Sensor for Safety in Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design and evaluation of the low-cost capacitive proximity-force-fusion sensor \"safe skin\", which can measure simultaneously the proximity of humans as well as the contact force. It was designed such that the force and proximity sensing functions can work concurrently without interfering with each other. Moreover, active shielding, on-chip digitization and ground isolation are implemented for the sensor to minimize the influence from stray capacitance and electromagnetic interference (EMI) from the environment, which ensures that the sensor has a high system robustness for industrial applications. The prototype version has the capability of detecting a grounded human hand sized object from a distance of 400 mm. Moreover, forces in the range of 5 to 40 N can be measured, with 43.7% hysteresis and 6.7% nonlinearity. Due to its sensing characteristics, when used on a robot, the sensor could be used to ensure the safety of nearby humans in the future. The sensor could also potentially be used as an interface for human-robot interaction (HRI).",
        "primary_area": "",
        "author": "Zhen Wang;Heyang Gao;Alexander Schmitz;Sophon Somlor;Tito Pradhono Tomo;Shigeki Sugano;Zhen Wang;Heyang Gao;Alexander Schmitz;Sophon Somlor;Tito Pradhono Tomo;Shigeki Sugano",
        "authorids": "/37087244272;/37089196608;/37587110100;/37085510233;/37085618711;/37274050800;/37087244272;/37089196608;/37587110100;/37085510233;/37085618711;/37274050800",
        "aff": "Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan; Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636308/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15812903312299914580&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.waseda.ac.jp",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636692",
        "title": "3D Ensemble-Based Online Oceanic Flow Field Estimation for Underwater Glider Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating ocean flow fields in 3D is a critical step in enabling the reliable operation of underwater gliders and other small, low-powered autonomous marine vehicles. Existing methods produce depth-averaged 2D layers arranged at discrete vertical intervals, but this type of estimation can lead to severe navigation errors. Based on the observation that real-world ocean currents exhibit relatively low vertical velocity components, we propose an accurate 3D estimator that extends our previous work in estimating 2D flow fields as a linear combination of basis flows. The proposed algorithm uses data from ensemble forecasting to build a set of 3D basis flows, and then iteratively updates basis coefficients using point measurements of underwater currents. We report results from experiments using actual ensemble forecasts and synthetic measurements to compare the performance of our method to the direct 3D extension of the previous work. These results show that our method produces estimates with dramatically lower error metrics, with and without measurement noise.",
        "primary_area": "",
        "author": "Felix H. Kong;K. Y. Cadmus To;Gary Brassington;Stuart Anstee;Robert Fitch;Felix H. Kong;K. Y. Cadmus To;Gary Brassington;Stuart Anstee;Robert Fitch",
        "authorids": "/37088545936;/37086933783;/37089196433;/37601910400;/38466367800;/37088545936;/37086933783;/37089196433;/37601910400;/38466367800",
        "aff": "University of Technology, Sydney, NSW, Australia; University of Technology, Sydney, NSW, Australia; Australian Bureau of Meteorology; Department of Defence, Defence Science and Technology Group, Australia; University of Technology, Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636692/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3620104510564453590&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "University of Technology Sydney;Australian Bureau of Meteorology;Defence Science and Technology Group",
        "aff_unique_dep": ";;Department of Defence",
        "aff_unique_url": "https://www.uts.edu.au;https://www.bom.gov.au;https://www.dstgroup.com.au",
        "aff_unique_abbr": "UTS;BOM;DST Group",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9636745",
        "title": "3D Human Reconstruction in the Wild with Collaborative Aerial Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial vehicles are revolutionizing applications that require capturing the 3D structure of dynamic targets in the wild, such as sports, medicine and entertainment. The core challenges in developing a motion-capture system that operates in outdoors environments are: (1) 3D inference requires multiple simultaneous viewpoints of the target, (2) occlusion caused by obstacles is frequent when tracking moving targets, and (3) the camera and vehicle state estimation is noisy. We present a real-time aerial system for multi-camera control that can reconstruct human motions in natural environments without the use of special-purpose markers. We develop a multi-robot coordination scheme that maintains the optimal flight formation for target reconstruction quality amongst obstacles. We provide studies evaluating system performance in simulation, and validate real-world performance using two drones while a target performs activities such as jogging and playing soccer. Supplementary video: https://youtu.be/jxt91vx0cns",
        "primary_area": "",
        "author": "Cherie Ho;Andrew Jong;Harry Freeman;Rohan Rao;Rogerio Bonatti;Sebastian Scherer;Cherie Ho;Andrew Jong;Harry Freeman;Rohan Rao;Rogerio Bonatti;Sebastian Scherer",
        "authorids": "/38489350800;/37088498708;/37089195649;/37089195701;/37086934741;/37584159000;/38489350800;/37088498708;/37089195649;/37089195701;/37086934741;/37584159000",
        "aff": "The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636745/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13131630638994899718&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "The Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636019",
        "title": "3D Radar Velocity Maps for Uncertain Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Future urban transportation concepts include a mixture of ground and air vehicles with varying degrees of autonomy in a congested environment. In such dynamic environments, occupancy maps alone are not sufficient for safe path planning. Safe and efficient transportation requires reasoning about the 3D flow of traffic and properly modeling uncertainty. Several different approaches can be taken for developing 3D velocity maps. This paper explores a Bayesian approach that captures our uncertainty in the map given training data. The approach involves projecting spatial coordinates into a high-dimensional feature space and then applying Bayesian linear regression to make predictions and quantify uncertainty in our estimates. On a collection of air and ground datasets, we demonstrate that this approach is effective and more scalable than several alternative approaches.",
        "primary_area": "",
        "author": "Ransalu Senanayake;Kyle Beltran Hatch;Jason Zheng;Mykel J. Kochenderfer;Ransalu Senanayake;Kyle Beltran Hatch;Jason Zheng;Mykel J. Kochenderfer",
        "authorids": "/38490726500;/37089195784;/37089194411;/37596929200;/38490726500;/37089195784;/37089194411;/37596929200",
        "aff": "Stanford Intelligent Systems Laboratory (SISL) in the Aeronautics and Astronautics Department, Stanford University, Stanford, CA, USA; Stanford Intelligent Systems Laboratory (SISL) in the Aeronautics and Astronautics Department, Stanford University, Stanford, CA, USA; Department of Computer Science, Stanford University; Stanford Intelligent Systems Laboratory (SISL) in the Aeronautics and Astronautics Department, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636019/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13545835981252122130&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Aeronautics and Astronautics Department",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636575",
        "title": "3D Reactive Control and Frontier-Based Exploration for Unstructured Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper proposes a reliable and robust planning solution to the long range robotic navigation problem in extremely cluttered environments. A two-layer planning architecture is proposed that leverages both the environment map and the direct depth sensor information to ensure maximal information gain out of the onboard sensors. A frontier-based pose sampling technique is used with a fast marching cost-to-go calculation to select a goal pose and plan a path to maximize robot exploration rate. An artificial potential function approach, relying on direct depth measurements, enables the robot to follow the path while simultaneously avoiding small scene obstacles that are not captured in the map due to mapping and localization uncertainties. We demonstrate the feasibility and robustness of the proposed approach through field deployments in a structurally complex warehouse using a micro-aerial vehicle (MAV) with all the sensing and computations performed onboard.",
        "primary_area": "",
        "author": "Shakeeb Ahmad;Andrew B. Mills;Eugene R. Rush;Eric W. Frew;J. Sean Humbert;Shakeeb Ahmad;Andrew B. Mills;Eugene R. Rush;Eric W. Frew;J. Sean Humbert",
        "authorids": "/37086176864;/37086110551;/37088507251;/37268793800;/37530064300;/37086176864;/37086110551;/37088507251;/37268793800;/37530064300",
        "aff": "Department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO; Department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO; Department of Mechanical Engineering, University of Colorado, Boulder, CO; Department of Aerospace Engineering Sciences, University of Colorado, Boulder, CO; Department of Mechanical Engineering, University of Colorado, Boulder, CO",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636575/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11442508343547759693&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Aerospace Engineering Sciences",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636244",
        "title": "3D-FFS: Faster 3D object detection with Focused Frustum Search in sensor fusion based networks",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we propose 3D-FFS, a novel approach to make sensor fusion based 3D object detection networks significantly faster using a class of computationally inexpensive heuristics. Existing sensor fusion based networks generate 3D region proposals by leveraging inferences from 2D object detectors. However, as images have no depth information, these networks rely on extracting semantic features of points from the entire scene to locate the object. By leveraging aggregated intrinsic properties (e.g. point density) of point cloud data, 3D-FFS can substantially constrain the 3D search space and thereby significantly reduce training time, inference time and memory consumption without sacrificing accuracy. To demonstrate the efficacy of 3D-FFS, we have integrated it with Frustum ConvNet (F-ConvNet), a prominent sensor fusion based 3D object detection model. We assess the performance of 3D-FFS on the KITTI dataset. Compared to F-ConvNet, we achieve improvements in training and inference times by up to 62.80% and 58.96%, respectively, while reducing the memory usage by up to 58.53%. Additionally, we achieve 0.36%, 0.59% and 2.19% improvements in accuracy for the Car, Pedestrian and Cyclist classes, respectively. 3D-FFS shows a lot of promise in domains with limited computing power, such as autonomous vehicles, drones and robotics where LiDAR-Camera based sensor fusion perception systems are widely used.",
        "primary_area": "",
        "author": "Aniruddha Ganguly;Tasin Ishmam;Khandker Aftarul Islam;Md Zahidur Rahman;Md. Shamsuzzoha Bayzid;Aniruddha Ganguly;Tasin Ishmam;Khandker Aftarul Islam;Md Zahidur Rahman;Md. Shamsuzzoha Bayzid",
        "authorids": "/37089198204;/37089196540;/37089197045;/37089194877;/38189994500;/37089198204;/37089196540;/37089197045;/37089194877;/38189994500",
        "aff": "Department of Computer Science and Engineering, Bangladesh University of Engineering and Technology, Dhaka, Bangladesh; Department of Computer Science and Engineering, Bangladesh University of Engineering and Technology, Dhaka, Bangladesh; Department of Computer Science and Engineering, Bangladesh University of Engineering and Technology, Dhaka, Bangladesh; AWS at Amazon, Palo Alto, California; Department of Computer Science and Engineering, Bangladesh University of Engineering and Technology, Dhaka, Bangladesh",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636244/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Erxy5nmu8Q8J:scholar.google.com/&scioq=3D-FFS:+Faster+3D+object+detection+with+Focused+Frustum+Search+in+sensor+fusion+based+networks&hl=en&as_sdt=0,14",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Bangladesh University of Engineering and Technology;Amazon",
        "aff_unique_dep": "Department of Computer Science and Engineering;AWS",
        "aff_unique_url": "https://www.buet.ac.bd;https://aws.amazon.com",
        "aff_unique_abbr": "BUET;AWS",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Dhaka;Palo Alto",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Bangladesh;United States"
    },
    {
        "id": "9635932",
        "title": "A Bio-Inspired Multi-Sensor System for Robust Orientation and Position Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "The nature animals have evolved highly efficient and robust organs that support their complex daily navigation tasks. To mimic animal\u2019s navigation capability, we present a novel bio-inspired navigation system that draws inspirations from nature animals in this paper. The system consists of a three-axis magnetometer, a monocular camera, a micro inertial measurement unit (MIMU) and a polarization camera. While dead reckoning, orientation, and landmark recognition are considered as three most important capability for various species, we also designed corresponding algorithms based on the bio-inspired sensing system to perform autonomous navigation. In detail, the dead reckoning component is accomplished by integrating the monocular camera and the MIMU into a visual inertial odometry (VIO) and the orientation capability is achieved by combining the absolute orientation from the magnetometer with the relative orientation from the VIO. A loop closure detection is then used as the landmark recognition component to reduce the navigation drifts. All the three components are fused with a graph optimization method to generate the robust navigation result. To valid the proposed navigation sensing system and the algorithms, we have conducted series of experiments on ground and aerial unmanned vehicles, and have added orientation noise to testify the accuracy and robustness of the system.",
        "primary_area": "",
        "author": "Jia Xie;Xiaofeng He;Jun Mao;Lilian Zhang;Guoliang Han;Wenzhou Zhou;Xiaoping Hu;Jia Xie;Xiaofeng He;Jun Mao;Lilian Zhang;Guoliang Han;Wenzhou Zhou;Xiaoping Hu",
        "authorids": "/37089195349;/37900361100;/37086596241;/37085501209;/37086806008;/37088841992;/37280710800;/37089195349;/37900361100;/37086596241;/37085501209;/37086806008;/37088841992;/37280710800",
        "aff": "College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635932/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3434445664499880117&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "National University of Defense Technology",
        "aff_unique_dep": "College of Intelligence Science and Technology",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Changsha",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635873",
        "title": "A Caging Inspired Gripper using Flexible Fingers and a Movable Palm",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes the design of a robotic gripper motivated by the bin-picking problem, where a variety of objects need to be picked from cluttered bins. The presented gripper design focuses on an enveloping cage-like approach, which surrounds the object with three hooked fingers, and then presses into the object with a movable palm. The fingers are flexible and imbue grasps with some elasticity, helping to conform to objects and, crucially, adding friction to cases where an object cannot be caged. This approach proved effective on a set of basic shapes, such as cuboids and cylinders, in which every object could be grasped. In particular, flat bottom parts could be grasped in a very stable manner, as demonstrated by testing grasps with multiple 5N and 10N disturbances. A set of supermarket items were also tested, highlighting promising features such as effective grasping of fruits and vegetables, as well as some limitations in the current embodiment, which is not always able to slip the fingers underneath objects.",
        "primary_area": "",
        "author": "Luke Beddow;Helge Wurdemann;Dimitrios Kanoulas;Luke Beddow;Helge Wurdemann;Dimitrios Kanoulas",
        "authorids": "/37089195937;/37991827000;/38230575500;/37089195937;/37991827000;/38230575500",
        "aff": "Department of Computer Science, University College London, London, UK; Department of Mechanical Engineering, University College London, London, UK; Department of Computer Science, University College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635873/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6710355437933498212&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636798",
        "title": "A Collaborative Visual SLAM Framework for Service Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a collaborative visual simultaneous localization and mapping (SLAM) framework for service robots. With an edge server maintaining a map database and performing global optimization, each robot can register to an existing map, update the map, or build new maps, all with a unified interface and low computation and memory cost. We design an elegant communication pipeline to enable real-time information sharing between robots. With a novel landmark organization and retrieval method on the server, each robot can acquire landmarks predicted to be in its view, to augment its local map. The framework is general enough to support both RGB-D and monocular cameras, as well as robots with multiple cameras, taking the rigid constraints between cameras into consideration. The proposed framework has been fully implemented and verified with public datasets and live experiments.",
        "primary_area": "",
        "author": "Ming Ouyang;Xuesong Shi;Yujie Wang;Yuxin Tian;Yingzhe Shen;Dawei Wang;Peng Wang;Zhiqiang Cao;Ming Ouyang;Xuesong Shi;Yujie Wang;Yuxin Tian;Yingzhe Shen;Dawei Wang;Peng Wang;Zhiqiang Cao",
        "authorids": "/37088801988;/37086577986;/37087006825;/37088503927;/37086938224;/37086573866;/37089393960;/37289586900;/37088801988;/37086577986;/37087006825;/37088503927;/37086938224;/37086573866;/37089393960;/37289586900",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Intel Corporation, Beijing, China; Intel Corporation, Beijing, China; Intel Corporation, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Intel Corporation, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636798/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13198553239057176815&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;0;0;1;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Intel",
        "aff_unique_dep": "School of Artificial Intelligence;Intel Corporation",
        "aff_unique_url": "http://www.ucas.ac.cn;https://www.intel.com",
        "aff_unique_abbr": "UCAS;Intel",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636615",
        "title": "A Comparison of Modern General-Purpose Visual SLAM Approaches",
        "track": "main",
        "status": "Poster",
        "abstract": "Advancing maturity in mobile and legged robotics technologies is changing the landscapes where robots are being deployed and found. This innovation calls for a transformation in simultaneous localization and mapping (SLAM) systems to support this new generation of service and consumer robots. No longer can traditionally robust 2D lidar systems dominate while robots are being deployed in multi-story indoor, outdoor unstructured, and urban domains with increasingly inexpensive stereo and RGB-D cameras. Visual SLAM (VSLAM) systems have been a topic of study for decades and a small number of openly available implementations have stood out: ORB-SLAM3, OpenVSLAM and RTABMap.This paper presents a comparison of these 3 modern, feature rich, and uniquely robust VSLAM techniques that have yet to be benchmarked against each other, using several different datasets spanning multiple domains negotiated by service robots. ORB-SLAM3 and OpenVSLAM each were not compared against at least one of these datasets previously in literature and we provide insight through this lens. This analysis is motivated to find general purpose, feature complete, and multi-domain VSLAM options to support a broad class of robot applications for integration into the new and improved ROS 2 Nav2 System as suitable alternatives to traditional 2D lidar solutions.",
        "primary_area": "",
        "author": "Alexey Merzlyakov;Steve Macenski;Alexey Merzlyakov;Steve Macenski",
        "authorids": "/37089194844;/37088461104;/37089194844;/37088461104",
        "aff": "Samsung Research Russia; Samsung Research America",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636615/",
        "gs_citation": 86,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17407236568083995341&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "Russia",
        "aff_unique_url": "https://www.samsung.com/global/research/",
        "aff_unique_abbr": "SRR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Russian Federation;United States"
    },
    {
        "id": "9636256",
        "title": "A Compliant Five-Bar Legged Mechanism for Heavy-Load Legged Robots by Using Magneto-Rheological Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a compliant five-bar leg mechanism is proposed, designed and manufactured for heavy-load legged robots, by using two magneto-rheological actuators (MRAs) that are capable of offering a maximal torque of 78Nm. To address the rate-dependent hysteresis of the MRA, a hybrid rate-dependent hysteresis model is derived based on the idea of mappings between different hysteresis loops. With integrating the classical Preisach model and the NARX neural network, the hybrid model is able to model hysteresis nonlinearity of the magneto-rheological clutch (MRC). It is then used to estimate and control the output torque of the MRA at the absent of external force/torque sensors. High fidelity force control and variable compliance of the leg mechanism are realized and validated in various experiments with using the MRAs.",
        "primary_area": "",
        "author": "Guangzeng Chen;Jiangtao Ran;Chenguang Bai;Pengyu Jie;Yunjiang Lou;Guangzeng Chen;Jiangtao Ran;Chenguang Bai;Pengyu Jie;Yunjiang Lou",
        "authorids": "/37086357010;/37088952604;/37088967763;/37088951753;/37279072300;/37086357010;/37088952604;/37088967763;/37088951753;/37279072300",
        "aff": "State Key Laboratory of Robotics and System, School of Mechatronics Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; State Key Laboratory of Robotics and System, School of Mechatronics Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; State Key Laboratory of Robotics and System, School of Mechatronics Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; State Key Laboratory of Robotics and System, School of Mechatronics Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China; State Key Laboratory of Robotics and System, School of Mechatronics Engineering and Automation, Harbin Institute of Technology (Shenzhen), Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636256/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18444552137197454720&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "School of Mechatronics Engineering and Automation",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636305",
        "title": "A Computational Framework for Robot Hand Design via Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot hand is essential for a fully functional robot and designing a good robot hand is a sophisticated job that challenges the designer\u2019s knowledge and experience. This paper presents a computational framework for automatic optimal robot hand design based on reinforcement learning (RL), which considers desired grasping tasks, grasp control strategies, and performance quality measures altogether. The RL-based framework intends to grow finger joints with different types and link lengths at different positions from null. Then, the reward function for such a growing action is defined in terms of quality indexes of the generated robot hand to perform desired grasping tasks under expected control strategies. To demonstrate the effectiveness of this framework, in this paper we set the desired task to simply grasping objects of three primitive shapes (i.e., box, cylinder, and sphere) with predefined hand positions and strategies to close fingers to achieve grasps for each object. The force closure condition, quantitative stability indexes, and energy consumption of grasps as well as some penalty terms are used to assemble the reward function. Through simulation and practical prototype experiments, we show that capable robot hands can be automatically generated by the proposed framework. Potential factors that affect the output of the framework and deserve further exploration are also discussed.",
        "primary_area": "",
        "author": "Zhong Zhang;Yu Zheng;Zhe Hu;Lezhang Liu;Xuan Zhao;Xiong Li;Jia Pan;Zhong Zhang;Yu Zheng;Zhe Hu;Lezhang Liu;Xuan Zhao;Xiong Li;Jia Pan",
        "authorids": "/37086920466;/37086993722;/37086328802;/37089194418;/37086510371;/37085669304;/37535628800;/37086920466;/37086993722;/37086328802;/37089194418;/37086510371;/37085669304;/37535628800",
        "aff": "Department of Biomedical Engineering, City University of Hong Kong; Tencent Robotics X, Shenzhen, China; Department of Biomedical Engineering, City University of Hong Kong; Faculty of Intelligent Manufacturing, Wuyi University; Department of Biomedical Engineering, City University of Hong Kong; Tencent Robotics X, Shenzhen, China; Department of Computer Science, The University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636305/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13997181733012209336&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;0;1;3",
        "aff_unique_norm": "City University of Hong Kong;Tencent;Wuyi University;University of Hong Kong",
        "aff_unique_dep": "Department of Biomedical Engineering;Robotics X;Faculty of Intelligent Manufacturing;Department of Computer Science",
        "aff_unique_url": "https://www.cityu.edu.hk;https://robotics.tencent.com;http://www.wyu.edu.cn/;https://www.hku.hk",
        "aff_unique_abbr": "CityU;Tencent Robotics X;;HKU",
        "aff_campus_unique_index": "0;1;0;0;1;0",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636487",
        "title": "A Conceptual Approach of Passive Human-Intention-Orientated Variable Admittance Control using Power Envelope",
        "track": "main",
        "status": "Poster",
        "abstract": "Two main challenges that need to be addressed in physical human-robot interaction (pHRI) are efficient recognition of human intention and interaction safety. In this paper, a general human intention framework was summarized, firstly, according to the robot's roles: a passive follower and a compliant leader. Secondly, we proposed variable admittance control models governed by human intentions. Power envelope approaches were then proposed to impose constraints on the variable admittance parameters inferred from human intention for maintaining passivity conservatively. Our passivity preserving approaches were validated via simulation and shown to avoid mismatching of time-varying admittance parameters that restrain drastic changes of admittance controller dynamics, which usually result in instability. Finally, the relationship between the robot's passivity and stability when it interacts with the human was analyzed.",
        "primary_area": "",
        "author": "Jingdong Chen;Paul I. Ro;Jingdong Chen;Paul I. Ro",
        "authorids": "/37089196439;/37284161200;/37089196439;/37284161200",
        "aff": "Department of Mechanical Engineering, School of Computer Science and Engineering, Baylor University; Department of Mechanical Engineering, School of Computer Science and Engineering, Baylor University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636487/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5408351413130003857&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Baylor University",
        "aff_unique_dep": "Department of Mechanical Engineering, School of Computer Science and Engineering",
        "aff_unique_url": "https://www.baylor.edu",
        "aff_unique_abbr": "Baylor",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636682",
        "title": "A Conformal Mapping-based Framework for Robot-to-Robot and Sim-to-Real Transfer Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel method for transferring motion planning and control policies between a teacher and a learner robot. With this work, we propose to reduce the sim-to-real gap, transfer knowledge designed for a specific system into a different robot, and compensate for system aging and failures. To solve this problem we introduce a Schwarz\u2013Christoffel mapping-based method to geometrically stretch and fit the control inputs from the teacher into the learner command space. We also propose a method based on primitive motion generation to create motion plans and control inputs compatible with the learner\u2019s capabilities. Our approach is validated with simulations and experiments with different robotic systems navigating occluding environments.",
        "primary_area": "",
        "author": "Shijie Gao;Nicola Bezzo;Shijie Gao;Nicola Bezzo",
        "authorids": "/37086940518;/37546843800;/37086940518;/37546843800",
        "aff": "Charles L. Brown Department of Electrical and Computer Engineering, and Link Lab, University of Virginia, Charlottesville, VA, USA; Charles L. Brown Department of Electrical and Computer Engineering, and Link Lab, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636682/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2513921706742696417&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Charles L. Brown Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635874",
        "title": "A Control and Drive System for Pneumatic Soft Robots: PneuSoRD",
        "track": "main",
        "status": "Poster",
        "abstract": "This article describes an open-source hardware platform for controlling pneumatic soft robotic systems and presents the comparison of control schemes with on-off and proportional valves. The Pneumatic Soft Robotics Driver (PneuSoRD) can be used with up to one pump and pressure accumulator, 26 on-off valves, and 5 proportional valves, any of which can be operated in open or closed-loop control using up to 12 sensor inputs, which allows for the simultaneous control of a large number of soft actuators. The electronic driver connects to a National Instruments myRIO controller or an Arduino Due with the use of an adapter shield. A library of pressure control algorithms in both LabVIEW and Simulink is provided that includes bang-bang control, hysteresis control and PID control using on-off or proportional valves. LabVIEW and Simulink provide user-friendly interfaces for rapid prototyping of control algorithms and real-time evaluation of pressure dynamics. The characteristics and performance of these control methods and pneumatic setups are evaluated to simplify the choice of valves and control algorithm for a given application.",
        "primary_area": "",
        "author": "Taylor R. Young;Matheus S. Xavier;Yuen K. Yong;Andrew J. Fleming;Taylor R. Young;Matheus S. Xavier;Yuen K. Yong;Andrew J. Fleming",
        "authorids": "/37089402809;/37087245955;/37304550100;/37265481600;/37089402809;/37087245955;/37304550100;/37265481600",
        "aff": "Precision Mechatronics Lab at the School of Electrical Engineering and Computer Science, The University of Newcastle, Callaghan, NSW, Australia; Precision Mechatronics Lab at the School of Electrical Engineering and Computer Science, The University of Newcastle, Callaghan, NSW, Australia; Precision Mechatronics Lab at the School of Electrical Engineering and Computer Science, The University of Newcastle, Callaghan, NSW, Australia; Precision Mechatronics Lab at the School of Electrical Engineering and Computer Science, The University of Newcastle, Callaghan, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635874/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3211499295379758327&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Newcastle",
        "aff_unique_dep": "School of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.newcastle.edu.au",
        "aff_unique_abbr": "UON",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Callaghan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9636162",
        "title": "A Dataset for Provident Vehicle Detection at Night",
        "track": "main",
        "status": "Poster",
        "abstract": "In current object detection, algorithms require the object to be directly visible in order to be detected. As humans, however, we intuitively use visual cues caused by the respective object to already make assumptions about its appearance. In the context of driving, such cues can be shadows during the day and often light reflections at night. In this paper, we study the problem of how to map this intuitive human behavior to computer vision algorithms to detect oncoming vehicles at night just from the light reflections they cause by their headlights. For that, we present an extensive open-source dataset containing 59 746 annotated grayscale images out of 346 different scenes in a rural environment at night. In these images, all oncoming vehicles, their corresponding light objects (e. g., headlamps), and their respective light reflections (e. g., light reflections on guardrails) are labeled. In this context, we discuss the characteristics of the dataset and the challenges in objectively describing visual cues such as light reflections. We provide different metrics for different ways to approach the task and report the results we achieved using state-of-the-art and custom object detection models as a first benchmark. With that, we want to bring attention to a new and so far neglected field in computer vision research, encourage more researchers to tackle the problem, and thereby further close the gap between human performance and computer vision systems.",
        "primary_area": "",
        "author": "Sascha Saralajew;Lars Ohnemus;Lukas Ewecker;Ebubekir Asan;Simon Isele;Stefan Roos;Sascha Saralajew;Lars Ohnemus;Lukas Ewecker;Ebubekir Asan;Simon Isele;Stefan Roos",
        "authorids": "/37085898519;/37088645190;/37089002333;/37089196593;/37089003630;/37089004774;/37085898519;/37088645190;/37089002333;/37089196593;/37089003630;/37089004774",
        "aff": "Institute of Product Development, Bosch Center for Artificial Intelligence, Renningen, and Leibniz University Hannover, Hannover, Germany; Dr. Ing. h.c. F. Porsche AG, Weissach, Germany; Dr. Ing. h.c. F. Porsche AG, Weissach, Germany; Dr. Ing. h.c. F. Porsche AG, Weissach, Germany; Dr. Ing. h.c. F. Porsche AG, Weissach, Germany; Dr. Ing. h.c. F. Porsche AG, Weissach, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636162/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1338231783734964682&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;1",
        "aff_unique_norm": "Bosch Center for Artificial Intelligence;Dr. Ing. h.c. F. Porsche AG",
        "aff_unique_dep": "Institute of Product Development;",
        "aff_unique_url": "https://www.bosch-ai.com;https://www.porsche.com",
        "aff_unique_abbr": "BCAI;Porsche AG",
        "aff_campus_unique_index": "0;1;1;1;1;1",
        "aff_campus_unique": "Renningen;Weissach",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636242",
        "title": "A Deep Learning-based Indoor Scene Classification Approach Enhanced with Inter-Object Distance Semantic Features",
        "track": "main",
        "status": "Poster",
        "abstract": "Convolutional Neural Networks (CNNs) have been increasingly applied in visual classification tasks by replacing hand-crafted features with deep features. However, problems such as inter-class similarity and intra-class variation led to the need of obtaining more descriptive features. To accomplish this, a new semantic inter-object relationship approach is proposed, which is based on the distance relationships between recognized objects. This new source of information represents how close or apart objects belonging to two object classes are, which, together with the number of object occurrences, allows to develop a more descriptive semantic feature representation of the scene. To exploit such semantic features, a two-branch CNN architecture based on 1D and 2D convolutional layers, is proposed. Also, an enhancement version, GSF2AppV2, of the Global and Semantic Feature Fusion described in [1] is proposed by integrating the new semantic inter-object relationship approach, as well as the aforementioned two-branch CNN architecture. The GSF2AppV2 is also composed of a CNN-based global feature branch, where five different CNN-based feature extraction approaches were assessed as global feature extraction modules. Moreover, to combine global and semantic features, two feature fusion approaches are proposed and evaluated: correlation and triple concatenation. GSF2AppV2 was evaluated in two benchmark datasets: the SUN RGB-D and NYU Depth V2. State-of-the-art results were achieved on both datasets, showing the effectiveness of the proposed semantic feature approach on the pipeline.",
        "primary_area": "",
        "author": "Ricardo Pereira;Lu\u00eds Garrote;Tiago Barros;Ana Lopes;Urbano J. Nunes;Ricardo Pereira;Lu\u00eds Garrote;Tiago Barros;Ana Lopes;Urbano J. Nunes",
        "authorids": "/37087119814;/38243509200;/37087120831;/37410502800;/37275938400;/37087119814;/38243509200;/37087120831;/37410502800;/37275938400",
        "aff": "Department of Electrical and Computer Engineering, Institute of Systems and Robotics, University of Coimbra, Portugal; Department of Electrical and Computer Engineering, Institute of Systems and Robotics, University of Coimbra, Portugal; Department of Electrical and Computer Engineering, Institute of Systems and Robotics, University of Coimbra, Portugal; Polytechnic Institute of Tomar, Portugal; Department of Electrical and Computer Engineering, Institute of Systems and Robotics, University of Coimbra, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636242/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16836809358991616941&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Coimbra;Polytechnic Institute of Tomar",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.uc.pt;https://www.ipt.pt",
        "aff_unique_abbr": "UC;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "9636538",
        "title": "A Dexterous, Reconfigurable, Adaptive Robot Hand Combining Anthropomorphic and Interdigitated Configurations",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot grasping and dexterous, in-hand manipulation allow robots to interact with their surroundings and execute a plethora of complex tasks such as pushing buttons, opening doors, and interacting with electrical appliances. In robotics, such complicated tasks are typically executed by multi-fingered end-effectors that are heavy, rigid, and expensive, employing numerous degrees of freedom and actuation. In this paper, we focus on the analysis, design, and development of a multi-grasp, reconfigurable, five fingered, anthropomorphic robot hand that can facilitate the execution of both robust grasping and dexterous manipulation tasks in service robotics and industrial automation applications. The robot hand is composed of eight actuators driving eighteen degrees of freedom with a telescoping mechanism and opposable thumb and pinky fingers to produce multiple anthropomorphic and non-anthropomorphic configurations for grasping and manipulation tasks. The reconfigurable finger base frames allow the hand to transform and utilize its degrees of actuation in an optimal manner to overcome its underactuated limitations. The underactuated robot hand is designed with a human hand structure that takes advantage of objects specifically designed for human operation (e.g., tool or handles with ergonomics for the human hand). This allows the system to better operate within a human-centered environment. The effectiveness of the proposed device is experimentally validated through three different tests: i) grasping experiments involving everyday-life objects, ii) force experiments that assess the force exertion capabilities of the hand in different finger base frame configurations, and iii) demonstration of in-hand object manipulation capabilities. The proposed hand weighs 1.28 kg and has a cost of approximately $1920 USD. The device is capable of exerting up to 14.3 N of contact force during pinch grasping and a maximum of 150.6 N power grasping.",
        "primary_area": "",
        "author": "Geng Gao;Jayden Chapman;Saori Matsunaga;Toshisada Mariyama;Bruce MacDonald;Minas Liarokapis;Geng Gao;Jayden Chapman;Saori Matsunaga;Toshisada Mariyama;Bruce MacDonald;Minas Liarokapis",
        "authorids": "/37087027460;/37088482031;/37088580339;/37087323162;/37300950400;/38558084100;/37087027460;/37088482031;/37088580339;/37087323162;/37300950400;/38558084100",
        "aff": "Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Information Technology R&D Center, Mitsubishi Electric Corporation, Japan; Information Technology R&D Center, Mitsubishi Electric Corporation, Japan; Department of Electrical, Computer and Software Engineering, Centre for Automation and Robotic Engineering Science, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636538/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15275838174313999455&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "University of Auckland;Mitsubishi Electric Corporation",
        "aff_unique_dep": "Department of Mechanical Engineering;Information Technology R&D Center",
        "aff_unique_url": "https://www.auckland.ac.nz;https://www.mitsubishielectric.com",
        "aff_unique_abbr": "UoA;MEC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;1;0;0",
        "aff_country_unique": "New Zealand;Japan"
    },
    {
        "id": "9636626",
        "title": "A Dual Doctor-Patient Twin Paradigm for Transparent Remote Examination, Diagnosis, and Rehabilitation",
        "track": "main",
        "status": "Poster",
        "abstract": "The need for comprehensive telemedicine solutions is becoming increasingly relevant due to challenges associated with the ageing population, the increasing shortage of health-care providers, and, more recently, the global pandemic. Existing solutions primarily focus on, e.g., electronic medical records, audiovisual connections, and, in some cases, robotic systems with very basic capabilities. Here we present a fundamentally new, holistic approach to a remote doctor visit, which enables transparent remote examination, anomaly detection, diagnosis, and rehabilitation. Our dual doctor-patient twin paradigm involves two robotic systems: one representing the doctor to the patient (\"GARMI\") and one representing the patient to the doctor (\"MUCKI\"). Through bidirectional telepresence control, this system enables transparent, natural, remote haptic interaction between doctor and patient. The control, interaction, and knowledge transfer to the doctor is enhanced by AI-based visual motion and facial expression analysis as well as a digital twin of the patient. Thus, each stage of a doctor visit can be replicated in the context of telemedicine and shared autonomy: from first assessment to observation-based and remote physical examination, to a better-informed doctor diagnosis and robot-assisted telerehabilitation.",
        "primary_area": "",
        "author": "Mario Tr\u00f6binger;Andrei Costinescu;Hao Xing;Jean Elsner;Tingli Hu;Abdeldjallil Naceri;Luis Figueredo;Elisabeth Jensen;Darius Burschka;Sami Haddadin;Mario Tr\u00f6binger;Andrei Costinescu;Hao Xing;Jean Elsner;Tingli Hu;Abdeldjallil Naceri;Luis Figueredo;Elisabeth Jensen;Darius Burschka;Sami Haddadin",
        "authorids": "/37088863248;/37089196470;/37089197003;/37088864033;/37086395867;/37546043900;/37063909900;/37967991000;/37267429200;/37542865300;/37088863248;/37089196470;/37089197003;/37088864033;/37086395867;/37546043900;/37063909900;/37967991000;/37267429200;/37542865300",
        "aff": "Munich School of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636626/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10213675056175299389&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Munich School of Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636669",
        "title": "A Fast Algorithm for Stochastic Orienteering with Chance Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the Stochastic Orienteering Problem with random traversal time for edges. In this scenario the length of the path is a random variable and we consider a formulation with chance constraints, i.e., a bound on the probability that the length of the path exceeds the allotted budget. Our proposed solution casts the problem as an instance of a suitably defined Constrained Markov Decision Process and uses a Lagrangian formulation to solve it. In particular, exploiting some structural properties of the associated decision process we can solve the Markov Decision Process using a Lagrangian approach and efficiently determine the optimal Lagrange multiplier. Our method is experimentally evaluated and demonstrated to be significantly faster than previous solutions using a linear programming approach to solve the Stochastic Orienteering Problem with chance constraints.",
        "primary_area": "",
        "author": "Thomas C. Thayer;Stefano Carpin;Thomas C. Thayer;Stefano Carpin",
        "authorids": "/37086455994;/37328709200;/37086455994;/37328709200",
        "aff": "Department of Computer Science and Engineering, University of California, Merced, CA, USA; Department of Computer Science and Engineering, University of California, Merced, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636669/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5012878134422695933&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Merced",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ucmerced.edu",
        "aff_unique_abbr": "UC Merced",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Merced",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636174",
        "title": "A Force Recognition System for Distinguishing Click Responses of Various Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "This study proposes a technique for determining completion of robotic tasks considering a characteristics that some features on force responses are common among various objects. In particular, this paper focuses on the click response because its pattern is common to many objects, although the magnitude of the response differs depending on the object. A discriminator for detecting the click response based on the force sensor values, which combines mel-frequency cepstral coefficient and time-delay neural network is introduced. Based on this discriminator, how to improve the generalization performance to untrained objects is investigated to detect click responses in general for various objects. The experimental results show that the performance can be improved by including several kinds of objects with close time constants and different amplitudes of click responses in the training data.",
        "primary_area": "",
        "author": "Koyo Sato;Sho Sakaino;Toshiaki Tsuji;Koyo Sato;Sho Sakaino;Toshiaki Tsuji",
        "authorids": "/37087120688;/37393460500;/37287863900;/37087120688;/37393460500;/37287863900",
        "aff": "Graduate School of Science and Engineering, Saitama University, Japan; JST PRESTO; Graduate School of Science and Engineering, Saitama University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636174/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2051490502200921784&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Saitama University;Japan Science and Technology Agency",
        "aff_unique_dep": "Graduate School of Science and Engineering;PRESTO",
        "aff_unique_url": "https://www.saitama-u.ac.jp;https://www.jst.go.jp",
        "aff_unique_abbr": ";JST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636400",
        "title": "A General Approach to State Refinement",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning algorithms such as Convolutional Neural Networks (CNNs) are currently used to solve a range of robotics and computer vision problems. These networks typically estimate the desired representation in a single forward pass and must therefore learn to converge from a wide range of initial conditions to a precise result. This is challenging, and has led to increased interest in the development of separate refinement modules which learn to improve a given initial estimate, thus reducing the required search space. Such modules are usually developed ad-hoc for each given application, often requiring significant engineering investment. In this work we propose a generic innovation-based CNN. Our CNN is implemented along with a stochastic gradient descent (SGD) algorithm to iteratively refine a given initial estimate. The proposed approach provides a general framework for the development of refinement modules applicable to a wide range of robotics problems. We apply this framework to object pose estimation and depth estimation and demonstrate significant improvement over the initial estimates, in the range of 4.2 - 8.1%, for both applications.",
        "primary_area": "",
        "author": "Gerard Kennedy;Jin Gao;Zheyu Zhuang;Xin Yu;Robert Mahony;Gerard Kennedy;Jin Gao;Zheyu Zhuang;Xin Yu;Robert Mahony",
        "authorids": "/37089194871;/37089197129;/37087324996;/37086213475;/37283743600;/37089194871;/37089197129;/37087324996;/37086213475;/37283743600",
        "aff": "Research School of Engineering, Australian National University, Canberra, Australia; Research School of Engineering, Australian National University, Canberra, Australia; Research School of Engineering, Australian National University, Canberra, Australia; University of Technology, Sydney, Australia; Research School of Engineering, Australian National University, Canberra, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636400/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Australian National University;University of Technology Sydney",
        "aff_unique_dep": "Research School of Engineering;",
        "aff_unique_url": "https://www.anu.edu.au;https://www.uts.edu.au",
        "aff_unique_abbr": "ANU;UTS",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Canberra;Sydney",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9635985",
        "title": "A General Framework for Lifelong Localization and Mapping in Changing Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "The environment of most real-world scenarios such as malls and supermarkets changes at all times. A pre-built map that does not account for these changes becomes out-of-date easily. Therefore, it is necessary to have an up-to-date model of the environment to facilitate long-term operation of a robot. To this end, this paper presents a general lifelong simultaneous localization and mapping (SLAM) framework. Our framework uses a multiple session map representation, and exploits an efficient map updating strategy that includes map building, pose graph refinement and sparsification. To mitigate the unbounded increase of memory usage, we propose a map-trimming method based on the Chow-Liu maximum-mutual-information spanning tree. The proposed SLAM framework has been comprehensively validated by over a month of robot deployment in real supermarket environment. Furthermore, we release the dataset collected from the indoor and outdoor changing environment with the hope to accelerate lifelong SLAM research in the community. Our dataset is available at https://github.com/sanduan168/lifelong-SLAM-dataset.",
        "primary_area": "",
        "author": "Min Zhao;Xin Guo;Le Song;Baoxing Qin;Xuesong Shi;Gim Hee Lee;Guanghui Sun;Min Zhao;Xin Guo;Le Song;Baoxing Qin;Xuesong Shi;Gim Hee Lee;Guanghui Sun",
        "authorids": "/37089193945;/37089196036;/37088506807;/37088506372;/37086577986;/37860021400;/37596858200;/37089193945;/37089196036;/37088506807;/37088506372;/37086577986;/37860021400;/37596858200",
        "aff": "Gaussian Robotics, Shanghai, China; Gaussian Robotics, Shanghai, China; Gaussian Robotics, Shanghai, China; Gaussian Robotics, Shanghai, China; Intel Labs China, Beijing, China; Department of Computer Science, School of Computing, Computer Vision and Robotic Perception Lab, National University of Singapore, Singapore; Department of Control Science and Engineering, Harbin Institute of Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635985/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16307225497485087478&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;3",
        "aff_unique_norm": "Gaussian Robotics;Intel;National University of Singapore;Harbin Institute of Technology",
        "aff_unique_dep": ";Intel Labs China;Department of Computer Science;Department of Control Science and Engineering",
        "aff_unique_url": ";https://www.intel.cn;https://www.nus.edu.sg;http://www.hit.edu.cn/",
        "aff_unique_abbr": ";Intel China;NUS;HIT",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Beijing;Harbin",
        "aff_country_unique_index": "0;0;0;0;0;1;0",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "9636119",
        "title": "A General Task and Motion Planning Framework For Multiple Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Many manipulation tasks combine high-level discrete planning over actions with low-level motion planning over continuous robot motions. Task and motion planning (TMP) provides a powerful general framework to combine discrete and geometric reasoning, and solvers have been previously proposed for single-robot problems. Multi-robot TMP expands the range of TMP problems that can be solved but poses significant challenges when considering scalability and solution quality. We present a general TMP framework designed for multiple robotic manipulators. This is based on two contributions. First, we propose an optimal task planner designed to support simultaneous discrete actions. Second, we introduce an intermediate scheduler layer between task planner and motion planner to evaluate alternate robot assignments to these actions. This aggressively explores the search space and typically reduces the number of expensive task planning calls. Several benchmarks with a rich set of actions for two manipulators are evaluated. We show promising results in scalability and solution quality of our TMP framework with the scheduler for up to six objects. A demonstration indicates scalability to up to five robots.",
        "primary_area": "",
        "author": "Tianyang Pan;Andrew M. Wells;Rahul Shome;Lydia E. Kavraki;Tianyang Pan;Andrew M. Wells;Rahul Shome;Lydia E. Kavraki",
        "authorids": "/37086938153;/37086687629;/37085557993;/37279015600;/37086938153;/37086687629;/37085557993;/37279015600",
        "aff": "Dept. of Comp. Sci., Rice Univ.; Dept. of Comp. Sci., Rice Univ.; Dept. of Comp. Sci., Rice Univ.; Dept. of Comp. Sci., Rice Univ.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636119/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16479211809099046827&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636757",
        "title": "A Hierarchical Framework for Quadruped Locomotion Based on Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadruped locomotion is a challenging task for learning-based algorithms. It requires tedious manual tuning and is difficult to deploy in reality due to the reality gap. In this paper, we propose a quadruped robot learning system for agile locomotion which does not require any pre-training and works well in various real-world terrains. We introduce a hierarchical learning framework that uses reinforcement learning as the high-level policy to adjust the low-level trajectory generator for better adaptability to the terrain. We compact the observation and action space of the reinforcement learning to deploy it on a host computer in reality. Besides, we design a trajectory generator guided by robot posture, which can generate adaptive foot trajectory to interact with the environment. Experimental results show that our system can be easily deployed in reality while only trained in simulation, and also has the advantages of fast convergence and good terrain adaptability. The supplementary video demonstration is available at https://vsislab.github.io/hfql/.",
        "primary_area": "",
        "author": "Wenhao Tan;Xing Fang;Wei Zhang;Ran Song;Teng Chen;Yu Zheng;Yibin Li;Wenhao Tan;Xing Fang;Wei Zhang;Ran Song;Teng Chen;Yu Zheng;Yibin Li",
        "authorids": "/37089406190;/37089198072;/37085379581;/37546859100;/37087243805;/37086993722;/37279897500;/37089406190;/37089198072;/37085379581;/37546859100;/37087243805;/37086993722;/37279897500",
        "aff": "School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; Tencent Robotics X Lab, Shenzhen, China; School of Control Science and Engineering, Shandong University, Jinan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636757/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4205120426936391206&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "Shandong University;Tencent",
        "aff_unique_dep": "School of Control Science and Engineering;Robotics",
        "aff_unique_url": "http://www.sdu.edu.cn;https://www.tencent.com",
        "aff_unique_abbr": "SDU;Tencent",
        "aff_campus_unique_index": "0;0;0;0;0;1;0",
        "aff_campus_unique": "Jinan;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635988",
        "title": "A High-Accuracy Fiducial Marker with Parallel Lenticular Angle Gauges",
        "track": "main",
        "status": "Poster",
        "abstract": "Lenticular angle gauge (LEAG) is a planar pattern that visualizes relative attitude by the position of the black line, which moves according to the viewing angle. The authors developed a new LEAG in which the direction of movement of the black line is 90\u25e6 different from the previous LEAG, and used it to develop a non-square high-accuracy fiducial marker. The new marker realized accurate pose estimation with a position error of 0.15% of the distance and an attitude error of 0.5\u00b0. This research contributes to the development of high-accuracy markers with a more flexible design. This paper describes the principle and behavior of the new LEAG, the design of the new fiducial marker, and the pose estimation algorithm, followed by the results of performance verification experiments.",
        "primary_area": "",
        "author": "Hideyuki Tanaka;Kunihiro Ogata;Hideyuki Tanaka;Kunihiro Ogata",
        "authorids": "/37676195700;/37647366000;/37676195700;/37647366000",
        "aff": "Human Augmentation Research Center, National Institute of Advanced Industrial Science and Technology, Kashiwa, Chiba, Japan; Human Augmentation Research Center, National Institute of Advanced Industrial Science and Technology, Kashiwa, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635988/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7355826395058662120&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Human Augmentation Research Center",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kashiwa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636861",
        "title": "A High-accuracy Framework for Vehicle Dynamic Modeling in Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Vehicle dynamic models are the key to bridge the gap between simulation and real road test in autonomous driving. An accurate vehicle model allows control algorithms in simulation being transferred to real road test with same quality. In this paper, we present a dynamic model residual correction framework (DRF) for vehicle dynamic modeling. DRF provides a general accuracy improvement framework on existing vehicle dynamic models. On top of any existing open-loop dynamic model, this framework builds a Residual Correction Model (RCM) by integrating deep Neural Networks (NN) with Stochastic Variational Gaussian Process (SVGP) model. RCM takes a sequence of vehicle control commands and dynamic states for a certain time duration as modeling inputs, extracts underlying context from this sequence with deep encoder networks, and predicts open-loop dynamic model prediction errors. Five vehicle dynamic models are derived from DRF via encoder variations. Our contribution is consolidated with evaluation of the absolute trajectory error and the similarity between DRF outputs and the ground truth. Compared to classic rule-based and learning-based vehicle dynamic models, DRF accomplishes as high as 74.12% to 85.02% of the absolute trajectory error drop among all DRF variations.",
        "primary_area": "",
        "author": "Shu Jiang;Yu Wang;Weiman Lin;Yu Cao;Longtao Lin;Jinghao Miao;Qi Luo;Shu Jiang;Yu Wang;Weiman Lin;Yu Cao;Longtao Lin;Jinghao Miao;Qi Luo",
        "authorids": "/37088637541;/37088921756;/37088920071;/37088922100;/37088922400;/37088643032;/37087321741;/37088637541;/37088921756;/37088920071;/37088922100;/37088922400;/37088643032;/37087321741",
        "aff": "Baidu USA LLC, Sunnyvale, CA; Baidu USA LLC, Sunnyvale, CA; Baidu USA LLC, Sunnyvale, CA; Baidu USA LLC, Sunnyvale, CA; Baidu USA LLC, Sunnyvale, CA; Baidu USA LLC, Sunnyvale, CA; Baidu USA LLC, Sunnyvale, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636861/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13825692633250022940&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Baidu",
        "aff_unique_dep": "Baidu USA LLC",
        "aff_unique_url": "https://www.baidu.com",
        "aff_unique_abbr": "Baidu USA",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Sunnyvale",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636811",
        "title": "A Highly Maneuverable Hybrid Energy-Efficient Rolling/Flying System",
        "track": "main",
        "status": "Poster",
        "abstract": "Spherical robots are typically comprised of an actuation unit enclosed by a spherical shell. Among nonholonomic systems, spherical robots offer the best maneuverability and lowest energy consumption (due to their omnidirectional movement and single contact point with the ground). This allows them to traverse rough and uneven terrains. Further, using their ability to roll on the ground, they can provide a significantly higher operating time compared to aerial-only robots. Unfortunately, these robots are under-emphasized by researchers compared to other robots (i.e., legged or wheeled robots). Additionally, despite their potential to be used in a multitude of real-world applications, spherical robots have not been successfully adopted by the industry. This is due to the lack of controllability and traversability of the developed designs. In this paper, we introduce a hybrid rolling/flying robot. This design benefits from a flywheel to reduce the effects of the terrain (shocks and vibrations) on the camera and sensors. Our design allows the application of existing control algorithms of drones (such as PX4) on a rolling system. In addition, we propose a dynamics model that can use the point cloud representation of the terrain to simulate the motion of the system with applications in real-time modeling and control.",
        "primary_area": "",
        "author": "Sahand Sabet;Mohit Singh;Mohammad Poursina;Parviz E. Nikravesh;Sahand Sabet;Mohit Singh;Mohammad Poursina;Parviz E. Nikravesh",
        "authorids": "/37086036298;/37089194740;/37086037856;/37086037082;/37086036298;/37089194740;/37086037856;/37086037082",
        "aff": "Department of Aerospace and Mechanical Engineering, University of Arizona, Tucson, AZ, USA; Indian Institute of Technology Kharagpour, West Bengal, India; Department of Engineering Sciences, University of Agder, Grimstad, Norway; Department of Aerospace and Mechanical Engineering, University of Arizona, Tucson, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636811/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7433777510269901826&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Arizona;Indian Institute of Technology Kharagpur;University of Agder",
        "aff_unique_dep": "Department of Aerospace and Mechanical Engineering;;Department of Engineering Sciences",
        "aff_unique_url": "https://www.arizona.edu;https://www.iitkgp.ac.in;https://www.uia.no",
        "aff_unique_abbr": "UArizona;IIT Kharagpur;",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Tucson;Kharagpur;Grimstad",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "United States;India;Norway"
    },
    {
        "id": "9636085",
        "title": "A Hybrid Dual Jacobian Approach for Autonomous Control of Concentric Tube Robots in Unknown Constrained Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Concentric Tube Robots (CTR) have been gaining ground in minimally-invasive robotic surgeries due to their small footprint, compliance, and high dexterity. CTRs can assure safe interaction with soft tissue, provided that precise and effective motion control is achieved. Controlling the motion of CTRs is still challenging. Commonly used model-based control approaches often employ simplified geometric/dynamic assumptions, which could be very inaccurate in the presence of unmodelled disturbances and external interaction forces. Additionally, application of emerging data-driven algorithms in real-time control of CTRs is limited due to the fact that these controllers require considerable amount of time to let the algorithm develop enough to reach a desired accuracy and relevancy. In this paper, we present a hybrid approach to overcome the aforementioned difficulties. This hybrid solution uses the solution of a kinematic model of the robot to estimate initial values for a model-free data-driven method. The proposed algorithm combines both model-based and data-driven algorithms to provide real-time motion control of CTRs interacting with an unknown external environment. Three different simulations studies were performed to thoroughly evaluate the efficacy of the proposed hybrid control approach as compared to two common model-based and data-driven control techniques. The results demonstrate superior performance of the proposed method. The root-mean-square error of the proposed hybrid approach is less than 1.1 mm, which is 9 times less than a common model-based controller.",
        "primary_area": "",
        "author": "Balint Thamo;Farshid Alambeigi;Kev Dhaliwal;Mohsen Khadem;Balint Thamo;Farshid Alambeigi;Kev Dhaliwal;Mohsen Khadem",
        "authorids": "/37089001416;/38542997100;/37086204046;/37085447737;/37089001416;/38542997100;/37086204046;/37085447737",
        "aff": "School of Informatics, University of Edinburgh, UK; Walker Department of Mechanical Engineering, University of Texas at Austin, Austin, USA; Translational Healthcare Technologies Group in Centre for Inflammation Research, The Queen\u2019s Medical Research Institute, University of Edinburgh, UK; Translational Healthcare Technologies Group in Centre for Inflammation Research, The Queen\u2019s Medical Research Institute, University of Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636085/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15439626747564625875&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Edinburgh;University of Texas at Austin",
        "aff_unique_dep": "School of Informatics;Walker Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.utexas.edu",
        "aff_unique_abbr": "Edinburgh;UT Austin",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Edinburgh;Austin;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "9636294",
        "title": "A Joint Imitation-Reinforcement Learning Framework for Reduced Baseline Regret",
        "track": "main",
        "status": "Poster",
        "abstract": "In various control task domains, existing controllers provide a baseline level of performance that\u2014though possibly suboptimal\u2014should be maintained. Reinforcement learning (RL) algorithms that rely on extensive exploration of the state and action space can be used to optimize a control policy. However, fully exploratory RL algorithms may decrease performance below a baseline level during training. In this paper, we address the issue of online optimization of a control policy while minimizing regret with respect to a baseline policy performance. We present a joint imitation-reinforcement learning framework, denoted JIRL. The learning process in JIRL assumes the availability of a baseline policy and is designed with two objectives in mind (a) training while leveraging demonstrations from the baseline policy to minimize regret with respect to the baseline policy, and (b) eventually surpassing the baseline performance. JIRL addresses these objectives by initially learning to imitate the baseline policy and gradually shifting control from the baseline to an RL agent. Experimental results show that JIRL effectively accomplishes the aforementioned objectives in several, continuous action-space domains. The results demonstrate that JIRL is comparable to a state-of-the-art algorithm in its final performance while incurring significantly lower baseline regret during training. Moreover, the results show a reduction factor of up to 21 in baseline regret over a trust-region-based approach that guarantees monotonic policy improvement.",
        "primary_area": "",
        "author": "Sheelabhadra Dey;Sumedh Pendurkar;Guni Sharon;Josiah P. Hanna;Sheelabhadra Dey;Sumedh Pendurkar;Guni Sharon;Josiah P. Hanna",
        "authorids": "/37087107671;/37088596253;/37086547276;/37088467292;/37087107671;/37088596253;/37086547276;/37088467292",
        "aff": "Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA; Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA; Department of Computer Science and Engineering, Texas A&M University, College Station, TX, USA; School of Informatics, University of Edinburgh, Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636294/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11500862821848834606&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Texas A&M University;University of Edinburgh",
        "aff_unique_dep": "Department of Computer Science and Engineering;School of Informatics",
        "aff_unique_url": "https://www.tamu.edu;https://www.ed.ac.uk",
        "aff_unique_abbr": "TAMU;Edinburgh",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "College Station;Edinburgh",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9635863",
        "title": "A Large-Scale Dataset for Water Segmentation of SAR Satellite",
        "track": "main",
        "status": "Poster",
        "abstract": "Not only on earth, but also in space, robot systems are increasingly becoming essential elements in our lives such as a mobile exploration robot on Mars. Satellites are also an indispensable field in space robot systems, for example, from low-orbit satellites for self-driving vehicles to small satellites launched for various purposes. A lot of research is being conducted on an automated system using more and more satellites. In particular, earth observation using satellite images is being used in various fields such as disaster prediction, damage analysis, and land cover classification. There are three main types of satellite imagery used in automation systems: optical, Synthetic Aperture Radar (SAR), and infrared. Unlike optical satellite, which is heavily influenced by weather and light, SAR satellite can acquire images in all-weather conditions. Thanks to this advantage, SAR satellite images are used in many fields, in particular, water segmentation. There are various traditional SAR image-based water segmentation methods based on thresholding technique. However, these methods are not suitable for rapidly processing a large amount of SAR images because they require a manual operation to set different thresholds for each image. In this paper, we create a large-scale dataset for water segmentation of KOrean Multi-Purpose SATellite (KOMPSAT-5) containing more than 3,000 images. We perform water segmentation using representative deep learning-based segmentation models such as Fully Convolutional Networks (FCN), U-Net, DeepUNet, and High Resolution Network (HRNet). Experimental results show that high performance of water segmentation can be obtained when a large number of training images are used for all five segmentation models. In addition, we confirm the possibility of the automatic water segmentation system from a large amount of SAR images, away from traditional manual work.",
        "primary_area": "",
        "author": "Myeung Un Kim;Han Oh;Seung-Jae Lee;Yeonju Choi;Sanghyuck Han;Myeung Un Kim;Han Oh;Seung-Jae Lee;Yeonju Choi;Sanghyuck Han",
        "authorids": "/37086044637;/37088756645;/37088748674;/37088748250;/37085465039;/37086044637;/37088756645;/37088748674;/37088748250;/37085465039",
        "aff": "Korea Aerospace Research Institute, Daejeon, Rep. Korea; Korea Aerospace Research Institute, Daejeon, Rep. Korea; Korea Aerospace Research Institute, Daejeon, Rep. Korea; Korea Aerospace Research Institute, Daejeon, Rep. Korea; Korea Aerospace Research Institute, Daejeon, Rep. Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635863/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14573095131235210446&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Korea Aerospace Research Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.kari.re.kr",
        "aff_unique_abbr": "KARI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636328",
        "title": "A Learning Approach to Robot-Agnostic Force-Guided High Precision Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we propose a learning approach to high-precision robotic assembly problems. We focus on the contact-rich phase, where the assembly pieces are in close contact with each other. Unlike many learning-based approaches that heavily rely on vision or spatial tracking, our approach takes force/torque in task space as the only observation. Our training environment is robotless, as the end-effector is not attached to any specific robot. Trained policies can then be applied to different robotic arms without re-training. This approach can greatly reduce complexity to perform contact-rich robotic assembly in the real world, especially in unstructured settings such as in architectural construction. To achieve it, we have developed a new distributed RL agent, named Recurrent Distributed DDPG (RD2), which extends Ape-X DDPG[1] with recurrency and makes two structural improvements on prioritized experience replay[2]. Our results show that RD2 is able to solve two fundamental high-precision assembly tasks, lap-joint and peg-in-hole, and outperforms two state-of-the-art algorithms, Ape-X DDPG and PPO with LSTM. We have successfully evaluated our robot-agnostic policies on three robotic arms, Kuka KR60, Franka Panda, and UR10, in simulation. The video presenting our experiments is available at https://sites.google.com/view/rd2-rl",
        "primary_area": "",
        "author": "Jieliang Luo;Hui Li;Jieliang Luo;Hui Li",
        "authorids": "/37086936909;/37089194741;/37086936909;/37089194741",
        "aff": "Autodesk Research, San Francisco, United States; Autodesk Research, San Francisco, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636328/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12814445460979829772&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Autodesk Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://research.autodesk.com",
        "aff_unique_abbr": "Autodesk",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Francisco",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635851",
        "title": "A Low-Cost Modular System of Customizable, Versatile, and Flexible Tactile Sensor Arrays",
        "track": "main",
        "status": "Poster",
        "abstract": "The key role of tactile sensing for human grasping and manipulation is widely acknowledged, but most industrial robot grippers and even multi-fingered hands are still designed and used without any tactile sensors. While the basic design principles for resistive or capacitive sensors are well known, several factors keep tactile sensing from large-scale deployment \u2014 high sensor costs, short lifespan, poor reliability, difficult production processes, a lack of suitable software and tools for system integration, and the unique requirement for tactile sensors to conform to application-specific shapes.In this work, we describe a very simple but efficient approach to design low-cost resistive matrix sensors, where sensor layout and geometry, taxel-size, and measurement sensitivity can be customized over a wide range. Sensor assembly needs nothing more than a hobby cutting plotter for precise cutting of aluminum tape and Velostat foils, as well as adhesive plastic tape. Our electronics combines transimpedance amplifiers with common Arduino microcontrollers, supporting standard communication protocols, and using either cabled or wireless data transfer to the host. We present three different application examples and sketch our ROS software for sensor calibration and visualization. All parts of our project, including detailed building instructions, bill-of-materials, electronics, and firmware are available open-source.",
        "primary_area": "",
        "author": "Niklas Fiedler;Philipp Ruppel;Yannick Jonetzko;Norman Hendrich;Jianwei Zhang;Niklas Fiedler;Philipp Ruppel;Yannick Jonetzko;Norman Hendrich;Jianwei Zhang",
        "authorids": "/37086932526;/37086456160;/37086579947;/37449613700;/37281460600;/37086932526;/37086456160;/37086579947;/37449613700;/37281460600",
        "aff": "Department of Informatics, Group Technical Aspects of Multimodal Systems (TAMS), Universit\u00e4t Hamburg, Germany; Department of Informatics, Group Technical Aspects of Multimodal Systems (TAMS), Universit\u00e4t Hamburg, Germany; Department of Informatics, Group Technical Aspects of Multimodal Systems (TAMS), Universit\u00e4t Hamburg, Germany; Department of Informatics, Group Technical Aspects of Multimodal Systems (TAMS), Universit\u00e4t Hamburg, Germany; Department of Informatics, Group Technical Aspects of Multimodal Systems (TAMS), Universit\u00e4t Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635851/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6827796475775090443&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Universit\u00e4t Hamburg",
        "aff_unique_dep": "Department of Informatics",
        "aff_unique_url": "https://www.uni-hamburg.de",
        "aff_unique_abbr": "UHH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636267",
        "title": "A Low-cost Robot with Autonomous Recharge and Navigation for Weed Control in Fields with Narrow Row Spacing",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern herbicide application in agricultural set-tings typically relies on either large scale sprayers that dispense herbicide over crops and weeds alike or portable sprayers that require labor intensive manual operation. The former method results in overuse of herbicide and reduction in crop yield while the latter is often untenable in large scale operations. This paper presents the first fully autonomous robot for weed management for row crops capable of computer vision based navigation, weed detection, complete field coverage, and automatic recharge for under $400. The target application is autonomous inter-row weed control in crop fields, e.g. flax and canola, where the spacing between croplines is as small as one foot. The proposed robot is small enough to pass between croplines at all stages of plant growth while detecting weeds and spraying herbicide. A recharging system incorporates newly designed robotic hardware, a ramp, a robotic charging arm, and a mobile charging station. An integrated vision algorithm is employed to assist with charger alignment effectively. Combined, they enable the robot to work continuously in the field without access to electricity. In addition, a color-based contour algorithm combined with preprocessing techniques is applied for robust navigation relying on the input from the onboard monocular camera. Incorporating such compact robots into farms could help automate weed control, even during late stages of growth, and reduce herbicide use by targeting weeds with precision. The robotic platform is field-tested in the flaxseed fields of North Dakota.",
        "primary_area": "",
        "author": "Yayun Du;Bhrugu Mallajosyula;Deming Sun;Jingyi Chen;Zihang Zhao;Mukhlesur Rahman;Mohiuddin Quadir;Mohammad Khalid Jawed;Yayun Du;Bhrugu Mallajosyula;Deming Sun;Jingyi Chen;Zihang Zhao;Mukhlesur Rahman;Mohiuddin Quadir;Mohammad Khalid Jawed",
        "authorids": "/37088689145;/37089194636;/37089197708;/37089196342;/37089194694;/37089194899;/37088690462;/37088686728;/37088689145;/37089194636;/37089197708;/37089196342;/37089194694;/37089194899;/37088690462;/37088686728",
        "aff": "Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA; Department of Plant Sciences, North Dakota State University, Fargo, ND; Department of Coatings and Polymeric Materials, North Dakota State University, Fargo, ND; Department of Mechanical & Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636267/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17391401855543916920&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;1;0",
        "aff_unique_norm": "University of California, Los Angeles;North Dakota State University",
        "aff_unique_dep": "Department of Mechanical & Aerospace Engineering;Department of Plant Sciences",
        "aff_unique_url": "https://www.ucla.edu;https://www.ndsu.edu",
        "aff_unique_abbr": "UCLA;NDSU",
        "aff_campus_unique_index": "0;0;0;0;0;1;1;0",
        "aff_campus_unique": "Los Angeles;Fargo",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636479",
        "title": "A Marginal Log-Likelihood Approach for the Estimation of Discount Factors of Multiple Experts in Inverse Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We focus on multiple experts performing a task in a Markov decision process (MDP) environment. A probabilistic assignment of trajectories to clusters and a mathematical framework which leverages the utility function are employed to jointly estimate the discount factor and reward. We treat the number of clusters as a hyperparameter which can be \"freely\" selected by the problem designer. In this work, we specifically treat the cluster of trajectories as a latent variable in the adapted maximum entropy inverse reinforcement learning (IRL) formulation; the introduction of this latent variable adds to the complexity of the IRL problem. To manage such complexity, we optimize a marginal log-likelihood function via Expectation Maximization. To test our approach, we have utilized behavioral data generated from three MDP environments. Experimental works show that our approach is promising towards the estimation of discount factors in IRL for non-interacting multiple experts.",
        "primary_area": "",
        "author": "Babatunde H. Giwa;Chi-Guhn Lee;Babatunde H. Giwa;Chi-Guhn Lee",
        "authorids": "/37089194122;/37088451673;/37089194122;/37088451673",
        "aff": "Department of Mechanical & Industrial Engineering, University of Toronto, Canada; Department of Mechanical & Industrial Engineering, University of Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636479/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14435826418186508030&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Department of Mechanical & Industrial Engineering",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9635918",
        "title": "A Meta-Learning-based Trajectory Tracking Framework for UAVs under Degraded Conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to changes in model dynamics or unexpected disturbances, an autonomous robotic system may experience unforeseen challenges during real-world operations which may affect its safety and intended behavior: in particular actuator and system failures and external disturbances are among the most common causes of degraded mode of operation. To deal with this problem, in this work, we present a meta-learning-based approach to improve the trajectory tracking performance of an unmanned aerial vehicle (UAV) under actuator faults and disturbances which have not been previously experienced. Our approach leverages meta-learning to train a model that is easily adaptable at runtime to make accurate predictions about the system\u2019s future state. A runtime monitoring and validation technique is proposed to decide when the system needs to adapt its model by considering a data pruning procedure for efficient learning. Finally, the reference trajectory is adapted based on future predictions by borrowing feedback control logic to make the system track the original and desired path without needing to access the system\u2019s controller. The proposed framework is applied and validated in both simulations and experiments on a faulty UAV navigation case study demonstrating a drastic increase in tracking performance.",
        "primary_area": "",
        "author": "Esen Yel;Nicola Bezzo;Esen Yel;Nicola Bezzo",
        "authorids": "/37086422921;/37546843800;/37086422921;/37546843800",
        "aff": "Departments of Engineering Systems and Environment and Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Departments of Engineering Systems and Environment and Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635918/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6290745043924293922&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Departments of Engineering Systems and Environment, Electrical and Computer Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636571",
        "title": "A Method to use Nonlinear Dynamics in a Whisker Sensor for Terrain Identification by Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper shows analytical and experimental evidence of using the vibration dynamics of a compliant whisker for accurate terrain classification during steady state motion of a mobile robot. A Hall effect sensor was used to measure whisker vibrations due to perturbations from the ground. Analytical results predict that the whisker vibrations will have one dominant frequency at the vertical perturbation frequency of the mobile robot and one with distinct frequency components. These frequency components may come from bifurcation of vibration frequency due to nonlinear interaction dynamics at steady state. Experimental results also exhibit distinct dominant frequency components unique to the speed of the robot and the terrain roughness. This nonlinear dynamic feature is used in a deep multi-layer perceptron neural network to classify terrains. We achieved 85.6% prediction success rate for seven flat terrain surfaces with different textures.",
        "primary_area": "",
        "author": "Zhenhua Yu;S.M. Hadi Sadati;Hasitha Wegiriya;Peter Childs;Thrishantha Nanayakkara;Zhenhua Yu;S.M. Hadi Sadati;Hasitha Wegiriya;Peter Childs;Thrishantha Nanayakkara",
        "authorids": "/37089195188;/37085509620;/37086131156;/38013543700;/37399134000;/37089195188;/37085509620;/37086131156;/38013543700;/37399134000",
        "aff": "Dyson School of Design Engineering, Imperial College London, London, UK; Department of Surgical and Interventional Engineering, King\u2019s College London, London, U.K; Faculty of Natural and Mathematical Sciences, King\u2019s College London, London, UK; Dyson School of Design Engineering, Imperial College London, London, UK; Dyson School of Design Engineering, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636571/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1436784880540582104&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Imperial College London;King\u2019s College London",
        "aff_unique_dep": "Dyson School of Design Engineering;Department of Surgical and Interventional Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.kcl.ac.uk",
        "aff_unique_abbr": "Imperial College;KCL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636090",
        "title": "A Mixed Reality Supervision and Telepresence Interface for Outdoor Field Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative human-robot field operations rely on timely decision-making and coordination, which can be challenging for heterogeneous teams operating in large-scale deployments. In this work, we present the design of an immersive, mixed reality (MR) interface to support sense-making and situational awareness based on the data collection capabilities of both human and robotic team members. Our solution integrates state-of-the-art methods in environment mapping and MR so that users may gain rapid insights regarding the working environment, the current and previous locations of human and robot team members, and the environment data such team members have collected. We describe the implementation of our system, share lessons learned in collaborating with emergency responders throughout our design process, and offer a vision for the use of immersive displays for human-robot field team deployments in large-scale outdoor environments.",
        "primary_area": "",
        "author": "Michael Walker;Zhaozhong Chen;Matthew Whitlock;David Blair;Danielle Albers Szafir;Christoffer Heckman;Daniel Szafir;Michael Walker;Zhaozhong Chen;Matthew Whitlock;David Blair;Danielle Albers Szafir;Christoffer Heckman;Daniel Szafir",
        "authorids": "/37086245063;/37086450966;/37086432016;/37089196319;/37085770068;/37086032368;/37086231248;/37086245063;/37086450966;/37086432016;/37089196319;/37085770068;/37086032368;/37086231248",
        "aff": "Department of Computer Science, University of Colorado Boulder; Department of Computer Science, University of Colorado Boulder; Department of Computer Science, University of Colorado Boulder; Department of Computer Science, University of Colorado Boulder; Department of Computer Science, University of North Carolina at Chapel Hill; Department of Computer Science, University of Colorado Boulder; Department of Computer Science, University of North Carolina at Chapel Hill",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636090/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15922930659517893581&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;1",
        "aff_unique_norm": "University of Colorado Boulder;University of North Carolina at Chapel Hill",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu;https://www.unc.edu",
        "aff_unique_abbr": "CU Boulder;UNC Chapel Hill",
        "aff_campus_unique_index": "0;0;0;0;1;0;1",
        "aff_campus_unique": "Boulder;Chapel Hill",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636558",
        "title": "A Morphing Quadrotor that Can Optimize Morphology for Transportation",
        "track": "main",
        "status": "Poster",
        "abstract": "Multirotors can be effectively applied to various tasks, such as transportation, investigation, exploration, and lifesaving, depending on the type of payload. However, due to the nature of multirotors, the payload loaded on the multirotor is limited in its position and weight, which presents a major disadvantage when the multirotor is used in various fields. In this paper, we propose a novel method that greatly improves the restrictions on payload position and weight using a morphing quadrotor system. Our method can estimate the drone\u2019s weight, center of gravity position, and inertia tensor in real-time, which change depending on payload, and determine the optimal morphology for efficient and stable flight. An adaptive control method that can reflect the change in flight dynamics by payload and morphing is also presented. Experiments were conducted to confirm that the proposed morphing quadrotor improves the stability and efficiency in various situations of transporting payloads compared with the conventional quadrotor systems.",
        "primary_area": "",
        "author": "Chanyoung Kim;Hyungyu Lee;Myeongwoo Jeong;Hyun Myung;Chanyoung Kim;Hyungyu Lee;Myeongwoo Jeong;Hyun Myung",
        "authorids": "/37088968738;/37088970270;/37088971325;/37424926900;/37088968738;/37088970270;/37088971325;/37424926900",
        "aff": "School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Urban Robotics Lab, School of Electrical Engineering, KI-AI, KI-R, KAIST, Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Urban Robotics Lab, School of Electrical Engineering, KI-AI, KI-R, KAIST, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636558/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12394279298966512977&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;KAIST",
        "aff_unique_dep": "School of Electrical Engineering;School of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.kaist.edu",
        "aff_unique_abbr": "KAIST;KAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636765",
        "title": "A Motion decoupled Aerial Robotic Manipulator for Better Inspection",
        "track": "main",
        "status": "Poster",
        "abstract": "For conventional aerial manipulators, the robotic arm is rigidly attached to the quadrotor. Consequently, the maneuver of the quadrotor will affect the motion of the robotic arm when it is used for tasks such as inspection. In this paper, we propose a novel aerial manipulator with a self-locking gimbal system which can switch between motion coupled and decoupled mode. Furthermore, a dynamic gravity compensation mechanism is designed, where the location of the battery and the number of teeth are optimized to minimize the weight imbalance of the robotic arm during its motions. To the best of the authors\u2019 knowledge, this is the first aerial manipulator with a motion-decoupled mechanism. Experimental results demonstrate that the proposed manipulator design can significantly improve the performance of the manipulator for general inspection tasks.",
        "primary_area": "",
        "author": "Rui Peng;Xianda Chen;Peng Lu;Rui Peng;Xianda Chen;Peng Lu",
        "authorids": "/37088446857;/37089196268;/37087243038;/37088446857;/37089196268;/37087243038",
        "aff": "Department of Mechanical Engineering, The University of Hong Kong; Department of Mechanical Engineering, The University of Hong Kong; Department of Mechanical Engineering, The University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636765/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7422225495214957155&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.hku.hk",
        "aff_unique_abbr": "HKU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635998",
        "title": "A Multi-Axis FBG-Based Tactile Sensor for Gripping in Space",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile sensing can improve end-effector control and grasp quality, especially for free-flying robots where target approach and alignment present particular challenges. However, many current tactile sensing technologies are not suitable for the harsh environment of space. We present a tactile sensor that measures normal and biaxial shear strains in the pads of a gripper using a single optical fiber with Bragg grating (FBG) sensors. Compared to conventional wired solutions, the encapsulated optical fibers are immune to electromagnetic interference \u2014 critical in the harsh environment of space. Sampling is possible at over 1 kHz to detect dynamic events. We mount sensor pads on a custom two-fingered gripper with independent control of the distal and proximal phalanges, allowing for grip readjustment based on sensing data. Calibrated sensor data for forces match those from a commercial multiaxial load cell with an average 96.2% RMS for all taxels. We demonstrate the gripper on tasks motivated by the Astrobee free-flying robots in the International Space Station (ISS): gripping corners, detecting misaligned grasps, and improving load sharing over the contact areas in pinch grasps.",
        "primary_area": "",
        "author": "Samuel Frishman;Julia Di;Zulekha Karachiwalla;Richard J. Black;Kian Moslehi;Trey Smith;Brian Coltin;Bijan Moslehi;Mark R. Cutkosky;Samuel Frishman;Julia Di;Zulekha Karachiwalla;Richard J. Black;Kian Moslehi;Trey Smith;Brian Coltin;Bijan Moslehi;Mark R. Cutkosky",
        "authorids": "/37086087081;/37089198216;/37089194061;/37591157500;/37089197659;/37085701375;/37592328000;/37424224600;/37329470000;/37086087081;/37089198216;/37089194061;/37591157500;/37089197659;/37085701375;/37592328000;/37424224600;/37329470000",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, California; Department of Mechanical Engineering, Stanford University, Stanford, California; Department of Computer Engineering, University of Maryland, Baltimore, Maryland; Intelligent Fiber Optic Systems Corporation, San Jose, California; Intelligent Fiber Optic Systems Corporation, San Jose, California; NASA Ames, Mountain View, California; NASA Ames, Mountain View, California; Intelligent Fiber Optic Systems Corporation, San Jose, California; Department of Mechanical Engineering, Stanford University, Stanford, California",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635998/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13928240790953778784&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;2;2;3;3;2;0",
        "aff_unique_norm": "Stanford University;University of Maryland, Baltimore;Intelligent Fiber Optic Systems Corporation;NASA Ames Research Center",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Computer Engineering;;",
        "aff_unique_url": "https://www.stanford.edu;https://www.umaryland.edu;;https://ames.nasa.gov",
        "aff_unique_abbr": "Stanford;UMB;;NASA Ames",
        "aff_campus_unique_index": "0;0;1;2;2;3;3;2;0",
        "aff_campus_unique": "Stanford;Baltimore;San Jose;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635852",
        "title": "A Multi-Chamber Smart Suction Cup for Adaptive Gripping and Haptic Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel robot end-effector for gripping and haptic exploration. Tactile sensing through suction flow monitoring is achieved with a new suction cup design that contains multiple chambers for air flow. Each chamber connects with its own remote pressure transducer, which enables both absolute and differential pressure measures between chambers. By changing the overall vacuum applied to this smart suction cup, it can perform different functions such as gentle haptic exploration (low pressure) and monitoring breaks in the seal during strong astrictive gripping (high pressure). Haptic exploration of surfaces through sliding and palpation can guide the selection of suction grasp locations and help to identify the local surface geometry. During suction gripping, a trained LSTM network can localize breaks in the suction seal between four quadrants with up to 97% accuracy and detects breaks in the suction seal early enough to avoid total grasp failure.",
        "primary_area": "",
        "author": "Tae Myung Huh;Kate Sanders;Michael Danielczuk;Monica Li;Yunliang Chen;Ken Goldberg;Hannah S. Stuart;Tae Myung Huh;Kate Sanders;Michael Danielczuk;Monica Li;Yunliang Chen;Ken Goldberg;Hannah S. Stuart",
        "authorids": "/37085751540;/37088083633;/37086541913;/37087043201;/37089196713;/37273026700;/37085437460;/37085751540;/37088083633;/37086541913;/37087043201;/37089196713;/37273026700;/37085437460",
        "aff": "Dept. of Mechanical Engineering, Embodied Dexterity Group, University of California Berkeley, Berkeley, CA, USA; Dept. of Electrical Engineering and Computer Science, Autolab, University of California Berkeley, Berkeley, CA, USA; Dept. of Electrical Engineering and Computer Science, Autolab, University of California Berkeley, Berkeley, CA, USA; Dept. of Mechanical Engineering, Embodied Dexterity Group, University of California Berkeley, Berkeley, CA, USA; Dept. of Electrical Engineering and Computer Science, Autolab, University of California Berkeley, Berkeley, CA, USA; Dept. of Electrical Engineering and Computer Science, Autolab, University of California Berkeley, Berkeley, CA, USA; Dept. of Mechanical Engineering, Embodied Dexterity Group, University of California Berkeley, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635852/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9527810571842345954&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635956",
        "title": "A Multi-Hypothesis Approach to Pose Ambiguity in Object-Based SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "In object-based Simultaneous Localization and Mapping (SLAM), 6D object poses offer a compact representation of landmark geometry useful for downstream planning and manipulation tasks. However, measurement ambiguity then arises as objects may possess complete or partial object shape symmetries (e.g., due to occlusion), making it difficult or impossible to generate a single consistent object pose estimate. One idea is to generate multiple pose candidates to counteract measurement ambiguity. In this paper, we develop a novel approach that enables an object-based SLAM system to reason about multiple pose hypotheses for an object, and synthesize this locally ambiguous information into a globally consistent robot and landmark pose estimation formulation. In particular, we (1) present a learned pose estimation network that provides multiple hypotheses about the 6D pose of an object; (2) by treating the output of our network as components of a mixture model, we incorporate pose predictions into a SLAM system, which, over successive observations, recovers a globally consistent set of robot and object (landmark) pose estimates. We evaluate our approach on the popular YCB-Video Dataset and a simulated video featuring YCB objects. Experiments demonstrate that our approach is effective in improving the robustness of object-based SLAM in the face of object pose ambiguity. 1",
        "primary_area": "",
        "author": "Jiahui Fu;Qiangqiang Huang;Kevin Doherty;Yue Wang;John J. Leonard;Jiahui Fu;Qiangqiang Huang;Kevin Doherty;Yue Wang;John J. Leonard",
        "authorids": "/37089270086;/37089002085;/37085769742;/37072299700;/37329387400;/37089270086;/37089002085;/37085769742;/37072299700;/37329387400",
        "aff": "MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635956/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17463686377610065194&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636392",
        "title": "A Multi-Modal Robotic Gripper with a Reconfigurable Base: Improving Dexterous Manipulation without Compromising Grasping Efficiency",
        "track": "main",
        "status": "Poster",
        "abstract": "Design optimization can lead to the development of robotic end-effectors with optimal grasping and dexterous, in-hand manipulation capabilities. In particular, the finger link dimensions have been identified as one of the primary design parameters that affects the performance of a robotic gripper. The ability of a gripper to manipulate objects is mainly attributed to the interaction between a set of coordinated fingers. This coordination is primarily affected by the inter-finger distance. This paper presents a framework for finding an appropriate distance between the finger bases of a two-fingered robotic gripper so as to increase the dexterous manipulation workspace for a range of object sizes. To do that, a parallel multi-start search algorithm is employed to solve a multiparametric optimization problem. The results demonstrate that different distances lead to completely different workspace shapes and that the ratio defined by the area of the optimized workspace (nominator) and the union of all workspaces (denominator) is always significantly less than 1. This means that the area of the union of all workspaces is always larger than the area of the \"optimized\" workspace. Based on these results a multi-modal robotic gripper with movable finger bases was developed. The proposed gripper can vary the distance between the finger bases online and it offers an increased dexterous manipulation workspace without sacrificing grasping performance.",
        "primary_area": "",
        "author": "Nathan Elangovan;Lucas Gerez;Geng Gao;Minas Liarokapis;Nathan Elangovan;Lucas Gerez;Geng Gao;Minas Liarokapis",
        "authorids": "/37087236413;/37086448935;/37087027460;/38558084100;/37087236413;/37086448935;/37087027460;/38558084100",
        "aff": "Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636392/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7092921457974424403&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Auckland",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "UoA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9636681",
        "title": "A Multi-Target Trajectory Planning of a 6-DoF Free-Floating Space Robot via Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Space robots have played an essential role in space junk removal. Compared with traditional model-based methods, model-free reinforcement learning methods are promising in tackling space capture missions, which is challenging due to the dynamic singular problem and measuring errors of dynamics parameters. Nevertheless, current research mostly focus on the single-target environment. In this paper, we propose a multi-target trajectory planning strategy of a 6-DoF free-floating space robot optimized by the Proximal Policy Optimization (PPO) algorithm. Furthermore, we adopt some augmentation techniques to improve the PPO algorithm on precision and stability of reaching multiple targets. In particular, we introduce an Action Ensembles Based on Poisson Distribution (AEP) method, which facilitates the policy to efficiently approximate the optimal policy. Our method can be easily extended to realize the task that the end-effector tracks a specific trajectory. We evaluate our approach on four tasks: circle trajectory tracking, external disturbances at joints, different masses of the base, and even single joint failure, without any further fine-tuning. The results suggest that the planning strategy has comparably high adaptability and anti-inference capacity. Qualitative results (videos) are available at [36].",
        "primary_area": "",
        "author": "Shengjie Wang;Xiang Zheng;Yuxue Cao;Tao Zhang;Shengjie Wang;Xiang Zheng;Yuxue Cao;Tao Zhang",
        "authorids": "/37089194492;/37086353886;/37088981851;/37288851000;/37089194492;/37086353886;/37088981851;/37288851000",
        "aff": "Department of Automation, Institute of Navigation and Control, Tsinghua University, Beijing, China; Department of Computer Science, City University of Hong Kong, Hong Kong, China; Beijing Institute of Control Engineering, Beijing, China; Department of Automation, Institute of Navigation and Control, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636681/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11175287024620812309&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Tsinghua University;City University of Hong Kong;Beijing Institute of Control Engineering",
        "aff_unique_dep": "Department of Automation, Institute of Navigation and Control;Department of Computer Science;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.cityu.edu.hk;",
        "aff_unique_abbr": "THU;CityU;",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Beijing;Hong Kong",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635900",
        "title": "A Multimodal and Hybrid Framework for Human Navigational Intent Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding human navigational intent is essential for robots to be able to interact with and navigate around humans safely and naturally. Current methods typically perform inference through only one mode of perception such as human motion trajectory, and a single theoretical framework such as a learning-based or classical approach. In contrast, this paper studies prediction of human navigational intent using multimodal perception within a hybrid framework. Our framework consists of two modules: a) a learning-based prediction module to predict a human\u2019s future goal position, and b) a classical control theory-inspired reconstruction module to reconstruct a possible future trajectory or a set of possible future positions using the predicted future goal position. For the prediction module, we propose an end-to-end LSTM-CNN hybrid neural network for predicting a human\u2019s future position in the real world, given human motion, human body pose and head orientation. This visual information from an egocentric perspective is used to make predictions of a human\u2019s future position in world space, essential for robotic navigation algorithms and planning. In the reconstruction module, we present two control theoretic methods to reconstruct possible future trajectories of human: trajectory generation for differentially flat system and reachability analysis. We evaluate the performance of our framework on a newly collected dataset called SFU-Store-Nav. Experimental results reveal that our method outperforms various baselines especially when a relatively small amount of data is available.",
        "primary_area": "",
        "author": "Zhitian Zhang;Jimin Rhim;Angelica Lim;Mo Chen;Zhitian Zhang;Jimin Rhim;Angelica Lim;Mo Chen",
        "authorids": "/37086885898;/37087120992;/37086880157;/37085494765;/37086885898;/37087120992;/37086880157;/37085494765",
        "aff": "School of Computing Science, Simon Fraser University, Burnaby, BC, Canada; School of Computing Science, Simon Fraser University, Burnaby, BC, Canada; School of Computing Science, Simon Fraser University, Burnaby, BC, Canada; School of Computing Science, Simon Fraser University, Burnaby, BC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635900/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6383547593604963881&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Simon Fraser University",
        "aff_unique_dep": "School of Computing Science",
        "aff_unique_url": "https://www.sfu.ca",
        "aff_unique_abbr": "SFU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Burnaby",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636774",
        "title": "A New Method for Generating Work Piece Surface Representations for Robotic Machining",
        "track": "main",
        "status": "Poster",
        "abstract": "Execution of automatically generated programs for accurate robotic machining requires the generated trajectories to be not only accurate with respect to the work piece, but also that the trajectories are continuous differentiable (C1) while avoiding unnecessary large curvatures leading to large accelerations that could compromise machining quality or speed. A widely used work piece representation is 3D triangle meshes as they can be easily generated in any CAD representations and from surface scans, and they are also very suitable for robotics applications. However, they lack the C1 property across the triangle edges.In this paper, a new method for generating C1 surfaces based on 3D triangle meshes is presented. It will be shown by an example that the method is as good as existing methods with respect to the accuracy of the generated surface, and that the problem with large curvatures is much smaller than for existing methods. Moreover, the difficult input specification of derivatives at the vertices is avoided with this method.",
        "primary_area": "",
        "author": "Nikolaj W. Leth;Henrik G. Petersen;Nikolaj W. Leth;Henrik G. Petersen",
        "authorids": "/37089196210;/37562505800;/37089196210;/37562505800",
        "aff": "SDU Robotics, University of Southern Denmark, Denmark; SDU Robotics, University of Southern Denmark, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636774/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5046706876995439938&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Southern Denmark",
        "aff_unique_dep": "SDU Robotics",
        "aff_unique_url": "https://www.sdu.dk",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9636689",
        "title": "A Novel 2-SUR 6-DOF Parallel Manipulator Actuated by Spherical Motion Generators",
        "track": "main",
        "status": "Poster",
        "abstract": "A novel 6-DOF parallel manipulator with two spherical-universal-revolute limbs is proposed in this work. Compared with general 6-DOF parallel manipulators of six kinematic limbs, this new manipulator actuated by spherical motion generators has only two limbs, which brings kinematic advantages such as small footprint and large workspace. The inverse position problem of the manipulator is solved by an analytical approach, upon which velocity equations are formulated. Kinematic performance including workspace and also manipulability are calculated to show the advantages of the new design.",
        "primary_area": "",
        "author": "Kun Wang;Xiaoyong Wu;Yujin Wang;Bo Li;Bo Yuan;Shaoping Bai;Kun Wang;Xiaoyong Wu;Yujin Wang;Bo Li;Bo Yuan;Shaoping Bai",
        "authorids": "/37086959001;/37088572856;/37088577233;/37089194301;/37089197201;/37288297800;/37086959001;/37088572856;/37088577233;/37089194301;/37089197201;/37288297800",
        "aff": "School of Mechanical Engineering, Chongqing University of Technology, Chongqing, China; School of Mechanical Engineering, Chongqing University of Technology, Chongqing, China; School of Mechanical Engineering, Chongqing University of Technology, Chongqing, China; School of Mechanical Engineering, Chongqing University of Technology, Chongqing, China; School of Mechanical Engineering, Chongqing University of Technology, Chongqing, China; Department of Materials and Production, Aalborg University, Aalborg, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636689/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2069112906418788481&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Chongqing University of Technology;Aalborg University",
        "aff_unique_dep": "School of Mechanical Engineering;Department of Materials and Production",
        "aff_unique_url": ";https://www.aau.dk",
        "aff_unique_abbr": ";AAU",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Chongqing;Aalborg",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;Denmark"
    },
    {
        "id": "9636121",
        "title": "A Novel Curved Gaussian Mixture Model and Its Application in Motion Skill Encoding",
        "track": "main",
        "status": "Poster",
        "abstract": "The purpose of this paper is to present a novel curved Gaussian Mixture Model (CGMM) and to study the application of it in motion skill encoding. Primarily, Gaussian mixture model (GMM) has been widely applied on many occasions when a probability density function is needed to approximate a complex probability distribution. However, GMM cannot efficiently approach highly non-linear distributions. Thus, the proposed novel CGMM, as a weighted mixture of curved Gaussian models (CGM), is structured with non-linear transfers, which reshapes the flat GMM into a geo-metrically curved one. As a consequence, CGMM has more freedoms and flexibilities than the flat GMM so a CGMM requires fewer number of components in fitting highly non-linear motion trajectories. Moreover, we derive a dedicated iterative parameter estimation algorithm for the CGMM based on maximum likelihood estimation (MLE) theory. To evaluate the performance of the CGMM and its parameter estimation algorithm, a series of quantitative experiments are carried out. We first test the model performance in the data fitting task with the generated synthetic data. Then a motion skill encoding test is carried out on a human motion trajectory dataset built by a Virtual Reality (VR) based motion tracking system. The empirical results support that CGMM outperforms state-of-the-arts in the model performance test. Meanwhile, CGMM has a significant improvement in encoding high dimensional non-linear trajectory data compared to the GMM in motion skill encoding test with its dedicated parameter estimation algorithm.",
        "primary_area": "",
        "author": "Disi Chen;Gongfa Li;Dalin Zhou;Zhaojie Ju;Disi Chen;Gongfa Li;Dalin Zhou;Zhaojie Ju",
        "authorids": "/37086608320;/37405549700;/37085593661;/37591031600;/37086608320;/37405549700;/37085593661;/37591031600",
        "aff": "School of Computing, Faculty of Technology, University of Portsmouth, Portsmouth, UK; School of Machinery and Automation, Wuhan University of Science and Technology, Wuhan, China; School of Computing, Faculty of Technology, University of Portsmouth, Portsmouth, UK; School of Computing, Faculty of Technology, University of Portsmouth, Portsmouth, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636121/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13543075750637222843&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Portsmouth;Wuhan University of Science and Technology",
        "aff_unique_dep": "School of Computing;School of Machinery and Automation",
        "aff_unique_url": "https://www.port.ac.uk;http://www.wust.edu.cn",
        "aff_unique_abbr": "UoP;",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Portsmouth;Wuhan",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9635942",
        "title": "A Novel Design of Mobile Robotic System for Opening and Transitioning Through a Watertight Ship Door",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent offshore drilling activities have dramatically bloomed oil and gas production. Due to extreme weather, such as hurricanes and tsunamis, offshore oil platforms may need to be constantly monitored in case of unexpected dangers. Using robots to monitor and prevent these dangerous situations is a cost-effective and safer solution compared to any human involvement. However, one major drawback for robotic intervention is the ability of the robot to operate water tight ship doors designed for marina facilities. Current studies have been focused on robots manipulating normal doors in people's daily life. However their presented methodology may not be suitable for opening heavy watertight ship doors since they have a special locking structure which needs much larger torque to open. This study explores the possibility of opening heavy watertight ship doors with an ordinary mobile robot under remote control. Given the watertight ship door\u2019s unique structure, a door opening tool with a pawl mechanism is designed for a mobile robot, which consists of a robotic arm and a wheeled platform, to complete the task. Experimental results have shown that the mobile robot can operate the tool to open the door and transition through the door.",
        "primary_area": "",
        "author": "Wenyu Zuo;Rahul Venkatraman;Gangbing Song;Zheng Chen;Wenyu Zuo;Rahul Venkatraman;Gangbing Song;Zheng Chen",
        "authorids": "/37086934162;/37089197231;/37420326900;/37085888133;/37086934162;/37089197231;/37420326900;/37085888133",
        "aff": "Department of Mechanical Engineering, University of Houston; Department of Mechanical Engineering, University of Houston; Mechanical Engineering, University of Houston; Mechanical Engineering, University of Houston, Houston, Texas",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635942/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=410968290855380203&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Houston",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.uh.edu",
        "aff_unique_abbr": "UH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Houston;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636168",
        "title": "A Novel Model-Based Robust Super-Twisting Sliding Mode Control of PKMs: Design and Real-Time Experiments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a new robust model-based super-twisting algorithm is proposed as a control solution for parallel kinematic manipulators (PKMs). The conventional super-twisting algorithm for robot manipulators has the structure of a computed-torque control which can be sensitive to measurement noise. This issue may deteriorate the dynamic performance of the manipulator and reduce its robustness towards changes in the operating conditions. The proposed approach, relying on the desired trajectory, is more computationally efficient and more robust. It includes a feedforward dynamic compensator, the super-twisting feedback control, and a feedback stabilizing term. As a validation, real-time experiments have been conducted on a 5-DOF redundantly actuated PKM. Several scenarios have been tested including nominal case and the robustness towards speed variations. The relevance of the proposed control solution is proved through the improvement of the tracking performance at different dynamic operating conditions.",
        "primary_area": "",
        "author": "Hussein Saied;Ahmed Chemori;Maher El Rafei;Clovis Francis;Hussein Saied;Ahmed Chemori;Maher El Rafei;Clovis Francis",
        "authorids": "/37086575618;/37273794600;/37640431900;/37282524600;/37086575618;/37273794600;/37640431900;/37282524600",
        "aff": "CRSI, Lebanese University, Beirut, Lebanon; LIRMM, University of Montpellier, CNRS, Montpellier, France; CRSI, Lebanese University, Beirut, Lebanon; CRSI, Lebanese University, Beirut, Lebanon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636168/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4422700177468571075&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Lebanese University;University of Montpellier",
        "aff_unique_dep": "CRSI;LIRMM",
        "aff_unique_url": ";https://www.univ-montp2.fr",
        "aff_unique_abbr": ";UM",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Beirut;Montpellier",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Lebanon;France"
    },
    {
        "id": "9636026",
        "title": "A Novel Quotient Space Approach to Model-Based Fault Detection and Isolation: Theory and Preliminary Simulation Evaluation",
        "track": "main",
        "status": "Poster",
        "abstract": "We report the development of novel fault detection and isolation (FDI) methods for model-based fault detection (MB-FD) and quotient-space fault isolation (QS-FI). This FDI approach performs MB-FD and QS-FI of single or multiple con-current faults in plants and actuators simultaneously, without a priori knowledge of fault form, type, or dynamics. To detect faults, MB-FD characterizes deviation from nominal behavior using the plant velocity and plant and actuator parameters estimated by nullspace-based adaptive identification. To isolate (i.e. identify) faults, the QS-FI algorithm compares the estimated parameters to a nominal parameter class in progressively decreasing-dimensional quotient spaces of the parameter space. A preliminary simulation study of these proposed FDI methods applied to a three degree-of-freedom uninhabited underwater vehicle plant model shows their ability to detect as well as isolate faults for the cases of both single and multiple simultaneous faults and suggests the generalizability of the MB-FD and QS-FI approaches to any well-defined second-order plant and actuator model whose parameters enter linearly: a broad class of systems which includes aerial vehicles, marine vehicles, spacecraft, and robot arms.",
        "primary_area": "",
        "author": "Annie M. Mao;Louis L. Whitcomb;Annie M. Mao;Louis L. Whitcomb",
        "authorids": "/37089197888;/37283591700;/37089197888;/37283591700",
        "aff": "Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636026/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5837447135997570142&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636153",
        "title": "A Novel Wax Based Piezo Actuator for Autonomous Deep Anterior Lamellar Keratoplasty (Piezo-DALK)",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper reports the design and evaluation of a novel piezo based actuator for needle drive in autonomous Deep Anterior Lamellar Keratoplasty (piezo-DALK). The actuator weighs less than 8g and is 20mm x 20mm x 10.5mm in size, making it ideal for eye-mounted applications. Mean open loop positional deviation was 1.17 \u00b1 3.15um, and system repeatability and accuracy were 17.16um and 18.33um, respectively. Stall force was found to vary linearly with the cooling cycle and the actuator achieved a maximum drive force of 3.98N. When simulating the DALK procedure in synthetic corneal tissue, the piezo-DALK achieved a penetration depth of 643.56um which was equivalent to 92.1% of the total corneal thickness. This correlated closely with our desired depth of 90% \u00b1 5% and took 2.5 hours to achieve. This work represents the first eye mountable actuator capable of \"Big Bubble\" needle drive for autonomous DALK procedures.",
        "primary_area": "",
        "author": "J. D. Opfermann;M. Barbic;M. Khrenov;S. Guo;N. R. Sarfaraz;J. U. Kang;A. Krieger;J. D. Opfermann;M. Barbic;M. Khrenov;S. Guo;N. R. Sarfaraz;J. U. Kang;A. Krieger",
        "authorids": "/37085778776;/37089197807;/37089194487;/37087040645;/37087323385;/37273713000;/38484449800;/37085778776;/37089197807;/37089194487;/37087040645;/37087323385;/37273713000;/38484449800",
        "aff": "Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Tech4Health Institute, NYU School of Medicine, New York, NY, USA; Department of Mechanical Engineering, University of Maryland, College Park, MD, USA; Department of Electrical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, University of Maryland, College Park, MD, USA; Department of Electrical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636153/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14409850409285795515&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;2;0;0",
        "aff_unique_norm": "Johns Hopkins University;New York University School of Medicine;University of Maryland",
        "aff_unique_dep": "Department of Mechanical Engineering;Tech4Health Institute;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu;https://med.nyu.edu;https://www/umd.edu",
        "aff_unique_abbr": "JHU;NYU School of Medicine;UMD",
        "aff_campus_unique_index": "0;1;2;0;2;0;0",
        "aff_campus_unique": "Baltimore;New York;College Park",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636447",
        "title": "A Parameter Identification Method for Static Cosserat Rod Models: Application to Soft Material Actuators with Exteroceptive Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft material robotics is a rather young research field in the robotics and material science communities. A popular design is the soft pneumatic actuator (SPA) which, if connected serially, becomes a highly compliant manipulator. This high compliance makes it possible to adapt to the environment and in the future might be very useful for manipulation tasks in narrow and wound environments. A central topic is the modelling of the manipulators. While comparatively rigid continuum robots are build of metal or other materials, that conduct a linear behaviour, the material used in soft material robotics often exhibits a nonlinear stress-strain relationship. In this paper we contribute an identification method for material parameters and data-based approach within the constitutive equations of a Cosserat rod model. We target bending and extension stiffness, consider shear and neglect torsional strains. The proposed method is applicable to any continuum robot which can be modelled by the classic theory of special Cosserat rods, including constraint models, and shows great improvement in experimental results with mean position errors of 0.59% reference length.",
        "primary_area": "",
        "author": "Max Bartholdt;Mats Wiese;Moritz Schappler;Svenja Spindeldreier;Annika Raatz;Max Bartholdt;Mats Wiese;Moritz Schappler;Svenja Spindeldreier;Annika Raatz",
        "authorids": "/37089194118;/37086148951;/37086131932;/37088940377;/37394383100;/37089194118;/37086148951;/37086131932;/37088940377;/37394383100",
        "aff": "Institute of Mechatronic Systems, Leibniz University, Hannover, Germany; Institute of Assembly Technology, Leibniz University, Hannover, Germany; Institute of Mechatronic Systems, Leibniz University, Hannover, Germany; Institute of Mechatronic Systems, Leibniz University, Hannover, Germany; Institute of Assembly Technology, Leibniz University, Hannover, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636447/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1316503893716995012&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Leibniz University Hannover",
        "aff_unique_dep": "Institute of Mechatronic Systems",
        "aff_unique_url": "https://www.tu-hannover.de",
        "aff_unique_abbr": "LUH",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hannover",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636644",
        "title": "A Photorealistic Terrain Simulation Pipeline for Unstructured Outdoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Suitable datasets are an integral part of robotics research, especially for training neural networks in robot perception. However, in many domains, suitable real-world data are scarce and cannot be easily obtained. This problem is especially prevalent for unstructured outdoor environments, in particular, planetary ones. Recent advances in photorealistic simulations help researchers to simulate close-to-real data in many domains. Yet, there exists no high-quality synthetic data for planetary exploration tasks. Also, existing simulators lack the fidelity required for generating planetary data, which is inherently less structured than human environments. Synthetic planetary data requires careful modeling and annotation of many different terrain aspect and details, such as textures and distributions of rocks, to become a valuable test-bed for robotics. To fill this gap, we present a novel simulator specifically designed for the needs of planetary robotics visual tasks, but also applicable for other outdoor environments. Our simulator is capable of generating large varieties of (planetary) outdoor scenes with rich generation of meta data, such as multilevel semantic and instance annotations. To demonstrate the wide applicability of this new simulator, we evaluate its performance on typical robotics applications, i.e. semantic segmentation, instance segmentation, and visual SLAM. Our simulator is accessible under https://github.com/DLR-RM/oaisys.",
        "primary_area": "",
        "author": "M. G. M\u00fcller;M. Durner;A. Gawel;W. St\u00fcrzl;R. Triebel;R. Siegwart;M. G. M\u00fcller;M. Durner;A. Gawel;W. St\u00fcrzl;R. Triebel;R. Siegwart",
        "authorids": "/37088444744;/37086116487;/37085766697;/37598170500;/37542908700;/37281398300;/37088444744;/37086116487;/37085766697;/37598170500;/37542908700;/37281398300",
        "aff": "Autonomous Systems Lab, Swiss Federal Institute of Technology (ETH Z\u00fcrich), Switzerland; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Autonomous Systems Lab, Swiss Federal Institute of Technology (ETH Z\u00fcrich), Switzerland; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Autonomous Systems Lab, Swiss Federal Institute of Technology (ETH Z\u00fcrich), Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636644/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18404458969822503845&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;1;0",
        "aff_unique_norm": "ETH Zurich;German Aerospace Center",
        "aff_unique_dep": "Autonomous Systems Lab;Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.ethz.ch;https://www.dlr.de",
        "aff_unique_abbr": "ETH Z\u00fcrich;DLR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Z\u00fcrich;",
        "aff_country_unique_index": "0;1;0;1;1;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "9636265",
        "title": "A Portable Remote Optoelectronic Tweezer System for Microobjects Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Non-contact manipulation technology has extensive application in the manipulation and fabrication of micro/nanomaterials. However, the manipulation devices are often precise and complex, operated only by professionals and subject to site constraints. We propose a simple optoelectronic tweezer platform, which can be controlled remotely and simply for the manipulation of microparticles at different scales, based on the novel manipulation technique called optically-induced dielectrophoresis. In this work, we design and set up the optoelectronic tweezer manipulation platform and develop the full-function human-computer interactive control interface and graphics rendering system to simplify the micro-operation process. Using Qt5.0 development environment, an experimental image processing system with multi-thread characteristics is developed, and the information interaction requirements needed in the experimental operation of optoelectronic tweezers are integrated into a control system to achieve unified information management and data analysis. Combined with cloud computing technology, the system realizes local/remote synchronous linkage operation, with cross-platform operation capability of various portable operating terminals like laptop and iPad.",
        "primary_area": "",
        "author": "Yuqing Cao;Shuzhang Liang;Hanlong Chen;Chunyuan Gan;Li Song;Chaonan Zhang;Fumihito Arai;Lin Feng;Yuqing Cao;Shuzhang Liang;Hanlong Chen;Chunyuan Gan;Li Song;Chaonan Zhang;Fumihito Arai;Lin Feng",
        "authorids": "/37089153376;/37087246689;/37089198076;/37089153741;/37087124252;/37086022880;/37274069600;/37403324400;/37089153376;/37087246689;/37089198076;/37089153741;/37087124252;/37086022880;/37274069600;/37403324400",
        "aff": "School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; Hanlong Chen; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; Department of Mechanical Engineering, The University of Tokyo, Tokyo, Japan; Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636265/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9478562875061370629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;2;0",
        "aff_unique_norm": "Beihang University;;University of Tokyo",
        "aff_unique_dep": "School of Mechanical Engineering & Automation;;Department of Mechanical Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn;;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "Beihang;;UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;2;0",
        "aff_campus_unique": "Beijing;;Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;2;0",
        "aff_country_unique": "China;;Japan"
    },
    {
        "id": "9636324",
        "title": "A Powered Prosthetic Ankle Designed for Task Variability \u2013 A Concept Validation",
        "track": "main",
        "status": "Poster",
        "abstract": "Ankle joints play key roles in everyday locomotion, such as walking, stair climbing, and sit-to-stand. Despite the achievement in designing powered prosthetic ankles, engineers still face challenges to duplicate the full mechanics of ankle joints, including high torque, large range of motion (ROM), low profile, backdrivability, and efficiency, using electric motors and related transmissions. In this study, our goal was to develop a new active prosthetic ankle, Variable Spring embedded Motor-ball screw (VSeM) ankle, to meet all these requirements at the same time. Using a manually adjustable elastic element, which is parallel with our motor actuator, we can readjust the ROM of VSeM to handle all normal locomotion tasks. VSeM\u2019s capability to mimic human ankle was validated through both bench tests and human subject tests.",
        "primary_area": "",
        "author": "Sameer Upadhye;Chinmay Shah;Ming Liu;Gregory Buckner;He Helen Huang;Sameer Upadhye;Chinmay Shah;Ming Liu;Gregory Buckner;He Helen Huang",
        "authorids": "/37089193983;/37086142233;/38237723700;/37331413300;/37401091200;/37089193983;/37086142233;/38237723700;/37331413300;/37401091200",
        "aff": "Department of Mechanical and Aerospace Engineering, North Carolina State University, Raleigh, NC, USA; Department of Mechanical and Aerospace Engineering, North Carolina State University, Raleigh, NC, USA; Joint Department of Biomedical Engineering, North Carolina State University/University of North Carolina, Chapel Hill, NC, USA; Department of Mechanical and Aerospace Engineering, North Carolina State University, Raleigh, NC, USA; Joint Department of Biomedical Engineering, North Carolina State University/University of North Carolina, Chapel Hill, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636324/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14938954022604379100&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "North Carolina State University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ncsu.edu",
        "aff_unique_abbr": "NCSU",
        "aff_campus_unique_index": "0;0;1;0;1",
        "aff_campus_unique": "Raleigh;Chapel Hill",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636055",
        "title": "A Predictive Control Method for Stabilizing a Manipulator-based UAV Landing Platform on Fluctuating Marine Surface",
        "track": "main",
        "status": "Poster",
        "abstract": "In the process of landing unmanned aerial vehicles (UAVs) on an unmanned surface vehicle (USV), a manipulator can be applied to help the UAV land safely and accurately. However, it is a challenge to control the manipulator on a disturbed USV due to joint velocity constraints and bandwidth limitations. To solve this problem, a predictive control framework is proposed in this paper. We leverage a first-order delay system to describe the kinematics of each joint, and control joint velocities by the model predictive controller (MPC). To generate references for MPC, the motion of the floating base needs to be predicted. We apply the recent approach for motion prediction based on the wavelet network (WN) and modify the network to get smooth trajectories. The accuracy of the modified wavelet network (MWN) for motion prediction is tested on four-hour motion data from the real ocean environment and the smoothness of the generated trajectories is also evaluated. Simulations and experiments are implemented to verify the proposed method, the results show that the average control accuracies are improved by more than 30% and 50% in position and rotation compared with the traditional inverse kinematics (IK) controller for 1 Hz base fluctuation.",
        "primary_area": "",
        "author": "Ruoyu Xu;Xiaoqiang Ji;Jiafan Hou;Hengli Liu;Huihuan Qian;Ruoyu Xu;Xiaoqiang Ji;Jiafan Hou;Hengli Liu;Huihuan Qian",
        "authorids": "/37087047735;/37088954362;/37087245956;/37086607474;/37549401900;/37087047735;/37088954362;/37087245956;/37086607474;/37549401900",
        "aff": "School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636055/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7206260957886323596&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "School of Science and Engineering",
        "aff_unique_url": "https://www.cuhk.edu.cn",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636403",
        "title": "A Real-Time Motion Detection and Object Tracking Framework for Future Robot-Rat Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an automatic robot-rat interaction framework that enables a robotic rat to realize real-time localization, tracking and movement analysis of a laboratory rat. Specifically, we combine an object detector with stereo matching to achieve fast localization of the laboratory rat. Combined with the rat-like motion of the robot, one-step tracking of the rat is achieved, which enables the robot to eliminate last location error in one cycle of visual servo control. When positioning the rat, a unified quantitative description and analysis of rat motion is implemented by using a state vector composed of the centroids of head, body and tail. Preliminary robot-rat interaction tests show that the robot achieved a steady tracking of a fast-moving rat for a duration of 10 minutes. To the best of our knowledge, it is the first time that a rat-sized robot achieves a continuous tracking of actual rats by a built-in miniature stereo vision system. Experimental results show that the sequence of state vectors accurately represents the pitch movement of the rat. Thus, this work is a step toward more natural interaction between robots and animals.",
        "primary_area": "",
        "author": "Chen Chen;Guanglu Jia;Zihang Gao;Xiaowen Guo;Qiang Huang;Toshio Fukuda;Qing Shi;Chen Chen;Guanglu Jia;Zihang Gao;Xiaowen Guo;Qiang Huang;Toshio Fukuda;Qing Shi",
        "authorids": "/37089393723;/37086250433;/37086594901;/37089195994;/37279982900;/37279174500;/37593189500;/37089393723;/37086250433;/37086594901;/37089195994;/37279982900;/37279174500;/37593189500",
        "aff": "Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing; Key Laboratory of Biomimetic Robots and Systems (Beijing Institute of Technology), Ministry of Education, Beijing, China; Key Laboratory of Biomimetic Robots and Systems (Beijing Institute of Technology), Ministry of Education, Beijing, China; Key Laboratory of Biomimetic Robots and Systems (Beijing Institute of Technology), Ministry of Education, Beijing, China; Key Laboratory of Biomimetic Robots and Systems (Beijing Institute of Technology), Ministry of Education, Beijing, China; Key Laboratory of Biomimetic Robots and Systems (Beijing Institute of Technology), Ministry of Education, Beijing, China; Key Laboratory of Biomimetic Robots and Systems (Beijing Institute of Technology), Ministry of Education, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636403/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17796116093557933992&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Beijing Institute of Technology",
        "aff_unique_dep": "School of Mechatronical Engineering",
        "aff_unique_url": "http://www.bit.edu.cn",
        "aff_unique_abbr": "BIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636775",
        "title": "A Reconfigurable Interface for Ergonomic and Dynamic Tele-Locomanipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Prolonged remote tele-locomanipulation of multi degrees-of-freedom mobile manipulators requires a compromise between the system\u2019s performance and the operator\u2019s ergonomics. Neglecting this demand can significantly affect either the task completion or the level of comfort to achieve it. However, the simultaneous consideration of these key factors has received less attention in the literature. To respond to this demand, in this work, we introduce a new teleoperation setup, which integrates the features of an ergonomic and a highly maneuverable interface into a unified solution. The ergonomic part of the interface implements a 3D mouse-like functionality, enabling the execution of long navigation tasks for the floating base. The highly manoeuvrable interface instead, enables the operator to perform dynamic or more precise manipulation by moving his/her arm in space. The locomotion and manipulation modes of the follower robot are controlled separately, which can be easily and seamlessly switched by the operator by pressing a button at any moment. Furthermore, due to the follower manipulator\u2019s redundancy, this robot is controlled by a hierarchical quadratic programming technique which enables the definition of a set of secondary tasks to be executed in the robot\u2019s nullspace. Finally, to demonstrate the advantages and disadvantages of the proposed user interfaces, five participants are asked to perform two different experiments: (i) target selection task on a moving surface and (ii) remote path tracking on a fixed surface. The quantitative and qualitative analyses show the effectiveness of the proposed interface during the teleoperation tasks, especially when it comes to the precise and dynamic task execution.",
        "primary_area": "",
        "author": "Soheil Gholami;Francesco Tassi;Elena De Momi;Arash Ajoudani;Soheil Gholami;Francesco Tassi;Elena De Momi;Arash Ajoudani",
        "authorids": "/37085622074;/37086861229;/37947344300;/37945239900;/37085622074;/37086861229;/37947344300;/37945239900",
        "aff": "Dept. of Electronics, Information and Bioengineering, NearLab, Politecnico di Milano, Milan, Italy; Dept. of Electronics, Information and Bioengineering, NearLab, Politecnico di Milano, Milan, Italy; Dept. of Electronics, Information and Bioengineering, NearLab, Politecnico di Milano, Milan, Italy; Human-Robot Interfaces and Physical Interaction (HRI2) Lab, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636775/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8971136656420677481&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Politecnico di Milano;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Dept. of Electronics, Information and Bioengineering;Human-Robot Interfaces and Physical Interaction (HRI2) Lab",
        "aff_unique_url": "https://www.polimi.it;https://www.iit.it",
        "aff_unique_abbr": "Politecnico di Milano;IIT",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Milan;Genoa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9635878",
        "title": "A Registration-aided Domain Adaptation Network for 3D Point Cloud Based Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "In the field of large-scale SLAM for autonomous driving and mobile robotics, 3D point cloud based place recognition has aroused significant research interest due to its robustness to changing environments with drastic daytime and weather variance. However, it is time-consuming and effort-costly to obtain high-quality point cloud data for place recognition model training and ground truth for registration in the real world. To this end, a novel registration-aided 3D domain adaptation network for point cloud based place recognition is proposed. A structure-aware registration network is introduced to help to learn features with geometric information and a 6-DoFs pose between two point clouds with partial overlap can be estimated. The model is trained through a synthetic virtual LiDAR dataset through GTA-V with diverse weather and daytime conditions and domain adaptation is implemented to the real-world domain by aligning the global features. Our results outperform state-of-the-art 3D place recognition baselines or achieve comparable on the real-world Oxford RobotCar dataset with the visualization of registration on the virtual dataset.",
        "primary_area": "",
        "author": "Zhijian Qiao;Hanjiang Hu;Weiang Shi;Siyuan Chen;Zhe Liu;Hesheng Wang;Zhijian Qiao;Hanjiang Hu;Weiang Shi;Siyuan Chen;Zhe Liu;Hesheng Wang",
        "authorids": "/37088419070;/37087321985;/37089196397;/37088403177;/38505849700;/37292567100;/37088419070;/37087321985;/37089196397;/37088403177;/38505849700;/37292567100",
        "aff": "Department of Automation, Shanghai Jiao Tong University, China; Department of Mechanical Engineering, Carnegie Mellon University, USA; Department of Automation, Shanghai Jiao Tong University, China; Department of Automation, Shanghai Jiao Tong University, China; Department of Computer Science and Technology, University of Cambridge, United Kingdom; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635878/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7120104333549246992&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;2;3",
        "aff_unique_norm": "Shanghai Jiao Tong University;Carnegie Mellon University;University of Cambridge;Beijing Institute of Technology",
        "aff_unique_dep": "Department of Automation;Department of Mechanical Engineering;Department of Computer Science and Technology;Beijing Advanced Innovation Center for Intelligent Robots and Systems",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.cmu.edu;https://www.cam.ac.uk;http://www.bit.edu.cn/",
        "aff_unique_abbr": "SJTU;CMU;Cambridge;BIT",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Cambridge;Beijing",
        "aff_country_unique_index": "0;1;0;0;2;0",
        "aff_country_unique": "China;United States;United Kingdom"
    },
    {
        "id": "9636104",
        "title": "A Resolution Adaptive Algorithm for the Stochastic Orienteering Problem with Chance Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We study a stochastic version of the classic orienteering problem where the time to traverse an edge is a continuous random variable. For a given temporal deadline B, our solution produces a policy, i.e., a function that, based on the current position along a solution path and the elapsed time, decides whether to continue along the path or take a shortcut to avoid missing the deadline. The solution is based on a formulation using constrained Markov decision processes to ensure that the deadline is met with a preassigned confidence level. To expedite the computation, a Monte Carlo simulation on an open loop policy is run to determine how to adaptively discretize the temporal dimension and therefore reduce the number of states and the number of optimization variables in the associated linear program. Our results show that the adaptive algorithm matches the performance of the non-adaptive one while taking significantly less time.",
        "primary_area": "",
        "author": "Thomas C. Thayer;Stefano Carpin;Thomas C. Thayer;Stefano Carpin",
        "authorids": "/37086455994;/37328709200;/37086455994;/37328709200",
        "aff": "Department of Computer Science and Engineering, University of California, Merced, CA, USA; Department of Computer Science and Engineering, University of California, Merced, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636104/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3430132182524411348&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Merced",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ucmerced.edu",
        "aff_unique_abbr": "UC Merced",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Merced",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635979",
        "title": "A Robust Data-Driven Approach for Dynamics Model Identification in Trajectory Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a data-driven modelling framework using a sparse regression technique to find the governing equations of dynamics systems. With this approach, the prior knowledge of features from simple structures can be used to deduce which on complex structures. The prior knowledge of single-pendulums, double-pendulums, and spherical pendulum enlightens the guess of the feature library for a 3-DOF manipulator. The feature library is sparsifled with a fully autonomous machine learning algorithm composited of the L1-regularization and proportional filter. The training dataset with non-zero-mean Gaussian noise simulates real-world conditions and proves the system's robustness to the noise. Compared with the neural-network-based system identification method, this paper's technique can be promptly applied in dynamic trajectory planning. A simulation of the optimal trajectory planning for the obstacle-avoidance on the Lynxmotion robot is accomplished by optimizing the objective function constructed with energy and penalty function. Results of the simulation support that the estimated model works correctly. Comparison between the data-driven and the closed-form model evidences the reliability and robustness of this identification technique.",
        "primary_area": "",
        "author": "Jiangqiu Chen;Minyu Zhang;Zhifei Yang;Linqing Xia;Jiangqiu Chen;Minyu Zhang;Zhifei Yang;Linqing Xia",
        "authorids": "/37089196314;/37089195278;/37089194108;/37089194955;/37089196314;/37089195278;/37089194108;/37089194955",
        "aff": "Department of Engineering Mathematics, Faculty of Engineering, University of Bristol, Bristol, UK; Department of Engineering Mathematics, Faculty of Engineering, University of Bristol, Bristol, UK; Department of Engineering Mathematics, Faculty of Engineering, University of Bristol, Bristol, UK; Shanghai Electric Group Co., Ltd. Central Academe, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635979/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17449338873902655052&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Bristol;Shanghai Electric Group Co., Ltd.",
        "aff_unique_dep": "Department of Engineering Mathematics;Central Academe",
        "aff_unique_url": "https://www.bristol.ac.uk;",
        "aff_unique_abbr": "UoB;",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Bristol;Shanghai",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9636542",
        "title": "A Robust Illumination-Invariant Camera System for Agricultural Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Object detection and semantic segmentation are two of the most widely adopted deep learning algorithms in agricultural applications. One of the major sources of variability in image quality acquired outdoors for such tasks is changing lighting conditions that can alter the appearance of the objects or the contents of the entire image. While transfer learning and data augmentation reduce the need for large amount of data to train deep neural networks to some extent, the large variety of cultivars and the lack of shared datasets in agriculture makes wide-scale field deployments difficult. In this paper, we present an active lighting-based camera system that generates robust and uniform images in any lighting conditions. We provide extensive validation experiments to evaluate the consistency in the quality of the images. Metrics for assessing image uniformity like Structural Similarity (SSIM) index and the Peak Signal to Noise Ratio (PSNR) ranged from 83.78 to 93.79 and from 25.30 to 31.78 respectively, showing stability over a day with changing sunlight. The validation stage also showed that the generated images effectively reduce the amount of training samples for object detection using deep neural networks. The camera system was then deployed in real field experiments for counting buds in dormant vines and shoots in early season grape vines as well as for counting apples in orchards. The mean absolute errors obtained when compared to ground truth were 5%, 2.55% and 8.57%, respectively.",
        "primary_area": "",
        "author": "Abhisesh Silwal;Tanvir Parhar;Francisco Yandun;Harjatin Baweja;George Kantor;Abhisesh Silwal;Tanvir Parhar;Francisco Yandun;Harjatin Baweja;George Kantor",
        "authorids": "/37086208291;/37086041333;/37086363686;/37086045922;/37273878300;/37086208291;/37086041333;/37086363686;/37086045922;/37273878300",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636542/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11382632936625966806&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636766",
        "title": "A Safe and Rapidly Switchable Stiffness Hydrostatic Actuator through Valve-controlled Air Springs",
        "track": "main",
        "status": "Poster",
        "abstract": "Hydrostatic transmission has shown promising results for enabling the manipulator to achieve low effective inertia, high stiffness, and high torque density. However, the incompressibility of fluid causes the lack of compliance, so that it could not provide intrinsic safety. Thus, it would be advantageous to introduce series compliance on the hydrostatic manipulator for adjusting stiffness depending on the situation. Here, we developed a safe and high-performance hydrostatic actuator based on the switchable stiffness mechanism implemented with an air spring and solenoid valve. The hydrostatic transmission is implemented with rolling diaphragms to attain zero fluid leakage and low seal friction. Air spring is serially connected to hydraulic lines for achieving compliance. Its modes (i.e., stiff and compliant modes) can be rapidly switched by modulating water flow via the solenoid valve. Block stiffness experiment shows that the stiffness of stiff mode is 9.63 times stiffer than one of compliant mode at 100 kPa. We experimentally demonstrated that compliant mode could mitigate the impact force to the level that a tangerine would not be crushed. The stiffness was switched within 12 ms; hence it is fast enough to be used for feedback application with vision or tactile sensors. As a result, the developed actuator can ensure safety without sacrificing the dynamic performance, owing to the simple and rapidly switchable stiffness mechanism.",
        "primary_area": "",
        "author": "Sungbin Park;Kyungseo Park;Hwayeong Jeong;Wonseok Shin;Jung Kim;Sungbin Park;Kyungseo Park;Hwayeong Jeong;Wonseok Shin;Jung Kim",
        "authorids": "/854106688641405;/37067235600;/37085760405;/37086493895;/37407273800;/854106688641405;/37067235600;/37085760405;/37086493895;/37407273800",
        "aff": "Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636766/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10710135155171247072&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636855",
        "title": "A Safety-Aware Architecture for Task Scheduling and Execution for Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "In collaborative robotic applications, human and robot have to work together to accomplish a common job, composed by a set of tasks. In order to achieve an efficient human-robot collaboration (HRC), it is important to have an integration between a proper task scheduling strategy and a task execution strategy. The first must deal with the variability of the two agents, while the second must deal with the safety standards. In this paper, we propose an integrated architecture for task scheduling and execution in a collaborative cell. The tasks are dynamically scheduled handling the uncertainity in both the human and the robot behaviors. Subsequently, at the execution level, the task is accomplished computing trajectories comply with the safety regulations. The planning information are mutually integrated in real-time with the scheduling procedure in order improve the HRC.",
        "primary_area": "",
        "author": "Andrea Pupa;Cristian Secchi;Andrea Pupa;Cristian Secchi",
        "authorids": "/37088839620;/37300905500;/37088839620;/37300905500",
        "aff": "Department of Science and Method of Engineering, University of Modena and Reggio Emilia, Italy; Department of Science and Method of Engineering, University of Modena and Reggio Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636855/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4232450612072786481&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia",
        "aff_unique_dep": "Department of Science and Method of Engineering",
        "aff_unique_url": "https://www.unimore.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636395",
        "title": "A Sampling-based Motion Planning Framework for Complex Motor Actions",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a framework for planning complex motor actions such as pouring or scooping from arbitrary start states in cluttered real-world scenes. Traditional approaches to such tasks use dynamic motion primitives (DMPs) learned from human demonstrations. We enhance a recently proposed state-of-the-art DMP technique capable of obstacle avoidance by including them within a novel hybrid framework. This complements DMPs with sampling-based motion planning algorithms, using the latter to explore the scene and reach promising regions from which a DMP can successfully complete the task. Experiments indicate that even obstacle-aware DMPs suffer in task success when used in scenarios which largely differ from the trained demonstration in terms of the start, goal, and obstacles. Our hybrid approach significantly outperforms obstacle-aware DMPs by successfully completing tasks in cluttered scenes for a pouring task in simulation. We further demonstrate our method on a real robot for pouring and scooping tasks.",
        "primary_area": "",
        "author": "Shlok Sobti;Rahul Shome;Swarat Chaudhuri;Lydia E. Kavraki;Shlok Sobti;Rahul Shome;Swarat Chaudhuri;Lydia E. Kavraki",
        "authorids": "/37087412631;/37085557993;/37072408200;/37279015600;/37087412631;/37085557993;/37072408200;/37279015600",
        "aff": "Department of Computer Science, Rice University, Houston; Department of Computer Science, Rice University, Houston; University of Texas, Austin; Department of Computer Science, Rice University, Houston",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636395/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6290783692232517355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Rice University;University of Texas at Austin",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.rice.edu;https://www.utexas.edu",
        "aff_unique_abbr": "Rice;UT Austin",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Houston;Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636293",
        "title": "A Scalable Distributed Collision Avoidance Scheme for Multi-agent UAV systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In this article we propose a distributed collision avoidance scheme for multi-agent unmanned aerial vehicles (UAVs) based on nonlinear model predictive control (NMPC), where other agents in the system are considered as dynamic obstacles with respect to the ego agent. Our control scheme operates at a low level and commands roll, pitch and thrust signals at a high frequency, each agent broadcasts its predicted trajectory to the other ones, and we propose an obstacle prioritization scheme based on the shared trajectories to allow up-scaling of the system. The NMPC problem is solved using an embedded solver generated by Optimization Engine (OpEn) where PANOC is combined with an augmented Lagrangian method to compute collision-free trajectories. We evaluate the proposed scheme in several challenging laboratory experiments for up to ten aerial agents, in dense aerial swarms.",
        "primary_area": "",
        "author": "Bj\u00f6rn Lindqvist;Pantelis Sopasakis;George Nikolakopoulos;Bj\u00f6rn Lindqvist;Pantelis Sopasakis;George Nikolakopoulos",
        "authorids": "/37088450622;/38548002400;/37301305200;/37088450622;/38548002400;/37301305200",
        "aff": "Department of Computer, Electrical and Space Engineering, Robotics and AI Team, Lule\u00e5 University of Technology, Lule\u00e5, Sweden; School of Electronics, Electrical Engineering and Computer Science (EEECS), Queen\u2019s University Belfast and Centre for Intelligent Autonomous Manufacturing Systems (i-AMS), United Kingdom; Department of Computer, Electrical and Space Engineering, Robotics and AI Team, Lule\u00e5 University of Technology, Lule\u00e5, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636293/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5022807894304352922&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Lule\u00e5 University of Technology;Queen\u2019s University Belfast",
        "aff_unique_dep": "Department of Computer, Electrical and Space Engineering;School of Electronics, Electrical Engineering and Computer Science (EEECS)",
        "aff_unique_url": "https://www.ltu.se;https://www.qub.ac.uk",
        "aff_unique_abbr": "LTU;QUB",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Lule\u00e5;Belfast",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Sweden;United Kingdom"
    },
    {
        "id": "9636155",
        "title": "A Self-Biasing Shape Memory Alloy Gripper for Lightweight Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Shape Memory Alloys (SMAs) are a type of smart material that are commonly used in compact and lightweight linear actuators. Paired with compliant motion conversion mechanisms, these alloys can be transformed into lightweight grippers ideal for applications such as drone deliveries. This work proposes to use the inherent stiffness of a compliant mechanism with an SMA coil, to design and size a self-biasing SMA gripper. In this paper, with the help of 2.5D design, a functional radial 4-prong gripper is designed and fabricated. While only weighing 17g, it has a gripping force and stroke of 1.8N and 4mm, respectively. Along with this functional prototype, an analytical model and design framework is presented allowing for the design and sizing of similar self-biasing SMA actuators for other different light-weight applications.",
        "primary_area": "",
        "author": "Sean Thomas;Gabriel Maquignaz;Adrien Thabuis;Yves Perriard;Sean Thomas;Gabriel Maquignaz;Adrien Thabuis;Yves Perriard",
        "authorids": "/37086533193;/37089196684;/37087103575;/37267563900;/37086533193;/37089196684;/37087103575;/37267563900",
        "aff": "Integrated Actuators Laboratory (LAI), Swiss Federal Institute of Technology (EPFL), Lausanne, Switzerland; Integrated Actuators Laboratory (LAI), Swiss Federal Institute of Technology (EPFL), Lausanne, Switzerland; Integrated Actuators Laboratory (LAI), Swiss Federal Institute of Technology (EPFL), Lausanne, Switzerland; Integrated Actuators Laboratory (LAI), Swiss Federal Institute of Technology (EPFL), Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636155/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6489264380568250149&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Swiss Federal Institute of Technology (EPFL)",
        "aff_unique_dep": "Integrated Actuators Laboratory (LAI)",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636462",
        "title": "A Series Elastic, Compact Differential Mechanism: On the Development of Adaptive, Lightweight Robotic Grippers and Hands",
        "track": "main",
        "status": "Poster",
        "abstract": "Differential mechanisms allow the designers of robotic and prosthetic grippers and hands to create devices that require a minimal number of motors in order to grasp a plethora of everyday life objects, leading to light-weight, compact, and low-cost implementations. The working principle of differential mechanisms is simple. They allow the distribution of the forces exerted by a single actuator to multiple outputs (e.g., fingers). This reduction in the number of motors leads to underactuation, which is the use of fewer motors than the available degrees of freedom. But differentials need also to be power-efficient, compact, adaptive, and lightweight. Most of the existing solutions lack at least one of these attributes. In this paper, we focus on the design, modeling, and development of a compact, adaptive, series elastic differential. The proposed mechanism consists of four elastic elements connected in series with the four output attachments. The compression of the elastic elements during grasping allows the gripper or hand to conform to the object\u2019s shape. The efficiency of the differential mechanism is experimentally validated using two different types of experiments, measuring: i) the maximum achievable tension load at the outputs, and ii) the maximum achievable compliance of a single output when all other outputs are blocked. The proposed differential has been employed for the development of a gripper and its efficiency has been assessed by executing grasping tasks with several everyday life objects. The device can be easily replicated using additive manufacturing and off-the-shelf materials and is disseminated in an open-source manner.",
        "primary_area": "",
        "author": "Mojtaba Shahmohammadi;Minas Liarokapis;Mojtaba Shahmohammadi;Minas Liarokapis",
        "authorids": "/37089186373;/38558084100;/37089186373;/38558084100",
        "aff": "Department of Mechanical Engineering, Faculty of Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering, Faculty of Engineering, New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636462/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3824674477558726985&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Auckland",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "UoA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9635858",
        "title": "A Simple and Efficient Multi-task Network for 3D Object Detection and Road Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "Detecting dynamic objects and predicting static road information such as drivable areas and ground heights are crucial for safe autonomous driving. Previous works studied each perception task separately, and lacked a collective quantitative analysis. In this work, we show that it is possible to perform all perception tasks via a simple and efficient multi-task network. Our proposed network, LidarMTL, takes raw LiDAR point cloud as inputs, and predicts six perception outputs for 3D object detection and road understanding. The network is based on an encoder-decoder architecture with 3D sparse convolution and deconvolution operations. Extensive experiments verify the proposed method with competitive accuracies compared to state-of-the-art object detectors and other task-specific networks. LidarMTL is also leveraged for online localization. Code and pre-trained model have been made available at https://github.com/frankfengdi/LidarMTL.",
        "primary_area": "",
        "author": "Di Feng;Yiyang Zhou;Chenfeng Xu;Masayoshi Tomizuka;Wei Zhan;Di Feng;Yiyang Zhou;Chenfeng Xu;Masayoshi Tomizuka;Wei Zhan",
        "authorids": "/37086544464;/37088504087;/37089197139;/37281933000;/37067099600;/37086544464;/37088504087;/37089197139;/37281933000;/37067099600",
        "aff": "Institute of Measurement, Control and Microtechnology, Ulm University, Ulm, Germany; Mechanical Systems Control Lab, University of California, Berkeley, CA, USA; Mechanical Systems Control Lab, University of California, Berkeley, CA, USA; Mechanical Systems Control Lab, University of California, Berkeley, CA, USA; Mechanical Systems Control Lab, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635858/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5899667965123383500&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Ulm University;University of California, Berkeley",
        "aff_unique_dep": "Institute of Measurement, Control and Microtechnology;Mechanical Systems Control Lab",
        "aff_unique_url": "https://www.uni-ulm.de;https://www.berkeley.edu",
        "aff_unique_abbr": "Ulm U;UC Berkeley",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Ulm;Berkeley",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9636771",
        "title": "A Soft Assistive Device for Elbow Effort-Compensation",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of assistive technologies in industrial environments to improve human ergonomics and comfort in repetitive and high effort tasks have increased considerably in the last decade. Predominantly, the goal is to provide additional physical support through lightweight and wearable devices, without posing major constraints to the human body movements. Towards achieving this objective, in this work we present a novel actuation mechanism for a soft assistive device, by taking into account the human elbow torque-angle profile. The proposed design integrates a single motor coupled with an elastic bungee and a cam-spool mechanism to enable energy exchange during the elbow flexion movement, while allowing for free-motions during the extension of the joint. A cable-driven transmission with passive elastic attachments is employed to implement compliant couplings with the wearer and to achieve easy donning/doffing. Experiments are conducted on two 3D printed functional prototypes. Results suggest that the assistive elbow torque is effectively transmitted with an average 90% success for balancing a 5N payload, and the free-motion range of 108\u00b0 is measured for both flexion and extension.",
        "primary_area": "",
        "author": "Emir Mobedi;Wansoo Kim;Elena De Momi;Nikos G. Tsagarakis;Arash Ajoudani;Emir Mobedi;Wansoo Kim;Elena De Momi;Nikos G. Tsagarakis;Arash Ajoudani",
        "authorids": "/37088529268;/37086291232;/37085735806;/37295830800;/37945239900;/37088529268;/37086291232;/37085735806;/37295830800;/37945239900",
        "aff": "Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milano, Italy; Istituto Italiano di Tecnologia, Genoa, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milano, Italy; Istituto Italiano di Tecnologia, Genoa, Italy; Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636771/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6770537736532525017&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;1",
        "aff_unique_norm": "Politecnico di Milano;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Electronics, Information and Bioengineering;",
        "aff_unique_url": "https://www.polimi.it;https://www.iit.it",
        "aff_unique_abbr": "Politecnico di Milano;IIT",
        "aff_campus_unique_index": "0;1;0;1;1",
        "aff_campus_unique": "Milano;Genoa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636225",
        "title": "A Soft Robotic Hip Exosuit (SR-HExo) to Assist Hip Flexion and Extension during Human Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design, fabrication, and preliminary results of a soft hip exosuit to assist hip flexion and extension during walking. The exosuit uses soft and compliant materials to create a wearable robot that has a low profile, low mass, and is highly flexible to freely move with the user\u2019s natural range of motion. The Soft Robotic Hip Exosuit (SR-HExo) consists of flat fabric pneumatic artificial muscles (ff-PAM) that contract when pressurized. The ff-PAM actuators are oriented in an \u2018X\u2019 shape to allow for natural range of motion across the hip joint and can generate 190 N of force at 200 kPa in a 0.3 sec window. The \u2018X\u2019 configuration (X-ff-PAM) actuators were placed on the anterior and posterior sides of the hip joint with height adjustable Velcro straps. Extension assistance and flexion assistance was provided in 10-45% and 50-90% of the gait cycle, respectively. To evaluate the effectiveness of the SR-HExo with healthy participants, hip range of motion and muscle activity during walking were monitored using a motion capture system and surface electromyography sensors. The impact of the SR-HExo on the range of motion was minimal with only a 4.0o reduction from the target range of motion of 30o. The exosuit contributed to reducing hip muscle activity. Hip extensor muscles showed a reduction of 13.1% for the gluteus maximus and 6.6% for the biceps femoris. Hip flexor muscles showed a reduction of 10.7% for the iliacus and 27.7% for the rectus femoris.",
        "primary_area": "",
        "author": "Carly M. Thalman;Lily Baye-Wallace;Hyunglae Lee;Carly M. Thalman;Lily Baye-Wallace;Hyunglae Lee",
        "authorids": "/37086415339;/37089197526;/37085768762;/37086415339;/37089197526;/37085768762",
        "aff": "Neuromuscular Control and Human Robotics Laboratory, Ira A. Fulton Schools of Engineering, Arizona State University, AZ, USA; Neuromuscular Control and Human Robotics Laboratory, Ira A. Fulton Schools of Engineering, Arizona State University, AZ, USA; Neuromuscular Control and Human Robotics Laboratory, Ira A. Fulton Schools of Engineering, Arizona State University, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636225/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14102729136085377685&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "Ira A. Fulton Schools of Engineering",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "AZ",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636431",
        "title": "A Soft Somesthetic Robotic Finger Based on Conductive Working Liquid and an Origami Structure",
        "track": "main",
        "status": "Poster",
        "abstract": "The tactile and proprioceptive sensation increases human manipulability, and soft tissue compliance stabilizes the grasping function. However, it is challenging to transpose this system to the small confined space of soft robotic fingers due to the material properties and complex wiring entailed. Furthermore, soft robotic fingers also incorporate actuating components, making such a system more difficult to bring to fruition. Therefore, optimizing soft robotic finger structure for greater functionality and manufacturability would be a desirable innovation. In this study, we developed a soft somesthetic robotic finger based on the conductive working liquid and an origami structure. The proposed design comprises an origami structure, porous scaffolds, and a silicone-coated fabric outer layer. The robotic finger was filled with conductive liquid used for both somesthetic sensing and bending actuation simultaneously. The origami structure was fabricated by connecting printed circuit boards (PCBs) and a polyimide film, with electrodes embedded on each PCB to enable somesthetic sensing. The electrodes were used to inject currents and measure voltage, with the measured data then used to reconstruct the deformation map and hinge angle by means of electrical resistance tomography (ERT). The experimental results confirm that the robotic finger could acquire tactile and proprioceptive information in real-time.",
        "primary_area": "",
        "author": "Junhwi Cho;Kyungseo Park;Hwayeong Jeong;Jung Kim;Junhwi Cho;Kyungseo Park;Hwayeong Jeong;Jung Kim",
        "authorids": "/37088356121;/37067235600;/37085760405;/37407273800;/37088356121;/37067235600;/37085760405;/37407273800",
        "aff": "Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Korea Advanced Institute of Science and Technology, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636431/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8049150439423799862&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636734",
        "title": "A Static Model for a Stiffness-Adjustable Snake-Like Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In minimally invasive surgery, miniaturisation and in situ adjustable stiffness of robotic manipulators are desired features. Previous research proposed a simple and effective tendon-driven curve-joint manipulator design using a variable neutral-line mechanism, which highly satisfies both criteria. A kinematic model was developed for such a manipulator based on the geometry of the structure. However, such a model assumes that joint angles are all equal between disks without a rigorous derivation, and fails if not all the shapes of the disks are identical. Moreover, the model does not involve an analysis of the tension of each tendon. This paper suggested a static model for predicting the articulation of such a manipulator given the applied tensions on driving tendons. It validates the assumption of equally distributed joint angles and works for manipulators with more general configurations of disks and tendons. It also sets a foundation for further development of tension based control and external force estimation. Simulations on Adams were conducted to prove the correctness of the proposed model. A video demonstrating the simulation results can be found via https://youtu.be/MXhL1LGwLtw",
        "primary_area": "",
        "author": "Di Shun Huang;Jian Hu;Liuchunzi Guo;Yi Sun;Liao Wu;Di Shun Huang;Jian Hu;Liuchunzi Guo;Yi Sun;Liao Wu",
        "authorids": "/37089194729;/37089195518;/37089197721;/37089197443;/37085418896;/37089194729;/37089195518;/37089197721;/37089197443;/37085418896",
        "aff": "School of Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, Australia; School of Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, Australia; School of Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, Australia; Sydney Institute for Robotics and Intelligent Systems and Australian Centre for Field Robotics, The University of Sydney, Sydney, Australia; School of Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636734/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11256024243263239633&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of New South Wales;University of Sydney",
        "aff_unique_dep": "School of Mechanical and Manufacturing Engineering;Sydney Institute for Robotics and Intelligent Systems",
        "aff_unique_url": "https://www.unsw.edu.au;https://www.sydney.edu.au",
        "aff_unique_abbr": "UNSW;USYD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9636758",
        "title": "A Three-Fingered Adaptive Gripper with Multiple Grasping Modes",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an underactuated robotic gripper that consists of three fingers. This gripper is driven by seven actuators and capable of grasping a wide range of objects in different working scenarios. A combination of a four-bar mechanism and parallelograms ensures that each finger can provide the basic pinch grasp and power grasp. Detailed fingertip grasping force analysis shows the large payload of this gripper. To fulfill multiple challenging grasping tasks, the fingertip orientation of each finger was designed to be decoupled from the finger flexion motion. Particular emphasis is placed on the environmental contact-based grasp and active transition from the pinch grasp to the power grasp. Detailed analysis shows that the contact-based fingertip grasp could be used to grasp thin objects lying on a flat surface with widths less than 168 mm safely and stably. To prevent over-squeezing of the grasped object in the active transition, the fingertip orientation and finger flexion motion were controlled coordinately. Moreover, a combination of the contact-based grasp and the direct power grasp was also allowed to grasp objects lying on a flat surface and having smooth surfaces robustly. Experimental results demonstrate the effectiveness of the proposed gripper in real-world applications.",
        "primary_area": "",
        "author": "Long Kang;Yang Yang;Jian Yang;Byung-Ju Yi;Long Kang;Yang Yang;Jian Yang;Byung-Ju Yi",
        "authorids": "/37085447348;/37085714206;/37280205100;/37273970700;/37085447348;/37085714206;/37280205100;/37273970700",
        "aff": "PCA Lab, Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Automation, Nanjing University of Information Science and Technology, Nanjing, China; PCA Lab, Key Laboratory of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Department of the Electronic Systems Engineering, Hanyang University, Ansan, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636758/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6842415463400373151&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Nanjing University of Science and Technology;Nanjing University of Information Science and Technology;Hanyang University",
        "aff_unique_dep": "School of Computer Science and Engineering;School of Automation;Department of the Electronic Systems Engineering",
        "aff_unique_url": "http://www.nust.edu.cn;http://www.nuist.edu.cn;http://www.hanyang.ac.kr",
        "aff_unique_abbr": "NJUST;;HYU",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Nanjing;Ansan",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "China;South Korea"
    },
    {
        "id": "9636714",
        "title": "A Topological Approach to Finding Coarsely Diverse Paths",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a topological method for finding coarsely diverse pathways. The use of pre-computed paths for online planning in a dynamic context reduces the overhead of re-planning alternate routes. Our algorithm applied the notion of discrete Morse theory to identify critical points incident on the obstacles and used this information to identify and return a diverse set of coarse paths. Three sampling-based planning approaches are converted to topology-aware planners and compared to another that employs the SPARS2 path planning algorithm. We report on the number of coarse pathways found, computation time, and average path length and show that our approach outperformed previously published path diversity algorithms.",
        "primary_area": "",
        "author": "Aakriti Upadhyay;Boris Goldfarb;Chinwe Ekenna;Aakriti Upadhyay;Boris Goldfarb;Chinwe Ekenna",
        "authorids": "/37086395279;/37089196391;/37085676589;/37086395279;/37089196391;/37085676589",
        "aff": "Department of Computer Science, University at Albany, SUNY, USA; Department of Mathematics and Statistics, University at Albany, SUNY, USA; Department of Computer Science, University at Albany, SUNY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636714/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13854657184236483344&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University at Albany, SUNY",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.albany.edu",
        "aff_unique_abbr": "UAlbany",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Albany",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636512",
        "title": "A Vision-based Irregular Obstacle Avoidance Framework via Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning has achieved great success in laser-based collision avoidance work because the laser can sense accurate depth information without too much redundant data, which can maintain the robustness of the algorithm when it is migrated from the simulation environment to the real world. However, high-cost laser devices are not only difficult to apply on a large scale but also have poor robustness to irregular objects, e.g., tables, chairs, shelves, etc. In this paper, we propose a vision-based collision avoidance framework to solve the challenging problem. Our method attempts to estimate the depth and incorporate the semantic information from RGB data to obtain a new form of data, pseudo-laser data, which combines the advantages of visual information and laser information. Compared to traditional laser data that only contains the one-dimensional distance information captured at a certain height, our proposed pseudo-laser data encodes the depth information and semantic information within the image, which makes our method more effective for irregular obstacles. Besides, we adaptively add noise to the laser data during the training stage to increase the robustness of our model in the real world, due to the estimated depth information is not accurate. Experimental results show that our framework achieves state-of-the-art performance in several unseen virtual and real-world scenarios.",
        "primary_area": "",
        "author": "Lingping Gao;Jianchuan Ding;Wenxi Liu;Haiyin Piao;Yuxin Wang;Xin Yang;Baocai Yin;Lingping Gao;Jianchuan Ding;Wenxi Liu;Haiyin Piao;Yuxin Wang;Xin Yang;Baocai Yin",
        "authorids": "/37089196389;/37089195944;/38239959600;/37088339703;/37337396100;/37086582086;/37268507700;/37089196389;/37089195944;/38239959600;/37088339703;/37337396100;/37086582086;/37268507700",
        "aff": "School of Computer Science, Dalian University of Technology, Dalian, China; School of Computer Science, Dalian University of Technology, Dalian, China; College of Mathematics and Computer Science, Fuzhou University, Fuzhou, China; School of Electronics and Information, Northwestern Polytechnical University, Xi\u2019an, China; School of Computer Science, Dalian University of Technology, Dalian, China; School of Computer Science, Dalian University of Technology, Dalian, China; School of Computer Science, Dalian University of Technology, Dalian, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636512/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16331351152479910645&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;0;0;0",
        "aff_unique_norm": "Dalian University of Technology;Fuzhou University;Northwestern Polytechnical University",
        "aff_unique_dep": "School of Computer Science;College of Mathematics and Computer Science;School of Electronics and Information",
        "aff_unique_url": "http://en.dlut.edu.cn/;https://www.fzu.edu.cn;http://www.nwpu.edu.cn",
        "aff_unique_abbr": "DUT;FZU;NPU",
        "aff_campus_unique_index": "0;0;1;2;0;0;0",
        "aff_campus_unique": "Dalian;Fuzhou;Xi'an",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636526",
        "title": "A Visual Inertial Odometry Framework for 3D Points, Lines and Planes",
        "track": "main",
        "status": "Poster",
        "abstract": "Recovering rigid registration between successive camera poses lies at the heart of 3D reconstruction, SLAM and visual odometry. Registration relies on the ability to compute discriminative 2D features in successive camera images for determining feature correspondences, which is very challenging in feature-poor environments, i.e. low-texture and/or low-light environments. In this paper, we aim to address the challenge of recovering rigid registration between successive camera poses in feature-poor environments in a Visual Inertial Odometry (VIO) setting. In addition to inertial sensing, we instrument a small aerial robot with an RGBD camera and propose a framework that unifies the incorporation of 3D geometric entities: points, lines, and planes. The tracked 3D geometric entities provide constraints in an Extended Kalman Filtering framework. We show that by directly exploiting 3D geometric entities, we can achieve improved registration. We demonstrate our approach on different texture-poor environments, with some containing only flat texture-less surfaces providing essentially no 2D features for tracking. In addition, we evaluate how the addition of different 3D geometric entities contributes to improved pose estimation by comparing an estimated pose trajectory to a ground truth pose trajectory obtained from a motion capture system. We consider computationally efficient methods for detecting 3D points, lines and planes, since our goal is to implement our approach on small mobile robots, such as drones.",
        "primary_area": "",
        "author": "Shenbagaraj Kannapiran;Jeroen van Baar;Spring Berman;Shenbagaraj Kannapiran;Jeroen van Baar;Spring Berman",
        "authorids": "/37088690274;/37324479700;/37583148200;/37088690274;/37324479700;/37583148200",
        "aff": "School for Engineering of Matter, Transport and Energy, Arizona State University, Tempe, AZ, USA; Mitsubishi Electric Research Laboratories (MERL), Cambridge, MA, USA; School for Engineering of Matter, Transport and Energy, Arizona State University, Tempe, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636526/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17300374586244760746&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Arizona State University;Mitsubishi Electric Research Laboratories",
        "aff_unique_dep": "School for Engineering of Matter, Transport and Energy;",
        "aff_unique_url": "https://www.asu.edu;https://www.merl.com",
        "aff_unique_abbr": "ASU;MERL",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Tempe;Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636126",
        "title": "A Wearable Robotic Device for Assistive Navigation and Object Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a hand-worn assistive device to assist a visually impaired person with object manipulation. The device uses a Google Pixel 3 as the computational platform, a Structure Core (SC) sensor for perception, a speech interface, and a haptic interface for human-device interaction. W-ROMA is intended to assist a visually impaired person to locate a target object (nearby or afar) and guide the user to move towards and eventually take a hold of the object. To achieve this objective, three functions, including object detection, wayfinding, and motion guidance, are developed. Object detection locates the target object\u2019s position if it falls within the camera\u2019s field of view. Wayfinding enables the user to approach the object. The haptic/speech interface guides the user to move close to the object and then guides the hand to reach the object. A new visual-inertial odometery (VIO), called RGBD-VIO, is devised to accurately estimate the device\u2019s pose (position and orientation), which is then used to generate the motion command to guide the user and his/her hand to reach the object. Experimental results demonstrate that RGBD-VIO outperforms the state-of-the-art VIO methods in 6-DOF device pose estimation and the device is effective in assistive object manipulation.",
        "primary_area": "",
        "author": "Lingqiu Jin;He Zhang;Cang Ye;Lingqiu Jin;He Zhang;Cang Ye",
        "authorids": "/37086702509;/37086004148;/37291591400;/37086702509;/37086004148;/37291591400",
        "aff": "Computer Science Department, Virginia Commonwealth University, Richmond, VA, USA; Computer Science Department, Virginia Commonwealth University, Richmond, VA, USA; Computer Science Department, Virginia Commonwealth University, Richmond, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636126/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5202919671040823527&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Virginia Commonwealth University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.vcu.edu",
        "aff_unique_abbr": "VCU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Richmond",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636345",
        "title": "A Wearable, Open-Source, Lightweight Forcemyography Armband: On Intuitive, Robust Muscle-Machine Interfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "With an increasing number of robotic and prosthetic devices, there is a need for intuitive interfaces which enable the user to efficiently interact with them. The conventional interfaces are generally bulky and unsuitable for dynamic and unstructured environments. An alternative to the traditional interfaces is the class of Muscle-Machine Interfaces (MuMIs) that allow the user to have an embodied interaction with the devices they are controlling. In this work, we present a wearable, lightweight, Forcemyography (FMG) based armband for Human-Machine Interaction fabricated entirely out of 3D-printed parts and silicone components. The armband uses six force sensing units, each housing an Force Sensitive Resistor (FSR) sensor. The capabilities of the armband are evaluated while decoding four different gestures (pinch, power, tripod, extension) and rest state and its performance is compared with a state-of-the-art Electromyography (EMG) bioamplifier. The decoding performance of the decoding models trained on the data acquired from the armband is significantly better than the performance of the models trained on raw EMG data. The hardware design and the related processing software, are disseminated in an open-source manner.",
        "primary_area": "",
        "author": "Jayden Chapman;Anany Dwivedi;Minas Liarokapis;Jayden Chapman;Anany Dwivedi;Minas Liarokapis",
        "authorids": "/37088482031;/37086133073;/38558084100;/37088482031;/37086133073;/38558084100",
        "aff": "New Dexterity Research Group, Department of Mechanical Engineering, The University of Auckland, New Zealand; New Dexterity Research Group, Department of Mechanical Engineering, The University of Auckland, New Zealand; New Dexterity Research Group, Department of Mechanical Engineering, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636345/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16114198886301605043&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Auckland",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "UoA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9636829",
        "title": "A novel testbed for investigating the impact of teleoperator dynamics on perceived environment dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-in-the-loop telerobotic systems (HiLTS) are robotic tools designed to extend and in some circumstances improve the dexterous capabilities of the human operator in virtual and remote environments. Dexterous manipulation, however, depends on how well the telerobot is incorporated into the operator\u2019s sensorimotor control scheme. Empirical evidence suggests that haptic feedback can lead to improved dexterity. Unfortunately, haptic feedback can also introduce dynamics between the leader and follower of the telerobot that affect both stability and device performance. While concerted research effort has focused on masking these device dynamics or bypassing them altogether, it is not well understood how human operators incorporate these dynamics into their control scheme. We believe that to advance dexterous telerobotic manipulation, it is crucial to understand the process by which human operators incorporate teleoperator dynamics and distinguish them from the dynamics of the environment. Key to this knowledge is an understanding of how advanced telerobotic architectures compare to the gold standard, the rigid mechanical teleoperators first introduced in the 1950\u2019s. In this manuscript, we present a teleoperator testbed that has reconfigurable transmissions between the leader and follower to change its dynamic behavior. The intent of this testbed is to investigate the effect of the teleoperator\u2019s dynamics on perception of and task performance in the remote/virtual environment. We describe the hardware and software components of the testbed and then demonstrate how the different teleoperator transmissions can lead to differences, sometimes significant, in the dynamics that would be felt by the operator when exploring the same environment.",
        "primary_area": "",
        "author": "Mohit Singhala;Jeremy D. Brown;Mohit Singhala;Jeremy D. Brown",
        "authorids": "/37088396940;/38556961200;/37088396940;/38556961200",
        "aff": "Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636829/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18022195511897996958&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636058",
        "title": "A transformable human-carrying wheel\u2013leg mobility for daily use",
        "track": "main",
        "status": "Poster",
        "abstract": "There is increasing demand for robots that provide a mode of transportation in environments in which people coexist. However, conventional mobile robots, especially those carrying people, are limited in terms of their environments and tasks. For example, wheeled robots are limited to moving on flat ground. Walking robots are limited to entertainment and so on. The originality of the present paper is the development of a novel movement mechanism for a mobility apparatus that can handle various daily use scenes. We first clarify functional requirements for daily use. We then propose a transformable human-carrying wheel\u2013leg mobility. The leg is based on a serial link and compactly uses a parallel link mechanism such that the motor is placed on top, which improves responsiveness when having a high payload and compact shape. By conducting simulations and experiments with the prototype, it is confirmed that expected operations can be realized. In particular, it is confirmed that the weight of the leg tips is reduced, such that the shaking of the waist in the direction of travel during the ascent of a step is reduced by 68%. The above results reveal that the prototype can be used in daily life.",
        "primary_area": "",
        "author": "Noriaki Imaoka;Kohei Kimura;Shintaro Noda;Yohei Kakiuchi;Masayuki Inaba;Takeshi Ando;Noriaki Imaoka;Kohei Kimura;Shintaro Noda;Yohei Kakiuchi;Masayuki Inaba;Takeshi Ando",
        "authorids": "/37089198148;/37085737047;/37085354213;/38242437800;/37286658200;/37285644700;/37089198148;/37085737047;/37085354213;/38242437800;/37286658200;/37285644700",
        "aff": "Robotics Promotion Office, Panasonic Corporation, Osaka, Japan; Graduate School of Information Science and Technology, Tokyo University, Tokyo, Japan; Graduate School of Information Science and Technology, Tokyo University, Tokyo, Japan; Graduate School of Information Science and Technology, Tokyo University, Tokyo, Japan; Graduate School of Information Science and Technology, Tokyo University, Tokyo, Japan; Robotics Promotion Office, Panasonic Corporation, Osaka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636058/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14640520684528809394&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;0",
        "aff_unique_norm": "Panasonic Corporation;University of Tokyo",
        "aff_unique_dep": "Robotics Promotion Office;Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www.panasonic.com;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "Panasonic;UTokyo",
        "aff_campus_unique_index": "0;1;1;1;1;0",
        "aff_campus_unique": "Osaka;Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636650",
        "title": "ADD: A Fine-grained Dynamic Inference Architecture for Semantic Image Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic inference that adaptively skips parts of model execution based on the complexity of input data can effectively reduce the computation cost of deep learning models during the inference. However, current architectures for dynamic inference only consider the exits at the block level, whose results may not be suitable for different applications. In this paper, we present the Auto-Dynamic-DeepLab (ADD), a network architecture that enables the fine-grained dynamic inference for semantic image segmentation. To allow the exit points in the cell level, ADD utilizes Neural Architecture Search (NAS), supported by the framework of Auto-DeepLab, to seek the optimal network structure. In addition, ADD replaces the cells in Auto-DeepLab with the densely connected cells to ease the interference among multiple classifiers and employs the earlier decision maker (EDM) to further improve the performance. Experimental results show that ADD can achieve similar accuracy as Auto-DeepLab in terms of mIoU with a 1.6 times speedup. For the fast mode, ADD can achieve 2.15 times speedup with only a 1.3% accuracy drop compared to those of Auto-DeepLab.",
        "primary_area": "",
        "author": "Chi-Hsi Kung;Che-Rung Lee;Chi-Hsi Kung;Che-Rung Lee",
        "authorids": "/37089195137;/37406334500;/37089195137;/37406334500",
        "aff": "Department of Computer Science, National Tsing Hua University, Taiwan; Department of Computer Science, National Tsing Hua University, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636650/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7816470257946381340&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National Tsing Hua University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nthu.edu.tw",
        "aff_unique_abbr": "NTHU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636711",
        "title": "APEX: Unsupervised, Object-Centric Scene Segmentation and Tracking for Robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in unsupervised learning for object detection, segmentation, and tracking hold significant promise for applications in robotics. A common approach is to frame these tasks as inference in probabilistic latent-variable models. In this paper, however, we show that the current state-of-the-art struggles with visually complex scenes such as typically encountered in robot manipulation tasks. We propose APEX, a new latent-variable model which is able to segment and track objects in more realistic scenes featuring objects that vary widely in size and texture, including the robot arm itself. This is achieved by a principled mask normalisation algorithm and a high-resolution scene encoder. To evaluate our approach, we present results on the real-world Sketchy dataset. This dataset, however, does not contain ground truth masks and object IDs for a quantitative evaluation. We thus introduce the Panda Pushing Dataset (P2D) which shows a Panda arm interacting with objects on a table in simulation and which includes ground-truth segmentation masks and object IDs for tracking. In both cases, APEX comprehensively outperforms the current state-of-the-art in unsupervised object segmentation and tracking. We demonstrate the efficacy of our segmentations for robot skill execution on an object arrangement task, where we also achieve the best or comparable performance among all the baselines.",
        "primary_area": "",
        "author": "Yizhe Wu;Oiwi Parker Jones;Martin Engelcke;Ingmar Posner;Yizhe Wu;Oiwi Parker Jones;Martin Engelcke;Ingmar Posner",
        "authorids": "/37089194821;/37088690104;/37086139639;/37601368300;/37089194821;/37088690104;/37086139639;/37601368300",
        "aff": "Applied AI Lab, Oxford Robotics Institute, University of Oxford; Applied AI Lab, Oxford Robotics Institute, University of Oxford; Applied AI Lab, Oxford Robotics Institute, University of Oxford; Applied AI Lab, Oxford Robotics Institute, University of Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636711/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11906859634005750766&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636746",
        "title": "AVP-Loc: Surround View Localization and Relocalization Based on HD Vector Map for Automated Valet Parking",
        "track": "main",
        "status": "Poster",
        "abstract": "Localization is a crucial prerequisite for automated valet parking, in which a vehicle is required to navigate itself in a GPS-denied parking lot. Traditional visual localization methods usually build a feature map and use it for future localizations. However, the feature map is not robust to changes in illumination, appearance, and viewing perspective. To deal with this issue, we need a more stable map. In this paper, we propose to use the parking lot\u2019s HD vector map directly for localization. The vector representation is ultimately stable but brings challenges in data association as well. To this end, we present a novel data association method to match the surround-view images with the vector map. In addition, we also propose a closed-form relocalization strategy by exploiting distinctive road mark combinations in the vector map. Experiments show that the proposed method is able to achieve centimeter-level localization accuracy in a multi-floor parking lot.",
        "primary_area": "",
        "author": "Chi Zhang;Hao Liu;Zhijun Xie;Kuiyuan Yang;Kun Guo;Rui Cai;Zhiwei Li;Chi Zhang;Hao Liu;Zhijun Xie;Kuiyuan Yang;Kun Guo;Rui Cai;Zhiwei Li",
        "authorids": "/37086571645;/37089264989;/37089197056;/37089194101;/37089197149;/37284702100;/37404741200;/37086571645;/37089264989;/37089197056;/37089194101;/37089197149;/37284702100;/37404741200",
        "aff": "Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636746/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4790261056992041789&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Xiaomi Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.xiaomi.com",
        "aff_unique_abbr": "Xiaomi",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636754",
        "title": "Accelerating Kinodynamic RRT* Through Dimensionality Reduction",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based motion planning algorithms such as RRT* are well-known for their ability to quickly find an initial solution and then converge to the optimal solution asymptotically as the number of samples tends to infinity. However, the convergence rate can be slow for high-dimensional planning problems, particularly for dynamical systems where the sampling space is not just the configuration space but the full state space. In this paper, we introduce the idea of using a partial-final-state-free (PFF) optimal controller in kinodynamic RRT* [1] to reduce the dimensionality of the sampling space. Instead of sampling the full state space, the proposed accelerated kinodynamic RRT*, called Kino-RRT*, only samples part of the state space, while the rest of the states are selected by the PFF optimal controller. We also propose a delayed and intermittent update of the optimal arrival time of all the edges in the RRT* tree to decrease the computation complexity. We tested the proposed algorithm using 4-D and 10-D state-space linear systems and showed that Kino-RRT* converges much faster than the kinodynamic RRT* algorithm.",
        "primary_area": "",
        "author": "Dongliang Zheng;Panagiotis Tsiotras;Dongliang Zheng;Panagiotis Tsiotras",
        "authorids": "/37086196977;/37330609800;/37086196977;/37330609800",
        "aff": "School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Aerospace Engineering and Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636754/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10583632668110647588&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Aerospace Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635931",
        "title": "Acceleration of Actor-Critic Deep Reinforcement Learning for Visual Grasping by State Representation Learning Based on a Preprocessed Input Image",
        "track": "main",
        "status": "Poster",
        "abstract": "For robotic grasping tasks with diverse target objects, some deep learning-based methods have achieved state-of-the-art results using direct visual input. In contrast, actor-critic deep reinforcement learning (RL) methods typically perform very poorly when applied to grasp diverse objects, especially when learning from raw images and sparse rewards. To render these RL techniques feasible for vision-based grasping tasks, we used state representation learning (SRL), in which we encode essential information for subsequent use in RL. However, typical representation learning procedures are unsuitable for extracting pertinent information for learning grasping skills owing to the high complexity of visual inputs for representation learning, in which a robot attempts to grasp a target object. We found that the proposed preprocessed input image is the key to capturing effectively a compact representation. This enables deep RL to learn robotic grasping skills from highly varied and diverse visual inputs. Further, we demonstrate the effectiveness of the proposed approach with varying levels of preprocessing in a realistic simulated environment. We also describe how the resulting model can be transferred to a real-world robot and also demonstrate a 68% success rate on real-world grasp attempts.",
        "primary_area": "",
        "author": "Taewon Kim;Yeseong Park;Youngbin Park;Sang Hyoung Lee;Il Hong Suh;Taewon Kim;Yeseong Park;Youngbin Park;Sang Hyoung Lee;Il Hong Suh",
        "authorids": "/37089197297;/37089194450;/37600943000;/38241379300;/37088446025;/37089197297;/37089194450;/37600943000;/38241379300;/37088446025",
        "aff": "Department of Electronics and Computer Engineering, Hanyang University, Korea; Department of Electronics and Computer Engineering, Hanyang University, Korea; Department of Electronics and Computer Engineering, Hanyang University, Korea; Innovative Smart Manufacturing R&D Department, Korea Institute of Industrial Technology; CogAplex Co., Ltd",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635931/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17099694634859641845&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "Hanyang University;Korea Institute of Industrial Technology;CogAplex Co., Ltd",
        "aff_unique_dep": "Department of Electronics and Computer Engineering;Innovative Smart Manufacturing R&D Department;",
        "aff_unique_url": "http://www.hanyang.ac.kr;http://www.kiot.or.kr;",
        "aff_unique_abbr": "HYU;KIOT;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea;"
    },
    {
        "id": "9636874",
        "title": "Accurate Grid Keypoint Learning for Efficient Video Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Video prediction methods generally consume substantial computing resources in training and deployment, among which keypoint-based approaches show promising improvement in efficiency by simplifying dense image prediction to light keypoint prediction. However, keypoint locations are often modeled only as continuous coordinates, so noise from semantically insignificant deviations in videos easily disrupt learning stability, leading to inaccurate keypoint modeling. In this paper, we design a new grid keypoint learning framework, aiming at a robust and explainable intermediate keypoint representation for long-term efficient video prediction. We have two major technical contributions. First, we detect keypoints by jumping among candidate locations in our raised grid space and formulate a condensation loss to encourage meaningful keypoints with strong representative capability. Second, we introduce a 2D binary map to represent the detected grid keypoints and then suggest propagating keypoint locations with stochasticity by selecting entries in the discrete grid space, thus preserving the spatial structure of keypoints in the long-term horizon for better future frame generation. Extensive experiments verify that our method outperforms the state-of-the-art stochastic video prediction methods while saves more than 98% of computing resources. We also demonstrate our method on a robotic-assisted surgery dataset with promising results. Our code is available at https://github.com/xjgaocs/Grid-Keypoint-Learning.",
        "primary_area": "",
        "author": "Xiaojie Gao;Yueming Jin;Qi Dou;Chi-Wing Fu;Pheng-Ann Heng;Xiaojie Gao;Yueming Jin;Qi Dou;Chi-Wing Fu;Pheng-Ann Heng",
        "authorids": "/37088506701;/37086369638;/37085465414;/37336329800;/37283077400;/37088506701;/37086369638;/37085465414;/37336329800;/37283077400",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, China; Cuhk T Stone Robotics Institute; Department of Computer Science and Engineering, The Chinese University of Hong Kong, China; Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636874/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2507452618222067275&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Chinese University of Hong Kong;Chinese Academy of Sciences",
        "aff_unique_dep": "Department of Computer Science and Engineering;Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems",
        "aff_unique_url": "https://www.cuhk.edu.hk;http://www.cas.cn",
        "aff_unique_abbr": "CUHK;CAS",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636186",
        "title": "Accurate Visual-Inertial SLAM by Feature Re-identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Most of the state-of-the-art visual inertial SLAM methods pay less attention to 2D-2D and 3D-2D matching with more reliable features in a long time span, which easily results in continuous estimation drift. In this paper, we propose an efficient drift-free visual-inertial SLAM method by a pose guided feature matching method to re-identify existing features from a spatial-temporal sensitive sub-global map. The re-identified features serve as augmented visual measurements to anchor the current frame and gradually decrease the accumulated error in the long run. When incorporating the measurements into the optimization module, it benefits to build a drift-free global map in the system. Extensive experiments show that our feature re-identification method is both effective and efficient. Specifically, when combining the feature re-identification with the state-of-the-art SLAM method [1], our method achieves 67.3% and 87.5% absolute trajectory error reduction with only a small additional computational cost on two public SLAM benchmark DBs: EuRoC and TUM-VI respectively.",
        "primary_area": "",
        "author": "Xiongfeng Peng;Zhihua Liu;Qiang Wang;Yun-Tae Kim;Myungjae Jeon;Hong-Seok Lee;Xiongfeng Peng;Zhihua Liu;Qiang Wang;Yun-Tae Kim;Myungjae Jeon;Hong-Seok Lee",
        "authorids": "/37089195222;/37086529587;/37089198031;/37086499563;/37089198265;/37086497865;/37089195222;/37086529587;/37089198031;/37086499563;/37089198265;/37086497865",
        "aff": "SaitChina Lab, Samsung Research Center, Beijing, China; SaitChina Lab, Samsung Research Center, Beijing, China; SaitChina Lab, Samsung Research Center, Beijing, China; Multimedia Processing Lab, Samsung Advanced Institute of Technology, South Korea; Multimedia Processing Lab, Samsung Advanced Institute of Technology, South Korea; Multimedia Processing Lab, Samsung Advanced Institute of Technology, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636186/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7073191240500654451&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "SaitChina Lab",
        "aff_unique_url": "https://www.samsung.com/cn/research/",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;1;1;1",
        "aff_country_unique": "China;South Korea"
    },
    {
        "id": "9636245",
        "title": "Accurate Visual-Inertial SLAM by Manhattan Frame Re-identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Most of the state-of-the-art visual-inertial SLAM methods pay less attention to the scene structure of man-made environments. In this paper, based on the assumption of multiple local Manhattan worlds (MWs), we propose a Manhattan frame (MF) re-identification method to build relative rotation constraints between MF matching pairs and tightly couple these constraints into global bundle adjust module. Specifically, a coarse-to-fine vanishing point (VP) estimation method and pose guided MF temporal consistency verification method are firstly proposed to improve the accuracy and robustness of MF estimation. Then unreliable MF matching pairs are filtered out by a spatial temporal consistency check. Finally, the relative rotation constraints of the remaining MF matching pairs are combined into global bundle adjustment energy function for further optimization. We have validated our proposed method on both synthetic and real-world datasets. When comparing with the baseline method [1], the real-time absolute trajectory error (ATE) of our proposed method has decreased by 29.1%, 19.8% on TartanAir hospital and EuRoC datasets respectively. Our method also exceeds existing state-of-the-art algorithms on both synthetic and real-world datasets.",
        "primary_area": "",
        "author": "Xiongfeng Peng;Zhihua Liu;Qiang Wang;Yun-Tae Kim;Hong-Seok Lee;Xiongfeng Peng;Zhihua Liu;Qiang Wang;Yun-Tae Kim;Hong-Seok Lee",
        "authorids": "/37089195222;/37086529587;/37089198031;/37086499563;/37086497865;/37089195222;/37086529587;/37089198031;/37086499563;/37086497865",
        "aff": "SAIT- China Lab, Samsung Research Center, Beijing, China; SAIT- China Lab, Samsung Research Center, Beijing, China; SAIT- China Lab, Samsung Research Center, Beijing, China; Multimedia Processing Lab, Samsung Advanced Institute of Technology, South Korea; Multimedia Processing Lab, Samsung Advanced Institute of Technology, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636245/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16036432828566765196&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "SAIT- China Lab",
        "aff_unique_url": "https://www.samsung.com/cn/research/",
        "aff_unique_abbr": "SRC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;1;1",
        "aff_country_unique": "China;South Korea"
    },
    {
        "id": "9635834",
        "title": "Accurate depth estimation from a hybrid event-RGB stereo setup",
        "track": "main",
        "status": "Poster",
        "abstract": "Event-based visual perception is becoming increasingly popular owing to interesting sensor characteristics enabling the handling of difficult conditions such as highly dynamic motion or challenging illumination. The mostly complementary nature of event cameras however still means that best results are achieved if the sensor is paired with a regular frame-based sensor. The present work aims at answering a simple question: Assuming that both cameras do not share a common optical center, is it possible to exploit the hybrid stereo setup's baseline to perform accurate stereo depth estimation? We present a learning based solution to this problem leveraging modern spatio-temporal input representations as well as a novel hybrid pyramid attention module. Results on real data demonstrate competitive performance against pure frame-based stereo alternatives as well as the ability to maintain the advantageous properties of event-based sensors.",
        "primary_area": "",
        "author": "Yi-Fan Zuo;Li Cui;Xin Peng;Yanyu Xu;Shenghua Gao;Xia Wang;Laurent Kneip;Yi-Fan Zuo;Li Cui;Xin Peng;Yanyu Xu;Shenghua Gao;Xia Wang;Laurent Kneip",
        "authorids": "/37089400248;/37089197664;/37087323642;/37086571568;/37403624600;/37966522800;/37569040300;/37089400248;/37089197664;/37087323642;/37086571568;/37403624600;/37966522800;/37569040300",
        "aff": "Mobile Perception Lab, ShanghaiTech University, China; Mobile Perception Lab, ShanghaiTech University, China; Mobile Perception Lab, ShanghaiTech University, China; A*STAR, Institute of High Performance Computing, Singapore, Singapore; ShanghaiTech University, Shanghai, China; Key Laboratory of Optoelectronic Imaging Technology and Systems, Ministry of Education, School of Optoelectronics, Beijing Institute of Technology, Beijing, China; Mobile Perception Lab, ShanghaiTech University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635834/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14274624767744550184&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;2;0",
        "aff_unique_norm": "ShanghaiTech University;A*STAR;Beijing Institute of Technology",
        "aff_unique_dep": "Mobile Perception Lab;Institute of High Performance Computing;School of Optoelectronics",
        "aff_unique_url": "http://www.shanghaitech.edu.cn;https://www.a-star.edu.sg;http://www.bit.edu.cn/",
        "aff_unique_abbr": "ShanghaiTech;A*STAR;BIT",
        "aff_campus_unique_index": "0;0;0;0;2;0",
        "aff_campus_unique": "Shanghai;;Beijing",
        "aff_country_unique_index": "0;0;0;1;0;0;0",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "9636585",
        "title": "AcousticFusion: Fusing Sound Source Localization to Visual SLAM in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic objects in the environment, such as people and other agents, lead to challenges for existing simultaneous localization and mapping (SLAM) approaches. To deal with dynamic environments, computer vision researchers usually apply some learning-based object detectors to remove these dynamic objects. However, these object detectors are computationally too expensive for mobile robot on-board processing. In practical applications, these objects output noisy sounds that can be effectively detected by on-board sound source localization. The directional information of the sound source object can be efficiently obtained by direction of sound arrival (DoA) estimation, but the depth estimation is difficult. Therefore, in this paper, we propose a novel audio-visual fusion approach that fuses sound source direction into the RGB-D image and thus removes the effect of dynamic obstacles on the multi-robot SLAM system. Experimental results of multirobot SLAM in different dynamic environments show that the proposed method uses very small computational resources to obtain very stable self-localization results.",
        "primary_area": "",
        "author": "Tianwei Zhang;Huayan Zhang;Xiaofei Li;Junfeng Chen;Tin Lun Lam;Sethu Vijayakumar;Tianwei Zhang;Huayan Zhang;Xiaofei Li;Junfeng Chen;Tin Lun Lam;Sethu Vijayakumar",
        "authorids": "/37086443242;/37088446376;/37085472516;/37089393433;/37571111600;/37295595500;/37086443242;/37088446376;/37085472516;/37089393433;/37571111600;/37295595500",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society, Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Chinese University of Hong Kong, Shenzhen; Westlake University & Westlake Institute for Advanced Study, Hangzhou, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636585/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5142416818669784453&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;2",
        "aff_unique_norm": "Chinese University of Hong Kong;Westlake University;Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "Shenzhen Institute of Artificial Intelligence and Robotics for Society;;Artificial Intelligence and Robotics",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.westlake.edu.cn;http://www.airs.shenzhen.gov.cn/",
        "aff_unique_abbr": "CUHK;WU;AIRS",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Shenzhen;Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636486",
        "title": "Active Exploration and Mapping via Iterative Covariance Regulation over Continuous SE(3) Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper develops iterative Covariance Regulation (iCR), a novel method for active exploration and mapping for a mobile robot equipped with on-board sensors. The problem is posed as optimal control over the SE(3) pose kinematics of the robot to minimize the differential entropy of the map conditioned the potential sensor observations. We introduce a differentiable field of view formulation, and derive iCR via the gradient descent method to iteratively update an open-loop control sequence in continuous space so that the covariance of the map estimate is minimized. We demonstrate autonomous exploration and uncertainty reduction in simulated occupancy grid environments.",
        "primary_area": "",
        "author": "Shumon Koga;Arash Asgharivaskasi;Nikolay Atanasov;Shumon Koga;Arash Asgharivaskasi;Nikolay Atanasov",
        "authorids": "/37085850367;/37088997086;/37670511000;/37085850367;/37088997086;/37670511000",
        "aff": "Department of Electrical and Computer Engineering, UC San Diego, La Jolla, CA; Department of Electrical and Computer Engineering, UC San Diego, La Jolla, CA; Department of Electrical and Computer Engineering, UC San Diego, La Jolla, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636486/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=986337881007545885&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636414",
        "title": "Active Perception for Ambiguous Objects Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent visual pose estimation and tracking solutions provide notable results on popular datasets such as T-LESS and YCB. However, in the real world, we can find ambiguous objects that do not allow exact classification and detection from a single view. In this work, we propose a framework that, given a single view of an object, provides the coordinates of a next viewpoint to discriminate the object against similar ones, if any, and eliminates ambiguities. We also describe a complete pipeline from a real object\u2019s scans to the viewpoint selection and classification. We validate our approach with a Franka Emika Panda robot and common household objects featured with ambiguities. We released the source code to reproduce our experiments.",
        "primary_area": "",
        "author": "Evgenii Safronov;Nicola Piga;Michele Colledanchise;Lorenzo Natale;Evgenii Safronov;Nicola Piga;Michele Colledanchise;Lorenzo Natale",
        "authorids": "/37086870741;/37088341326;/37085361393;/37542770000;/37086870741;/37088341326;/37085361393;/37542770000",
        "aff": "Department of Informatics, Bioengineering, Robotics and Systems Engineering, Universit\u00e0 di Genova, Genova, Italy; Department of Informatics, Bioengineering, Robotics and Systems Engineering, Universit\u00e0 di Genova, Genova, Italy; Istituto Italiano di Tecnologia, Genova, Italy; Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636414/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8433087018098105189&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Universit\u00e0 di Genova;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Informatics, Bioengineering, Robotics and Systems Engineering;",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it",
        "aff_unique_abbr": "UniGe;IIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genova",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636877",
        "title": "Active Visuo-Tactile Point Cloud Registration for Accurate Pose Estimation of Objects in an Unknown Workspace",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel active visuo-tactile based methodology wherein the accurate estimation of the time-invariant SE(3) pose of objects is considered for autonomous robotic manipulators. The robot equipped with tactile sensors on the gripper is guided by a vision estimate to actively explore and localize the objects in the unknown workspace. The robot is capable of reasoning over multiple potential actions, and execute the action to maximize information gain to update the current belief of the object. We formulate the pose estimation process as a linear translation invariant quaternion filter (TIQF) by decoupling the estimation of translation and rotation and formulating the update and measurement model in linear form. We perform pose estimation sequentially on acquired measurements using very sparse point cloud (\u2264 15 points) as acquiring each measurement using tactile sensing is time consuming. Furthermore, our proposed method is computationally efficient to perform an exhaustive uncertainty-based active touch selection strategy in real-time without the need for trading information gain with execution time. We evaluated the performance of our approach extensively in simulation and by a robotic system.",
        "primary_area": "",
        "author": "Prajval Kumar Murali;Michael Gentner;Mohsen Kaboli;Prajval Kumar Murali;Michael Gentner;Mohsen Kaboli",
        "authorids": "/37088524017;/37089195346;/37085362292;/37088524017;/37089195346;/37085362292",
        "aff": "University of Glasgow, Scotland; Technische Universit\u00e4t M\u00fcnchen, Germany; Donders Institute for Brain and Cognition, Radboud University, Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636877/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10818163668235277971&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Glasgow;Technische Universit\u00e4t M\u00fcnchen;Radboud University",
        "aff_unique_dep": ";;Donders Institute for Brain and Cognition",
        "aff_unique_url": "https://www.gla.ac.uk;https://www.tum.de;https://www.ru.nl",
        "aff_unique_abbr": "Glasgow;TUM;RU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "United Kingdom;Germany;Netherlands"
    },
    {
        "id": "9636393",
        "title": "Adaptive Force-based Control for Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Adaptive control can address model uncertainty in control systems. However, it is preliminarily designed for tracking control. Recent advancements in the control of quadruped robots show that force control can effectively realize agile and robust locomotion. In this paper, we present a novel adaptive force-based control framework for legged robots. We introduce a new architecture in our proposed approach to incorporate adaptive control into quadratic programming (QP) force control. Since our approach is based on force control, it also retains the advantages of the baseline framework, such as robustness to uneven terrain, controllable friction constraints, or soft impacts. Our method is successfully validated in both simulation and hardware experiments. While the baseline QP control has shown a significant degradation in the body tracking error with a small load, our proposed adaptive force-based control can enable the 12-kg Unitree A1 robot to walk on rough terrains while carrying a heavy load of up to 6 kg (50% of the robot weight). When standing with four legs, our proposed adaptive control can even allow the robot to carry up to 11 kg of load (92% of the robot weight) with less than 5-cm tracking error in the robot height.",
        "primary_area": "",
        "author": "Mohsen Sombolestan;Yiyu Chen;Quan Nguyen;Mohsen Sombolestan;Yiyu Chen;Quan Nguyen",
        "authorids": "/37089195082;/37089197452;/37085362091;/37089195082;/37089197452;/37085362091",
        "aff": "Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA; Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA; Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636393/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=450758978094367570&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Aerospace and Mechanical Engineering",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636038",
        "title": "Adaptive Hyperparameter Tuning for Black-box LiDAR Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "This study proposes an adaptive data-driven hy-perparameter tuning framework for black-box 3D LiDAR odometry algorithms. The proposed framework comprises offline parameter-error function modeling and online adaptive parameter selection. In the offline step, we run the odometry estimation algorithm for tuning with different parameters and environments and evaluate the accuracy of the estimated trajectories to build a surrogate function that predicts the trajectory estimation error for the given parameters and environments. Subsequently, we select the parameter set that is expected to result in good accuracy in the given environment based on trajectory error prediction with the surrogate function. The proposed framework does not require detailed information on the inner working of the algorithm to be tuned, and improves its accuracy by adaptively optimizing the parameter set. We first demonstrate the role of the proposed framework in improving the accuracy of odometry estimation across different environments with a simulation-based toy example. Further, an evaluation on the public dataset KITTI shows that the proposed framework can improve the accuracy of several odometry estimation algorithms in practical situations.",
        "primary_area": "",
        "author": "Kenji Koide;Masashi Yokozuka;Shuji Oishi;Atsuhiko Banno;Kenji Koide;Masashi Yokozuka;Shuji Oishi;Atsuhiko Banno",
        "authorids": "/37086179385;/38230409400;/37085895378;/37391486400;/37086179385;/38230409400;/37085895378;/37391486400",
        "aff": "Department of Information Technology and Human Factors, National Institute of Advanced Industrial Science and Technology, Ibaraki, Japan; Department of Information Technology and Human Factors, National Institute of Advanced Industrial Science and Technology, Ibaraki, Japan; Department of Information Technology and Human Factors, National Institute of Advanced Industrial Science and Technology, Ibaraki, Japan; Department of Information Technology and Human Factors, National Institute of Advanced Industrial Science and Technology, Ibaraki, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636038/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1052268848322669752&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Department of Information Technology and Human Factors",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ibaraki",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9635828",
        "title": "Adaptive Optimization of Autonomous Vehicle Computational Resources for Performance and Energy Improvement",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles usually consume a large amount of computational power for their operations, especially for the tasks of sensing and perception with artificial intelligence algorithms. Such a computation may not only cost a significant amount of energy but also cause performance issues when the onboard computational resources are limited. To address this issue, this paper proposes an adaptive optimization method to online allocate the onboard computational resources of an autonomous vehicle amongst multiple vehicular subsystems depending on the contexts of the situations that the vehicle is facing. Different autonomous driving scenarios were designed to validate the proposed approach and the results showed that it could help improve the overall performance and energy consumption of autonomous vehicles compared to existing computational arrangement.",
        "primary_area": "",
        "author": "Saurabh Jambotkar;Longxiang Guo;Yunyi Jia;Saurabh Jambotkar;Longxiang Guo;Yunyi Jia",
        "authorids": "/37089197216;/37086350606;/37532721400;/37089197216;/37086350606;/37532721400",
        "aff": "Department of Automotive Engineering, Clemson University, Greenville, SC, USA; Department of Automotive Engineering, Clemson University, Greenville, SC, USA; Department of Automotive Engineering, Clemson University, Greenville, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635828/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1238562881409695008&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Clemson University",
        "aff_unique_dep": "Department of Automotive Engineering",
        "aff_unique_url": "https://www.clemson.edu",
        "aff_unique_abbr": "Clemson",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Greenville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636528",
        "title": "Adaptive Terrain Traversability Prediction based on Multi-Source Transfer Gaussian Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "This study addresses the challenge of predicting the terrain traversability of off-road vehicles. When an off-road vehicle is operated on rough terrains or slopes of unconsolidated materials, it is crucial to accurately predict terrain traversability for efficient operations and to avoid critical mobility risks. However, the prediction of traversability is challenging, especially for the prediction of possibly risky terrains because for such terrains, the traverse data available is either limited or non-existent. To address this limitation, this study proposes an adaptive terrain traversability prediction method based on the multi-source transfer Gaussian process regression (MS-TGPR). The proposed method utilizes limited data available on low risk terrains of the target environment to enhance the prediction accuracy by leveraging past traverse experiences on multiple types of terrain surfaces. The effectiveness of the proposed method is demonstrated using a slip dataset of various terrain surfaces and geometries.",
        "primary_area": "",
        "author": "Hiroaki Inotsume;Takashi Kubota;Hiroaki Inotsume;Takashi Kubota",
        "authorids": "/38235072700;/37273332400;/38235072700;/37273332400",
        "aff": "Research and Development Unit, NEC Corporation, Kawasaki, Kanagawa, Japan; Institute of Space and Astronautical Science, Japan Aerospace Exploration Agency, Sagamihara, Kanagawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636528/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11503881905009439163&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "NEC Corporation;Japan Aerospace Exploration Agency",
        "aff_unique_dep": "Research and Development Unit;Institute of Space and Astronautical Science",
        "aff_unique_url": "https://www.nec.com;https://www.jaxa.jp",
        "aff_unique_abbr": "NEC;JAXA",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Kawasaki;Sagamihara",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636639",
        "title": "Adaptive Tracking Controller for an Alginate Artificial Cell",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an adaptive backstepping controller for the reference tracking of an alginate artificial cell. An adaptive controller was implemented to precisely manipulate a magnetic artificial cell actuated by rotating magnetic fields. The rolling motion of a small-scale robot in a fluidic environment is challenging, especially when the fluid imparts an unknown response at low Reynolds number. In order to compensate for this uncertainty, an unknown tuning parameter encapsulating these effects was added to the governing equations of motion. A controller with an update law was then designed to estimate the unknown parameter and force the artificial cell to produce the desired response. The stability of the proposed controller was established by a candidate Lyapunov function. Real-time experiments were conducted to demonstrate the effectiveness of the designed controller at guiding an artificial cell to an arbitrary target position. Alginate cells were guided through a maze using the controller and was later combined with wall constraints to allow multiple alginate cells to reach the same target location. This controller can be applied to both surface motion and swimming-based small-scale robots in future applications for micro-assembly and targeted drug delivery.",
        "primary_area": "",
        "author": "Gokhan Kararsiz;Louis William Rogowski;Xiao Zhang;Anuruddha Bhattacharjee;Min Jun Kim;Gokhan Kararsiz;Louis William Rogowski;Xiao Zhang;Anuruddha Bhattacharjee;Min Jun Kim",
        "authorids": "/37086524467;/37086020640;/37086024991;/37086937600;/37536816100;/37086524467;/37086020640;/37086024991;/37086937600;/37536816100",
        "aff": "Department of Mechanical Engineering, Southern Methodist University, Dallas, TX, USA; Department of Mechanical Engineering, Southern Methodist University, Dallas, TX, USA; Department of Mechanical Engineering, Southern Methodist University, Dallas, TX, USA; Department of Mechanical Engineering, Southern Methodist University, Dallas, TX, USA; Department of Mechanical Engineering, Southern Methodist University, Dallas, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636639/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7821036222028986944&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Southern Methodist University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.smu.edu",
        "aff_unique_abbr": "SMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Dallas",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636413",
        "title": "Adaptive t-Momentum-based Optimization for Unknown Ratio of Outliers in Amateur Data in Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Behavioral cloning (BC) bears a high potential for safe and direct transfer of human skills to robots. However, demonstrations performed by human operators often contain noise or imperfect behaviors that can affect the efficiency of the imitator if left unchecked. In order to allow the imitators to effectively learn from imperfect demonstrations, we propose to employ the robust t-momentum optimization algorithm. This algorithm builds on the Student's t-distribution in order to deal with heavy-tailed data and reduce the effect of outlying observations. We extend the t-momentum algorithm to allow for an adaptive and automatic robustness and show empirically how the algorithm can be used to produce robust BC imitators against datasets with unknown heaviness. Indeed, the imitators trained with the t-momentum-based Adam optimizers displayed robustness to imperfect demonstrations on two different manipulation tasks with different robots and revealed the capability to take advantage of the additional data while reducing the adverse effect of non-optimal behaviors.",
        "primary_area": "",
        "author": "Wendyam Eric Lionel Ilboudo;Taisuke Kobayashi;Kenji Sugimoto;Wendyam Eric Lionel Ilboudo;Taisuke Kobayashi;Kenji Sugimoto",
        "authorids": "/37089196917;/38542406800;/37301856400;/37089196917;/38542406800;/37301856400",
        "aff": "Division of Information Science, Nara Institute of Science and Technology, Nara, Japan; Division of Information Science, Nara Institute of Science and Technology, Nara, Japan; Division of Information Science, Nara Institute of Science and Technology, Nara, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636413/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2434625624298847930&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nara Institute of Science and Technology",
        "aff_unique_dep": "Division of Information Science",
        "aff_unique_url": "https://www.nist.go.jp",
        "aff_unique_abbr": "NIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nara",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636638",
        "title": "Adversarial Attacks on Camera-LiDAR Models for 3D Car Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Most autonomous vehicles (AVs) rely on LiDAR and RGB camera sensors for perception. Using these point cloud and image data, perception models based on deep neural nets (DNNs) have achieved state-of-the-art performance in 3D detection. The vulnerability of DNNs to adversarial attacks have been heavily investigated in the RGB image domain and more recently in the point cloud domain, but rarely in both domains simultaneously. Multi-modal perception systems used in AVs can be divided into two broad types: cascaded models which use each modality independently, and fusion models which learn from different modalities simultaneously. We propose a universal and physically realizable adversarial attack for each type, and study and contrast their respective vulnerabilities to attacks. We place a single adversarial object with specific shape and texture on top of a car with the objective of making this car evade detection. Evaluating on the popular KITTI benchmark, our adversarial object made the host vehicle escape detection by each model type more than 50% of the time. The dense RGB input contributed more to the success of the adversarial attacks on both cascaded and fusion models.",
        "primary_area": "",
        "author": "Mazen Abdelfattah;Kaiwen Yuan;Z. Jane Wang;Rabab Ward;Mazen Abdelfattah;Kaiwen Yuan;Z. Jane Wang;Rabab Ward",
        "authorids": "/37087469768;/37088526828;/37335978400;/37272152500;/37087469768;/37088526828;/37335978400;/37272152500",
        "aff": "Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636638/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6395193872040836184&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of British Columbia",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ubc.ca",
        "aff_unique_abbr": "UBC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Vancouver",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9635933",
        "title": "Aerial Manipulator Suspended from a Cable-Driven Parallel Robot: Preliminary Experimental Results",
        "track": "main",
        "status": "Poster",
        "abstract": "Since omnidirectional aerial vehicles can generate a six degrees of freedom wrench, they could be used for dexterous manipulation tasks without the need for an additional robotic arm. However, they suffer from a reduced efficiency and dynamics range due to the huge amount of energy lost in gravity compensation.In this work, we introduce an omnidirectional aerial manipulator suspended from a cable-driven parallel robot (CDPR) by a spring, combining the advantages of the CDPR large workspace with the high dynamics of aerial vehicles, while reducing energy consumption thanks to gravity compensation.A partitioned control scheme is implemented to regulate both systems separately. A preliminary control strategy is proposed for the CDPR motion that minimizes the total energy consumption. Experiments are carried out to assess the added value of the CDPR carrier.",
        "primary_area": "",
        "author": "Arda Yi\u011fit;Miguel Arpa Perozo;Mandela Ouafo;Lo\u00efc Cuvillon;Sylvain Durand;Jacques Gangloff;Arda Yi\u011fit;Miguel Arpa Perozo;Mandela Ouafo;Lo\u00efc Cuvillon;Sylvain Durand;Jacques Gangloff",
        "authorids": "/37088507420;/37088652283;/37089194595;/37563879500;/37411970500;/37283578200;/37088507420;/37088652283;/37089194595;/37563879500;/37411970500;/37283578200",
        "aff": "ICube Laboratory, University of Strasbourg, INSA Strasbourg, Strasbourg, France; ICube Laboratory, University of Strasbourg, INSA Strasbourg, Strasbourg, France; ICube Laboratory, University of Strasbourg, INSA Strasbourg, Strasbourg, France; ICube Laboratory, University of Strasbourg, INSA Strasbourg, Strasbourg, France; ICube Laboratory, University of Strasbourg, INSA Strasbourg, Strasbourg, France; ICube Laboratory, University of Strasbourg, INSA Strasbourg, Strasbourg, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635933/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9387143568363112579&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Strasbourg",
        "aff_unique_dep": "ICube Laboratory",
        "aff_unique_url": "https://www.unistra.fr",
        "aff_unique_abbr": "UNistra",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Strasbourg",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636572",
        "title": "Aerodynamic Modeling of Fully-Actuated Multirotor UAVs with Nonparallel Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "The beneficial aspects of fully-actuated multirotor UAVs, provided by nonparallel rotor configuration, are increasingly being recognized and utilized to great benefit in high-precision applications. Full six-degree-of-freedom force control, higher control bandwidth and improved disturbance rejection prove valuable. However, the cant angle will cause great multirotor dihedral effect and significantly affects blade flapping, which decreases the flight performance of nonparallel actuated UAVs. Therefore, this paper presents a novel aerodynamic model for fully-actuated hexrotor UAVs while considering the aerodynamic effects caused due to tilt angled propeller configurations. In the proposed aerodynamic model, the significance of multirotor dihedral effect, defined as an aerodynamic coefficient proportional to the relative linear velocity of the UAV, is modeled for nonparallel actuators. Additionally, the modeling for blade flapping effect for cant angled propellers is provided to accurately model the aerodynamics. Wind tunnel experiments were conducted to characterize the aerodynamic constants for multirotor dihedral effect, blade flapping effect and air friction. Experimental results are presented to validate the proposed aerodynamic model on a fully-actuated hexrotor UAV (Purdue\u2019s Dexterous Hexrotor). Lastly, the multirotor dihedral effect and blade flapping effect at different cant angles and at different wind speeds are analyzed.",
        "primary_area": "",
        "author": "Praveen Abbaraju;Xin Ma;Guangying Jiang;Mo Rastgaar;Richard M. Voyles;Praveen Abbaraju;Xin Ma;Guangying Jiang;Mo Rastgaar;Richard M. Voyles",
        "authorids": "/37089001824;/37085857304;/37061022800;/37085355283;/37283531400;/37089001824;/37085857304;/37061022800;/37085355283;/37283531400",
        "aff": "Collaborative Robotics Lab, SoET, Purdue University, West Lafayette, IN, USA; Collaborative Robotics Lab, SoET, Purdue University, West Lafayette, IN, USA; Collaborative Robotics Lab, SoET, Purdue University, West Lafayette, IN, USA; SoET, Purdue University, West Lafayette, IN, USA; Collaborative Robotics Lab & SoET, Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636572/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7967215325273277473&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "School of Engineering and Technology",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636451",
        "title": "Affect-driven Robot Behavior Learning System using EEG Signals for Less Negative Feelings and More Positive Outcomes",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from human feedback using event-related electroencephalography (EEG) signals has attracted extensive attention recently owing to their intuitive communication ability by decoding user intentions. However, this approach requires users to perform specified tasks and their success or failure. In addition, the amount of attention needed for decision-making increases with the task difficulty, decreasing human feedback quality over time because of fatigue. Consequently, this can reduce the interaction quality and can even cause interaction breakdowns. To overcome these limitations and enable the interaction of robots with higher complexity tasks, we propose a closed-loop control system that learns affective responses to robot behaviors and provides natural feedback to optimize robot parameters for smoothing the next action. Experimental results demonstrate our affect-driven closed-loop control system yielded better affective outcomes and task performance than an open-loop system with correlated neuroscientific characteristics of EEG signals, thus enhancing the quality of human-robot interaction.",
        "primary_area": "",
        "author": "Byung Hyung Kim;Ji Ho Kwak;Minuk Kim;Sungho Jo;Byung Hyung Kim;Ji Ho Kwak;Minuk Kim;Sungho Jo",
        "authorids": "/37085364983;/37088924460;/37089196798;/37586566700;/37085364983;/37088924460;/37089196798;/37586566700",
        "aff": "Department of Artificial Intelligence, Inha University, Republic of Korea; School of Computing, KAIST, Republic of Korea; School of Electrical Engineering, KAIST, Republic of Korea; School of Computing, KAIST, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636451/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16783748225910031069&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Inha University;KAIST",
        "aff_unique_dep": "Department of Artificial Intelligence;School of Computing",
        "aff_unique_url": "https://www.inha.edu;https://www.kaist.ac.kr",
        "aff_unique_abbr": "Inha;KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636210",
        "title": "Agent-Aware State Estimation in Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous systems often operate in environments where the behavior of multiple agents is coordinated by a shared global state. Reliable estimation of the global state is thus critical for successfully operating in a multi-agent setting. We introduce agent-aware state estimation\u2014a framework for calculating indirect estimations of state given observations of the behavior of other agents in the environment. We also introduce transition-independent agent-aware state estimation\u2014a tractable class of agent-aware state estimation\u2014and show that it allows the speed of inference to scale linearly with the number of agents in the environment. As an example, we model traffic light classification in instances of complete loss of direct observation. By taking into account observations of vehicular behavior from multiple directions of traffic, our approach exhibits accuracy higher than that of existing traffic light-only HMM methods on a real-world autonomous vehicle data set under a variety of simulated occlusion scenarios.",
        "primary_area": "",
        "author": "Shane Parr;Ishan Khatri;Justin Svegliato;Shlomo Zilberstein;Shane Parr;Ishan Khatri;Justin Svegliato;Shlomo Zilberstein",
        "authorids": "/37089198196;/37087995751;/37072711700;/37285091900;/37089198196;/37087995751;/37072711700;/37285091900",
        "aff": "University of Massachusetts Amherst; University of Massachusetts Amherst; College of Information and Computer Sciences, University of Massachusetts Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636210/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3334879146026170212&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Massachusetts Amherst",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass Amherst",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Amherst",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636690",
        "title": "Aggressive Visual Perching with Quadrotors on Inclined Surfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous Micro Aerial Vehicles (MAVs) have the potential to be employed for surveillance and monitoring tasks. By perching and staring on one or multiple locations aerial robots can save energy while concurrently increasing their overall mission time without actively flying. In this paper, we address the estimation, planning, and control problems for autonomous perching on inclined surfaces with small quadrotors using visual and inertial sensing. We focus on planning and executing dynamically feasible trajectories to navigate and perch to a desired target location with on board sensing and computation. Our planner also supports certain classes of nonlinear global constraints by leveraging an efficient algorithm that we have mathematically verified. The on board cameras and IMU are concurrently used for state estimation and to infer the relative robot/target localization. The proposed solution runs in real-time on board a limited computational unit. Experimental results validate the proposed approach by tackling aggressive perching maneuvers with flight envelopes that include large excursions from the hover position on inclined surfaces up to 90\u00b0, angular rates up to 600 deg/s, and accelerations up to 10 m/s2.",
        "primary_area": "",
        "author": "Jeffrey Mao;Guanrui Li;Stephen Nogar;Christopher Kroninger;Giuseppe Loianno;Jeffrey Mao;Guanrui Li;Stephen Nogar;Christopher Kroninger;Giuseppe Loianno",
        "authorids": "/37089195746;/37086455447;/37086354053;/37992994100;/37085496544;/37089195746;/37086455447;/37086354053;/37992994100;/37085496544",
        "aff": "Tandon School of Engineering, New York University, Brooklyn, NY, USA; Tandon School of Engineering, New York University, Brooklyn, NY, USA; U.S. Army Research Laboratory, Adelphi, MD, USA; U.S. Army Research Laboratory, Adelphi, MD, USA; Tandon School of Engineering, New York University, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636690/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13148552595018181935&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "New York University;U.S. Army Research Laboratory",
        "aff_unique_dep": "Tandon School of Engineering;",
        "aff_unique_url": "https://www.nyu.edu;https://www.arl.army.mil",
        "aff_unique_abbr": "NYU;ARL",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Brooklyn;Adelphi",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636373",
        "title": "All Characteristics Preservation: Single Image Dehazing based on Hierarchical Detail Reconstruction Wavelet Decomposition Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Single image haze removal is crucial in computer vision. In open literatures, two kinds of dehazing strategies (prior-based and learning-based methods) have been developed. However, they have a trade-off between detail preservation and the image quality. Prior-based methods reconstruct the detail well but have lower image quality while learning-based methods achieve better recovered quality but lose the detail. In this paper, to mitigate this dilemma, a hierarchical architecture using the discrete wavelet transform (DWT) is proposed. It divides the dehazing problem into two parts: detail and background reconstruction. Based on investigating how haze affects the image in the wavelet domain, two networks for detail and background reconstruction are proposed. To avoid color distortion and the detail loss, the anti-vanish wavelet loss and the bound penalty are proposed. The multi-level wavelet component discriminator is proposed for further improvement. Experiments show that the proposed network can achieve superior performance in all metrics.",
        "primary_area": "",
        "author": "Wei-Ting Chen;Hao-Yu Fang;Cheng-Che Tsai;Jian-Jiun Ding;Sy-Yen Kuo;Wei-Ting Chen;Hao-Yu Fang;Cheng-Che Tsai;Jian-Jiun Ding;Sy-Yen Kuo",
        "authorids": "/37086524660;/37087085124;/37089195694;/37279610700;/37275685500;/37086524660;/37087085124;/37089195694;/37279610700;/37275685500",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636373/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13844990703974465777&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10
    },
    {
        "id": "9636136",
        "title": "Alternating Drive-and-Glide Flight Navigation of a Kiteplane for Sound Source Position Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Drone audition, namely the hearing capability of a drone, is expected to compensate for the drawbacks of visual sensors in search-and-rescue missions. Current multi-rotor drones have limitations of flight duration and sound processing due to ego-noise generated by rotors and air-flow. Drone audition for a kiteplane, i.e., a fixed-wing drone that can fly slowly and stably, has not been investigated. This paper proposes \"Alternating Drive-and-Glide Flight Navigation\"(AltDGFNavi) of a kiteplane for sound source position estimation. AltDGFNavi consists of two functions: periodical switching rotor for driving and gliding to reduce ego-noise, and dynamic flight path generation to fly close to the target. AltDGFNavi was evaluated through numerical simulations, and the results of sound source position estimation demonstrated the effectiveness of AltDGFNavi.",
        "primary_area": "",
        "author": "Makoto Kumon;Hiroshi G. Okuno;Shuichi Tajima;Makoto Kumon;Hiroshi G. Okuno;Shuichi Tajima",
        "authorids": "/37296098600;/37273831200;/37089196478;/37296098600;/37273831200;/37089196478",
        "aff": "Kumamoto University, Kumamoto, Japan; Waseda University, Kyoto & Tokyo, Japan; Kumamoto University, Kumamoto, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636136/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4413690755631460666&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Kumamoto University;Waseda University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.kumamoto-u.ac.jp;https://www.waseda.jp/top",
        "aff_unique_abbr": "KU;Waseda",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Kumamoto;Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636470",
        "title": "Amplification of Clamping Mechanism Using Internally-Balanced Magnetic Unit",
        "track": "main",
        "status": "Poster",
        "abstract": "Machines tend to use powerful actuators and large gearboxes to bear large loads, which are inconvenient in terms of responsiveness as they affect the duration of operations. Thus, to compensate the force to grasp an object, we propose a clamping mechanism implementing the internally-balanced magnetic unit (IB Magnet) as a force amplifier, which is a mechanism able to switch attached and detached states of a permanent magnet with an external force considerably smaller than its original attractive force. To realize the bi-parting constitution of fingers, a new compensation method using conical coil springs was designed to provide both precision and miniaturization. Relative to the constitution with a single motored screw, the prototype gripper for proof of concept successfully amplified the grasping force at most to 292.2% assisted by the magnetic attraction, while keeping the increase in power consumption of a DC motor only by 11.8%, making the force-energy efficiency 2.6 times larger. Thus, it was verified that the proposed gripper enables the use of actuators and current supplies that require less power.",
        "primary_area": "",
        "author": "Tori Shimizu;Kenjiro Tadakuma;Masahiro Watanabe;Eri Takane;Masashi Konyo;Satoshi Tadokoro;Tori Shimizu;Kenjiro Tadakuma;Masahiro Watanabe;Eri Takane;Masashi Konyo;Satoshi Tadokoro",
        "authorids": "/37087013645;/38534909200;/37403419100;/37086003949;/37296053600;/37296054300;/37087013645;/38534909200;/37403419100;/37086003949;/37296053600;/37296054300",
        "aff": "Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan; Graduate School of Information Sciences, Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636470/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14765985968743056849&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Graduate School of Information Sciences",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Sendai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636298",
        "title": "An Adversarial Objective for Scalable Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "Collecting new experience is costly in many robotic tasks, so determining how to efficiently explore in a new environment to learn as much as possible in as few trials as possible is an important problem for robotics. In this paper, we propose a method for exploring for the purpose of learning a dynamics model. Our key idea is to minimize a score given by a discriminator network as an objective for a planner which chooses actions. This discriminator is optimized jointly with a prediction model and enables our active learning approach to sample sequences of observations and actions which result in predictions considered the least realistic by the discriminator. Comparable existing exploration methods cannot operate in many prediction-planning pipelines used in robotic learning without hardware modifications to standard robotics platforms in order to accommodate their large compute requirements, so the primary contribution of our adversarial exploration method is scalability. We demonstrate progressively increased performance of our adversarial exploration approach compared to leading model-based exploration strategies as compute is restricted in simulated environments. We further demonstrate the ability of our adversarial method to scale to a robotic manipulation prediction-planning pipeline where we improve sample efficiency and prediction performance for a domain transfer problem.",
        "primary_area": "",
        "author": "Bernadette Bucher;Karl Schmeckpeper;Nikolai Matni;Kostas Daniilidis;Bernadette Bucher;Karl Schmeckpeper;Nikolai Matni;Kostas Daniilidis",
        "authorids": "/37089194773;/37086802970;/37398611500;/37270623200;/37089194773;/37086802970;/37398611500;/37270623200",
        "aff": "GRASP Laboratory, University of Pennsylvania; GRASP Laboratory, University of Pennsylvania; GRASP Laboratory, University of Pennsylvania; GRASP Laboratory, University of Pennsylvania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636298/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15327974312021709872&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636637",
        "title": "An Analysis of Human-Robot Information Streams to Inform Dynamic Autonomy Allocation",
        "track": "main",
        "status": "Poster",
        "abstract": "A dynamic autonomy allocation framework automatically shifts how much control lies with the human versus the robotics autonomy, for example based on factors such as environmental safety or user preference. To investigate the question of which factors should drive dynamic autonomy allocation, we perform a human subject study to collect ground truth data that shifts between levels of autonomy during shared-control robot operation. Information streams from the human, the interaction between the human and the robot, and the environment are analyzed. Machine learning methods\u2014both classical and deep learning\u2014are trained on this data. An analysis of information streams from the human-robot team suggests features which capture the interaction between the human and the robotics autonomy are the most informative in predicting when to shift autonomy levels. Even the addition of data from the environment does little to improve upon this predictive power. The features learned by deep networks, in comparison to the hand-engineered features, prove variable in their ability to represent shift-relevant information. This work demonstrates the classification power of human-only and human-robot interaction information streams for use in the design of shared-control frameworks, and provides insights into the comparative utility of various data streams and methods to extract shift-relevant information from those data.",
        "primary_area": "",
        "author": "Christopher X. Miller;Temesgen Gebrekristos;Michael Young;Enid Montague;Brenna Argall;Christopher X. Miller;Temesgen Gebrekristos;Michael Young;Enid Montague;Brenna Argall",
        "authorids": "/37086937951;/37089197451;/37086919393;/37085594203;/37568669000;/37086937951;/37089197451;/37086919393;/37085594203;/37568669000",
        "aff": "The Department of Mechanical Engineering, Northwestern University, and the Shirley Ryan AbilityLab, Chicago, IL, USA; The Department of Mechanical Engineering, Northwestern University, and the Shirley Ryan AbilityLab, Chicago, IL, USA; The Department of Mechanical Engineering, Northwestern University, and the Shirley Ryan AbilityLab, Chicago, IL, USA; College of Computing, DePaul University and Feinberg School of Medicine, Northwestern University, Chicago, IL, USA; Departments of Computer Science and Physical Medicine and Rehabilitation, Northwestern University, Chicago, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636637/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8492126617160990491&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Northwestern University;DePaul University",
        "aff_unique_dep": "Department of Mechanical Engineering;College of Computing",
        "aff_unique_url": "https://www.northwestern.edu;https://www.depaul.edu",
        "aff_unique_abbr": "NU;DePaul",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636291",
        "title": "An Analysis on the Modeling Accuracy of Industrial Manipulators with Inherent Joint Elasticity",
        "track": "main",
        "status": "Poster",
        "abstract": "High precision industrial applications call for equally precise functioning of industrial manipulators, which in turn requires accurate modeling of the manipulators. This paper carries out a detailed study on the modeling of industrial manipulators with elastic joints to improve their accuracy. In particular, the effect of adopting a simple harmonic drive (HD) model and ignoring a dynamic effect called low inertia coupling between the actuators and links on the model accuracy has been analyzed from a parameter estimation perspective. Since the aforementioned model characteristics have been generally ignored for high gear reduction ratios, this study is carried out with five different reduction ratios ranging from low to high, where three different models of a three-joints elastic manipulator are considered. The accuracy of the models is compared using the torque performance metrics of a predefined joint motion of the robot. Furthermore, the impact of the models with different accuracy is assessed by carrying out a state-of-the-art dynamic parameter estimation, and the resulting errors are compared to ascertain the merits of adopting a detailed elastic dynamic model of a manipulator.",
        "primary_area": "",
        "author": "Rajesh Subburaman;Mariapaola D\u2019Imperio;Jinoh Lee;Ferdinando Cannella;Rajesh Subburaman;Mariapaola D\u2019Imperio;Jinoh Lee;Ferdinando Cannella",
        "authorids": "/37086102614;/37085381441;/37085391573;/37681701900;/37086102614;/37085381441;/37085391573;/37681701900",
        "aff": "Industrial Robotics Unit, Istituto Italiano di Tecnologia (IIT), Genova, Italy; Industrial Robotics Unit, Istituto Italiano di Tecnologia (IIT), Genova, Italy; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), We\u00dfling, Germany; Industrial Robotics Unit, Istituto Italiano di Tecnologia (IIT), Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636291/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:W3RbEde7wlwJ:scholar.google.com/&scioq=An+Analysis+on+the+Modeling+Accuracy+of+Industrial+Manipulators+with+Inherent+Joint+Elasticity&hl=en&as_sdt=0,5",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;German Aerospace Center",
        "aff_unique_dep": "Industrial Robotics Unit;Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.iit.it;https://www.dlr.de",
        "aff_unique_abbr": "IIT;DLR",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Genova;We\u00dfling",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Italy;Germany"
    },
    {
        "id": "9636621",
        "title": "An Anthropomorphic Prosthetic Hand with an Active, Selectively Lockable Differential Mechanism: Towards Affordable Dexterity",
        "track": "main",
        "status": "Poster",
        "abstract": "Over the last decade, adaptive tendon driven devices have gained an increased interest from the research community for their lightweight, compact, and affordable design features attributed to the utilisation of underactuation, differential mechanisms, and structural compliance. Although adaptive tendon driven devices are capable of efficiently executing stable grasps under significant object pose uncertainties with simplistic control algorithms, they lack the controllability over individual fingers in comparison to traditional fully actuated designs. In this paper, we focus on the development of a selectively lockable differential mechanism that is powered through a small and low torque servo to provide increased autonomy to highly underactuated and adaptive prosthetic hands, without compromising the weight, cost, and compactness of the device. The proposed prosthetic hand is experimentally validated through four tests: i) grasping posture and gesture execution experiments, ii) grasping experiments with everyday life objects, iii) force exertion experiments, and iv) Electromyography (EMG) based control of the prosthetic hand.",
        "primary_area": "",
        "author": "Geng Gao;Anany Dwivedi;Minas Liarokapis;Geng Gao;Anany Dwivedi;Minas Liarokapis",
        "authorids": "/37087027460;/37086133073;/38558084100;/37087027460;/37086133073;/38558084100",
        "aff": "Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636621/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17536859165981081092&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Auckland",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "UoA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9636319",
        "title": "An Approach to Deploy Interactive Robotic Simulators on the Web for HRI Experiments: Results in Social Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Evaluation of social robot navigation inherently requires human input due to its qualitative nature. Motivated by the need to scale human evaluation, we propose a general method for deploying interactive, rich-client robotic simulations on the web. Prior approaches implement specific web- compatible simulators or provide tools to build a simulator for a specific study. Instead, our approach builds on standard Linux tools to share a graphical desktop with remote users. We leverage these tools to deploy simulators on the web that would typically be constrained to desktop computing environments. As an example implementation of our approach, we introduce the SEAN Experimental Platform (SEAN-EP). With SEAN- EP, remote users can virtually interact with a mobile robot in the Social Environment for Autonomous Navigation, without installing any software on their computer or needing specialized hardware. We validated that SEAN-EP could quickly scale the collection of human feedback and its usability through an online survey. In addition, we compared human feedback from participants that interacted with a robot using SEAN- EP with feedback obtained through a more traditional video survey. Our results suggest that human perceptions of robots may differ based on whether they interact with the robots in simulation or observe them in videos. Also, they suggest that people perceive the surveys with interactive simulations as less mentally demanding than video surveys.",
        "primary_area": "",
        "author": "Nathan Tsoi;Mohamed Hussein;Olivia Fugikawa;J. D. Zhao;Marynel V\u00e1zquez;Nathan Tsoi;Mohamed Hussein;Olivia Fugikawa;J. D. Zhao;Marynel V\u00e1zquez",
        "authorids": "/37087231155;/37089198065;/37089197587;/37089194051;/37707834500;/37087231155;/37089198065;/37089197587;/37089194051;/37707834500",
        "aff": "Rutgers University-Camden, Camden, NJ, USA; Rutgers University-Camden, Camden, NJ, USA; Rutgers University-Camden, Camden, NJ, USA; Rutgers University-Camden, Camden, NJ, USA; Rutgers University-Camden, Camden, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636319/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5679881706721238859&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Camden",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636261",
        "title": "An Assistive Shared Control Architecture for a Robotic Arm Using EEG-Based BCI with Motor Imagery",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper presents a shared control architecture for robotic systems commanded through a motor imagery based Brain-Computer Interface (BCI). The overall system is aimed at assisting people to perform teleoperated manipulation tasks, and it is structured so as to leave different levels of autonomy to the user depending on the actual stage of the task execution. The low-level part of the shared control architecture is also in charge of taking into account safety and operational tasks, such as to avoid collisions or to manage robot joint limits. The overall architecture has been realized by integrating control and perception software modules developed within the ROS environment, with the OpenVibe framework used to operate the BCI device. The effectiveness of the proposed architecture has been validated through experiments where a healthy user, wearing a Unicorn g.tec BCI, performs an assisted task through motor imagery sessions, with a 7 Degrees of Freedoms Kinova Jaco2 robotic arm.",
        "primary_area": "",
        "author": "Giuseppe Gillini;Paolo Di Lillo;Filippo Arrichiello;Giuseppe Gillini;Paolo Di Lillo;Filippo Arrichiello",
        "authorids": "/37087103540;/37086181378;/37298259000;/37087103540;/37086181378;/37298259000",
        "aff": "Department of Electrical and Information Engineering, University of Cassino and Southern Lazio, Cassino (FR), Italy; Department of Electrical and Information Engineering, University of Cassino and Southern Lazio, Cassino (FR), Italy; Department of Electrical and Information Engineering, University of Cassino and Southern Lazio, Cassino (FR), Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636261/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5994643218740448230&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Cassino and Southern Lazio",
        "aff_unique_dep": "Department of Electrical and Information Engineering",
        "aff_unique_url": "https://www.unicas.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cassino",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636601",
        "title": "An Efficient Image-to-Image Translation HourGlass-based Architecture for Object Pushing Policy Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans effortlessly solve pushing tasks in everyday life but unlocking these capabilities remains a challenge in robotics because physics models of these tasks are often inaccurate or unattainable. State-of-the-art data-driven approaches learn to compensate for these inaccuracies or replace the approximated physics models altogether. Nevertheless, approaches like Deep Q-Networks (DQNs) suffer from local optima in large state-action spaces. Furthermore, they rely on well-chosen deep learning architectures and learning paradigms. In this paper, we propose to frame the learning of pushing policies (where to push and how) by DQNs as an image-to-image translation problem and exploit an Hourglass-based architecture. We present an architecture combining a predictor of which pushes lead to changes in the environment with a state-action value predictor dedicated to the pushing task. Moreover, we investigate positional information encoding to learn position-dependent policy behaviors. We demonstrate in simulation experiments with a UR5 robot arm that our overall architecture helps the DQN learn faster and achieve higher performance in a pushing task involving objects with unknown dynamics.",
        "primary_area": "",
        "author": "Marco Ewerton;Angel Mart\u00ednez-Gonz\u00e1lez;Jean-Marc Odobez;Marco Ewerton;Angel Mart\u00ednez-Gonz\u00e1lez;Jean-Marc Odobez",
        "authorids": "/37085357736;/37086639130;/37271897800;/37085357736;/37086639130;/37271897800",
        "aff": "Idiap Research Institute, Martigny, Switzerland; Idiap Research Institute, Martigny, Switzerland; Idiap Research Institute, Martigny, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636601/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2687306083593052634&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Idiap Research Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.idiap.ch",
        "aff_unique_abbr": "Idiap",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Martigny",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636007",
        "title": "An Efficient Understandability Objective for Dynamic Optimal Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion optimization for legible robot intent has largely ignored the robot\u2019s dynamics, citing burdensome complexity that prevents online deployment. Even where the original task (to be communicated) could be solved on the dynamical system, the legibility problem (to communicate that task\u2019s intent) could not. This work simplifies the legibility objective to have equivalent computational complexity as the original objective to be communicated. This enables any optimal control algorithm that can solve the original task to also solve the legible version of that task.Along the way, we expand the definition of \"intent\" to include any parameter of the optimal control problem, thereby opening the door to extend communications beyond merely desired end-points to running preferences or even, in the future, hard capabilities or safety constraints. We demonstrate how this method can replicate the properties introduced in previous communicative motion state-of-the-art (like legibility, exaggeration, and anticipation) as well as apply to non-holonomic dynamical systems.",
        "primary_area": "",
        "author": "D. Livingston McPherson;S. Shankar Sastry;D. Livingston McPherson;S. Shankar Sastry",
        "authorids": "/37085370314;/37270557300;/37085370314;/37270557300",
        "aff": "Department of Electrical Engineering and Computer Science, University of California, Berkeley; Department of Electrical Engineering and Computer Science, University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636007/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11738688804155629471&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635937",
        "title": "An Efficient and Continuous Representation for Occupancy Mapping with Random Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Generating meaningful spatial models of physical environments is a crucial ability for autonomous navigation of mobile robots. This paper considers the problem of building continuous occupancy maps from sparse and noisy sensor data. To this end, we propose a new method named random mapping maps that advances the popular methods in two aspects. Firstly, it can represent environment models in a memory-saving and time-saving manner by randomly mapping a low-dimensional feature space to a high-dimensional one where a linear model is learnt. Secondly, it can rapidly obtain accurate inferences of the occupancy states of the spatial locations. This technique is based on the random mapping that projects the measurement data into a random feature space in which a discriminative model is learnt by the available data. It can asymptotically represent the complexity of the real world as the mapping dimension increases. Evaluations of the proposed method were conducted on various environments to verify its availability to environment modeling. Its performances in terms of time and memory consumptions were evaluated quantitatively. Finally, as a practical application, experiments about path planning were conducted based on the gradients of the proposed representation of environment model.",
        "primary_area": "",
        "author": "Xu Liu;Decai Li;Yuqing He;Xu Liu;Decai Li;Yuqing He",
        "authorids": "/37086945181;/37086182699;/37288326300;/37086945181;/37086182699;/37288326300",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; Shenyang Institute of Automation (Guangzhou), Chinese Academy of Sciences, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635937/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15243209182982871052&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences;Shenyang Institute of Automation",
        "aff_unique_dep": ";Institutes for Robotics and Intelligent Manufacturing;Chinese Academy of Sciences",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.cas.cn;http://www.sia.cas.cn",
        "aff_unique_abbr": "UCAS;CAS;SIA",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Beijing;Shenyang;Guangzhou",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636247",
        "title": "An Industrial Robot for Firewater Piping Inspection and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "The design of an industrial pipe inspection robot for 4\" firewater piping inspection and mapping with some new and unreported features is presented. The robot consists of a compact 3D MEMs Lidar with non-linear scanning pattern in the form of Lissajous trajectories that produces a dense scan of inner pipe surfaces. Evaluating the surface integrals of these 3D point clouds acquired at pipe turns allow for turn direction discrimination on the horizontal plane which is not realizable using IMUs. A non-SLAM method is used for robust localization: the actual distance traveled by the robot inside a pipe network is measured explicitly by measuring tether displacement; this measurand is then used as the arc length parameter of a parametric curve. This parameterization represents the robot trajectory such that the 3D robot positions along this trajectory are defined in terms of distances traveled (arc length of parametric curve). Pose transitions measured using an on-board IMU combined with the arc-length parametric trajectory let us determine the full 6D robot pose inside featureless pipes. Instantaneous Lidar scans and the 6D poses are used to create a high density 3D map of the pipe network to help identify pipe joint deformation at cm level.",
        "primary_area": "",
        "author": "Aneesh N. Chand;Naji Zuhdi;Asmadi Mansor;Asif Iqbal;Faiz Rustam;Walter Baur;Aneesh N. Chand;Naji Zuhdi;Asmadi Mansor;Asif Iqbal;Faiz Rustam;Walter Baur",
        "authorids": "/37845594200;/37088873231;/37088871536;/37089196523;/37088871765;/37089193922;/37845594200;/37088873231;/37088871536;/37089196523;/37088871765;/37089193922",
        "aff": "Robotics Lab, Facilities of the Future, Petronas Research, Malaysia; Robotics Lab, Facilities of the Future, Petronas Research, Malaysia; Robotics Lab, Facilities of the Future, Petronas Research, Malaysia; Robotics Lab, Facilities of the Future, Petronas Research, Malaysia; Robotics Lab, Facilities of the Future, Petronas Research, Malaysia; Waygate Technologies, Baker Hughes, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636247/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11739768235721970053&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Petronas Research;Baker Hughes",
        "aff_unique_dep": "Robotics Lab, Facilities of the Future;",
        "aff_unique_url": "https://www.petronas.com.my;https://www.bakerhughes.com",
        "aff_unique_abbr": ";Baker Hughes",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "Malaysia;Switzerland"
    },
    {
        "id": "9636434",
        "title": "An Integrated Approach to Context-Sensitive Moral Cognition in Robot Cognitive Architectures",
        "track": "main",
        "status": "Poster",
        "abstract": "Acceptance of social robots in human-robot collaborative environments depends on the robots\u2019 sensitivity to human moral and social norms. Robot behavior that violates norms may decrease trust and lead human interactants to blame the robot and view it negatively. Hence, for long-term acceptance, social robots need to detect possible norm violations in their action plans and refuse to perform such plans. This paper integrates the Distributed, Integrated, Affect, Reflection, Cognition (DIARC) robot architecture (implemented in the Agent Development Environment (ADE)) with a novel place recognition module and a norm-aware task planner to achieve context-sensitive moral reasoning. This will allow the robot to reject inappropriate commands and comply with context-sensitive norms. In a validation scenario, our results show that the robot would not comply with a human command to violate a privacy norm in a private context.",
        "primary_area": "",
        "author": "Ryan Blake Jackson;Sihui Li;Santosh Balajee Banisetty;Sriram Siva;Hao Zhang;Neil Dantam;Tom Williams;Ryan Blake Jackson;Sihui Li;Santosh Balajee Banisetty;Sriram Siva;Hao Zhang;Neil Dantam;Tom Williams",
        "authorids": "/37089196456;/37087060752;/37089194651;/37086453331;/37085545929;/37546520000;/37085468519;/37089196456;/37087060752;/37089194651;/37086453331;/37085545929;/37546520000;/37085468519",
        "aff": "Department of Computer Science, Colorado School of Mines, USA; Department of Computer Science, Colorado School of Mines, USA; Department of Computer Science, Colorado School of Mines, USA; Department of Computer Science, Colorado School of Mines, USA; Department of Computer Science, Colorado School of Mines, USA; Department of Computer Science, Colorado School of Mines, USA; Department of Computer Science, Colorado School of Mines, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636434/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16303600201226336836&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Colorado School of Mines",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.mines.edu",
        "aff_unique_abbr": "CSM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636569",
        "title": "An Interleaved Approach to Trait-Based Task Allocation and Scheduling",
        "track": "main",
        "status": "Poster",
        "abstract": "To realize effective heterogeneous multi-robot teams, researchers must leverage individual robots\u2019 relative strengths and coordinate their individual behaviors. Specifically, heterogeneous multi-robot systems must answer three important questions: who (task allocation), when (scheduling), and how (motion planning). While specific variants of each of these problems are known to be NP-Hard, their interdependence only exacerbates the challenges involved in solving them together. In this paper, we present a novel framework that interleaves task allocation, scheduling, and motion planning. We introduce a search-based approach for trait-based time-extended task allocation named Incremental Task Allocation Graph Search (ITAGS). In contrast to approaches that solve the three problems in sequence, ITAGS\u2019s interleaved approach enables efficient search for allocations while simultaneously satisfying scheduling constraints and accounting for the time taken to execute motion plans. To enable effective interleaving, we develop a convex combination of two search heuristics that optimizes the satisfaction of task requirements as well as the makespan of the associated schedule. We demonstrate the efficacy of ITAGS using detailed ablation studies and comparisons against two state-of-the-art algorithms in a simulated emergency response domain.",
        "primary_area": "",
        "author": "Glen Neville;Andrew Messing;Harish Ravichandar;Seth Hutchinson;Sonia Chernova;Glen Neville;Andrew Messing;Harish Ravichandar;Seth Hutchinson;Sonia Chernova",
        "authorids": "/37087236646;/37089196646;/37085429366;/37282386200;/37283184200;/37087236646;/37089196646;/37085429366;/37282386200;/37283184200",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636569/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13536670163607837796&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636198",
        "title": "An Open-Source, Fiducial-Based, Underwater Stereo Visual-Inertial Localization Method with Refraction Correction",
        "track": "main",
        "status": "Poster",
        "abstract": "Underwater visual localization is an essential technique for the autonomous operation of underwater robots. However, the unique underwater image characteristics, including refraction, sparse features, and severe noise, pose an enormous challenge to it. For addressing these issues, this paper proposes an open-source fiducial-based underwater stereo visual-inertial localization method under the extended Kalman filter (EKF) framework, which is called FBUS-EKF. First, the refraction is corrected by the refractive camera model and akin triangulation. Second, the fiducial marker and a novel marker pose estimation method are applied to alleviate the adverse effect of sparse features. Third, the EKF is utilized to fuse the inertial and visual information so as to reject the serious noise. Finally, extensive experiments on a test bench demonstrate the effectiveness of the FBUS-EKF method, where the typical localization error is less than 3%, namely, the average error is lower than 3 cm within one meter. The obtained results reveal that the FBUS-EKF method has the prospect to be applied in the precise short-range operation and the localization for underwater robots, which offers a valuable insight for further autonomous underwater task.",
        "primary_area": "",
        "author": "Pengfei Zhang;Zhengxing Wu;Jian Wang;Shihan Kong;Min Tan;Junzhi Yu;Pengfei Zhang;Zhengxing Wu;Jian Wang;Shihan Kong;Min Tan;Junzhi Yu",
        "authorids": "/37088373104;/38580572600;/37086447299;/37086419106;/37274596200;/37278401500;/37088373104;/38580572600;/37086447299;/37086419106;/37274596200;/37278401500",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; University of Chinese Academy of Sciences, Beijing, China; Department of Advanced Manufacturing and Robotics, BIC-ESAT, College of Engineering, State Key Laboratory for Turbulence and Complex Systems, Peking University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636198/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13518884250822884365&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Peking University",
        "aff_unique_dep": ";Department of Advanced Manufacturing and Robotics",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.pku.edu.cn",
        "aff_unique_abbr": "UCAS;Peking U",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636665",
        "title": "An Optical Spatial Localization System for Tracking Unmanned Aerial Vehicles Using a Single Dynamic Vision Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper reports a novel optical localization method, including both the hardware design and algorithm design, to track mobile Unmanned Aerial Vehicles (UAVs). The method relies on a circle-shaped blinking LED marker installed on the UAV and uses a single Dynamic Vision Sensing (DVS) camera to sense the temporal difference of the video streams. A temporal-filtering algorithm processes the video stream and detects the target marker by filtering out the background image. The triangulation-based spatial localization algorithm captures the trace of the target with the help of the prior knowledge of the physical size of the marker. The proposed system was evaluated in flight tests and compared with ground truth data provided by a motion capture system. The proposed system provides a simple and accurate localization solution for UAV tracking with a low computing overhead.",
        "primary_area": "",
        "author": "Hunter Stuckey;Amer Al-Radaideh;Leonardo Escamilla;Liang Sun;Luis Garcia Carrillo;Wei Tang;Hunter Stuckey;Amer Al-Radaideh;Leonardo Escamilla;Liang Sun;Luis Garcia Carrillo;Wei Tang",
        "authorids": "/37089196946;/38362834400;/37089196379;/37085365146;/37089195109;/37085633088;/37089196946;/38362834400;/37089196379;/37085365146;/37089195109;/37085633088",
        "aff": "Hunter Stuckey; Amer Al-Radaideh; Leonardo Escamilla; Liang Sun; Luis Garcia Carrillo; Wei Tang",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636665/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9997424586681079408&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0",
        "aff_unique_norm": "Hunter Stuckey;",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9635872",
        "title": "An Under-Actuated Whippletree Mechanism Gripper based on Multi-Objective Design Optimization with Auto-Tuned Weights",
        "track": "main",
        "status": "Poster",
        "abstract": "Current rigid linkage grippers are limited in flexibility, and gripper design optimality relies on expertise, experiments, or arbitrary parameters. Our proposed rigid gripper can accommodate irregular and off-center objects through a whippletree mechanism, improving adaptability. We present a whippletree-based rigid under-actuated gripper and its parametric design multi-objective optimization for a one-wall climbing task. Our proposed objective function considers kinematics and grasping forces simultaneously with a mathematical metric based on a model of an object environment. Our multi-objective problem is formulated as a single kinematic objective function with auto-tuning force-based weight. Our results indicate that our proposed objective function determines optimal parameters and kinematic ranges for our under-actuated gripper in the task environment with sufficient grasping forces.",
        "primary_area": "",
        "author": "Yusuke Tanaka;Yuki Shirai;Zachary Lacey;Xuan Lin;Jane Liu;Dennis Hong;Yusuke Tanaka;Yuki Shirai;Zachary Lacey;Xuan Lin;Jane Liu;Dennis Hong",
        "authorids": "/37088439498;/37086344073;/37089195490;/37085891795;/37089197798;/37575333900;/37088439498;/37086344073;/37089195490;/37085891795;/37089197798;/37575333900",
        "aff": "Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635872/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18265648677231083408&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636495",
        "title": "An augmented MDP approach for solving Stochastic Security Games",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel theoretical approach for solving a Stochastic Security Game using augmented Markov Decison Processes and an experimental evaluation. Most of the previous works mentioned in the literature focus on Linear Programming techniques seeking Strong Stackelberg Equilibria through the defender and attacker\u2019s strategy spaces. Although effective, these techniques are computationally expensive and tend to not scale well to very large problems. By fixing the set of the possible defense strategies, our approach is able to use the well-known augmented MDP formalism to compute an optimal policy for an attacker facing a defender patrolling. Experimental results on fully observable cases validate our approach and show good performances in comparison with optimistic and pessimistic approaches. However, these results also highlight the need of scalability improvements and of handling the partial observability cases.",
        "primary_area": "",
        "author": "Romain Ch\u00e2tel;Abdel-Illah Mouaddib;Romain Ch\u00e2tel;Abdel-Illah Mouaddib",
        "authorids": "/37089194972;/37282448000;/37089194972;/37282448000",
        "aff": "Research Group in Computer Science, Image and Instrumentation of Caen (GREYC), University of Caen Normandy, Caen Cedex 5, France; Research Group in Computer Science, Image and Instrumentation of Caen (GREYC), University of Caen Normandy, Caen Cedex 5, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636495/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9222183165323689022&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Caen Normandy",
        "aff_unique_dep": "Research Group in Computer Science, Image and Instrumentation of Caen (GREYC)",
        "aff_unique_url": "https://www.unicaen.fr",
        "aff_unique_abbr": "unicaen",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Caen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636852",
        "title": "Analysis of User Preferences for Robot Motions in Immersive Telepresence",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers how the motions of a telepresence robot moving autonomously affect a person immersed in the robot through a head-mounted display. In particular, we explore the preference, comfort, and naturalness of elements of piecewise linear paths compared to the same elements on a smooth path. In a user study, thirty-six subjects watched panoramic videos of three different paths through a simulated museum in virtual reality and responded to questionnaires regarding each path. Preference for a particular path was influenced the most by comfort, forward speed, and characteristics of the turns. Preference was also strongly associated with the users\u2019 perceived naturalness, which was primarily determined by the ability to see salient objects, the distance to the walls and objects, as well as the turns. Participants favored the paths that had a one meter per second forward speed and rated the path with the least amount of turns as the most comfortable.",
        "primary_area": "",
        "author": "Katherine J. Mimnaugh;Markku Suomalainen;Israel Becerra;Eliezer Lozano;Rafael Murrieta-Cid;Steven M. LaValle;Katherine J. Mimnaugh;Markku Suomalainen;Israel Becerra;Eliezer Lozano;Rafael Murrieta-Cid;Steven M. LaValle",
        "authorids": "/37088399028;/37086198609;/38277933900;/37088469833;/38323692300;/37280522300;/37088399028;/37086198609;/38277933900;/37088469833;/38323692300;/37280522300",
        "aff": "Center of Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Finland; Center of Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Finland; Centro de Investigaci\u00f3n en Matem\u00e1ticas (CIMAT), Guanajuato, Mexico; Centro de Investigaci\u00f3n en Matem\u00e1ticas (CIMAT), Guanajuato, Mexico; Centro de Investigaci\u00f3n en Matem\u00e1ticas (CIMAT), Guanajuato, Mexico; Center of Ubiquitous Computing, Faculty of Information Technology and Electrical Engineering, University of Oulu, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636852/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17740578879905156473&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;0",
        "aff_unique_norm": "University of Oulu;Centro de Investigaci\u00f3n en Matem\u00e1ticas",
        "aff_unique_dep": "Center of Ubiquitous Computing;",
        "aff_unique_url": "https://www.oulu.fi;",
        "aff_unique_abbr": ";CIMAT",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Guanajuato",
        "aff_country_unique_index": "0;0;1;1;1;0",
        "aff_country_unique": "Finland;Mexico"
    },
    {
        "id": "9636853",
        "title": "Analysis of the Effect of Clearance in Spherical Joints on the Rotation Accuracy of Parallel Type Micro-Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "The spherical joint is an effective solution to design parallel micro-robotic systems with rotation capabilities in the three-dimensional space. This type of joint has however some non-linear characteristics, such as the clearance, which affect the positioning accuracy in micro-robotic tasks. The starting point of this study lies in experimental observations of rotation errors from a 3-PPPS 6-DOF parallel micro-robotic systems operating inside a scanning electron microscope. The objective of the paper is to assess the role of the spherical joints in the rotation errors and to evaluate whether the joints non-linearities can cause errors with the same order of magnitude as those observed experimentally. To this end, the first part of the study addresses the modeling of 3-PPPS 6-DOF parallel micro-robotic systems with spherical joints including the clearance. This model allows for analysing the effect of the clearance on position and rotation accuracies of the micro-robotic system. It is found by simulations that the same positioning behavior as in the experiments occurs when the clearance of the spherical joint is included in the model, supporting the hypothesis. Therefore, it is concluded that clearance in spherical joints has a significant effect on the precision of parallel type micro-robotic systems which opens new challenges in the control of poly-articulated micro-robotic systems with clearance compensation.",
        "primary_area": "",
        "author": "Michael Pumphrey;Mahmoud Al-Tamimi;Aylar Abouzarkhanifard;Mohammad Al Janaideh;St\u00e9phane R\u00e9gnier;Mokrane Boudaoud;Michael Pumphrey;Mahmoud Al-Tamimi;Aylar Abouzarkhanifard;Mohammad Al Janaideh;St\u00e9phane R\u00e9gnier;Mokrane Boudaoud",
        "authorids": "/37088921134;/37088920300;/37088945861;/37657960900;/37283234800;/37594372000;/37088921134;/37088920300;/37088945861;/37657960900;/37283234800;/37594372000",
        "aff": "Department of Mechanical Engineering, Memorial University, St. John\u2019s, Canada; Department of Mechanical Engineering, Memorial University, St. John\u2019s, Canada; Department of Mechanical Engineering, Memorial University, St. John\u2019s, Canada; Department of Mechanical Engineering, Memorial University, St. John\u2019s, Canada; Institut des Syst\u00e8mes Intelligents et de Robotique, Sorbonne Universit\u00e9, Paris, France; Institut des Syst\u00e8mes Intelligents et de Robotique, Sorbonne Universit\u00e9, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636853/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10168942548999408443&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;1",
        "aff_unique_norm": "Memorial University;Sorbonne Universit\u00e9",
        "aff_unique_dep": "Department of Mechanical Engineering;Institut des Syst\u00e8mes Intelligents et de Robotique",
        "aff_unique_url": "https://www.mun.ca;https://www.sorbonne-universite.fr",
        "aff_unique_abbr": ";Sorbonne",
        "aff_campus_unique_index": "0;0;0;0;1;1",
        "aff_campus_unique": "St. John\u2019s;Paris",
        "aff_country_unique_index": "0;0;0;0;1;1",
        "aff_country_unique": "Canada;France"
    },
    {
        "id": "9635996",
        "title": "Analytical Modeling of a Soft Pneu-net Actuator Based on Finite Strain Beam Theory",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a simple analytical model for pneu-net soft actuator. The model is based on Euler\u2013 Bernoulli finite strain hyperelastic thin cantilever beam theory. The deformation of the air chambers is modelled using infinitesimal strain membrane theory. The proposed theoretical model estimates the deformation and force characteristics of the actuator. The developed model accounts the axial stretch and forces applied to the actuator. The theoretical deformation and force characteristics of different actuators are compared with finite element (FE) model and experimental characteristics. The theoretically estimated deformation and force of the actuator are similar to the FE model, but the theoretical model computation time is less than 1% of the FE model.",
        "primary_area": "",
        "author": "Sachin Sachin;Zhongkui Wang;Shinichi Hirai;Sachin Sachin;Zhongkui Wang;Shinichi Hirai",
        "authorids": "/37089475297;/37404934700;/37280572900;/37089475297;/37404934700;/37280572900",
        "aff": "Department of Robotics, Soft Robotics Laboratory, Ritsumeikan University, Kusatsu, Japan; Research Organization of Science and Technology, Ritsumeikan University, Kusatsu, Japan; Department of Robotics, Soft Robotics Laboratory, Ritsumeikan University, Kusatsu, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635996/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1165573127894897445&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kusatsu",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636560",
        "title": "Analytical Tip Force Estimation on Tendon-driven Catheters Through Inverse Solution of Cosserat Rod Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Tip force estimation on continuum arms is of crucial clinical importance for catheter-based procedures, i.e., catheter-based ablation therapies. In this study, an analytical solution for force estimation based on inverse Cosserat rod modeling was proposed and validated. Initially, a previously validated Bezier-based shape interpolation was used to parameterize the deformation and the kinematics and balance equations of the catheter were derived thereof. The tip force estimation problem was formulated as an inverse problem with a functional minimization technique and was solved analytically. In the end, the proposed method was experimentally tested for accuracy and computation efficiency through a series of simulations and experiments. The results showed that the estimated forces were in agreement with reference measurement with a mean-absolute error of 0.024 \u00b1 0.020 N and a computation time of 7 \u00b1 5 ms per frame. The exhibited performance was comparable to other studies and was in compliance with the requirements of catheter-based procedures.",
        "primary_area": "",
        "author": "Amir Hooshiar;Amir Sayadi;Mohammad Jolaei;Javad Dargahi;Amir Hooshiar;Amir Sayadi;Mohammad Jolaei;Javad Dargahi",
        "authorids": "/37086081709;/37088478688;/37086938451;/37394714000;/37086081709;/37088478688;/37086938451;/37394714000",
        "aff": "Dept. of Surgery, Surgical Robotics Centre (SRC), McGill University; Mechanical Engineering Dept., Robotic Surgery Lab., Concordia University, Montreal, Canada; Mechanical Engineering Dept., Robotic Surgery Lab., Concordia University, Montreal, Canada; Mechanical Engineering Dept., Robotic Surgery Lab., Concordia University, Montreal, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636560/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3027103926062635785&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "McGill University;Concordia University",
        "aff_unique_dep": "Dept. of Surgery;Mechanical Engineering Dept.",
        "aff_unique_url": "https://www.mcgill.ca;https://www.concordia.ca",
        "aff_unique_abbr": "McGill;Concordia",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Montreal",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636438",
        "title": "Angular Super-Resolution Radar SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Radar SLAM has attracted wide attention due to its all-day and all-weather working characteristics in the last decade. The existing radar SLAM systems mainly adopt mechanically pivoting radar with simple principle and high resolution, but this kind of radar has disadvantages such as low frame rate, distortion of the radar image, and high cost. Although array snapshot radar has the advantages of high frame rate and low cost, its low azimuth resolution, multipath reflection, and angular glint limit its application in SLAM. This paper proposes a SLAM system developed on array snapshot radar. The system realizes angular super-resolution radar imaging through compressed sensing, which effectively solves the problems of poor azimuth resolution and multipath reflection of array snapshot radar. We also propose the corresponding point cloud extraction method and scan matching method, this method performs a centroid iterative closest point algorithm between the submaps, thereby effectively improving the interference of noise and angular glint. Experimental results show that our proposed array snapshot radar SLAM system can reduce the mean absolute trajectory error by more than 3 times compared with the existing system, and can show accuracy and robustness in various environments.",
        "primary_area": "",
        "author": "Zhiyuan Zeng;Xiangwei Dang;Yanlei Li;Xiangxi Bu;Xingdong Liang;Zhiyuan Zeng;Xiangwei Dang;Yanlei Li;Xiangxi Bu;Xingdong Liang",
        "authorids": "/37088990727;/37088222626;/37086579083;/37086371895;/37559499300;/37088990727;/37088222626;/37086579083;/37086371895;/37559499300",
        "aff": "National Key Laboratory of Microwave Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; National Key Laboratory of Microwave Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; National Key Laboratory of Microwave Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; National Key Laboratory of Microwave Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China; National Key Laboratory of Microwave Imaging Technology, Aerospace Information Research Institute, Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636438/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13665876580009191804&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Chinese Academy of Sciences",
        "aff_unique_dep": "National Key Laboratory of Microwave Imaging Technology",
        "aff_unique_url": "http://www.cas.cn",
        "aff_unique_abbr": "CAS",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635838",
        "title": "Animal Gaits on Quadrupedal Robots Using Motion Matching and Model-Based Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we explore the challenge of generating animal-like walking motions for legged robots. To this end, we propose a versatile and robust control pipeline that combines a state-of-the-art model-based controller with a data-driven technique that is commonly used in computer animation. We demonstrate the efficacy of our control framework on a variety of quadrupedal robots in simulation. We show, in particular, that our approach can automatically reproduce key characteristics of animal motions, including speed-specific gaits, unscripted footfall patterns for nonperiodic motions, and natural small variations in overall body movements.",
        "primary_area": "",
        "author": "Dongho Kang;Simon Zimmermann;Stelian Coros;Dongho Kang;Simon Zimmermann;Stelian Coros",
        "authorids": "/37089194550;/37088231270;/37077396200;/37089194550;/37088231270;/37077396200",
        "aff": "Computational Robotics Lab in the Institute for Intelligent Interactive Systems (IIIS), ETH Zurich, Switzerland; Computational Robotics Lab in the Institute for Intelligent Interactive Systems (IIIS), ETH Zurich, Switzerland; Computational Robotics Lab in the Institute for Intelligent Interactive Systems (IIIS), ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635838/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4108392772500105725&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Institute for Intelligent Interactive Systems",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636355",
        "title": "Annotation Cost Reduction of Stream-based Active Learning by Automated Weak Labeling using a Robot Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "Stream-based active learning (AL) is an efficient training data collection method, and it is used to reduce human annotation cost required in machine learning. However, it is difficult to say that the human cost is low enough because most previous studies have assumed that an oracle is a human with domain knowledge. In this study, we propose a method to replace a part of the oracle\u2019s work in stream-based AL by self-training with weak labeling using a robot arm. A camera attached to a robot arm takes a series of image data related to a streamed object, which should have the same label. We use this information as a weak label to connect a pseudo-label (estimated class label) and a target instance. Our method selects two data from a series of image data; high confidence data for correcting pseudo-labels and low confidence data for improving the performance of the classifier. We paired a pseudo-label provided to high confidence data with a target instance (low confidence data). By using this technique, we mitigate the inefficiency in self-training, that is, difficulty in creating pseudo-labeled training data with a high impact on the target classifier. In the experiments, we employed the proposed method in the classification task of objects on a belt conveyor. We evaluated the performance against human cost on multiple scenarios considering the temporal variation of data. The proposed method achieves the same or better performance as the conventional methods while reducing human cost.",
        "primary_area": "",
        "author": "Kanata Suzuki;Taro Sunagawa;Tomotake Sasaki;Takashi Katoh;Kanata Suzuki;Taro Sunagawa;Tomotake Sasaki;Takashi Katoh",
        "authorids": "/37086050797;/37089197498;/37061214000;/37089195124;/37086050797;/37089197498;/37061214000;/37089195124",
        "aff": "Artificial Intelligence Laboratories, Fujitsu Laboratories LTD., Kanagawa, Japan; Artificial Intelligence Laboratories, Fujitsu Laboratories LTD., Kanagawa, Japan; Artificial Intelligence Laboratories, Fujitsu Laboratories LTD., Kanagawa, Japan; Artificial Intelligence Laboratories, Fujitsu Laboratories LTD., Kanagawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636355/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5209844249670159692&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Fujitsu Laboratories Ltd.",
        "aff_unique_dep": "Artificial Intelligence Laboratories",
        "aff_unique_url": "https://www.fujitsu.com/global/labs/",
        "aff_unique_abbr": "Fujitsu Labs",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Kanagawa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636124",
        "title": "AquaVis: A Perception-Aware Autonomous Navigation Framework for Underwater Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual monitoring operations underwater require both observing the objects of interest in close-proximity, and tracking the few feature-rich areas necessary for state estimation. This paper introduces the first navigation framework, called AquaVis, that produces on-line visibility-aware motion plans that enable Autonomous Underwater Vehicles (AUVs) to track multiple visual objectives with an arbitrary camera configuration in real-time. Using the proposed pipeline, AUVs can efficiently move in 3D, reach their goals while avoiding obstacles safely, and maximizing the visibility of multiple objectives along the path within a specified proximity. The method is sufficiently fast to be executed in real-time and is suitable for single or multiple camera configurations. Experimental results show the significant improvement on tracking multiple automatically-extracted points of interest, with low computational overhead and fast re-planning times.Accompanying short video: https://youtu.be/JKO bbrIZyU",
        "primary_area": "",
        "author": "Marios Xanthidis;Michail Kalaitzakis;Nare Karapetyan;James Johnson;Nikolaos Vitzilaios;Jason M. O\u2019Kane;Ioannis Rekleitis;Marios Xanthidis;Michail Kalaitzakis;Nare Karapetyan;James Johnson;Nikolaos Vitzilaios;Jason M. O\u2019Kane;Ioannis Rekleitis",
        "authorids": "/37085810183;/37086942753;/37086299803;/37087321754;/37571943800;/37279835400;/37281356300;/37085810183;/37086942753;/37086299803;/37087321754;/37571943800;/37279835400;/37281356300",
        "aff": "Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA; Department of Mechanical Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA; Department of Mechanical Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636124/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11525921358811819550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of South Carolina",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.sc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Columbia",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636379",
        "title": "Area Defense and Surveillance on Rectangular Regions Using Control Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "A formulation of the area defense and surveillance problem for one intruder and one defense and surveillance robot and its corresponding solution using control barrier functions is presented. The defense robot must follow the intruder as it moves through a rectangular region in the plane, ensuring that the position of the intruder is also within a rectangular region attached to the surveillance robot. The proposed reactive and closed-form control laws depend on the positions of the robots, their maximum speeds, and the size of the rectangular regions. We show the application and effectiveness of our results in experiments with real robots.",
        "primary_area": "",
        "author": "Luis Guerrero-Bonilla;Magnus Egerstedt;Dimos V. Dimarogonas;Luis Guerrero-Bonilla;Magnus Egerstedt;Dimos V. Dimarogonas",
        "authorids": "/37085815538;/37269707500;/37282084700;/37085815538;/37269707500;/37282084700",
        "aff": "School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Samueli School of Engineering, University of California, Irvine, CA, USA; Division of Decision and Control Systems, School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636379/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11657426063390124778&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Georgia Institute of Technology;University of California, Irvine;KTH Royal Institute of Technology",
        "aff_unique_dep": "School of Electrical and Computer Engineering;Samueli School of Engineering;Division of Decision and Control Systems",
        "aff_unique_url": "https://www.gatech.edu;https://www.uci.edu;https://www.kth.se",
        "aff_unique_abbr": "Georgia Tech;UCI;KTH",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Atlanta;Irvine;Stockholm",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;Sweden"
    },
    {
        "id": "9636226",
        "title": "Arena-Rosnav: Towards Deployment of Deep-Reinforcement-Learning-Based Obstacle Avoidance into Conventional Autonomous Navigation Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, mobile robots have become important tools in various industries, especially in logistics. Deep reinforcement learning emerged as an alternative planning method to replace overly conservative approaches and promises more efficient and flexible navigation. However, deep reinforcement learning approaches are not suitable for long-range navigation due to their proneness to local minima and lack of long term memory, which hinders its widespread integration into industrial applications of mobile robotics. In this paper, we propose a navigation system incorporating deep-reinforcement-learning- based local planners into conventional navigation stacks for long-range navigation. Therefore, a framework for training and testing the deep reinforcement learning algorithms along with classic approaches is presented. We evaluated our deep-reinforcement-learning-enhanced navigation system against various conventional planners and found that our system outperforms them in terms of safety, efficiency and robustness.",
        "primary_area": "",
        "author": "Linh K\u00e4stner;Teham Buiyan;Lei Jiao;Tuan Anh Le;Xinlin Zhao;Zhengcheng Shen;Jens Lambrecht;Linh K\u00e4stner;Teham Buiyan;Lei Jiao;Tuan Anh Le;Xinlin Zhao;Zhengcheng Shen;Jens Lambrecht",
        "authorids": "/37087466037;/37089197716;/37089197847;/37089197501;/37089197226;/37088811455;/37342634600;/37087466037;/37089197716;/37089197847;/37089197501;/37089197226;/37088811455;/37342634600",
        "aff": "Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636226/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13972092381440066571&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Berlin Institute of Technology",
        "aff_unique_dep": "Faculty of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636375",
        "title": "Asking the Right Questions: Facilitating Semantic Constraint Specification for Robot Skill Learning and Repair",
        "track": "main",
        "status": "Poster",
        "abstract": "Developments in human-robot teaming have given rise to significant interest in training methods that enable collaborative agents to safely and successfully execute tasks alongside human teammates. While effective, many existing methods are brittle to changes in the environment and do not account for the preferences of human collaborators. This ineffectiveness is typically due to the complexity of deployment environments and the unique personal preferences of human teammates. These complications lead to behavior that can cause task failure or user discomfort. In this work, we introduce Plan Augmentation and Repair through SEmantic Constraints (PARSEC): a novel algorithm that utilizes a semantic hierarchy to enable novice users to quickly and effectively select constraints using natural language that correct faulty behavior or adapt skills to their preferences. We show through a case study that our algorithm efficiently finds corrective constraints that match the user\u2019s intent, providing a path for novice users to exploit the advantages of constrained motion planning combined with human-in-the-loop skill training.",
        "primary_area": "",
        "author": "Aaquib Tabrez;Jack Kawell;Bradley Hayes;Aaquib Tabrez;Jack Kawell;Bradley Hayes",
        "authorids": "/37086802109;/37089198008;/38573944100;/37086802109;/37089198008;/38573944100",
        "aff": "Department of Computer Science, The University of Colorado Boulder; Department of Computer Science, The University of Colorado Boulder; Department of Computer Science, The University of Colorado Boulder",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636375/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17250771204418374260&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636715",
        "title": "Assembly Action Understanding from Fine-Grained Hand Motions, a Multi-camera and Deep Learning Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "This article presents a novel software architecture enabling the analysis of assembly actions from fine-grained hand motions. Unlike previous works that compel humans to wear ad-hoc devices or visual markers in the human body, our approach enables users to move without additional burdens. Modules developed are able to: (i) reconstruct the 3D motions of body and hands keypoints using multi-camera systems; (ii) recognize objects manipulated by humans, and (iii) analyze the relationship between the human motions and the manipulated objects. We implement different solutions based on OpenPose and Mediapipe for body and hand keypoint detection. Additionally, we discuss the suitability of these solutions for enabling real-time data processing. We also propose a novel method using Long Short-Term Memory (LSTM) deep neural networks to analyze the relationship between the detected human motions and manipulated objects. Experimental validations show the superiority of the proposed approach against previous works based on Hidden Markov Models (HMMs).",
        "primary_area": "",
        "author": "Enrique Coronado;Kosuke Fukuda;Ixchel G. Ramirez-Alpizar;Natsuki Yamanobe;Gentiane Venture;Kensuke Harada;Enrique Coronado;Kosuke Fukuda;Ixchel G. Ramirez-Alpizar;Natsuki Yamanobe;Gentiane Venture;Kensuke Harada",
        "authorids": "/37085691355;/37086823788;/38272901900;/37281644100;/37546539800;/37277067400;/37085691355;/37086823788;/38272901900;/37281644100;/37546539800;/37277067400",
        "aff": "Department of Mechanical Systems Engineering, Tokyo University of Agriculture and Technology, Koganei, Tokyo, Japan; Department of Systems Innovation, Graduate School of Science and Engineering, Osaka University, Toyonaka, Japan; Automation Research Team, Industrial CPS Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Koto-ku, Tokyo, Japan; Automation Research Team, Industrial CPS Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Koto-ku, Tokyo, Japan; Department of Mechanical Systems Engineering, Tokyo University of Agriculture and Technology, Koganei, Tokyo, Japan; Automation Research Team, Industrial CPS Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Koto-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636715/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15092740603745534121&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;0;2",
        "aff_unique_norm": "Tokyo University of Agriculture and Technology;Osaka University;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Department of Mechanical Systems Engineering;Department of Systems Innovation;Automation Research Team, Industrial CPS Research Center",
        "aff_unique_url": "https://www.tuat.ac.jp;https://www.osaka-u.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "TUAT;OSU;AIST",
        "aff_campus_unique_index": "0;1;2;2;0;2",
        "aff_campus_unique": "Koganei, Tokyo;Toyonaka;Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636041",
        "title": "Assembly Planning by Recognizing a Graphical Instruction Manual",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a robot assembly planning method by automatically reading the graphical instruction manuals designed for humans. Essentially, the method generates an Assembly Task Sequence Graph (ATSG) by recognizing a graphical instruction manual. An ATSG is a graph describing the assembly task procedure by detecting types of parts included in the instruction images, completing the missing information automatically, and correcting the detection errors automatically. To build an ATSG, the proposed method first extracts the information of the parts contained in each image of the graphical instruction manual. Then, by using the extracted part information, it estimates the proper work motions and tools for the assembly task. After that, the method builds an ATSG by considering the relationship between the previous and following images, which makes it possible to estimate the undetected parts caused by occlusion using the information of the entire image series. Finally, by collating the total number of each part with the generated ATSG, the excess or deficiency of parts are investigated, and task procedures are removed or added according to those parts. In the experiment section, we build an ATSG using the proposed method to a graphical instruction manual for a chair and demonstrate the action sequences found in the ATSG can be performed by a dual-arm robot execution. The results show the proposed method is effective and simplifies robot teaching in automatic assembly.",
        "primary_area": "",
        "author": "Issei Sera;Natsuki Yamanobe;Ixchel G. Ramirez-Alpizar;Zhenting Wang;Weiwei Wan;Kensuke Harada;Issei Sera;Natsuki Yamanobe;Ixchel G. Ramirez-Alpizar;Zhenting Wang;Weiwei Wan;Kensuke Harada",
        "authorids": "/37089196661;/37281644100;/38272901900;/37088342463;/37085689483;/37277067400;/37089196661;/37281644100;/38272901900;/37088342463;/37085689483;/37277067400",
        "aff": "Graduate School of Engineering Science, Osaka University, Toyonaka, Japan; Automation Research Team, Industrial CPS Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; Automation Research Team, Industrial CPS Research Center, National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636041/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18100570166177156202&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;0;0",
        "aff_unique_norm": "Osaka University;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Graduate School of Engineering Science;Automation Research Team, Industrial CPS Research Center",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "Osaka U;AIST",
        "aff_campus_unique_index": "0;1;1;0;0;0",
        "aff_campus_unique": "Toyonaka;Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636531",
        "title": "Assembly Sequence Generation for New Objects via Experience Learned from Similar Object",
        "track": "main",
        "status": "Poster",
        "abstract": "Assembly orders of components have direct influence on feasibility and efficiency of assembly process in manufacturing and are usually defined by experienced operators. To automate the assembly sequence generation process, we present a method using the idea of case-based reasoning, which can take advantage of experience of a reference assembly to generate the assembly sequence of a new assembly. First, a novel assembly representation method named assembly graph is present in which nodes indicating components\u2019 3D shape information and edges indicating the geometry constraints. Second, a similar components retrieve process is conducted based on assembly graph representation. Then, the assembly sequence is generated by applying the assembly order of retrieved components to the new ones. Next, the generated sequence is revised to satisfy the inherent constraints in the new assembly which is formulated as a contact graph. Finally, the revised sequence is stored into a case library with corresponding assembly model. We apply the proposed method to generate assembly sequences for chair assemblies and experimental results show its effectiveness and flexibility.",
        "primary_area": "",
        "author": "Zhongxiang Zhou;Rong Xiong;Zexi Chen;Yue Wang;Zhongxiang Zhou;Rong Xiong;Zexi Chen;Yue Wang",
        "authorids": "/37088809302;/37271511300;/37088601253;/37072299700;/37088809302;/37271511300;/37088601253;/37072299700",
        "aff": "State Key Laboratory of Industrial Control Technology, and Institute of Cyber-Systems and Control of Zhejiang Province, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control Technology, and Institute of Cyber-Systems and Control of Zhejiang Province, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control Technology, and Institute of Cyber-Systems and Control of Zhejiang Province, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control Technology, and Institute of Cyber-Systems and Control of Zhejiang Province, Zhejiang University, Hangzhou, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636531/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3647118296128067178&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636021",
        "title": "Assessing Grasp Quality using Local Sensitivity Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new approach to investigate and quantify dynamic grasp performance. Oftentimes, existing approaches to grasp analysis assess a grasp\u2019s quality in a static situation. We build upon such considerations to also account for the dynamic nature of most grasp operations. In particular, these typically do not, in practice, occur in a static setting. Robotic grasping is indeed commonly involved in, for instance, pick-and-place operations which involve movement and thus a dynamic aspect. We investigate grasp quality over such movements, affording consideration not only to the gripper\u2019s and grasp configuration, but also to their trajectory. More specifically, we explore the relationship from the gripper\u2019s base acceleration to the stability of the grasped object (assessed using the relative acceleration of the object with respect to that of the gripper), using linear approximations of the corresponding dynamics. From such relations, we construct a grasp\u2019s robustness metric, which accounts for the movements involved in the considered scenario. Numerical simulations are used to compare achieved results with those obtained using alternate existing methods. We illustrate merit of the proposed metric by exploring robustness of a given grasp under different trajectories.",
        "primary_area": "",
        "author": "Michael Zechmair;Yannick Morel;Michael Zechmair;Yannick Morel",
        "authorids": "/37089197330;/37547701400;/37089197330;/37547701400",
        "aff": "Faculty of Psychology and Neuroscience, Maastricht, Netherlands; Faculty of Psychology and Neuroscience, Maastricht, Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636021/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18074739914445217471&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Maastricht University",
        "aff_unique_dep": "Faculty of Psychology and Neuroscience",
        "aff_unique_url": "https://www.maastrichtuniversity.nl",
        "aff_unique_abbr": "MU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Maastricht",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9636336",
        "title": "Attainment Regions in Feature-Parameter Space for High-Level Debugging in Autonomous Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding a controller\u2019s performance in different scenarios is crucial for robots that are going to be deployed in safety-critical tasks. If we do not have a model of the dynamics of the world, which is often the case in complex domains, we may need to approximate a performance function of the robot based on its interaction with the environment. Such a performance function gives us insights into the behaviour of the robot, allowing us to fine-tune the controller with manual interventions. In high-dimensionality systems, where the action-state space is large, fine-tuning a controller is non-trivial. To overcome this problem, we propose a performance function whose domain is defined by external features and parameters of the controller. Attainment regions are defined over such a domain defined by feature-parameter pairs, and serve the purpose of enabling prediction of successful execution of the task. The use of the feature-parameter space \u2013in contrast to the action-state space\u2013 allows us to adapt, explain and fine-tune the controller over a simpler (i.e., lower dimensional) space. When the robot successfully executes the task, we use the attainment regions to gain insights into the limits of the controller, and its robustness. When the robot fails to execute the task, we use the regions to debug the controller and find adaptive and counterfactual changes to the solutions. Another advantage of this approach is that we can generalise through the use of Gaussian processes regression of the performance function in the high-dimensional space. To test our approach, we demonstrate learning an approximation to the performance function in simulation, with a mobile robot traversing different terrain conditions. Then, with a sample-efficient method, we propagate the attainment regions to a physical robot in a similar environment.",
        "primary_area": "",
        "author": "Sim\u00f3n C. Smith;Subramanian Ramamoorthy;Sim\u00f3n C. Smith;Subramanian Ramamoorthy",
        "authorids": "/37086590301;/37529920500;/37086590301;/37529920500",
        "aff": "Adaptive & Intelligent Robotics Lab, Imperial College London; Institute of Perception, Action and Behaviour, School of Informatics, The University of Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636336/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14896172009947705746&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Imperial College London;University of Edinburgh",
        "aff_unique_dep": "Adaptive & Intelligent Robotics Lab;School of Informatics",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.ed.ac.uk",
        "aff_unique_abbr": "ICL;Edinburgh",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "London;Edinburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636386",
        "title": "Attention Augmented ConvLSTM for Environment Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Safe and proactive planning in robotic systems generally requires accurate predictions of the environment. Prior work on environment prediction applied video frame prediction techniques to bird\u2019s-eye view environment representations, such as occupancy grids. ConvLSTM-based frameworks used previously often result in significant blurring of the predictions, loss of static environment structure, and vanishing of moving objects, thus hindering their applicability for use in safety-critical applications. In this work, we propose two extensions to the ConvLSTM architecture to address these issues. We present the Temporal Attention Augmented ConvLSTM (TAAConvLSTM) and Self-Attention Augmented ConvLSTM (SAAConvLSTM) frameworks for spatiotemporal occupancy grid prediction, and demonstrate improved performance over baseline architectures on the real-world KITTI and Waymo datasets. We provide our implementation at https: //github.com/sisl/AttentionAugmentedConvLSTM.",
        "primary_area": "",
        "author": "Bernard Lange;Masha Itkina;Mykel J. Kochenderfer;Bernard Lange;Masha Itkina;Mykel J. Kochenderfer",
        "authorids": "/37088860729;/37087102957;/37596929200;/37088860729;/37087102957;/37596929200",
        "aff": "Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636386/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7530333250023535530&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635919",
        "title": "AuraSense: Robot Collision Avoidance by Full Surface Proximity Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Perceiving obstacles and avoiding collisions is fundamental to the safe operation of a robot system, particularly when the robot must operate in highly dynamic human environments. Proximity detection using on-robot sensors can be used to avoid or mitigate impending collisions. However, existing proximity sensing methods are orientation and placement dependent, resulting in blind spots even with large numbers of sensors. In this paper, we introduce the phenomenon of the Leaky Surface Wave (LSW), a novel sensing modality, and present AuraSense, a proximity detection system using the LSW. AuraSense is the first system to realize no-dead-spot proximity sensing for robot arms. It requires only a single pair of piezoelectric transducers, and can easily be applied to off-the-shelf robots with minimal modifications. We further introduce a set of signal processing techniques and a lightweight neural network to address the unique challenges in using the LSW for proximity sensing. Finally, we demonstrate a prototype system consisting of a single piezoelectric element pair on a robot manipulator, which validates our design. We conducted several micro benchmark experiments and performed more than 2000 on-robot proximity detection trials with various potential robot arm materials, colliding objects, approach patterns, and robot movement patterns. AuraSense achieves 100% and 95.3% true positive proximity detection rates when the arm approaches static and mobile obstacles respectively, with a true negative rate over 99%, showing the real-world viability of this system.",
        "primary_area": "",
        "author": "Xiaoran Fan;Riley Simmons-Edler;Daewon Lee;Larry Jackel;Richard Howard;Daniel Lee;Xiaoran Fan;Riley Simmons-Edler;Daewon Lee;Larry Jackel;Richard Howard;Daniel Lee",
        "authorids": "/37086418973;/37089196145;/37599980600;/37089466321;/37089405964;/37280609600;/37086418973;/37089196145;/37599980600;/37089466321;/37089405964;/37280609600",
        "aff": "Samsung AI Center NY, New York; Samsung AI Center NY, New York; Samsung AI Center NY, New York; Samsung AI Center NY, New York; Samsung AI Center NY, New York; Samsung AI Center NY, New York",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635919/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5996104390770602667&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "SAC NY",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636788",
        "title": "AutoPhoto: Aesthetic Photo Capture using Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The process of capturing a well-composed photo is difficult and it takes years of experience to master. We propose a novel pipeline for an autonomous agent to automatically capture an aesthetic photograph by navigating within a local region in a scene. Instead of classical optimization over heuristics such as the rule-of-thirds, we adopt a data-driven aesthetics estimator to assess photo quality. A reinforcement learning framework is used to optimize the model with respect to the learned aesthetics metric. We train our model in simulation with indoor scenes, and we demonstrate that our system can capture aesthetic photos in both simulation and real world environments on a ground robot. To our knowledge, this is the first system that can automatically explore an environment to capture an aesthetic photo with respect to a learned aesthetic estimator. Source code is at https://github.com/HadiZayer/AutoPhoto",
        "primary_area": "",
        "author": "Hadi AlZayer;Hubert Lin;Kavita Bala;Hadi AlZayer;Hubert Lin;Kavita Bala",
        "authorids": "/37089196793;/37086493247;/37697899000;/37089196793;/37086493247;/37697899000",
        "aff": "Department of Computer Science, Cornell University, Ithaca, NY, USA; Department of Computer Science, Cornell University, Ithaca, NY, USA; Department of Computer Science, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636788/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=539769530941736193&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ithaca",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635906",
        "title": "Automata-based Optimal Planning with Relaxed Specifications",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce an automata-based framework for planning with relaxed specifications. User relaxation preferences are represented as weighted finite state edit systems that capture permissible operations on the specification, substitution and deletion of tasks, with complex constraints on ordering and grouping. We propose a three-way product automaton construction method that allows us to compute minimal relaxation policies for the robots using shortest path algorithms. The three-way product automaton captures the robot\u2019s motion, specification satisfaction, and available relaxations at the same time. Additionally, we consider a bi-objective problem that balances temporal relaxation of deadlines within specifications with changing and deleting tasks. Finally, we present the runtime performance and a case study that highlights different modalities of our framework.",
        "primary_area": "",
        "author": "Disha Kamale;Eleni Karyofylli;Cristian-Ioan Vasile;Disha Kamale;Eleni Karyofylli;Cristian-Ioan Vasile",
        "authorids": "/37088526999;/37089196842;/37085532895;/37088526999;/37089196842;/37085532895",
        "aff": "Lehigh University, Bethlehem, PA; Lehigh University, Bethlehem, PA; Lehigh University, Bethlehem, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635906/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16949421734395477347&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Lehigh University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.lehigh.edu",
        "aff_unique_abbr": "Lehigh",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bethlehem",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636781",
        "title": "Automated Generation of Robotic Planning Domains from Observations",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated planning enables robots to find plans to achieve complex, long-horizon tasks, given a planning domain. This planning domain consists of a list of actions, with their associated preconditions and effects, and is usually manually defined by a human expert, which is very time-consuming or even infeasible. In this paper, we introduce a novel method for generating this domain automatically from human demonstrations. First, we automatically segment and recognize the different observed actions from human demonstrations. From these demonstrations, the relevant preconditions and effects are obtained, and the associated planning operators are generated. Finally, a sequence of actions that satisfies a user-defined goal can be planned using a symbolic planner. The generated plan is executed in a simulated environment by the TIAGo robot. We tested our method on a dataset of 12 demonstrations collected from three different participants. The results show that our method is able to generate executable plans from using one single demonstration with a 92% success rate, and 100% when the information from all demonstrations are included, even for previously unseen stacking goals.",
        "primary_area": "",
        "author": "Maximilian Diehl;Chris Paxton;Karinne Ramirez-Amaro;Maximilian Diehl;Chris Paxton;Karinne Ramirez-Amaro",
        "authorids": "/37088530375;/37085403975;/37079218400;/37088530375;/37085403975;/37079218400",
        "aff": "Faculty of Electrical Engineering, Chalmers University of Technology, Gothenburg, Sweden; NVIDIA, USA; Faculty of Electrical Engineering, Chalmers University of Technology, Gothenburg, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636781/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16859790924403658937&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Chalmers University of Technology;NVIDIA",
        "aff_unique_dep": "Faculty of Electrical Engineering;NVIDIA",
        "aff_unique_url": "https://www.chalmers.se;https://www.nvidia.com",
        "aff_unique_abbr": "Chalmers;NV",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Gothenburg;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "9636559",
        "title": "Automated Type-Aware Traffic Speed Prediction based on Sparse Intelligent Camera System",
        "track": "main",
        "status": "Poster",
        "abstract": "Many essential services for autonomous vehicles, e.g., navigation on high-quality maps, are designed based on the understanding of traffic conditions, e.g., travel time/speed on road segments, traffic flow, etc. However, most existing traffic condition models lack the consideration of the differentiation for vehicles with different types (e.g., personal vehicles or trucks) and thus they cannot satisfy some type-specific services, e.g., traffic-condition-based routing for autonomous vehicles with different types. To address this challenge, we design a novel vehicular mobility based sensing model called mDrive to predict the travel speed on the road segments, which is targeted for different types of vehicles by utilizing the camera data obtained from the traffic cameras equipped in the road intersections only, without any in-vehicle GPS devices. mDrive addresses the type-aware traffic speed prediction problem with sparse sensors based on three correlations: (1) the spatial correlation of travel speed on the connected road segments; (2) the temporal correlation of travel speed on the consecutive time slots; (3) the type correlation of different vehicular types\u2019 speed on the same road segment. We implement mDrive on traffic camera data from the Chinese city Suzhou and evaluate it by using the detailed GPS data from personal vehicles, taxis, and trucks, with road contextual data as ground truth. The experiment show mDrive outperforms state-of-the-art methods by reducing 6.2% mean relative error on average for all types of vehicles.",
        "primary_area": "",
        "author": "Xiaoyang Xie;Kangjia Shao;Yang Wang;Fei Miao;Desheng Zhang;Xiaoyang Xie;Kangjia Shao;Yang Wang;Fei Miao;Desheng Zhang",
        "authorids": "/37086592762;/37088894458;/37293653800;/37072758500;/38547561000;/37086592762;/37088894458;/37293653800;/37072758500;/38547561000",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636559/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7322128985543877989&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10
    },
    {
        "id": "9636205",
        "title": "Automatic Construction of Lane-level HD Maps for Urban Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "High definition (HD) maps have demonstrated their essential roles in enabling full autonomy, especially in complex urban scenarios. As a crucial layer of the HD map, lane-level maps are particularly useful: they contain geometrical and topological information for both lanes and intersections. However, large scale construction of HD maps is limited by tedious human labeling and high maintenance costs, especially for urban scenarios with complicated road structures and irregular markings. This paper proposes an approach based on semantic-particle filter to tackle the automatic lane-level mapping problem in urban scenes. The map skeleton is firstly structured as a directed cyclic graph from online mapping database OpenStreetMap. Our proposed method then performs semantic segmentation on 2D front-view images from ego vehicles and explores the lane semantics on a birds-eye-view domain with true topographical projection. Exploiting OpenStreetMap, we further infer lane topology and reference trajectory at intersections with the aforementioned lane semantics. The proposed algorithm has been tested in densely urbanized areas, and the results demonstrate accurate and robust reconstruction of the lane-level HD map.",
        "primary_area": "",
        "author": "Yiyang Zhou;Yuichi Takeda;Masayoshi Tomizuka;Wei Zhan;Yiyang Zhou;Yuichi Takeda;Masayoshi Tomizuka;Wei Zhan",
        "authorids": "/37088504087;/37086962675;/37281933000;/37067099600;/37088504087;/37086962675;/37281933000;/37067099600",
        "aff": "Mechanical Systems Control Lab, University of California, Berkeley, CA, USA; Nissan Motor Co. Ltd., Atsugi, Kanagawa, Japan; Mechanical Systems Control Lab, University of California, Berkeley, CA, USA; Mechanical Systems Control Lab, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636205/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=699268145445824674&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;Nissan Motor Co. Ltd.",
        "aff_unique_dep": "Mechanical Systems Control Lab;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.nissan-global.com",
        "aff_unique_abbr": "UC Berkeley;Nissan",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Berkeley;Atsugi",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9635895",
        "title": "Automatic Learning System for Object Function Points from Random Shape Generation and Physical Validation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we aim to recognize function points of category-agnostic objects and perform object manipulation. To recognize function points of various shapes, it is necessary to train with a large amount of training data. Also, it is necessary to take into account not only visual information but also physics and interaction between objects. To solve these problems, we are working on the automatic generation of training data by detecting function points from a physical simulation. In the proposed system, we add simulation with target task operation and goal state, which allows a robot to acquire the target function point recognizer. We also use GAN to generate various random shapes and render them with random domains, and train Deep Neural Networks on these data. These enable the robot to recognize function points of unseen objects in the real world and realize manipulation.",
        "primary_area": "",
        "author": "Kosuke Takeuchi;Iori Yanokura;Yohei Kakiuchi;Kei Okada;Masayuki Inaba;Kosuke Takeuchi;Iori Yanokura;Yohei Kakiuchi;Kei Okada;Masayuki Inaba",
        "authorids": "/37088996846;/37086105883;/38242437800;/37280639000;/37286658200;/37088996846;/37086105883;/38242437800;/37280639000;/37286658200",
        "aff": "JSK Laboratory, The University of Tokyo, Japan; JSK Laboratory, The University of Tokyo, Japan; JSK Laboratory, The University of Tokyo, Japan; JSK Laboratory, The University of Tokyo, Japan; JSK Laboratory, The University of Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635895/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18006230425912717594&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "JSK Laboratory",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636432",
        "title": "Autonomous Bi-Manual Surgical Suturing Based on Skills Learned from Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel application of Learning from Demonstration to realize a fully autonomous bi-manual surgical suturing task, including needle pick up, insertion, re-grasping, extraction and hand-over. Surgical action primitives are learned from a single human demonstration and encoded into an action library from which they are pulled to compose more elaborate tasks at planning/execution time. The method is demonstrated in a non-clinical setting, using unmodified surgical instruments with a custom surgical robot system. We use stereo vision to automatically detect the suture needle and entry points to close the control loop and generalize tasks to different task conditions. The suturing task is shown to generalize well to differing initial conditions with a success rate of 17 % for the full task, a mean subtask success rate of 75 % and mean needle insertion error of 3.3 mm over the course of 46 trial task executions at human speed. Failures could all be attributed to erroneous vision-based detection, pose estimation and robot calibration.",
        "primary_area": "",
        "author": "Kim L. Schwaner;I\u00f1igo Iturrate;Jakob K. H. Andersen;Pernille T. Jensen;Thiusius R. Savarimuthu;Kim L. Schwaner;I\u00f1igo Iturrate;Jakob K. H. Andersen;Pernille T. Jensen;Thiusius R. Savarimuthu",
        "authorids": "/37089272328;/37086185479;/37089194455;/37086801683;/37946053800;/37089272328;/37086185479;/37089194455;/37086801683;/37946053800",
        "aff": "Faculty of Engineering, SDU Robotics, The M\u00e6rsk Mc-Kinney M\u00f8ller Institute, University of Southern Denmark, Odense, Denmark; Faculty of Engineering, SDU Robotics, The M\u00e6rsk Mc-Kinney M\u00f8ller Institute, University of Southern Denmark, Odense, Denmark; Faculty of Engineering, SDU Robotics, The M\u00e6rsk Mc-Kinney M\u00f8ller Institute, University of Southern Denmark, Odense, Denmark; Department of Gynaecology and Obstetrics, Aarhus University Hospital, Aarhus, Denmark; Faculty of Engineering, SDU Robotics, The M\u00e6rsk Mc-Kinney M\u00f8ller Institute, University of Southern Denmark, Odense, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636432/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1614708646544202370&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Southern Denmark;Aarhus University Hospital",
        "aff_unique_dep": "Faculty of Engineering;Department of Gynaecology and Obstetrics",
        "aff_unique_url": "https://www.sdu.dk;https://www.auh.dk",
        "aff_unique_abbr": "SDU;",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Odense;Aarhus",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9636145",
        "title": "Autonomous Cooperative Transportation System involving Multi-Aerial Robots with Variable Attachment Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "Cooperative transportation by multi-aerial robots has the potential to support various payloads and improve fail- safe against dropping. Furthermore, changing the attachment positions of robots according payload characteristics increases the stability of transportation. However, there are almost no transportation systems capable of scaling to the payload weight and size and changing the optimal attachment positions. To address this issue, we propose a cooperative transportation sys- tem comprising autonomously executable software and suitable hardware, covering the entire process, from pre-takeoff setting to controlled flight. The proposed system decides the formation of the attachment positions by prioritizing controllability based on the center of gravity obtained from Bayesian estimations with robot pairs. We investigated the cooperative transportation of an unknown payload larger than that of whole carrier robots through numerical simulations. Furthermore, we performed cooperative transportation of an unknown payload (with a weight of about 3.2 kg and maximum length of 1.76 m) using eight robots. The proposed system was found to be versatile with regard to handling unknown payloads with different shapes and center-of-gravity positions.",
        "primary_area": "",
        "author": "Koshi Oishi;Tomohiko Jimbo;Koshi Oishi;Tomohiko Jimbo",
        "authorids": "/37088541019;/37569079000;/37088541019;/37569079000",
        "aff": "Cloud Informatics Research-Domain, Toyota Central R&D Labs., Inc, Nagakute, Japan; Cloud Informatics Research-Domain, Toyota Central R&D Labs., Inc, Nagakute, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636145/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18168958538124173263&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Toyota Central R&D Labs., Inc",
        "aff_unique_dep": "Cloud Informatics Research-Domain",
        "aff_unique_url": "https://www.toyota-global.com",
        "aff_unique_abbr": "Toyota R&D",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nagakute",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636378",
        "title": "Autonomous Decision Making in a Bioinspired Adaptive Robotic Anchoring Module",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a bioinspired adaptive anchoring module that can be integrated into robots to enhance their mobility and manipulation abilities. The design of the module is inspired by the structure of the mouth in Chilean lamprey (Mordacia lapicida) where a combination of suction and several arrays of teeth with different sizes around the mouth opening is used for catching preys and anchoring onto them. The module can deploy a suitable mode of attachment, via teeth or vacuum suction, to different contact surfaces in response to the textural properties of those surfaces. In order to make a decision on the suitable mode of attachment, an original dataset of 500 images of outdoor and indoor surfaces was used to train a visual surface examination model using YOLOv3; a virtually real-time object detection algorithm. The mean average precision of the trained model was calculated to be 91%. We have conducted a series of pull-out tests to characterize the module's strength of attachments. The results of the experiments indicate that the anchoring module can withstand an applied detachment force of up to 70N and 30N when attached using teeth and vacuum suction, respectively.",
        "primary_area": "",
        "author": "Rasoul Sadeghian;Pooya Sareh;Shahrooz Shahin;Sina Sareh;Rasoul Sadeghian;Pooya Sareh;Shahrooz Shahin;Sina Sareh",
        "authorids": "/37085635080;/37088867743;/37086346623;/37085434081;/37085635080;/37088867743;/37086346623;/37085434081",
        "aff": "RCA Robotics Laboratory, Royal College of Art, London, UK; Creative Design Engineering Lab (Cdel), School of Engineering, University of Liverpool, Liverpool, UK; RCA Robotics Laboratory, Royal College of Art, London, UK; RCA Robotics Laboratory, Royal College of Art, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636378/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6660310975561805410&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Royal College of Art;University of Liverpool",
        "aff_unique_dep": "RCA Robotics Laboratory;School of Engineering",
        "aff_unique_url": "https://www.rca.ac.uk;https://www.liverpool.ac.uk",
        "aff_unique_abbr": "RCA;Liv Uni",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "London;Liverpool",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636053",
        "title": "Autonomous Drone Racing with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In many robotic tasks, such as autonomous drone racing, the goal is to travel through a set of waypoints as fast as possible. A key challenge for this task is planning the timeoptimal trajectory, which is typically solved by assuming perfect knowledge of the waypoints to pass in advance. The resulting solution is either highly specialized for a single-track layout, or suboptimal due to simplifying assumptions about the platform dynamics. In this work, a new approach to near-time-optimal trajectory generation for quadrotors is presented. Leveraging deep reinforcement learning and relative gate observations, our approach can compute near-time-optimal trajectories and adapt the trajectory to environment changes. Our method exhibits computational advantages over approaches based on trajectory optimization for non-trivial track configurations. The proposed approach is evaluated on a set of race tracks in simulation and the real world, achieving speeds of up to 60kmh\u22121 with a physical quadrotor.",
        "primary_area": "",
        "author": "Yunlong Song;Mats Steinweg;Elia Kaufmann;Davide Scaramuzza;Yunlong Song;Mats Steinweg;Elia Kaufmann;Davide Scaramuzza",
        "authorids": "/37088688858;/37088996148;/37086293209;/37397688400;/37088688858;/37088996148;/37086293209;/37397688400",
        "aff": "Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; RWTH Aachen University; Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636053/",
        "gs_citation": 237,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13569188497578145840&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Zurich;RWTH Aachen University",
        "aff_unique_dep": "Department of Neuroinformatics;",
        "aff_unique_url": "https://www.unizh.ch;https://www.rwth-aachen.de",
        "aff_unique_abbr": "UZH;RWTH",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Aachen",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "9636117",
        "title": "Autonomous Flights in Dynamic Environments with Onboard Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce a complete system for autonomous flight of quadrotors in dynamic environments with onboard sensing. Extended from existing work, we develop an occlusion-aware dynamic perception method based on depth images, which classifies obstacles as dynamic and static. For representing generic dynamic environment, we model dynamic objects with moving ellipsoids and fuse static ones into an occupancy grid map. To achieve dynamic avoidance, we design a planning method composed of modified kinodynamic path searching and gradient-based optimization. The method leverages manually constructed gradients without maintaining a signed distance field (SDF), making the planning procedure finished in milliseconds. We integrate the above methods into a customized quadrotor system and thoroughly test it in real-world experiments, verifying its effective collision avoidance in dynamic environments.",
        "primary_area": "",
        "author": "Yingjian Wang;Jialin Ji;Qianhao Wang;Chao Xu;Fei Gao;Yingjian Wang;Jialin Ji;Qianhao Wang;Chao Xu;Fei Gao",
        "authorids": "/37089002292;/37088999913;/37089197978;/37404060100;/37086045143;/37089002292;/37088999913;/37089197978;/37404060100;/37086045143",
        "aff": "Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636117/",
        "gs_citation": 65,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15659910239913993694&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Huzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636635",
        "title": "Autonomous Mobile Robot Navigation Independent of Road Boundary Using Driving Recommendation Map",
        "track": "main",
        "status": "Poster",
        "abstract": "Numerous autonomous navigation systems have been proposed, so far, for use in walking environments. Of these, systems that do not rely on high-definition maps and precise localization are cheaper to maintain and easier to implement in unknown outdoor environments. In these systems, road-following navigation using road boundaries is commonly used. In outdoor environments, however, the road boundary is indistinct in some cases. Therefore, it is necessary to infer an area recommended by traffic rules and navigate based on this inference. This paper proposes an autonomous navigation system that is independent of the road boundaries by using a driving recommendation map. In this system, the driving recommendation degree is inferred by deep learning-based semantic segmentation using automatically labeled training data, and a map that probabilistically represents the driving recommendation degree is generated using this information. The proposed autonomous navigation system has demonstrated its usefulness in an environment with indistinct road boundaries. The demonstration shows the proposed autonomous navigation system can plan a path based on driving recommendation degree and properly drive in a scene where the road boundary is indistinct.",
        "primary_area": "",
        "author": "Yuya Onozuka;Ryosuke Matsumi;Motoki Shino;Yuya Onozuka;Ryosuke Matsumi;Motoki Shino",
        "authorids": "/37088690172;/37089198135;/38192315700;/37088690172;/37089198135;/38192315700",
        "aff": "Department of Human and Engineered Environmental Studies, Graduate School of Frontier Sciences, The University of Tokyo, Chiba, Japan; Department of Human and Engineered Environmental Studies, Graduate School of Frontier Sciences, The University of Tokyo, Chiba, Japan; Department of Human and Engineered Environmental Studies, Graduate School of Frontier Sciences, The University of Tokyo, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636635/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8751641419536226618&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Human and Engineered Environmental Studies",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chiba",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9635902",
        "title": "Autonomous Scanning Target Localization for Robotic Lung Ultrasound Imaging",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Xihan Ma;Ziming Zhang;Haichong K. Zhang;Xihan Ma;Ziming Zhang;Haichong K. Zhang",
        "authorids": "/37088505948;/37088400388;/37088589789;/37088505948;/37088400388;/37088589789",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635902/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13690326812731102354&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "9636082",
        "title": "Autonomous Vehicle Navigation in Semi-structured Environments Based on Sparse Waypoints and LiDAR Road-tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "During the last decades, the research endeavours on autonomous driving found great resonance in Advanced Driver-Assistance Solutions that equipped the contemporary civilian vehicles and significantly boosted their driver-less mobility. The existing applications are mostly focused on urban scenarios where signs, road lanes and markers are well defined and ordered favouring the motion of the vehicles whilst, less attention has been paid to the semi-structured and rural environments where traffic infrastructure is scarce. The paper at hand introduces a holistic framework for autonomous vehicles navigation in semi-structured environments. Semantic cues fused with geometrical information of LiDAR data are used for road detection and tracking. OpenStreetMaps are employed as a rough route planner, the waypoints of which are rectified via a probability distribution function over the visible area of vehicle\u2019s vicinity. Thus, vehicle\u2019s localization is obtained by Normal Distribution Transform (NDT) SLAM, where the covariance of egomotion estimation is obtained by processing short-term 3D maps, fused with GPS measurements by means of an extended Kalman filter. Local planning and execution of vehicle\u2019s motion is applied on local cost maps formulated by the union of 2D laser readings and the detected road boundaries fitted through B\u00e9zier curves. The complete framework has been evaluated with the aid of a real Autonomous Guided Vehicle in a constrained semi-structured urban area, exhibiting robust navigation performance.",
        "primary_area": "",
        "author": "Kosmas Tsiakas;Ioannis Kostavelis;Antonios Gasteratos;Dimitrios Tzovaras;Kosmas Tsiakas;Ioannis Kostavelis;Antonios Gasteratos;Dimitrios Tzovaras",
        "authorids": "/37089194289;/38480784400;/37303793300;/37269764300;/37089194289;/38480784400;/37303793300;/37269764300",
        "aff": "Laboratory of Robotics and Automation, Democritus University of Thrace, Xanthi, Greece; Centre for Research and Technology Hellas, Information Technologies Institute (CERTH / ITI), Thessaloniki, Greece; Laboratory of Robotics and Automation, Democritus University of Thrace, Xanthi, Greece; Centre for Research and Technology Hellas, Information Technologies Institute (CERTH / ITI), Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636082/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3435541098570828828&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Democritus University of Thrace;Centre for Research and Technology Hellas",
        "aff_unique_dep": "Laboratory of Robotics and Automation;Information Technologies Institute",
        "aff_unique_url": "https://www.duth.gr;https://www.certh.gr",
        "aff_unique_abbr": ";CERTH",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Xanthi;Thessaloniki",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9636475",
        "title": "Autonomous object harvesting using synchronized optoelectronic microrobots",
        "track": "main",
        "status": "Poster",
        "abstract": "Optoelectronic tweezer-driven microrobots (OETdMs) are a versatile micromanipulation technology based on the application of light induced dielectrophoresis to move small dielectric structures (microrobots) across a photoconductive substrate. The microrobots in turn can be used to exert forces on secondary objects and carry out a wide range of micromanipulation operations, including collecting, transporting and depositing microscopic cargos. In contrast to alternative (direct) micromanipulation techniques, OETdMs are relatively gentle, making them particularly well suited to interacting with sensitive objects such as biological cells. However, at present such systems are used exclusively under manual control by a human operator. This limits the capacity for simultaneous control of multiple microrobots, reducing both experimental throughput and the possibility of cooperative multi-robot operations. In this article, we describe an approach to automated targeting and path planning to enable open-loop control of multiple microrobots. We demonstrate the performance of the method in practice, using microrobots to simultaneously collect, transport and deposit silica microspheres. Using computational simulations based on real microscopic image data, we investigate the capacity of microrobots to collect target cells from within a dissociated tissue culture. Our results indicate the feasibility of using OETdMs to autonomously carry out micromanipulation tasks within complex, unstructured environments.",
        "primary_area": "",
        "author": "Christopher Bendkowski;Laurent Mennillo;Tao Xu;Mohamed Elsayed;Filip Stojic;Harrison Edwards;Shuailong Zhang;Cindi Morshead;Vijay Pawar;Aaron R. Wheeler;Danail Stoyanov;Michael Shaw;Christopher Bendkowski;Laurent Mennillo;Tao Xu;Mohamed Elsayed;Filip Stojic;Harrison Edwards;Shuailong Zhang;Cindi Morshead;Vijay Pawar;Aaron R. Wheeler;Danail Stoyanov;Michael Shaw",
        "authorids": "/37089198178;/37089194567;/37089195867;/37089198256;/37089195371;/37089195169;/37089198270;/37089196896;/38191148100;/37428062800;/37563622300;/37089195553;/37089198178;/37089194567;/37089195867;/37089198256;/37089195371;/37089195169;/37089198270;/37089196896;/38191148100;/37428062800;/37563622300;/37089195553",
        "aff": "University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom; University of Toronto, Toronto, Canada; University of Toronto, Toronto, Canada; University of Toronto, Toronto, Canada; University of Toronto, Toronto, Canada; University of Toronto, Toronto, Canada; University College London, London, United Kingdom; University of Toronto, Toronto, Canada; University College London, London, United Kingdom; National Physical Laboratory, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636475/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11179810913966161321&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;0;0;1;1;1;1;1;0;1;0;2",
        "aff_unique_norm": "University College London;University of Toronto;National Physical Laboratory",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.utoronto.ca;https://www.npl.co.uk",
        "aff_unique_abbr": "UCL;U of T;NPL",
        "aff_campus_unique_index": "0;0;0;1;1;1;1;1;0;1;0",
        "aff_campus_unique": "London;Toronto;",
        "aff_country_unique_index": "0;0;0;1;1;1;1;1;0;1;0;0",
        "aff_country_unique": "United Kingdom;Canada"
    },
    {
        "id": "9636612",
        "title": "B-spline path planner for safe navigation of mobile robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a 2D path planning algorithm in a non-convex workspace defined as a sequence of connected convex polytopes. The reference path is parameterized as a B-spline curve, which is guaranteed to entirely remain within the workspace by exploiting the local convexity property and by formulating linear constraints on the control points of the B-spline. The novelties of the paper lie in the use of the equivalent B\u00e9zier representation of the B-spline curve, which significantly reduces the conservatism in the local convexity bound and in the integration of these constraints into a convex quadratic optimization problem, which minimizes the curve length. The algorithm is successfully validated in both simulations and experiments, by providing obstacle-free reference paths on real occupancy grid maps obtained from the laser scan data of a mobile robot platform.",
        "primary_area": "",
        "author": "Ngoc Thinh Nguyen;Lars Schilling;Michael Sebastian Angern;Heiko Hamann;Floris Ernst;Georg Schildbach;Ngoc Thinh Nguyen;Lars Schilling;Michael Sebastian Angern;Heiko Hamann;Floris Ernst;Georg Schildbach",
        "authorids": "/37086093218;/37089195213;/37089195770;/37683321200;/38580466700;/38232682600;/37086093218;/37089195213;/37089195770;/37683321200;/38580466700;/38232682600",
        "aff": "Institute for Robotics and Cognitive Systems, University of Luebeck (UzL), Luebeck, Germany; Institute for Robotics and Cognitive Systems, University of Luebeck (UzL), Luebeck, Germany; UzL, Institute for Electrical Engineering in Medicine, Luebeck, Germany; UzL, Institute of Computer Engineering, Luebeck, Germany; Institute for Robotics and Cognitive Systems, University of Luebeck (UzL), Luebeck, Germany; UzL, Institute for Electrical Engineering in Medicine, Luebeck, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636612/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9246188886031374189&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Luebeck",
        "aff_unique_dep": "Institute for Robotics and Cognitive Systems",
        "aff_unique_url": "https://www.uni-luebeck.de",
        "aff_unique_abbr": "UzL",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Luebeck",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636810",
        "title": "BEV-Net: A Bird\u2019s Eye View Object Detection Network for LiDAR Point Cloud",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR-only object detection is essential for autonomous driving systems and is a challenging problem. For the representation of a bird\u2019s eye view LiDAR point-cloud, this paper proposes a single-stage object detector. The detector can output classification information and accurate positioning information for multi-category objects. In this paper, the detector\u2019s design methods are detailed from a bird\u2019s eye view LiDAR point-cloud encoding, network design, data augmentation, etc. The detector was evaluated on three challenging datasets: KITTI, nuScenes and Waymo. The experimental results demonstrated that the proposed detector can accurately achieve object detection tasks and the detection speed can reach 26.9 FPS. Both the precision and the speed can meet the requirements of most autonomous driving scenarios.",
        "primary_area": "",
        "author": "Meng Liu;Jianwei Niu;Meng Liu;Jianwei Niu",
        "authorids": "/37086236482;/37276941100;/37086236482;/37276941100",
        "aff": "State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; Zhengzhou University Research Institute of Industrial Technology, School of Information Engineering, Zhengzhou University, Zhengzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636810/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1200281908241957272&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Beihang University;Zhengzhou University",
        "aff_unique_dep": "School of Computer Science and Engineering;School of Information Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn;http://www.zzu.edu.cn",
        "aff_unique_abbr": "BUAA;ZZU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Beijing;Zhengzhou",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636024",
        "title": "BORM: Bayesian Object Relation Model for Indoor Scene Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Scene recognition is a fundamental task in robotic perception. For human beings, scene recognition is reasonable because they have abundant object knowledge of the real world. The idea of transferring prior object knowledge from humans to scene recognition is significant but still less exploited. In this paper, we propose to utilize meaningful object representations for indoor scene representation. First, we utilize an improved object model (IOM) as a baseline that enriches the object knowledge by introducing a scene parsing algorithm pretrained on the ADE20K dataset with rich object categories related to the indoor scene. To analyze the object co-occurrences and pairwise object relations, we formulate the IOM from a Bayesian perspective as the Bayesian object relation model (BORM). Meanwhile, we incorporate the proposed BORM with the PlacesCNN model as the combined Bayesian object relation model (CBORM) for scene recognition and significantly outperforms the state-of-the-art methods on the reduced Places365 dataset, and SUN RGB-D dataset without retraining, showing the excellent generalization ability of the proposed method. Code can be found at https://github.com/FreeformRobotics/BORM.",
        "primary_area": "",
        "author": "Liguang Zhou;Jun Cen;Xingchao Wang;Zhenglong Sun;Tin Lun Lam;Yangsheng Xu;Liguang Zhou;Jun Cen;Xingchao Wang;Zhenglong Sun;Tin Lun Lam;Yangsheng Xu",
        "authorids": "/37086212444;/37088568552;/37089197556;/37086799406;/37571111600;/37277722000;/37086212444;/37088568552;/37089197556;/37086799406;/37571111600;/37277722000",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen; Hong Kong University of Science and Technology; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636024/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10474396040858539326&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Hong Kong University of Science and Technology",
        "aff_unique_dep": "Shenzhen Institute of Artificial Intelligence and Robotics for Society;",
        "aff_unique_url": "https://www.cuhk.edu.cn;https://www.ust.hk",
        "aff_unique_abbr": "CUHK;HKUST",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Shenzhen;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636321",
        "title": "BSP-MonoLoc: Basic Semantic Primitives based Monocular Localization on Roads",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust visual localization in traffic scenes is a fundamental problem for self-driving vehicles. However, it is still challenging to achieve accurate localization performance because of drastic viewpoint and illumination changes. To address the issues, we design a novel monocular localization framework based on a light-weight prior map, called BSP-MonoLoc, which leverages the 2D semantic primitives from the monocular images and the 3D basic semantic primitives from the prior map. These primitives are commonly available but lack of distinctive signature. To effectively make associations between the 2D and 3D primitives and refine the vehicle\u2019s pose, we adopt an iterative optimization method, where an efficient hierarchical sample strategy is designed to give a good initial prediction for the associations and the pose. Experimental results on the KAIST dataset and our dataset demonstrate the proposed method can achieve high localization accuracy and run at a real-time performance.",
        "primary_area": "",
        "author": "Heping Li;Changliang Xue;Feng Wen;Hongbo Zhang;Wei Gao;Heping Li;Changliang Xue;Feng Wen;Hongbo Zhang;Wei Gao",
        "authorids": "/37600697500;/37089001737;/37088690190;/37859161500;/37066625700;/37600697500;/37089001737;/37088690190;/37859161500;/37066625700",
        "aff": "Chinese Academy of Sciences, National Laboratory of Pattern Recognition, Institute of Automation; Chinese Academy of Sciences, National Laboratory of Pattern Recognition, Institute of Automation; Noah\u2019s Ark Lab, Huawei Technologies; Noah\u2019s Ark Lab, Huawei Technologies; Chinese Academy of Sciences, National Laboratory of Pattern Recognition, Institute of Automation",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636321/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11320250434136309728&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Chinese Academy of Sciences;Huawei",
        "aff_unique_dep": "National Laboratory of Pattern Recognition, Institute of Automation;Noah\u2019s Ark Lab",
        "aff_unique_url": "http://www.cas.cn;https://www.huawei.com",
        "aff_unique_abbr": "CAS;Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635842",
        "title": "Balloon Animal Robots: Reconfigurable Isoperimetric Inflated Soft Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a new class of soft reconfigurable robot: balloon animal robots. The balloon animal robot consists of a closed volume inflatable tube which can be reconfigured into structures of varying topology by a collective of simple sub-unit robots. The robotic sub-units can (1) drive along the length of the tube to localize a joint, (2) create pinch points that locally reduce the bending stiffness of the tube to form a joint, and (3) selectively mechanically couple to one another through cable driven actuators to create nodes of the structure. In this work we introduce the hardware necessary to construct the robot, present experiments to guide the hardware design, and formulate an algorithm using graph theory to calculate the number of nodes and node connections needed to form different 2D shapes. Finally, we demonstrate the system with two active nodes and four passive nodes forming multiple 2D shapes from the same hardware.",
        "primary_area": "",
        "author": "Anthony D. Stuart;Zachary M. Hammond;Sean Follmer;Anthony D. Stuart;Zachary M. Hammond;Sean Follmer",
        "authorids": "/37089194193;/37086066571;/37085667725;/37089194193;/37086066571;/37085667725",
        "aff": "Dept. of Mechanical Engineering, Stanford University, Stanford, CA, USA; Dept. of Mechanical Engineering, Stanford University, Stanford, CA, USA; Dept. of Mechanical Engineering, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635842/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9117916307235044814&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636496",
        "title": "Bat Bot 2.0: bio-inspired anisotropic skin, passive wrist joints, and redesigned flapping mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "Bat flight has been an underdeveloped area of bio-inspired robotics because of the vast complexities of biological bat flight and the over 40 degrees of freedom present in their bodies. The robotic flapping system Bat Bot (B2) has been shown to exhibit fundamental properties of biological bat flight with its articulated wings, its deformable membrane, and its controllable hindlimbs. However, the system is limited in performance by its relatively large mass for the thrust it produces. In an effort to further pursue this important area of flapping flight, we have made several important hardware improvements to the system based on biological inspiration. These include passive wrist joints to reduce negative lift in the upstroke and a novel elastic fiber membrane to mimic the anistropic nature of bat skin for performance and durability. The redesigned flapping mechanism and structure have reduced the weight by 22%, increased the flapping amplitude, lowered mechanical slackness, and improved mass distribution. These hardware improvements are functional together in free-flight tests. This new system Bat Bot 2.0 (B2.0) provides insights into the important elements of design of bat robots, and it brings the goal of complex bat flight maneuvers closer to reality.",
        "primary_area": "",
        "author": "Jonathan Hoff;Nicole Jeon;Patrick Li;Joohyung Kim;Jonathan Hoff;Nicole Jeon;Patrick Li;Joohyung Kim",
        "authorids": "/37087321873;/37089194677;/37089196171;/37085576403;/37087321873;/37089194677;/37089196171;/37085576403",
        "aff": "Coordinated Science Laboratory and Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign (UIUC), Urbana, IL, USA; Mechanical Science and Engineering Department, UIUC; Mechanical Science and Engineering Department, UIUC; Coordinated Science Laboratory and Department of Electrical and Computer Engineering, University of Illinois at Urbana-Champaign (UIUC), Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636496/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13630396455641412220&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Urbana;Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636628",
        "title": "Bayesian Meta-Learning for Few-Shot Policy Adaptation Across Robotic Platforms",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning methods can achieve significant performance but require a large amount of training data collected on the same robotic platform. A policy trained with expensive data is rendered useless after making even a minor change to the robot hardware. In this paper, we address the challenging problem of adapting a policy, trained to perform a task, to a novel robotic hardware platform given only few demonstrations of robot motion trajectories on the target robot. We formulate it as a few-shot meta-learning problem where the goal is to find a meta-model that captures the common structure shared across different robotic platforms such that data-efficient adaptation can be performed. We achieve such adaptation by introducing a learning framework consisting of a probabilistic gradient-based meta-learning algorithm that models the uncertainty arising from the few-shot setting with a low-dimensional latent variable. We experimentally evaluate our framework on a simulated reaching and a real-robot picking task using 400 simulated robots generated by varying the physical parameters of an existing set of robotic platforms. Our results show that the proposed method can successfully adapt a trained policy to different robotic platforms with novel physical parameters and the superiority of our meta-learning algorithm compared to state-of-the-art methods for the introduced few-shot policy adaptation problem.",
        "primary_area": "",
        "author": "Ali Ghadirzadeh;Xi Chen;Petra Poklukar;Chelsea Finn;M\u00e5rten Bj\u00f6rkman;Danica Kragic;Ali Ghadirzadeh;Xi Chen;Petra Poklukar;Chelsea Finn;M\u00e5rten Bj\u00f6rkman;Danica Kragic",
        "authorids": "/37085340524;/37088506786;/37088686149;/37085523464;/37283063600;/37281296000;/37085340524;/37088506786;/37088686149;/37085523464;/37283063600;/37281296000",
        "aff": "Stanford University; KTH Royal Institute of Technology; KTH Royal Institute of Technology; Stanford University; KTH Royal Institute of Technology; KTH Royal Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636628/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12155867682935830006&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;1;1",
        "aff_unique_norm": "Stanford University;KTH Royal Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://www.kth.se",
        "aff_unique_abbr": "Stanford;KTH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;1;1;0;1;1",
        "aff_country_unique": "United States;Sweden"
    },
    {
        "id": "9636163",
        "title": "Bayesian Residual Policy Optimization: : Scalable Bayesian Reinforcement Learning with Clairvoyant Experts",
        "track": "main",
        "status": "Poster",
        "abstract": "Informed and robust decision making in the face of uncertainty is critical for robots operating in unstructured environments. We formulate this as Bayesian Reinforcement Learning over latent Markov Decision Processes (MDPs). While Bayes-optimality is theoretically the gold standard, existing algorithms scale poorly to continuous state and action spaces. We build on the following insight: in the absence of uncertainty, each latent MDP is easier to solve. We first obtain an ensemble of experts, one for each latent MDP, and fuse their advice to compute a baseline policy. Next, we train a Bayesian residual policy to improve upon the ensemble\u2019s recommendation and learn to reduce uncertainty. Our algorithm, Bayesian Residual Policy Optimization (BRPO), imports the scalability of policy gradient methods and task-specific expert skills. BRPO significantly improves the ensemble of experts and drastically outperforms existing adaptive RL methods, both in simulated and physical robot experiments.",
        "primary_area": "",
        "author": "Gilwoo Lee;Brian Hou;Sanjiban Choudhury;Siddhartha S. Srinivasa;Gilwoo Lee;Brian Hou;Sanjiban Choudhury;Siddhartha S. Srinivasa",
        "authorids": "/37086687821;/37088506431;/37077381500;/37339877600;/37086687821;/37088506431;/37077381500;/37339877600",
        "aff": "School of Computer Science and Engineering, University of Washington, Seattle, Washington; School of Computer Science and Engineering, University of Washington, Seattle, Washington; School of Computer Science and Engineering, University of Washington, Seattle, Washington; School of Computer Science and Engineering, University of Washington, Seattle, Washington",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636163/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2389416385153745085&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636297",
        "title": "Behavior Self-Organization Supports Task Inference for Continual Robot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in robot learning have enabled robots to become increasingly better at mastering a predefined set of tasks. On the other hand, as humans, we have the ability to learn a growing set of tasks over our lifetime. Continual robot learning is an emerging research direction with the goal of endowing robots with this ability. In order to learn new tasks over time, the robot first needs to infer the task at hand. Task inference, however, has received little attention in the multi-task learning literature. In this paper, we propose a novel approach to continual learning of robotic control tasks. Our approach performs unsupervised learning of behavior embeddings by incrementally self-organizing demonstrated behaviors. Task inference is made by finding the nearest behavior embedding to a demonstrated behavior, which is used together with the environment state as input to a multi-task policy trained with reinforcement learning to optimize performance over tasks. Unlike previous approaches, our approach makes no assumptions about task distribution and requires no task exploration to infer tasks. We evaluate our approach in experiments with concurrently and sequentially presented tasks and show that it outperforms other multi-task learning approaches in terms of generalization performance and convergence speed, particularly in the continual learning setting.",
        "primary_area": "",
        "author": "Muhammad Burhan Hafez;Stefan Wermter;Muhammad Burhan Hafez;Stefan Wermter",
        "authorids": "/37089194688;/37323875400;/37089194688;/37323875400",
        "aff": "Department of Informatics, Knowledge Technology, University of Hamburg, Germany; Department of Informatics, Knowledge Technology, University of Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636297/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11628385820411972898&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Hamburg",
        "aff_unique_dep": "Department of Informatics, Knowledge Technology",
        "aff_unique_url": "https://www.uni-hamburg.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636586",
        "title": "Benchmarking Off-The-Shelf Solutions to Robotic Assembly Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, many learning based approaches have been studied to realize robotic manipulation and assembly tasks, often including vision and force/tactile feedback. How-ever, it is unclear what the baseline state-of-the-art performance is and what the bottleneck problems are. In this work, we evaluate off-the-shelf (OTS) industrial solutions on a recently introduced benchmark, the National Institute of Standards and Technology (NIST) Assembly Task Board. A set of assembly tasks is introduced and baseline methods are provided to understand their intrinsic difficulty. Multiple sensor-based robotic solutions are then evaluated, including hybrid force/motion control and 2D/3D pattern matching. An end-to-end integrated solution that accomplishes the tasks is also provided.The results and findings throughout the study reveal a few noticeable factors that impede the adoptions of the OTS solutions: dependency on expertise, limited applicability, lack of interoperability, no scene awareness or error recovery mechanisms, and high cost. This paper also provides a first attempt of an objective benchmark performance on the NIST Assembly Task Boards as a reference comparison for future works on this problem.",
        "primary_area": "",
        "author": "Wenzhao Lian;Tim Kelch;Dirk Holz;Adam Norton;Stefan Schaal;Wenzhao Lian;Tim Kelch;Dirk Holz;Adam Norton;Stefan Schaal",
        "authorids": "/37088998889;/37089197754;/37542800400;/38059491100;/37282144700;/37088998889;/37089197754;/37542800400;/38059491100;/37282144700",
        "aff": "Intrinsic Innovation LLC, Mountain View, CA, USA; Intrinsic Innovation LLC, Mountain View, CA, USA; Intrinsic Innovation LLC, Mountain View, CA, USA; New England Robotics Validation and Experimentation (NERVE) Center, University of Massachusetts Lowell, Lowell, MA, USA; Intrinsic Innovation LLC, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636586/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5203494951370566333&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Intrinsic Innovation LLC;University of Massachusetts Lowell",
        "aff_unique_dep": ";New England Robotics Validation and Experimentation (NERVE) Center",
        "aff_unique_url": ";https://www.uml.edu",
        "aff_unique_abbr": ";UMass Lowell",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Mountain View;Lowell",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635925",
        "title": "Benchmarking Safe Deep Reinforcement Learning in Aquatic Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel benchmark environment for Safe Reinforcement Learning focusing on aquatic navigation. Aquatic navigation is an extremely challenging task due to the non-stationary environment and the uncertainties of the robotic platform, hence it is crucial to consider the safety aspect of the problem, by analyzing the behavior of the trained network to avoid dangerous situations (e.g., collisions). To this end, we consider a value-based and policy-gradient Deep Reinforcement Learning (DRL) and we propose a crossover-based strategy that combines gradient-based and gradient-free DRL to improve sample-efficiency. Moreover, we propose a verification strategy based on interval analysis that checks the behavior of the trained models over a set of desired properties. Our results show that the crossover-based training outperforms prior DRL approaches, while our verification allows us to quantify the number of configurations that violate the behaviors that are described by the properties. Crucially, this will serve as a benchmark for future research in this domain of applications.",
        "primary_area": "",
        "author": "Enrico Marchesini;Davide Corsi;Alessandro Farinelli;Enrico Marchesini;Davide Corsi;Alessandro Farinelli",
        "authorids": "/37086805241;/37086805416;/37266396700;/37086805241;/37086805416;/37266396700",
        "aff": "Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635925/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6452351139475607710&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Verona",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.univr.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Verona",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636825",
        "title": "Binary Neural Network in Robotic Manipulation: Flexible Object Manipulation for Humanoid Robot Using Partially Binarized Auto-Encoder on FPGA",
        "track": "main",
        "status": "Poster",
        "abstract": "A neural network based flexible object manipulation system for a humanoid robot on FPGA is proposed. Although the manipulations of flexible objects using robots attract ever increasing attention since these tasks are the basic and essential activities in our daily life, it has been put into practice only recently with the help of deep neural networks. However such systems have relied on GPU accelerators, which cannot be implemented into the space limited robotic body. Although field programmable gate arrays (FPGAs) are known to be energy efficient and suitable for embedded systems, the model size should be drastically reduced since FPGAs have limited on-chip memory. To this end, we propose \"partially\" binarized deep convolutional auto-encoder technique, where only an encoder part is binarized to compress model size without degrading the inference accuracy. The model implemented on Xilinx ZCU102 achieves 41.1 frames per second with a power consumption of 3.1 W, which corresponds to 10\u00d7 and 3.7\u00d7 improvements from the systems implemented on Core i7 6700K and RTX 2080 Ti, respectively.",
        "primary_area": "",
        "author": "Satoshi Ohara;Tetsuya Ogata;Hiromitsu Awano;Satoshi Ohara;Tetsuya Ogata;Hiromitsu Awano",
        "authorids": "/37089196138;/37273829100;/38235583600;/37089196138;/37273829100;/38235583600",
        "aff": "Department of Information Systems Engineering, Graduate School of Information Science and Technology, Osaka University, Osaka, Japan; Department of Intermedia Art and Science, School of Fundamental Science and Engineering, Waseda University, Tokyo, Japan; Department of Communication and Computer Engineering, Graduate School of Infomatics, Kyoto University, Kyoto, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636825/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15049544977990427881&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Osaka University;Waseda University;Kyoto University",
        "aff_unique_dep": "Department of Information Systems Engineering;Department of Intermedia Art and Science;Department of Communication and Computer Engineering",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.waseda.jp/top;https://www.kyoto-u.ac.jp",
        "aff_unique_abbr": "Osaka U;Waseda;Kyoto U",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Osaka;Tokyo;Kyoto",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636412",
        "title": "BogieBot: A Climbing Robot in Cluttered Confined Space of Bogies with Ferrous Metal Surfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "Proactive inspection is essential for prediction and prevention of rolling stock component failures. The conventional process for inspecting bogies under trains presents significant challenges for inspectors who need to visually check the tight and cluttered environment. We propose a miniature multi-link climbing robot, called BogieBot, that can be deployed inside the undercarriage areas of trains and other large vehicles for inspection and maintenance purposes. BogieBot can carry a visual sensor or manipulator on its main body. The novel compact design utilises six identical couple joints and two mechanically switchable magnetic grippers that together, empower multi-modal climbing and manipulation. The proposed mechanism is kinematically redundant, allowing the robot to perform self-motions in a tight space and manoeuvre around obstacles. The mechanism design and various analyses on the forward and inverse kinematic, work-space, and self-motions of BogieBot are presented. The robot is demonstrated to perform challenging navigation tasks in different scenarios involving simulated complex environments.",
        "primary_area": "",
        "author": "Mohammad Adinehvand;Ehsan Asadi;Chow Y. Lai;Hamid Khayyam;Kevin Tan;Reza Hoseinnezhad;Mohammad Adinehvand;Ehsan Asadi;Chow Y. Lai;Hamid Khayyam;Kevin Tan;Reza Hoseinnezhad",
        "authorids": "/37088922098;/37829521400;/37086306071;/37572204700;/37089197275;/37300014700;/37088922098;/37829521400;/37086306071;/37572204700;/37089197275;/37300014700",
        "aff": "School of Engineering, RMIT University, Melbourne, Australia; School of Engineering, RMIT University, Melbourne, Australia; University College London, United Kingdom; School of Engineering, RMIT University, Melbourne, Australia; Downer Group, Melbourne, Australia; School of Engineering, RMIT University, Melbourne, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636412/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7708723017642864371&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;2;0",
        "aff_unique_norm": "RMIT University;University College London;Downer Group",
        "aff_unique_dep": "School of Engineering;;",
        "aff_unique_url": "https://www.rmit.edu.au;https://www.ucl.ac.uk;https://www.downergroup.com",
        "aff_unique_abbr": "RMIT;UCL;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Melbourne;",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "Australia;United Kingdom"
    },
    {
        "id": "9636330",
        "title": "Bootstrapped Self-Supervised Training with Monocular Video for Semantic Segmentation and Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "For a robot deployed in the world, it is desirable to have the ability of autonomous learning to improve its initial pre-set knowledge. We formalize this as a bootstrapped self-supervised learning problem where a system is initially bootstrapped with supervised training on a labeled dataset and we look for a self-supervised training method that can subsequently improve the system over the supervised training baseline using only unlabeled data. In this work, we leverage temporal consistency between frames in monocular video to per-form this bootstrapped self-supervised training. We show that a well-trained state-of-the-art semantic segmentation network can be further improved through our method. In addition, we show that the bootstrapped self-supervised training framework can help a network learn depth estimation better than pure supervised training or self-supervised training.",
        "primary_area": "",
        "author": "Yihao Zhang;John J. Leonard;Yihao Zhang;John J. Leonard",
        "authorids": "/37088999548;/37329387400;/37088999548;/37329387400",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636330/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3421814250959276066&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636661",
        "title": "Bootstrapping Motor Skill Learning with Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning a robot motor skill from scratch is impractically slow; so much so that in practice, learning must typically be bootstrapped using human demonstration. However, relying on human demonstration necessarily degrades the autonomy of robots that must learn a wide variety of skills over their operational lifetimes. We propose using kinematic motion planning as a completely autonomous, sample efficient way to bootstrap motor skill learning for object manipulation. We demonstrate the use of motion planners to bootstrap motor skills in two complex object manipulation scenarios with different policy representations: opening a drawer with a dynamic movement primitive representation, and closing a microwave door with a deep neural network policy. We also show how our method can bootstrap a motor skill for the challenging dynamic task of learning to hit a ball off a tee, where a kinematic plan based on treating the scene as static is insufficient to solve the task, but sufficient to bootstrap a more dynamic policy. In all three cases, our method is competitive with human-demonstrated initialization, and significantly out-performs starting with a random policy. This approach enables robots to to efficiently and autonomously learn motor policies for dynamic tasks without human demonstration.",
        "primary_area": "",
        "author": "Ben Abbatematteo;Eric Rosen;Stefanie Tellex;George Konidaris;Ben Abbatematteo;Eric Rosen;Stefanie Tellex;George Konidaris",
        "authorids": "/37089197450;/37086078687;/37402794800;/38318614200;/37089197450;/37086078687;/37402794800;/38318614200",
        "aff": "Department of Computer Science, Brown University, Providence RI; Department of Computer Science, Brown University, Providence RI; Department of Computer Science, Brown University, Providence RI; Department of Computer Science, Brown University, Providence RI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636661/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3613564970562312444&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Brown University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.brown.edu",
        "aff_unique_abbr": "Brown",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Providence",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635991",
        "title": "BundleTrack: 6D Pose Tracking for Novel Objects without Instance or Category-Level 3D Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Tracking the 6D pose of objects in video sequences is important for robot manipulation. Most prior efforts, however, often assume that the target object's CAD model, at least at a category-level, is available for offline training or during online template matching. This work proposes BundleTrack, a general framework for 6D pose tracking of novel objects, which does not depend upon 3D models, either at the instance or category-level. It leverages the complementary attributes of recent advances in deep learning for segmentation and robust feature extraction, as well as memory-augmented pose graph optimization for spatiotemporal consistency. This enables long-term, low-drift tracking under various challenging scenarios, including significant occlusions and object motions. Comprehensive experiments given two public benchmarks demonstrate that the proposed approach significantly outperforms state-of-art, category-level 6D tracking or dynamic SLAM methods. When compared against state-of-art methods that rely on an object instance CAD model, comparable performance is achieved, despite the proposed method\u2019s reduced information requirements. An efficient implementation in CUDA provides a real-time performance of 10Hz for the entire framework. Code is available at: https://github.com/wenbowen123/BundleTrack",
        "primary_area": "",
        "author": "Bowen Wen;Kostas Bekris;Bowen Wen;Kostas Bekris",
        "authorids": "/37088488448;/37282424700;/37088488448;/37282424700",
        "aff": "Computer Science Dept. of Rutgers, NJ, USA; Computer Science Dept. of Rutgers, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635991/",
        "gs_citation": 125,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8262558349595071173&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636022",
        "title": "CCRobot-IV-F: A Ducted-Fan-Driven Flying-Type Bridge-Stay-Cable Climbing Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "A Flying-type cable climbing robot, CCRobot-IV-F, is presented in this paper. It is a climbing precursor of the fourth version of CCRobot, designed to surpass the abilities of previous robots with high climbing speed and obstacle-crossing capability. CCRobot-IV-F weighs less than 10 kg and a no-load speed of up to 4.5 m/s, which significantly exceeds that of other climbing robots. A dynamic model integrated with a cable-fixed coordinate system is developed, and a cascaded controller designed for stabilizing hover and climb with grippers, when a Global Positioning System and magnetometer are unavailable, is shown to work reliably in practice. Experimental results show that CCRobot-IV-F significantly improves the locomotive performance of CCRobot-IV, exhibiting fast speed, good payload capacity, and excellent obstacle-crossing capability. Moreover, CCRobot-IV-F is applied to a cable-stayed bridge in the field.",
        "primary_area": "",
        "author": "Wenchao Zhang;Zhenliang Zheng;Xueqi Fu;Sarsenbek Hazken;Huaping Chen;Min Zhao;Ning Ding;Wenchao Zhang;Zhenliang Zheng;Xueqi Fu;Sarsenbek Hazken;Huaping Chen;Min Zhao;Ning Ding",
        "authorids": "/37089195762;/37086610641;/37085497654;/37089196631;/37089197841;/37089193934;/37086099653;/37089195762;/37086610641;/37085497654;/37089196631;/37089197841;/37089193934;/37086099653",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society, and the Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, and the Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, and the Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, and the Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, and the Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, and the Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, and the Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636022/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13933282405368721475&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong, Shenzhen",
        "aff_unique_dep": "Institute of Robotics and Intelligent Manufacturing",
        "aff_unique_url": "https://www.cuhk.edu.cn",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636253",
        "title": "CFEAR Radarodometry - Conservative Filtering for Efficient and Accurate Radar Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an accurate, highly efficient and learning free method for large-scale radar odometry estimation. By using a simple filtering technique that keeps the strongest returns, we produce a clean radar data representation and reconstruct surface normals for efficient and accurate scan matching. Registration is carried out by minimizing a point-to-line metric and robustness to outliers is achieved using a Huber loss. Drift is additionally reduced by jointly registering the latest scan to a history of keyframes. We found that our odometry pipeline generalize well to different sensor models and datasets without changing a single parameter. We evaluate our method in three widely different environments and demonstrate an improvement over spatially cross validated state-of-the-art with an overall translation error of 1.76% in a public urban radar odometry benchmark, running merely on a single laptop CPU thread at 55 Hz.",
        "primary_area": "",
        "author": "Daniel Adolfsson;Martin Magnusson;Anas Alhashimi;Achim J. Lilienthal;Henrik Andreasson;Daniel Adolfsson;Martin Magnusson;Anas Alhashimi;Achim J. Lilienthal;Henrik Andreasson",
        "authorids": "/37086335293;/37584850000;/37085486579;/37273127300;/37564252100;/37086335293;/37584850000;/37085486579;/37273127300;/37564252100",
        "aff": "MRO lab of the AASS Research Centre at \u00d6rebro University, Sweden; MRO lab of the AASS Research Centre at \u00d6rebro University, Sweden; MRO lab of the AASS Research Centre at \u00d6rebro University, Sweden; MRO lab of the AASS Research Centre at \u00d6rebro University, Sweden; MRO lab of the AASS Research Centre at \u00d6rebro University, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636253/",
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10282051763757128614&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "\u00d6rebro University",
        "aff_unique_dep": "AASS Research Centre",
        "aff_unique_url": "https://www.oru.se",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9636369",
        "title": "CLAMGen: Closed-Loop Arm Motion Generation via Multi-view Vision-Based RL",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a vision-based reinforcement learning (RL) approach for closed-loop trajectory generation in an arm reaching problem. Arm trajectory generation is a fundamental robotics problem which entails finding collision-free paths to move the robot\u2019s body (e.g. arm) in order to satisfy a goal (e.g. place end-effector at a point). While classical methods typically require the model of the environment to solve a planning, search or optimization problem, learning-based approaches hold the promise of directly mapping from observations to robot actions. However, learning a collision-avoidance policy using RL remains a challenge for various reasons, including, but not limited to, partial observability, poor exploration, low sample efficiency, and learning instabilities. To address these challenges, we present a residual-RL method that leverages a greedy goal-reaching RL policy as the base to improve exploration, and the base policy is augmented with residual state-action values and residual actions learned from images to avoid obstacles. Further more, we introduce novel learning objectives and techniques to improve 3D understanding from multiple image views and sample efficiency of our algorithm. Compared to RL baselines, our method achieves superior performance in terms of success rate.",
        "primary_area": "",
        "author": "Iretiayo Akinola;Zizhao Wang;Peter Allen;Iretiayo Akinola;Zizhao Wang;Peter Allen",
        "authorids": "/37086319261;/37088504428;/37280851400;/37086319261;/37088504428;/37280851400",
        "aff": "Department of Computer Science, Columbia University, New York; Department of Computer Science, Columbia University, New York; Department of Computer Science, Columbia University, New York",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636369/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17183378808695373817&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636676",
        "title": "CLINS: Continuous-Time Trajectory Estimation for LiDAR-Inertial System",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a highly accurate continuous-time trajectory estimation framework dedicated to SLAM (Simultaneous Localization and Mapping) applications, which enables fuse high-frequency and asynchronous sensor data effectively. We apply the proposed framework in a 3D LiDAR-inertial system for evaluations. The proposed method adopts a non-rigid registration method for continuous-time trajectory estimation and simultaneously removing the motion distortion in LiDAR scans. Additionally, we propose a two-state continuous-time trajectory correction method to efficiently and efficiently tackle the computationally-intractable global optimization problem when loop closure happens. We examine the accuracy of the proposed approach on several publicly available datasets and the data we collected. The experimental results indicate that the proposed method outperforms the discrete-time methods regarding accuracy especially when aggressive motion occurs. Furthermore, we open source our code at https://github.com/APRIL-ZJU/clins to benefit research community.",
        "primary_area": "",
        "author": "Jiajun Lv;Kewei Hu;Jinhong Xu;Yong Liu;Xiushui Ma;Xingxing Zuo;Jiajun Lv;Kewei Hu;Jinhong Xu;Yong Liu;Xiushui Ma;Xingxing Zuo",
        "authorids": "/37086604079;/37088690855;/37421833200;/37066946100;/37086497943;/37086314032;/37086604079;/37088690855;/37421833200;/37066946100;/37086497943;/37086314032",
        "aff": "April Lab, Zhejiang University, Hangzhou, China; April Lab, Zhejiang University, Hangzhou, China; April Lab, Zhejiang University, Hangzhou, China; April Lab, Zhejiang University, Hangzhou, China; NingboTech University, Ningbo, China; April Lab, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636676/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16179357016761075903&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Zhejiang University;NingboTech University",
        "aff_unique_dep": "April Lab;",
        "aff_unique_url": "http://www.zju.edu.cn;",
        "aff_unique_abbr": "ZJU;",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Hangzhou;Ningbo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636332",
        "title": "CLMM-Net: Robust Cascaded LiDAR Map Matching based on Multi-Level Intensity Map",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR map matching(LMM) is a critical localization technique in autonomous driving while existing methods have problems in terms of both accuracy and robustness when driving in the scenes with poor structure information (e.g. highways). This paper put forward a multi-level intensity map based cascaded network for LiDAR map matching in autonomous driving. The network uses an effective multi-level intensity map representation to compactly encode the appearance and structure information of point clouds, which effectively reduce the position ambiguity in structure-less scenarios. Besides, this method leverages the multi-scale nature of deep neural networks and matches the online LiDAR observation with the offline map in a coarse-to-fine manner so as to balance the time-consuming and precision. Extensive experiments on diverse autonomous driving environments demonstrate the superiority of our proposed method over other existing state-of-the-art methods.",
        "primary_area": "",
        "author": "Kai Chen;Lei He;Xiaofeng Wang;Yuqian Liu;Ming Zhao;Kai Chen;Lei He;Xiaofeng Wang;Yuqian Liu;Ming Zhao",
        "authorids": "/37089194203;/37089196172;/37089197320;/37089194529;/37089193995;/37089194203;/37089196172;/37089197320;/37089194529;/37089193995",
        "aff": "SenseTime Research; SenseTime Research; SenseTime Research; SenseTime Research; SenseTime Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636332/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:3ueRrXf3PTcJ:scholar.google.com/&scioq=CLMM-Net:+Robust+Cascaded+LiDAR+Map+Matching+based+on+Multi-Level+Intensity+Map&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "SenseTime",
        "aff_unique_dep": "SenseTime Research",
        "aff_unique_url": "https://www.sensetime.com",
        "aff_unique_abbr": "SenseTime",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636836",
        "title": "COCOI: Contact-aware Online Context Inference for Generalizable Non-planar Pushing",
        "track": "main",
        "status": "Poster",
        "abstract": "General contact-rich manipulation problems are long-standing challenges in robotics due to the difficulty of understanding complicated contact physics. Deep reinforcement learning (RL) has shown great potential in solving robot manipulation tasks. However, existing RL policies have limited adaptability to environments with diverse dynamics properties, which is pivotal in solving many contact-rich manipulation tasks. In this work, we propose Contact-aware Online COntext Inference (COCOI), a deep RL method that encodes a context embedding of dynamics properties online using contact-rich interactions. We sample sensor data using a novel contact-aware strategy and formulate an interpretable dynamics transition module. We study this method based on a novel and challenging non-planar pushing task, where the robot uses a monocular camera image and wrist force torque sensor reading to push an object to a goal location while keeping it upright. We run extensive experiments to demonstrate the capability of COCOI in a wide range of settings and dynamics properties in simulation, and also in a sim-to-real transfer scenario on a real robot (Webpage: https://context-inference.github.io/).",
        "primary_area": "",
        "author": "Zhuo Xu;Wenhao Yu;Alexander Herzog;Wenlong Lu;Chuyuan Fu;Masayoshi Tomizuka;Yunfei Bai;C. Karen Liu;Daniel Ho;Zhuo Xu;Wenhao Yu;Alexander Herzog;Wenlong Lu;Chuyuan Fu;Masayoshi Tomizuka;Yunfei Bai;C. Karen Liu;Daniel Ho",
        "authorids": "/37086544987;/37085891022;/38251894500;/37089194596;/37089196975;/37281933000;/37086454356;/38240584300;/37267934200;/37086544987;/37085891022;/38251894500;/37089194596;/37089196975;/37281933000;/37086454356;/38240584300;/37267934200",
        "aff": "University of California, Berkeley, Berkeley, CA, USA; Robotics at Google, Mountain View, CA, USA; Everyday Robots, X The Moonshot Factory, Mountain View, CA, USA; Everyday Robots, X The Moonshot Factory, Mountain View, CA, USA; Everyday Robots, X The Moonshot Factory, Mountain View, CA, USA; University of California, Berkeley, Berkeley, CA, USA; Everyday Robots, X The Moonshot Factory, Mountain View, CA, USA; Stanford University, Stanford, CA, USA; Everyday Robots, X The Moonshot Factory, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636836/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8028540802863106229&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;1;0;1;2;1",
        "aff_unique_norm": "University of California, Berkeley;Google;Stanford University",
        "aff_unique_dep": ";Robotics;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.google.com;https://www.stanford.edu",
        "aff_unique_abbr": "UC Berkeley;Google;Stanford",
        "aff_campus_unique_index": "0;1;1;1;1;0;1;2;1",
        "aff_campus_unique": "Berkeley;Mountain View;Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636111",
        "title": "COINet: Adaptive Segmentation with Co-Interactive Network for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic segmentation serves as a cornerstone for safety autonomous driving and has been achieved remarkable progress at the price of dense annotations. Unsupervised domain adaptation was widely utilized to addresses this labor-intensive problem, which transfers the knowledge learned from labeled synthetic datset to real-world without any annotations. However, most existing adaptation works predict the segmentation results and domain identification results separately only with the last-layer feature, and ignore the intrinsic relationship among these two tasks. To address this issue, we present a CO-Interactive Network (COINet) for unsupervised adaptive segmentation. In particular, we propose a scale-aware distilled decoder to integrate multi-scale features dynamically through the designed inter-distilled module (IDM) and obtain fine-grained feature representations. A dual-task classifier is advanced with this decoder, to jointly predict the segmentation results and pixel-wise domain prediction results, which extracts shared complementary information for accurate segmentation. We further devise a co-interactive loss to explicitly model the intrinsic relationship among the segmentation and domain prediction, enabling the feature distribution alignment in pixel-level and an optimal segmentation decision boundary. We demonstrate the effectiveness of the proposed COINet on benchmark adaptation settings with extensive experimental and ablation results, and our model shows favorable performance against existing algorithms.",
        "primary_area": "",
        "author": "Jie Liu;Xiaoqing Guo;Baopu Li;Yixuan Yuan;Jie Liu;Xiaoqing Guo;Baopu Li;Yixuan Yuan",
        "authorids": "/37089197565;/37086608221;/37089613067;/37075918800;/37089197565;/37086608221;/37089613067;/37075918800",
        "aff": "Department of Electrical Engineering, City University of Hong Kong, Hong Kong, China; Department of Electrical Engineering, City University of Hong Kong, Hong Kong, China; Baidu Research, USA; Department of Electrical Engineering, City University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636111/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=460620090457157953&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "City University of Hong Kong;Baidu",
        "aff_unique_dep": "Department of Electrical Engineering;Baidu Research",
        "aff_unique_url": "https://www.cityu.edu.hk;https://research.baidu.com",
        "aff_unique_abbr": "CityU;Baidu Research",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9635839",
        "title": "CORAL: Colored structural representation for bi-modal place recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Place recognition is indispensable for a drift-free localization system. Due to the variations of the environment, place recognition using single-modality has limitations. In this paper, we propose a bi-modal place recognition method, which can extract a compound global descriptor from the two modalities, vision and LiDAR. Specifically, we first build the elevation image generated from 3D points as a structural representation. Then, we derive the correspondences between 3D points and image pixels that are further used in merging the pixel-wise visual features into the elevation map grids. In this way, we fuse the structural features and visual features in the consistent bird-eye view frame, yielding a semantic representation, namely CORAL. And the whole network is called CORAL-VLAD. Comparisons on the Oxford RobotCar show that CORAL-VLAD has superior performance against other state-of-the-art methods. We also demonstrate that our network can be generalized to other scenes and sensor configurations on cross-city datasets.",
        "primary_area": "",
        "author": "Yiyuan Pan;Xuecheng Xu;Weijie Li;Yunxiang Cui;Yue Wang;Rong Xiong;Yiyuan Pan;Xuecheng Xu;Weijie Li;Yunxiang Cui;Yue Wang;Rong Xiong",
        "authorids": "/37087246473;/37087245452;/37089000146;/37089195394;/37072299700;/37271511300;/37087246473;/37087245452;/37089000146;/37089195394;/37072299700;/37271511300",
        "aff": "State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635839/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13598456833320807028&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636347",
        "title": "CORSAIR: Convolutional Object Retrieval and Symmetry-AIded Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers online object-level mapping using partial point-cloud observations obtained online in an unknown environment. We develop an approach for fully Convolutional Object Retrieval and Symmetry-AIded Registration (CORSAIR). Our model extends the Fully Convolutional Geo-metric Features model to learn a global object-shape embedding in addition to local point-wise features from the point-cloud observations. The global feature is used to retrieve a similar object from a category database, and the local features are used for robust pose registration between the observed and the retrieved object. Our formulation also leverages symmetries, present in the object shapes, to obtain promising local-feature pairs from different symmetry classes for matching. We present results from synthetic and real-world datasets with different object categories to verify the robustness of our method.",
        "primary_area": "",
        "author": "Tianyu Zhao;Qiaojun Feng;Sai Jadhav;Nikolay Atanasov;Tianyu Zhao;Qiaojun Feng;Sai Jadhav;Nikolay Atanasov",
        "authorids": "/37089194371;/37087322298;/37089196598;/37670511000;/37089194371;/37087322298;/37089196598;/37670511000",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636347/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13675233749704616323&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636060",
        "title": "CP-loss: Connectivity-preserving Loss for Road Curb Detection in Autonomous Driving with Aerial Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Road curb detection is important for autonomous driving. It can be used to determine road boundaries to constrain vehicles on roads, so that potential accidents could be avoided. Most of the current methods detect road curbs online using vehicle-mounted sensors, such as cameras or 3-D Lidars. However, these methods usually suffer from severe occlusion issues. Especially in highly-dynamic traffic environments, most of the field of view is occupied by dynamic objects. To alleviate this issue, we detect road curbs offline using high-resolution aerial images in this paper. Moreover, the detected road curbs can be used to create high-definition (HD) maps for autonomous vehicles. Specifically, we first predict the pixel-wise segmentation map of road curbs, and then conduct a series of post-processing steps to extract the graph structure of road curbs. To tackle the disconnectivity issue in the segmentation maps, we propose an innovative connectivity-preserving loss (CP-loss) to improve the segmentation performance. The experimental results on a public dataset demonstrate the effectiveness of our proposed loss function. This paper is accompanied with a demonstration video and a supplementary document, which are available at https://sites.google.com/view/cp-loss.",
        "primary_area": "",
        "author": "Zhenhua Xu;Yuxiang Sun;Lujia Wang;Ming Liu;Zhenhua Xu;Yuxiang Sun;Lujia Wang;Ming Liu",
        "authorids": "/37088656714;/37085435479;/37406752700;/37085398677;/37088656714;/37085435479;/37406752700;/37085398677",
        "aff": "Department of Computer Science and Engineering, The Hong Kong University of Science and Technology; Department of Mechanical Engineering, The Hong Kong Polytechnic University; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636060/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8501321659373118805&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Hong Kong Polytechnic University",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ust.hk;https://www.polyu.edu.hk",
        "aff_unique_abbr": "HKUST;PolyU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636722",
        "title": "CR-LSTM: Collision-prior Guided Social Refinement for Pedestrian Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Pedestrian trajectory prediction is a challenge because of the complex social interactions in context and the elusive intention of each pedestrian. Collision avoidance is one of the most common social interactions in real world, while existing data-driven works have not handled it well yet. In order to address this issue, we propose a framework that considers the theory about the minimum distance between each pedestrian-pedestrian pair and the corresponding time as the collision related prior knowledge. With the prior, our social refinement module, called Collision-prior Guided Refinement, can be guided to understand the collision situations of a crowd through a message passing mechanism. To focus on more useful information from context, we also introduce pedestrian-wise attention and collision gate to jointly judge collision potential for all pedestrian-pedestrian pairs. Experimental results demonstrate that our framework can achieve competitive results on ETH and UCY datasets by comparing with existing works. In addition, it indicates the superiority of our framework in the aspect of collision avoidance.",
        "primary_area": "",
        "author": "Zhaoxin Su;Sanyuan Zhang;Wei Hua;Zhaoxin Su;Sanyuan Zhang;Wei Hua",
        "authorids": "/37089197991;/37277714600;/37089196345;/37089197991;/37277714600;/37089196345",
        "aff": "College of Computer Science and Technology, Zhejiang University, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Zhejiang Lab, Institute of Artifical Intelligence, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636722/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12509235558524215413&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Zhejiang University;Zhejiang Lab",
        "aff_unique_dep": "College of Computer Science and Technology;Institute of Artifical Intelligence",
        "aff_unique_url": "http://www.zju.edu.cn;",
        "aff_unique_abbr": "ZJU;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636803",
        "title": "CRACT: Cascaded Regression-Align-Classification for Robust Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "High quality object proposals are crucial in visual tracking algorithms that utilize region proposal network (RPN). Refinement of these proposals, typically by box regression and classification in parallel, has been popularly adopted to boost tracking performance. However, it still meets problems when dealing with complex and dynamic background. Thus motivated, in this paper we introduce an improved proposal refinement module, Cascaded Regression-Align-Classification (CRAC), which yields new state-of-the-art performances on many benchmarks.First, having observed that the offsets from box regression can serve as guidance for proposal feature refinement, we design CRAC as a cascade of box regression, feature alignment and box classification. The key is to bridge box regression and classification via an alignment step, which leads to more accurate features for proposal classification with improved robustness. To address the variation in object appearance, we introduce an identification-discrimination component for box classification, which leverages offline reliable fine-grained template and online rich background information to distinguish the target from background. Moreover, we present pyramid RoIAlign that benefits CRAC by exploiting both the local and global cues of proposals. During inference, tracking proceeds by ranking all refined proposals and selecting the best one. In experiments on seven benchmarks including OTB-2015, UAV123, NfS, VOT-2018, TrackingNet, GOT-10k and LaSOT, our CRACT exhibits very promising results in comparison with state-of-the-art competitors and runs in real-time at 28 fps.",
        "primary_area": "",
        "author": "Heng Fan;Haibin Ling;Heng Fan;Haibin Ling",
        "authorids": "/37085561988;/37291439800;/37085561988;/37291439800",
        "aff": "Department of Computer Science, Stony Brook University, Stony Brook, NY, USA; Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636803/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14482589800855719178&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stony Brook University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.stonybrook.edu",
        "aff_unique_abbr": "SBU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stony Brook",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636069",
        "title": "CRIL: Continual Robot Imitation Learning via Generative and Prediction Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Imitation learning (IL) algorithms have shown promising results for robots to learn skills from expert demonstrations. However, they need multi-task demonstrations to be provided at once for acquiring diverse skills, which is difficult in real world. In this work we study how to realize continual imitation learning ability that empowers robots to continually learn new tasks one by one, thus reducing the burden of multitask IL and accelerating the process of new task learning at the same time. We propose a novel trajectory generation model that employs both a generative adversarial network and a dynamics-aware prediction model to generate pseudo trajectories from all learned tasks in the new task learning process. Our experiments on both simulation and real-world manipulation tasks demonstrate the effectiveness of our method.",
        "primary_area": "",
        "author": "Chongkai Gao;Haichuan Gao;Shangqi Guo;Tianren Zhang;Feng Chen;Chongkai Gao;Haichuan Gao;Shangqi Guo;Tianren Zhang;Feng Chen",
        "authorids": "/37089195376;/37088691157;/37086553300;/37088212536;/37536944100;/37089195376;/37088691157;/37086553300;/37088212536;/37536944100",
        "aff": "Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; LSBDPA Beijing Key Laboratory, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636069/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=545635070697901508&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Tsinghua University;LSBDPA Beijing Key Laboratory",
        "aff_unique_dep": "Department of Automation;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;",
        "aff_unique_abbr": "THU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636806",
        "title": "Camera Parameters Aware Motion Segmentation Network with Compensated Optical Flow",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning to distinguish independent moving objects from the observed optical flow with a moving camera remains challenging. In this work, we first present a novel camera pose compensation (CPC) scheme. With the help of ingenious geometric analysis, it breaks the observed optical flow into patterns that are easier to interpret for the motion segmentation network. Secondly, we further refine such compensation with a camera parameter aware (CPA) module to account for poses\u2019 errors in the CPC processing and enhance the entire network\u2019s tolerance to noises. Additionally, an MMPNet is developed to intensify the identification ability of overall motion patterns. It reaches a larger receptive field with a bottom-up information transmission structure and integrates motion information at different granularities. We demonstrate the benefits of our framework on FlyingThings3D and Monkaa datasets. Without the complement of semantic information, our approach outperforms the top methods for moving objects segmentation.",
        "primary_area": "",
        "author": "Xianshun Wang;Dongchen Zhu;Shaojie Xu;Wenjun Shi;Yanqing Liu;Jiamao Li;Xiaolin Zhang;Xianshun Wang;Dongchen Zhu;Shaojie Xu;Wenjun Shi;Yanqing Liu;Jiamao Li;Xiaolin Zhang",
        "authorids": "/37086823920;/37086420004;/37089197037;/37086421586;/37086418759;/37086083391;/37085830972;/37086823920;/37086420004;/37089197037;/37086421586;/37086418759;/37086083391;/37085830972",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences, Beijing, China; Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences; Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology, Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences; University of Chinese Academy of Sciences, Beijing, China; ShanghaiTech University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636806/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5982668208834786704&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;1;1;0;2",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Shanghai Institute of Microsystem and Information Technology;ShanghaiTech University",
        "aff_unique_dep": ";Bionic Vision System Laboratory, State Key Laboratory of Transducer Technology;",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.sIMIT.ac.cn;http://www.shanghaitech.edu.cn",
        "aff_unique_abbr": "UCAS;;ShanghaiTech",
        "aff_campus_unique_index": "0;0;0;2",
        "aff_campus_unique": "Beijing;;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636500",
        "title": "Can A Vibrotactile Stimulation On Fingertips Make An Illusion Of Elbow Joint Movement?",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditionally vibrotactile feedback delivered by haptic interfaces is used to provide additional support for visual interaction via prehensile object manipulation using fingers. Nevertheless, haptic stimuli can be also applied for non-prehensile interaction that involves movements of the elbow joint. In this paper, we have designed a table-top haptic device that provides vibrotactile stimulation to the user\u2019s fingertips. This stimulation creates a kinesthetic illusion of the user\u2019s forearm pivot movement with respect to the elbow joint. The vibrotactile stimulation is amplified by the pseudo-haptic effect delivered through a head-mounted display (HMD). The efficacy of the approach was validated in experiments with human subjects. The results show that the combination of pseudo-haptic and haptic illusion effects can be used to render various soft and rigid virtual objects.",
        "primary_area": "",
        "author": "Dinmukhammed Mukashev;Adilzhan Adilkhanov;Zhanat Kappassov;Dinmukhammed Mukashev;Adilzhan Adilkhanov;Zhanat Kappassov",
        "authorids": "/37089197588;/37086820373;/37075692900;/37089197588;/37086820373;/37075692900",
        "aff": "Department of Robotics and Mechatronics, School of Engineering and Digital Sciences, Nazarbayev University, Nur-Sultan, Kazakhstan; Department of Robotics and Mechatronics, School of Engineering and Digital Sciences, Nazarbayev University, Nur-Sultan, Kazakhstan; Department of Robotics and Mechatronics, School of Engineering and Digital Sciences, Nazarbayev University, Nur-Sultan, Kazakhstan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636500/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3583759760750424975&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nazarbayev University",
        "aff_unique_dep": "Department of Robotics and Mechatronics",
        "aff_unique_url": "https://www.nu.edu.kz",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nur-Sultan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Kazakhstan"
    },
    {
        "id": "9636123",
        "title": "Capacitated Vehicle Routing with Target Geometric Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate the capacitated vehicle routing problem (CVRP) under a robotics context, where a vehicle with limited payload must complete delivery (or pickup) tasks to serve a set of geographically distributed customers with varying demands. In classical CVRP, a customer location is modeled as a point. In many robotics applications, however, it is more appropriate to model such \"customer locations\" as 2D regions. For example, in aerial delivery, a drone may drop a package anywhere in a customer\u2019s lot. This yields the problem of CVRG (Capacitated Vehicle Routing with Target Geometric Constraints). Computationally, CVRP is already strongly NPhard; CVRG is therefore more challenging. Nevertheless, we develop fast algorithms for CVRG, capable of computing high quality solutions for hundreds of regions. Our algorithmic solution is guaranteed to be optimal when customer regions are convex. Numerical evaluations show that our proposed methods significantly outperform greedy best-first approaches. Comprehensive simulation studies confirm the effectiveness of our methods.",
        "primary_area": "",
        "author": "Kai Gao;Jingjin Yu;Kai Gao;Jingjin Yu",
        "authorids": "/37088997464;/37536570700;/37088997464;/37536570700",
        "aff": "Department of Computer Science, Rutgers University at New Brunswick; Department of Computer Science, Rutgers University at New Brunswick",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636123/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10184390881099628592&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636850",
        "title": "Capturing Skill State in Curriculum Learning for Human Skill Acquisition",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans learn complex motor skills with practice and training. Though the learning process is not fully understood, several theories from motor learning, neuroscience, education, and game design suggest that curriculum-based training may be the key to efficient skill acquisition. However, designing such a curriculum and understanding its effects on learning are challenging problems. In this paper, we define the Human-skill Curriculum Markov Decision Process (H-CMDP) to systematize the design of training protocols. We also identify a vocabulary of performance features to enable the approximation for a human\u2019s skill level across a variety of cognitive and motor tasks. A novel task domain is introduced as a testbed to evaluate the effectiveness of our approach. Human subject experiments show that (1) participants can learn to improve their performance in tasks within this domain, (2) the learning is quantifiable via our performance features, and (3) the domain is flexible enough to create distinct levels of difficulty. The long-term goal of this work is to systematize the process of curriculum-based training toward the design of protocols for robot-mediated rehabilitation.",
        "primary_area": "",
        "author": "Keya Ghonasgi;Reuth Mirsky;Sanmit Narvekar;Bharath Masetty;Adrian M. Haith;Peter Stone;Ashish D. Deshpande;Keya Ghonasgi;Reuth Mirsky;Sanmit Narvekar;Bharath Masetty;Adrian M. Haith;Peter Stone;Ashish D. Deshpande",
        "authorids": "/37086480491;/37089195703;/37085775966;/37089196536;/37947191500;/37269574900;/37405479700;/37086480491;/37089195703;/37085775966;/37089196536;/37947191500;/37269574900;/37405479700",
        "aff": "Mechanical Engineering Department, Rehabilitation and Neuromuscular Robotics Lab, The University of Texas at Austin, TX, USA; Computer Science Department, Learning Agents Research Group, The University of Texas at Austin, TX, USA; Computer Science Department, Learning Agents Research Group, The University of Texas at Austin, TX, USA; Mechanical Engineering Department, Rehabilitation and Neuromuscular Robotics Lab, The University of Texas at Austin, TX, USA; Neuroscience Department, BLAM Lab, Johns Hopkins University, MD, USA; Sony AI; Mechanical Engineering Department, Rehabilitation and Neuromuscular Robotics Lab, The University of Texas at Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636850/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2981244322851094342&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;0",
        "aff_unique_norm": "University of Texas at Austin;Johns Hopkins University;Sony",
        "aff_unique_dep": "Mechanical Engineering Department;Neuroscience Department;Sony AI",
        "aff_unique_url": "https://www.utexas.edu;https://www.jhu.edu;https://www.sony.com",
        "aff_unique_abbr": "UT Austin;JHU;Sony AI",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Austin;Baltimore;",
        "aff_country_unique_index": "0;0;0;0;0;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9636503",
        "title": "Car Racing Line Optimization with Genetic Algorithm using Approximate Homeomorphism",
        "track": "main",
        "status": "Poster",
        "abstract": "In every timed car race, the goal is to drive through the racing track as fast as possible. The total time depends on selection of the racing line. Following a better racing line often decides who wins. In this paper, we solve the optimal racing line problem using a genetic algorithm. We propose a novel racing line encoding based on a homeomorphic transformation called Matryoshka mapping. We evaluate the fitness of racing lines by lap time estimation using a vehicle model suitable for F1/10 autonomous racing competition. By comparing to the former state-of-the-art, we show that our method is able to find racing lines with lower lap times. Specifically, on one of the testing tracks, we achieve 2.5% improvement.",
        "primary_area": "",
        "author": "Jaroslav Klap\u00e1lek;Anton\u00edn Nov\u00e1k;Michal Sojka;Zden\u011bk Hanz\u00e1lek;Jaroslav Klap\u00e1lek;Anton\u00edn Nov\u00e1k;Michal Sojka;Zden\u011bk Hanz\u00e1lek",
        "authorids": "/37089194709;/38243137400;/37298816300;/37284758900;/37089194709;/38243137400;/37298816300;/37284758900",
        "aff": "Department of Control Engineering, Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; Department of Control Engineering, Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics (CIIRC), Czech Technical University in Prague, Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics (CIIRC), Czech Technical University in Prague, Prague, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636503/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10601801557036316897&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Department of Control Engineering",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "9635837",
        "title": "Casting manipulation of unknown string by robot arm",
        "track": "main",
        "status": "Poster",
        "abstract": "Casting manipulation has been studied to expand the robot\u2019s movable range. In this manipulation, the robot throws and reaches the end effector to a distant target. Usually, a special casting manipulator, which consists of rigid arm links and specific flexible linear objects, is constructed for an effective casting manipulation. However, the special manipulator cannot perform normal manipulations, such as picking and placing, grasping, and operating objects. We propose that the normal robot arm, which can perform normal tasks, picks up an unknown string in the surrounding environment and realizes casting manipulation with it. As the properties of the string are not provided in advance, it is crucial how to reflect it in casting manipulation. This is realized by the motion generation of the robot arm with the simulation of string movement, actual string manipulation by the robot arm, and string parameter estimation from the actual string movement. After repeating these three steps, the simulated string movement approximates the actual to realize casting manipulation with the unknown string. We confirmed the effectiveness of the proposed method through experiments. The try of this study will lead to enhancement of the performance of home service robot, exploration robot, rescue robot and entertainment robot.",
        "primary_area": "",
        "author": "Kenta Tabata;Hiroaki Seki;Tokuo Tsuji;Tatsuhiro Hiramitsu;Kenta Tabata;Hiroaki Seki;Tokuo Tsuji;Tatsuhiro Hiramitsu",
        "authorids": "/37089194497;/37302257200;/37650707900;/37089271181;/37089194497;/37302257200;/37650707900;/37089271181",
        "aff": "Kenta Tabata; Hiroaki Seki; Tokuo Tsuji; Tatsuhiro Hiramitsu",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635837/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11104688630959024525&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9636212",
        "title": "Category-Level 6D Object Pose Estimation via Cascaded Relation and Recurrent Reconstruction Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Category-level 6D pose estimation, aiming to predict the location and orientation of unseen object instances, is fundamental to many scenarios such as robotic manipulation and augmented reality, yet still remains unsolved. Precisely recovering instance 3D model in the canonical space and accurately matching it with the observation is an essential point when estimating 6D pose for unseen objects. In this paper, we achieve accurate category-level 6D pose estimation via cascaded relation and recurrent reconstruction networks. Specifically, a novel cascaded relation network is dedicated for advanced representation learning to explore the complex and informative relations among instance RGB image, instance point cloud and category shape prior. Furthermore, we design a recurrent reconstruction network for iterative residual refinement to progressively improve the reconstruction and correspondence estimations from coarse to fine. Finally, the instance 6D pose is obtained leveraging the estimated dense correspondences between the instance point cloud and the reconstructed 3D model in the canonical space. We have conducted extensive experiments on two well-acknowledged benchmarks of category-level 6D pose estimation, with significant performance improvement over existing approaches. On the representatively strict evaluation metrics of 3D75 and 5\u00b02cm, our method exceeds the latest state-of-the-art SPD [1] by 4.9% and 17.7% on the CAMERA25 dataset, and by 2.7% and 8.5% on the REAL275 dataset. Codes are avaliable at https://wangjiaze.cn/projects/6DPoseEstimation.html.",
        "primary_area": "",
        "author": "Jiaze Wang;Kai Chen;Qi Dou;Jiaze Wang;Kai Chen;Qi Dou",
        "authorids": "/37088230311;/37404002500;/37085465414;/37088230311;/37404002500;/37085465414",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong SAR, China; T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636212/",
        "gs_citation": 114,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13287115900202829799&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636349",
        "title": "Centralizing State-Values in Dueling Networks for Multi-Robot Reinforcement Learning Mapless Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of multi-robot mapless navigation in the popular Centralized Training and Decentralized Execution (CTDE) paradigm. This problem is challenging when each robot considers its path without explicitly sharing observations with other robots and can lead to non-stationary issues in Deep Reinforcement Learning (DRL). The typical CTDE algorithm factorizes the joint action-value function into individual ones, to favor cooperation and achieve decentralized execution. Such factorization involves constraints (e.g., monotonicity) that limit the emergence of novel behaviors in an individual as each agent is trained starting from a joint action-value. In contrast, we propose a novel architecture for CTDE that uses a centralized state-value network to compute a joint state-value, which is used to inject global state information in the value-based updates of the agents. Consequently, each model computes its gradient update for the weights, considering the overall state of the environment. Our idea follows the insights of Dueling Networks as a separate estimation of the joint state-value has both the advantage of improving sample efficiency, while providing each robot information whether the global state is (or is not) valuable. Experiments in a robotic navigation task with 2 4, and 8 robots, confirm the superior performance of our approach over prior CTDE methods (e.g., VDN, QMIX).",
        "primary_area": "",
        "author": "Enrico Marchesini;Alessandro Farinelli;Enrico Marchesini;Alessandro Farinelli",
        "authorids": "/37086805241;/37266396700;/37086805241;/37266396700",
        "aff": "Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636349/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15495756425926421244&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Verona",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.univr.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Verona",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636350",
        "title": "ChangeSim: Towards End-to-End Online Scene Change Detection in Industrial Indoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a challenging dataset, ChangeSim, aimed at online scene change detection (SCD) and more. The data is collected in photo-realistic simulation environments with the presence of environmental non-targeted variations, such as air turbidity and light condition changes, as well as targeted object changes in industrial indoor environments. By collecting data in simulations, multi-modal sensor data and precise ground truth labels are obtainable such as the RGB image, depth image, semantic segmentation, change segmentation, camera poses, and 3D reconstructions. While the previous online SCD datasets evaluate models given well-aligned image pairs, ChangeSim also provides raw unpaired sequences that present an opportunity to develop an online SCD model in an end-to-end manner, considering both pairing and detection. Experiments show that even the latest pair-based SCD models suffer from the bottleneck of the pairing process, and it gets worse when the environment contains the non-targeted variations. Our dataset is available at https://sammica.github.io/ChangeSim/.",
        "primary_area": "",
        "author": "Jin-Man Park;Jae-Hyuk Jang;Sahng-Min Yoo;Sun-Kyung Lee;Ue-Hwan Kim;Jong-Hwan Kim;Jin-Man Park;Jae-Hyuk Jang;Sahng-Min Yoo;Sun-Kyung Lee;Ue-Hwan Kim;Jong-Hwan Kim",
        "authorids": "/37086125349;/37089197404;/37088878105;/37087125042;/37085896789;/37281186400;/37086125349;/37089197404;/37088878105;/37087125042;/37085896789;/37281186400",
        "aff": "School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; School of Electrical Engineering, KAIST, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636350/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15626292921467689801&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "KAIST",
        "aff_unique_dep": "School of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636476",
        "title": "Circumventing Conceptual Flaws in Classical Interaction Control Strategies",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the problem of interaction control based on force and velocity measurements. Without restricting ourselves to fixed control structures such as admittance or impedance control, we consider the general topology of the problem. Adopting the idea of Youla-based 2DOF control, we reveal a generic control architecture that splits the problem into two independent parts: nominal admittance shaping and disturbance rejection. This pinpoints conceptual flaws in classical interaction control architectures and suggests a way to circumvent them. As a by-product, a complete and compact parameterization of all achievable admittances is derived. The potential of the proposed architecture for analysis and controller design is demonstrated and validated experimentally.",
        "primary_area": "",
        "author": "Maxim Kristalny;Jang Ho Cho;Maxim Kristalny;Jang Ho Cho",
        "authorids": "/37846431000;/37085573278;/37846431000;/37085573278",
        "aff": "Faculty of Mechanical Engineering, Technion-IIT and Rafael-ADS Ltd., Haifa, Israel; Department of Medical Assistive Robotics, Korea Institute of Machinery & Materials, Daegu, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636476/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10014224134253618061&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Technion-IIT;Korea Institute of Machinery & Materials",
        "aff_unique_dep": "Faculty of Mechanical Engineering;Department of Medical Assistive Robotics",
        "aff_unique_url": "https://www.technion.ac.il;http://www.kimm.co.kr",
        "aff_unique_abbr": "Technion;KIMM",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Haifa;Daegu",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Israel;South Korea"
    },
    {
        "id": "9636736",
        "title": "Class-Ordered LPA*: An Incremental-Search Algorithm for Weighted Colored Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Replanning is an essential problem for robots operating in a dynamic and complex environment for responsive and robust autonomy. Previous incremental-search algorithms efficiently reuse existing search results to facilitate a new plan when the environment changes. Yet, they rely solely on geometric information of the environment encoded in an edge-weighted graph. However, semantic information often provides valuable insights that cannot easily be captured quantitatively. We encode both semantic and geometric information of the environment in a weighted colored graph, in which the edges are partitioned into a finite set of ordered semantic classes (e.g., colors), and then we incrementally search for the shortest path among the set of paths with minimal inclusion of inferior classes, using information from the previous search using ideas similar to LPA*. The proposed Class-Ordered LPA* (COLPA*) algorithm inherits the strong theoretical properties of LPA*, namely, optimality and efficiency, but optimality now is with respect to the total path order. Numerical examples show that semantic information helps reduce the relevant search space in a dynamic environment.",
        "primary_area": "",
        "author": "Jaein Lim;Oren Salzman;Panagiotis Tsiotras;Jaein Lim;Oren Salzman;Panagiotis Tsiotras",
        "authorids": "/37088506597;/37077497700;/37330609800;/37088506597;/37077497700;/37330609800",
        "aff": "School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Henry and Marilyn Taub Faculty of Computer Science, Technion, Haifa, Israel; Daniel Guggenheim School of Aerospace Engineering and the Institute for Robotics & Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636736/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15789140170578946928&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Technion",
        "aff_unique_dep": "School of Aerospace Engineering;Henry and Marilyn Taub Faculty of Computer Science",
        "aff_unique_url": "https://www.gatech.edu;https://www.technion.ac.il",
        "aff_unique_abbr": "Georgia Tech;Technion",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Atlanta;Haifa",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "9636566",
        "title": "Climbot-\u03a9: A Soft Robot with Novel Grippers and Rigid-compliantly Constrained Body for Climbing on Various Poles",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft climbing robots have been attracting increasing attention in soft robotics community, and a lot of prototypes been proposed with basic climbing function implemented. Climbing on poles is a challenge with soft robots, and the capability of current pole-climbing soft robots needs to be improved in terms of adaptability to various poles and deformation controllability or constraining of the soft body. In this paper, a rigid-compliant coupling or constraint method is proposed in design of pole climbing robots. Specifically, a novel gripper with inner expanding bubbles and a rigid-compliant belt is presented and designed, featured with excellent shape/size-adaptability and grip-reliability. To constrain undesired deformation of the soft body, rigid-compliant belts are also adopted. Three rigid-compliant constrained actuators are connected to implement an \u03a9-shaped deformation of the body for climbing motion. The kinematic feature of the body is established, and the two main features of the inner expanding gripper are analyzed. A series of experiments, where the robot climbs on poles with different shapes and sizes and in different poses, have verified the effectiveness of the presented rigid-compliant constraint and the shape/size adaptability and grip-reliability of the novel inner expanding grippers.",
        "primary_area": "",
        "author": "Manjia Su;Yu Qiu;Yisheng Guan;Haifei Zhu;Zhi Liu;Manjia Su;Yu Qiu;Yisheng Guan;Haifei Zhu;Zhi Liu",
        "authorids": "/38469204700;/37089194700;/37402001000;/37853668000;/37089196715;/38469204700;/37089194700;/37402001000;/37853668000;/37089196715",
        "aff": "Biomimetic and Intelligent Robotics Lab (BIRL), Guangdong University of Technology, Guangzhou, Guangdong, China; Biomimetic and Intelligent Robotics Lab (BIRL), Guangdong University of Technology, Guangzhou, Guangdong, China; Biomimetic and Intelligent Robotics Lab (BIRL), Guangdong University of Technology, Guangzhou, Guangdong, China; Biomimetic and Intelligent Robotics Lab (BIRL), Guangdong University of Technology, Guangzhou, Guangdong, China; Biomimetic and Intelligent Robotics Lab (BIRL), Guangdong University of Technology, Guangzhou, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636566/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4138399141026471784&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Guangdong University of Technology",
        "aff_unique_dep": "Biomimetic and Intelligent Robotics Lab (BIRL)",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636750",
        "title": "Closed-Loop Robotic Cooking of Scrambled Eggs with a Salinity-based \u2018Taste\u2019 Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "The sense of taste is fundamental to a human chef\u2019s ability to cook tasty food. To develop robots that can demonstrate human-like cooking, robots need to be equipped with a sense of taste and enabled to use this perception capability to improve or understand the food which they are cooking. We propose a first study of using a salinity sensor to provide a robot with a sense of saltiness. We then demonstrate how this artificial taste receptor can be used to create an autonomous closed-loop cooking system that uses a measurement of saltiness to improve the cooking process of preparing scrambled eggs. Specifically, we show that the sensor measurements can be mapped to different taste metrics such as the overall saltiness and state of mixing the eggs, and how the cooking process can be adapted to match a human-cooked dish, hence individual preferences.",
        "primary_area": "",
        "author": "Grzegorz Sochacki;Josie Hughes;Simon Hauser;Fumiya Iida;Grzegorz Sochacki;Josie Hughes;Simon Hauser;Fumiya Iida",
        "authorids": "/37089195244;/37085816016;/38243975000;/37552719700;/37089195244;/37085816016;/38243975000;/37552719700",
        "aff": "Department of Engineering, Bio-Inspired Robotics Laboratory (BIRL), University of Cambridge, UK; Department of Engineering, Bio-Inspired Robotics Laboratory (BIRL), University of Cambridge, UK; Department of Engineering, Bio-Inspired Robotics Laboratory (BIRL), University of Cambridge, UK; Department of Engineering, Bio-Inspired Robotics Laboratory (BIRL), University of Cambridge, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636750/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=108325725798605983&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "Department of Engineering",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636509",
        "title": "Closed-loop Fast Marching Tree (CL-FMT*) with Application to Helicopter Landing Trajectory Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning for complex dynamic systems such as helicopters is a challenging problem due to non-holonomic and nonlinear differential constraints. Approaches for optimal kinodynamics motion planning have only been demonstrated for simple dynamic systems such as Dubins car or linear systems. In this paper we present Closed-loop FMT* (CL-FMT*) which is an extension of FMT* [7] that uses closed-loop prediction. With closed-loop prediction the computationally intense two-point-boundary-value steering procedure can be avoided. We describe the effectiveness of CL-FMT* compared to CL-RRT*. We then demonstrate the use of CL-FMT* for helicopter landing trajectory planning with realistic dynamics constrains.",
        "primary_area": "",
        "author": "Navid Dadkhah Tehrani;Igor Cherepinsky;Sean Carlson;Navid Dadkhah Tehrani;Igor Cherepinsky;Sean Carlson",
        "authorids": "/37088883066;/37424783600;/37088883620;/37088883066;/37424783600;/37088883620",
        "aff": "Sikorsky Aircraft, a Lockheed Martin Company, Stratford, Connecticut, USA; Sikorsky Aircraft, a Lockheed Martin Company, Stratford, Connecticut, USA; Sikorsky Aircraft, a Lockheed Martin Company, Stratford, Connecticut, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636509/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1111726958909671896&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Sikorsky Aircraft",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sikorsky.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636513",
        "title": "Co-design of Embodied Intelligence: A Structured Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of co-designing embodied intelligence as a whole in a structured way, from hardware components such as propulsion systems and sensors to software modules such as control and perception pipelines. We propose a principled approach to formulate and solve complex embodied intelligence co-design problems, leveraging a monotone co-design theory. The methods we propose are intuitive and integrate heterogeneous engineering disciplines, allowing analytical and simulation-based modeling techniques and enabling interdisciplinarity. We illustrate through a case study how, given a set of desired behaviors, our framework is able to compute Pareto efficient solutions for the entire hardware and software stack of a self-driving vehicle.",
        "primary_area": "",
        "author": "Gioele Zardini;Dejan Milojevic;Andrea Censi;Emilio Frazzoli;Gioele Zardini;Dejan Milojevic;Andrea Censi;Emilio Frazzoli",
        "authorids": "/37088597031;/37086937809;/37398994000;/37283368500;/37088597031;/37086937809;/37398994000;/37283368500",
        "aff": "Institute for Dynamic Systems and Control, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Automotive Powertrain Technologies Laboratory, Empa \u2013 Swiss Federal Laboratories for Materials Science and Technology, D\u00fcbendorf, Switzerland; Institute for Dynamic Systems and Control, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Institute for Dynamic Systems and Control, ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636513/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12307765154145019333&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "ETH Zurich;Empa \u2013 Swiss Federal Laboratories for Materials Science and Technology",
        "aff_unique_dep": "Institute for Dynamic Systems and Control;Automotive Powertrain Technologies Laboratory",
        "aff_unique_url": "https://www.ethz.ch;https://www.empa.ch",
        "aff_unique_abbr": "ETHZ;Empa",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Z\u00fcrich;D\u00fcbendorf",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636388",
        "title": "Coarse-to-Fine for Sim-to-Real: Sub-Millimetre Precision Across Wide Task Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the problem of zero-shot sim-to-real when the task requires both highly precise control with sub-millimetre error tolerance, and wide task space generalisation. Our framework involves a coarse-to-fine controller, where trajectories begin with classical motion planning using ICP-based pose estimation, and transition to a learned end-to-end controller which maps images to actions and is trained in simulation with domain randomisation. In this way, we achieve precise control whilst also generalising the controller across wide task spaces, and keeping the robustness of vision-based, end-to-end control. Real-world experiments on a range of different tasks show that, by exploiting the best of both worlds, our framework significantly outperforms purely motion planning methods, and purely learning-based methods. Furthermore, we answer a range of questions on best practices for precise sim-to-real transfer, such as how different image sensor modalities and image feature representations perform.",
        "primary_area": "",
        "author": "Eugene Valassakis;Norman Di Palo;Edward Johns;Eugene Valassakis;Norman Di Palo;Edward Johns",
        "authorids": "/37088689402;/37089196767;/37602799000;/37088689402;/37089196767;/37602799000",
        "aff": "The Robot Learning Lab, Imperial College London; The Robot Learning Lab, Imperial College London; The Robot Learning Lab, Imperial College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636388/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=930297420209512979&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "The Robot Learning Lab",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9635923",
        "title": "Coarse-to-fine Semantic Localization with HD Map for Autonomous Driving in Structural Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust and accurate localization is an essential component for robotic navigation and autonomous driving. The use of cameras for localization with high definition map (HD Map) provides an affordable localization sensor set. Existing methods suffer from pose estimation failure due to error prone data association or initialization with accurate initial pose requirement. In this paper, we propose a cost-effective vehicle localization system with HD map for autonomous driving that uses cameras as primary sensors. To this end, we formulate vision-based localization as a data association problem that maps visual semantics to landmarks in HD map. Specifically, system initialization is finished in a coarse to fine manner by combining coarse GPS (Global Positioning System) measurement and fine pose searching. In tracking stage, vehicle pose is refined by implicitly aligning the semantic segmentation result between image and landmarks in HD maps with photometric consistency. Finally, vehicle pose is computed by pose graph optimization in a sliding window fashion. We evaluate our method on two datasets and demonstrate that the proposed approach yields promising localization results in different driving scenarios. Additionally, our approach is suitable for both monocular camera and multi-cameras that provides flexibility and improves robustness for the localization system.",
        "primary_area": "",
        "author": "Chengcheng Guo;Minjie Lin;Heyang Guo;Pengpeng Liang;Erkang Cheng;Chengcheng Guo;Minjie Lin;Heyang Guo;Pengpeng Liang;Erkang Cheng",
        "authorids": "/37089195855;/37086398776;/37089195905;/37076966700;/37088874018;/37089195855;/37086398776;/37089195905;/37076966700;/37088874018",
        "aff": "NullMax, Shanghai, China; NullMax, Shanghai, China; NullMax, Shanghai, China; NullMax, Shanghai, China; School of Information Engineering, Zhengzhou University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635923/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2165098459027171688&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "NullMax;Zhengzhou University",
        "aff_unique_dep": ";School of Information Engineering",
        "aff_unique_url": ";http://www.zzu.edu.cn",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635850",
        "title": "Cognitive Navigation for Indoor Environment Using Floorplan",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent years have seen the increasing importance of cognitive models for improved robot navigation. In this paper, a novel cognitive navigation package, which consists of topometric map representation and a three-level path planner, is proposed. The topometric maps are built from architectural floor plans with additional features within a limited number of selected regions. The inherent discrepancies between floor plans and the robot\u2019s actual sensory readings are handled by the three-level path planner. The unique feature of this approach is that accurate localization is only required at the selected regions. At the other regions the robot will rely on the guiding directions towards the goal rather than on its accurate position on the map for navigation. Experiments show that our approach can endow a robot with capability for semantic interpretation and localization in unseen and dynamic environments.",
        "primary_area": "",
        "author": "Jun Li;Chee Leong Chan;Jian Le Chan;Zhengguo Li;Kong Wah Wan;Wei Yun Yau;Jun Li;Chee Leong Chan;Jian Le Chan;Zhengguo Li;Kong Wah Wan;Wei Yun Yau",
        "authorids": "/37292366900;/37089194759;/37089193924;/37279074200;/37271975700;/37089198103;/37292366900;/37089194759;/37089193924;/37279074200;/37271975700;/37089198103",
        "aff": "Institute for Infocomm Research, A*STAR, Singapore; Institute for Infocomm Research, A*STAR, Singapore; Institute for Infocomm Research, A*STAR, Singapore; Institute for Infocomm Research, A*STAR, Singapore; Institute for Infocomm Research, A*STAR, Singapore; Institute for Infocomm Research, A*STAR, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635850/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4806204659555090100&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Institute for Infocomm Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.i2r.a-star.edu.sg",
        "aff_unique_abbr": "I2R",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9636409",
        "title": "Collaborative Storytelling with Social Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Storytelling plays a central role in human socializing and entertainment, and research on conducting storytelling with robots is gaining interest. However, much of this research assumes that story content is curated. In this paper, we expand the recently-proposed task of collaborative storytelling, where an intelligent agent and a person collaborate to create a unique story by taking turns adding to it, for application to social robot and consider the design implications that arise. Since latency can be detrimental to human-robot interaction, we examine the performance-latency trade-offs of an existing generate-and-rank-based approach to collaborative storytelling by finding the optimal ranker\u2019s sample size that strikes the best balance between quality and computational cost. We improve on existing evaluation that was previously based on system-generated stories by having human participants play the collaborative storytelling game with our system and comparing the stories they create with our system to a naive baseline. Finally, we conduct a pilot elicitation survey that sheds light on issues to consider when adapting our collaborative storytelling system to a social robot. Our evaluation shows that participants have a positive view of collaborative storytelling with a social robot and consider rich, emoting capabilities to be key to enjoyment.",
        "primary_area": "",
        "author": "Eric Nichols;Leo Gao;Yurii Vasylkiv;Randy Gomez;Eric Nichols;Leo Gao;Yurii Vasylkiv;Randy Gomez",
        "authorids": "/324054555661300;/37089196392;/37085884941;/37979526500;/324054555661300;/37089196392;/37085884941;/37979526500",
        "aff": "Honda Research Institute Japan Co., Ltd; EleutherAI; University of Manitoba; Honda Research Institute Japan Co., Ltd",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636409/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=427091917588839879&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Honda Research Institute Japan Co., Ltd;EleutherAI;University of Manitoba",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.honda-ri.jp/english/;https://www.eleuther.ai;https://umanitoba.ca",
        "aff_unique_abbr": "HRI-JP;EleutherAI;U of M",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "Japan;United States;Canada"
    },
    {
        "id": "9636428",
        "title": "Coloured Petri Nets for Monitoring Human Actions in Flexible Human-Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot collaboration in shared workspaces enables companies to improve efficiency and the quality of work for human workers. A novel research direction in this field is that human and robot dynamically negotiate which actions to perform. This requires the robot to permanently monitor the current task state and actions the human has performed. We envision a system that tracks the task progress based on visual input. We assume that a task specification is provided in terms of a coloured Petri net. The contribution of this paper is twofold. We introduce the notion of emissions for coloured Petri nets that incorporate partial observability and uncertainty. We then show how one can efficiently determine the evolution of the net when a sequence of partial observations is provided. To this end, we determine a small set of transition as candidates in a firing sequence first. Then, transition sequences are sampled to obtain markings compatible with the latest observation. We evaluate our algorithm in a simulated environment on a pick and place task and compare it to an aging-based approach from literature. Results show that our algorithm achieves higher precision compared to the aging-based approach. Running times indicate that the update procedure can run at 15 Hz on average.",
        "primary_area": "",
        "author": "Nico H\u00f6llerich;Dominik Henrich;Nico H\u00f6llerich;Dominik Henrich",
        "authorids": "/37088530193;/37328758200;/37088530193;/37328758200",
        "aff": "Chair for Applied Computer Science III (Robotics and Embedded Systems), University of Bayreuth, Bayreuth, Germany; Chair for Applied Computer Science III (Robotics and Embedded Systems), University of Bayreuth, Bayreuth, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636428/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11779183103453076841&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bayreuth",
        "aff_unique_dep": "Chair for Applied Computer Science III (Robotics and Embedded Systems)",
        "aff_unique_url": "https://www.uni-bayreuth.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bayreuth",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636684",
        "title": "Combined Routing and Scheduling of Heterogeneous Transport and Service Agents",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates servicing waypoints in a wide area using collaborative deployments of vehicles with heterogeneous range and mobility constraints. We formulate a joint planning problem for a single transport truck and multiple service drones in which the truck is constrained to a road and must deploy a team of range-constrained drones to visit waypoints. The need to deploy, collect, and redeploy drones over multiple flights introduces both route finding and scheduling aspects to this problem. We solve large problem instances by decoupling our approach into a service drone route finding phase and a transport truck scheduling phase. Numerical simulations explore the qualitative character of the driving schedule and the quantitative marginal value of adding additional drones to the team as a function of agent number and relative speed. The combination of road network constraints and range constraints make this problem especially relevant to wide area forestry, last-mile delivery, and ecological monitoring applications.",
        "primary_area": "",
        "author": "Saaketh Narayan;James Paulos;Steven W. Chen;Sandeep Manjanna;Vijay Kumar;Saaketh Narayan;James Paulos;Steven W. Chen;Sandeep Manjanna;Vijay Kumar",
        "authorids": "/37089195110;/37085335548;/37086191716;/37072300900;/37280341400;/37089195110;/37085335548;/37086191716;/37072300900;/37280341400",
        "aff": "GRASP Lab, University of Pennsylvania, Philadelphia, PA; GRASP Lab, University of Pennsylvania, Philadelphia, PA; GRASP Lab, University of Pennsylvania, Philadelphia, PA; GRASP Lab, University of Pennsylvania, Philadelphia, PA; GRASP Lab, University of Pennsylvania, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636684/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7958974419668726272&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Lab",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636306",
        "title": "Combined stochastic-deterministic predictive control using local-minima free navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes a model predictive control approach of a wheeled mobile robot based on a local-minima free navigation function. The constructed navigation function includes information on a goal location and obstacles. Novel conservative navigation is introduced that is simple to compute and yields convergent control behavior. To solve the optimization problem the combined optimization is proposed by a fixed candidate set and particle swarm optimization. The efficiency of the proposed approaches is validated on simulations, by experimental results on the Husky A200 mobile robot and comparisons to Stable Sparse RRT planner.",
        "primary_area": "",
        "author": "Gregor Klan\u010dar;Marija Seder;Gregor Klan\u010dar;Marija Seder",
        "authorids": "/37938421600;/38228267600;/37938421600;/38228267600",
        "aff": "Department of System, Control and Cybernetics, Faculty of Elecrical Engineering, University of Ljubljana, Slovenia; Department of Control and Computer Engineering, Faculty of Electrical Engineering and Computing, University of Zagreb, Croatia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636306/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13091603448077508015&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Ljubljana;University of Zagreb",
        "aff_unique_dep": "Department of System, Control and Cybernetics;Department of Control and Computer Engineering",
        "aff_unique_url": "https://www.uni-lj.si;https://www.unizg.hr",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Slovenia;Croatia"
    },
    {
        "id": "9636417",
        "title": "Combining Learning from Demonstration with Learning by Exploration to Facilitate Contact-Rich Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative robots are expected to work alongside humans and directly replace human workers in some cases, thus effectively responding to rapid changes in assembly lines. Current methods for programming contact-rich tasks, particularly in heavily constrained spaces, tend to be fairly inefficient. Therefore, faster and more intuitive approaches are urgently required for robot teaching. This study focuses on combining visual servoing-based learning from demonstration (LfD) and force-based learning by exploration (LbE) to enable the fast and intuitive programming of contact-rich tasks with minimal user efforts. Two learning approaches were developed and integrated into a framework, one relying on human-to-robot motion mapping (visual servoing approach) and the other relying on force-based reinforcement learning. The developed framework implements the noncontact demonstration teaching method based on the visual servoing approach and optimizes the demonstrated robot target positions according to the detected contact state. The developed framework is compared with two most commonly used baseline techniques, i.e., teach pendant-based teaching and hand-guiding teaching. Furthermore, the efficiency and reliability of the framework are validated via comparison experiments involving the teaching and execution of contact-rich tasks. The proposed framework shows the best performance in terms of the teaching time, execution success rate, risk of damage, and ease of use.",
        "primary_area": "",
        "author": "Yunlei Shi;Zhaopeng Chen;Yansong Wu;Dimitri Henkel;Sebastian Riedel;Hongxu Liu;Qian Feng;Jianwei Zhang;Yunlei Shi;Zhaopeng Chen;Yansong Wu;Dimitri Henkel;Sebastian Riedel;Hongxu Liu;Qian Feng;Jianwei Zhang",
        "authorids": "/37088999645;/37404312400;/37089194756;/37089194682;/37085795468;/37088997970;/37088504248;/37281460600;/37088999645;/37404312400;/37089194756;/37089194682;/37085795468;/37088997970;/37088504248;/37281460600",
        "aff": "Agile Robots AG; Department of Informatics, TAMS (Technical Aspects of Multimodal Systems), Universit\u00e4t Hamburg; Technische Universit\u00e4t Munchen; Agile Robots AG; Agile Robots AG; Technische Universit\u00e4t Munchen; Agile Robots AG; Department of Informatics, TAMS (Technical Aspects of Multimodal Systems), Universit\u00e4t Hamburg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636417/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1780725299981791148&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;0;0;2;0;1",
        "aff_unique_norm": "Agile Robots AG;Universit\u00e4t Hamburg;Technische Universit\u00e4t M\u00fcnchen",
        "aff_unique_dep": ";Department of Informatics;",
        "aff_unique_url": "https://www.agilerobots.com;https://www.uni-hamburg.de;https://www.tum.de",
        "aff_unique_abbr": "Agile Robots;UHH;TUM",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";M\u00fcnchen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636208",
        "title": "Communicative Learning with Natural Gestures for Embodied Navigation Agents with Human-in-the-Scene",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot collaboration is an essential re-search topic in artificial intelligence (AI), enabling researchers to devise cognitive AI systems and affords an intuitive means for users to interact with the robot. Of note, communication plays a central role. To date, prior studies in embodied agent navigation have only demonstrated that human languages facilitate communication by instructions in natural languages. Nevertheless, a plethora of other forms of communication is left unexplored. In fact, human communication originated in gestures and oftentimes is delivered through multimodal cues, e.g., \u201cgo there\u201d with a pointing gesture. To bridge the gap and fill in the missing dimension of communication in embodied agent navigation, we propose investigating the effects of using gestures as the communicative interface instead of verbal cues. Specifically, we develop a VR-based 3D simulation environment, named Gesture-based THOR (Ges-THOR), based on AI2-THOR platform. In this virtual environment, a human player is placed in the same virtual scene and shepherds the artificial agent using only gestures. The agent is tasked to solve the navigation problem guided by natural gestures with unknown semantics; we do not use any predefined gestures due to the diversity and versatile nature of human gestures. We argue that learning the semantics of natural gestures is mutually beneficial to learning the navigation task\u2014learn to communicate and communicate to learn. In a series of experiments, we demonstrate that human gesture cues, even without predefined semantics, improve the object-goal navigation for an embodied agent, outperforming various state-of-the-art methods.",
        "primary_area": "",
        "author": "Qi Wu;Cheng-Ju Wu;Yixin Zhu;Jungseock Joo;Qi Wu;Cheng-Ju Wu;Yixin Zhu;Jungseock Joo",
        "authorids": "/37089195796;/37089195529;/37086172463;/37076035400;/37089195796;/37089195529;/37086172463;/37076035400",
        "aff": "UCLA; UCLA; UCLA; UCLA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636208/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7623366130600545696&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636590",
        "title": "CompROS: A composable ROS2 based architecture for real-time embedded robotic development",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot Operating System (ROS) is a de-facto standard robot middleware in many academic and industrial use cases. However, utilizing ROS/ROS2 in safety-critical embedded applications with real-time requirement is challenging because of C1) Non-real-time underlying hardware, C2) No control on the host OS scheduler, C3) Unpredictable dynamic memory allocation, C4) High resource requirement, and C5) Unpredictable execution model for ROS nodes. In this paper, we address these limiting factors by proposing a hardwaresoftware architecture -CompROS- for ROS2 based robotic development in a Multi-Processor System on Chip (MPSoC) platform. The proposed hardware architecture consists of a Hard Real-Time (HRT) RISC-V based subsystem implemented in the Programmable Logic (PL) part of the MPSoC platform, a Soft Real-Time (SRT) ARM-based subsystem in the Processing System (PS) part of the MPSoC platform, and a Non-Real-Time (NRT) PC. While the proposed hardware architecture along with a partitioning layer overcomes the first two limiting factors, the rest are managed by the proposed multi-layer software architecture. We make a bare-metal implementation of XRCE-DDS standard for PL-PS communication, while peer-to-peer PL-PL communication is done through a proposed real-time publish-subscribe approach. The reliable communication for PS-PL communication is done through utilizing C-HEAP protocol. Further, we integrate ROS2 software layers on top of the proposed hardware and software layers. Finally, with respect to C5, we present a real-time execution model of ROS2 nodes by a mapping of ROS2 entities to CompROS entities, which is validated through experimental results. We run ROS2 middleware with an executable size of less than 200 KB on an MPSoC platform.",
        "primary_area": "",
        "author": "Saeid Dehnavi;Martijn Koedam;Andrew Nelson;Dip Goswami;Kees Goossens;Saeid Dehnavi;Martijn Koedam;Andrew Nelson;Dip Goswami;Kees Goossens",
        "authorids": "/37086408769;/37888898600;/37529596200;/37528478600;/37294784500;/37086408769;/37888898600;/37529596200;/37528478600;/37294784500",
        "aff": "Department of Electrical Engineering, Eindhoven University of Technology, The Netherlands; Department of Electrical Engineering, Eindhoven University of Technology, The Netherlands; Department of Electrical Engineering, Eindhoven University of Technology, The Netherlands; Department of Electrical Engineering, Eindhoven University of Technology, The Netherlands; Department of Electrical Engineering, Eindhoven University of Technology, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636590/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6439797034227477811&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Eindhoven University of Technology",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.tue.nl",
        "aff_unique_abbr": "TU/e",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9636670",
        "title": "Comparative Analysis of Control Barrier Functions and Artificial Potential Fields for Obstacle Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Artificial potential fields (APFs) and their variants have been a staple for collision avoidance of mobile robots and manipulators for almost 40 years. Its model-independent nature, ease of implementation, and real-time performance have played a large role in its continued success over the years. Control barrier functions (CBFs), on the other hand, are a more recent development, commonly used to guarantee safety for nonlinear systems in real-time in the form of a filter on a nominal controller. In this paper, we address the connections between APFs and CBFs. At a theoretic level, we show that given a broad class of APFs, one can construct a CBF that guarantees safety. Additionally, we prove that CBFs obtained from these APFs have additional beneficial properties and can be applied to nonlinear systems. Practically, we compare the performance of APFs and CBFs in the context of obstacle avoidance on simple illustrative examples and for a quadrotor with unknown dynamics, both in simulation and on hardware using onboard sensing.",
        "primary_area": "",
        "author": "Andrew Singletary;Karl Klingebiel;Joseph Bourne;Andrew Browning;Phil Tokumaru;Aaron Ames;Andrew Singletary;Karl Klingebiel;Joseph Bourne;Andrew Browning;Phil Tokumaru;Aaron Ames",
        "authorids": "/37086449553;/37089195669;/37086936012;/37089198290;/37089194875;/37300877900;/37086449553;/37089195669;/37086936012;/37089198290;/37089194875;/37300877900",
        "aff": "Andrew Singletary; Karl Klingebiel; Joseph Bourne; Andrew Browning; Phil Tokumaru; Aaron Ames",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636670/",
        "gs_citation": 161,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6740118996033259133&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9635939",
        "title": "Comprehension of Spatial Constraints by Neural Logic Learning from a Single RGB-D Scan",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous industrial assembly relies on the precise measurement of spatial constraints as designed by computer-aided design (CAD) software such as SolidWorks. This paper proposes a framework for an intelligent industrial robot to understand the spatial constraints for model assembly. An extended generative adversary network (GAN) with a 3D long short-term memory (LSTM) network was designed to composite 3D point clouds from a single RGB-D scan. The spatial constraints of the segmented point clouds are identified by a neural-logic network that incorporates general knowledge of spatial constraints in terms of first-order logic. The model was designed to comprehend a complete set of spatial constraints that are consistent with industrial CAD software, including left, right, above, below, front, behind, parallel, perpendicular, concentric, and coincident relations. The accuracy of 3D model composition and spatial constraint identification was evaluated by the RGB-D scans and 3D models in the ABC dataset. The proposed model achieved 57.23% intersection over union (IoU) in 3D model composition, and over 99% in comprehending all spatial constraints.",
        "primary_area": "",
        "author": "Fujian Yan;Dali Wang;Hongsheng He;Fujian Yan;Dali Wang;Hongsheng He",
        "authorids": "/37087244707;/37598466400;/37085561124;/37087244707;/37598466400;/37085561124",
        "aff": "School of Computing, Wichita State University, Wichita, KS, USA; Artificial Intelligence (AI) Team, Oak Ridge National Laboratory (ORNL); School of Computing, Wichita State University, Wichita, KS, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635939/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16645233596161596925&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Wichita State University;Oak Ridge National Laboratory",
        "aff_unique_dep": "School of Computing;Artificial Intelligence (AI) Team",
        "aff_unique_url": "https://www.wichita.edu;https://www.ornl.gov",
        "aff_unique_abbr": "WSU;ORNL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Wichita;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636792",
        "title": "Computational Design of Reconfigurable Underactuated Linkages for Adaptive Grippers",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an optimization-based structural-parametric synthesis method for reconfigurable closed-chain underactuated linkages for robotic systems that physically interact with the environment with an emphasis on adaptive grasping. The key idea is to implement morphological computation concepts to keep both necessary trajectory-specific holonomic constraints and mechanism adaptivity using variable length links (VLL), while we evolve from a fully actuated to an underactuated system satisfying imposed design requirements. It allows to minimize the number of actuators, weight, and cost but keep high payload and endurance that are not reachable by tendon-driven designs. Despite the method is general enough, for clarity, we demonstrate its use on a number of finger mechanisms for adaptive grippers.",
        "primary_area": "",
        "author": "Ivan I. Borisov;Evgenii E. Khomutov;Sergey A. Kolyubin;Stefano Stramigioli;Ivan I. Borisov;Evgenii E. Khomutov;Sergey A. Kolyubin;Stefano Stramigioli",
        "authorids": "/37086250938;/37089197572;/37887676700;/37282439300;/37086250938;/37089197572;/37887676700;/37282439300",
        "aff": "Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Department of Electrical Engineering, Mathematics and Computer Science, University of Twente, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636792/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8132267747697348427&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "ITMO University;University of Twente",
        "aff_unique_dep": "Biomechatronics and Energy-Efficient Robotics Lab;Department of Electrical Engineering, Mathematics and Computer Science",
        "aff_unique_url": "https://www.itmo.ru;https://www.utwente.nl",
        "aff_unique_abbr": "ITMO;UT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Saint Petersburg;",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Russian Federation;Netherlands"
    },
    {
        "id": "9636013",
        "title": "Computationally Affordable Hierarchical Framework for Humanoid Robot Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a hierarchical control framework for generating versatile motions by a humanoid robot. The central feature of our framework is computational affordability: a large amount of computation time is allowable in the upper-level hierarchy. Consequently, whole-body trajectory optimization for a long time horizon becomes feasible. To ensure such affordability, a fast feedback loop is established in the lower-level hierarchy to increase the robustness against the large latency in the upper level. We experimentally examined the advantages of the achieved computational affordability. Our framework allowed a large computational time of 100 ms in each control cycle. This enables online trajectory optimization to predict 50 time steps ahead while taking full-body dynamics into account. Due to such a long prediction range, 20 motions were successfully generated in real time with our computation-ally affordable framework.",
        "primary_area": "",
        "author": "Koji Ishihara;Jun Morimoto;Koji Ishihara;Jun Morimoto",
        "authorids": "/37085707763;/37282128500;/37085707763;/37282128500",
        "aff": "Department of Brain Robot Interface, ATR Computational Neuroscience Laboratories, Kyoto, Japan; School of Informatics, Kyoto University, Kyoto, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636013/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15842477518261963012&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "ATR Computational Neuroscience Laboratories;Kyoto University",
        "aff_unique_dep": "Department of Brain Robot Interface;School of Informatics",
        "aff_unique_url": "https://www.atr.jp/en/research/labs/cnl/;https://www.kyoto-u.ac.jp",
        "aff_unique_abbr": "ATR-CNL;Kyoto U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kyoto",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636867",
        "title": "Computationally Efficient HQP-based Whole-body Control Exploiting the Operational-space Formulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel and practical approach to enhance the computational efficiency of the hierarchical quadratic programming (HQP)-based whole-body control. The HQP method is known to offer control solutions satisfying strict priority with various constraints for multiple-tasks execution. However, it inherently comes at the price of high computation time to solve QP optimization problems in each hierarchical level which limits practicability in a real-time control system with fast sampling time. To mitigate this issue, we propose that the operational space formulation is incorporated into the HQP method, where the decision variables are intuitively defined at the task level and possess smaller dimensions. Indeed, it serves faster whole-body control solution for multiple tasks under equality and inequality constraints yet strictly fulfilling the task priority. The performance of the pro-posed method is experimentally verified on the actual floating-based humanoid, named TOCABI with 33 degrees-of-freedom. In addition, computation time is analyzed by comparison with conventional HQP and other advanced implementation forms.",
        "primary_area": "",
        "author": "Yisoo Lee;Junewhee Ahn;Jinoh Lee;Jaeheung Park;Yisoo Lee;Junewhee Ahn;Jinoh Lee;Jaeheung Park",
        "authorids": "/38240852700;/37089197761;/37085391573;/37281014000;/38240852700;/37089197761;/37085391573;/37281014000",
        "aff": "Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology (KIST), Seoul, South Korea; Graduate School of Convergence Science and Technology, Seoul National University (SNU), Seoul, Republic of Korea; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), We\u00dfling, Germany; Graduate School of Convergence Science and Technology, Seoul National University (SNU), Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636867/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9895997092066265169&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Korea Institute of Science and Technology;Seoul National University;German Aerospace Center",
        "aff_unique_dep": "Center for Intelligent and Interactive Robotics;Graduate School of Convergence Science and Technology;Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.kist.re.kr;https://www.snu.ac.kr;https://www.dlr.de",
        "aff_unique_abbr": "KIST;SNU;DLR",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Seoul;We\u00dfling",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "South Korea;Germany"
    },
    {
        "id": "9636197",
        "title": "Computing a Task-Dependent Grasp Metric Using Second-Order Cone Programs",
        "track": "main",
        "status": "Poster",
        "abstract": "Evaluating a grasp generated by a set of hand-object contact locations is a key component of many grasp planning algorithms. In this paper, we present a novel second-order cone program (SOCP) based optimization formulation for evaluating a grasps\u2019 ability to apply wrenches to generate a linear motion along a given direction and/or an angular motion about the given direction. Our quality measure can be computed efficiently since the SOCP is a convex optimization problem, which can be solved optimally with interior point methods. A key feature of our approach is that we can consider the effect of contact wrenches from any contact of the object with the environment. This is different from the extant literature where only the effect of finger-object contacts is considered. Exploiting the environmental contact is useful in many manipulation scenarios either to enhance the dexterity of simple hands or improve the payload capability of the manipulator. In contrast to most existing approaches, our approach also takes into account the practical constraint that the maximum contact force that can be applied at a finger-object contact can be different for each contact. We can also include the effect of external forces like gravity, as well as the joint torque constraints of the fingers/manipulators. Furthermore, for a given motion path as a constant screw motion or a sequence of constant screw motions, we can discretize the path and compute a global grasp metric to accomplish the whole task with a chosen set of finger-object contact locations.",
        "primary_area": "",
        "author": "Amin Fakhari;Aditya Patankar;Jiayin Xie;Nilanjan Chakraborty;Amin Fakhari;Aditya Patankar;Jiayin Xie;Nilanjan Chakraborty",
        "authorids": "/37088377881;/312854643498475;/37086160608;/37314871600;/37088377881;/312854643498475;/37086160608;/37314871600",
        "aff": "Department of Mechanical Engineering, Stony Brook University, NY, USA; Department of Mechanical Engineering, Stony Brook University, NY, USA; Department of Mechanical Engineering, Stony Brook University, NY, USA; Department of Mechanical Engineering, Stony Brook University, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636197/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3772276158217932544&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Stony Brook University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stonybrook.edu",
        "aff_unique_abbr": "SBU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stony Brook",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636039",
        "title": "Connecting Deep-Reinforcement-Learning-based Obstacle Avoidance with Conventional Global Planners using Waypoint Generators",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Reinforcement Learning has emerged as an efficient dynamic obstacle avoidance method in highly dynamic environments. It has the potential to replace overly conservative or inefficient navigation approaches. However, integrating Deep Reinforcement Learning into existing navigation systems is still an open frontier due to the myopic nature of Deep-Reinforcement-Learning-based navigation, which hinders its widespread integration into current navigation systems. In this paper, we propose the concept of an intermediate planner to interconnect novel Deep-Reinforcement-Learning-based obstacle avoidance with conventional global planning methods using waypoint generation. Therefore, we integrate different waypoint generators into existing navigation systems and compare the joint system against traditional ones. We found an increased performance in terms of safety, efficiency and path smoothness, especially in highly dynamic environments.",
        "primary_area": "",
        "author": "Linh K\u00e4stner;Xinlin Zhao;Teham Buiyan;Junhui Li;Zhengcheng Shen;Jens Lambrecht;Cornelius Marx;Linh K\u00e4stner;Xinlin Zhao;Teham Buiyan;Junhui Li;Zhengcheng Shen;Jens Lambrecht;Cornelius Marx",
        "authorids": "/37087466037;/37089197226;/37089197716;/37089197592;/37088811455;/37342634600;/37088526290;/37087466037;/37089197226;/37089197716;/37089197592;/37088811455;/37342634600;/37088526290",
        "aff": "Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636039/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10563387422951479015&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Berlin Institute of Technology",
        "aff_unique_dep": "Faculty of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636213",
        "title": "Consensus-Informed Optimization Over Mixtures for Ambiguity-Aware Object SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Building object-level maps can facilitate robot-environment interactions (e.g. planning and manipulation), but objects could often have multiple probable poses when viewed from a single vantage point, due to symmetry, occlusion or perceptual failures. A robust object-level simultaneous localization and mapping (object SLAM) algorithm needs to be aware of this pose ambiguity. We propose to maintain and subsequently disambiguate the multiple pose interpretations to gradually recover a globally consistent world representation. The max-mixtures model is applied to implicitly and efficiently track all pose hypotheses, but the resulting formulation is non-convex, and therefore subject to local optima. To mitigate this problem, temporally consistent hypotheses are extracted, guiding the optimization into the global optimum. This consensus-informed inference method is applied online via landmark variable re-initialization within an incremental SLAM framework, iSAM2, for robust real-time performance. We demonstrate that this approach improves SLAM performance on both simulated and real object SLAM problems with pose ambiguity.",
        "primary_area": "",
        "author": "Ziqi Lu;Qiangqiang Huang;Kevin Doherty;John J. Leonard;Ziqi Lu;Qiangqiang Huang;Kevin Doherty;John J. Leonard",
        "authorids": "/37089194233;/37089002085;/37085769742;/37329387400;/37089194233;/37089002085;/37085769742;/37329387400",
        "aff": "Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636213/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9916925752433468960&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636787",
        "title": "Consistent SLAM using Local Optimization with Virtual Prior Topologies",
        "track": "main",
        "status": "Poster",
        "abstract": "In the present work we address the problem of achieving a consistent estimator for SLAM. We propose a novel method capable of computing approximately consistent global uncertainties without scaling in complexity with the total size of the explored area. The method allows arbitrary selection of local areas for optimization, introducing a methodology for building a virtual prior in bounded time. The constructed prior topologies serve as a way of contextualizing the local optimizations, resulting in consistent uncertainty estimations. This overcomes several shortcomings of previous approaches that rely on conditioning (fixing variables) and/or sliding window marginalization. Evaluations are presented in different simulated scenarios comparing results against a global batch optimization and other canonical approaches.",
        "primary_area": "",
        "author": "Gast\u00f3n Castro;Facundo Pessacg;Pablo De Crist\u00f3foris;Gast\u00f3n Castro;Facundo Pessacg;Pablo De Crist\u00f3foris",
        "authorids": "/37086237669;/38548551800;/38015830200;/37086237669;/38548551800;/38015830200",
        "aff": "ICC-UBA-CONICET, Instituto de Ciencias de la Computaci\u00f3n, Argentina; ICC-UBA-CONICET, Instituto de Ciencias de la Computaci\u00f3n, Argentina; ICC-UBA-CONICET, Instituto de Ciencias de la Computaci\u00f3n, Argentina",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636787/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12010159892841434406&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Instituto de Ciencias de la Computaci\u00f3n",
        "aff_unique_dep": "Instituto de Ciencias de la Computaci\u00f3n",
        "aff_unique_url": "",
        "aff_unique_abbr": "ICC-UBA-CONICET",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Argentina"
    },
    {
        "id": "9636351",
        "title": "Consolidating Kinematic Models to Promote Coordinated Mobile Manipulations",
        "track": "main",
        "status": "Poster",
        "abstract": "We construct a Virtual Kinematic Chain (VKC) that readily consolidates the kinematics of the mobile base, the arm, and the object to be manipulated in mobile manipulations. Accordingly, a mobile manipulation task is represented by altering the state of the constructed VKC, which can be converted to a motion planning problem, formulated and solved by trajectory optimization. This new VKC perspective of mobile manipulation allows a service robot to (i) produce well-coordinated motions, suitable for complex household environments, and (ii) perform intricate multi-step tasks while interacting with multiple objects without an explicit definition of intermediate goals. In simulated experiments, we validate these advantages by comparing the VKC-based approach with baselines that solely optimize individual components. The results manifest that VKC-based joint modeling and planning promote task success rates and produce more efficient trajectories.",
        "primary_area": "",
        "author": "Ziyuan Jiao;Zeyu Zhang;Xin Jiang;David Han;Song-Chun Zhu;Yixin Zhu;Hangxin Liu;Ziyuan Jiao;Zeyu Zhang;Xin Jiang;David Han;Song-Chun Zhu;Yixin Zhu;Hangxin Liu",
        "authorids": "/37085784268;/37086938580;/37089194417;/37588964400;/37281407500;/37086172463;/37086274715;/37085784268;/37086938580;/37089194417;/37588964400;/37281407500;/37086172463;/37086274715",
        "aff": "Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); ECE Department, UCLA; Department of Electrical and Computer Engineering, Drexel University; Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636351/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9592434703131013163&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles;Drexel University",
        "aff_unique_dep": "Statistics Department;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucla.edu;https://www.drexel.edu",
        "aff_unique_abbr": "UCLA;Drexel",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636630",
        "title": "Constant Fluidic Mass Control for Soft Actuators Using Artificial Neural Network Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft fluidic actuators are increasingly being used for wearable haptic devices due to their high energy density and low encumbrance. These actuators are typically controlled using constant fluidic pressure control (CFPC), where the actuator pressure is switched between a high pressure source and atmospheric pressure using a fluidic valve. However, this type of control has several limitations for soft actuators including limited dynamic range, slow actuator response, low pressure control resolution and unnatural haptic interaction. In this paper, we present a novel control strategy for soft fluidic actuators, called constant fluidic mass control (CFMC), where the mass of fluid introduced into the actuator is kept constant during actuation, rather than the pressure as in CFPC. Our experimental results show that compared to CFPC, CFMC results in a larger dynamic range of actuator output forces, faster actuator response time to reach a desired target pressure, and higher resolution of pressure control, which makes it particularly useful for wearable haptics. In addition, CFMC enables analog pressure control and we present a neural-network-based supervised learning algorithm for accurate pressure control of soft actuators. Results show that our algorithm can predict actuator pressure with an accuracy of 99% and can be generalized to different soft TPU-fabric fluidic actuators.",
        "primary_area": "",
        "author": "Heng Xu;Priyanshu Agarwal;Benjamin Stephens-Fripp;Heng Xu;Priyanshu Agarwal;Benjamin Stephens-Fripp",
        "authorids": "/37086378497;/37089972918;/37086337789;/37086378497;/37089972918;/37086337789",
        "aff": "Facebook Reality Labs, Redmond, WA, USA; Facebook Reality Labs, Redmond, WA, USA; Facebook Reality Labs, Redmond, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636630/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4985459156543235914&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Meta",
        "aff_unique_dep": "Facebook Reality Labs",
        "aff_unique_url": "https://www.facebook.com/realitylabs",
        "aff_unique_abbr": "FRL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Redmond",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636187",
        "title": "Constrained Iterative LQG for Real-Time Chance-Constrained Gaussian Belief Space Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning under uncertainty is of significant importance for safety-critical systems such as autonomous vehicles. Such systems have to satisfy necessary constraints (e.g., collision avoidance) with potential uncertainties coming from either disturbed system dynamics or noisy sensor measurements. However, existing motion planning methods cannot efficiently find the robust optimal solutions under general nonlinear and non-convex settings. In this paper, we formulate such problem as chance-constrained Gaussian belief space planning and propose the constrained iterative Linear Quadratic Gaussian (CILQG) algorithm as a real-time solution. In this algorithm, we iteratively calculate a Gaussian approximation of the belief and transform the chance-constraints. We evaluate the effectiveness of our method in simulations of autonomous driving planning tasks with static and dynamic obstacles. Results show that CILQG can handle uncertainties more appropriately and has faster computation time than baseline methods.",
        "primary_area": "",
        "author": "Jianyu Chen;Yutaka Shimizu;Liting Sun;Masayoshi Tomizuka;Wei Zhan;Jianyu Chen;Yutaka Shimizu;Liting Sun;Masayoshi Tomizuka;Wei Zhan",
        "authorids": "/37086004703;/37089197396;/37085425729;/37281933000;/37067099600;/37086004703;/37089197396;/37085425729;/37281933000;/37067099600",
        "aff": "Shanghai Qizhi Institute, Shanghai, China; Graduate School of Information Science and Technology, University of Tokyo, Japan; Department of Mechanical Engineering, University of California, Berkeley, USA; Department of Mechanical Engineering, University of California, Berkeley, USA; Department of Mechanical Engineering, University of California, Berkeley, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636187/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12834490314790701293&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;2",
        "aff_unique_norm": "Shanghai Qizhi Institute;University of Tokyo;University of California, Berkeley",
        "aff_unique_dep": ";Graduate School of Information Science and Technology;Department of Mechanical Engineering",
        "aff_unique_url": ";https://www.u-tokyo.ac.jp;https://www.berkeley.edu",
        "aff_unique_abbr": ";UTokyo;UC Berkeley",
        "aff_campus_unique_index": "0;1;2;2;2",
        "aff_campus_unique": "Shanghai;Tokyo;Berkeley",
        "aff_country_unique_index": "0;1;2;2;2",
        "aff_country_unique": "China;Japan;United States"
    },
    {
        "id": "9636130",
        "title": "Contact Anticipation for Physical Human\u2013Robot Interaction with Robotic Manipulators using Onboard Proximity Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a framework that unites obstacle avoidance and deliberate physical interaction for robotic manipulators. As humans and robots begin to coexist in work and household environments, pure collision avoidance is insufficient, as human\u2013robot contact is inevitable and, in some situations, desired. Our work enables manipulators to anticipate, detect, and act on contact. To achieve this, we allow limited deviation from the robot\u2019s original trajectory through velocity reduction and motion restrictions. Then, if contact occurs, a robot can detect it and maneuver based on a novel dynamic contact thresholding algorithm. The core contribution of this work is dynamic contact thresholding, which allows a manipulator with onboard proximity sensors to track nearby objects and reduce contact forces in anticipation of a collision. Our framework elicits natural behavior during physical human\u2013robot interaction. We evaluate our system on a variety of scenarios using the Franka Emika Panda robot arm; collectively, our results demonstrate that our contribution is not only able to avoid and react on contact, but also anticipate it.",
        "primary_area": "",
        "author": "Caleb Escobedo;Matthew Strong;Mary West;Ander Aramburu;Alessandro Roncone;Caleb Escobedo;Matthew Strong;Mary West;Ander Aramburu;Alessandro Roncone",
        "authorids": "/37089195404;/37088852557;/37089195452;/37089194905;/37085343755;/37089195404;/37088852557;/37089195452;/37089194905;/37085343755",
        "aff": "Department of Computer Science, University of Colorado Boulder, Boulder, CO, USA; Department of Computer Science, University of Colorado Boulder, Boulder, CO, USA; Department of Computer Science, University of Colorado Boulder, Boulder, CO, USA; Department of Computer Science, University of Colorado Boulder, Boulder, CO, USA; Department of Computer Science, University of Colorado Boulder, Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636130/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8305457559364131021&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636313",
        "title": "Contact Tracing: A Low Cost Reconstruction Framework for Surface Contact Interpolation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel, low cost framework for reconstructing surface contact movements during in-hand manipulations. Unlike many existing methods focused on hand pose tracking, ours models the behavior of contact patches, and by doing so is the first to obtain detailed contact tracking estimates for multi-contact manipulations. Our framework is highly accessible, requiring only low cost, readily available paint materials, a single RGBD camera, and a simple, deterministic interpolation algorithm. Despite its simplicity, we demonstrate the framework\u2019s effectiveness over the course of several manipulations on three common household items. Finally, we demonstrate the use of a generated contact time series in manipulation learning for a simulated robot hand.",
        "primary_area": "",
        "author": "Arjun Lakshmipathy;Dominik Bauer;Nancy S. Pollard;Arjun Lakshmipathy;Dominik Bauer;Nancy S. Pollard",
        "authorids": "/37088398470;/37086606269;/37341211200;/37088398470;/37086606269;/37341211200",
        "aff": "Computer Science Department, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636313/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16177259454977354092&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635948",
        "title": "Content Disentanglement for Semantically Consistent Synthetic-to-Real Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Synthetic data generation is an appealing approach to generate novel traffic scenarios in autonomous driving. However, deep learning perception algorithms trained solely on synthetic data encounter serious performance drops when they are tested on real data. Such performance drops are commonly attributed to the domain gap between real and synthetic data. Domain adaptation methods that have been applied to mitigate the aforementioned domain gap achieve visually appealing results, but usually introduce semantic inconsistencies into the translated samples. In this work, we propose a novel, unsupervised, end-to-end domain adaptation network architecture that enables semantically consistent sim2real image transfer. Our method performs content disentanglement by employing shared content encoder and fixed style code.",
        "primary_area": "",
        "author": "Mert Keser;Artem Savkin;Federico Tombari;Mert Keser;Artem Savkin;Federico Tombari",
        "authorids": "/37089194008;/37086960994;/37593332100;/37089194008;/37086960994;/37593332100",
        "aff": "BMW AG, Munich, Germany; BMW AG, Munich, Germany; Google, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635948/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2412908313219805954&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "BMW AG;Google",
        "aff_unique_dep": ";Google",
        "aff_unique_url": "https://www.bmw.com;https://www.google.ch",
        "aff_unique_abbr": "BMW;Google",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Munich;Zurich",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "id": "9635922",
        "title": "Context and Orientation Aware Path Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles on city roads and especially in pedestrian environments require agility to navigate narrow passages and turn in tight spaces, leading to the need for a real-time, robust and adaptable controller. In this paper, we present orientation and context aware controllers for autonomous vehicles that can closely track the reference path wit alh respect to the current state of the vehicle, environmental properties, and the desired target orientation at the desired target location. Our proposed controllers are derived from the widely used pure pursuit controller. We validate our proposed controllers with respect to the baseline pure pursuit controller in simulation and on a full-size autonomous vehicle in a pedestrian environment. Our experimental results suggest significant improvements in adaptability and tracking performance compared to the pure pursuit controller.",
        "primary_area": "",
        "author": "Nicholas Michael B\u00fcnger;Sahil Panjwani;Malika Meghjani;Zefan Huang;Marcelo H. Ang;Daniela Rus;Nicholas Michael B\u00fcnger;Sahil Panjwani;Malika Meghjani;Zefan Huang;Marcelo H. Ang;Daniela Rus",
        "authorids": "/37089194378;/37089194849;/37393934900;/37087323099;/37279138700;/37279652300;/37089194378;/37089194849;/37393934900;/37087323099;/37279138700;/37279652300",
        "aff": "Swiss Institute of Technology, Z\u00fcrich, Switzerland; Singapore-MIT Alliance for Research and Technology; Singapore-MIT Alliance for Research and Technology; Singapore-MIT Alliance for Research and Technology; National University of Singapore, Singapore; Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635922/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:g_e24QvkY00J:scholar.google.com/&scioq=Context+and+Orientation+Aware+Path+Tracking&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;2;3",
        "aff_unique_norm": "Swiss Federal Institute of Technology Zurich;Singapore-MIT Alliance for Research and Technology;National University of Singapore;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.ethz.ch;https://smart.singapore.edu.sg;https://www.nus.edu.sg;https://www.mit.edu",
        "aff_unique_abbr": "ETH Z\u00fcrich;SMART;NUS;MIT",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Z\u00fcrich;;Cambridge",
        "aff_country_unique_index": "0;1;1;1;1;2",
        "aff_country_unique": "Switzerland;Singapore;United States"
    },
    {
        "id": "9635920",
        "title": "Continuous Robust Trajectory Tracking Control for Autonomous Ground Vehicles Considering Lateral and Longitudinal Kinematics and Dynamics via Recursive Backstepping",
        "track": "main",
        "status": "Poster",
        "abstract": "Maintaining lateral and longitudinal trajectory tracking accuracy is challenging for autonomous ground vehicles (AGVs). This paper considers kinematics and dynamics of longitudinal and lateral motion to form a novel composite structure considering the cross-impacts of acceleration and steering commands on tracking errors in the lateral and longitudinal directions, respectively. The multi-tiered structure uses backstepping with smooth robust control to iteratively map kinematics-based velocity and yaw rate commands to slip-yaw dynamics-based acceleration and steering commands. In kinematics, longitudinal tracking error is stabilized by sliding mode control (SMC) while variable structure control (VSC) stabilizes lateral tracking error and balances tracking accuracy and steering gracefulness. Backstepping extends these commands through vehicle dynamics to provide robust steering and acceleration commands. Cross impacts between lateral and longitudinal motion is addressed by vehicle modeling and controller designs. A robust observer is applied for sideslip estimation to reject uncertainties. Peaking from the high gain observer and robust control is addressed. Stability analysis is provided and field experiments on an open road demonstrate and validate effectiveness of the controllers.",
        "primary_area": "",
        "author": "Ming Xin;Yue Yin;Kai Zhang;David Lackner;Zhongchao Ren;Mark Minor;Ming Xin;Yue Yin;Kai Zhang;David Lackner;Zhongchao Ren;Mark Minor",
        "authorids": "/38242862700;/37089194950;/37088505720;/37088505529;/37089193915;/37279831800;/38242862700;/37089194950;/37088505720;/37088505529;/37089193915;/37279831800",
        "aff": "University of Utah and Inceptio Tech., Fremont, CA, USA; NIO Tech., Inceptio Tech, Shanghai, China; Alibaba Inc, Inceptio Tech., Hangzhou, China; Inceptio Tech, Fremont, CA, USA; RobotSense Technology, Autel, Shenzhen, China; Mechanical Engineering Department, University of Utah, Salt Lake City, Utah, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635920/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13224228365076550224&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;4;0",
        "aff_unique_norm": "University of Utah;NIO Tech.;Alibaba Inc;Inceptio Tech;RobotSense Technology",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.utah.edu;;https://www.alibaba.com;;",
        "aff_unique_abbr": "U of U;;Alibaba;;",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Fremont;Salt Lake City",
        "aff_country_unique_index": "0;1;1;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9636573",
        "title": "Continuous-time Gaussian Process Trajectory Generation for Multi-robot Formation via Probabilistic Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we extend a famous motion planning approach, GPMP2, to multi-robot cases, yielding a novel centralized trajectory generation method for the multi-robot formation. A sparse Gaussian Process model is employed to represent the continuous-time trajectories of all robots as a limited number of states, which improves computational efficiency due to the sparsity. We add constraints to guarantee collision avoidance between individuals as well as formation maintenance, then all constraints and kinematics are formulated on a factor graph. By introducing a global planner, our proposed method can generate trajectories efficiently for a team of robots which have to get through a width-varying area by adaptive formation change. Finally, we provide the implementation of an incremental replanning algorithm to demonstrate the online operation potential of our proposed framework. The experiments in simulation and real world illustrate the feasibility, efficiency and scalability of our approach.",
        "primary_area": "",
        "author": "Shuang Guo;Bo Liu;Shen Zhang;Jifeng Guo;Changhong Wang;Shuang Guo;Bo Liu;Shen Zhang;Jifeng Guo;Changhong Wang",
        "authorids": "/37087883476;/37089198213;/37089198224;/37403048900;/37280022000;/37087883476;/37089198213;/37089198224;/37403048900;/37280022000",
        "aff": "Department of Aerospace Engineering, Harbin Institute of Technology, Harbin, China; Space Control and Inertial Technology Research Center, Harbin Institute of Technology, Harbin, China; Department of Microelectronics, Harbin Institute of Technology, Harbin, China; Department of Aerospace Engineering, Harbin Institute of Technology, Harbin, China; Space Control and Inertial Technology Research Center, Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636573/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3865822425081700221&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "Department of Aerospace Engineering",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636014",
        "title": "Continuous-time Radar-inertial Odometry for Automotive Radars",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an approach for radar-inertial odometry which uses a continuous-time framework to fuse measurements from multiple automotive radars and an inertial measurement unit (IMU). Adverse weather conditions do not have a significant impact on the operating performance of radar sensors unlike that of camera and LiDAR sensors. Radar\u2019s robustness in such conditions and the increasing prevalence of radars on passenger vehicles motivate us to look at the use of radar for ego-motion estimation. A continuous-time trajectory representation is applied not only as a framework to enable heterogeneous and asynchronous multi-sensor fusion, but also, to facilitate efficient optimization by being able to compute poses and their derivatives in closed-form and at any given time along the trajectory. We compare our continuous-time estimates to those from a discrete-time radar-inertial odometry approach and show that our continuous-time method outperforms the discrete-time method. To the best of our knowledge, this is the first time a continuous-time framework has been applied to radar-inertial odometry.",
        "primary_area": "",
        "author": "Yin Zhi Ng;Benjamin Choi;Robby Tan;Lionel Heng;Yin Zhi Ng;Benjamin Choi;Robby Tan;Lionel Heng",
        "authorids": "/37089196624;/37086199757;/37089197181;/37968251100;/37089196624;/37086199757;/37089197181;/37968251100",
        "aff": "Department of Electrical and Computer Engineering, National University of Singapore; Robotics Autonomy Lab, Robotics Division, DSO National Laboratories; Department of Electrical and Computer Engineering, National University of Singapore; Robotics Autonomy Lab, Robotics Division, DSO National Laboratories",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636014/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11829117149532642658&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "National University of Singapore;DSO National Laboratories",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Robotics Division",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.dso.org.sg",
        "aff_unique_abbr": "NUS;DSO",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9636760",
        "title": "Contrastively Learning Visual Attention as Affordance Cues from Demonstrations for Robotic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Conventional works that learn grasping affordance from demonstrations need to explicitly predict grasping configurations, such as gripper approaching angles or grasping preshapes. Classic motion planners could then sample trajectories by using such predicted configurations. In this work, our goal is instead to fill the gap between affordance discovery and affordance-based policy learning by integrating the two objectives in an end-to-end imitation learning framework based on deep neural networks. From a psychological perspective, there is a close association between attention and affordance. Therefore, with an end-to-end neural network, we propose to learn affordance cues as visual attention that serves as a useful indicating signal of how a demonstrator accomplishes tasks, instead of explicitly modeling affordances. To achieve this, we propose a contrastive learning framework that consists of a Siamese encoder and a trajectory decoder. We further introduce a coupled triplet loss to encourage the discovered affordance cues to be more affordance-relevant. Our experimental results demonstrate that our model with the coupled triplet loss achieves the highest grasping success rate in a simulated robot environment. Our project website can be accessed at1.",
        "primary_area": "",
        "author": "Yantian Zha;Siddhant Bhambri;Lin Guan;Yantian Zha;Siddhant Bhambri;Lin Guan",
        "authorids": "/37089193977;/37087041646;/37089196977;/37089193977;/37087041646;/37089196977",
        "aff": "School of CS & AI, Arizona State University, United States of America; School of CS & AI, Arizona State University, United States of America; School of CS & AI, Arizona State University, United States of America",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636760/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12095978687610501039&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School of CS & AI",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636543",
        "title": "Control of Spherical Robots on Uneven Terrains",
        "track": "main",
        "status": "Poster",
        "abstract": "Hybrid robots incorporate the advantages of both aerial-only and terrestrial-only vehicles to achieve enhanced mobility and better energy efficiency. Among hybrid vehicles, spherical robots offer the best maneuverability. While operating on uneven surfaces is one of the main benefits of spherical robots, the current literature only covers control of these robots on flat surfaces. This work presents two control algorithms to track a desired trajectory and angular velocity of spherical robots on uneven terrains. The proposed control algorithms can be used when the terrain is known analytically or empirically (i.e., point cloud). By allowing the controller to use empirical information about the terrain profile, this work broadens the implementation of spherical robots in real applications.",
        "primary_area": "",
        "author": "Sahand Sabet;Mohammad Poursina;Parviz E. Nikravesh;Sahand Sabet;Mohammad Poursina;Parviz E. Nikravesh",
        "authorids": "/37086036298;/37086037856;/37086037082;/37086036298;/37086037856;/37086037082",
        "aff": "Department of Aerospace and Mechanical Engineering, University of Arizona, Tucson, AZ, USA; Department of Engineering Sciences, University of Agder, Grimstad, Norway; Department of Aerospace and Mechanical Engineering, University of Arizona, Tucson, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636543/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11883804681368839492&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Arizona;University of Agder",
        "aff_unique_dep": "Department of Aerospace and Mechanical Engineering;Department of Engineering Sciences",
        "aff_unique_url": "https://www.arizona.edu;https://www.uia.no",
        "aff_unique_abbr": "UArizona;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Tucson;Grimstad",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Norway"
    },
    {
        "id": "9636415",
        "title": "Control-Aware Design Optimization for Bio-Inspired Quadruped Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a control-aware design optimization method for quadrupedal robots. In particular, we show that it is possible to analytically differentiate typical, inverse dynamics-based whole body controllers with respect to design parameters, and that gradient-based methods can be used to efficiently improve an initial morphological design according to well-established metrics. We apply our design optimization method to various types of quadrupedal robots, including designs that feature closed kinematic chains. The methodology we present enables a principled comparison of different types of optimized legged robot designs. Our experiments, for example, suggest that mechanically-coupled three-link leg designs present notable advantages in terms of performance and efficiency over the common two-link leg designs used in most quadrupedal robots today.",
        "primary_area": "",
        "author": "Flavio De Vincenti;Dongho Kang;Stelian Coros;Flavio De Vincenti;Dongho Kang;Stelian Coros",
        "authorids": "/37089196705;/37089194550;/37077396200;/37089196705;/37089194550;/37077396200",
        "aff": "Computational Robotics Lab, ETH, Zurich, Switzerland; Computational Robotics Lab, ETH, Zurich, Switzerland; Computational Robotics Lab, ETH, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636415/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10201186761263283606&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Computational Robotics Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636801",
        "title": "Convex Approximation for LTL-based Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a formulation for linear temporal logic (LTL)-based task planning of nonlinear dynamical systems. We consider pick-and-place task planning as a typical example of the planning task that can be modeled as a hybrid system that includes the states of robots and objects. LTL-based planning for hybrid systems is solved as a mixed-integer problem (MIP), especially a mixed-integer linear programming problem (MILP). Due to the formulation by the MILP, we could only deal with linear systems and linear constraints. In our proposed method, we apply a convex approximation to systems that have bilinear terms and quadratic terms in their dynamics. And we incorporate nonlinear systems into existing LTL-based planning as an MILP. We demonstrate the effectiveness through numerical simulations of a simple robot arm system and drone system.",
        "primary_area": "",
        "author": "Shumpei Tokuda;Masaki Yamakita;Hiroyuki Oyama;Rin Takano;Shumpei Tokuda;Masaki Yamakita;Hiroyuki Oyama;Rin Takano",
        "authorids": "/37087031509;/37279385100;/37085392095;/37086014041;/37087031509;/37279385100;/37085392095;/37086014041",
        "aff": "Department of Systems and Control Engineering, Tokyo Institute of Technology, Meguro, Japan; Department of Systems and Control Engineering, Tokyo Institute of Technology, Meguro, Japan; Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan; Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636801/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=56424823956467344&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Tokyo Institute of Technology;NEC Corporation",
        "aff_unique_dep": "Department of Systems and Control Engineering;Data Science Research Laboratories",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.nec.com",
        "aff_unique_abbr": "Titech;NEC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Meguro;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636427",
        "title": "Convex Optimization for Spring Design in Series Elastic Actuators: From Theory to Practice",
        "track": "main",
        "status": "Poster",
        "abstract": "Natural dynamics, nonlinear optimization, and, more recently, convex optimization are available methods for stiffness design of energy-efficient series elastic actuators. Natural dynamics and general nonlinear optimization only work for a limited set of load kinetics and kinematics, cannot guarantee convergence to a global optimum, or depend on initial conditions to the numerical solver. Convex programs alleviate these limitations and allow a global solution in polynomial time, which is useful when the space of optimization variables grows (e.g., when designing optimal nonlinear springs or co-designing spring, controller, and reference trajectories). Our previous work introduced the stiffness design of series elastic actuators via convex optimization when the transmission dynamics are negligible, which is an assumption that applies mostly in theory or when the actuator uses a direct or quasi-direct drive. In this work, we extend our analysis to include friction at the transmission. Coulomb friction at the transmission results in a non-convex expression for the energy dissipated as heat, but we illustrate a convex approximation for stiffness design. We experimentally validated our framework using a series elastic actuator with specifications similar to the knee joint of the Open Source Leg, an open-source robotic knee-ankle prosthesis.",
        "primary_area": "",
        "author": "Edgar A. Bol\u00edvar-Nieto;Gray C. Thomas;Elliott Rouse;Robert D. Gregg;Edgar A. Bol\u00edvar-Nieto;Gray C. Thomas;Elliott Rouse;Robert D. Gregg",
        "authorids": "/37086859696;/37085525465;/37991140400;/37547699100;/37086859696;/37085525465;/37991140400;/37547699100",
        "aff": "Robotics Institute at the University of Michigan, Ann Arbor, MI, USA; Robotics Institute at the University of Michigan, Ann Arbor, MI, USA; Robotics Institute at the University of Michigan, Ann Arbor, MI, USA; Robotics Institute at the University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636427/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14469951711135479582&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636326",
        "title": "Cooperative ASV/AUV system exploiting active acoustic localization",
        "track": "main",
        "status": "Poster",
        "abstract": "The lack of GPS signal in the underwater environment poses limitations in terms of localization and navigation of mobile robots. Strategies based on acoustic localization systems are employed to improve underwater navigation. In this paper we describe a first step towards the development of a marine system of systems involving autonomous mobile nodes. The approach relies on communication networking between an Autonomous Surface Vehicle (ASV), equipped with an Ultra Short BaseLine (USBL) device, and an Autonomous Underwater Vehicle (AUV). An active acoustic communication protocol prioritizes the AUV positioning rate, whereas a model-based navigation filter handles the delayed measurements caused by the acoustic communication latency. The system has been tested in a real marine environment to analyze its behavior and the quality of the navigation estimation. The experimental results show that the navigation algorithm on-board the AUV provides an estimate of its position with an error of a few meters with respect to the GPS ground-truth, over a total path of approximately 210m, exploiting acoustic positioning data provided by the ASV in order to limit drift problems.",
        "primary_area": "",
        "author": "Matteo Bresciani;Giovanni Peralta;Francesco Ruscio;Lorenzo Bazzarello;Andrea Caiti;Riccardo Costanzi;Matteo Bresciani;Giovanni Peralta;Francesco Ruscio;Lorenzo Bazzarello;Andrea Caiti;Riccardo Costanzi",
        "authorids": "/37088835895;/37088836066;/37088835151;/37089195050;/37281984600;/38228070000;/37088835895;/37088836066;/37088835151;/37089195050;/37281984600;/38228070000",
        "aff": "Interuniversity Center of Integrated Systems for the Marine Environment (ISME), Italy; Interuniversity Center of Integrated Systems for the Marine Environment (ISME), Italy; Interuniversity Center of Integrated Systems for the Marine Environment (ISME), Italy; Naval Support and Experimentation Center (CSSN), La Spezia, Italy; Centro di Ricerca \"E. Piaggio\", University of Pisa, Italy; Centro di Ricerca \"E. Piaggio\", University of Pisa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636326/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1834919140897858564&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;2",
        "aff_unique_norm": "Interuniversity Center of Integrated Systems for the Marine Environment;Naval Support and Experimentation Center;University of Pisa",
        "aff_unique_dep": "Center of Integrated Systems for the Marine Environment;;Centro di Ricerca \"E. Piaggio\"",
        "aff_unique_url": ";;https://www.unipi.it",
        "aff_unique_abbr": "ISME;CSSN;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";La Spezia",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636193",
        "title": "Cooperative Assistance in Robotic Surgery through Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Cognitive cooperative assistance in robot-assisted surgery holds the potential to increase quality of care in minimally invasive interventions. Automation of surgical tasks promises to reduce the mental exertion and fatigue of surgeons. In this work, multi-agent reinforcement learning is demonstrated to be robust to the distribution shift introduced by pairing a learned policy with a human team member. Multi-agent policies are trained directly from images in simulation to control multiple instruments in a sub task of the minimally invasive removal of the gallbladder. These agents are evaluated individually and in cooperation with humans to demonstrate their suitability as autonomous assistants. Compared to human teams, the hybrid teams with artificial agents perform better considering completion time (44.4% to 71.2% shorter) as well as number of collisions (44.7% to 98.0% fewer). Path lengths, however, increase under control of an artificial agent (11.4% to 33.5% longer). A multi-agent formulation of the learning problem was favored over a single-agent formulation on this surgical sub task, due to the sequential learning of the two instruments. This approach may be extended to other tasks that are difficult to formulate within the standard reinforcement learning framework. Multi-agent reinforcement learning may shift the paradigm of cognitive robotic surgery towards seamless cooperation between surgeons and assistive technologies.",
        "primary_area": "",
        "author": "Paul Maria Scheikl;Bal\u00e1zs Gyenes;Tornike Davitashvili;Rayan Younis;Andr\u00e9 Schulze;Beat P. M\u00fcller-Stich;Gerhard Neumann;Martin Wagner;Franziska Mathis-Ullrich;Paul Maria Scheikl;Bal\u00e1zs Gyenes;Tornike Davitashvili;Rayan Younis;Andr\u00e9 Schulze;Beat P. M\u00fcller-Stich;Gerhard Neumann;Martin Wagner;Franziska Mathis-Ullrich",
        "authorids": "/37087467712;/37089197926;/37089198137;/37089196203;/37089195938;/37085457120;/38542033100;/37085725819;/37088949823;/37087467712;/37089197926;/37089198137;/37089196203;/37089195938;/37085457120;/38542033100;/37085725819;/37088949823",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Department for General, Visceral and Transplantation Surgery, Heidelberg University Hospital, Heidelberg, Germany; Department for General, Visceral and Transplantation Surgery, Heidelberg University Hospital, Heidelberg, Germany; Department for General, Visceral and Transplantation Surgery, Heidelberg University Hospital, Heidelberg, Germany; Department for General, Visceral and Transplantation Surgery, Heidelberg University Hospital, Heidelberg, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Department for General, Visceral and Transplantation Surgery, Heidelberg University Hospital, Heidelberg, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636193/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15144493924498403052&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;1;1;1;0;1;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology;Heidelberg University Hospital",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics;Department for General, Visceral and Transplantation Surgery",
        "aff_unique_url": "https://www.kit.edu;https://www.klinikum.uni-heidelberg.de",
        "aff_unique_abbr": "KIT;",
        "aff_campus_unique_index": "0;0;1;1;1;1;0;1;0",
        "aff_campus_unique": "Karlsruhe;Heidelberg",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636151",
        "title": "Cooperative Autonomous Vehicles that Sympathize with Human Drivers",
        "track": "main",
        "status": "Poster",
        "abstract": "Widespread adoption of autonomous vehicles will not become a reality until solutions are developed that enable these intelligent agents to co-exist with humans. This includes safely and efficiently interacting with human-driven vehicles, especially in both conflictive and competitive scenarios. We build up on the prior work on socially-aware navigation and borrow the concept of social value orientation from psychology \u2014that formalizes how much importance a person allocates to the welfare of others\u2014 in order to induce altruistic behavior in autonomous driving. In contrast with existing works that explicitly model the behavior of human drivers and rely on their expected response to create opportunities for cooperation, our Sympathetic Cooperative Driving (SymCoDrive) paradigm trains altruistic agents that realize safe and smooth traffic flow in competitive driving scenarios only from experiential learning and without any explicit coordination. We demonstrate a significant improvement in both safety and traffic-level metrics as a result of this altruistic behavior and importantly conclude that the level of altruism in agents requires proper tuning as agents that are too altruistic also lead to sub-optimal traffic flow. The code and supplementary material are available at: https://symcodrive.toghi.net/",
        "primary_area": "",
        "author": "Behrad Toghi;Rodolfo Valiente;Dorsa Sadigh;Ramtin Pedarsani;Yaser P. Fallah;Behrad Toghi;Rodolfo Valiente;Dorsa Sadigh;Ramtin Pedarsani;Yaser P. Fallah",
        "authorids": "/37086612583;/37086961828;/38234464200;/37845785600;/37393243700;/37086612583;/37086961828;/38234464200;/37845785600;/37393243700",
        "aff": "Connected & Autonomous Vehicle Research Lab (CAVREL), University of Central Florida, Orlando, FL, USA; Connected & Autonomous Vehicle Research Lab (CAVREL), University of Central Florida, Orlando, FL, USA; Intelligent and Interactive Autonomous Systems Group (ILIAD), Stanford University, Stanford, CA, USA; Department of Electrical and Computer Engineering, University of California, Santa Barbara, CA, USA; Connected & Autonomous Vehicle Research Lab (CAVREL), University of Central Florida, Orlando, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636151/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3287932462380367081&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "University of Central Florida;Stanford University;University of California, Santa Barbara",
        "aff_unique_dep": "Connected & Autonomous Vehicle Research Lab (CAVREL);Intelligent and Interactive Autonomous Systems Group (ILIAD);Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucf.edu;https://www.stanford.edu;https://www.ucsb.edu",
        "aff_unique_abbr": "UCF;Stanford;UCSB",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Orlando;Stanford;Santa Barbara",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635928",
        "title": "Cooperative Object Transportation using Gibbs Random Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel methodology that allows a swarm of robots to perform a cooperative transportation task. Our approach consists of modeling the swarm as a Gibbs Random Field (GRF), taking advantage of this framework\u2019s locality properties. By setting appropriate potential functions, robots can dynamically navigate, form groups, and perform co- operative transportation in a completely decentralized fashion. Moreover, these behaviors emerge from the local interactions without the need for explicit communication or coordination. To evaluate our methodology, we perform a series of simulations and proof-of-concept experiments in different scenarios. Our results show that the method is scalable, adaptable, and robust to failures and changes in the environment.",
        "primary_area": "",
        "author": "Paulo Rezeck;Renato M. Assun\u00e7\u00e3o;Luiz Chaimowicz;Paulo Rezeck;Renato M. Assun\u00e7\u00e3o;Luiz Chaimowicz",
        "authorids": "/37086210134;/37085580375;/37277207100;/37086210134;/37085580375;/37277207100",
        "aff": "Department of Computer Science, Universidade Federal de Minas Gerais, Brazil; ESRI Inc., Redlands, CA; Department of Computer Science, Universidade Federal de Minas Gerais, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635928/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12098418909118316617&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Universidade Federal de Minas Gerais;ESRI Inc.",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "http://www.ufmg.br;https://www.esri.com",
        "aff_unique_abbr": "UFMG;ESRI",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Redlands",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Brazil;United States"
    },
    {
        "id": "9636238",
        "title": "Cooperative Transportation Robot System Using Risk-Sensitive Stochastic Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a method to determine control input on the basis of minimizing the risk-sensitive cost function and show the results of an experiment in which the method was applied to a cooperative transportation robot system that we have developed. In the robot system, two robots hold a work object to transport without an external fixing device. The mechanism yields the force interaction between the robots and the object, which results in unexpected random errors in transportation. We add a stochastic term to the system model to describe such errors and solve the stochastic differential equation numerically to estimate the cost function. Utilizing the risk-sensitive cost function enables us to find the control input that balances efficiency and safety. The experimental results revealed that the chance of a robot colliding with an obstacle during transportation decreased from 90% to 7% compared with the optimal control.",
        "primary_area": "",
        "author": "Shinya Yasuda;Taichi Kumagai;Hiroshi Yoshida;Shinya Yasuda;Taichi Kumagai;Hiroshi Yoshida",
        "authorids": "/37086564013;/37086359016;/37292935100;/37086564013;/37086359016;/37292935100",
        "aff": "System Platform Research Laboratories, NEC Corporation, Kanagawa, Japan; System Platform Research Laboratories, NEC Corporation, Kanagawa, Japan; System Platform Research Laboratories, NEC Corporation, Kanagawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636238/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=320819399151189077&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "NEC Corporation",
        "aff_unique_dep": "System Platform Research Laboratories",
        "aff_unique_url": "https://www.nec.com",
        "aff_unique_abbr": "NEC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636652",
        "title": "Coordinated Motion Generation and Object Placement: A Reactive Planning and Landing Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Similar to human work, robotic tasks sometimes require two hands to be accomplished. This requires coordinated motion planning and control. While fulfilling the task in a coordinated manner is already a big challenge, the task at hand becomes even harder when obstacles are introduced in the environment that need to be avoided. Furthermore in the case of dynamic environments, contacts cannot be avoided all the time, even with robust planning. In addition to geometric constraints, bimanual systems need to be able to detect and react to contacts during task execution. To this aim, we integrate a vector-field based planning scheme, that is able to avoid obstacles, with contact detection and reactive control methods based on contact wrench estimation such as admittance control. We also fuse the real contact forces into the planner directly together with the circular repulsive fields. The resulting planner-controller combination is capable of obstacle avoidance planning as well as reaction control in the case of unforeseen contacts that can also be used in situations where the manipulation needs to be guided by the environment such as landing control in only roughly known environments. We evaluate our approach on the torque-controlled Kobo bimanual set-up and also perform rigorous simulation studies.",
        "primary_area": "",
        "author": "Riddhiman Laha;Jonathan Vorndamme;Luis F.C. Figueredo;Zheng Qu;Abdalla Swikir;Christoph J\u00e4hne;Sami Haddadin;Riddhiman Laha;Jonathan Vorndamme;Luis F.C. Figueredo;Zheng Qu;Abdalla Swikir;Christoph J\u00e4hne;Sami Haddadin",
        "authorids": "/37089002102;/37085761454;/37063909900;/37088889967;/37085861833;/37086040696;/37542865300;/37089002102;/37085761454;/37063909900;/37088889967;/37085861833;/37086040696;/37542865300",
        "aff": "Munich School of Robotics and Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany; Chair of Robotics Science and Systems, TUM; Munich School of Robotics and Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany; Franka Emika GmbH, Munich, Germany; Munich School of Robotics and Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany; Franka Emika GmbH, Munich, Germany; Munich School of Robotics and Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636652/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14898868781773307470&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;0;2;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen;Technical University of Munich;Franka Emika GmbH",
        "aff_unique_dep": "Munich School of Robotics and Machine Intelligence;Chair of Robotics Science and Systems;",
        "aff_unique_url": "https://www.tum.de;https://www.tum.de;https://www.franka.de",
        "aff_unique_abbr": "TUM;TUM;",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636703",
        "title": "Coordinated Path Planning for Surface Acoustic Beacons for Supporting Underwater Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate localization is one of the biggest challenges in underwater robotics. The primary reasons behind that are unavailability of satellite-based positioning below the surface, and lack of clear features in natural water bodies for visually aided localization. As such, the common method of choice for external position referencing in underwater robots is the use of acoustic signals for computing range or direction of arrival. To that end, we have developed an acoustic range based navigation system with floating, movable beacons. In this paper, we present an approach for planning the trajectory of acoustic beacons in a way that they provide the best possible navigation support for a group of underwater vehicles. We use an information theoretic approach to beacon path planning that minimizes the group\u2019s position uncertainty. We evaluate our approach with realistic simulations calibrated using real-world data, and present results.",
        "primary_area": "",
        "author": "Anwar Quraishi;Alcherio Martinoli;Anwar Quraishi;Alcherio Martinoli",
        "authorids": "/37086204472;/37325252600;/37086204472;/37325252600",
        "aff": "Distributed Intelligent Systems and Algorithms Laboratory (DISAL), School of Architecture, Civil and Environmental Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Distributed Intelligent Systems and Algorithms Laboratory (DISAL), School of Architecture, Civil and Environmental Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636703/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18232392098322725612&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "School of Architecture, Civil and Environmental Engineering",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9635909",
        "title": "Correlate-and-Excite: Real-Time Stereo Matching via Guided Cost Volume Excitation",
        "track": "main",
        "status": "Poster",
        "abstract": "Volumetric deep learning approach towards stereo matching aggregates a cost volume computed from input left and right images using 3D convolutions. Recent works showed that utilization of extracted image features and a spatially varying cost volume aggregation complements 3D convolutions. However, existing methods with spatially varying operations are complex, cost considerable computation time, and cause memory consumption to increase. In this work, we construct Guided Cost volume Excitation (GCE) and show that simple channel excitation of cost volume guided by image can improve performance considerably. Moreover, we propose a novel method of using top-k selection prior to soft-argmin disparity regression for computing the final disparity estimate. Combining our novel contributions, we present an end-to-end network that we call Correlate-and-Excite (CoEx). Extensive experiments of our model on the SceneFlow, KITTI 2012, and KITTI 2015 datasets demonstrate the effectiveness and efficiency of our model and show that our model outperforms other speed-based algorithms while also being competitive to other state-of-the-art algorithms. Codes will be made available at https://github.com/antabangun/coex.",
        "primary_area": "",
        "author": "Antyanta Bangunharcana;Jae Won Cho;Seokju Lee;In So Kweon;Kyung-Soo Kim;Soohyun Kim;Antyanta Bangunharcana;Jae Won Cho;Seokju Lee;In So Kweon;Kyung-Soo Kim;Soohyun Kim",
        "authorids": "/37088568123;/37290237700;/37085378123;/37270474800;/37292681500;/37309955400;/37088568123;/37290237700;/37085378123;/37270474800;/37292681500;/37309955400",
        "aff": "Mechatronics, Systems and Control Laboratory, KAIST, Daejeon, Republic of Korea; Robotics and Computer Vision Laboratory, KAIST, Daejeon, Republic of Korea; Robotics and Computer Vision Laboratory, KAIST, Daejeon, Republic of Korea; Robotics and Computer Vision Laboratory, KAIST, Daejeon, Republic of Korea; Mechatronics, Systems and Control Laboratory, KAIST, Daejeon, Republic of Korea; Mechatronics, Systems and Control Laboratory, KAIST, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635909/",
        "gs_citation": 85,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8545370654617810421&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "KAIST",
        "aff_unique_dep": "Mechatronics, Systems and Control Laboratory",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636646",
        "title": "Coupling-dependent convergence behavior of phase oscillators with tegotae-control",
        "track": "main",
        "status": "Poster",
        "abstract": "A bio-inspired way to model locomotion is using a network of coupled phase oscillators to create a Central Pattern Generator (CPG). The recently developed feedback control method tegotae includes exteroceptive force feedback into the governing phase update equations, leading to gait limit cycles. However, the oscillator coupling weights are often determined empirically. Here, we first investigate how the coupling coefficients influence the limit cycle convergence behavior on a 2- and 3-limbed structure in simulation. We find that the convergence with tegotae can be improved by introducing appropriate cross-couplings. This results in a smoother convergence and steady-state behavior where each individual oscillator drives the full network to a common convergence state in comparison to competing convergence states with ill-chosen cross-couplings. We then validate the findings in hardware and hypothesize how the appropriate couplings could be derived directly from the morphology, potentially eliminating the empiric determination.",
        "primary_area": "",
        "author": "Simon Hauser;Matthieu Dujany;Jonathan Arreguit;Auke Ijspeert;Fumiya Iida;Simon Hauser;Matthieu Dujany;Jonathan Arreguit;Auke Ijspeert;Fumiya Iida",
        "authorids": "/38243975000;/37088689141;/37086600379;/37268732300;/37552719700;/38243975000;/37088689141;/37086600379;/37268732300;/37552719700",
        "aff": "Department of Engineering, Bio-Inspired Robotics Laboratory (BIRL), University of Cambridge, Cambridge, UK; Biorobotics Laboratory (BIOROB), Institute of Bioengineering, School of Engineering, Epfl, Lausanne, Switzerland; Biorobotics Laboratory (BIOROB), Institute of Bioengineering, School of Engineering, Epfl, Lausanne, Switzerland; Biorobotics Laboratory (BIOROB), Institute of Bioengineering, School of Engineering, Epfl, Lausanne, Switzerland; Department of Engineering, Bio-Inspired Robotics Laboratory (BIRL), University of Cambridge, Cambridge, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636646/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=509111032715534126&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of Cambridge;EPFL",
        "aff_unique_dep": "Department of Engineering;Institute of Bioengineering",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.epfl.ch",
        "aff_unique_abbr": "Cambridge;EPFL",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Cambridge;Lausanne",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "United Kingdom;Switzerland"
    },
    {
        "id": "9635968",
        "title": "CovarianceNet: Conditional Generative Model for Correct Covariance Prediction in Human Motion Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "The correct characterization of uncertainty when predicting human motion is equally important as the accuracy of this prediction. We present a new method to correctly predict the uncertainty associated with the predicted distribution of future trajectories. Our approach, CovariaceNet, is based on a Conditional Generative Model with Gaussian latent variables in order to predict the parameters of a bi-variate Gaussian distribution. The combination of CovarianceNet with a motion prediction model results in a hybrid approach that outputs a uni-modal distribution. We will show how some state of the art methods in motion prediction become overconfident when predicting uncertainty, according to our proposed metric and validated in the ETH data-set [1]. CovarianceNet correctly predicts uncertainty, which makes our method suitable for applications that use predicted distributions, e.g., planning or decision making.",
        "primary_area": "",
        "author": "Aleksey Postnikov;Aleksander Gamayunov;Gonzalo Ferrer;Aleksey Postnikov;Aleksander Gamayunov;Gonzalo Ferrer",
        "authorids": "/37088806694;/37089194924;/38469245200;/37088806694;/37089194924;/38469245200",
        "aff": "Skolkovo Institute of Science and Technology, Moscow, Russia; Skolkovo Institute of Science and Technology, Moscow, Russia; Skolkovo Institute of Science and Technology, Moscow, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635968/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4053254728522123526&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Skolkovo Institute of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.skoltech.ru",
        "aff_unique_abbr": "Skoltech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Moscow",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "9636645",
        "title": "Coxgraph: Multi-Robot Collaborative, Globally Consistent, Online Dense Reconstruction System",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time dense reconstruction has been extensively studied for its wide applications in computer vision and robotics, meanwhile much effort has been made for the multi-robot system which plays an irreplaceable role in complicated but time-critical scenarios, e.g., search and rescue tasks. In this paper, we propose an efficient system named Coxgraph for multi-robot collaborative dense reconstruction in real-time. In our system, each client performs volumetric mapping in a producer-consumer manner. To facilitate transmission, we propose a compact 3D representation which transforms the SDF submap to mesh packs. During the recovery of submaps from mesh packs, the system can perform loop closure outlier rejection based on geometry consistency, trajectory collision and fitness check. Then we develop a robust map fusion method through joint optimization of trajectories and submaps. Extensive experiments demonstrate that our system can produce a globally consistent dense map in real-time with less transmission load, which is available as open-source software 1.",
        "primary_area": "",
        "author": "Xiangyu Liu;Weicai Ye;Chaoran Tian;Zhaopeng Cui;Hujun Bao;Guofeng Zhang;Xiangyu Liu;Weicai Ye;Chaoran Tian;Zhaopeng Cui;Hujun Bao;Guofeng Zhang",
        "authorids": "/37089195548;/37088645513;/37088348806;/37085646310;/37271755400;/37405938800;/37089195548;/37088645513;/37088348806;/37085646310;/37271755400;/37405938800",
        "aff": "State Key Lab of CAD&CG, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China; State Key Lab of CAD&CG, Zhejiang University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636645/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4365926831197471879&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Lab of CAD&CG",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636498",
        "title": "Cross-Modal 3D Object Detection and Tracking for Auto-Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Detecting and tracking objects in 3D scenes play crucial roles in autonomous driving. Successfully recognizing objects through space and time hinges on a strong detector and a reliable association scheme. Recent 3D detection and tracking approaches widely represent objects as points when associating detection results with trajectories. Despite the demonstrated success, these approaches do not fully exploit the rich appearance information of objects. In this paper, we present a conceptually simple yet effective algorithm, named AlphaTrack, which considers both the location and appearance changes to perform joint 3D object detection and tracking. To achieve this, we propose a cross-modal fusion scheme that fuses camera appearance feature with LiDAR feature to facilitate 3D detection and tracking. We further attach an additional branch to the 3D detector to output instance-aware appearance embedding, which significantly improves tracking performance with our designed association mechanisms. Extensive validations on large-scale autonomous driving dataset demonstrate the effectiveness of the proposed algorithm in comparison with state-of-the-art approaches. Notably, the proposed algorithm ranks first on the nuScenes tracking leaderboard to date.",
        "primary_area": "",
        "author": "Yihan Zeng;Chao Ma;Ming Zhu;Zhiming Fan;Xiaokang Yang;Yihan Zeng;Chao Ma;Ming Zhu;Zhiming Fan;Xiaokang Yang",
        "authorids": "/37089196733;/37076012000;/37088887893;/37089198017;/37275557500;/37089196733;/37076012000;/37088887893;/37089198017;/37275557500",
        "aff": "MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China; MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636498/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15903519709849843168&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "MoE Key Lab of Artificial Intelligence, AI Institute",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636158",
        "title": "Cross-Modal Analysis of Human Detection for Robotics: An Industrial Case Study",
        "track": "main",
        "status": "Poster",
        "abstract": "Advances in sensing and learning algorithms have led to increasingly mature solutions for human detection by robots, particularly in selected use-cases such as pedestrian detection for self-driving cars or close-range person detection in consumer settings. Despite this progress, the simple question which sensor-algorithm combination is best suited for a person detection task at hand\u0192 remains hard to answer. In this paper, we tackle this issue by conducting a systematic cross-modal analysis of sensor-algorithm combinations typically used in robotics. We compare the performance of state-of-the-art person detectors for 2D range data, 3D lidar, and RGB-D data as well as selected combinations thereof in a challenging industrial use-case.We further address the related problems of data scarcity in the industrial target domain, and that recent research on human detection in 3D point clouds has mostly focused on autonomous driving scenarios. To leverage these methodological advances for robotics applications, we utilize a simple, yet effective multi-sensor transfer learning strategy by extending a strong image-based RGB-D detector to provide cross-modal supervision for lidar detectors in the form of weak 3D bounding box labels.Our results show a large variance among the different approaches in terms of detection performance, generalization, frame rates and computational requirements. As our use-case contains difficulties representative for a wide range of service robot applications, we believe that these results point to relevant open challenges for further research and provide valuable support to practitioners for the design of their robot system.",
        "primary_area": "",
        "author": "Timm Linder;Narunas Vaskevicius;Robert Schirmer;Kai O. Arras;Timm Linder;Narunas Vaskevicius;Robert Schirmer;Kai O. Arras",
        "authorids": "/37085534169;/37391716300;/37086287430;/37276687700;/37085534169;/37391716300;/37086287430;/37276687700",
        "aff": "Robert Bosch GmbH, Corporate Research, Renningen, Germany; Robert Bosch GmbH, Corporate Research, Renningen, Germany; Robert Bosch GmbH, Corporate Research, Renningen, Germany; Robert Bosch GmbH, Corporate Research, Renningen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636158/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18074629414144698967&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Robert Bosch GmbH",
        "aff_unique_dep": "Corporate Research",
        "aff_unique_url": "https://www.bosch.com",
        "aff_unique_abbr": "Bosch",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Renningen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9635978",
        "title": "Cross-layer Configuration Optimization for Localization on Resource-constrained Devices",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile devices are increasingly expected to sup-port high-performance cyber-physical applications in small form factors, e.g., drones and rovers. However, the gap between hardware limitations of these devices and application requirements is still prohibitive \u2013 conflicting goals such as robust, accurate, and efficient execution must be managed carefully to achieve acceptable operation. In this paper, we explore the tradeoff between performance and efficiency in such cyber-physical systems, specifically with respect to localization (a core task for any mobile autonomous device). We perform a design space exploration (DSE) given a number of configurable parameters for both localization algorithm and platform layers. Given the configuration space, we formulate a cross-layer multi-objective optimization problem to explore the tradeoff between localization accuracy and power consumption. We then propose a predictive model for robust execution that can be used to determine desirable configurations at runtime in the face of environmental changes.",
        "primary_area": "",
        "author": "Sandra Hern\u00e1ndez;Jos\u00e9 Araujo;Patric Jensfelt;Ioannis Karagiannis;Ananya Muddukrishna;Bryan Donyanavard;Sandra Hern\u00e1ndez;Jos\u00e9 Araujo;Patric Jensfelt;Ioannis Karagiannis;Ananya Muddukrishna;Bryan Donyanavard",
        "authorids": "/37089194425;/37590835500;/37281289200;/38529377300;/37085387734;/37086035868;/37089194425;/37590835500;/37281289200;/38529377300;/37085387734;/37086035868",
        "aff": "Ericsson Research, Sweden; Ericsson Research, Sweden; RPL, KTH Royal Institute of Technology, Sweden; Ericsson Research, Sweden; Ericsson Research, Sweden; Department of Computer Science, San Diego State University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635978/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11139074465024866279&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;2",
        "aff_unique_norm": "Ericsson Research;KTH Royal Institute of Technology;San Diego State University",
        "aff_unique_dep": ";RPL;Department of Computer Science",
        "aff_unique_url": "https://www.ericsson.com/research;https://www.kth.se;https://www.sdsu.edu",
        "aff_unique_abbr": "Ericsson;KTH;SDSU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";San Diego",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "9636579",
        "title": "Crowd-Aware Robot Navigation for Pedestrians with Multiple Collision Avoidance Strategies via Map-based Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "It is challenging for a mobile robot to navigate through human crowds. Existing approaches usually assume that pedestrians follow a predefined collision avoidance strategy, like social force model (SFM) or optimal reciprocal collision avoidance (ORCA). However, their performances commonly need to be further improved for practical applications, where pedestrians follow multiple different collision avoidance strategies. In this paper, we propose a map-based deep reinforcement learning approach for crowd-aware robot navigation with various pedestrians. We use the sensor map to represent the environmental information around the robot, including its shape and observable appearances of obstacles. We also introduce the pedestrian map that specifies the movements of pedestrians around the robot. By applying both maps as inputs of the neural network, we show that a navigation policy can be trained to better interact with pedestrians following different collision avoidance strategies. We evaluate our approach under multiple scenarios both in the simulator and on an actual robot. The results show that our approach allows the robot to successfully interact with various pedestrians and outperforms compared methods in terms of the success rate.",
        "primary_area": "",
        "author": "Shunyi Yao;Guangda Chen;Quecheng Qiu;Jun Ma;Xiaoping Chen;Jianmin Ji;Shunyi Yao;Guangda Chen;Quecheng Qiu;Jun Ma;Xiaoping Chen;Jianmin Ji",
        "authorids": "/37088594684;/37086702150;/37089194199;/37088597940;/37439596700;/38100458700;/37088594684;/37086702150;/37089194199;/37088597940;/37439596700;/38100458700",
        "aff": "School of Computer Science and Technology, University of Science and Technology of China (USTC), Hefei, China; School of Computer Science and Technology, University of Science and Technology of China (USTC), Hefei, China; School of Data Science, USTC, Hefei, China; School of Data Science, USTC, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China (USTC), Hefei, China; School of Computer Science and Technology, University of Science and Technology of China (USTC), Hefei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636579/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18197310678009173867&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "School of Computer Science and Technology",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hefei",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636008",
        "title": "Cursor-based Robot Tele-manipulation through 2D-to-SE2 Interfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "Cursor-based tele-operation interfaces for manipulators can enable widely available and accessible control of robots to make many near term applications possible. However, their efficiency is restricted by the challenge of controlling 6 Degrees-of-Freedom (DoF) with 2D input from the cursor. Existing interfaces make use of different strategies to tackle this challenge, including viewpoint constraints, mode switching, and visual overlays, but it is unclear how these strategies impact the efficiency and accessibility of the interface. In this paper we characterize the design space of cursor-based robot control interfaces and compare alternatives in two user studies. Study 1 (N=216) compares nine alternative interfaces focusing on control of 3 DoFs to understand the differences of the interfaces at the basic level and examine the impact of task parameters on efficiency. Study 2 (N=60) compares a subset of the interfaces integrated into a system that allows full control of a robot manipulator from three orthogonal views. We also present a framework for heuristically evaluating accessibility of these interfaces and discuss the efficiency and accessibility trade-off with recommendations.",
        "primary_area": "",
        "author": "Maria E. Cabrera;Kavi Dey;Kavita Krishnaswamy;Tapomayukh Bhattacharjee;Maya Cakmak;Maria E. Cabrera;Kavi Dey;Kavita Krishnaswamy;Tapomayukh Bhattacharjee;Maya Cakmak",
        "authorids": "/37086667242;/37088946999;/37089195058;/37531634500;/37409159800;/37086667242;/37088946999;/37089195058;/37531634500;/37409159800",
        "aff": "University of Washington, USA; Seattle Academy, USA; U. of Maryland, USA; University of Washington, USA; University of Washington, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636008/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8604137551070190476&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "University of Washington;Seattle Academy;University of Maryland",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.washington.edu;;https://www/umd.edu",
        "aff_unique_abbr": "UW;;UMD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636169",
        "title": "DEALIO: Data-Efficient Adversarial Learning for Imitation from Observation",
        "track": "main",
        "status": "Poster",
        "abstract": "In imitation learning from observation (IfO), a learning agent seeks to imitate a demonstrating agent using only observations of the demonstrated behavior without access to the control signals generated by the demonstrator. Recent methods based on adversarial imitation learning have led to state-of-the-art performance on IfO problems, but they typically suffer from high sample complexity due to a reliance on data-inefficient, model-free reinforcement learning algorithms. This issue makes them impractical to deploy in real-world settings, where gathering samples can incur high costs in terms of time, energy, and risk. In this work, we hypothesize that we can incorporate ideas from model-based reinforcement learning with adversarial methods for IfO in order to increase the data efficiency of these methods without sacrificing performance. Specifically, we consider time-varying linear Gaussian policies, and propose a method that integrates the linear-quadratic regulator with path integral policy improvement into an existing adversarial IfO framework. The result is a more data-efficient IfO algorithm with better performance, which we show empirically in four simulation domains: using far fewer interactions with the environment, the proposed method exhibits similar or better performance than the existing technique.",
        "primary_area": "",
        "author": "Faraz Torabi;Garrett Warnell;Peter Stone;Faraz Torabi;Garrett Warnell;Peter Stone",
        "authorids": "/37088467305;/37079072000;/37269574900;/37088467305;/37079072000;/37269574900",
        "aff": "Department of Computer Science, The University of Texas at Austin, USA; Department of Computer Science, Army Research Laboratory, USA, The University of Texas at Austin, USA; Department of Computer Science, The University of Texas at Austin and Sony AI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636169/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=137562434966196866&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636501",
        "title": "DLL: Direct LIDAR Localization. A map-based localization approach for aerial robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents DLL, a fast direct map-based localization technique using 3D LIDAR for its application to aerial robots. DLL implements a point cloud to map registration based on non-linear optimization of the distance of the points and the map, thus not requiring features, neither point correspondences. Given an initial pose, the method is able to track the pose of the robot by refining the predicted pose from odometry. Through benchmarks using real datasets and simulations, we show how the method performs much better than Monte-Carlo localization methods and achieves comparable precision to other optimization-based approaches but running one order of magnitude faster. The method is also robust under odometric errors. The approach has been implemented under the Robot Operating System (ROS), and it is publicly available.",
        "primary_area": "",
        "author": "Fernando Caballero;Luis Merino;Fernando Caballero;Luis Merino",
        "authorids": "/37282357300;/37282385100;/37282357300;/37282385100",
        "aff": "Service Robotics Laboratory, Universidad de Sevilla, Seville, Spain; Service Robotics Laboratory, Universidad Pablo de Olavide, Seville, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636501/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11595155777590947611&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Universidad de Sevilla;Universidad Pablo de Olavide",
        "aff_unique_dep": "Service Robotics Laboratory;Service Robotics Laboratory",
        "aff_unique_url": "https://www.us.es;https://www.upo.es",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9636362",
        "title": "DMotion: Robotic Visuomotor Control with Unsupervised Forward Model Learned from Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning an accurate model of the environment is essential for model-based control tasks. Existing methods in robotic visuomotor control usually learn from data with heavily labelled actions, object entities or locations, which can be demanding in many cases. To cope with this limitation, we propose a method, dubbed DMotion, that trains a forward model from video data only, via disentangling the motion of controllable agent to model the transition dynamics. An object extractor and an interaction learner are trained in an end-to-end manner without supervision. The agent\u2019s motions are explicitly represented using spatial transformation matrices containing physical meanings. In the experiments, DMotion achieves superior performance on learning an accurate forward model in a Grid World environment, as well as a more realistic robot control environment in simulation. With the accurate learned forward models, we further demonstrate their usage in model predictive control as an effective approach for robotic manipulations. Code, video and more materials are available at: https://hyperplane-lab.github.io/dmotion.",
        "primary_area": "",
        "author": "Haoqi Yuan;Ruihai Wu;Andrew Zhao;Haipeng Zhang;Zihan Ding;Hao Dong;Haoqi Yuan;Ruihai Wu;Andrew Zhao;Haipeng Zhang;Zihan Ding;Hao Dong",
        "authorids": "/37089197338;/37089197962;/37089197990;/37089196925;/37089399494;/37088968899;/37089197338;/37089197962;/37089197990;/37089196925;/37089399494;/37088968899",
        "aff": "CFCS, CS Dept., Peking University; CFCS, CS Dept., Peking University; CFCS, CS Dept., Peking University; CFCS, CS Dept., Peking University; Princeton University; Peng Cheng Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636362/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12583024067440250810&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "Peking University;Princeton University;Pengcheng Laboratory",
        "aff_unique_dep": "Computer Science Department;;Peng Cheng Lab",
        "aff_unique_url": "http://www.pku.edu.cn;https://www.princeton.edu;",
        "aff_unique_abbr": "PKU;Princeton;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9635949",
        "title": "DRQN-based 3D Obstacle Avoidance with a Limited Field of View",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a map-based end-to-end DRL approach for three-dimensional (3D) obstacle avoidance in a partially observed environment, which is applied to achieve autonomous navigation for an indoor mobile robot using a depth camera with a narrow field of view. We first train a neural network with LSTM units in a 3D simulator of mobile robots to approximate the Q-value function in double DRQN. We also use a curriculum learning strategy to accelerate and stabilize the training process. Then we deploy the trained model to a real robot to perform 3D obstacle avoidance in its navigation. We evaluate the proposed approach both in the simulated environment and on a robot in the real world. The experimental results show that the approach is efficient and easy to be deployed, and it performs well for 3D obstacle avoidance with a narrow observation angle, which outperforms other existing DRL-based models by 15.5% on success rate.",
        "primary_area": "",
        "author": "Yu\u2019an Chen;Guangda Chen;Lifan Pan;Jun Ma;Yu Zhang;Yanyong Zhang;Jianmin Ji;Yu\u2019an Chen;Guangda Chen;Lifan Pan;Jun Ma;Yu Zhang;Yanyong Zhang;Jianmin Ji",
        "authorids": "/37089001547;/37086702150;/37088543648;/37088597940;/37676486300;/37279961200;/38100458700;/37089001547;/37086702150;/37088543648;/37088597940;/37676486300;/37279961200;/38100458700",
        "aff": "School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635949/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16439474831936583016&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "School of Computer Science and Technology",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Hefei",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636473",
        "title": "DSVP: Dual-Stage Viewpoint Planner for Rapid Exploration by Dynamic Expansion",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for efficiently exploring highly convoluted environments. The method incorporates two planning stages - an exploration stage for extending the boundary of the map, and a relocation stage for explicitly transiting the robot to different sub-areas in the environment. The exploration stage develops a local Rapidly-exploring Random Tree (RRT) in the free space of the environment, and the relocation stage maintains a global graph through the mapped environment, both are dynamically expanded over replanning steps. The method is compared to existing state-of-the-art methods in various challenging simulation and real environments. Experiment comparisons show that our method is twice as efficient in exploring spaces using less processing than the existing methods. Further, we release a benchmark environment to evaluate exploration algorithms as well as facilitate development of autonomous navigation systems. The benchmark environment and our method are open-sourced.",
        "primary_area": "",
        "author": "Hongbiao Zhu;Chao Cao;Yukun Xia;Sebastian Scherer;Ji Zhang;Weidong Wang;Hongbiao Zhu;Chao Cao;Yukun Xia;Sebastian Scherer;Ji Zhang;Weidong Wang",
        "authorids": "/37086564449;/37086934694;/37089198269;/37584159000;/38541910000;/37696479700;/37086564449;/37086934694;/37089198269;/37584159000;/38541910000;/37696479700",
        "aff": "Robotics Institute, Harbin Institute of Technology, Harbin, China; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636473/",
        "gs_citation": 85,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16659949466447151920&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;0",
        "aff_unique_norm": "Harbin Institute of Technology;Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute;Robotics Institute",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.cmu.edu",
        "aff_unique_abbr": "HIT;CMU",
        "aff_campus_unique_index": "0;1;1;1;1;0",
        "aff_campus_unique": "Harbin;Pittsburgh",
        "aff_country_unique_index": "0;1;1;1;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9636399",
        "title": "DT*: Temporal Logic Path Planning in a Dynamic Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Path planning for a robot is one of the major problems in the area of robotics. When a robot is given a task in the form of a Linear Temporal Logic (LTL) specification such that the task needs to be carried out repetitively, we want the robot to follow the shortest cyclic path so that the number of times the robot completes the mission within a given duration gets maximized. In this paper, we address the LTL path planning problem in a dynamic environment where the newly arrived dynamic obstacles may invalidate some of the available paths at any arbitrary point in time. We present DT*, an SMT-based receding horizon planning strategy that solves an optimization problem repetitively based on the current status of the workspace to lead the robot to follow the best available path in the current situation. We implement our algorithm using the Z3 SMT solver and evaluate it extensively on an LTL specification capturing a pick-and-drop application in a warehouse environment and an office environment2. We compare our SMT-based algorithm with two carefully crafted greedy algorithms. Our experimental results show that the proposed algorithm can deal with the dynamism in the workspace in LTL path planning effectively.",
        "primary_area": "",
        "author": "Priya Purohit;Indranil Saha;Priya Purohit;Indranil Saha",
        "authorids": "/37089195827;/37542496500;/37089195827;/37542496500",
        "aff": "Department of Computer Science and Engineering, Indian Institute of Technology Kanpur; Department of Computer Science and Engineering, Indian Institute of Technology Kanpur",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636399/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=866664928499327658&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Technology Kanpur",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.iitk.ac.in",
        "aff_unique_abbr": "IIT Kanpur",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kanpur",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9636419",
        "title": "DT-Loc: Monocular Visual Localization on HD Vector Map Using Distance Transforms of 2D Semantic Detections",
        "track": "main",
        "status": "Poster",
        "abstract": "Localizing a vehicle on a prebuilt HD vector map is a prerequisite for many autonomous driving applications. Existing visual localization approaches usually require a separate local feature layer to function. The separate localization layer suffers from the robustness issue inherited from the local features. Also, it could be difficult to create a feature layer that aligns perfectly with an existing vector map. In this paper, we propose a monocular visual localization method that exploits the vector map directly as the localization layer. The method detects semantic traffic elements from the images and matches them with the vectors in the map. To deal with the harmful problem of false matches, we propose to align the vector map to the distance transforms of the semantic detections, which enables a non-explicit and differentiable data association process. The system is able to achieve centimeter and sub-meter accuracies in lateral and longitudinal directions, respectively.",
        "primary_area": "",
        "author": "Chi Zhang;Hao Liu;Hao Li;Kun Guo;Kuiyuan Yang;Rui Cai;Zhiwei Li;Chi Zhang;Hao Liu;Hao Li;Kun Guo;Kuiyuan Yang;Rui Cai;Zhiwei Li",
        "authorids": "/37086571645;/37089264989;/37089263794;/37089197149;/37089194101;/37284702100;/37404741200;/37086571645;/37089264989;/37089263794;/37089197149;/37089194101;/37284702100;/37404741200",
        "aff": "Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636419/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16439348169877570180&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Xiaomi Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.xiaomi.com",
        "aff_unique_abbr": "Xiaomi",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636680",
        "title": "DarkLighter: Light Up the Darkness for UAV Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent years have witnessed the fast evolution and promising performance of the convolutional neural network (CNN)-based trackers, which aim at imitating biological visual systems. However, current CNN-based trackers can hardly generalize well to low-light scenes that are commonly lacked in the existing training set. In indistinguishable night scenarios frequently encountered in unmanned aerial vehicle (UAV) tracking-based applications, the robustness of the state-of-the-art (SOTA) trackers drops significantly. To facilitate aerial tracking in the dark through a general fashion, this work proposes a low-light image enhancer namely DarkLighter, which dedicates to alleviate the impact of poor illumination and noise iteratively. A lightweight map estimation network, i.e., ME-Net, is trained to efficiently estimate illumination maps and noise maps jointly. Experiments are conducted with several SOTA trackers on numerous UAV dark tracking scenes. Exhaustive evaluations demonstrate the reliability and universality of DarkLighter, with high efficiency. Moreover, DarkLighter has further been implemented on a typical UAV system. Real-world tests at night scenes have verified its practicability and dependability.",
        "primary_area": "",
        "author": "Junjie Ye;Changhong Fu;Guangze Zheng;Ziang Cao;Bowen Li;Junjie Ye;Changhong Fu;Guangze Zheng;Ziang Cao;Bowen Li",
        "authorids": "/37088917418;/37086797986;/37088996628;/37088997696;/37089000657;/37088917418;/37086797986;/37088996628;/37088997696;/37089000657",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Automotive Studies, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636680/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13396427409545302794&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tongji University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn",
        "aff_unique_abbr": "Tongji",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636541",
        "title": "Data-fusion for robust off-road perception considering data quality of uncertain sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust off-road perception for autonomous navigation is hard to achieve. Versatile environments, different hardware, and numerous disturbances limit the perceptional portability in changing applications and cross-platform. This contribution proposes sensor-fusion considering the data quality of uncertain sensors to increase the classification and mapping components\u2019 perceptual robustness. The resulting benefits on perception are demonstrated using the autonomous off-road robot U5023.",
        "primary_area": "",
        "author": "Patrick Wolf;Karsten Berns;Patrick Wolf;Karsten Berns",
        "authorids": "/37086455222;/37274823100;/37086455222;/37274823100",
        "aff": "Robotics Research Lab, TU Kaiserslautern, Kaiserslautern, Germany; Robotics Research Lab, TU Kaiserslautern, Kaiserslautern, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636541/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13396454763038125867&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "TU Kaiserslautern",
        "aff_unique_dep": "Robotics Research Lab",
        "aff_unique_url": "https://www.tu-kl.de",
        "aff_unique_abbr": "TU KL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kaiserslautern",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636609",
        "title": "Deadlock Prediction and Recovery for Distributed Collision Avoidance with Buffered Voronoi Cells",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a distributed multi-robot collision avoidance algorithm based on the concept of Buffered Voronoi Cells (BVC). We propose a novel algorithm for avoiding deadlocks consisting of three stages: deadlock prediction, deadlock recovery, and deadlock recovery success prediction. Simple heuristics (such as the right-hand rule) are often used to avoid deadlocks. Such heuristics might reduce deadlock in simple configurations and sparsely populated environments, but they begin to fail in complex configurations and more densely populated environments. We evaluate the performance of our algorithm using an open-source web-based multi-robot simulation. The results show that while the proposed algorithm does not eliminate the occurrence of deadlocks, it drastically reduces their occurrence, and leads to a considerable improvement in performance, especially in high-density environments. We also validate the real-world performance of the proposed algorithm in live experiments.",
        "primary_area": "",
        "author": "Mohammed Abdullhak;Andrew Vardy;Mohammed Abdullhak;Andrew Vardy",
        "authorids": "/37089195275;/37285559900;/37089195275;/37285559900",
        "aff": "Department of Computer Science, Memorial University of Newfoundland, St. John\u2019s, Canada; Department of Computer Science and the Department of Electrical and Computer Engineering, Memorial University of Newfoundland, St. John\u2019s, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636609/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2200293814508277090&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Memorial University of Newfoundland",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.mun.ca",
        "aff_unique_abbr": "MUN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "St. John\u2019s",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636177",
        "title": "Decentralized Classification with Assume-Guarantee Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of decentralized classification conducted over a network of mobile sensors. We model the multiagent classification task as a hypothesis testing problem where each sensor has to almost surely find the true hypothesis from a finite set of candidate hypotheses. Each sensor makes noisy local observations and can also share information on their observations with other mobile sensors in communication range. In order to address the state-space explosion in the multiagent system, we propose a decentralized synthesis procedure that guarantees that each sensor will almost surely converge to the true hypothesis even in the presence of faulty or malicious agents. Additionally, we employ a contract-based synthesis approach that produces trajectories designed to empirically increase information-sharing between mobile sensors in order to converge faster to the true hypothesis. We implement and test the approach on experiments with both physical and simulated hardware to showcase the approach\u2019s scalability and viability in real-world systems. Finally, we run a Gazebo/ROS simulated experiment with 12 agents to demonstrate the scalability of our approach in large environments with many agents.",
        "primary_area": "",
        "author": "Steven Carr;Jesse Quattrociocchi;Suda Bharadwaj;Steven J. Spencer;Anup Parikh;Carol C. Young;Stephen P. Buerger;Bo Wu;Ufuk Topcu;Steven Carr;Jesse Quattrociocchi;Suda Bharadwaj;Steven J. Spencer;Anup Parikh;Carol C. Young;Stephen P. Buerger;Bo Wu;Ufuk Topcu",
        "authorids": "/37086431605;/37089194769;/37086597302;/37979247100;/37085389823;/37089195738;/37294845300;/37085391595;/37299604900;/37086431605;/37089194769;/37086597302;/37979247100;/37085389823;/37089195738;/37294845300;/37085391595;/37299604900",
        "aff": "The University of Texas at Austin; The University of Texas at Austin; The University of Texas at Austin; High Consequence Automation and Robotics, Sandia National Laboratories; High Consequence Automation and Robotics, Sandia National Laboratories; High Consequence Automation and Robotics, Sandia National Laboratories; High Consequence Automation and Robotics, Sandia National Laboratories; The University of Texas at Austin; The University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636177/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:BJ5ftENbMSsJ:scholar.google.com/&scioq=Decentralized+Classification+with+Assume-Guarantee+Planning&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;1;1;1;1;0;0",
        "aff_unique_norm": "University of Texas at Austin;Sandia National Laboratories",
        "aff_unique_dep": ";High Consequence Automation and Robotics",
        "aff_unique_url": "https://www.utexas.edu;https://www.sandia.gov",
        "aff_unique_abbr": "UT Austin;SNL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636195",
        "title": "Decentralized Control and Teleoperation of a Multi-UAV Parallel Robot Based on Intrinsic Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial manipulators have great potential in accomplishing a variety of aerial tasks. One class of aerial manipulators, multi-UAV parallel robots, consists of multiple UAVs connected to a payload or an end-effector by passive kinematic chains. The primary limitation of such aerial manipulators is the dependence on motion capture (MOCAP) systems that provide precise and high-rate exteroceptive pose measurements of all bodies in a common inertial frame, but which are impractical in the majority of real applications.This paper proposes a novel methodology of controlling multi-UAV parallel robots, using a Flying Parallel Robot (FPR) as a case study, that could be deployed without a system of external localisation. Intrinsic measurements acquired onboard the UAVs are used to recover a set of robot states that avoid using coordinates derived from a global frame and allow control of the robot by teleoperation. Two decentralized control methods are proposed, based on inter-UAV communicating or non-communicating scenarios. Experiments with intrinsic measurements emulated by MOCAP are carried out to show the performance of the proposed method.",
        "primary_area": "",
        "author": "Shiyu Liu;Julian Erskine;Abdelhamid Chriette;Isabelle Fantoni;Shiyu Liu;Julian Erskine;Abdelhamid Chriette;Isabelle Fantoni",
        "authorids": "/37089196886;/37086938233;/37300806500;/37301364100;/37089196886;/37086938233;/37300806500;/37301364100",
        "aff": "\u00c9cole Centrale de Nantes, Laboratoire des Sciences du Num\u00e9rique de Nantes (LS2N), UMR CNRS, Nantes, France; \u00c9cole Centrale de Nantes, Laboratoire des Sciences du Num\u00e9rique de Nantes (LS2N), UMR CNRS, Nantes, France; \u00c9cole Centrale de Nantes, Laboratoire des Sciences du Num\u00e9rique de Nantes (LS2N), UMR CNRS, Nantes, France; LS2N, Centre National de la Recherche Scientifique, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636195/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17918242553397146945&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "\u00c9cole Centrale de Nantes;Centre National de la Recherche Scientifique",
        "aff_unique_dep": "Laboratoire des Sciences du Num\u00e9rique de Nantes (LS2N);LS2N",
        "aff_unique_url": "https://www.ecn.fr;https://www.cnrs.fr",
        "aff_unique_abbr": "ECN;CNRS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nantes;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636088",
        "title": "Decentralized, Unlabeled Multi-Agent Navigation in Obstacle-Rich Environments using Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a decentralized, learning-based solution to the challenging problem of unlabeled multi-agent navigation among obstacles, where robots need to simultaneously tackle the problems of goal assignment, local collision avoidance, and navigation. Our method has each robot infer their desired action by communicating with each other as well as a set of position-fixed routers. The inference is carried out on a graph neural network (GNN) with both robot and router nodes. We train our GNN using imitation learning on a small group of robots, where we modify the centralized version of the concurrent goal assignment and planning algorithm (CAPT) as our expert. By sharing weights among all robots and routers, our model can scale to unseen environments with any number of possibly kinodynamic agents during test time. We have achieved a success rate of 91.2% and 85.6% for point and car-like robots, respectively. Source code will be publicly available upon the publication of the work.",
        "primary_area": "",
        "author": "Xuebo Ji;He Li;Zherong Pan;Xifeng Gao;Changhe Tu;Xuebo Ji;He Li;Zherong Pan;Xifeng Gao;Changhe Tu",
        "authorids": "/37089196885;/37089194783;/37086067204;/37088506715;/37535215100;/37089196885;/37089194783;/37086067204;/37088506715;/37535215100",
        "aff": "Department of Computer Science, Shandong University; Department of Computer Science, Shandong University; Department of Computer Science, University of Illinois at Urbana Champaign; Department of Computer Science, Florida State University; Department of Computer Science, Shandong University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636088/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10613008327167860720&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Shandong University;University of Illinois Urbana-Champaign;Florida State University",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "http://www.sdu.edu.cn;https://illinois.edu;https://www.fsu.edu",
        "aff_unique_abbr": "SDU;UIUC;FSU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Urbana-Champaign",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9636577",
        "title": "Decoder Fusion RNN: Context and Interaction Aware Decoders for Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Forecasting the future behavior of all traffic agents in the vicinity is a key task to achieve safe and reliable autonomous driving systems. It is a challenging problem as agents adjust their behavior depending on their intentions, the others\u2019 actions, and the road layout. In this paper, we propose Decoder Fusion RNN (DF-RNN), a recurrent, attention-based approach for motion forecasting. Our network is composed of a recurrent behavior encoder, an inter-agent multi-headed attention module, and a context-aware decoder. We design a map encoder that embeds polyline segments, combines them to create a graph structure, and merges their relevant parts with the agents\u2019 embeddings. We fuse the encoded map information with further inter-agent interactions only inside the decoder and propose to use explicit training as a method to effectively utilize the information available. We demonstrate the efficacy of our method by testing it on the Argoverse motion forecasting dataset and show its state-of-the-art performance on the public benchmark.",
        "primary_area": "",
        "author": "Edoardo Mello Rella;Jan-Nico Zaech;Alexander Liniger;Luc Van Gool;Edoardo Mello Rella;Jan-Nico Zaech;Alexander Liniger;Luc Van Gool",
        "authorids": "/37089196910;/37087103975;/37085702116;/37277167600;/37089196910;/37087103975;/37085702116;/37277167600",
        "aff": "Computer Vision Lab, ETH Z\u00fcurich, Switzerland; Computer Vision Lab, ETH Z\u00fcurich, Switzerland; Computer Vision Lab, ETH Z\u00fcurich, Switzerland; PSI, KU Leuven, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636577/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15353045257501183098&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "ETH Zurich;KU Leuven",
        "aff_unique_dep": "Computer Vision Lab;PSI",
        "aff_unique_url": "https://www.ethz.ch;https://www.kuleuven.be",
        "aff_unique_abbr": "ETHZ;KU Leuven",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Z\u00fcrich;",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Switzerland;Belgium"
    },
    {
        "id": "9636870",
        "title": "Decoder Modulation for Indoor Depth Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth completion recovers a dense depth map from sensor measurements. Current methods are mostly tailored for very sparse depth measurements from LiDARs in outdoor settings, while for indoor scenes Time-of-Flight (ToF) or structured light sensors are mostly used. These sensors provide semi-dense maps, with dense measurements in some regions and almost empty in others. We propose a new model that takes into account the statistical difference between such regions. Our main contribution is a new decoder modulation branch added to the encoder-decoder architecture. The encoder extracts features from the concatenated RGB image and raw depth. Given the mask of missing values as input, the proposed modulation branch controls the decoding of a dense depth map from these features differently for different regions. This is implemented by modifying the spatial distribution of output signals inside the decoder via Spatially-Adaptive Denormalization (SPADE) blocks. Our second contribution is a novel on-the- y sensor simulation strategy that allows us to train on a semi-dense sensor data when the ground truth depth map is not available. Our model achieves the state of the art results on indoor Matterport3D dataset [1]. Being designed for semi-dense input depth, our model is still competitive with LiDAR-oriented approaches on the KITTI dataset [2]. Our sensor simulation strategy significantly improves prediction quality with no dense ground truth available, as validated on the NYUv2 dataset [3].",
        "primary_area": "",
        "author": "Dmitry Senushkin;Mikhail Romanov;Ilia Belikov;Nikolay Patakin;Anton Konushin;Dmitry Senushkin;Mikhail Romanov;Ilia Belikov;Nikolay Patakin;Anton Konushin",
        "authorids": "/37089194105;/37086031176;/37089197765;/37089195818;/38306221200;/37089194105;/37086031176;/37089197765;/37089195818;/38306221200",
        "aff": "Lomonosov Moscow State University, Moscow, Russia; Samsung AI Research Center, Moscow, Russia; Samsung AI Research Center, Moscow, Russia; Samsung AI Research Center, Moscow, Russia; Lomonosov Moscow State University, Moscow, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636870/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14814212442475122411&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Lomonosov Moscow State University;Samsung",
        "aff_unique_dep": ";AI Research",
        "aff_unique_url": "https://www.msu.ru;https://www.samsung.com/global/researchers/samsung-ai-research-center/",
        "aff_unique_abbr": "MSU;SARC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Moscow",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "9636588",
        "title": "Deep Leg Tracking by Detection and Gait Analysis in 2D Range Data for Intelligent Robotic Assistants",
        "track": "main",
        "status": "Poster",
        "abstract": "Online human leg tracking and gait analysis are crucial functionalities for mobility assistant robots, like intelligent walkers. Usually, such walkers are equipped with various sensors for the extraction of human-related features for adaptive human-robot interaction and assistance. We treat the gait detection problem jointly, presenting a novel method for detecting and recognizing gait features from 2D range data produced by a laser sensor mounted on a robotic walker. We propose an effective Convolutional Neural Network (CNN) as a powerful feature extractor for detecting the user\u2019s leg centers in range data represented as occupancy grid maps. We couple the CNN with a Long Short Term Memory (LSTM) network for learning the legs\u2019 motion temporal dynamics while walking, improving the prior detection, and providing better leg occlusion handling. Moreover, we perform gait analysis by recognizing gait phases over both legs by feeding the leg tracking output to a subsequent LSTM. Our proposed lightweight framework has been trained and tested on real patients-data. The presented experimental results show our method\u2019s efficiency in providing accurate detections compared to state-of-the-art and application to an online system due to its high frequency, making it a competitive method for gait detection on robotic mobility assistants.",
        "primary_area": "",
        "author": "Danai Efstathiou;Georgia Chalvatzaki;Athanasios Dometios;Dionisios Spiliopoulos;Costas S. Tzafestas;Danai Efstathiou;Georgia Chalvatzaki;Athanasios Dometios;Dionisios Spiliopoulos;Costas S. Tzafestas",
        "authorids": "/37089194482;/37085353493;/37085837403;/37089194321;/37296005200;/37089194482;/37085353493;/37085837403;/37089194321;/37296005200",
        "aff": "Electrical and Computer Engineering, National Technical University of Athens, Greece; Intelligent Robotics for Assistance Group, Technische Universitat Darmstadt, Germany; Electrical and Computer Engineering, National Technical University of Athens, Greece; Electrical and Computer Engineering, National Technical University of Athens, Greece; Electrical and Computer Engineering, National Technical University of Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636588/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14698122394636599669&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "National Technical University of Athens;Technische Universitat Darmstadt",
        "aff_unique_dep": "Electrical and Computer Engineering;Intelligent Robotics for Assistance Group",
        "aff_unique_url": "https://www.ntua.gr;https://www.tu-darmstadt.de",
        "aff_unique_abbr": "NTUA;TU Darmstadt",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Greece;Germany"
    },
    {
        "id": "9636627",
        "title": "Deep Neural Skill Assessment and Transfer: Application to Robotic Surgery Training",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the high sensitivity and complexity of robotic surgery tasks, acquiring appropriate skill levels by trainee surgeons through an effective training process is very important and affects the patient\u2019s safety and the quality of surgical outcomes. With the advanced deep learning technology and the recent availability of surgical procedures data, intelligent methods can be deployed to assess and transfer the skills of an experienced surgeon (mentor) to a novice surgeon (trainee). In this paper, we introduce a novel deep-learning-based skill transfer scheme consisting of a deep convolutional model, SkillNet, and a skill transfer algorithm for robotic surgery training. The proposed SkillNet extracts skill-related features of the mentor from different layers of the network. Then, trainee\u2019s maneuver is enhanced by the proposed skill transfer algorithm while minimizing deviations from the trainee\u2019s original intended trajectory. For validation, the JIGSAWS dataset and also our own experimental data were used to prove the generalizability of SkillNet in capturing skill-related features. The capability of the skill transfer algorithm in enhancing trainee trajectories in terms of predictability, hand tremor reduction, and noise cancellation were investigated separately. The obtained results indicate that this approach can be used as a high-performance filter that makes minor corrections to the input trajectory and improves the skill level of the trainee\u2019s trajectory in practice.",
        "primary_area": "",
        "author": "Abed Soleymani;Xingyu Li;Mahdi Tavakoli;Abed Soleymani;Xingyu Li;Mahdi Tavakoli",
        "authorids": "/37089002006;/37089195399;/37282400400;/37089002006;/37089195399;/37282400400",
        "aff": "Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636627/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4512534644821614267&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Edmonton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9635969",
        "title": "Deep Semantic Segmentation at the Edge for Autonomous Navigation in Vineyard Rows",
        "track": "main",
        "status": "Poster",
        "abstract": "Precision agriculture is a fast-growing field that aims at introducing affordable and effective automation into agricultural processes. Nowadays, algorithmic solutions for navigation in vineyards require expensive sensors and high computational workloads that preclude large-scale applicability of autonomous robotic platforms in real business case scenarios. From this perspective, our novel proposed control leverages the latest advancement in machine perception and edge AI techniques to achieve highly affordable and reliable navigation inside vineyard rows with low computational and power consumption. Indeed, using a custom-trained segmentation network and a low-range RGB-D camera, we are able to take advantage of the semantic information of the environment to produce smooth trajectories and stable control in different vineyards scenarios. Moreover, the segmentation maps generated by the control algorithm itself could be directly exploited as filters for a vegetative assessment of the crop status. Extensive experimentations and evaluations against real-world data and simulated environments demonstrated the effectiveness and intrinsic robustness of our methodology.",
        "primary_area": "",
        "author": "Diego Aghi;Simone Cerrato;Vittorio Mazzia;Marcello Chiaberge;Diego Aghi;Simone Cerrato;Vittorio Mazzia;Marcello Chiaberge",
        "authorids": "/37088949027;/37088949480;/37087094427;/37352548500;/37088949027;/37088949480;/37087094427;/37352548500",
        "aff": "Department of Electronics and Telecommunications, Politecnico di Torino, Turin, Italy; Department of Electronics and Telecommunications, Politecnico di Torino, Turin, Italy; Department of Electronics and Telecommunications, Politecnico di Torino, Turin, Italy; Department of Electronics and Telecommunications, Politecnico di Torino, Turin, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635969/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1225591817228379917&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Politecnico di Torino",
        "aff_unique_dep": "Department of Electronics and Telecommunications",
        "aff_unique_url": "https://www.polito.it",
        "aff_unique_abbr": "Politecnico di Torino",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Turin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636131",
        "title": "Deep Unsupervised Learning Based Visual Odometry with Multi-scale Matching and Latent Feature Constraint",
        "track": "main",
        "status": "Poster",
        "abstract": "A novel siamese autoencoder visual odometry system named SAEVO is proposed in this paper. SAEVO can jointly estimate the 6-DoF pose and the depth using deep neural networks trained with monocular clips only. The main idea of the proposed method is an unsupervised deep learning scheme that combines siamese networks with auto-encoder for multi-scale matching to estimate ego-motion. Also, two unsupervised losses are designed to align extracted features from the siamese autoencoder networks. A system overview is shown in Fig. 1. The experiments on KITTI and CityScapes datasets demonstrate the SAEVO achieves good performance in terms of pose and depth accuracy, and competitive performance to state-of-the-art methods.",
        "primary_area": "",
        "author": "Zhenzhen Liang;Qixin Wang;Yuanlong Yu;Zhenzhen Liang;Qixin Wang;Yuanlong Yu",
        "authorids": "/37087246013;/37089197988;/37089854109;/37087246013;/37089197988;/37089854109",
        "aff": "AI Institute, Ecovacs Robotics, Nanjing, China; AI Institute, Ecovacs Robotics, Nanjing, China; AI Institute, Ecovacs Robotics, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636131/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18033125747014000672&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ecovacs Robotics",
        "aff_unique_dep": "AI Institute",
        "aff_unique_url": "https://www.ecovacs.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636408",
        "title": "DeepKoCo: Efficient latent planning with a task-relevant Koopman representation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents DeepKoCo, a novel modelbased agent that learns a latent Koopman representation from images. This representation allows DeepKoCo to plan efficiently using linear control methods, such as linear model predictive control. Compared to traditional agents, DeepKoCo learns taskrelevant dynamics, thanks to the use of a tailored lossy autoencoder network that allows DeepKoCo to learn latent dynamics that reconstruct and predict only observed costs, rather than all observed dynamics. As our results show, DeepKoCo achieves a similar final performance as traditional model-free methods on complex control tasks, while being considerably more robust to distractor dynamics, making the proposed agent more amenable for real-life applications.",
        "primary_area": "",
        "author": "Bas van der Heijden;Laura Ferranti;Jens Kober;Robert Babu\u0161ka;Bas van der Heijden;Laura Ferranti;Jens Kober;Robert Babu\u0161ka",
        "authorids": "/37089197872;/37085778570;/37542833400;/37270682600;/37089197872;/37085778570;/37542833400;/37270682600",
        "aff": "Cognitive Robotics at the Faculty of 3mE, Delft University of Technology, The Netherlands; Cognitive Robotics at the Faculty of 3mE, Delft University of Technology, The Netherlands; Cognitive Robotics at the Faculty of 3mE, Delft University of Technology, The Netherlands; Cognitive Robotics at the Faculty of 3mE, Delft University of Technology, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636408/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11114127324362841368&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Faculty of 3mE",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TUDelft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9636504",
        "title": "DeepRelativeFusion: Dense Monocular SLAM using Single-Image Relative Depth Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional monocular visual simultaneous localization and mapping (SLAM) algorithms have been extensively studied and proven to reliably recover a sparse structure and camera motion. Nevertheless, the sparse structure is still insufficient for scene interaction, e.g., visual navigation and augmented reality applications. To densify the scene reconstruction, the use of single-image absolute depth prediction from convolutional neural networks (CNNs) for filling in the missing structure has been proposed. However, the prediction accuracy tends to not generalize well on scenes that are different from the training datasets.In this paper, we propose a dense monocular SLAM system, named DeepRelativeFusion, that is capable to recover a globally consistent 3D structure. To this end, we use a visual SLAM algorithm to reliably recover the camera poses and semi-dense depth maps of the keyframes, and then use relative depth prediction to densify the semi-dense depth maps and refine the keyframe pose-graph. To improve the semi-dense depth maps, we propose an adaptive filtering scheme, which is a structure- preserving weighted average smoothing filter that takes into account the pixel intensity and depth of the neighbouring pixels, yielding substantial reconstruction accuracy gain in densification. To perform densification, we introduce two incremental improvements upon the energy minimization framework proposed by DeepFusion: (1) an improved cost function, and(2) the use of single-image relative depth prediction. After densification, we update the keyframes with two-view consistent optimized semi-dense and dense depth maps to improve pose- graph optimization, providing a feedback loop to refine the keyframe poses for accurate scene reconstruction. Our system outperforms the state-of-the-art dense SLAM systems quantitatively in dense reconstruction accuracy by a large margin.For more information, see the demo video and supplementary material.",
        "primary_area": "",
        "author": "Shing Yan Loo;Syamsiah Mashohor;Sai Hong Tang;Hong Zhang;Shing Yan Loo;Syamsiah Mashohor;Sai Hong Tang;Hong Zhang",
        "authorids": "/37086936856;/37266078200;/37891138200;/37280789900;/37086936856;/37266078200;/37891138200;/37280789900",
        "aff": "Faculty of Engineering, Universiti Putra Malaysia, Malaysia; Faculty of Engineering, Universiti Putra Malaysia, Malaysia; Faculty of Engineering, Universiti Putra Malaysia, Malaysia; Department of Computing Science, University of Alberta, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636504/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7553927203762423777&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Universiti Putra Malaysia;University of Alberta",
        "aff_unique_dep": "Faculty of Engineering;Department of Computing Science",
        "aff_unique_url": "https://www.upm.edu.my;https://www.ualberta.ca",
        "aff_unique_abbr": "UPM;UAlberta",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Malaysia;Canada"
    },
    {
        "id": "9636423",
        "title": "DeepSIL: A Software-in-the-Loop Framework for Evaluating Motion Planning Schemes Using Multiple Trajectory Prediction Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Testing and verification is still an open issue on the way to fully automated driving. Simulations can help to reduce the required testing efforts, however, classical simulators based on physical models and heuristics, such as the intelligent driver model (IDM), show limited model accuracy on a microscopic scenario level. In turn, learning-based driver models are often capable to predict human driver\u2019s behavior accurately, but are difficult to tailor such that they follow an intended scenario description. In this work, we propose a software-in-the-loop framework to combine a learned model with a rule-based logic layer and a kinematic vehicle model of a classical traffic simulator. Thus, the merits of both, classical simulators and learning-based models are exploited. We demonstrate with a case study of evaluating a motion planning scheme that the simulator fits well with the needs of testing such methods. Furthermore, we show by experiments with real-world traffic data from a traffic surveillance system that the proposed simulator yields realistic behavior of the simulated road users.",
        "primary_area": "",
        "author": "Jan Strohbeck;Johannes M\u00fcller;Adrian Holzbock;Michael Buchholz;Jan Strohbeck;Johannes M\u00fcller;Adrian Holzbock;Michael Buchholz",
        "authorids": "/37087103892;/37086442433;/37089193919;/38180084100;/37087103892;/37086442433;/37089193919;/38180084100",
        "aff": "Institute of Measurement, Control and Microtechnology, Ulm University, D-89081, Germany; Institute of Measurement, Control and Microtechnology, Ulm University, D-89081, Germany; Institute of Measurement, Control and Microtechnology, Ulm University, D-89081, Germany; Institute of Measurement, Control and Microtechnology, Ulm University, D-89081, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636423/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=607779511517992271&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Ulm University",
        "aff_unique_dep": "Institute of Measurement, Control and Microtechnology",
        "aff_unique_url": "https://www.uni-ulm.de",
        "aff_unique_abbr": "Ulm U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ulm",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636808",
        "title": "Deformable Elasto-Plastic Object Shaping using an Elastic Hand and Model-Based Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Deformable solid objects such as clay or dough are prevalent in industrial and home environments. However, robotic manipulation of such objects has largely remained unexplored in literature due to the high complexity involved in representing and modeling their deformation. This work addresses the problem of shaping elasto-plastic dough by proposing to use a novel elastic end-effector to roll dough in a reinforcement learning framework. The transition model for the end-effector-to-dough interactions is learned from one hour of robot exploration, and doughs of different hydration levels are rolled out into varying lengths. Experimental results are encouraging, with the proposed framework accomplishing the task of rolling out dough into a specified length with 60% fewer actions than a heuristic method. Furthermore, we show that estimating stiffness using the soft end-effector can be used to effectively initialize models, improving robot performance by approximately 40% over incorrect model initialization.",
        "primary_area": "",
        "author": "Carolyn Matl;Ruzena Bajcsy;Carolyn Matl;Ruzena Bajcsy",
        "authorids": "/37087324669;/37298488400;/37087324669;/37298488400",
        "aff": "Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636808/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2628584108955497819&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636157",
        "title": "Deformation Control of a Deformable Object Based on Visual and Tactile Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we presented a new method for deformation control of deformable objects, which utilizes both visual and tactile feedback. At present, manipulation of deformable objects is basically formulated by assuming positional constraints. But in fact, in many situations manipulation has to be performed under actively applied force constraints. This scenario is considered in this research. In the proposed scheme a tactile feedback is integrated to ensure a stable contact between the robot end-effector and the soft object to be manipulated. The controlled contact force is also utilized to regulate the deformation of the soft object with its shape measured by a vision sensor. The effectiveness of the proposed method is demonstrated by a book page turning and shaping experiment.",
        "primary_area": "",
        "author": "Yuhao Guo;Xin Jiang;Yunhui Liu;Yuhao Guo;Xin Jiang;Yunhui Liu",
        "authorids": "/37089196889;/37086028734;/37279412600;/37089196889;/37086028734;/37279412600",
        "aff": "Department of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, HIT Campus Shenzhen University Town, Shenzhen, China; Department of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, HIT Campus Shenzhen University Town, Shenzhen, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636157/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15183745510733339226&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Harbin Institute of Technology;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical Engineering and Automation;Department of Mechanical and Automation Engineering",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "HIT;CUHK",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Shenzhen;Hong Kong",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636276",
        "title": "Deformation Recovery Control and Post-Impact Trajectory Replanning for Collision-Resilient Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper focuses on collision-inclusive motion planning for impact-resilient mobile robots. We propose a new deformation recovery and replanning strategy to handle collisions that may occur at run-time. Contrary to collision avoidance methods that generate trajectories only in conservative local space or require collision checking that has high computational cost, our method directly generates (local) trajectories with imposing only waypoint constraints. If a collision occurs, our method then estimates the post-impact state and computes from there an intermediate waypoint to recover from the collision. To achieve so, we develop two novel components: 1) a deformation recovery controller that optimizes the robot\u2019s states during post-impact recovery phase, and 2) a post-impact trajectory replanner that adjusts the next waypoint with the information from the collision for the robot to pass through and generates a polynomial-based minimum effort trajectory. The proposed strategy is evaluated experimentally with an omnidirectional impact-resilient wheeled robot. The robot is designed in house, and it can perceive collisions with the aid of Hall effect sensors embodied between the robot\u2019s main chassis and a surrounding deflection ring-like structure.",
        "primary_area": "",
        "author": "Zhouyu Lu;Zhichao Liu;Konstantinos Karydis;Zhouyu Lu;Zhichao Liu;Konstantinos Karydis",
        "authorids": "/37087243079;/37088505148;/38252121900;/37087243079;/37088505148;/38252121900",
        "aff": "Dept. of Electrical and Computer Engineering, University of California, Riverside; Dept. of Electrical and Computer Engineering, University of California, Riverside; Dept. of Electrical and Computer Engineering, University of California, Riverside",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636276/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7827925865840022758&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Riverside",
        "aff_unique_dep": "Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucr.edu",
        "aff_unique_abbr": "UCR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Riverside",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635917",
        "title": "Delay Aware Universal Notice Network: Real world multi-robot transfer learning",
        "track": "main",
        "status": "Poster",
        "abstract": "General purpose simulators provide cheap training data to learn complex robotic skills. However, the transition from simulation to reality is often very challenging for the agent. One major issue is the delay on the physical robot that may deteriorate the performance of the deployed agent. Furthermore, once a successfully trained learning-based control policy is available, re-purposing the knowledge acquired by the agent to enable a structurally distinct agent to perform the same task is hazardous if done naively. In this work, we address the above issues with a single method, the DA-UNN (Delay Aware Universal Notice Network), which decomposes the knowledge into robot-specific and task-specific modules for fast transfer. Our framework deals with delays immanent to physical systems in order to improve sim2real transfer. We evaluate the efficiency of our approach using simulated and actual robots on a dynamic manipulation task where delay management is crucial.",
        "primary_area": "",
        "author": "Samuel Beaussant;S\u00e9bastien Lengagne;Benoit Thuilot;Olivier Stasse;Samuel Beaussant;S\u00e9bastien Lengagne;Benoit Thuilot;Olivier Stasse",
        "authorids": "/37089196495;/37568812800;/37283368100;/37295476000;/37089196495;/37568812800;/37283368100;/37295476000",
        "aff": "Universit\u00e9 Clermont Auvergne, CNRS, Clermont Auvergne INP, Institut Pascal, Clermont-Ferrand, France; Universit\u00e9 Clermont Auvergne, CNRS, Clermont Auvergne INP, Institut Pascal, Clermont-Ferrand, France; Universit\u00e9 Clermont Auvergne, CNRS, Clermont Auvergne INP, Institut Pascal, Clermont-Ferrand, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635917/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1919110774838465317&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Universit\u00e9 Clermont Auvergne;LAAS-CNRS",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uca.fr;https://www.laas.fr/",
        "aff_unique_abbr": "UCA;LAAS-CNRS",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Clermont-Ferrand;Toulouse",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636856",
        "title": "DemoGrasp: Few-Shot Learning for Robotic Grasping with Human Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to successfully grasp objects is crucial in robotics, as it enables several interactive downstream applications. To this end, most approaches either compute the full 6D pose for the object of interest or learn to predict a set of grasping points. While the former approaches do not scale well to multiple object instances or classes yet, the latter require large annotated datasets and are hampered by their poor generalization capabilities to new geometries. To overcome these shortcomings, we propose to teach a robot how to grasp an object with a simple and short human demonstration. Hence, our approach neither requires many annotated images nor is it restricted to a specific geometry. We first present a small sequence of RGB-D images displaying a human-object interaction. This sequence is then leveraged to build associated hand and object meshes that represent the depicted interaction. Subsequently, we complete missing parts of the reconstructed object shape and estimate the relative transformation between the reconstruction and the visible object in the scene. Finally, we transfer the a-priori knowledge from the relative pose between object and human hand with the estimate of the current object pose in the scene into necessary grasping instructions for the robot. Exhaustive evaluations with Toyota\u2019s Human Support Robot (HSR) in real and synthetic environments demonstrate the applicability of our proposed methodology and its advantage in comparison to previous approaches.",
        "primary_area": "",
        "author": "Pengyuan Wang;Fabian Manhardt;Luca Minciullo;Lorenzo Garattoni;Sven Meier;Nassir Navab;Benjamin Busam;Pengyuan Wang;Fabian Manhardt;Luca Minciullo;Lorenzo Garattoni;Sven Meier;Nassir Navab;Benjamin Busam",
        "authorids": "/37089197506;/37085664475;/37086098395;/37085673854;/37089695612;/37282965500;/37085664553;/37089197506;/37085664475;/37086098395;/37085673854;/37089695612;/37282965500;/37085664553",
        "aff": "Technical University of Munich; Technical University of Munich; Toyota Motor Europe; Toyota Motor Europe; Toyota Motor Europe; Technical University of Munich; Technical University of Munich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636856/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2763375420722773007&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;1;0;0",
        "aff_unique_norm": "Technical University of Munich;Toyota Motor Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tum.de;https://www.toyota-europe.com",
        "aff_unique_abbr": "TUM;TME",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;1;1;0;0",
        "aff_country_unique": "Germany;Unknown"
    },
    {
        "id": "9636144",
        "title": "Denoising 3D Human Poses from Low-Resolution Video using Variational Autoencoder",
        "track": "main",
        "status": "Poster",
        "abstract": "We tackle the problem of refining and denoising a series of 3D human poses estimated from a low-resolution video. Low-resolution often causes the wrong pose estimation, e.g., left-right switching and the absence of keypoints. We propose to use the variational autoencoder (VAE) to remove these challenging noises. The VAE model utilizes time-series information and motion priors in denoising. From our experiments, the VAE model can reduce the pose estimation error (MPJPE) for poor-quality images by 24.37mm, from the original 105.53mm. This improves about 6.5 times over the traditional DCT approach. In addition, it removes jitters and generates smooth movements, which is helpful in recognition of human behaviors.",
        "primary_area": "",
        "author": "Chihiro Nakatsuka;Satoshi Komorita;Chihiro Nakatsuka;Satoshi Komorita",
        "authorids": "/37089194968;/37400201100;/37089194968;/37400201100",
        "aff": "KDDI Research, Saitama, Japan; KDDI Research, Saitama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636144/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8420835415992668528&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "KDDI Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kddi-research.jp",
        "aff_unique_abbr": "KDDI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Saitama",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636211",
        "title": "Depth Ranging Performance Evaluation and Improvement for RGB-D Cameras on Field-Based High-Throughput Phenotyping Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "RGB-D cameras have been successfully used for indoor High-ThroughPut Phenotyping (HTPP). However, their capability and feasibility for in-field HTPP applications still need to be evaluated. To solve the problem, we evaluate the depth-ranging performances of a consumer-level RGB-D camera (RealSense D435i) under in-field scenarios. First, we focus on determining their optimal ranging areas for different crop organs. Second, based on the evaluation results, we analyze the influences of light intensity on depth measurements and propose a brightness-and-distance based Support Vector Regression Strategy, to compensate the ranging error. Finally, we give an intuitive accuracy ranking diagram for RealSense D435i under natural lighting intensities. Experimental results show that: 1) RealSense D435i has good ranging performances on in-field HTPP. 2) Our error compensation model can effectively reduce the influences of lighting intensity and target distance.",
        "primary_area": "",
        "author": "Zhengqiang Fan;Na Sun;Quan Qiu;Tao Li;Chunjiang Zhao;Zhengqiang Fan;Na Sun;Quan Qiu;Tao Li;Chunjiang Zhao",
        "authorids": "/37086179746;/37089026737;/37085680715;/37088942835;/37271178900;/37086179746;/37089026737;/37085680715;/37088942835;/37271178900",
        "aff": "Beijing Research Center of Intelligent Equipment for Agriculture, Beijing Academy of Agriculture and Forestry Sciences, Beijing, China; Beijing Research Center of Intelligent Equipment for Agriculture, Beijing Academy of Agriculture and Forestry Sciences, Beijing, China; Beijing Research Center for Information Technology in Agriculture, Beijing Academy of Agriculture and Forestry Sciences, Beijing, China; Beijing Research Center of Intelligent Equipment for Agriculture, Beijing Academy of Agriculture and Forestry Sciences, Beijing, China; Beijing Research Center for Information Technology in Agriculture, Beijing Academy of Agriculture and Forestry Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636211/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15069613811705915187&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Beijing Academy of Agriculture and Forestry Sciences",
        "aff_unique_dep": "Beijing Research Center of Intelligent Equipment for Agriculture",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636382",
        "title": "DepthGrasp: Depth Completion of Transparent Objects Using Self-Attentive Adversarial Network with Spectral Residual for Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Transparent objects with unique visual properties often make depth cameras fail to scan their reflective and refractive surfaces. Recent studies on depth completion of transparent objects have leveraged a linear system based on the geometric constraints to predict the missing depth, which is hard to be employed in an end-to-end framework and achieve joint optimization. In this paper, we propose DepthGrasp - a deep learning approach for depth completion of transparent objects from a raw RGB-D image. More specifically, we use a generative adversarial network, which utilizes the generator to complete the depth maps by predicting the missing or inaccurate depth values, and use discriminator to guide the completed depth maps against the groundtruth. In the generator, we devise spectral residual blocks (SRB) with spectral normalization for network stability, and residual block to pass the attention map in order to capture the structure information and distinguish the geometric shape of transparent objects. In the discriminator, we use a patch-based convolutional network to adapt the data distributions of the predicted depth maps according to groundtruth. Extensive experiments conducted on ClearGrasp dataset show the effectiveness and generalization of the DepthGrasp for depth completion, and the deployed robotic picking system makes significant improvement on the performance of grasping on transparent objects.",
        "primary_area": "",
        "author": "Yingjie Tang;Junhong Chen;Zhenguo Yang;Zehang Lin;Qing Li;Wenyin Liu;Yingjie Tang;Junhong Chen;Zhenguo Yang;Zehang Lin;Qing Li;Wenyin Liu",
        "authorids": "/37089401853;/37087325291;/37085435553;/37086223014;/37277887900;/37086155310;/37089401853;/37087325291;/37085435553;/37086223014;/37277887900;/37086155310",
        "aff": "College of Computer Science and Technology, Guangdong University of Technology, Guangzhou, China; College of Computer Science and Technology, Guangdong University of Technology, Guangzhou, China; College of Computer Science and Technology, Guangdong University of Technology, Guangzhou, China; Department of Computing, HongKong Polytechnic University, Hong Kong, China; Department of Computing, HongKong Polytechnic University, Hong Kong, China; Cyberspace Security Research Center, Peng Cheng Laboratory, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636382/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9228394061987511591&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;2",
        "aff_unique_norm": "Guangdong University of Technology;Hong Kong Polytechnic University;Pengcheng Laboratory",
        "aff_unique_dep": "College of Computer Science and Technology;Department of Computing;Cyberspace Security Research Center",
        "aff_unique_url": "http://www.gdut.edu.cn;https://www.polyu.edu.hk;",
        "aff_unique_abbr": "GDUT;PolyU;",
        "aff_campus_unique_index": "0;0;0;1;1;2",
        "aff_campus_unique": "Guangzhou;Hong Kong;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636845",
        "title": "Design Optimization of Musculoskeletal Humanoids with Maximization of Redundancy to Compensate for Muscle Rupture",
        "track": "main",
        "status": "Poster",
        "abstract": "Musculoskeletal humanoids have various biomimetic advantages, and the redundant muscle arrangement allowing for variable stiffness control is one of the most important. In this study, we focus on one feature of the redundancy, which enables the humanoid to keep moving even if one of its muscles breaks, an advantage that has not been dealt with in many studies. In order to make the most of this advantage, the design of muscle arrangement is optimized by considering the maximization of minimum available torque that can be exerted when one muscle breaks. This method is applied to the elbow of a musculoskeletal humanoid Musashi with simulations, the design policy is extracted from the optimization results, and its effectiveness is confirmed with the actual robot.",
        "primary_area": "",
        "author": "Kento Kawaharazuka;Yasunori Toshimitsu;Manabu Nishiura;Yuya Koga;Yusuke Omura;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba;Kento Kawaharazuka;Yasunori Toshimitsu;Manabu Nishiura;Yuya Koga;Yusuke Omura;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba",
        "authorids": "/37086101930;/37086842924;/37088690295;/37088339856;/37088340210;/38238750500;/37280639000;/37085684621;/37286658200;/37086101930;/37086842924;/37088690295;/37088339856;/37088340210;/38238750500;/37280639000;/37085684621;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Toyota Motor Corporation; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636845/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7977728548734097298&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "University of Tokyo;Toyota Motor Corporation",
        "aff_unique_dep": "Department of Mechano-Informatics;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.toyota-global.com",
        "aff_unique_abbr": "UTokyo;Toyota",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636421",
        "title": "Design and Analysis of a Bi-directional Transformable Wheel Robot Trimode",
        "track": "main",
        "status": "Poster",
        "abstract": "This article presents a novel transformable wheeled robot with three motion modes. Based on the four-bar mechanism design, the transformable wheel can transform into CW (clockwise) legged wheel mode and CCW (counterclock-wise) legged wheel mode from the circular wheel. Both legged wheel modes achieve good obstacle-climbing performance when the robot overcomes obstacles such as steps in the forward and backward directions. Mathematical expression of shape of the transformable wheel is established for design variables selection of the wheel to improve the obstacle-overcoming ability of the legged wheel modes. Dynamics model of the robot in the step-overcoming scene is analyzed to determine and reduce the torque load of the motor. Finally, two prototypes of the robot are developed. The early-stage prototype made by 3D printing verifies the step-overcoming ability of the transformable wheel. Then, structural strength of the robot chassis and the robustness of the hardware are improved in the second prototype, which can play a role in SAR and indoor service tasks. In general, the prototype can overcome steps with the height of more than 2 times the radius of the wheel in CW/CCW legged wheel mode and move at a maximum speed of 3.15 m/s in circular wheel mode (about 5.83 times the length of the robot per second).",
        "primary_area": "",
        "author": "Qiwei Xu;Hao Xu;Kun Xiong;Qinqin Zhou;Weizhong Guo;Qiwei Xu;Hao Xu;Kun Xiong;Qinqin Zhou;Weizhong Guo",
        "authorids": "/37086798547;/37089196634;/37089193973;/37089195270;/37898365800;/37086798547;/37089196634;/37089193973;/37089195270;/37898365800",
        "aff": "Tencent Robotics X Lab, Shenzhen, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Tencent Robotics X Lab, Shenzhen, China; Tencent Robotics X Lab, Shenzhen, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636421/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14825161955843498908&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "Tencent;Shanghai Jiao Tong University",
        "aff_unique_dep": "Robotics;School of Mechanical Engineering",
        "aff_unique_url": "https://www.tencent.com;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "Tencent;SJTU",
        "aff_campus_unique_index": "0;1;0;0;1",
        "aff_campus_unique": "Shenzhen;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636768",
        "title": "Design and Evaluation of a Hair Combing System Using a General-Purpose Robotic Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "This work introduces an approach for automatic hair combing by a lightweight robot. For people living with limited mobility, dexterity, or chronic fatigue, combing hair is often a difficult task that negatively impacts personal routines. We propose a modular system for enabling general robot manipulators to assist with a hair-combing task. The system consists of three main components. The first component is the segmentation module, which segments the location of hair in space. The second component is the path planning module that proposes automatically-generated paths through hair based on user input. The final component creates a trajectory for the robot to execute. We quantitatively evaluate the effectiveness of the paths planned by the system with 48 users and qualitatively evaluate the system with 30 users watching videos of the robot performing a hair-combing task in the physical world. The system is shown to effectively comb different hairstyles.",
        "primary_area": "",
        "author": "Nathaniel Dennler;Eura Shin;Maja Matari\u0107;Stefanos Nikolaidis;Nathaniel Dennler;Eura Shin;Maja Matari\u0107;Stefanos Nikolaidis",
        "authorids": "/37088946555;/37089195973;/38300930600;/37643766400;/37088946555;/37089195973;/38300930600;/37643766400",
        "aff": "Computer Science Department, University of Southern California, Los Angeles, CA; Computer Science Department, Harvard University, Cambridge, MA; Computer Science Department, University of Southern California, Los Angeles, CA; Computer Science Department, University of Southern California, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636768/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6240535881915558731&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Southern California;Harvard University",
        "aff_unique_dep": "Computer Science Department;Computer Science Department",
        "aff_unique_url": "https://www.usc.edu;https://www.harvard.edu",
        "aff_unique_abbr": "USC;Harvard",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Los Angeles;Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636100",
        "title": "Design and Experimental Learning of Swimming Gaits for a Magnetic, Modular, Undulatory Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Here we developed an experimental platform with a magnetic, modular, undulatory robot (\u03bcBot) for studying fish-inspired underwater locomotion. This platform will enable us to systematically explore the relationship between body morphology, swimming gaits, and swimming performance via reinforcement learning methods. The \u03bcBot was designed to be easily modifiable in morphology, compact in size, easy to be controlled and inexpensive. The experimental platform also included a towing tank and a motion tracking system for real-time measurement of the \u03bcBot kinematics. The swimming gaits of \u03bcBot were generated by a central pattern generator (CPG), which outputs voltage signals to \u03bcBot's magnetic actuators. The CPG parameters were learned experimentally using the parameter exploring policy gradient (PGPE) method to maximize swimming speed. In the experiments, two \u03bcBot designs with the same body morphology but different caudal-fin shapes were tested. Results showed that swimming gaits with back-propagating traveling waves can be learned experimentally via PGPE, while the shape of the caudal fins had moderate influences on the learned gaits and the swimming speed. Furthermore, robot swimming speed was sensitive to the undulating frequency and the voltage magnitude of the last three posterior actuators. In contrast, swimming gaits and speed were relatively invariant to the variances within the inter-module connection weights of CPG and the voltage applied to the anterior actuator.",
        "primary_area": "",
        "author": "Hankun Deng;Patrick Burke;Donghao Li;Bo Cheng;Hankun Deng;Patrick Burke;Donghao Li;Bo Cheng",
        "authorids": "/37089195069;/37089194375;/37089196935;/37536373700;/37089195069;/37089194375;/37089196935;/37536373700",
        "aff": "Department of Mechanical Engineering, Penn State University, University Park, PA, USA; Department of Mechanical Engineering, Penn State University, University Park, PA, USA; Department of Mechanical Engineering, Penn State University, University Park, PA, USA; Department of Mechanical Engineering, Penn State University, University Park, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636100/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5130292942652636457&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Penn State University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.psu.edu",
        "aff_unique_abbr": "PSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "University Park",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636189",
        "title": "Design and analysis of a robotic out-pipe grinding system with friction actuating",
        "track": "main",
        "status": "Poster",
        "abstract": "To cope with the requirements on efficiency and labour-saving of the out-pipe surface grinding tasks in the wild, several proposals are revealed and discussed. The one benefiting from the characteristics of planetary gear transmission and friction actuating mechanism are expatiated. To realize full coverage of out-pipe surface, the self-rotation and revolution motions of every polishing tool (cutter) are actuated by the same motor, and the friction force produced in grinding process acts as suitable tractive force for the forward travel of the grinding system. The friction statics analysis is established to illustrate the force transmission. Compression spring system are utilized to realize force equilibrium and support passive diameter adaptability. The proposed robotic grinding system is characterized by less actuator, online grinding capability and high working efficiency. It has clear advantages regarding manufacturing costs and control complexity. As the result of prototype experiments, performance of smooth grinding the out-pipe surface is confirmed.",
        "primary_area": "",
        "author": "Mingyuan Wang;Sheng Bao;Jianjun Yuan;Shugen Ma;Shijie Guo;Weiwei Wan;Mingyuan Wang;Sheng Bao;Jianjun Yuan;Shugen Ma;Shijie Guo;Weiwei Wan",
        "authorids": "/37089197781;/37088951181;/37293594200;/37280187400;/37086276620;/37085689483;/37089197781;/37088951181;/37293594200;/37280187400;/37086276620;/37085689483",
        "aff": "Shanghai Robotics Institute, Shanghai University, Shanghai, China; Shanghai Robotics Institute, Shanghai University, Shanghai, China; Shanghai Robotics Institute, Shanghai University, Shanghai, China; Department of Robotics, Ritsumeikan University, Shiga, Japan; Institute of AI and Robotics, Fudan University, Shanghai, China; Graduate School of Engineering Science, Osaka University, Osaka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636189/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16843690120667195486&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;3",
        "aff_unique_norm": "Shanghai University;Ritsumeikan University;Fudan University;Osaka University",
        "aff_unique_dep": "Shanghai Robotics Institute;Department of Robotics;Institute of AI and Robotics;Graduate School of Engineering Science",
        "aff_unique_url": "https://www.shu.edu.cn;https://www.ritsumeikan.ac.jp;https://www.fudan.edu.cn/en/;https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "SHU;Ritsumeikan;Fudan;Osaka U",
        "aff_campus_unique_index": "0;0;0;1;0;2",
        "aff_campus_unique": "Shanghai;Shiga;Osaka",
        "aff_country_unique_index": "0;0;0;1;0;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9635990",
        "title": "Design and comparison of tails for bird-scale flapping-wing robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Flapping-wing robots (so-called ornithopters) are a promising type of platform to perform efficient winged flight and interaction with the environment. However, the control of such vehicles is challenging due to their under-actuated morphology to meet lightweight requirements. Consequently, the flight control of flapping-wing robots is predominantly handled by the tail. Most ornithopters feature a tail with two degrees of freedom but the configuration choice is often arbitrary and without in-depth study. In this paper, we propose a thorough analysis of the design and in-flight performance for three tails. Their design and manufacturing methods are presented, with an emphasis on low weight, which is critical in ornithopters. The aerodynamics of the tails is analyzed through CFD simulations and their performance compared experimentally. The advantages and performance metrics of each configuration are discussed based on flight data. Two types of 3D flight tests were carried out: aggressive heading maneuvers and level turns. The results show that an inverted V-tail outperforms the others regarding maneuverability and stability. From the three configurations, only the inverted V-Tail can perform an aggressive stable banked level turn with a radius of 3.7 m at a turning rate of 1.6 rad/s. This research work describes the impact of the tail configuration choice on the performance of bird-scale flapping-wing robots.",
        "primary_area": "",
        "author": "M.M. Guzm\u00e1n;C. Ruiz P\u00e1ez;F. J. Maldonado;R. Zufferey;J. Tormo-Barbero;J.\u00c1 Acosta;A. Ollero;M.M. Guzm\u00e1n;C. Ruiz P\u00e1ez;F. J. Maldonado;R. Zufferey;J. Tormo-Barbero;J.\u00c1 Acosta;A. Ollero",
        "authorids": "/37088691085;/37089197389;/37088688490;/37086336427;/37088690316;/37399220800;/37265412000;/37088691085;/37089197389;/37088688490;/37086336427;/37088690316;/37399220800;/37265412000",
        "aff": "GRVC, University of Seville, Spain; GRVC, University of Seville, Spain; GRVC, University of Seville, Spain; GRVC, University of Seville, Spain; GRVC, University of Seville, Spain; GRVC, University of Seville, Spain; GRVC, University of Seville, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635990/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17080786685051984748&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Seville",
        "aff_unique_dep": "GRVC",
        "aff_unique_url": "https://www.us.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9636879",
        "title": "Design and implementation of a stumble recovery controller for a knee exoskeleton",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a stumble recovery controller for a knee exoskeleton that detects a stumble perturbation; selects an anticipated recovery strategy; and provides appropriate recovery assistance. In order to assess the efficacy of the controller in providing an assistive response to a stumble perturbation, the controller was implemented in a knee exoskeleton and evaluated in a single healthy adult participant against several other controller reactions, and against the participant\u2019s response without an exoskeleton. Results show that the stumble recovery controller successfully detected the perturbation and correctly selected the strategy that matched the participant\u2019s response for all 29 trials in which the exoskeleton was used. Further, results show improvements in stumble recovery metrics when using the exoskeleton with the stumble recovery controller, compared to the control cases of: 1) no change in the nominal controller when stumble is detected; 2) turning off exoskeleton torque when a stumble is detected; and 3) not wearing an exoskeleton.",
        "primary_area": "",
        "author": "Maura Eveld;Shane King;Karl Zelik;Michael Goldfarb;Maura Eveld;Shane King;Karl Zelik;Michael Goldfarb",
        "authorids": "/37089196943;/37088801351;/37704832000;/37284476400;/37089196943;/37088801351;/37704832000;/37284476400",
        "aff": "Vanderbilt University, Nashville, TN, USA; Vanderbilt University; Vanderbilt University; Vanderbilt University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636879/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=167984179319830233&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Vanderbilt University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Nashville;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636533",
        "title": "Design of Taking a Walk with a Robot that Receives Care from a Person and Indirectly Mediates Communication with Strangers",
        "track": "main",
        "status": "Poster",
        "abstract": "We report the results of our study on whether taking a walk with a child-like robot that a person takes care of can generate interaction with the surrounding people whom the person has never met before. As the number of single-person households increases, it is expected that more people will live with not only robots that can be useful for people but also robots that people can take care of. Our study is important because we explored the possibilities of such a robot to create interaction between people in the community, which has been lost in recent years. In this paper, we designed the behavior of a robot that follows a person and learns about the scenery while walking together and implemented it using Pepper. Then, the first author walked around the university building with the robot and observed the initial reactions of the surrounding people. As we expected, the surrounding people interacted with the first author by talking to the robot as if it were a child and helping the robot. This paper contributes to taking a step forward a new research theme \u2018taking a walk with a robot and a person\u2019 by focusing on the important role of robots in the future relationship with a person: care-receiving from a person and communication mediation between a person and others.",
        "primary_area": "",
        "author": "Kanae Kochigami;Kei Okada;Masayuki Inaba;Kanae Kochigami;Kei Okada;Masayuki Inaba",
        "authorids": "/37085736490;/37280639000;/37286658200;/37085736490;/37280639000;/37286658200",
        "aff": "Graduate School of Interdisciplinary Information Studies, The University of Tokyo, Tokyo, Japan; Graduate School of Interdisciplinary Information Studies, The University of Tokyo, Tokyo, Japan; Graduate School of Interdisciplinary Information Studies, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636533/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:fTJscrP7SBgJ:scholar.google.com/&scioq=Design+of+Taking+a+Walk+with+a+Robot+that+Receives+Care+from+a+Person+and+Indirectly+Mediates+Communication+with+Strangers&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Graduate School of Interdisciplinary Information Studies",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636262",
        "title": "Design of a Large-scale Electrically-actuated Quadruped Robot and Locomotion Control for the Narrow Passage",
        "track": "main",
        "status": "Poster",
        "abstract": "With the gradual maturity of the software and hardware of quadruped robots, the application scenarios of quadruped robots are increasing, such as security, rescue, exploration and other tasks. Quadruped robots are flexible and adaptive to challenging or complex environment. This study presents a large-scale quadruped robot, Pegasus II, which is a new version upgraded from the previous quadruped robot, Pegasus [1]. System design of Pegasus II is introduced, including mechanical and electronic design. Locomotion control for a special scene, L-shaped narrow corner, in which a large-scale quadruped robot is not able to traverse in a common quadrupedal mode, is demonstrated. The long body length of a large-scale quadruped robot, such as Pegasus II, incurs difficulty in traversing freely in such a narrow passage. Motivated by this issue, this study proposes an experimental implementation to realize the transition from quadrupedal mode to bipedal mode. The control framework is presented, which mainly includes trajectory optimization, whole-body control, compliance control, and joint torque estimator. Simulations and experiments are conducted to validate the performance, including gait transition, compliance control.",
        "primary_area": "",
        "author": "Shusheng Ye;Jianwen Luo;Caiming Sun;Bingchen Jin;Juntong Su;Aidong Zhang;Shusheng Ye;Jianwen Luo;Caiming Sun;Bingchen Jin;Juntong Su;Aidong Zhang",
        "authorids": "/37087245115;/37085835145;/37086270576;/37086282585;/37089194617;/37086269590;/37087245115;/37085835145;/37086270576;/37086282585;/37089194617;/37086269590",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), Shenzhen, China; Institute of Robotics and Intelligent Manufacturing (IRIM), The Chinese University of Hong Kong (CUHK), Shenzhen, China; Institute of Robotics and Intelligent Manufacturing (IRIM), The Chinese University of Hong Kong (CUHK), Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), Shenzhen, China; Institute of Robotics and Intelligent Manufacturing (IRIM), The Chinese University of Hong Kong (CUHK), Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636262/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18115950322934496626&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;0;1",
        "aff_unique_norm": "Shenzhen Institute of Artificial Intelligence and Robotics for Society;Chinese University of Hong Kong",
        "aff_unique_dep": "Artificial Intelligence and Robotics for Society;Institute of Robotics and Intelligent Manufacturing",
        "aff_unique_url": ";https://www.cuhk.edu.hk",
        "aff_unique_abbr": "AIRS;CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636597",
        "title": "Design of a New Robot End-Effector Based on Compliant Constant-Force Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes the design of a new robot end-effector based on compliant constant-force mechanism for robot-assisted manufacturing, such as polishing. One uniqueness of the proposed end-effector lies in that it offers a constant contact force without using a force sensor and controller. An industrial robot is adopted to position the end-effector and the end-effector regulates the contact force passively. When the end-effector contacts the workpiece, the constant-force motion range acts as a buffer to counteract the excessive displacement caused by inertia. As a result, there is no force overshoot, protecting the consistency of the workpiece. The analytical model of the constant-force mechanism is deduced and the structural parameters are optimized to maximize the constant-force motion range under other constraints. For experimental testing, a prototype of the constant-force end-effector has been fabricated. The mechanism exhibits constant-force tendency with the force varying from 3.4 to 4.2 N between 0.7 and 1.7 mm. Experimental results verify the effectiveness of the presented constant-force end-effector mechanism.",
        "primary_area": "",
        "author": "Yuzhang Wei;Qingsong Xu;Yuzhang Wei;Qingsong Xu",
        "authorids": "/37086169563;/37290823000;/37086169563;/37290823000",
        "aff": "Department of Electromechanical Engineering, Faculty of Science and Technology, University of Macau, Macau, China; Department of Electromechanical Engineering, Faculty of Science and Technology, University of Macau, Macau, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636597/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16755122245358032651&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Macau",
        "aff_unique_dep": "Department of Electromechanical Engineering",
        "aff_unique_url": "https://www.um.edu.mo",
        "aff_unique_abbr": "UMacau",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Macau",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636720",
        "title": "Design of an SSVEP-based BCI Stimuli System for Attention-based Robot Navigation in Robotic Telepresence",
        "track": "main",
        "status": "Poster",
        "abstract": "Brain-computer interface (BCI)-based robotic telepresence provides an opportunity for people with disabilities to control robots remotely without any actual physical movement. However, traditional BCI systems usually require the user to select the navigation direction from visual stimuli in a fixed background, which makes it difficult to control the robot in a dynamic environment during the locomotion. In this paper, a novel SSVEP-based BCI stimuli system is proposed for robotic telepresence. The novel system utilized the live video streamed from the robot onboard camera as the input. By altering and flickering the detected objects in the scene with different frequencies predefined based on their relative positions on the screen, the robot can be navigated based on the user\u2019s attention in a dynamic manner. In order to better differentiate multiple objects (more than the number of frequencies predefined), the task-related component analysis (TRCA) model was trained with a priori offline experimental data to select the front objects with priority. Experiments were conducted to validate the proposed system. Using the system, four human subjects are able to control a humanoid robot to navigate through multiple objects to reach the desired goal. The success rate reaches 87.5% in average.",
        "primary_area": "",
        "author": "Xingchao Wang;Xiaopeng Huang;Yi Lin;Liguang Zhou;Zhenglong Sun;Yangsheng Xu;Xingchao Wang;Xiaopeng Huang;Yi Lin;Liguang Zhou;Zhenglong Sun;Yangsheng Xu",
        "authorids": "/37089197556;/37089198116;/37089195493;/37086212444;/37086799406;/37277722000;/37089197556;/37089198116;/37089195493;/37086212444;/37086799406;/37277722000",
        "aff": "School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society(AIRS), The Chinese University of Hong Kong, Shenzhen, China; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636720/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14319735457347395158&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "School of Science and Engineering",
        "aff_unique_url": "https://www.cuhk.edu.cn",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636859",
        "title": "Design of galloping robots with elastic spine: tracking relations between dynamic model parameters based on motion analysis of a real cheetah",
        "track": "main",
        "status": "Poster",
        "abstract": "One way to create a quadruped galloping robot from scratch is to design a brick-shaped body and utilize relatively simple open-chain leg mechanisms controlled with relatively complex control algorithms. Alternatively, we can look at how nature solved the same task designing fast mammals such as cheetah, and by means of morphological computation, we can design a complex mechanical system that has much of the desired behavior within inherent dynamics and only a little control effort is needed to stabilize or augment the motion.In this paper, we have analyzed a real cheetah motion using video tracking and looked for a way to match the dynamic model parameters of the real cheetah with a galloping robot with an elastic spine. We believe the elastic spine is the essential feature for a fast-running energy-efficient galloping robot. Within this paper, we are focused on the flying stage when the elastic spine affects the motion of the robot\u2019s front and rear bodies. We have found how to optimize mass distribution and elasticity in the spine in order to get the cheetah-like galloping motion of a quadruped robot.",
        "primary_area": "",
        "author": "Olga Borisova;Ivan Borisov;Sergey Kolyubin;Stefano Stramigioli;Olga Borisova;Ivan Borisov;Sergey Kolyubin;Stefano Stramigioli",
        "authorids": "/37088601167;/37086250938;/37887676700;/37282439300;/37088601167;/37086250938;/37887676700;/37282439300",
        "aff": "Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, Saint Petersburg, Russia; Department of Electrical Engineering, Mathematics and Computer Science, University of Twente, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636859/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7509590147708193543&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "ITMO University;University of Twente",
        "aff_unique_dep": "Biomechatronics and Energy-Efficient Robotics Lab;Department of Electrical Engineering, Mathematics and Computer Science",
        "aff_unique_url": "https://www.itmo.ru;https://www.utwente.nl",
        "aff_unique_abbr": "ITMO;UT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Saint Petersburg;",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Russian Federation;Netherlands"
    },
    {
        "id": "9635924",
        "title": "Design, Integration and Implementation of an Intelligent and Self-recharging Drone System for Autonomous Power line Inspection",
        "track": "main",
        "status": "Poster",
        "abstract": "Today, many inspection domains utilize the benefits of drones to monitor and inspect infrastructure in an efficient manner. The energy grid is challenged by frequent and thorough inspection to stay operational. So far, drones have already been introduced to solve this challenge. However, the inspection drone still requires manual control and subsequent human examination of the captured photos and videos. This inspection process comes with a high inspection cost and is susceptible to human errors in fault finding. The proposed system builds on top of the authors\u2019 previous research to develop and verify an integrated drone system for autonomous power line inspection, enabling functioning mechanics through pneumatics, extension of operation time through energy harvesting, Artificial Intelligent (AI) fault detection, and system autonomy using navigational algorithms. An advanced drone system has been designed and manufactured for the mission, with the results demonstrating the capability to perform an autonomous inspection mission in conditions up to 30 kts wind speeds, being additionally able to detect faults in real-time at a high rate during drone motion. Furthermore, we demonstrate the ability to recharge the drone battery within 2.4 hours.",
        "primary_area": "",
        "author": "Nicolai Iversen;Oscar Bowen Schofield;Linda Cousin;Naeem Ayoub;Gerd vom B\u00f6gel;Emad Ebeid;Nicolai Iversen;Oscar Bowen Schofield;Linda Cousin;Naeem Ayoub;Gerd vom B\u00f6gel;Emad Ebeid",
        "authorids": "/37088526272;/37088526037;/37088526864;/37089401043;/37085571380;/38233264800;/37088526272;/37088526037;/37088526864;/37089401043;/37085571380;/38233264800",
        "aff": "SDU UAS Center, The Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Odense, Denmark; SDU UAS Center, The Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Odense, Denmark; Fraunhofer IMS, Duisburg, Germany; Department of Mathematics and Computer Science, University of Southern Denmark, Odense, Denmark; Fraunhofer IMS, Duisburg, Germany; SDU UAS Center, The Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Odense, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635924/",
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14439059490232650943&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;1;0",
        "aff_unique_norm": "University of Southern Denmark;Fraunhofer Institute for Integrated Systems and Device Technology",
        "aff_unique_dep": "SDU UAS Center, The Maersk Mc-Kinney Moller Institute;Institute for Integrated Systems and Device Technology",
        "aff_unique_url": "https://www.sdu.dk;https://www.ims.fraunhofer.de/",
        "aff_unique_abbr": "SDU;Fraunhofer IMS",
        "aff_campus_unique_index": "0;0;1;0;1;0",
        "aff_campus_unique": "Odense;Duisburg",
        "aff_country_unique_index": "0;0;1;0;1;0",
        "aff_country_unique": "Denmark;Germany"
    },
    {
        "id": "9636430",
        "title": "Design, Optimal Guidance and Control of a Low-cost Re-usable Electric Model Rocket",
        "track": "main",
        "status": "Poster",
        "abstract": "In the last decade, autonomous vertical take-off and landing (VTOL) vehicles have become increasingly important as they lower mission costs thanks to their re-usability. However, their development is complex, rendering even the basic experimental validation of the required advanced guidance and control (G & C) algorithms prohibitively time-consuming and costly. In this paper, we present the design of an inexpensive small-scale VTOL platform that can be built from off-the-shelf components for less than 1000 USD. The vehicle design mimics the first stage of a reusable launcher, making it a perfect test-bed for G & C algorithms. To control the vehicle during ascent and descent, we propose a real-time optimization-based G & C algorithm. The key features are a real-time minimum fuel and free-final-time optimal guidance combined with an offset-free tracking model predictive position controller. The vehicle hardware design and the G & C algorithm are experimentally validated both indoors and outdoor, showing reliable operation in a fully autonomous fashion with all computations done on-board and in real-time.",
        "primary_area": "",
        "author": "Lukas Spannagl;Elias Hampp;Andrea Carron;Jerome Sieber;Carlo Alberto Pascucci;Aldo U. Zgraggen;Alexander Domahidi;Melanie N. Zeilinger;Lukas Spannagl;Elias Hampp;Andrea Carron;Jerome Sieber;Carlo Alberto Pascucci;Aldo U. Zgraggen;Alexander Domahidi;Melanie N. Zeilinger",
        "authorids": "/37087322237;/37086936042;/38547450500;/37088902751;/38548019000;/38547563100;/37391593100;/37398798800;/37087322237;/37086936042;/38547450500;/37088902751;/38548019000;/38547563100;/37391593100;/37398798800",
        "aff": "Institute for Dynamic Systems and Control (IDSC), ETH Zurich, Zurich, Switzerland; Embotech AG, Zurich, Switzerland; Institute for Dynamic Systems and Control (IDSC), ETH Zurich, Zurich, Switzerland; Institute for Dynamic Systems and Control (IDSC), ETH Zurich, Zurich, Switzerland; Embotech AG, Zurich, Switzerland; Embotech AG, Zurich, Switzerland; Embotech AG, Zurich, Switzerland; Institute for Dynamic Systems and Control (IDSC), ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636430/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13806835502574628048&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;1;1;1;0",
        "aff_unique_norm": "ETH Zurich;Embotech AG",
        "aff_unique_dep": "Institute for Dynamic Systems and Control (IDSC);",
        "aff_unique_url": "https://www.ethz.ch;https://www.embotech.com",
        "aff_unique_abbr": "ETHZ;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zurich;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636587",
        "title": "Designing Rotary Linkages for Polar Motions",
        "track": "main",
        "status": "Poster",
        "abstract": "Polar linkages have two degrees-of-freedom (DOF) where one input joint angle controls the length of a radial segment while another controls its angle. Considering a theoretical planar robot model, this mapping between joint angles to output motions can be shown to be energetically advantageous over the ubiquitous two-revolute linkage. Since a polar linkage\u2019s typical construction involves a moving prismatic joint, it is cumbersome to implement alongside rotary electromagnetic actuators offsetting any advantage. In this paper, we present a procedure for designing polar linkages using only revolute joints. The procedure starts with a pre-existing single DOF straight line linkage and then finds the dimensions of a three-link attachment to produce the second DOF. In the end, the straight line linkage actuates the polar length and the attachment actuates the polar angle. The design process is framed under optimization with an objective that is both polynomial and invariant to the number of discretization points. This enables the techniques of numerical continuation to efficiently find complete sets of minima. We demonstrate our procedure with an example in which multiple minima are found including the global minimum. This computed design solution is then fabricated in order to validate the designed kinematics.",
        "primary_area": "",
        "author": "Aravind Baskar;Chang Liu;Mark Plecnik;Jonathan D. Hauenstein;Aravind Baskar;Chang Liu;Mark Plecnik;Jonathan D. Hauenstein",
        "authorids": "/37088998829;/37089194305;/37085786438;/37087996614;/37088998829;/37089194305;/37085786438;/37087996614",
        "aff": "Department of Aerospace and Mechanical Engineering, University of Notre Dame, Indiana, USA; Department of Aerospace and Mechanical Engineering, University of Notre Dame, Indiana, USA; Department of Aerospace and Mechanical Engineering, University of Notre Dame, Indiana, USA; Department of Applied and Computational Mathematics and Statistics, University of Notre Dame, Indiana, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636587/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13261715450884493892&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Aerospace and Mechanical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Notre Dame",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636260",
        "title": "Designing and Deploying a Mobile UVC Disinfection Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a mobile UVC disinfection robot designed to mitigate the threat of airborne and surface pathogens. Our system comprises a mobile robot base, a custom UVC lamp assembly, and algorithms for autonomous navigation and path planning. We present a model of UVC disinfection and dosage of UVC light delivered by the mobile robot. We also discuss challenges and prototyping decisions for rapid deployment of the robot during the COVID-19 pandemic. Experimental results summarize a long-term deployment at The Greater Boston Food Bank, where the robot delivers (nightly) UVC dosages of at least 10 mJ/cm2 to a 4000 ft2 area in under 30 minutes. These dosages are capable of neutralizing 99% of coronaviruses, including SARS-CoV-2, on surfaces and in airborne particles. Further simulations present how this mobile UVC disinfection robot may be extended to classic problems in robotic path planning and adaptive multi-robot coverage control.",
        "primary_area": "",
        "author": "Alyssa Pierson;John W. Romanishin;Hunter Hansen;Leonardo Zamora Ya\u00f1ez;Daniela Rus;Alyssa Pierson;John W. Romanishin;Hunter Hansen;Leonardo Zamora Ya\u00f1ez;Daniela Rus",
        "authorids": "/37085345711;/37077931000;/37089196602;/37089197071;/37279652300;/37085345711;/37077931000;/37089196602;/37089197071;/37279652300",
        "aff": "Department of Mechanical Engineering, Boston University, Boston, MA, USA; Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636260/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=683153019410951587&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Boston University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering;Computer Science & Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.bu.edu;https://web.mit.edu",
        "aff_unique_abbr": "BU;MIT",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Boston;Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635955",
        "title": "Desperate Times Call for Desperate Measures: Towards Risk-Adaptive Task Allocation",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-robot task allocation (MRTA) problems involve optimizing the allocation of robots to tasks. MRTA problems are known to be challenging when tasks require multiple robots and the team is composed of heterogeneous robots. These challenges are further exacerbated when we need to account for uncertainties encountered in the real-world. In this work, we address coalition formation in heterogeneous multi-robot teams with uncertain capabilities. We specifically focus on tasks that require coalitions to collectively satisfy certain minimum requirements. Existing approaches to uncertainty-aware task allocation either maximize expected pay-off (risk-neutral approaches) or improve worst-case or near-worst-case outcomes (risk-averse approaches). Within the context of our problem, we demonstrate the inherent limitations of unilaterally ignoring or avoiding risk and show that these approaches can in fact reduce the probability of satisfying task requirements. Inspired by models that explain foraging behaviors in animals, we develop a risk-adaptive approach to task allocation. Our approach adaptively switches between risk-averse and risk-seeking behavior in order to maximize the probability of satisfying task requirements. Comprehensive numerical experiments conclusively demonstrate that our risk-adaptive approach outperforms risk-neutral and risk-averse approaches. We also demonstrate the effectiveness of our approach using a simulated multi-robot emergency response scenario.",
        "primary_area": "",
        "author": "Max Rudolph;Sonia Chernova;Harish Ravichandar;Max Rudolph;Sonia Chernova;Harish Ravichandar",
        "authorids": "/37088999897;/37283184200;/37085429366;/37088999897;/37283184200;/37085429366",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635955/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12225716251415825075&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636484",
        "title": "Detecting Grasp Phases and Adaption of Object-Hand Interaction Forces of a Soft Humanoid Hand Based on Tactile Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Engineering humanoid robot hands with the ability to dexterously grasp objects of different sizes, shapes, mate-rial properties and weights requires sophisticated tactile sensing and intelligent controllers able to interpret sensory information and adapt contact forces with the object to achieve a stable and safe grasp. In this paper, we present a new soft humanoid hand equipped with a multimodal sensor system in each finger and a human-inspired grasp-phases controller that is able to detect the different phases of a grasping and manipulation task, adapt interaction forces with the manipulated object and balance the force distribution in both precision and power grasps based on tactile feedback. To evaluate the controller, we conducted experiments with the hand on the humanoid robot ARMAR-6 and 31 different soft and rigid everyday objects and food items with weights ranging from 4.8 g of a paper cup to 1133.8 g of a bottle, different shapes and material properties. The results show that grasping force can be reduced by 65% compared to a naive grasping approach using maximum force for grasping and manipulating both fragile objects without destruction as well as heavy objects.",
        "primary_area": "",
        "author": "Pascal Weiner;Felix Hundhausen;Raphael Grimm;Tamim Asfour;Pascal Weiner;Felix Hundhausen;Raphael Grimm;Tamim Asfour",
        "authorids": "/37086015396;/37086581259;/37085813662;/37295529100;/37086015396;/37086581259;/37085813662;/37295529100",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636484/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2161248504652262523&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9635899",
        "title": "Detection and Inference of Randomness-based Behavior for Resilient Multi-vehicle Coordinated Operations",
        "track": "main",
        "status": "Poster",
        "abstract": "A resilient multi-vehicle system cooperatively performs tasks by exchanging information, detecting, and removing cyber attacks that have the intent of hijacking or diminishing performance of the entire system. In this paper, we propose a framework to: i) detect and isolate misbehaving vehicles in the network, and ii) securely encrypt information among the network to alert and attract nearby vehicles toward points of interest in the environment without explicitly broadcasting safety-critical information. To accomplish these goals, we lever-age a decentralized virtual spring-damper mesh physics model for formation control on each vehicle. To discover inconsistent behavior of any vehicle in the network, we consider an approach that monitors for changes in sign behavior of an inter-vehicle residual that does not match with an expectation. Similarly, to disguise important information and trigger vehicles to switch to different behaviors, we leverage side-channel information on the state of the vehicles and characterize a hidden spring-damper signature model detectable by neighbor vehicles. Our framework is demonstrated in simulation and experiments on formations of unmanned ground vehicles (UGVs) in the presence of malicious man-in-the-middle communication attacks.",
        "primary_area": "",
        "author": "Paul J Bonczek;Nicola Bezzo;Paul J Bonczek;Nicola Bezzo",
        "authorids": "/37088481021;/37546843800;/37088481021;/37546843800",
        "aff": "Charles L. Brown Department of Electrical and Computer Engineering, Link Lab, University of Virginia, Charlottesville, VA, USA; Charles L. Brown Department of Electrical and Computer Engineering, Link Lab, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635899/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1017014987875529496&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Charles L. Brown Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636840",
        "title": "Development of Rotating Workspace Ground Contact Force Observer for Legged Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged robots have opened their way to more stable and practical mobile robot applications. However, their locomotion strategies are limited to similar patterns, and dynamic running at high speed still is not successfully realized. One of the key technology required for the realization of the dynamic running of the legged robot is to estimate the ground contact force and control it in real-time. This paper tackles this problem in two ways: the derivation of the observer algorithm based on the leg dynamics and the simplification of the observer design using the Rotating Workspace motion description. To this end, two novel coordinate systems are introduced to describe the joint space motion and the workspace differently, and the ground contact force observer is designed in the novel coordinate systems. The performance of the proposed observer is verified through experimental results.",
        "primary_area": "",
        "author": "Woosong Kang;Chan Lee;Sehoon Oh;Woosong Kang;Chan Lee;Sehoon Oh",
        "authorids": "/37088549878;/37085745664;/37279132500;/37088549878;/37085745664;/37279132500",
        "aff": "Woosong Kang; Chan Lee; Sehoon Oh",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636840/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10506589074322160005&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0",
        "aff_unique_norm": "Woosong University;",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.woosong.ac.kr;",
        "aff_unique_abbr": "Woosong;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0",
        "aff_country_unique": "South Korea;"
    },
    {
        "id": "9635929",
        "title": "Development of a Bio-inspired Soft Robotic Gripper based on Tensegrity Structures",
        "track": "main",
        "status": "Poster",
        "abstract": "The bones, muscles, tendons and connective tissues form a continuous tension network throughout human body. This heterogeneous mixture presents the characteristics of tensegrity, providing the body with structurally integrity, stability and flexibility. Inspired by this, this paper proposes a novel soft robotic gripper based on tensegrity structures. Firstly, the design and working principle of the tensegrity-based robotic gripper is introduced, which is composed of a series of discrete rigid segments connected with tensegrity joints by means of tensional cables. Then, the kinematics of the robotic gripper is analyzed using force density method to obtain the relationship between the pose of the gripper and the tension of cables. Finally experiments on the developed prototype demonstrates that the robotic gripper is able to grasp various objects of different sizes, shapes, and materials. Additional desirable properties are derived from using tensegrity structures in the robotic gripper: light weight, high compliance, inherent safety, low cost, and waterproof and dustproof performance. It is suggested that tensegrity structures have great potential to be an effective alternative to the development of soft robotic grippers.",
        "primary_area": "",
        "author": "Yixiang Liu;Qing Bi;Yibin Li;Yixiang Liu;Qing Bi;Yibin Li",
        "authorids": "/37085416040;/37087243979;/37279897500;/37085416040;/37087243979;/37279897500",
        "aff": "Engineering Research Center of Intelligent Unmanned Systems, Ministry of Education, School of Control Science and Engineering, Shandong University, Jinan, China; Chinese Academy of Sciences, Shandong Institute of Advanced Technology, Jinan, China; Engineering Research Center of Intelligent Unmanned Systems, Ministry of Education, School of Control Science and Engineering, Shandong University, Jinan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635929/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1424890415038607630&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Shandong University;Chinese Academy of Sciences",
        "aff_unique_dep": "School of Control Science and Engineering;Shandong Institute of Advanced Technology",
        "aff_unique_url": "http://www.sdu.edu.cn;http://www.cas.cn",
        "aff_unique_abbr": "SDU;CAS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Jinan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636817",
        "title": "Development of a Permanent Magnet Elastomer (PME) Infused Soft Robot Skin for Tactile Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "The skin is an important organ which enables humans to interact with the unstructured environment around. It is perfectly soft and covers the entire body providing immediate feedback even when that part is not directly in the field of vision. With the human skin as an inspiration, in this paper, we develop a novel completely soft robot skin for tactile sensing. The skin utilizes a new type of material called as Permanent Magnet Elastomer (PME) to replace the traditionally used hard permanent magnet for hall effect based tactile sensors. PME is formed by mixing Neodymium particles in a polymer base and using strong magnetization (up to 6 T) for anisotropy and to achieve strong and complete magnetization. The 6-axis soft PME is a perfect replacement for powerful hard magnets. We also do a thorough analysis of this material by infusing it in different types of silicone and as a result the most suitable combinations are selected. Performance tests show that the sensor can detect minute forces like 0.1 N. Moreover, the hysteresis test is carried out and the hysteresis error for our skin is found to be only 1.402%. An overloading test is also performed by loading the skin up to 64 N to check the robustness. In conclusion, the skin can produce reliable Triaxial force measurements and we present two models of it for smaller and large force range measurements respectively.",
        "primary_area": "",
        "author": "Sahil Shembekar;Mitsuhiro Kamezaki;Peizhi Zhang;Zhuoyi He;Yuhiro Iwamoto;Yasushi Ido;Hiroyuki Sakamoto;Shigeki Sugano;Sahil Shembekar;Mitsuhiro Kamezaki;Peizhi Zhang;Zhuoyi He;Yuhiro Iwamoto;Yasushi Ido;Hiroyuki Sakamoto;Shigeki Sugano",
        "authorids": "/37088698315;/37546400600;/37086449639;/37087046716;/37089196931;/37089196336;/37087048590;/37274050800;/37088698315;/37546400600;/37086449639;/37087046716;/37089196931;/37089196336;/37087048590;/37274050800",
        "aff": "Department of Modern Mechanical Engineering, Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Research Institute for Science and Engineering (RISE), Waseda University, Tokyo, Japan; Department of Modern Mechanical Engineering, Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Department of Modern Mechanical Engineering, Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Department of Electrical and Mechanical Engineering, Nagoya Institute of Technology, Aichi, Japan; Department of Electrical and Mechanical Engineering, Nagoya Institute of Technology, Aichi, Japan; Nippon Paint Holdings Corp, Ltd, Tokyo, Japan; Department of Modern Mechanical Engineering, Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636817/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3001346159241757887&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;1;2;0",
        "aff_unique_norm": "Waseda University;Nagoya Institute of Technology;Nippon Paint Holdings Corp, Ltd",
        "aff_unique_dep": "Department of Modern Mechanical Engineering;Department of Electrical and Mechanical Engineering;",
        "aff_unique_url": "https://www.waseda.jp/top;https://www.nitech.ac.jp;https://www.nipponpaint.com/",
        "aff_unique_abbr": "Waseda;NIT;Nippon Paint",
        "aff_campus_unique_index": "0;0;0;0;1;1;0;0",
        "aff_campus_unique": "Tokyo;Nagoya",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636732",
        "title": "Development of a Vision-Based Robotic Manipulation System for Transferring of Oocytes",
        "track": "main",
        "status": "Poster",
        "abstract": "Embryos/oocytes vitrification is an essential cryopreservation technique in IVF (in vitro fertilization) clinics. The reliable and effective transferring of embryos/oocytes is crucial to the subsequent steps in the whole procedure of vitrification. After each transferring, the straw needs to be replaced with a new one. Due to the uncertainties in the fabrication and installation, the exact knowledge of the kinematic model of the straw is usually unknown, and the relationship between the microscope and the straw is also unknown without calibration beforehand. In such situation, automatically transferring the oocytes from micropipette to the narrow tip of straw (0.7mm) is very challenging. In this paper, a new vision-guided robotic system is developed to automate the transferring of the oocyte without calibration. To this end, the unknown depth information is estimated then compensated by constructing a deep vision network through microscope image, and an approximate Jacobian control algorithm is also proposed to servo control the end tip of the uncalibrated straw to contact the micropipette with the vision feedback. After that, the oocyte is automatically transferred from the micropipette to the straw to finalize the task. The stability of the closed-loop control system is rigorously proved with Lyapunov methods, and the effectiveness of the developed robot is validated in experiments.",
        "primary_area": "",
        "author": "Shu Miao;Dayuan Chen;Qiang Nie;Xin Jiang;Xulin Sun;Jianjun Dai;Yun-Hui Liu;Xiang Li;Shu Miao;Dayuan Chen;Qiang Nie;Xin Jiang;Xulin Sun;Jianjun Dai;Yun-Hui Liu;Xiang Li",
        "authorids": "/37088394711;/37086813300;/37086798026;/37086028734;/37089194652;/37089195891;/37279412600;/37280877200;/37088394711;/37086813300;/37086798026;/37086028734;/37089194652;/37089195891;/37279412600;/37280877200",
        "aff": "Department of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; Department of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; T Stone Robotics Institute and Department of Mechanical Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; T Stone Robotics Institute and Department of Mechanical Engineering, The Chinese University of Hong Kong, Hong Kong, China; Institute of Animal Husbandry Veterinary Science, Shanghai Academy of Agricultural Sciences, Shanghai, China; T Stone Robotics Institute and Department of Mechanical Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Automation, Tsinghua University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636732/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14507440767912898547&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;1;2;1;3",
        "aff_unique_norm": "Harbin Institute of Technology;Chinese University of Hong Kong;Shanghai Academy of Agricultural Sciences;Tsinghua University",
        "aff_unique_dep": "Department of Mechanical Engineering and Automation;Department of Mechanical Engineering;Institute of Animal Husbandry Veterinary Science;Department of Automation",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.cuhk.edu.hk;http://www.saaas.ac.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "HIT;CUHK;;Tsinghua",
        "aff_campus_unique_index": "0;0;1;0;1;2;1",
        "aff_campus_unique": "Shenzhen;Hong Kong;Shanghai;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636095",
        "title": "Dexterous textile manipulation using electroadhesive fingers",
        "track": "main",
        "status": "Poster",
        "abstract": "Handling of fabric is a crucial step in the manufacturing of garments. This task is typically performed by trained workers who manipulate one sheet at a time, thus introducing a bottleneck in the automation of the textile industry. This paper seeks to address the challenge of picking fabric up by proposing a new method of achieving ply-separation. Our approach relies on a finger-tip sized (2 cm2) electroadhesive skin to lift fabric up. A pinch-type grasp is then used to securely hold the separated sheet of fabric, enabling easy manipulation thereafter. The ability to successfully pick up and manipulate a variety of commercial fabrics with diverse materials, shapes, sizes and textures is demonstrated. The ability to handle fabrics 100s of times larger than the electroadhesive skin is unique to our approach. Additionally, we demonstrate the manipulation of non-flat fabrics, a challenge that has not been previously addressed by electroadhesive approaches. We believe that this method introduces a smarter way of handling flexible and limp materials, showing great potential towards automation of garment manufacturing.",
        "primary_area": "",
        "author": "Krishna Manaswi Digumarti;Vito Cacucciolo;Herbert Shea;Krishna Manaswi Digumarti;Vito Cacucciolo;Herbert Shea",
        "authorids": "/37086145365;/37085357007;/37284098900;/37086145365;/37085357007;/37284098900",
        "aff": "Laboratory of Intelligent Systems (LIS), \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Soft Transducers Lab (LMTS), \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Neuchatel, Switzerland; Soft Transducers Lab (LMTS), \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Neuchatel, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636095/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18296052487655759193&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "Laboratory of Intelligent Systems",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636376",
        "title": "DiGNet: Learning Scalable Self-Driving Policies for Generic Traffic Scenarios with Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional decision and planning frameworks for self-driving vehicles (SDVs) scale poorly in new scenarios, thus they require tedious hand-tuning of rules and parameters to maintain acceptable performance in all foreseeable cases. Recently, self-driving methods based on deep learning have shown promising results with better generalization capability but less hand engineering effort. However, most of the previous learning-based methods are trained and evaluated in limited driving scenarios with scattered tasks, such as lane-following, autonomous braking, and conditional driving. In this paper, we propose a graph-based deep network to achieve scalable self-driving that can handle massive traffic scenarios. Specifically, more than 7,000 km of evaluation is conducted in a high-fidelity driving simulator, in which our method can obey the traffic rules and safely navigate the vehicle in a large variety of urban, rural, and highway environments, including unprotected left turns, narrow roads, roundabouts, and pedestrian-rich intersections. Demonstration videos are available at https: //caipeide.github.io/dignet/.",
        "primary_area": "",
        "author": "Peide Cai;Hengli Wang;Yuxiang Sun;Ming Liu;Peide Cai;Hengli Wang;Yuxiang Sun;Ming Liu",
        "authorids": "/37087104388;/37086939511;/37085435479;/37085398677;/37087104388;/37086939511;/37085435479;/37085398677",
        "aff": "ECE, the HKUST; ECE, the HKUST; ME, PolyU of HK; ECE, the HKUST",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636376/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12883029126197710954&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Hong Kong Polytechnic University",
        "aff_unique_dep": "Electronic and Computer Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ust.hk;https://www.polyu.edu.hk",
        "aff_unique_abbr": "HKUST;PolyU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636300",
        "title": "Differentiable Factor Graph Optimization for Learning Smoothers",
        "track": "main",
        "status": "Poster",
        "abstract": "A recent line of work has shown that end-to-end optimization of Bayesian filters can be used to learn state estimators for systems whose underlying models are difficult to hand-design or tune, while retaining the core advantages of probabilistic state estimation. As an alternative approach for state estimation in these settings, we present an end-to-end approach for learning state estimators modeled as factor graph-based smoothers. By unrolling the optimizer we use for maximum a posteriori inference in these probabilistic graphical models, our method is able to learn probabilistic system models in the full context of an overall state estimator, while also taking advantage of the distinct accuracy and runtime advantages that smoothers offer over recursive filters. We study our approach using two fundamental state estimation problems, object tracking and visual odometry, where we demonstrate a significant improvement over existing baselines. Our work comes with an extensive code release, which includes training and evaluation scripts, as well as Python libraries for Lie theory and factor graph optimization: https://sites.google.com/view/diffsmoothing/.",
        "primary_area": "",
        "author": "Brent Yi;Michelle A. Lee;Alina Kloss;Roberto Mart\u00edn-Mart\u00edn;Jeannette Bohg;Brent Yi;Michelle A. Lee;Alina Kloss;Roberto Mart\u00edn-Mart\u00edn;Jeannette Bohg",
        "authorids": "/37088687522;/37086935666;/37085615238;/37085788640;/37591153900;/37088687522;/37086935666;/37085615238;/37085788640;/37591153900",
        "aff": "Stanford University; Stanford University; Max Planck Institute for Intelligent Systems; Stanford University; Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636300/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10875451716411052220&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Stanford University;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": ";Intelligent Systems",
        "aff_unique_url": "https://www.stanford.edu;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "Stanford;MPI-IS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "9636721",
        "title": "Direct Bundle Adjustment for 3D Image Fusion with Application to Transesophageal Echocardiography",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel algorithm for fusing a sequence of 3D images, named as Direct Bundle Adjustment (DBA). This algorithm simultaneously optimizes the global pose parameters of image frames and the intensity values of the fused global image using the 3D image data directly (without extracting features from the images). This one-step 3D image fusion approach is achieved by formulating the problem as an optimization problem to minimize the intensity differences between the global image and the corresponding points in the different local images. The proposed DBA method is particularly useful in the scenarios where distinct features are not available, such as Transesophageal Echocardiography (TEE) images. We validate the proposed method via simulated and in-vivo 3D TEE images. It is shown that the proposed method is robust to intensity noises and much more accurate than the conventional sequential fusion method.",
        "primary_area": "",
        "author": "Zhehua Mao;Liang Zhao;Shoudong Huang;Yiting Fan;Alex Pui-Wai Lee;Zhehua Mao;Liang Zhao;Shoudong Huang;Yiting Fan;Alex Pui-Wai Lee",
        "authorids": "/37089195076;/37857963600;/37421307400;/37089151973;/37086361170;/37089195076;/37857963600;/37421307400;/37089151973;/37086361170",
        "aff": "Centre for Autonomous Systems, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Centre for Autonomous Systems, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Centre for Autonomous Systems, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Department of Cardiology, Shanghai Chest Hospital, Shanghai Jiao Tong University, Shanghai, China; Department of Medicine and Therapeutics, Prince of Wales Hospital and Laboratory of Cardiac Imaging and 3D Printing, Division of Cardiology, Li Ka Shing Institute of Health Science, Faculty of Medicine, The Chinese University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636721/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15764592469685294206&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "University of Technology Sydney;Shanghai Jiao Tong University;Chinese University of Hong Kong",
        "aff_unique_dep": "Centre for Autonomous Systems;Department of Cardiology;Department of Medicine and Therapeutics",
        "aff_unique_url": "https://www.uts.edu.au;https://www.sjtu.edu.cn;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "UTS;SJTU;CUHK",
        "aff_campus_unique_index": "0;0;0;1;2",
        "aff_campus_unique": "Ultimo;Shanghai;Hong Kong",
        "aff_country_unique_index": "0;0;0;1;1",
        "aff_country_unique": "Australia;China"
    },
    {
        "id": "9636181",
        "title": "Discrete Optimization of Adaptive State Lattices for Iterative Motion Planning on Unmanned Ground Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust motion planners for unmanned ground vehicles must minimize risk while obeying vehicle mobility constraints. Algorithms such as the State Lattice (SL) utilize offline computation to generate expressive control sets which form recombinant search spaces, enabling the use of heuristic search to efficiently produce feasible motion plans online. The Adaptive State Lattice (ASL) demonstrated that local optimizations of the continuous states explored by heuristic search can produce lower-cost solutions in less time than more densely sampled unadapted lattices in sufficiently complex environments. However, the computational cost of this online adaptation limits the application of ASL for mobile robot navigation. We present the Efficiently Adaptive State Lattice (EASL), a novel formalism for online discrete ASL adaptation to overcome this limitation. By discretizing the space of states considered during adaptation, EASL limits the set of feasible motions which could arise during search. This permits the precomputation of an approximation of all motions that could be expressed by an ASL. This approximation removes the online trajectory generation component of the ASL while retaining the benefits of lattice adaptation and enables the use of precomputed swaths for evaluating edge costs. Experimental results demonstrate how an EASL-based planner can generate lower-cost paths than a SL-based planner in roughly equal to or less than the same amount of time.",
        "primary_area": "",
        "author": "Benned Hedegaard;Ethan Fahnestock;Jacob Arkin;Ashwin Menon;Thomas M. Howard;Benned Hedegaard;Ethan Fahnestock;Jacob Arkin;Ashwin Menon;Thomas M. Howard",
        "authorids": "/37089197130;/37089197470;/37086336771;/37089195589;/37546611500;/37089197130;/37089197470;/37086336771;/37089195589;/37546611500",
        "aff": "Univeristy of Rochester, Rochester, NY; Univeristy of Rochester, Rochester, NY; Univeristy of Rochester, Rochester, NY; Univeristy of Rochester, Rochester, NY; Univeristy of Rochester, Rochester, NY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636181/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14889495190485862943&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Rochester",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.rochester.edu",
        "aff_unique_abbr": "U of R",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Rochester",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636397",
        "title": "Disentangling Dense Multi-Cable Knots",
        "track": "main",
        "status": "Poster",
        "abstract": "Disentangling two or more cables often requires many steps to remove crossings between and within cables. We formalize the problem of disentangling multiple cables and present an algorithm, Iterative Reduction Of Non-planar Multiple cAble kNots (IRON-MAN), that outputs robot actions to remove crossings from multi-cable knotted structures. IRON-MAN uses a learned perception system inspired by prior work in single-cable untying to imitate a graph-based supervisor, and operates on RGB image inputs of the workspace. Given a sequence of images as input, the system can disentangle two-cable twists, three-cable braids, and knots of two or three cables, such as overhand, square, carrick bend, sheet bend, crown, and fisherman\u2019s knots. IRON-MAN keeps track of task-relevant keypoints corresponding to cable endpoints and crossings and iteratively disentangles the cables by identifying and undoing crossings that are critical to knot structure. Using a da Vinci surgical robot, we experimentally evaluate the effectiveness of IRON-MAN on disentangling multi-cable knots of types that appear in the training data, as well as generalizing to novel classes of multi-cable knots. Results suggest that IRON-MAN is effective in disentangling knots involving up to three cables with 80.5% success and generalizing to knot types that are not present during training, with cables of identical or distinct colors. Supplementary material and videos can be found at https://tinyurl.com/multi-cable-disentangling.",
        "primary_area": "",
        "author": "Vainavi Viswanath;Jennifer Grannen;Priya Sundaresan;Brijen Thananjeyan;Ashwin Balakrishna;Ellen Novoseller;Jeffrey Ichnowski;Michael Laskey;Joseph E. Gonzalez;Ken Goldberg;Vainavi Viswanath;Jennifer Grannen;Priya Sundaresan;Brijen Thananjeyan;Ashwin Balakrishna;Ellen Novoseller;Jeffrey Ichnowski;Michael Laskey;Joseph E. Gonzalez;Ken Goldberg",
        "authorids": "/37089196164;/37088507002;/37087011905;/37086105009;/37085692655;/37088507027;/38541287200;/37085370242;/37086566024;/37273026700;/37089196164;/37088507002;/37087011905;/37086105009;/37085692655;/37088507027;/38541287200;/37085370242;/37086566024;/37273026700",
        "aff": "AUTOLAB at the University of California, Berkeley; AUTOLAB at the University of California, Berkeley; AUTOLAB at the University of California, Berkeley; AUTOLAB at the University of California, Berkeley; AUTOLAB at the University of California, Berkeley; AUTOLAB at the University of California, Berkeley; AUTOLAB at the University of California, Berkeley; Toyota Research Institute; AUTOLAB at the University of California, Berkeley; AUTOLAB at the University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636397/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9469735376935472800&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;0;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;Toyota Research Institute",
        "aff_unique_dep": "AUTOLAB;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.tri.global",
        "aff_unique_abbr": "UC Berkeley;TRI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636707",
        "title": "Disentangling and Vectorization: A 3D Visual Perception Approach for Autonomous Driving Based on Surround-View Fisheye Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "The 3D visual perception for vehicles with the surround-view fisheye camera system is a critical and challenging task for low-cost urban autonomous driving. While existing monocular 3D object detection methods perform not well enough on the fisheye images for mass production, partly due to the lack of 3D datasets of such images. In this paper, we manage to overcome and avoid the difficulty of acquiring the large scale of accurate 3D labeled truth data, by breaking down the 3D object detection task into some sub-tasks, such as vehicle\u2019s contact point detection, type classification, re-identification and unit assembling, etc. Particularly, we propose the concept of Multidimensional Vector to include the utilizable information generated in different dimensions and stages, instead of the descriptive approach for the bird\u2019s eye view (BEV) or a cube of eight points. The experiments of real fisheye images demonstrate that our solution achieves state-of-the-art accuracy while being real-time in practice.",
        "primary_area": "",
        "author": "Zizhang Wu;Wenkai Zhang;Jizheng Wang;Man Wang;Yuanzhu Gan;Xinchao Gou;Muqing Fang;Jing Song;Zizhang Wu;Wenkai Zhang;Jizheng Wang;Man Wang;Yuanzhu Gan;Xinchao Gou;Muqing Fang;Jing Song",
        "authorids": "/37088645948;/37089385727;/37089195439;/37088641112;/37089197542;/37089193989;/37089195377;/37089196969;/37088645948;/37089385727;/37089195439;/37088641112;/37089197542;/37089193989;/37089195377;/37089196969",
        "aff": "Zongmu Technology; Zongmu Technology; Zongmu Technology; Zongmu Technology; Zongmu Technology; Karlsruhe Institute of Technology; Zongmu Technology; Zongmu Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636707/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2836127947801758510&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;0;0",
        "aff_unique_norm": "Zongmu Technology;Karlsruhe Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.kit.edu",
        "aff_unique_abbr": ";KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;1;0;0",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "9636274",
        "title": "Disruption-Limited Planning for Robot Navigation in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Path planning in the presence of dynamic obstacles is a fundamental problem in robotics with widespread applications. A typical approach to such problems is that a robot predicts the trajectories of dynamic obstacles, and plans its path while avoiding them. Such a formulation becomes limiting though for scenarios where an agent cannot complete its task efficiently, without disrupting the movement of dynamic obstacles. For example, when merging in heavy traffic or navigating through crowded corridors. In this paper, we propose a paradigm for planning in dynamic environments, called Disruption-Limited Planning (DLP), that allows a robot to disrupt the motions of dynamic obstacles in order to accomplish its task. DLP builds on the premise that while a robot may have to disrupt others\u2019 trajectories to achieve its goals, it should try to limit the disruption. DLP assumes that it can estimate others\u2019 response to its own actions/plans, and plans its own path while ensuring that no other agents\u2019 disrupted trajectory cost gets worse than w-times their initial trajectory costs. While our formulation is motivated by the Stackelberg competitions, we show that DLP can be both more expressive and computationally more efficient compared to a Stackelberg planner. We present DLP paradigm, develop its efficient implementation based on A*, analyze its theoretical properties, and apply it to multiple planning in dynamic environment problems, including x,y,time planning, planning for self-driving, and planning for arm manipulation. We compare DLP with purely altruistic, purely egocentric, and optimal Stackelberg planners, demonstrating the efficacy of DLP over these alternatives.",
        "primary_area": "",
        "author": "Sandip Aine;Yash Oza;Maxim Likhachev;Sandip Aine;Yash Oza;Maxim Likhachev",
        "authorids": "/37591301400;/839624040602928;/37309318800;/37591301400;/839624040602928;/37309318800",
        "aff": "The Robotics Institute, Carnegie Mellon University, PA, USA; The Robotics Institute, Carnegie Mellon University, PA, USA; The Robotics Institute, Carnegie Mellon University, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636274/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:mGiaLIs5VWsJ:scholar.google.com/&scioq=Disruption-Limited+Planning+for+Robot+Navigation+in+Dynamic+Environments&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "The Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635870",
        "title": "DistillPose: Lightweight Camera Localization Using Auxiliary Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a lightweight retrieval-based pipeline to predict 6DOF camera poses from RGB images. Our pipeline uses a convolutional neural network (CNN) to encode a query image as a feature vector. A nearest neighbor lookup finds the pose-wise nearest database image. A siamese convolutional neural network regresses the relative pose from the nearest neighboring database image to the query image. The relative pose is then applied to the nearest neighboring absolute pose to obtain the query image\u2019s final absolute pose prediction. Our model is a distilled version of NN-Net [1] that reduces its parameters by 98.87%, information retrieval feature vector size by 87.5%, and inference time by 89.18% without a significant decrease in localization accuracy.",
        "primary_area": "",
        "author": "Yehya Abouelnaga;Mai Bui;Slobodan Ilic;Yehya Abouelnaga;Mai Bui;Slobodan Ilic",
        "authorids": "/37086185308;/37085995729;/37266931500;/37086185308;/37085995729;/37266931500",
        "aff": "Faculty of Informatics, Technical University of Munich, Garching, Germany; Faculty of Informatics, Technical University of Munich, Garching, Germany; Technical University of Munich and Siemens AG, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635870/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11312932042160571530&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Faculty of Informatics",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Garching;Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636524",
        "title": "Distributed Event- and Self-Triggered Coverage Control with Speed Constrained Unicycle Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Voronoi coverage control is a particular problem of importance in the area of multi-robot systems, which considers a network of multiple autonomous robots, tasked with optimally covering a large area. This is a common task for fleets of fixed-wing Unmanned Aerial Vehicles (UAVs), which are described in this work by a unicycle model with constant forward-speed constraints. We develop event-based control/communication algorithms to relax the resource requirements on wireless communication and control actuators, an important feature for battery-driven or otherwise energy-constrained systems. To overcome the drawback that the event-triggered algorithm requires continuous measurement of system states, we propose a self-triggered algorithm to estimate the next triggering time. Hardware experiments illustrate the theoretical results.",
        "primary_area": "",
        "author": "Yuni Zhou;Lingxuan Kong;Stefan Sosnowski;Qingchen Liu;Sandra Hirche;Yuni Zhou;Lingxuan Kong;Stefan Sosnowski;Qingchen Liu;Sandra Hirche",
        "authorids": "/37089197640;/37087322551;/37296041900;/37085653776;/37301349100;/37089197640;/37087322551;/37296041900;/37085653776;/37301349100",
        "aff": "Chair of Information-Oriented Control, Technical University of Munich, Munich, Germany; Chair of Information-Oriented Control, Technical University of Munich, Munich, Germany; Chair of Information-Oriented Control, Technical University of Munich, Munich, Germany; Chair of Information-Oriented Control, Technical University of Munich, Munich, Germany; Chair of Information-Oriented Control, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636524/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14677208909996874551&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Chair of Information-Oriented Control",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636101",
        "title": "Distributed Sampling-based Planning for Non-Myopic Active Information Gathering",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of active information gathering for multi-robot systems. Specifically, we consider scenarios where robots are tasked with reducing uncertainty of dynamical hidden states evolving in complex environments. The majority of existing information gathering approaches are centralized and, therefore, they cannot be applied to distributed robot teams where communication to a central user is not available. To address this challenge, we propose a novel distributed sampling-based planning algorithm that can significantly increase robot and target scalability while decreasing computational cost. In our non-myopic approach, all robots build in parallel local trees exploring the information space and their corresponding motion space. As the robots construct their respective local trees, they communicate with their neighbors to exchange and aggregate their local beliefs about the hidden state through a distributed Kalman filter. We show that the proposed algorithm is probabilistically complete and asymptotically optimal. We provide extensive simulation results that demonstrate the scalability of the proposed algorithm and that it can address large-scale, multi-robot information gathering tasks, that are computationally challenging for centralized methods.",
        "primary_area": "",
        "author": "Mariliza Tzes;Yiannis Kantaros;George J. Pappas;Mariliza Tzes;Yiannis Kantaros;George J. Pappas",
        "authorids": "/37086395388;/37085499544;/37281547100;/37086395388;/37085499544;/37281547100",
        "aff": "Grasp Lab, University of Pennsylvania, Philadelphia, PA, USA; Grasp Lab, University of Pennsylvania, Philadelphia, PA, USA; Grasp Lab, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636101/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4731727606814436425&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Grasp Lab",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636031",
        "title": "Distributed Visual-Inertial Cooperative Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a consistent and distributed state estimator for multi-robot cooperative localization (CL) which efficiently fuses environmental features and loop-closure constraints across time and robots. In particular, we leverage covariance intersection (CI) to allow each robot to only estimate its own state and autocovariance and compensate for the unknown correlations between robots. Two novel multi-robot methods for utilizing common environmental SLAM features are introduced and evaluated in terms of accuracy and efficiency. Moreover, we adapt CI to enable drift-free estimation through the use of loop-closure measurement constraints to other robots\u2019 historical poses without a significant increase in computational cost. The proposed distributed CL estimator is validated against its non-realtime centralized counterpart extensively in both simulations and real-world experiments.",
        "primary_area": "",
        "author": "Pengxiang Zhu;Patrick Geneva;Wei Ren;Guoquan Huang;Pengxiang Zhu;Patrick Geneva;Wei Ren;Guoquan Huang",
        "authorids": "/37086958473;/37086125563;/37271980400;/37077670600;/37086958473;/37086125563;/37271980400;/37077670600",
        "aff": "Department of Electrical and Computer Engineering, University of California, Riverside, CA, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Department of Electrical and Computer Engineering, University of California, Riverside, CA, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636031/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6478697322808593461&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of California, Riverside;University of Delaware",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Robot Perception and Navigation Group",
        "aff_unique_url": "https://www.ucr.edu;https://www.udel.edu",
        "aff_unique_abbr": "UCR;UD",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Riverside;Newark",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636869",
        "title": "Diverse Complexity Measures for Dataset Curation in Self-Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern self-driving systems heavily rely on deep learning. As a consequence, their performance is influenced significantly by the quality and richness of the training data. Data collection platforms can generate many hours of raw data on a daily basis, however, it is not feasible to label everything. Therefore, it is critical to have a mechanism to identify \"what to label\". Active learning approaches identify examples to label, but their interestingness is tied to a fixed model performing a particular task. These assumptions are not valid in self-driving, where we must solve a diverse set of tasks (i.e., perception, motion forecasting, and planning) and models frequently evolve over time. In this paper, we introduce a novel approach to dataset selection that exploits a diverse set of criteria that quantize interestingness of traffic scenes. Our experiments on a wide range of tasks and models demonstrate that the proposed curation pipeline is able to select datasets that lead to better generalization and improved performance.",
        "primary_area": "",
        "author": "Abbas Sadat;Sean Segal;Sergio Casas;James Tu;Bin Yang;Raquel Urtasun;Ersin Yumer;Abbas Sadat;Sean Segal;Sergio Casas;James Tu;Bin Yang;Raquel Urtasun;Ersin Yumer",
        "authorids": "/37087231701;/37088686947;/37086821588;/37088455138;/37399884400;/37269502900;/37086161237;/37087231701;/37088686947;/37086821588;/37088455138;/37399884400;/37269502900;/37086161237",
        "aff": "Waabi; University of Toronto; University of Toronto; Waabi; University of Toronto; University of Toronto; Aurora",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636869/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14135771125939898945&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;0;1;1;2",
        "aff_unique_norm": "Waabi;University of Toronto;Aurora",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";https://www.utoronto.ca;",
        "aff_unique_abbr": ";U of T;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "1;1;1;1",
        "aff_country_unique": ";Canada"
    },
    {
        "id": "9636266",
        "title": "Diverse Critical Interaction Generation for Planning and Planner Evaluation",
        "track": "main",
        "status": "Poster",
        "abstract": "Generating diverse and comprehensive interacting agents to evaluate the decision-making modules is essential for the safe and robust planning of autonomous vehicles (AV). Due to efficiency and safety concerns, most researchers choose to train interactive adversary (competitive or weakly competitive) agents in simulators and generate test cases to interact with evaluated AVs. However, most existing methods fail to provide both natural and critical interaction behaviors in various traffic scenarios. To tackle this problem, we propose a styled generative model RouteGAN that generates diverse interactions by controlling the vehicles separately with desired styles. By altering its style coefficients, the model can generate trajectories with different safety levels serve as an online planner. Experiments show that our model can generate diverse interactions in various scenarios. We evaluate different planners with our model by testing their collision rate in interaction with RouteGAN planners of multiple critical levels.",
        "primary_area": "",
        "author": "Zhao-Heng Yin;Lingfeng Sun;Liting Sun;Masayoshi Tomizuka;Wei Zhan;Zhao-Heng Yin;Lingfeng Sun;Liting Sun;Masayoshi Tomizuka;Wei Zhan",
        "authorids": "/37089196259;/37087105341;/37085425729;/37281933000;/37067099600;/37089196259;/37087105341;/37085425729;/37281933000;/37067099600",
        "aff": "Department of Computer Science and Technology, Nanjing University, Nanjing, PRC; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636266/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13477452981447597728&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Nanjing University;University of California, Berkeley",
        "aff_unique_dep": "Department of Computer Science and Technology;Department of Mechanical Engineering",
        "aff_unique_url": "http://www.nju.edu.cn;https://www.berkeley.edu",
        "aff_unique_abbr": "Nanjing U;UC Berkeley",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Nanjing;Berkeley",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9636578",
        "title": "Domain Adaptive Robotic Gesture Recognition with Unsupervised Kinematic-Visual Data Alignment",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated surgical gesture recognition is of great importance in robot-assisted minimally invasive surgery. However, existing methods assume that training and testing data are from the same domain, which suffers from severe performance degradation when a domain gap exists, such as the simulator and real robot. In this paper, we propose a novel unsupervised domain adaptation framework which can simultaneously transfer multi-modality knowledge, i.e., both kinematic and visual data, from simulator to real robot. It remedies the domain gap with enhanced transferable features by using temporal cues in videos, and inherent correlations in multi-modal towards recognizing gesture. Specifically, we first propose a Motion Direction Oriented Kinematics feature alignment (MDO-K) to align kinematics, which exploits temporal continuity to transfer motion directions with smaller gap rather than position values, relieving the adaptation burden. Moreover, we propose a Kinematic and Visual Relation Attention (KV-Relation-ATT) to transfer the co-occurrence signals of kinematics and vision. Such features attended by correlation similarity are more informative for enhancing domain-irreverent of the model. Two feature alignment strategies benefit the model mutually during the end-to-end learning process. We extensively evaluate our method for gesture recognition using DESK dataset with peg transfer procedure. Results show that our approach recovers the performance with great improvement gains, up to 12.91% in Accuracy and 20.16% in F1score without using any annotations in real robot.",
        "primary_area": "",
        "author": "Xueying Shi;Yueming Jin;Qi Dou;Jing Qin;Pheng-Ann Heng;Xueying Shi;Yueming Jin;Qi Dou;Jing Qin;Pheng-Ann Heng",
        "authorids": "/37086885413;/37086369638;/37085465414;/37085387571;/37283077400;/37086885413;/37086369638;/37085465414;/37085387571;/37283077400",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; T Stone Robotics Institute, The Chinese University of Hong Kong; Centre for Smart Health, School of Nursing, The Hong Kong Polytechnic University; Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636578/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9523637259264168065&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "Chinese University of Hong Kong;Hong Kong Polytechnic University;Chinese Academy of Sciences",
        "aff_unique_dep": "Department of Computer Science and Engineering;School of Nursing;Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.polyu.edu.hk;http://www.cas.cn",
        "aff_unique_abbr": "CUHK;PolyU;CAS",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635864",
        "title": "Domain Curiosity: Learning Efficient Data Collection Strategies for Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Domain adaptation is a common problem in robotics, with applications such as transferring policies from simulation to real world and lifelong learning. Performing such adaptation, however, requires informative data about the environment to be available during the adaptation. In this paper, we present domain curiosity\u2014a method of training exploratory policies that are explicitly optimized to provide data that allows a model to learn about the unknown aspects of the environment. In contrast to most curiosity methods, our approach explicitly rewards learning, which makes it robust to environment noise without sacrificing its ability to learn. We evaluate the proposed method by comparing how much a model can learn about environment dynamics given data collected by the proposed approach, compared to standard curious and random policies. The evaluation is performed using a toy environment, two simulated robot setups, and on a real-world haptic exploration task. The results show that the proposed method allows data-efficient and accurate estimation of dynamics.",
        "primary_area": "",
        "author": "Karol Arndt;Oliver Struckmeier;Ville Kyrki;Karol Arndt;Oliver Struckmeier;Ville Kyrki",
        "authorids": "/37087322085;/37087236410;/37274001900;/37087322085;/37087236410;/37274001900",
        "aff": "Intelligent Robotics Group, Aalto University, Espoo, Finland; Intelligent Robotics Group, Aalto University, Espoo, Finland; Intelligent Robotics Group, Aalto University, Espoo, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635864/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16333218430573450354&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Aalto University",
        "aff_unique_dep": "Intelligent Robotics Group",
        "aff_unique_url": "https://www.aalto.fi",
        "aff_unique_abbr": "Aalto",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Espoo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "9636706",
        "title": "Double-Dot Network for Antipodal Grasp Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a new deep learning approach to antipodal grasp detection, named Double-Dot Network (DD-Net). It follows the recent anchor-free object detection framework, which does not depend on empirically pre-set anchors and thus allows more generalized and flexible prediction on unseen objects. Specifically, unlike the widely used 5-dimensional rectangle, the gripper configuration is defined as a pair of fingertips. An effective CNN architecture is introduced to localize such fingertips, and with the help of auxiliary centers for refinement, it accurately and robustly infers grasp candidates. Additionally, we design a specialized loss function to measure the quality of grasps, and in contrast to the IoU scores of bounding boxes adopted in object detection, it is more consistent to the grasp detection task. Both the simulation and robotic experiments are executed and state of the art accuracies are achieved, showing that DD-Net is superior to the counterparts in handling unseen objects.",
        "primary_area": "",
        "author": "Yao Wang;Yangtao Zheng;Boyang Gao;Di Huang;Yao Wang;Yangtao Zheng;Boyang Gao;Di Huang",
        "authorids": "/37086801213;/37088365264;/37085855554;/37401456900;/37086801213;/37088365264;/37085855554;/37401456900",
        "aff": "State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China; Geometry Robotics; State Key Laboratory of Software Development Environment, School of Computer Science and Engineering, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636706/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6582864270024091332&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Beihang University;Geometry Robotics",
        "aff_unique_dep": "School of Computer Science and Engineering;",
        "aff_unique_url": "http://www.buaa.edu.cn;",
        "aff_unique_abbr": "BUAA;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9636065",
        "title": "Downing a Rogue Drone with a Team of Aerial Radio Signal Jammers",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes a novel distributed control framework in which a team of pursuer agents equipped with a radio jamming device cooperate in order to track and radio-jam a rogue target in 3D space, with the ultimate purpose of disrupting its communication and navigation circuitry. The target evolves in 3D space according to a stochastic dynamical model and it can appear and disappear from the surveillance area at random times. The pursuer agents cooperate in order to estimate the probability of target existence and its spatial density from a set of noisy measurements in the presence of clutter. Additionally, the proposed control framework allows a team of pursuer agents to optimally choose their radio transmission levels and their mobility control actions in order to ensure uninterrupted radio jamming to the target, as well as to avoid the jamming interference among the team of pursuer agents. Extensive simulation analysis of the system\u2019s performance validates the applicability of the proposed approach.",
        "primary_area": "",
        "author": "Savvas Papaioannou;Panayiotis Kolios;Georgios Ellinas;Savvas Papaioannou;Panayiotis Kolios;Georgios Ellinas",
        "authorids": "/38666812600;/37669519700;/37273786700;/38666812600;/37669519700;/37273786700",
        "aff": "KIOS Research and Innovation Centre of Excellence (KIOS CoE) and the Department of Electrical and Computer Engineering, University of Cyprus, Nicosia, Cyprus; KIOS Research and Innovation Centre of Excellence (KIOS CoE) and the Department of Electrical and Computer Engineering, University of Cyprus, Nicosia, Cyprus; KIOS Research and Innovation Centre of Excellence (KIOS CoE) and the Department of Electrical and Computer Engineering, University of Cyprus, Nicosia, Cyprus",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636065/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7301199269678149321&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Cyprus",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucy.ac.cy",
        "aff_unique_abbr": "UCY",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nicosia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Cyprus"
    },
    {
        "id": "9635879",
        "title": "Drawing Elon Musk: A Robot Avatar for Remote Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "The fast growth of communication technologies such as 5G provides high bandwidth and low latency wireless internet access. This enables both high definition video stream and real-time robot commands transmitted between robots and operators in the context of telepresence and teleoperation. Although there has been substantial research to establish algorithms that convert images to robot motions and telerobotic systems, little effort was made in establishing a clear scheme that enable artists to draw portraits using telerobotic systems. In this paper, we provide an easy-to-follow structure and implementation of a robot avatar for portrait drawing by artists through remote manipulation. The proposed telerobotic system uses a digital tablet and motion capture suit as input devices, which provides accurate drawing and continuous motion data stream respectively. With sensor fusion of the input data on the robot side, the drawing process presented in this work uses a unified force and impedance controller to ensure smooth and uniform pen-strokes. The proposed scheme was used to synthesise a system that was used by an artist to successfully finish the portrait drawing of Elon Musk. Finally, we show the effectiveness of the introduced control framework through an experiment. In particular, we validate the benefit of combining unified force and impedance control with sensor fusion of the digital tablet and motion capture suit data.",
        "primary_area": "",
        "author": "Lingyun Chen;Abdalla Swikir;Sami Haddadin;Lingyun Chen;Abdalla Swikir;Sami Haddadin",
        "authorids": "/37089198301;/37085861833;/37542865300;/37089198301;/37085861833;/37542865300",
        "aff": "Munich School of Robotics and Machine Intelligence and the Chair of Robotics Science and Systems Intelligence, Technical University of Munich; Munich School of Robotics and Machine Intelligence and the Chair of Robotics Science and Systems Intelligence, Technical University of Munich; Munich School of Robotics and Machine Intelligence and the Chair of Robotics Science and Systems Intelligence, Technical University of Munich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635879/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11865022946118999500&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Munich School of Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636848",
        "title": "Drive on Pedestrian Walk. TUK Campus Dataset",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous driving in a pedestrian zone is a challenging task. Technische Universitaet Kaiserslautern (TUK) is currently researching autonomous driving on the university campus for elderly or disabled people. This paper presents a novel campus dataset from the TUK campus, recorded over the span of one year for an autonomous bus project. John Deere\u2019s Gator X855D is used for the work which is equipped with an inertial GPS navigation system, stereo cameras, monocular camera, and lidar sensors. For pedestrian safety during autonomous driving, the sensors are attached to capture the view of all four directions. Each sensor is calibrated with respect to the rear axle center of the vehicle and the intrinsic/extrinsic calibration values are provided. Moreover, the loop closure is performed in every data sequence. Several pose estimation and deep learning techniques are implemented to validate the provided data. The dataset is publicly available4.",
        "primary_area": "",
        "author": "Hannan Ejaz Keen;Qazi Hamza Jan;Karsten Berns;Hannan Ejaz Keen;Qazi Hamza Jan;Karsten Berns",
        "authorids": "/37089197102;/37089194448;/37274823100;/37089197102;/37089194448;/37274823100",
        "aff": "Faculty of Informatik, Technische Universit\u00e4te Kaiserslautern, Germany; Faculty of Informatik, Technische Universit\u00e4te Kaiserslautern, Germany; Faculty of Informatik, Technische Universit\u00e4te Kaiserslautern, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636848/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18152485174369368881&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Kaiserslautern",
        "aff_unique_dep": "Faculty of Informatik",
        "aff_unique_url": "https://www.uni-kl.de",
        "aff_unique_abbr": "TU Kaiserslautern",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9635892",
        "title": "Drop Prevention Control for Humanoid Robots Carrying Stacked Boxes",
        "track": "main",
        "status": "Poster",
        "abstract": "We developed a method to enable a humanoid robot to carry stacked boxes. In order to transport objects efficiently, it is necessary to carry multiple objects at the same time, but in previous studies, humanoid robots have only been able to carry a single object. When a humanoid robot carries stacked boxes, the robot drops boxes when the positional relationship between un-grasped boxes changes. The causes for dropping the boxes can be divided into sudden changes attributed to robot making turns or losing balance, and the accumulation of small changes that occur because of the impact of landing while walking. We propose a method that prevents sudden changes in the stacked boxes by smoothing the hand trajectory and modifying the misalignment by tilting or shaking the entire stack. We verify the effectiveness of proposed method for enabling a humanoid robot to carry stacked boxes through experiments using a simulator and an actual robot.",
        "primary_area": "",
        "author": "Shimpei Sato;Yuta Kojio;Kunio Kojima;Fumihito Sugai;Yohei Kakiuchi;Kei Okada;Masayuki Inaba;Shimpei Sato;Yuta Kojio;Kunio Kojima;Fumihito Sugai;Yohei Kakiuchi;Kei Okada;Masayuki Inaba",
        "authorids": "/37089197675;/37086211574;/37085360901;/37085651948;/38242437800;/37280639000;/37286658200;/37089197675;/37086211574;/37085360901;/37085651948;/38242437800;/37280639000;/37286658200",
        "aff": "Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635892/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11263925809695346221&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Infomatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636654",
        "title": "Dual-Filtering for On-Line Simultaneously Estimate Weights and Phase Parameter of Probabilistic Movement Primitives for Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "The Probabilistic Movement Primitives (ProMPs) is an essential issue and framework for robotics Learning from Demonstration (LfD). It has been successfully applied to the robotics field in tasks such as skill acquisition and Human-Robot Collaboration (HRC). In this paper, we focus on its adaptability in the HRC scenario, in which the adaptability of the ProMPs allows the robot to predict the future movement of its human partner and plan its movement accordingly, given the observed human movement. Most of the existing works about the application of the ProMPs in HRC either only focus on the estimation of the weights on-line and lack the estimation of the phase parameter or merely depend on the prior distribution of the phase parameter. As a result, these methods can lead to a misinterpretation of the basis matrix when the divergence between the prior distribution and the posterior distribution of the phase parameter becomes large, resulting in a divergence of the estimation of the weights. In this paper, we propose a Dual-Filtering method for the ProMPs, which is able to simultaneously on-line estimate the weights and phase parameter for the ProMPs. The preliminary experimental result demonstrates the proposed method is able to provide better prediction performance and more accurate estimation of the phase parameter in comparison with the previous works.",
        "primary_area": "",
        "author": "Ren.C Luo;Licong Mai;Ren.C Luo;Licong Mai",
        "authorids": "/37268829000;/37087323704;/37268829000;/37087323704",
        "aff": "Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan; Department of Electrical Engineering, National Taiwan University, Taipei, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636654/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:rRrAs3FRQjgJ:scholar.google.com/&scioq=Dual-Filtering+for+On-Line+Simultaneously+Estimate+Weights+and+Phase+Parameter+of+Probabilistic+Movement+Primitives+for+Human-Robot+Collaboration&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National Taiwan University",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.ntu.edu.tw",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636343",
        "title": "Dynamic Domain Adaptation for Single-view 3D Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning 3D object reconstruction from a single RGB image is a fundamental and extremely challenging problem for robots. As acquiring labeled 3D shape representations for real-world data is time-consuming and expensive, synthetic image-shape pairs are widely used for 3D reconstruction. However, the models trained on synthetic data set did not perform equally well on real-world images. The existing method used the domain adaptation to fill the domain gap between different data sets. Unlike the approach simply considered global distribution for domain adaptation, this paper presents a dynamic domain adaptation (DDA) network to extract domain-invariant image features for 3D reconstruction. The relative importance between global and local distributions are considered to reduce the discrepancy between synthetic and real-world data. In addition, graph convolution network (GCN) based mesh generation methods have achieved impressive results than voxel-based and point cloud-based methods. However, the global context in a graph is not effectively used due to the limited receptive field of GCN. In this paper, a multi-scale processing method for graph convolution network (GCN) is proposed to further improve the performance of GCN-based 3D reconstruction. The experiment results conducted on both synthetic and real-world data set have demonstrated the effectiveness of the proposed methods.",
        "primary_area": "",
        "author": "Cong Yang;Housen Xie;Haihong Tian;Yuanlong Yu;Cong Yang;Housen Xie;Haihong Tian;Yuanlong Yu",
        "authorids": "/37090022570;/37089196101;/37089194235;/37089854109;/37090022570;/37089196101;/37089194235;/37089854109",
        "aff": "Ecovacs Robotics AI Institute, Nanjing, China; Ecovacs Robotics AI Institute, Nanjing, China; Ecovacs Robotics AI Institute, Nanjing, China; Ecovacs Robotics AI Institute, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636343/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3673856518598508384&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Ecovacs Robotics AI Institute",
        "aff_unique_dep": "AI Institute",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636398",
        "title": "Dynamic Event Camera Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "Camera calibration is an important prerequisite towards the solution of 3D computer vision problems. Traditional methods rely on static images of a calibration pattern. This raises interesting challenges towards the practical usage of event cameras, which notably require image change to produce sufficient measurements. The current standard for event camera calibration therefore consists of using flashing patterns. They have the advantage of simultaneously triggering events in all reprojected pattern feature locations, but it is difficult to construct or use such patterns in the field. We present the first dynamic event camera calibration algorithm. It calibrates directly from events captured during relative motion between camera and calibration pattern. The method is propelled by a novel feature extraction mechanism for calibration patterns, and leverages existing calibration tools before optimizing all parameters through a multi-segment continuous-time formulation. As demonstrated through our results on real data, the obtained calibration method is highly convenient and reliably calibrates from data sequences spanning less than 10 seconds.",
        "primary_area": "",
        "author": "Kun Huang;Yifu Wang;Laurent Kneip;Kun Huang;Yifu Wang;Laurent Kneip",
        "authorids": "/37712672400;/37086160259;/37569040300;/37712672400;/37086160259;/37569040300",
        "aff": "University of Chinese Academy of Sciences; ShanghaiTech University; Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636398/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13917807476337116375&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Chinese Academy of Sciences;ShanghaiTech University;Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.ucas.ac.cn;https://www.shanghaitech.edu.cn;",
        "aff_unique_abbr": "UCAS;ShanghaiTech;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636057",
        "title": "Dynamic Grasping with Reachability and Motion Awareness",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping in dynamic environments presents a unique set of challenges. A stable and reachable grasp can become unreachable and unstable as the target object moves, motion planning needs to be adaptive and in real time, the delay in computation makes prediction necessary. In this paper, we present a dynamic grasping framework that is reachability-aware and motion-aware. Specifically, we model the reachability space of the robot using a signed distance field which enables us to quickly screen unreachable grasps. Also, we train a neural network to predict the grasp quality conditioned on the current motion of the target. Using these as ranking functions, we quickly filter a large grasp database to a few grasps in real time. In addition, we present a seeding approach for arm motion generation that utilizes solution from previous time step. This quickly generates a new arm trajectory that is close to the previous plan and prevents fluctuation. We implement a recurrent neural network (RNN) for modelling and predicting the object motion. Our extensive experiments demonstrate the importance of each of these components and we validate our pipeline on a real robot.",
        "primary_area": "",
        "author": "Iretiayo Akinola;Jingxi Xu;Shuran Song;Peter K. Allen;Iretiayo Akinola;Jingxi Xu;Shuran Song;Peter K. Allen",
        "authorids": "/37086319261;/37088507340;/37085613509;/37280851400;/37086319261;/37088507340;/37085613509;/37280851400",
        "aff": "Department of Computer Science, Columbia University, New York, NY, USA; Department of Computer Science, Columbia University, New York, NY, USA; Department of Computer Science, Columbia University, New York, NY, USA; Department of Computer Science, Columbia University, New York, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636057/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7197480576499213237&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635927",
        "title": "Dynamic Grasping with a \"Soft\" Drone: From Theory to Practice",
        "track": "main",
        "status": "Poster",
        "abstract": "Rigid grippers used in existing aerial manipulators require precise positioning to achieve successful grasps and transmit large contact forces that may destabilize the drone. This limits the speed during grasping and prevents \"dynamic grasping\", where the drone attempts to grasp an object while moving. On the other hand, biological systems (e.g., birds) rely on compliant and soft parts to dampen contact forces and compensate for grasping inaccuracy, enabling impressive feats.This paper presents the first prototype of a soft drone \u2014 a quadrotor where traditional (i.e., rigid) landing gears are replaced with a soft tendon-actuated gripper to enable aggressive grasping. We provide three key contributions. First, we describe our soft drone prototype, including electro-mechanical design, software infrastructure, and fabrication. Second, we review the set of algorithms we use for trajectory optimization and control of the drone and the soft gripper; the algorithms combine state-of-the-art techniques for quadrotor control (i.e., an adaptive geometric controller) with advanced soft robotics models (i.e., a quasi-static finite element model). Finally, we evaluate our soft drone in physics simulations (using SOFA and Unity) and in real tests in a motion-capture room. Our drone is able to dynamically grasp objects of unknown shape where baseline approaches fail. Our physical prototype ensures consistent performance, achieving 91.7% successful grasps across 23 trials. We showcase dynamic grasping results in the video attachment.",
        "primary_area": "",
        "author": "Joshua Fishman;Samuel Ubellacker;Nathan Hughes;Luca Carlone;Joshua Fishman;Samuel Ubellacker;Nathan Hughes;Luca Carlone",
        "authorids": "/37088883668;/37087652384;/37089198205;/37545784100;/37088883668;/37087652384;/37089198205;/37545784100",
        "aff": "Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology, Cambridge, MA; Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology, Cambridge, MA; Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology, Cambridge, MA; Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635927/",
        "gs_citation": 91,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6379809215148494561&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information and Decision Systems (LIDS)",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636218",
        "title": "Dynamic Humanoid Locomotion Over Rough Terrain With Streamlined Perception-Control Pipeline",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision aided dynamic exploration on bipedal robots poses an integrated challenge for perception and control. Rapid walking motions as well as the vibrations caused by the landing-foot contact-force introduce critical uncertainty in the visual-inertial system, which can cause the robot to misplace its feet placing on complex terrains and even fall over. In this paper, we present a streamlined integration of an efficient geometric footstep planner and the corresponding walking controller for a humanoid robot to dynamically walk across rough terrain at speeds up to 0.3 m/s. To handle perception uncertainty that arises during dynamic locomotion, we present a geometric safety scoring method in our footstep planner to optimally select feasible path candidates. In addition, the real-time performance of the perception pipeline allows for reactive locomotion such as generating a new corresponding swing leg trajectory in mid-gait if a sudden change in the terrain is detected. The proposed perception-control pipeline is evaluated and demonstrated with real experiments using a full-scale humanoid to traverse across various terrains.",
        "primary_area": "",
        "author": "Moonyoung Lee;Youngsun Kwon;Sebin Lee;JongHun Choe;Junyong Park;Hyobin Jeong;Yujin Heo;Min-Su Kim;Jo Sungho;Sung-Eui Yoon;Jun-Ho Oh;Moonyoung Lee;Youngsun Kwon;Sebin Lee;JongHun Choe;Junyong Park;Hyobin Jeong;Yujin Heo;Min-Su Kim;Jo Sungho;Sung-Eui Yoon;Jun-Ho Oh",
        "authorids": "/37087323875;/37085769014;/37089197945;/37086085969;/37085751804;/37085760405;/37087323364;/37404419900;/37089194807;/37066068100;/37292052500;/37087323875;/37085769014;/37089197945;/37086085969;/37085751804;/37085760405;/37087323364;/37404419900;/37089194807;/37066068100;/37292052500",
        "aff": "Department of Mechanical Engineering, Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Scalable Graphics, Vision & Robotics Lab, School of Computing, Korea Advanced Institute of Science and Technology, Korea; Scalable Graphics, Vision & Robotics Lab, School of Computing, Korea Advanced Institute of Science and Technology, Korea; Department of Mechanical Engineering, Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Neuro-Machine Augmented Intelligence Laboratory, School of Computing, Korea Advanced Institute of Science and Technology, Korea; Korea Atomic Energy Research Institute (KAERI), Korea; Department of Mechanical Engineering, Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Department of Mechanical Engineering, Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Neuro-Machine Augmented Intelligence Laboratory, School of Computing, Korea Advanced Institute of Science and Technology, Korea; Scalable Graphics, Vision & Robotics Lab, School of Computing, Korea Advanced Institute of Science and Technology, Korea; Department of Mechanical Engineering, Humanoid Robot Research Center, Korea Advanced Institute of Science and Technology, Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636218/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14404285248700444507&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;1;0;0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;Korea Atomic Energy Research Institute",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.kaist.ac.kr;http://www.kaeri.re.kr",
        "aff_unique_abbr": "KAIST;KAERI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Daejeon;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636804",
        "title": "Dynamic Lambda-Field: A Counterpart of the Bayesian Occupancy Grid for Risk Assessment in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In the context of autonomous vehicles, one of the most crucial tasks is to estimate the risk of the undertaken action. While navigating in complex urban environments, the Bayesian occupancy grid is one of the most popular types of maps, where the information of occupancy is stored as the probability of collision. Although widely used, this kind of representation is not well suited for risk assessment: because of its discrete nature, the probability of collision becomes dependent on the tessellation size. Therefore, risk assessments on Bayesian occupancy grids cannot yield risks with meaningful physical units. In this article, we propose an alternative framework called Dynamic Lambda-Field that is able to assess generic physical risks in dynamic environments without being dependent on the tessellation size. Using our framework, we are able to plan safe trajectories where the risk function can be adjusted depending on the scenario. We validate our approach with quantitative experiments, showing the convergence speed of the grid and that the framework is suitable for real-world scenarios.",
        "primary_area": "",
        "author": "Johann Laconte;Elie Randriamiarintsoa;Abderrahim Kasmi;Fran\u00e7ois Pomerleau;Roland Chapuis;Christophe Debain;Romuald Aufr\u00e8re;Johann Laconte;Elie Randriamiarintsoa;Abderrahim Kasmi;Fran\u00e7ois Pomerleau;Roland Chapuis;Christophe Debain;Romuald Aufr\u00e8re",
        "authorids": "/37086937678;/37089197178;/37086544996;/37594916100;/37284680500;/37295668300;/37443102500;/37086937678;/37089197178;/37086544996;/37594916100;/37284680500;/37295668300;/37443102500",
        "aff": "Cnrs, Clermont Auvergne INP, Institut Pascal, Universit\u00e9 Clermont Auvergne, Clermont-Ferrand, France; Cnrs, Clermont Auvergne INP, Institut Pascal, Universit\u00e9 Clermont Auvergne, Clermont-Ferrand, France; R&D Department, Sherpa Engineering, France; Northern Robotics Laboratory, Universit\u00e9 Laval, Canada; Cnrs, Clermont Auvergne INP, Institut Pascal, Universit\u00e9 Clermont Auvergne, Clermont-Ferrand, France; Inrae, UR Tscf, Universit\u00e9 Clermont Auvergne, France; Cnrs, Clermont Auvergne INP, Institut Pascal, Universit\u00e9 Clermont Auvergne, Clermont-Ferrand, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636804/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=626901097595854200&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;0;3;0",
        "aff_unique_norm": "Universit\u00e9 Clermont Auvergne;Sherpa Engineering;Universit\u00e9 Laval;Institut National de Recherche pour l'Agriculture, l'Alimentation et l'Environnement",
        "aff_unique_dep": ";R&D Department;Northern Robotics Laboratory;Unit\u00e9 de Recherche Transdisciplinaire en Sciences du Climat et de la Forg\u00e9tronique",
        "aff_unique_url": "https://www.uca.fr;;https://www.ulaval.ca;https://www.inrae.fr",
        "aff_unique_abbr": "UCA;;;INRAE",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Clermont-Ferrand;",
        "aff_country_unique_index": "0;0;0;1;0;0;0",
        "aff_country_unique": "France;Canada"
    },
    {
        "id": "9636361",
        "title": "Dynamic Modeling of Hand-Object Interactions via Tactile Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile sensing is critical for humans to perform everyday tasks. While significant progress has been made in analyzing object grasping from vision, it remains unclear how we can utilize tactile sensing to reason about and model the dynamics of hand-object interactions. In this work, we employ a high-resolution tactile glove to perform four different interactive activities on a diversified set of objects. We propose a framework aiming at predicting the 3d locations of both the hand and the object purely from the touch data by combining a predictive model and a contrastive learning module. This framework can reason about the interaction patterns from the tactile data, hallucinate the changes in the environment, esti-mate the uncertainty of the prediction, and generalize to unseen objects. We also provide detailed ablation studies regarding different system designs as well as visualizations of the predicted trajectories. This work takes a step on dynamics modeling in hand-object interactions from dense tactile sensing, which opens the door for future applications in activity learning, human-computer interactions, and imitation learning for robotics.",
        "primary_area": "",
        "author": "Qiang Zhang;Yunzhu Li;Yiyue Luo;Wan Shou;Michael Foshey;Junchi Yan;Joshua B. Tenenbaum;Wojciech Matusik;Antonio Torralba;Qiang Zhang;Yunzhu Li;Yiyue Luo;Wan Shou;Michael Foshey;Junchi Yan;Joshua B. Tenenbaum;Wojciech Matusik;Antonio Torralba",
        "authorids": "/37087230838;/37086933816;/37089013363;/37089015842;/37089013761;/37407421600;/37622583000;/37295070400;/38183107900;/37087230838;/37086933816;/37089013363;/37089015842;/37089013761;/37407421600;/37622583000;/37295070400;/38183107900",
        "aff": "Shanghai Jiao Tong University; Computer Science and Artificial Intelligence Laboratory (CSAIL) at Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory (CSAIL) at Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory (CSAIL) at Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory (CSAIL) at Massachusetts Institute of Technology; Shanghai Jiao Tong University; Computer Science and Artificial Intelligence Laboratory (CSAIL) at Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory (CSAIL) at Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory (CSAIL) at Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636361/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7605405954475548484&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;1;0;1;1;1",
        "aff_unique_norm": "Shanghai Jiao Tong University;Massachusetts Institute of Technology",
        "aff_unique_dep": ";Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.mit.edu",
        "aff_unique_abbr": "SJTU;MIT",
        "aff_campus_unique_index": "1;1;1;1;1;1;1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;1;1;1;1;0;1;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9636666",
        "title": "Dynamic Pre-Grasp Planning when Tracing a Moving Object Through a Multi-Agent Perspective",
        "track": "main",
        "status": "Poster",
        "abstract": "While a human is tracking a moving object to prepare for later grasping, we naturally change our hand pose to generate optimal pre-grasp to avoid post-grasp adjustment. Robot hand controllers need dynamic pre-grasp planning capability, so they are not limited in dynamic tracking and catching tasks. To fill this gap, we explore the feasibility of using a two-stage optimization method to enable dynamic pre-grasp planning of individual fingers while tracking a moving object to ensure a later successful grasp. The first stage adopts multi-agent pursuit to partition the search space on the object surface. The method allows each finger to consider its immediate surroundings in a local view instead of globally determining the best location for all fingers. The search space for each finger is dramatically reduced since sensible alternatives are the ones left after pruning. Each finger goal location acts independently yet coordinates with others to achieve the goal of covering the object. In the second stage, four different goal point movement strategies are presented to impact the finger goal location in their respective search space to demonstrate the ability to facilitate different needs of the task and requirements of the designer. Dynamic finger goal adaption is obtained by iteratively updating these two stages. The approach is consistent in different scenarios for the object.",
        "primary_area": "",
        "author": "Michael Bowman;Xiaoli Zhang;Michael Bowman;Xiaoli Zhang",
        "authorids": "/37086937096;/37085581881;/37086937096;/37085581881",
        "aff": "Department of Mechanical Engineering, Colorado School of Mines, Golden, CO, USA; Department of Mechanical Engineering, Colorado School of Mines, Golden, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636666/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2140777145488045091&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Colorado School of Mines",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mines.edu",
        "aff_unique_abbr": "CSM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Golden",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636744",
        "title": "Dynamic hand gesture recognition using a stretchable multi-layer capacitive array, proximity sensing, and a SVM classifier",
        "track": "main",
        "status": "Poster",
        "abstract": "Hand Gesture Recognition (HGR) has application in Human Machine Interfaces (HMIs), to control robots, games, and machines. Here we demonstrate a soft-matter multi-layer printed electronic circuit, that can be used to detect the human gesture without the need for physical contact, except for unlocking the system. The film is able to detect touch and proximity of the hand at various nodes, and thus is able to construct an image of the hand. This is performed through fabrication of a thin, stretchable, high resolution, and multilayer circuit, that embeds a mesh of capacitive sensors for human gesture detection, through proximity sensing. The film is fabricated by superposing 6 layers: 3 insulating polymer layers, two EGaIn liquid metal layers patterned in shape of a mesh, and one flexible printed circuit board (FPCB) layer. The fabrication technique absed on spray deposition of EGaIn liquid metal is fast, low-cost, and easy, and can be used for scalable fabrication of large area multi-node sensing surfaces, with application in Robotic e-skins, and general Human Machine Interfaces. The system is trained with five gestures, including dynamic gestures. We demonstrate classification of these gestures using a support vector machine (SVM) based algorithm.",
        "primary_area": "",
        "author": "Matteo Virone;Pedro Lopes;Rui Pedro Rocha;Anibal. T. de Almeida;Mahmoud Tavakoli;Matteo Virone;Pedro Lopes;Rui Pedro Rocha;Anibal. T. de Almeida;Mahmoud Tavakoli",
        "authorids": "/37089194047;/37070527900;/37408311600;/37276441900;/37642159700;/37089194047;/37070527900;/37408311600;/37276441900;/37642159700",
        "aff": "Soft and Printed Microelectronics Labratory (SPM-UC), Institute of Systems and Robotics of University of Coimbra, Portugal; Soft and Printed Microelectronics Labratory (SPM-UC), Institute of Systems and Robotics of University of Coimbra, Portugal; Soft and Printed Microelectronics Labratory (SPM-UC), Institute of Systems and Robotics of University of Coimbra, Portugal; Soft and Printed Microelectronics Labratory (SPM-UC), Institute of Systems and Robotics of University of Coimbra, Portugal; Soft and Printed Microelectronics Labratory (SPM-UC), Institute of Systems and Robotics of University of Coimbra, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636744/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5143779515777028799&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Coimbra",
        "aff_unique_dep": "Institute of Systems and Robotics",
        "aff_unique_url": "https://www.uc.pt",
        "aff_unique_abbr": "UC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "9636785",
        "title": "Dynamic modelling and visco-elastic parameter identification of a fibre-reinforced soft fluidic elastomer manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "A dynamic model of a soft fibre-reinforced fluidic elastomer is presented and experimentally verified, which can be used for model-based controller design. Due to the inherent visco-(hyper)elastic characteristics and nonlinear time-dependent behaviour of soft fluidic elastomer robots, analytic dynamic modelling is challenging. The fibre reinforced noninflatable soft fluidic elastomer robot used in this paper can produce both planar and spatial movements. Dynamic equations are developed for both cases. Parameters, related to the viscoelastic behaviour of the robot during elongation and bending motion, are identified experimentally and incorporated into our model. The modified dynamic model is then validated in experiments comparing the time responses of the physical robot with the corresponding outputs of the simulation model. The results validate the accuracy of the proposed dynamic model.",
        "primary_area": "",
        "author": "Azadeh Shariati;Jialei Shi;Sarah Spurgeon;Helge A Wurdemann;Azadeh Shariati;Jialei Shi;Sarah Spurgeon;Helge A Wurdemann",
        "authorids": "/37090019645;/37088996767;/37270909200;/37991827000;/37090019645;/37088996767;/37270909200;/37991827000",
        "aff": "Department of Mechanical Engineering, University College London, UK; Department of Mechanical Engineering, University College London, UK; Department of Electronic and Electrical Engineering, University College London, UK; Department of Mechanical Engineering, University College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636785/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4541236013742444714&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636823",
        "title": "Dynamic-based RCM Torque Controller for Robotic-Assisted Minimally Invasive Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we propose a novel flexible and optimization-free controller for standard torque-controlled manipulator for Robotic-Assisted Minimally Invasive Surgery. A novel method has been developed to model the constraint introduced by the laparoscopic tool, i.e. the remote center of motion, exploiting closed chain manipulators theory, and the final controller was synthesized considering the effects the constraint produces at a dynamic level. A set of simulations has been performed in a trajectory tracking task to validate the performances of the proposed controller. Performances have been also tested in a real experimental scenario with a KUKA LWR 4+ with 7 degrees of freedom endowed with a laparoscopic-like tool. Results show the effectiveness of the proposed controller and its capability of modifying the trajectory in order to preserve the RCM constraint.",
        "primary_area": "",
        "author": "Marco Minelli;Cristian Secchi;Marco Minelli;Cristian Secchi",
        "authorids": "/37086036138;/37300905500;/37086036138;/37300905500",
        "aff": "Department of Sciences and Methods of Engineering, University of Modena and Reggio Emilia, Italy; Department of Sciences and Methods of Engineering, University of Modena and Reggio Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636823/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17532210941439332240&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia",
        "aff_unique_dep": "Department of Sciences and Methods of Engineering",
        "aff_unique_url": "https://www.unimore.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636036",
        "title": "Dynamical effect of elastically supported wobbling mass on biped running",
        "track": "main",
        "status": "Poster",
        "abstract": "Our research team has been developing biped robots based on the nature of passive dynamics. We aim to both investigate the effect of wobbling mass and apply the findings to biped robots to achieve high-performance running. We used an elastically supported wobbling mass in the trunk of biped robots because humans utilize their elastic organs in the upper body and arms to improve running performance. To investigate the characteristics and mechanisms of passive dynamics of the wobbling mass focusing on the vertical ground reaction force, we used a simple model equipped with an elastically supported wobbling mass and analytically derived periodic solutions. The normal mode analysis of the obtained solutions explained the mechanism under which periodic solutions are achieved, and analytic solutions showed similar vertical locomotion to human running and suggested the mechanism under which high-performance locomotion is achieved from the viewpoint of the ground reaction force and energy efficiency. Based on these solutions, we conducted experiments using a prototype and a biped robot equipped with wobbling mass. Experimental results showed similar characteristics in the vertical movement to the simple model and human running. These findings will help improve our understanding of biped running and contribute to producing human-like running of biped robots.",
        "primary_area": "",
        "author": "Tomoya Kamimura;Koudai Sato;Daiki Murayama;Nanako Kawase;Akihito Sano;Tomoya Kamimura;Koudai Sato;Daiki Murayama;Nanako Kawase;Akihito Sano",
        "authorids": "/37086120932;/37089194380;/37089196464;/37089197630;/37276868500;/37086120932;/37089194380;/37089196464;/37089197630;/37276868500",
        "aff": "Department of Electrical and Mechanical Engineering, Nagoya Institute of Technology, Nagoya, Japan; Department of Electrical and Mechanical Engineering, Nagoya Institute of Technology, Nagoya, Japan; Department of Electrical and Mechanical Engineering, Nagoya Institute of Technology, Nagoya, Japan; Department of Electrical and Mechanical Engineering, Nagoya Institute of Technology, Nagoya, Japan; Department of Electrical and Mechanical Engineering, Nagoya Institute of Technology, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636036/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16696456549700383482&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Nagoya Institute of Technology",
        "aff_unique_dep": "Department of Electrical and Mechanical Engineering",
        "aff_unique_url": "https://www.nitech.ac.jp",
        "aff_unique_abbr": "NIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Nagoya",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636733",
        "title": "Dynamics Computation of a Hybrid Multi-link Humanoid Robot Integrating Rigid and Soft Bodies",
        "track": "main",
        "status": "Poster",
        "abstract": "This study presents dynamics computation and control of a hybrid multi-link system that integrates rigid- and soft-bodies. It is a challenging problem to install a softness in a robot system, which is an important factor in human body. Softness achieved by human muscles and ligaments contributes to dynamic motion. Flexibility of a sports prosthetic leg allows a handicapped person to run. However, traditional algorithms of dynamics computation for a robot system or human skeletal model only consider a rigid-body multi-link system. Recent progress in soft robotics such as piecewise constant strain (PCS) model provides the way to compute dynamics of soft deformation with a low computational cost. We construct a hybrid multi-link system integrating rigid-body and the PCS model. For controlling a humanoid robot with soft links, we implement a dynamics computation with a floating-base and derive the center-of-gravity Jacobian matrix of the hybrid link system. Moreover, we demonstrate a forward dynamics simulation of a humanoid robot with prosthetic legs.",
        "primary_area": "",
        "author": "Taiki Ishigaki;Ko Yamamoto;Taiki Ishigaki;Ko Yamamoto",
        "authorids": "/37089197618;/37536641800;/37089197618;/37536641800",
        "aff": "Department of Mechano-Informatics, Univ. of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Univ. of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636733/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5263464563457250827&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636327",
        "title": "EVReflex: Dense Time-to-Impact Prediction for Event-based Obstacle Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "The broad scope of obstacle avoidance has led to many kinds of computer vision-based approaches. Despite its popularity, it is not a solved problem. Traditional computer vision techniques using cameras and depth sensors often focus on static scenes, or rely on priors about the obstacles. Recent developments in bio-inspired sensors present event cameras as a compelling choice for dynamic scenes. Although these sensors have many advantages over their frame-based counterparts, such as high dynamic range and temporal resolution, event-based perception has largely remained in 2D. This often leads to solutions reliant on heuristics and specific to a particular task.We show that the fusion of events and depth overcomes the failure cases of each individual modality when performing obstacle avoidance. Our proposed approach unifies event camera and lidar streams to estimate metric Time-To-Impact (TTI) without prior knowledge of the scene geometry or obstacles. In addition, we release an extensive event-based dataset with six visual streams spanning over 700 scanned scenes.",
        "primary_area": "",
        "author": "Celyn Walters;Simon Hadfield;Celyn Walters;Simon Hadfield",
        "authorids": "/37087323095;/38232557500;/37087323095;/38232557500",
        "aff": "CVSSP, University of Surrey, UK; CVSSP, University of Surrey, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636327/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12983822299705436059&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Surrey",
        "aff_unique_dep": "Centre for Vision, Speech and Signal Processing",
        "aff_unique_url": "https://www.surrey.ac.uk",
        "aff_unique_abbr": "Surrey",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636179",
        "title": "Effect of Assembly Design on a Walking Multi-Arm Robotics for In-Space Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic In-space assembly (ISA) is the next step to building larger and more permanent structures in orbit. Robotic ISA offers a unique opportunity for engineers to design the robotic system and the structure at the same time. ISA structures can be optimized to minimize weight or the number of pieces but these decisions have large impacts on the complexity of the robotic system. This impact goes beyond just defining the length and number of joints for the robotic system; the assembly process itself will drive the robot design. Robot trajectories will result in the forces and torques being applied to individual truss pieces and to the whole assembly itself, which are driven by the assembly plan. This study focuses on some of the design concerns of a robotic ISA system; specifically focusing on a walking robotic as it assembles a linear truss.",
        "primary_area": "",
        "author": "Katherine McBryan;Katherine McBryan",
        "authorids": "/38529231600;/38529231600",
        "aff": "Katherine McBryan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636179/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10634983005408952912&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2
    },
    {
        "id": "9636452",
        "title": "Effect of Display Response Time on Brain Activity in Human\u2013Machine Interface Commander Operation",
        "track": "main",
        "status": "Poster",
        "abstract": "With the recent diversification of operating devices, the demand for input operations that require confirmation of the effect of differences in display response on operability has increased. Regarding display response, previous studies have investigated the threshold time and sense of agency for a delayed response during device operation. However, these studies only focused on subjective evaluations. Therefore, this study aims to clarify the human motor characteristics and activated brain regions based on the differences in display response time during device operation. The target motion is the rotational operation of the cylindrical rotary controller using the index finger and thumb. The experimental conditions involve four types of display response times (the duration from the operation to the indicated response). We measured the brain activity using near-infrared spectroscopy, the muscle activity from a surface myoelectric potential measurement device, and the force data of the index finger and thumb tip obtained from two independent six-axis force/torque sensors. Although the experimental results showed no significant difference in the muscle activity and gripping force, a significant difference was observed in the brain activity and the questionnaire survey by the difference in display response time. This investigation reveals that the difference in display response time affects brain activity and subjective information, clarifying the relationship between brain activity and subjective information.",
        "primary_area": "",
        "author": "Kentaro Oshima;Toru Tsumugiwa;Ryuichi Yokogawa;Mitsuhiro Narusue;Hiroto Nishimura;Yusaku Takeda;Toshihiro Hara;Kentaro Oshima;Toru Tsumugiwa;Ryuichi Yokogawa;Mitsuhiro Narusue;Hiroto Nishimura;Yusaku Takeda;Toshihiro Hara",
        "authorids": "/37089194353;/37294043300;/37294044400;/37086741273;/37088506603;/37088505186;/37086551886;/37089194353;/37294043300;/37294044400;/37086741273;/37088506603;/37088505186;/37086551886",
        "aff": "Graduate School of Life and Medical Sciences, Doshisha University, Kyoto, Japan; Department of Biomedical Engineering, Faculty of Life and Medical Sciences, Doshisha University, Kyoto, Japan; Department of Biomedical Engineering, Faculty of Life and Medical Sciences, Doshisha University, Kyoto, Japan; Technical Research Center, Mazda Motor Corporation, Hiroshima, Japan; Technical Research Center, Mazda Motor Corporation, Hiroshima, Japan; Technical Research Center, Mazda Motor Corporation, Hiroshima, Japan; Technical Research Center, Mazda Motor Corporation, Hiroshima, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636452/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9033142090748551197&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;1;1",
        "aff_unique_norm": "Doshisha University;Mazda Motor Corporation",
        "aff_unique_dep": "Graduate School of Life and Medical Sciences;Technical Research Center",
        "aff_unique_url": "https://www.doshisha.ac.jp;https://www.mazda.com",
        "aff_unique_abbr": "Doshisha;Mazda",
        "aff_campus_unique_index": "0;0;0;1;1;1;1",
        "aff_campus_unique": "Kyoto;Hiroshima",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636589",
        "title": "Effects of Conversational Contexts and Forms of Non-lexical Backchannel on User Perception of Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "A non-lexical backchannel is known to be dependent on the conversational context, and its form can be distinguished by the social relation between the speaker and the listener in the Korean language. Thus, to investigate the effect of a non-lexical backchannel, we conducted a 2 (context: information-centric versus emotion-centric) \u00d7 3 (forms of backchannel: \"ne\" versus \"eo\" versus \"eum\") mixed-participant experiment (N = 96). After watching video stimuli, the participants evaluated a robot using one of the three forms of non-lexical backchannels under both contexts. No significant main effect of the forms of the non-lexical backchannel was found. By contrast, we found that task attraction and appropriateness of the robot were rated more positively under the information-centric context than under the emotion-centric context. The functions of the non-lexical backchannel of attentive listening and understanding were manifested more under the information-centric context than under the emotion-centric context. Furthermore, these functions mediated the effect of conversational context on the user perception of the robot in terms of task attraction and appropriateness.",
        "primary_area": "",
        "author": "Sangmin Kim;Sukyung Seok;Jongsuk Choi;Yoonseob Lim;Sonya S. Kwak;Sangmin Kim;Sukyung Seok;Jongsuk Choi;Yoonseob Lim;Sonya S. Kwak",
        "authorids": "/37089195721;/37089196008;/37292544300;/37695437400;/37398989100;/37089195721;/37089196008;/37292544300;/37695437400;/37398989100",
        "aff": "Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; Department of Korean Language and Literature, Korea University, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea; Center for Intelligent and Interactive Robotics, Korea Institute of Science and Technology, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636589/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18104645573990919710&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Korea Institute of Science and Technology;Korea University",
        "aff_unique_dep": "Center for Intelligent and Interactive Robotics;Department of Korean Language and Literature",
        "aff_unique_url": "https://www.kist.re.kr;http://www.korea.ac.kr",
        "aff_unique_abbr": "KIST;KU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636603",
        "title": "Efficient Computation of Map-scale Continuous Mutual Information on Chip in Real Time",
        "track": "main",
        "status": "Poster",
        "abstract": "Exploration tasks are essential to many emerging robotics applications, ranging from search and rescue to space exploration. The planning problem for exploration requires determining the best locations for future measurements that will enhance the fidelity of the map, for example, by reducing its total entropy. A widely-studied technique involves computing the Mutual Information (MI) between the current map and future measurements, and utilizing this MI metric to decide the locations for future measurements. However, computing MI for reasonably-sized maps is slow and power hungry, which has been a bottleneck towards fast and efficient robotic exploration. In this paper, we introduce a new hardware accelerator architecture for MI computation that features a low-latency, energy-efficient MI compute core and an optimized memory subsystem that provides sufficient bandwidth to keep the cores fully utilized. The core employs interleaving to counter the recursive algorithm, and workload balancing and numerical approximations to reduce latency and energy consumption. We demonstrate this optimized architecture with a Field-Programmable Gate Array (FPGA) implementation, which can compute MI for all cells in an entire 201-by-201 occupancy grid (e.g., representing a 20.1m-by-20.1m map at 0.1m resolution) in 1.55 ms while consuming 1.7 mJ of energy, thus finally rendering MI computation for the whole map real time and at a fraction of the energy cost of traditional compute platforms. For comparison, this particular FPGA implementation running on the Xilinx Zynq-7000 platform is two orders of magnitude faster and consumes three orders of magnitude less energy per MI map compute, when compared to a baseline GPU implementation running on an NVIDIA GeForce GTX 980 platform. The improvements are more pronounced when compared to CPU implementations of equivalent algorithms.",
        "primary_area": "",
        "author": "Keshav Gupta;Peter Zhi Xuan Li;Sertac Karaman;Vivienne Sze;Keshav Gupta;Peter Zhi Xuan Li;Sertac Karaman;Vivienne Sze",
        "authorids": "/37089194911;/37089196151;/37304113000;/37394718900;/37089194911;/37089196151;/37304113000;/37394718900",
        "aff": "Massachusetts Institute of Technology, Cambridge, Massachusetts; Massachusetts Institute of Technology, Cambridge, Massachusetts; Massachusetts Institute of Technology, Cambridge, Massachusetts; Massachusetts Institute of Technology, Cambridge, Massachusetts",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636603/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4197190747149634177&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636028",
        "title": "Efficient LiDAR-based In-water Obstacle Detection and Segmentation by Autonomous Surface Vehicles in Aquatic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Identifying in-water obstacles is fundamental for safe navigation of Autonomous Surface Vehicles (ASVs). This paper presents a model-free method for segmenting individual in-water objects (e.g., swimmers, buoys, boats) and shorelines from LiDAR sensor data. To reduce the computational requirement, our method first converts the 3D point cloud into a 2D spherical projection image. Then, an algorithm based on the integration of a breadth-first search and a variant of a hierarchical agglomerative clustering segments the points according to different objects. Our method addresses the sparsity and instability of the point cloud in the aquatic domain \u2013 a characteristic that makes the methods developed for self-driving cars not directly applicable for in-water obstacle segmentation, as demonstrated in our experiments. Our method is compared with other state-of-the-art approaches and is validated both in simulation and in real-world ASV deployments, with different objects and encountering scenarios. The proposed method is effective in segmenting in-water obstacles not known a priori, in real-time, outperforming other state-of-the art methods.",
        "primary_area": "",
        "author": "Mingi Jeong;Alberto Quattrini Li;Mingi Jeong;Alberto Quattrini Li",
        "authorids": "/37087244961;/37085808885;/37087244961;/37085808885",
        "aff": "Department of Computer Science, Dartmouth College, Hanover, NH; Department of Computer Science, Dartmouth College, Hanover, NH",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636028/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4433616135770526939&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Dartmouth College",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://dartmouth.edu",
        "aff_unique_abbr": "Dartmouth",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hanover",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635972",
        "title": "Efficient Localisation Using Images and OpenStreetMaps",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to localise is key for robot navigation. We describe an efficient method for vision-based localisation, which combines sequential Monte Carlo tracking with matching ground-level images to 2-D cartographic maps such as OpenStreetMaps. The matching is based on a learned embedded space representation linking images and map tiles, encoding the common semantic information present in both and providing potential for invariance to changing conditions. Moreover, the compactness of 2-D maps supports scalability. This contrasts with the majority of previous approaches based on matching with single-shot geo-referenced images or 3-D reconstructions. We present experiments using the StreetLearn and Oxford RobotCar datasets and demonstrate that the method is highly effective, giving high accuracy and fast convergence.",
        "primary_area": "",
        "author": "Mengjie Zhou;Xieyuanli Chen;Noe Samano;Cyrill Stachniss;Andrew Calway;Mengjie Zhou;Xieyuanli Chen;Noe Samano;Cyrill Stachniss;Andrew Calway",
        "authorids": "/37089000993;/37086247697;/37088997215;/37329668600;/37326243500;/37089000993;/37086247697;/37088997215;/37329668600;/37326243500",
        "aff": "University of Bristol, UK; University of Bonn, Germany; University of Bristol, UK; University of Bonn, Germany; University of Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635972/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15358763326204449015&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "University of Bristol;University of Bonn",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.bristol.ac.uk;https://www.uni-bonn.de",
        "aff_unique_abbr": "Bristol;UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "id": "9636323",
        "title": "Efficient Manoeuvring of Quadrotor under Constrained Space and Predefined Accuracy",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent times, quadrotors have become immensely applicable in scenarios such as relief operations, infrastructure maintenance, search-and-rescue missions etc. A key control design challenge arises in these applications when the quadrotor has to manoeuvre through constrained spaces such as narrow windows, pipelines in the presence of external disturbances and parametric uncertainties: such conditions necessitate the controller to guarantee predefined tracking accuracy so as to not violate the constraints and simultaneously tackle uncertainties. However, state-of-the-art controllers dealing with constrained system motion are not applicable either for an underactuated system like quadrotor or for an uncertain system dynamics. This work proposes a robust controller that enables the quadrotor to follow a trajectory with predefined tracking accuracy in constrained space as well as to tackle uncertainties stemming from imprecise system modelling and external disturbances. The closed-loop system stability is analysed via the Barrier Lyapunov approach and the effectiveness of the proposed controller is validated via simulation with state of the art.",
        "primary_area": "",
        "author": "Sourish Ganguly;Viswa N. Sankaranarayanan;B. V. S. G. Suraj;Rishabh Dev Yadav;Spandan Roy;Sourish Ganguly;Viswa N. Sankaranarayanan;B. V. S. G. Suraj;Rishabh Dev Yadav;Spandan Roy",
        "authorids": "/37087093268;/37088685917;/37089198260;/37089197600;/37085547823;/37087093268;/37088685917;/37089198260;/37089197600;/37085547823",
        "aff": "Robotics Research Center, International Institute of Information Technology Hyderabad (IIIT-H), Hyderabad, India; Robotics Research Center, International Institute of Information Technology Hyderabad (IIIT-H), Hyderabad, India; Robotics Research Center, International Institute of Information Technology Hyderabad (IIIT-H), Hyderabad, India; Robotics Research Center, International Institute of Information Technology Hyderabad (IIIT-H), Hyderabad, India; Robotics Research Center, International Institute of Information Technology Hyderabad (IIIT-H), Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636323/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18102633564343228004&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "International Institute of Information Technology Hyderabad",
        "aff_unique_dep": "Robotics Research Center",
        "aff_unique_url": "https://iiit Hyderabad.ac.in",
        "aff_unique_abbr": "IIIT-H",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hyderabad",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9636040",
        "title": "Efficient Multimodal Belief Propagation for Robust SLAM Using Clustering Based Reparameterization",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the presence of ambiguities caused by sensor noise and structural similarity, simultaneous localization and mapping (SLAM) observation models are typically multimodal. The multimodal inference process can be directly dealt with by belief propagation (BP) using weighted Gaussian mixture messages, but for efficiency, a combinatorial explosion of the complexity must be suitably relaxed. In this study, we present an effective multimodal BP SLAM for robust inference with ambiguities. Using Gaussian bandwidth mean shift and cluster-based reparameterization, we reduce the number of Gaussian components in each message due to the BP nature. The proposed algorithm reduces the number of components of the product by summarizing indistinguishable modes in weighted Gaussian mixtures and keeping only the significant modes, making BP computationally efficient.",
        "primary_area": "",
        "author": "Seungwon Choi;Tae-Wan Kim;Seungwon Choi;Tae-Wan Kim",
        "authorids": "/37085590711;/37085717917;/37085590711;/37085717917",
        "aff": "Department of Naval Architecture and Ocean Engineering, Seoul National University, Seoul, Republic of Korea; Department of Naval Architecture and Ocean Engineering, Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636040/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:1Vzz6ZQ1Bu8J:scholar.google.com/&scioq=Efficient+Multimodal+Belief+Propagation+for+Robust+SLAM+Using+Clustering+Based+Reparameterization&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Naval Architecture and Ocean Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636727",
        "title": "Efficient Picking by Considering Simultaneous Two-Object Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a motion planning algorithm that enables robots to efficiently pick up objects by considering simultaneous multi-object grasping. At the center of the algorithm is a cost function that helps to determine one of the following three grasping policies considering distance and friction constraints \u2013 Grasping a single object; Grasping two objects simultaneously; Grasping two object simultaneously after pushing one of the objects close to the other. After recognizing the object distributions on a table by using a depth camera and Mask R-CNN, our algorithm will select grasp policies from the three candidates considering the cost function, and plan a policy sequence that can most quickly finish picking all the objects using dynamic programming. Both simulation and real-world experiments are carried out to examine the performance of the proposed planner. Results show that the proposed method significantly improves the efficiency of robotic picking compared to conventional single-object-based methods.",
        "primary_area": "",
        "author": "Takumi Sakamoto;Weiwei Wan;Takao Nishi;Kensuke Harada;Takumi Sakamoto;Weiwei Wan;Takao Nishi;Kensuke Harada",
        "authorids": "/37089194668;/37085689483;/37275663600;/37277067400;/37089194668;/37085689483;/37275663600;/37277067400",
        "aff": "Graduate School of Engineering Science, Osaka University, Toyonaka, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Japan; Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636727/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17753673609655944225&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Osaka University;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Graduate School of Engineering Science;Artificial Intelligence Research Center",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "Osaka U;AIST",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Toyonaka;Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636554",
        "title": "Efficient Task Planning for Mobile Manipulation: a Virtual Kinematic Chain Perspective",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a Virtual Kinematic Chain (VKC) perspective, a simple yet effective method, to improve task planning efficacy for mobile manipulation. By consolidating the kinematics of the mobile base, the arm, and the object being manipulated collectively as a whole, this novel VKC perspective naturally defines abstract actions and eliminates unnecessary predicates in describing intermediate poses. As a result, these advantages simplify the design of the planning domain and significantly reduce the search space and branching factors in solving planning problems. In experiments, we implement a task planner using Planning Domain Definition Language (PDDL) with VKC. Compared with conventional domain definition, our VKC-based domain definition is more efficient in both planning time and memory. In addition, abstract actions perform better in producing feasible motion plans and trajectories. We further scale up the VKC-based task planner in complex mobile manipulation tasks. Taken together, these results demonstrate that task planning using VKC for mobile manipulation is not only natural and effective but also introduces new capabilities.",
        "primary_area": "",
        "author": "Ziyuan Jiao;Zeyu Zhang;Weiqi Wang;David Han;Song-Chun Zhu;Yixin Zhu;Hangxin Liu;Ziyuan Jiao;Zeyu Zhang;Weiqi Wang;David Han;Song-Chun Zhu;Yixin Zhu;Hangxin Liu",
        "authorids": "/37085784268;/37086938580;/37089196788;/37588964400;/37281407500;/37086172463;/37086274715;/37085784268;/37086938580;/37089196788;/37588964400;/37281407500;/37086172463;/37086274715",
        "aff": "Learning, and Autonomy (VCLA) at Statistics Department, UCLA Center for Vision, Cognition; Learning, and Autonomy (VCLA) at Statistics Department, UCLA Center for Vision, Cognition; Learning, and Autonomy (VCLA) at Statistics Department, UCLA Center for Vision, Cognition; Department of Electrical and Computer Engineering, Drexel University; Learning, and Autonomy (VCLA) at Statistics Department, UCLA Center for Vision, Cognition; Learning, and Autonomy (VCLA) at Statistics Department, UCLA Center for Vision, Cognition; Learning, and Autonomy (VCLA) at Statistics Department, UCLA Center for Vision, Cognition",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636554/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3431426098716750787&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles;Drexel University",
        "aff_unique_dep": "Statistics Department;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucla.edu;https://www.drexel.edu",
        "aff_unique_abbr": "UCLA;Drexel",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636215",
        "title": "Efficient and Accurate Candidate Generation for Grasp Pose Detection in SE(3)",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasp detection of novel objects in unstructured environments is a key capability in robotic manipulation. For 2D grasp detection problems where grasps are assumed to lie in the plane, it is common to design a fully convolutional neural network that predicts grasps over an entire image in one step. However, this is not possible for grasp pose detection where grasp poses are assumed to exist in SE(3). In this case, it is common to approach the problem in two steps: grasp candidate generation and candidate classification [1], [2], [3], [4]. Since grasp candidate classification is typically expensive, the problem becomes one of efficiently identifying high quality candidate grasps. This paper proposes a new grasp candidate generation method that significantly outperforms major 3D grasp detection baselines. Supplementary material is available at this website.",
        "primary_area": "",
        "author": "Andreas ten Pas;Colin Keil;Robert Platt;Andreas ten Pas;Colin Keil;Robert Platt",
        "authorids": "/37085488239;/37088688648;/37273991200;/37085488239;/37088688648;/37273991200",
        "aff": "Khoury College of Computer Sciences, Northeastern University, Boston, MA, USA; Khoury College of Computer Sciences, Northeastern University, Boston, MA, USA; Khoury College of Computer Sciences, Northeastern University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636215/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9732697184551120195&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Khoury College of Computer Sciences",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636263",
        "title": "Efficient and Reactive Planning for High Speed Robot Air Hockey",
        "track": "main",
        "status": "Poster",
        "abstract": "Highly dynamic robotic tasks require high-speed and reactive robots. These tasks are particularly challenging due to the physical constraints, hardware limitations, and the high uncertainty of dynamics and sensor measures. To face these issues, it\u2019s crucial to design robotics agents that generate precise and fast trajectories and react immediately to environmental changes. Air hockey is an example of this kind of task. Due to the environment\u2019s characteristics, it is possible to formalize the problem and derive clean mathematical solutions. For these reasons, this environment is perfect for pushing to the limit the performance of currently available general-purpose robotic manipulators. Using two Kuka Iiwa 14, we show how to design a policy for general-purpose robotic manipulators for the air hockey game. We demonstrate that a real robot arm can perform fast-hitting movements and that the two robots can play against each other on a medium-size air hockey table in simulation.",
        "primary_area": "",
        "author": "Puze Liu;Davide Tateo;Haitham Bou-Ammar;Jan Peters;Puze Liu;Davide Tateo;Haitham Bou-Ammar;Jan Peters",
        "authorids": "/37089195561;/37086271891;/38272128400;/37533077600;/37089195561;/37086271891;/38272128400;/37533077600",
        "aff": "Department of Computer Science, Technische Universit\u00e4t Darmstadt, Germany; Department of Computer Science, Technische Universit\u00e4t Darmstadt, Germany; University College London (UCL), Honorary Position; Department of Computer Science, Technische Universit\u00e4t Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636263/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4887497857458954200&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt;University College London",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://www.ucl.ac.uk",
        "aff_unique_abbr": "TUD;UCL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "9636337",
        "title": "Embedded Hardware Appropriate Fast 3D Trajectory Optimization for Fixed Wing Aerial Vehicles by Leveraging Hidden Convex Structures",
        "track": "main",
        "status": "Poster",
        "abstract": "Most commercially available fixed-wing aerial vehicles (FWV) can carry only small, lightweight computing hardware such as Jetson TX2 onboard. Solving non-linear trajectory optimization on these computing resources is computationally challenging even while considering only the kinematic motion model. Most importantly, the computation time increases sharply as the environment becomes more cluttered. In this paper, we take a step towards overcoming this bottleneck and propose a trajectory optimizer that achieves online performance on both conventional laptops/desktops and Jetson TX2 in a typical urban environment setting. Our optimizer builds on the novel insight that the seemingly non-linear trajectory optimization problem for FWV has an implicit multi-convex structure. Our optimizer exploits these computational structures by bringing together diverse concepts from Alternating Minimization, Bregman iteration, and Alternating Direction Method of Multipliers. We show that our optimizer outperforms the state-of-the-art implementation of sequential quadratic programming approach in optimal control solver ACADO in computation time and solution quality measured in terms of control and goal reaching cost.",
        "primary_area": "",
        "author": "Vivek Kantilal Adajania;Houman Masnavi;Fatemeh Rastgar;Karl Kruusamae;Arun Kumar Singh;Vivek Kantilal Adajania;Houman Masnavi;Fatemeh Rastgar;Karl Kruusamae;Arun Kumar Singh",
        "authorids": "/37088415563;/37088687300;/37086436834;/37085528953;/38237873200;/37088415563;/37088687300;/37086436834;/37085528953;/38237873200",
        "aff": "Institute of Technology, University of Tartu; Institute of Technology, University of Tartu; Institute of Technology, University of Tartu; Institute of Technology, University of Tartu; Institute of Technology, University of Tartu",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636337/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4732900988338403525&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Tartu",
        "aff_unique_dep": "Institute of Technology",
        "aff_unique_url": "https://www.ut.ee",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Estonia"
    },
    {
        "id": "9635962",
        "title": "Embedded Stochastic Field Exploration with Micro Diving Agents using Bayesian Optimization-Guided Tree-Search and GMRFs",
        "track": "main",
        "status": "Poster",
        "abstract": "Exploration and monitoring of hazardous fields in marine environments is one of the most promising tasks to be performed by fleets of low-cost micro autonomous underwater vehicles (\u03bcAUVs). In contrast to vehicles in other domains, underwater robots are forced to perform all computations onboard as no powerful communication links are available underwater. This puts the focus on computationally efficient field exploration algorithms. We propose CBTS-GMRF \u2013 an extremely light-weight tree-search exploration framework suitable for embedded computing. With our framework we build on recent work in POMDP-exploration and field belief representations based on efficient Gaussian Markov random fields (GMRF). We propose a reward function for energy-efficient field exploration together with a sparse trajectory parameterization. By reducing both, energy consumption and computational complexity, we enable underwater field exploration with \u03bcAUVs. We benchmark the performance of our exploration framework in simulation against state-of-the-art exploratory planning schemes and provide an experimental study using a low-cost micro diving agent. In order to support community-wide algorithm benchmarking, our code and robot design can be accessed online.",
        "primary_area": "",
        "author": "Daniel A Duecker;Benedikt Mersch;Rene C Hochdahl;Edwin Kreuzer;Daniel A Duecker;Benedikt Mersch;Rene C Hochdahl;Edwin Kreuzer",
        "authorids": "/37086262227;/37088917207;/37089197213;/37622316900;/37086262227;/37088917207;/37089197213;/37622316900",
        "aff": "Hamburg University of Technology, Germany; University of Bonn, Germany; Hamburg University of Technology, Germany; Hamburg University of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635962/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17474438708381840940&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Hamburg University of Technology;University of Bonn",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tuhh.de/;https://www.uni-bonn.de",
        "aff_unique_abbr": "TUHH;UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636605",
        "title": "Embedding a Nonlinear Strict Oscillatory Mode into a Segmented Leg",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic legs often lag behind the performance of their biological counterparts. The inherent passive dynamics of natural legs largely influences the locomotion and can be abstracted through the spring-loaded inverted pendulum (SLIP) model. This model is often approximated in physical robotic legs using a leg with minimal mass. Our work aims to embed the SLIP dynamics by using a nonlinear strict oscillatory mode into a segmented robotic leg with significant mass, to minimize the control required for achieving periodic motions. For the first time, we provide a realization of a nonlinear oscillatory mode in a robotic leg prototype. This is achieved by decoupling the polar task dynamics and fulfilling the resulting conditions with the physical leg design. Extensive experiments validate that the robotic leg effectively embodies the strict mode. The decoupled leg-length dynamic is exhibited in leg configurations corresponding to the stance and flight phases of the locomotion task, both for the passive system and when actuating the motors. We additionally show that the leg retains this behavior while performing jumping in place experiments.",
        "primary_area": "",
        "author": "Anna Sesselmann;Florian Loeffl;Cosimo Della Santina;Maximo A. Roa;Alin Albu-Sch\u00e4ffer;Anna Sesselmann;Florian Loeffl;Cosimo Della Santina;Maximo A. Roa;Alin Albu-Sch\u00e4ffer",
        "authorids": "/37088806799;/37086099528;/37085627033;/37628512100;/38270361100;/37088806799;/37086099528;/37085627033;/37628512100;/38270361100",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Cognitive Robotics Department, Delft University of Technology, Delft, The Netherlands; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Department of Informatics, Chair of Sensor Based Robotic Systems and Intelligent Assistance Systems, Technical University of Munich (TUM), M\u00fcnchen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636605/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17298743500503854110&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "German Aerospace Center;Delft University of Technology;Technical University of Munich",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;Cognitive Robotics Department;Department of Informatics",
        "aff_unique_url": "https://www.dlr.de;https://www.tudelft.nl;https://www.tum.de",
        "aff_unique_abbr": "DLR;TUDelft;TUM",
        "aff_campus_unique_index": "0;0;1;0;2",
        "aff_campus_unique": "Wessling;Delft;M\u00fcnchen",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Germany;Netherlands"
    },
    {
        "id": "9636127",
        "title": "Encirclement Guaranteed Cooperative Pursuit with Robust Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies a novel encirclement guaranteed cooperative pursuit problem involving N pursuers and a single evader in an unbounded two-dimensional game domain. Throughout the game, the pursuers are required to maintain encirclement of the evader, i.e., the evader should always stay inside the convex hull generated by all the pursuers, in addition to achieving the classical capture condition. To tackle this challenging cooperative pursuit problem, a robust model predictive control (RMPC) based formulation framework is first introduced, which simultaneously accounts for the encirclement and capture requirements under the assumption that the evader\u2019s action is unavailable to all pursuers. Despite the reformulation, the resulting RMPC problem involves a bilinear constraint due to the encirclement requirement. To further handle such a bilinear constraint, a novel encirclement guaranteed partitioning scheme is devised that simplifies the original bilinear RMPC problem to a number of linear tube MPC (TMPC) problems solvable in a decentralized manner. Simulation experiments demonstrate the effectiveness of the proposed solution framework. Furthermore, comparisons with existing approaches show that the explicit consideration of the encirclement condition significantly improves the chance of successful capture of the evader in various scenarios.",
        "primary_area": "",
        "author": "Chen Wang;Hua Chen;Jia Pan;Wei Zhang;Chen Wang;Hua Chen;Jia Pan;Wei Zhang",
        "authorids": "/37089197329;/37086195529;/37535628800;/37089656248;/37089197329;/37086195529;/37535628800;/37089656248",
        "aff": "Department of Computer Science, The University of Hong Kong; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Computer Science, The University of Hong Kong; Peng Cheng Laboratory, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636127/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3253574687533299242&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "University of Hong Kong;Southern University of Science and Technology;Pengcheng Laboratory",
        "aff_unique_dep": "Department of Computer Science;Department of Mechanical and Energy Engineering;Peng Cheng Laboratory",
        "aff_unique_url": "https://www.hku.hk;https://www.sustech.edu.cn;",
        "aff_unique_abbr": "HKU;SUSTech;",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635877",
        "title": "Energy-Efficient Mobile Robot Control via Run-time Monitoring of Environmental Complexity and Computing Workload",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an energy-efficient controller to minimize the energy consumption of a mobile robot by dynamically manipulating the mechanical and computational actuators of the robot. The mobile robot performs real-time vision-based applications based on an event-based camera. The actuators of the controller are CPU voltage/frequency for the computation part and motor voltage for the mechanical part. We show that independently considering speed control of the robot and voltage/frequency control of the CPU does not necessarily result in an energy-efficient solution. In fact, to obtain the highest efficiency, the computation and mechanical parts should be controlled together in synergy. We propose a fast hill-climbing optimization algorithm to allow the controller to find the best CPU/motor configuration at run-time and whenever the mobile robot is facing a new environment during its travel. Experimental results on a robot with Brushless DC Motors, Jetson TX2 board as the computing unit, and a DAVIS-346 event-based camera show that the proposed control algorithm can save battery energy by an average of 50.5%, 41%, and 30%, in low-complexity, medium-complexity, and high-complexity environments, over baselines.",
        "primary_area": "",
        "author": "Sherif A.S. Mohamed;Mohammad-Hashem Haghbayan;Antonio Miele;Onur Mutlu;Juha Plosila;Sherif A.S. Mohamed;Mohammad-Hashem Haghbayan;Antonio Miele;Onur Mutlu;Juha Plosila",
        "authorids": "/37086809484;/37846916800;/37273951700;/37265510200;/37282178600;/37086809484;/37846916800;/37273951700;/37265510200;/37282178600",
        "aff": "Autonomous Systems Laboratory (ASL), University of Turku, Turku, Finland; ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Laboratory (ASL), University of Turku, Turku, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635877/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16604640405383812893&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "University of Turku;ETH Zurich;Politecnico di Milano",
        "aff_unique_dep": "Autonomous Systems Laboratory (ASL);;Dipartimento di Elettronica, Informazione e Bioingegneria",
        "aff_unique_url": "https://www.utu.fi;https://www.ethz.ch;https://www.polimi.it",
        "aff_unique_abbr": ";ETHZ;Politecnico di Milano",
        "aff_campus_unique_index": "0;1;2;1;0",
        "aff_campus_unique": "Turku;Z\u00fcrich;Milano",
        "aff_country_unique_index": "0;1;2;1;0",
        "aff_country_unique": "Finland;Switzerland;Italy"
    },
    {
        "id": "9636784",
        "title": "Enumeration of Polyominoes & Polycubes Composed of Magnetic Cubes",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper examines a family of designs for magnetic cubes and counts how many configurations are possible for each design as a function of the number of modules. Magnetic modular cubes are cubes with magnets arranged on their faces. The magnets are positioned so that each face has either magnetic south or north pole outward. Moreover, we require that the net magnetic moment of the cube passes through the center of opposing faces. These magnetic arrangements enable coupling when cube faces with opposite polarity are brought in close proximity and enable moving the cubes by controlling the orientation of a global magnetic field. This paper investigates the 2D and 3D shapes that can be constructed by magnetic modular cubes, and describes all possible magnet arrangements that obey these rules. We select ten magnetic arrangements and assign a \"color\" to each of them for ease of visualization and reference. We provide a method to enumerate the number of unique polyominoes and polycubes that can be constructed from a given set of colored cubes. We use this method to enumerate all arrangements for up to 20 modules in 2D and 16 modules in 3D. We provide a motion planner for 2D assembly and through simulations compare which arrangements require fewer movements to generate and which arrangements are more common. Hardware demonstrations explore the self-assembly and disassembly of these modules in 2D and 3D.",
        "primary_area": "",
        "author": "Yitong Lu;Anuruddha Bhattacharjee;Daniel Biediger;MinJun Kim;Aaron T. Becker;Yitong Lu;Anuruddha Bhattacharjee;Daniel Biediger;MinJun Kim;Aaron T. Becker",
        "authorids": "/37088686719;/37086937600;/37086325072;/37536816100;/37588897100;/37088686719;/37086937600;/37086325072;/37536816100;/37588897100",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636784/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6742305758800008145&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10
    },
    {
        "id": "9636416",
        "title": "Environmentally Adaptive Control Including Variance Minimization Using Stochastic Predictive Network with Parametric Bias: Application to Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we propose a predictive model composed of a recurrent neural network including parametric bias and stochastic elements, and an environmentally adaptive robot control method including variance minimization using the model. Robots which have flexible bodies or whose states can only be partially observed are difficult to modelize, and their predictive models often have stochastic behaviors. In addition, the physical state of the robot and the surrounding environment change sequentially, and so the predictive model can change online. Therefore, in this study, we construct a learning-based stochastic predictive model implemented in a neural network embedded with such information from the experience of the robot, and develop a control method for the robot to avoid unstable motion with large variance while adapting to the current environment. This method is verified through a mobile robot in simulation and to the actual robot Fetch.",
        "primary_area": "",
        "author": "Kento Kawaharazuka;Koki Shinjo;Yoichiro Kawamura;Kei Okada;Masayuki Inaba;Kento Kawaharazuka;Koki Shinjo;Yoichiro Kawamura;Kei Okada;Masayuki Inaba",
        "authorids": "/37086101930;/37087324644;/37088170182;/37280639000;/37286658200;/37086101930;/37087324644;/37088170182;/37280639000;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636416/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2706105006196264226&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechano-Informatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636673",
        "title": "Error Diagnosis of Deep Monocular Depth Estimation Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating depth from a monocular image is an ill-posed problem: when the camera projects a 3D scene onto a 2D plane, depth information is inherently and permanently lost. Nevertheless, recent work has shown impressive results in estimating 3D structure from 2D images using deep learning. In this paper, we put on an introspective hat and analyze state-of-the-art monocular depth estimation models in indoor scenes to understand these models\u2019 limitations and error patterns. To address errors in depth estimation, we introduce a novel Depth Error Detection Network (DEDN) that spatially identifies erroneous depth predictions in the monocular depth estimation models. By experimenting with multiple state-of-the-art monocular indoor depth estimation models on multiple datasets, we show that our proposed depth error detection network can identify a significant number of errors in the predicted depth maps. Our module is flexible and can be readily plugged into any monocular depth prediction network to help diagnose its results. Additionally, we propose a simple yet effective Depth Error Correction Network (DECN) that iteratively corrects errors based on our initial error diagnosis.",
        "primary_area": "",
        "author": "Jagpreet Chawla;Nikhil Thakurdesai;Anuj Godase;Md Reza;David Crandall;Soon-Heung Jung;Jagpreet Chawla;Nikhil Thakurdesai;Anuj Godase;Md Reza;David Crandall;Soon-Heung Jung",
        "authorids": "/37089198077;/37089195305;/37089196267;/37086063470;/37282605100;/37291205100;/37089198077;/37089195305;/37089196267;/37086063470;/37282605100;/37291205100",
        "aff": "Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; Electronics and Telecommunications Research Institute, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636673/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=225106222348460963&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Indiana University;Electronics and Telecommunications Research Institute",
        "aff_unique_dep": "Luddy School of Informatics, Computing, and Engineering;",
        "aff_unique_url": "https://www.indiana.edu;http://www.etri.re.kr",
        "aff_unique_abbr": "IU;ETRI",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Bloomington;Daejeon",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "9636514",
        "title": "Estimating the Center of Mass of Human-Exoskeleton Systems with Physically Coupled Serial Chain",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating the center of mass (CoM) is essential for both gait planning and controlling of lower limb exoskeletons. Different from CoM estimation in human and humanoid robots, a critical issue in human-exoskeleton systems pis how to describe the effect of physical human-exoskeleton interactions in estimating the CoM of lower limb exoskeletons. This paper presents a novel center of mass estimation method Physically Coupled Serial Chain (PCSC) for human-coupled lower limb exoskeleton systems. Different from traditional serial chain methods, the proposed PCSC involves physical human-exoskeleton models to describe physical interactions between the pilot and the lower limb exoskeleton. We demonstrated the effectiveness of proposed PCSC model in the AIDER lower limb exoskeleton system. Experimental results indicate that the proposed PCSC model is more accuracy than traditional serial chain methods.",
        "primary_area": "",
        "author": "Rui Huang;Zhinan Peng;Siying Guo;Kecheng Shi;Chaobin Zou;Jing Qiu;Hong Cheng;Rui Huang;Zhinan Peng;Siying Guo;Kecheng Shi;Chaobin Zou;Jing Qiu;Hong Cheng",
        "authorids": "/37085625169;/37086471879;/37089194601;/37085491942;/37086267498;/37086356733;/37280209600;/37085625169;/37086471879;/37089194601;/37085491942;/37086267498;/37086356733;/37280209600",
        "aff": "Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Mechanical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636514/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13811959269349577377&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Electronic Science and Technology of China",
        "aff_unique_dep": "School of Automation Engineering",
        "aff_unique_url": "https://www.uestc.edu.cn",
        "aff_unique_abbr": "UESTC",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Chengdu",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636527",
        "title": "Estimating the Shape of Soft Pneumatic Actuators using Active Vibroacoustic Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robotic devices, including actuators fabricated from materials with a low modulus of elasticity, such as silicone elastomers, have gained significant interest in recent years. A flexible sensor is a vital component for estimating the conditions of soft actuators, such as shape, and deformation due to contact events. However, it is challenging to develop a flexible sensor with tolerability and versatility for soft actuators. Additionally, when an embedded sensor is employed, the fabrication process becomes complex. Therefore, to have tolerability and to increase versatility, we propose a method for estimating the shape of a soft pneumatic actuator based on vibroacoustic sensing. We employ a data-driven approach by utilizing several machine-learning techniques; hence, the proposed method could be applied to other types of actuators without employing any specific sensor or changing the fabrication process. The convolutional neural network is used as one of the dominant techniques, and huge annotated datasets are required. However, datasets can be obtained automatically using a robotic system, and estimation targets can be changed smoothly by switching datasets. We confirmed the feasibility, and versatility of the proposed method through several evaluation experiments. The bending angle can be estimated in real-time using active vibroacoustic, by emitting sweep signals. The mean error of bending angle estimation was between 5\u00b0 to 10\u00b0. Furthermore, the proposed method is applied to a tensile actuator, and the mean error of the estimated length was approximately 0.21 mm.",
        "primary_area": "",
        "author": "Kazumi Randika;Kentaro Takemura;Kazumi Randika;Kentaro Takemura",
        "authorids": "/37089195566;/37280523600;/37089195566;/37280523600",
        "aff": "Graduate School of Engineering, Course of Electrical and Electronic Engineering, Tokai University, Kanagawa, Japan; Department of Applied Computer Engineering, School of Information Science and Technology, Tokai University, Kanagawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636527/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2558429099146766375&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tokai University",
        "aff_unique_dep": "Graduate School of Engineering, Course of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.tokai-u.ac.jp",
        "aff_unique_abbr": "Tokai U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kanagawa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636271",
        "title": "Evaluating the Impact of Semantic Segmentation and Pose Estimation on Dense Semantic SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent Semantic SLAM methods combine classical geometry-based estimation with deep learning-based object detection or semantic segmentation. In this paper we evaluate the quality of semantic maps generated by state-of-the-art class-and instance-aware dense semantic SLAM algorithms whose codes are publicly available and explore the impacts both semantic segmentation and pose estimation have on the quality of semantic maps. We obtain these results by providing algorithms with ground-truth pose and/or semantic segmentation data available from simulated environments. We establish that semantic segmentation is the largest source of error through our experiments, dropping mAP and OMQ performance by up to 74.3% and 71.3% respectively.",
        "primary_area": "",
        "author": "Suman Raj Bista;David Hall;Ben Talbot;Haoyang Zhang;Feras Dayoub;Niko S\u00fcnderhauf;Suman Raj Bista;David Hall;Ben Talbot;Haoyang Zhang;Feras Dayoub;Niko S\u00fcnderhauf",
        "authorids": "/37085713281;/37085436532;/37085398028;/37089197122;/37866588000;/37563890800;/37085713281;/37085436532;/37085398028;/37089197122;/37866588000;/37563890800",
        "aff": "Queensland University of Technology (QUT); Queensland University of Technology (QUT); Queensland University of Technology (QUT); Queensland University of Technology (QUT); Queensland University of Technology (QUT); Queensland University of Technology (QUT)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636271/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12658806179119950842&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Queensland University of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.qut.edu.au",
        "aff_unique_abbr": "QUT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9636320",
        "title": "Evaluation of Long-term LiDAR Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "We compare a state-of-the-art deep image retrieval and a deep place recognition method for place recognition using LiDAR data. Place recognition aims to detect previously visited locations and thus provides an important tool for navigation, mapping, and localisation. Experimental comparisons are conducted using challenging outdoor and indoor datasets, Oxford Radar RobotCar and COLD, in the \"long-term\" setting where the test conditions differ substantially from the training and gallery data. Based on our results the image retrieval methods using LiDAR depth images can achieve accurate localization (the single best match recall 80%) within 5.00 m in urban outdoors. In office indoors the comparable accuracy is 50 cm but is more sensitive to changes in the environment.",
        "primary_area": "",
        "author": "Jukka Peltom\u00e4ki;Farid Alijani;Jussi Puura;Heikki Huttunen;Esa Rahtu;Joni-Kristian K\u00e4m\u00e4r\u00e4inen;Jukka Peltom\u00e4ki;Farid Alijani;Jussi Puura;Heikki Huttunen;Esa Rahtu;Joni-Kristian K\u00e4m\u00e4r\u00e4inen",
        "authorids": "/37086592109;/37089194186;/37086594086;/38503116300;/37269930000;/37268498700;/37086592109;/37089194186;/37086594086;/38503116300;/37269930000;/37268498700",
        "aff": "Tampere University, Finland; Tampere University, Finland; Sandvik Mining and Construction Ltd; Tampere University, Finland; Tampere University, Finland; Tampere University, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636320/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=29548632420496986&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Tampere University;Sandvik Mining and Construction",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tuni.fi;https://www.sandvik.com/mining-and-construction/",
        "aff_unique_abbr": "Tuni;SMC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "Finland;Sweden"
    },
    {
        "id": "9636063",
        "title": "Evaluation of Lumbar Burdens for Endoskeleton-Type Assist Suit Based on Musculoskeletal Model and Its Improvement of the Utility",
        "track": "main",
        "status": "Poster",
        "abstract": "In endoskeleton-type assist suits, since the compressive force is added to the spine, a lumbar disc may be badly affected. However, in general, the lumbar burdens while lifting a heavy object under wearing the endoskeleton-type assist suit have not been fully investigated. In this paper, first, lumbar burdens while lifting the heavy object under wearing the endoskeleton-type assist suit \u2018Sustainable\u2019 were investigated through dynamic analysis based on the musculoskeletal model software AnyBody Modeling System. The results of analysis showed that the lumbar burdens can be decreased under wearing the Sustainable as compared with not wearing the Sustainable. Second, in order to improve the utility of the Sustainable, suitable number of artificial muscles of the Sustainable was investigated. Under the condition that the CO2 gas cylinder is used as an air source, Sustainable with two artificial muscles and that with one artificial muscle were compared in terms of assist effect, lumbar burdens and cost performance through measurements of practical assistable times and experiments of lifting the heavy object. Then, suitable number of artificial muscles of the Sustainable was determined.",
        "primary_area": "",
        "author": "Chiharu Ishii;Kouhei Takahashi;Chiharu Ishii;Kouhei Takahashi",
        "authorids": "/37289854000;/37089196619;/37289854000;/37089196619",
        "aff": "Department of Mechanical Engineering, Hosei University, Tokyo, Japan; Graduate School of Science and Engineering, Hosei University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636063/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15616165833571062395&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hosei University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.hosei.ac.jp",
        "aff_unique_abbr": "Hosei",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636574",
        "title": "Event-Triggered Control for Weight-Unbalanced Directed Robot Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop an event-triggered control strategy for a weighted-unbalanced directed homogeneous robot network to reach a dynamic consensus in this work. We present some guarantees for synchronizing a robot network when all robots have access to the reference and when a limited number of robots have access. The proposed event-triggered control can reduce and avoid the periodic updating of the signals. Unlike some current control methods, we prove stability by making use of a logarithmic norm, which extends the possibilities of the control law to be applied to a wide range of directed graphs, in contrast to other works where the event-triggered control can be only implemented over strongly connected and weight-balanced digraphs. We test the performance of our algorithm by carrying out experiments both in simulation and in a real team of robots.",
        "primary_area": "",
        "author": "Juan D. Pabon;Gustavo A. Cardona;Nestor I. Ospina;Juan Calderon;Eduardo Mojica-Nava;Juan D. Pabon;Gustavo A. Cardona;Nestor I. Ospina;Juan Calderon;Eduardo Mojica-Nava",
        "authorids": "/37087113414;/37085799776;/37089195778;/37086344270;/38275046400;/37087113414;/37085799776;/37089195778;/37086344270;/38275046400",
        "aff": "Desync-LAB, Universidad Nacional de Colombia, Bogota, Colombia; AIR-Lab, Lehigh University, PA, USA; Desync-LAB, Universidad Nacional de Colombia, Bogota, Colombia; Bethune Cookman University, Daytona, FL; Desync-LAB, Universidad Nacional de Colombia, Bogota, Colombia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636574/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:dYpoogbBMx0J:scholar.google.com/&scioq=Event-Triggered+Control+for+Weight-Unbalanced+Directed+Robot+Networks&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "Universidad Nacional de Colombia;Lehigh University;Bethune-Cookman University",
        "aff_unique_dep": "Desync-LAB;AIR-Lab;",
        "aff_unique_url": "https://www.unal.edu.co;https://www.lehigh.edu;https://www.cookman.edu",
        "aff_unique_abbr": ";Lehigh;BCU",
        "aff_campus_unique_index": "0;1;0;2;0",
        "aff_campus_unique": "Bogota;Bethlehem;Daytona",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "Colombia;United States"
    },
    {
        "id": "9636307",
        "title": "Event-based Motion Segmentation by Cascaded Two-Level Multi-Model Fitting",
        "track": "main",
        "status": "Poster",
        "abstract": "Among prerequisites for a synthetic agent to inter-act with dynamic scenes, the ability to identify independently moving objects is specifically important. From an application perspective, nevertheless, standard cameras may deteriorate remarkably under aggressive motion and challenging illumination conditions. In contrast, event-based cameras, as a category of novel biologically inspired sensors, deliver advantages to deal with these challenges. Its rapid response and asynchronous nature enables it to capture visual stimuli at exactly the same rate of the scene dynamics. In this paper, we present a cascaded two-level multi-model fitting method for identifying independently moving objects (i.e., the motion segmentation problem) with a monocular event camera. The first level leverages tracking of event features and solves the feature clustering problem under a progressive multi-model fitting scheme. Initialized with the resulting motion model instances, the second level further addresses the event clustering problem using a spatio-temporal graph-cut method. This combination leads to efficient and accurate event-wise motion segmentation that cannot be achieved by any of them alone. Experiments demonstrate the effectiveness and versatility of our method in real-world scenes with different motion patterns and an unknown number of independently moving objects.",
        "primary_area": "",
        "author": "Xiuyuan Lu;Yi Zhou;Shaojie Shen;Xiuyuan Lu;Yi Zhou;Shaojie Shen",
        "authorids": "/37089196444;/37088979635;/37954847200;/37089196444;/37088979635;/37954847200",
        "aff": "Dept. of ECE, Hong Kong University of Science and Technology, Hong Kong, China; Dept. of ECE, Hong Kong University of Science and Technology, Hong Kong, China; Dept. of ECE, Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636307/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4760804671856877230&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Dept. of ECE",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635907",
        "title": "EventVLAD: Visual Place Recognition with Reconstructed Edges from Event Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "Event cameras are neuromorphic vision sensors that are able to capture high dynamic range with low latency in microseconds, without motion blur. Their strength lies in the unique representation of data as asynchronous events, enabling detection of scene structures less invariantly from dynamic luminance changes. However, a single event does not represent spatial information, and events must be integrated to translate into meaningful information. Therefore, state-of-the-art deep learning algorithms have focused on reconstructing the original scene from events. However, as environmental variances are also captured throughout events and restored in reconstructed images, simple reconstruction does not help achieving robust visual place recognition. In this paper, we suggest to use reconstructed event edges denoised for place recognition. While brightness wavers with dynamic environmental variances, edge contours only change with gradient magnitude scale. We utilize the high dynamic range of event cameras to detect these scaled edges from different environments and show that using reconstructed edges shows robust performance in overcoming day-to-night illumination variance without a large training set.",
        "primary_area": "",
        "author": "Alex Junho Lee;Ayoung Kim;Alex Junho Lee;Ayoung Kim",
        "authorids": "/37086278558;/37403315600;/37086278558;/37403315600",
        "aff": "Department of Civil and Environmental Engineering, KAIST, Daejeon, S. Korea; Department of Mechanical Engineering, SNU, Seoul, S. Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635907/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1662970075510215707&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "KAIST;Seoul National University",
        "aff_unique_dep": "Department of Civil and Environmental Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.snu.ac.kr",
        "aff_unique_abbr": "KAIST;SNU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Daejeon;Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636779",
        "title": "Evolving Infotaxis for Meandering Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Locating odour sources with mobile robots is a difficult task with many real world applications. Over the years, researchers have devised bio-inspired and cognitive methods to enable mobile robots to fulfil this task. One of the most popular cognitive approaches is Infotaxis, which computes a probability map for the location of the chemical source and, on each time step, moves the robot in the direction that minimises the entropy of that probability map. The main difficulty for applying Infotaxis in the real world is selecting proper values for the parameters of its internal gas dispersion model, as it has been shown that its performance is greatly influenced by the accuracy of said model. This work proposes a Genetic Algorithm for optimising those parameters for specific environments. The proposed method is applied to environments with distinct wind and odour dispersion characteristics and the resulting parameters are compared. Moreover, the performance of Infotaxis is compared to that of reactive search strategies evolved by Geometric Syntactic Genetic Programming. The statistically validated results show that the evolved reactive strategies achieve equivalent success rates to Infotaxis, while being significantly faster. Real world experiments conducted in a controlled wind tunnel validated the simulation results.",
        "primary_area": "",
        "author": "Jo\u00e3o Macedo;Lino Marques;Ernesto Costa;Jo\u00e3o Macedo;Lino Marques;Ernesto Costa",
        "authorids": "/37085996566;/37296172300;/37276140000;/37085996566;/37296172300;/37276140000",
        "aff": "Centre for Informatics and Systems of the University of Coimbra, Coimbra, Portugal; Institute of Systems and Robotics, University of Coimbra, Coimbra, Portugal; Centre for Informatics and Systems of the University of Coimbra, Coimbra, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636779/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15721820185614140822&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Coimbra",
        "aff_unique_dep": "Centre for Informatics and Systems",
        "aff_unique_url": "https://www.uc.pt",
        "aff_unique_abbr": "UC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Coimbra",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "9636594",
        "title": "Explaining the Decisions of Deep Policy Networks for Robotic Manipulations",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep policy networks enable robots to learn behaviors to solve various real-world complex tasks in an end-to-end fashion. However, they lack transparency to provide the reasons of actions. Thus, such a black-box model often results in low reliability and disruptive actions during the deployment of the robot in practice. To enhance its transparency, it is important to explain robot behaviors by considering the extent to which each input feature contributes to determining a given action. In this paper, we present an explicit analysis of deep policy models through input attribution methods to explain how and to what extent each input feature affects the decisions of the robot policy models. To this end, we present two methods for applying input attribution methods to robot policy networks: (1) we measure the importance factor of each joint torque to re ect the influence of the motor torque on the end-effector movement, and (2) we modify a relevance propagation method to handle negative inputs and outputs in deep policy networks properly. To the best of our knowledge, this is the first report to identify the dynamic changes of input attributions of multi-modal sensor inputs in deep policy networks online for robotic manipulation.",
        "primary_area": "",
        "author": "Seongun Kim;Jaesik Choi;Seongun Kim;Jaesik Choi",
        "authorids": "/37089195779;/37085412501;/37089195779;/37085412501",
        "aff": "Graduate School of Artificial Intelligence, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Graduate School of Artificial Intelligence, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636594/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15630947343516286338&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Graduate School of Artificial Intelligence",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636243",
        "title": "Exploration-RRT: A multi-objective Path Planning and Exploration Framework for Unknown and Unstructured Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This article establishes the Exploration-RRT algorithm: A novel general-purpose combined exploration and path planning algorithm, based on a multi-goal Rapidly-Exploring Random Trees (RRT) framework. Exploration-RRT (ERRT) has been specifically designed for utilization in 3D exploration missions, with partially or completely unknown and unstructured environments. The novel proposed ERRT is based on a multi-objective optimization framework and it is able to take under consideration the potential information gain, the distance travelled, and the actuation costs, along trajectories to pseudorandom goals, generated from considering the on-board sensor model and the non-linear model of the utilized platform. In this article, the algorithmic pipeline of the ERRT will be established and the overall applicability and efficiency of the proposed scheme will be presented on an application with an Unmanned Aerial Vehicle (UAV) model, equipped with a 3D lidar, in a simulated operating environment, with the goal of exploring a completely unknown area as efficiently and quickly as possible.",
        "primary_area": "",
        "author": "Bj\u00f6rn Lindqvist;Ali-Akbar Agha-Mohammadi;George Nikolakopoulos;Bj\u00f6rn Lindqvist;Ali-Akbar Agha-Mohammadi;George Nikolakopoulos",
        "authorids": "/37088450622;/38274170800;/37301305200;/37088450622;/38274170800;/37301305200",
        "aff": "Department of Computer, Electrical and Space Engineering, Robotics and Artificial Intelligence Team, Lule\u00e5 University of Technology, Lule\u00e5, Sweden; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Department of Computer, Electrical and Space Engineering, Robotics and Artificial Intelligence Team, Lule\u00e5 University of Technology, Lule\u00e5, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636243/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13637462427582866001&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Lule\u00e5 University of Technology;California Institute of Technology",
        "aff_unique_dep": "Department of Computer, Electrical and Space Engineering;Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.ltu.se;https://www.caltech.edu",
        "aff_unique_abbr": "LTU;Caltech",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Lule\u00e5;Pasadena",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Sweden;United States"
    },
    {
        "id": "9636365",
        "title": "Exploring Consequential Robot Sound: Should We Make Robots Quiet and Kawaii-et?",
        "track": "main",
        "status": "Poster",
        "abstract": "All robots create consequential sound\u2014sound produced as a result of the robot\u2019s mechanisms\u2014yet little work has explored how sound impacts human-robot interaction. Recent work shows that the sound of different robot mechanisms affects perceived competence, trust, human-likeness, and discomfort. However, the physical sound characteristics responsible for these perceptions have not been clearly identified. In this paper, we aim to explore key characteristics of robot sound that might influence perceptions. A pilot study from our past work showed that quieter and higher-pitched robots may be perceived as more competent and less discomforting. To better understand how variance in these attributes affects perception, we performed audio manipulations on two sets of industrial robot arm videos within a series of four new studies presented in this paper. Results confirmed that quieter robots were perceived as less discomforting. In addition, higher-pitched robots were perceived as more energetic, happy, warm, and competent. Despite the robot\u2019s industrial purpose and appearance, participants seemed to prefer more \"cute\" (or \"kawaii\") sound profiles, which could have implications for the design of more acceptable and fulfilling sound profiles for human-robot interactions with practical collaborative robots.",
        "primary_area": "",
        "author": "Brian J. Zhang;Knut Peterson;Christopher A. Sanchez;Naomi T. Fitter;Brian J. Zhang;Knut Peterson;Christopher A. Sanchez;Naomi T. Fitter",
        "authorids": "/37088691065;/37089194384;/37088217744;/37077925800;/37088691065;/37089194384;/37088217744;/37077925800",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; School of Psychological Science, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636365/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16017201254967301912&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636795",
        "title": "Exploring Imitation Learning for Autonomous Driving with Feedback Synthesizer and Differentiable Rasterization",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a learning-based planner that aims to robustly drive a vehicle by mimicking human drivers\u2019 driving behavior. We leverage a mid-to-mid approach that allows us to manipulate the input to our imitation learning network freely. With that in mind, we propose a novel feedback synthesizer for data augmentation. It allows our agent to gain more driving experience in various previously unseen environments that are likely to encounter, thus improving overall performance. This is in contrast to prior works that rely purely on random synthesizers. Furthermore, rather than completely commit to imitating, we introduce task losses that penalize undesirable behaviors, such as collision, off-road, and so on. Unlike prior works, this is done by introducing a differentiable vehicle rasterizer that directly converts the waypoints output by the network into images. This effectively avoids the usage of heavyweight ConvLSTM networks, therefore, yields a faster model inference time. About the network architecture, we exploit an attention mechanism that allows the network to reason critical objects in the scene and produce better interpretable attention heatmaps. To further enhance the safety and robustness of the network, we add an optional optimization-based post-processing planner improving the driving comfort. We comprehensively validate our method\u2019s effectiveness in different scenarios that are specifically created for evaluating self-driving vehicles. Results demonstrate that our learning-based planner achieves high intelligence and can handle complex situations. Detailed ablation and visualization analysis are included to further demonstrate each of our proposed modules\u2019 effectiveness in our method.",
        "primary_area": "",
        "author": "Jinyun Zhou;Rui Wang;Xu Liu;Yifei Jiang;Shu Jiang;Jiaming Tao;Jinghao Miao;Shiyu Song;Jinyun Zhou;Rui Wang;Xu Liu;Yifei Jiang;Shu Jiang;Jiaming Tao;Jinghao Miao;Shiyu Song",
        "authorids": "/37087103315;/37089395079;/37089195697;/37089196050;/37088637541;/37088921506;/37088643032;/37086455081;/37087103315;/37089395079;/37089195697;/37089196050;/37088637541;/37088921506;/37088643032;/37086455081",
        "aff": "Baidu Autonomous Driving Technology Department; Baidu Autonomous Driving Technology Department; Baidu Autonomous Driving Technology Department; Baidu Autonomous Driving Technology Department; Baidu Autonomous Driving Technology Department; Baidu Autonomous Driving Technology Department; Baidu Autonomous Driving Technology Department; Baidu Autonomous Driving Technology Department",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636795/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1373593580420638249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Baidu",
        "aff_unique_dep": "Autonomous Driving Technology Department",
        "aff_unique_url": "https://www.baidu.com",
        "aff_unique_abbr": "Baidu",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635993",
        "title": "Exploring Learning for Intercepting Projectiles with a Robot-Held Stick",
        "track": "main",
        "status": "Poster",
        "abstract": "For many tasks, including table tennis, catching, and sword fighting, a critical step is intercepting the incoming object with a robot arm or held tool. Solutions to robot arm interception via learning, specifically reinforcement learning (RL), have become prevalent, as they provide robust solutions to the robot arm interception problem, even for high degree of freedom robotic systems. Despite numerous solutions, there has been little exploration into the factors of learning that impact solution quality. Thus, there is little insight into what problem features lead to better learning success. In this paper, we explore the parameters that impact solution quality. We find that link position observations outperform joint angle observations in terms of learning speed, performance, ability to utilize more than one frame of observation, and generalization to situations not trained for. These results are immediately applicable to RL for robot arm interception tasks.",
        "primary_area": "",
        "author": "John E. G. Baxter;Torin Adamson;Satomi Sugaya;Lydia Tapia;John E. G. Baxter;Torin Adamson;Satomi Sugaya;Lydia Tapia",
        "authorids": "/37089196053;/37087472665;/37087323775;/37564283100;/37089196053;/37087472665;/37087323775;/37564283100",
        "aff": "Department of Computer Science, University of New Mexico, Albuquerque, NM, USA; Department of Computer Science, University of New Mexico, Albuquerque, NM, USA; Department of Computer Science, University of New Mexico, Albuquerque, NM, USA; Department of Computer Science, University of New Mexico, Albuquerque, NM, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635993/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:L3KFw84YMyAJ:scholar.google.com/&scioq=Exploring+Learning+for+Intercepting+Projectiles+with+a+Robot-Held+Stick&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of New Mexico",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.unm.edu",
        "aff_unique_abbr": "UNM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Albuquerque",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636171",
        "title": "Exponential stability of trajectory tracking control in the orientation space utilizing unit quaternions",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory tracking in the orientation space utilizing unit quaternions yields non linear error dynamics as opposed to Cartesian position. In this work, we study trajectory tracking in the orientation space utilizing the most popular quaternion error representations and angular velocity errors. By selecting error functions carefully we show exponential convergence in a region of attraction containing large initial errors. We further show that under certain conditions frequently en-countered in practice, the formulation respecting the geometric characteristics of the quaternion manifold and its tangent space yields linear tracking dynamics allowing us to guarantee a desired tracking performance by gain selection without tuning. Simulation and experimental results are provided.",
        "primary_area": "",
        "author": "Leonidas Koutras;Zoe Doulgeri;Leonidas Koutras;Zoe Doulgeri",
        "authorids": "/37088507216;/37274011500;/37088507216;/37274011500",
        "aff": "Automation & Robotics Lab, Dept. of Electrical & Computer Engineering, Aristotle University of Thessaloniki, Greece; Automation & Robotics Lab, Dept. of Electrical & Computer Engineering, Aristotle University of Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636171/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14894829686103502368&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki",
        "aff_unique_dep": "Dept. of Electrical & Computer Engineering",
        "aff_unique_url": "https://www.auth.gr",
        "aff_unique_abbr": "AUTH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Thessaloniki",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9636677",
        "title": "Extended Tactile Perception: Vibration Sensing through Tools and Grasped Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans display the remarkable ability to sense the world through tools and other held objects. For example, we are able to pinpoint impact locations on a held rod and tell apart different textures using a rigid probe. In this work, we consider how we can enable robots to have a similar capacity, i.e., to embody tools and extend perception using standard grasped objects. We propose that vibro-tactile sensing using dynamic tactile sensors on the robot fingers, along with machine learning models, enables robots to decipher contact information that is transmitted as vibrations along rigid objects. This paper reports on extensive experiments using the BioTac micro-vibration sensor and a new event dynamic sensor, the NUSkin, capable of multi-taxel sensing at 4 kHz. We demonstrate that fine localization on a held rod is possible using our approach (with errors less than 1 cm on a 20 cm rod). Next, we show that vibro-tactile perception can lead to reasonable grasp stability prediction during object handover, and accurate food identification using a standard fork. We find that multi-taxel vibro-tactile sensing at a sufficiently high sampling rate (above 2 kHz) led to the best performance across the various tasks and objects. Taken together, our results provide both evidence and guidelines for using vibro-tactile perception to extend tactile perception, which we believe will lead to enhanced competency with tools and better physical human-robot interaction.",
        "primary_area": "",
        "author": "Tasbolat Taunyazov;Luar Shui Song;Eugene Lim;Hian Hian See;David Lee;Benjamin C.K. Tee;Harold Soh;Tasbolat Taunyazov;Luar Shui Song;Eugene Lim;Hian Hian See;David Lee;Benjamin C.K. Tee;Harold Soh",
        "authorids": "/37085673647;/37089196928;/37089196158;/37086153215;/37089197447;/37088921220;/37684942300;/37085673647;/37089196928;/37089196158;/37086153215;/37089197447;/37088921220;/37684942300",
        "aff": "Dept. of Computer Science, National University of Singapore; Dept. of Computer Science, National University of Singapore; Dept. of Computer Science, National University of Singapore; Dept. of Materials Science and Engineering, National University of Singapore; Dept. of Materials Science and Engineering, National University of Singapore; Dept. of Materials Science and Engineering, National University of Singapore; Dept. of Computer Science, National University of Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636677/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5865933770737948142&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Dept. of Computer Science",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9636776",
        "title": "Extended VINS-Mono: A Systematic Approach for Absolute and Relative Vehicle Localization in Large-Scale Outdoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a systematic approach called Extended VINS-Mono to utilize VINS-Mono, a state-of-the-art monocular visual-inertial relative localization method, targeting practical vehicle localization in large-scale outdoor road environments. Our proposed fusion approach associates multiple independent localization methods and provides multiple (projected) state estimates in a desired coordinate system to satisfy different accuracy, rate and latency requirements. We extend VINS-Mono with absolute localization methods like GNSS and relative localization methods like Kalman-filter-based INS to provide global state estimation for navigation/routing and local state estimation for planning/control. Additionally, Extended VINS-Mono addresses two significant drawbacks in VINS-Mono for use in large-scale outdoor road environments. First, motion on an almost planar road surface will make scale unobservable in VINS-Mono. Secondly, moving objects in dynamic scenarios will degrade accuracy. We handle the scale estimation problem of VINS-Mono by extending its (re-)initialization process with speed readings and introducing a speed factor for use with graph optimization. A dynamic feature-point filter method with masks from DNN-based object detection handles dynamic environments and re-collects feature points on stationary objects like parked cars. Better global accuracy is obtained with Extended VINS-Mono, compared to VINS-Mono, in a 25 km-trip journey through highways, tunnels, urban areas and suburban areas in Pittsburgh. Thus, Extended VINS-Mono can be used for reliable and accurate absolute localization in dynamic road environments. We also evaluate the accuracy, localization rate and latency of multiple (projected) state estimates in the global coordinate system from multiple localization methods. Our fusion method is therefore able to satisfy different localization requirements of various tasks on an intelligent vehicle.",
        "primary_area": "",
        "author": "Mengwen He;Ragunathan Raj Rajkumar;Mengwen He;Ragunathan Raj Rajkumar",
        "authorids": "/37089013383;/37268048500;/37089013383;/37268048500",
        "aff": "Department of Electric and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Electric and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636776/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15798758333741651794&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Electric and Computer Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636796",
        "title": "Extending Referring Expression Generation through shared knowledge about past Human-Robot collaborative activity",
        "track": "main",
        "status": "Poster",
        "abstract": "Being able to refer to an object, a person, or a place in a non-ambiguous manner is a need when one has to achieve collaborative activities with a partner. This is the so-called Referring Expression Generation (REG) problem. While widely used for Human-Robot Interaction, state of the art approaches restrict its use to the current environment. We propose a novel extension to the REG which takes full advantage of the Human-Robot shared knowledge about past actions as additional information to generate Referring Expressions. We show that our approach is usable with a domain-independent ontology as a knowledge base and that it can also use a semantic representation of past activity to generate RE. We illustrate our method through simulated situations and discuss its efficiency and pertinence.",
        "primary_area": "",
        "author": "Guillaume Sarthou;Guilhem Buisan;Aur\u00e9lie Clodic;Rachid Alami;Guillaume Sarthou;Guilhem Buisan;Aur\u00e9lie Clodic;Rachid Alami",
        "authorids": "/37087235675;/37088529065;/37296056000;/37278643600;/37087235675;/37088529065;/37296056000;/37278643600",
        "aff": "LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636796/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16740460502002766494&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "LAAS-CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.laas.fr/",
        "aff_unique_abbr": "LAAS-CNRS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toulouse",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9635944",
        "title": "Extension of Flocking Models to Environments with Obstacles and Degraded Communications",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study existing flocking models and propose extensions to improve their abilities to deal with environments having obstacles impacting the communication quality. Often depicted as robust systems, there is yet a lack of understanding how flocking models compare and how they are impacted by the communication quality when they exchange control data. We extend two standard models to improve their ability to stay connected while evolving in environments with different obstacles distributions. By taking into account the radio propagation, we model the obstacles impact on communications in a simulator that we use to optimize flocking parameters. The simulation results show the efficiency of the proposed models and how they adapt to different environmental constraints.",
        "primary_area": "",
        "author": "Alexandre Bonnefond;Olivier Simonin;Isabelle Gu\u00e9rin-Lassous;Alexandre Bonnefond;Olivier Simonin;Isabelle Gu\u00e9rin-Lassous",
        "authorids": "/37089196059;/37329541300;/38272455000;/37089196059;/37329541300;/38272455000",
        "aff": "Lyon 1 University, LIP Lab., Inria Dante Team, Lyon Cedex 07, France; INSA Lyon, CITI Lab., Inria Chroma Team, Villeurbanne, France; Lyon 1 University, LIP Lab., Inria Dante Team, Lyon Cedex 07, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635944/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9165285385405033801&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Lyon 1 University;INSA Lyon",
        "aff_unique_dep": "LIP Lab.;CITI Lab.",
        "aff_unique_url": "https://www.universite-lyon1.fr;https://www.insa-lyon.fr",
        "aff_unique_abbr": "UCBL;INSA Lyon",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Lyon;Villeurbanne",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636655",
        "title": "F-LOAM : Fast LiDAR Odometry and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous Localization and Mapping (SLAM) has wide robotic applications such as autonomous driving and unmanned aerial vehicles. Both computational efficiency and localization accuracy are of great importance towards a good SLAM system. Existing works on LiDAR based SLAM often formulate the problem as two modules: scan-to-scan match and scan-to-map refinement. Both modules are solved by iterative calculation which are computationally expensive. In this paper, we propose a general solution that aims to provide a computationally efficient and accurate framework for LiDAR based SLAM. Specifically, we adopt a non-iterative two-stage distortion compensation method to reduce the computational cost. For each scan input, the edge and planar features are extracted and matched to a local edge map and a local plane map separately, where the local smoothness is also considered for iterative pose optimization. Thorough experiments are performed to evaluate its performance in challenging scenarios, including localization for a warehouse Automated Guided Vehicle (AGV) and a public dataset on autonomous driving. The proposed method achieves a competitive localization accuracy with a processing rate of more than 10 Hz in the public dataset evaluation, which provides a good trade-off between performance and computational cost for practical applications. It is one of the most accurate and fastest open-sourced SLAM systems1 in KITTI dataset ranking.",
        "primary_area": "",
        "author": "Han Wang;Chen Wang;Chun-Lin Chen;Lihua Xie;Han Wang;Chen Wang;Chun-Lin Chen;Lihua Xie",
        "authorids": "/37292552600;/37089398088;/37539309300;/37274139300;/37292552600;/37089398088;/37539309300;/37274139300",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636655/",
        "gs_citation": 382,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15800847443983620253&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Nanyang Technological University;Carnegie Mellon University",
        "aff_unique_dep": "School of Electrical and Electronic Engineering;Robotics Institute",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.cmu.edu",
        "aff_unique_abbr": "NTU;CMU",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Singapore;Pittsburgh",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "9636335",
        "title": "F-VESPA: A Kinematic-based Algorithm for Real-time Heel-strike Detection During Walking",
        "track": "main",
        "status": "Poster",
        "abstract": "With over 10 million people currently suffering from significant long-term gait disability in the United States only, robot-assisted rehabilitation and wearable devices are increasingly gaining attention as a mean to regain functional mobility. Since these devices work collaborative and synchronously with the human gait, it is necessary to be able to detect gait events, such as heel-strikes, in real-time. Although many algorithms have been proposed for detecting heel-strikes with either wearable (e.g. Inertial Measurement Units (IMUs)) or non-wearable (e.g. force plates) sensors, there is a great need for employing less obtrusive and reliable sensors that rely only on recording the kinematics of the leg motion. This work proposes a novel and efficient kinematic algorithm, called the Foot VErtical & Sagittal Position Algorithm (F-VESPA), which has several advantages over existing methods. First, it accurately estimates heel-strike events using kinematic data without requiring access to future data points, rendering it the first to our knowledge kinematic algorithm capable of real-time implementation during treadmill walking. Moreover, it does not require tuning of the utilized parameters, rendering it robust to different subjects, conditions and equipment. The algorithm is tested in a large set of subjects across various treadmill speeds, and it is shown to outperform online and offline implementations of existing prominent kinematic algorithms. Using a 150 Hz data collection system, the F-VESPA achieved a total true error of 33 ms (median) in detecting heel-strike. The F-VESPA is the first to our knowledge kinematic algorithm that can detect heel-strike events during treadmill walking in real-time, with high accuracy, robustness and fast response, enabling real-time control of a variety of assistive platforms and devices, among others.",
        "primary_area": "",
        "author": "Chrysostomos Karakasis;Panagiotis Artemiadis;Chrysostomos Karakasis;Panagiotis Artemiadis",
        "authorids": "/37088453878;/38495840200;/37088453878;/38495840200",
        "aff": "Mechanical Engineering Department, University of Delaware, Newark, DE, USA; Mechanical Engineering Department, University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636335/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7432751173445277364&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636448",
        "title": "FAST-Dynamic-Vision: Detection and Tracking Dynamic Objects with Event and Depth Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "The development of aerial autonomy has enabled aerial robots to fly agilely in complex environments. However, dodging fast-moving objects in flight remains a challenge, limiting the further application of unmanned aerial vehicles (UAVs). The bottleneck of solving this problem is the accurate perception of rapid dynamic objects. Recently, event cameras have shown great potential in solving this problem. This paper presents a complete perception system including ego-motion compensation, object detection, and trajectory prediction for fast-moving dynamic objects with low latency and high precision. Firstly, we propose an accurate ego-motion compensation algorithm by considering both rotational and translational motion for more robust object detection. Then, for dynamic object detection, an event camera-based efficient regression algorithm is designed. Finally, we propose an optimization-based approach that asynchronously fuses event and depth cameras for trajectory prediction. Extensive real-world experiments and benchmarks are performed to validate our framework. Moreover, our code will be released to benefit related researches.",
        "primary_area": "",
        "author": "Botao He;Haojia Li;Siyuan Wu;Dong Wang;Zhiwei Zhang;Qianli Dong;Chao Xu;Fei Gao;Botao He;Haojia Li;Siyuan Wu;Dong Wang;Zhiwei Zhang;Qianli Dong;Chao Xu;Fei Gao",
        "authorids": "/37089000065;/37086544200;/37089197278;/37089396836;/37088996226;/37089195681;/37404060100;/37086045143;/37089000065;/37086544200;/37089197278;/37089396836;/37088996226;/37089195681;/37404060100;/37086045143",
        "aff": "School of Automation, Nanjing Institute of Technology, Nanjing, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Faculty of Electronic and Information Engineering, Xi\u2019an Jiaotong University, Xi\u2019an, China; Nation Engineering Research Center for Industrial Automation, Ningbo Institute, Ningbo, China; Nation Engineering Research Center for Industrial Automation, Ningbo Institute, Ningbo, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Nation Engineering Research Center for Industrial Automation, Ningbo Institute, Ningbo, China; Nation Engineering Research Center for Industrial Automation, Ningbo Institute, Ningbo, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636448/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8197437553814580836&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;3;3;1;3;3",
        "aff_unique_norm": "Nanjing Institute of Technology;Northeastern University;Xi'an Jiao Tong University;Nation Engineering Research Center for Industrial Automation",
        "aff_unique_dep": "School of Automation;Faculty of Robot Science and Engineering;Faculty of Electronic and Information Engineering;",
        "aff_unique_url": ";http://www.neu.edu.cn/;http://www.xjtu.edu.cn;",
        "aff_unique_abbr": ";NEU;XJTU;",
        "aff_campus_unique_index": "0;1;2;3;3;1;3;3",
        "aff_campus_unique": "Nanjing;Shenyang;Xi'an;Ningbo",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636084",
        "title": "FEANet: Feature-Enhanced Attention Network for RGB-Thermal Real-time Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "The RGB-Thermal (RGB-T) information for semantic segmentation has been extensively explored in recent years. However, most existing RGB-T semantic segmentation usually compromises spatial resolution to achieve real-time inference speed, which leads to poor performance. To better extract detail spatial information, we propose a two-stage Feature-Enhanced Attention Network (FEANet) for the RGB-T semantic segmentation task. Specifically, we introduce a Feature-Enhanced Attention Module (FEAM) to excavate and enhance multi-level features from both the channel and spatial views. Benefited from the proposed FEAM module, our FEANet can preserve the spatial information and shift more attention to high-resolution features from the fused RGB-T images. Extensive experiments on the urban scene dataset demonstrate that our FEANet outperforms other state-of-the-art (SOTA) RGB-T methods in terms of objective metrics and subjective visual comparison (+2.6% in global mAcc and +0.8% in global mIoU). For the 480 \u00d7 640 RGB-T test images, our FEANet can run with a real-time speed on an NVIDIA GeForce RTX 2080 Ti card.",
        "primary_area": "",
        "author": "Fuqin Deng;Hua Feng;Mingjian Liang;Hongmin Wang;Yong Yang;Yuan Gao;Junfeng Chen;Junjie Hu;Xiyue Guo;Tin Lun Lam;Fuqin Deng;Hua Feng;Mingjian Liang;Hongmin Wang;Yong Yang;Yuan Gao;Junfeng Chen;Junjie Hu;Xiyue Guo;Tin Lun Lam",
        "authorids": "/37087470921;/37088468115;/37089194206;/37088929397;/37088468673;/37089157084;/37089393433;/37088469703;/37088961551;/37571111600;/37087470921;/37088468115;/37089194206;/37088929397;/37088468673;/37089157084;/37089393433;/37088469703;/37088961551;/37571111600",
        "aff": "3irobotix Co.,Ltd, Shenzhen, China; School of Intelligent Manufacturing, the Wuyi University, Jiangmen, China; School of Intelligent Manufacturing, the Wuyi University, Jiangmen, China; School of Intelligent Manufacturing, the Wuyi University, Jiangmen, China; 3irobotix Co.,Ltd, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, the Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, the Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, the Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, the Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society, the Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636084/",
        "gs_citation": 134,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1446532225509726240&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;1;1;0;2;2;2;2;2",
        "aff_unique_norm": "3irobotix Co., Ltd.;Wuyi University;Chinese University of Hong Kong",
        "aff_unique_dep": ";School of Intelligent Manufacturing;Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_url": ";;https://www.cuhk.edu.cn",
        "aff_unique_abbr": ";;CUHK",
        "aff_campus_unique_index": "1;1;1;2;2;2;2;2",
        "aff_campus_unique": ";Jiangmen;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636385",
        "title": "FIDNet: LiDAR Point Cloud Semantic Segmentation with Fully Interpolation Decoding",
        "track": "main",
        "status": "Poster",
        "abstract": "Projecting the point cloud on the 2D spherical range image transforms the LiDAR semantic segmentation to a 2D segmentation task on the range image. However, the LiDAR range image is still naturally different from the regular 2D RGB image; for example, each position on the range image encodes the unique geometry information. In this paper, we propose a new projection-based LiDAR semantic segmentation pipeline that consists of a novel network structure and an efficient post-processing step. In our network structure, we design a FID (fully interpolation decoding) module that directly upsamples the multi-resolution feature maps using bilinear interpolation. Inspired by the 3D distance interpolation used in PointNet++, we argue this FID module is a 2D version distance interpolation on (\u03b8, \u03d5) space. As a parameter-free decoding module, the FID largely reduces the model complexity by maintaining good performance. Besides the network structure, we empirically find that our model predictions have clear boundaries between different semantic classes. This makes us rethink whether the widely used K-nearest-neighbor post-processing is still necessary for our pipeline. Then, we realize the many-to-one mapping causes the blurring effect that some points are mapped into the same pixel and share the same label. Therefore, we propose to process those occluded points by assigning the nearest predicted label to them. This NLA (nearest label assignment) post-processing step shows a better performance than KNN with faster inference speed in the ablation study. On SemanticKITTI dataset, our pipeline achieves the best performance among all projection-based methods with 64\u00d72048 resolution and all point-wise solutions. With a ResNet-34 as the backbone, both the training and testing of our model can be finished on a single RTX 2080 Ti with 11G memory. The code is released here.1",
        "primary_area": "",
        "author": "Yiming Zhao;Lin Bai;Xinming Huang;Yiming Zhao;Lin Bai;Xinming Huang",
        "authorids": "/37086463567;/37086462488;/37281303400;/37086463567;/37086462488;/37281303400",
        "aff": "Department of Electrical and Computer Engineering, Worcester Polytechnic Institute, Massachusetts, USA; Department of Electrical and Computer Engineering, Worcester Polytechnic Institute, Massachusetts, USA; Department of Electrical and Computer Engineering, Worcester Polytechnic Institute, Massachusetts, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636385/",
        "gs_citation": 78,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6223252654806621181&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636455",
        "title": "FINO-Net: A Deep Multimodal Sensor Fusion Framework for Manipulation Failure Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "We need robots more aware of the unintended outcomes of their actions for ensuring safety. This can be achieved by an onboard failure detection system to monitor and detect such cases. Onboard failure detection is challenging with a limited set of onboard sensor setup due to the limitations of sensing capabilities of each sensor. To alleviate these challenges, we propose FINO-Net, a novel multimodal sensor fusion based deep neural network to detect and identify manipulation failures. We also introduce FAILURE, a multimodal dataset, containing 229 real-world manipulation data recorded with a Baxter robot. Our network combines RGB, depth and audio readings to effectively detect failures. Results indicate that fusing RGB with depth and audio modalities significantly improves the performance. FINO-Net achieves %98.60 detection accuracy on our novel dataset. Code and data are publicly available at https://github.com/ardai/fino-net.",
        "primary_area": "",
        "author": "Arda Inceoglu;Eren Erdal Aksoy;Abdullah Cihan Ak;Sanem Sariel;Arda Inceoglu;Eren Erdal Aksoy;Abdullah Cihan Ak;Sanem Sariel",
        "authorids": "/37086552433;/37544389700;/37089195250;/37563656200;/37086552433;/37544389700;/37089195250;/37563656200",
        "aff": "Artificial Intelligence and Robotics Laboratory, Faculty of Computer and Informatics Engineering, Istanbul Technical University, Maslak, Turkey; School of Information Technology, Center for Applied Intelligent Systems Research, Halmstad University, Halmstad, Sweden; Artificial Intelligence and Robotics Laboratory, Faculty of Computer and Informatics Engineering, Istanbul Technical University, Maslak, Turkey; Artificial Intelligence and Robotics Laboratory, Faculty of Computer and Informatics Engineering, Istanbul Technical University, Maslak, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636455/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16410858136940600695&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Istanbul Technical University;Halmstad University",
        "aff_unique_dep": "Faculty of Computer and Informatics Engineering;School of Information Technology",
        "aff_unique_url": "https://www.itu.edu.tr;https://www.hh.se",
        "aff_unique_abbr": "ITU;",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Maslak;Halmstad",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "T\u00fcrkiye;Sweden"
    },
    {
        "id": "9636678",
        "title": "Fall detection for robotic endoscope holders in Minimally Invasive Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Classic Minimally Invasive Surgery (MIS) is an ergonomic burden for assistants and surgeons. The former need to adopt uncomfortable positions for hours while holding a camera to track the latter\u2019s gestures inside the patient. This incurs assistant\u2019s muscle fatigue which can lead to tremor or drift of the video feedback. A backdrivable robotic holder can be attached to this device in order to compensate its weight. This allows the user to place the camera at a desired position which the robot will steadily keep once he/she releases it. However, endoscopic cameras present difficult-to-model accessories whose gravity parameters can change during the same surgery. If these changes are not foreseen by the gravity model of the robot this results in a fall of the endoscope each time it is released. Therefore, it is desired to firstly detect if there is a fall in order to be able to correct it. In this article a fall detection method for a comanipulated robotic endoscope holder is proposed. It evaluates smoothness of the robot end effector trajectory to identify whether the user manipulates the instrument or it has been released and poorly compensated. An experiment was carried out with 10 subjects where 240 releases of the endoscope were performed while it was poorly compensated. The algorithm succeeded to detect the falls with sensitivity up to 99.17%.",
        "primary_area": "",
        "author": "Jesus Mago;Fran\u00e7ois Louveau;Marie-Aude Vitrani;Jesus Mago;Fran\u00e7ois Louveau;Marie-Aude Vitrani",
        "authorids": "/37086933852;/37089193927;/37563937400;/37086933852;/37089193927;/37563937400",
        "aff": "Haption SARL; Haption SARL; Sorbonne Universit\u00e9, INSERM U1150, CNRS UMR 7222, Institut des Syst\u00e8mes Intelligents et de Robotique (ISIR), Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636678/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2119941951081239164&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Haption SARL;Sorbonne Universit\u00e9",
        "aff_unique_dep": ";Institut des Syst\u00e8mes Intelligents et de Robotique (ISIR)",
        "aff_unique_url": "https://www.haption.com;https://www.sorbonne-universite.fr",
        "aff_unique_abbr": ";Sorbonne U",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Paris",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636148",
        "title": "Fast Autonomous Robotic Exploration Using the Underlying Graph Structure",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we fully define the existing relationships between traditional optimality criteria and the connectivity of the underlying pose-graph in Active SLAM, characterizing, therefore, the connection between Graph Theory and the Theory Optimal Experimental Design. We validate the proposed relationships in 2D and 3D graph SLAM datasets, showing a remarkable relaxation of the computational load when using the graph structure. Furthermore, we present a novel Active SLAM framework which outperforms traditional methods by successfully leveraging the graphical facet of the problem so as to autonomously explore an unknown environment.",
        "primary_area": "",
        "author": "Julio A. Placed;Jos\u00e9 A. Castellanos;Julio A. Placed;Jos\u00e9 A. Castellanos",
        "authorids": "/37089195728;/37447788900;/37089195728;/37447788900",
        "aff": "Departamento de Inform\u00e1tica e Ingenier\u00eda de Sistemas, Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n, Universidad de Zaragoza, Zaragoza, Spain; Departamento de Inform\u00e1tica e Ingenier\u00eda de Sistemas, Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n, Universidad de Zaragoza, Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636148/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1448126142571789589&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universidad de Zaragoza",
        "aff_unique_dep": "Departamento de Inform\u00e1tica e Ingenier\u00eda de Sistemas",
        "aff_unique_url": "https://www.unizar.es",
        "aff_unique_abbr": "UniZar",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Zaragoza",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9636002",
        "title": "Fast Generation of Obstacle-Avoiding Motion Primitives for Quadrotors",
        "track": "main",
        "status": "Poster",
        "abstract": "This work considers the problem of generating computationally efficient quadrotor motion primitives between a given pose (position, velocity, and acceleration) and a goal plane in the presence of obstacles. A new motion primitive tool based on the logistic curve is proposed and a closed-form analytic approach is developed to satisfy constraints on starting pose, goal plane, velocity, acceleration, and jerk. The geometric obstacle avoidance problem is represented as a combinatorial set problem and a heuristic approach is proposed to accelerate the solution search. Numerical examples are presented to highlight the fast motion primitive generation in multi-obstacle pose-to-plane scenarios.",
        "primary_area": "",
        "author": "Saurabh Upadhyay;Thomas Richardson;Arthur Richards;Saurabh Upadhyay;Thomas Richardson;Arthur Richards",
        "authorids": "/37085701702;/37683275600;/37299756300;/37085701702;/37683275600;/37299756300",
        "aff": "Department of Aerospace Engineering, University of Bristol, Bristol, United Kingdom; Department of Aerospace Engineering, University of Bristol, Bristol, United Kingdom; Bristol Robotics Laboratory, Bristol, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636002/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13136962299728570336&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Bristol;Bristol Robotics Laboratory",
        "aff_unique_dep": "Department of Aerospace Engineering;",
        "aff_unique_url": "https://www.bristol.ac.uk;",
        "aff_unique_abbr": "UoB;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bristol",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9635855",
        "title": "Fast Image-Anomaly Mitigation for Autonomous Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Camera anomalies like rain or dust can severely degrade image quality and its related tasks, such as localization and segmentation. In this work we address this important issue by implementing a pre-processing step that can effectively mitigate such artifacts in a real-time fashion, thus supporting the deployment of autonomous systems with limited compute capabilities. We propose a shallow generator with aggregation, trained in an adversarial setting to solve the ill-posed problem of reconstructing the occluded regions. We add an enhancer to further preserve high-frequency details and image colorization. We also produce one of the largest publicly available datasets1 to train our architecture and use realistic synthetic raindrops to obtain an improved initialization of the model. We benchmark our framework on existing datasets and on our own images obtaining state-of-the-art results while enabling real-time performance, with up to 40x faster inference time than existing approaches.",
        "primary_area": "",
        "author": "Gianmario Fumagalli;Yannick Huber;Marcin Dymczyk;Roland Siegwart;Renaud Dub\u00e9;Gianmario Fumagalli;Yannick Huber;Marcin Dymczyk;Roland Siegwart;Renaud Dub\u00e9",
        "authorids": "/37089196718;/37089197475;/37085425643;/37281398300;/37085782572;/37089196718;/37089197475;/37085425643;/37281398300;/37085782572",
        "aff": "Autonomous Systems Lab, ETH Z\u00fcrich; Sevensense Robotics AG; Sevensense Robotics AG; Autonomous Systems Lab, ETH Z\u00fcrich; Sevensense Robotics AG",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635855/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18221652854851127580&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "ETH Zurich;Sevensense Robotics",
        "aff_unique_dep": "Autonomous Systems Lab;",
        "aff_unique_url": "https://www.ethz.ch;https://www.sevensense.io",
        "aff_unique_abbr": "ETHZ;Sevensense",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636043",
        "title": "Fast Reactive Grasping with In-Finger Vision and In-Hand FPGA-accelerated CNNs",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a soft humanoid hand with in-finger integrated cameras and in-hand real-time image processing system for fast reactive grasping. Specifically, we describe an FPGA-based, in-hand integrated, embedded system for processing visual data captured by the five in-finger cameras while avoiding high bandwidth raw data streaming via the robots real-time data bus. The hardware acceleration allows fast detection and localization of objects based on finger-camera images and provides input for a grasping controller. To this end, we implement a resource-aware encoder-decoder Convolutional Neural Network (CNN) for pixel-wise object segmentation and run inference on the in-hand embedded system at 3.58 GOPS. We evaluate the system, consisting of the soft hand with in-finger vision and the in-hand FPGA-accelerated CNN in several experiments on the humanoid robot ARMAR-6. Specifically, we evaluate the overall system response time, the ability to perform precision grasps and test reactivity and reliability that are required for handover actions. We obtain an overall system response time of 154 ms for catching a falling object and obtain a success rate of 90 % reliability for the power drill handover tasks. Further, we successfully demonstrate ability of dexterous grasping and manipulation of a pencil from a cup.",
        "primary_area": "",
        "author": "Felix Hundhausen;Raphael Grimm;Leon Stieber;Tamim Asfour;Felix Hundhausen;Raphael Grimm;Leon Stieber;Tamim Asfour",
        "authorids": "/37086581259;/37085813662;/37089197209;/37295529100;/37086581259;/37085813662;/37089197209;/37295529100",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636043/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8460718928862725810&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9636334",
        "title": "Fast and Robust Bio-inspired Teach and Repeat Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Fully autonomous mobile robots have a multitude of potential applications, but guaranteeing robust navigation performance remains an open research problem. For many tasks such as repeated infrastructure inspection, item delivery, or inventory transport, a route repeating capability can be sufficient and offers potential practical advantages over a full navigation stack. Previous teach and repeat research has achieved high performance in difficult conditions predominantly by using sophisticated, expensive sensors, and has often had high computational requirements. Biological systems, such as small animals and insects like seeing ants, offer a proof of concept that robust and generalisable navigation can be achieved with extremely limited visual systems and computing power. In this work we create a novel asynchronous formulation for teach and repeat navigation that fully utilises odometry information, paired with a correction signal driven by much more computationally lightweight visual processing than is typically required. This correction signal is also decoupled from the robot\u2019s motor control, allowing its rate to be modulated by the available computing capacity. We evaluate this approach with extensive experimentation on two different robotic platforms, the Consequential Robotics Miro and the Clearpath Jackal robots, across navigation trials totalling more than 6000 metres in a range of challenging indoor and outdoor environments. Our approach continues to succeed when multiple state-of-the-art systems fail due to low resolution images, unreliable odometry, or lighting change, while requiring significantly less compute. We also \u2013 for the first time \u2013 demonstrate versatile cross-platform teach and repeat without changing parameters, in which we learn to navigate a route with one robot and repeat that route using a completely different robot.",
        "primary_area": "",
        "author": "Dominic Dall\u2019Osto;Tobias Fischer;Michael Milford;Dominic Dall\u2019Osto;Tobias Fischer;Michael Milford",
        "authorids": "/37089196408;/37085784700;/37283633100;/37089196408;/37085784700;/37283633100",
        "aff": "QUT Centre for Robotics, Queensland University of Technology, Brisbane, QLD, Australia; QUT Centre for Robotics, Queensland University of Technology, Brisbane, QLD, Australia; QUT Centre for Robotics, Queensland University of Technology, Brisbane, QLD, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636334/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13202391309906831990&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queensland University of Technology",
        "aff_unique_dep": "Centre for Robotics",
        "aff_unique_url": "https://www.qut.edu.au",
        "aff_unique_abbr": "QUT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9636042",
        "title": "Fast and Unsupervised Non-Local Feature Learning for Direct Volume Rendering of 3D Medical Images",
        "track": "main",
        "status": "Poster",
        "abstract": "To improve the efficiency of medical visualization for computer aided surgery, we propose a fast and unsupervised 3D-CNN based non-local feature learning network. The proposed network consists of an encoder structure and a decoder structure. The encoder of the network projects the cube into a high-dimensional feature space, and the decoder of the network reconstructs the cube from the feature space. The decoder of the network serves as a dictionary shared by the cube to enforce the features for similar parts to be similar although they may distribute at disjointed locations. With such structures, the network is able to extract non-local features of the entire data. Moreover, a sparse constraint is incorporated into the network to increase the discriminative of the non-local features. Then the extracted non-local features of each voxel are fused with the corresponding position matrix and Hessian matrix for the voxel classification using Random Forest. Finally, a multidimensional transfer function is designed to enable the volume rendering. Experimental results demonstrate that the proposed method outperforms the state-of-the-art methods with much less training time.",
        "primary_area": "",
        "author": "Xinmei Fu;Zhenzhou Shao;Ying Qu;Yong Guan;Yibo Zou;Zhiping Shi;Jindong Tan;Xinmei Fu;Zhenzhou Shao;Ying Qu;Yong Guan;Yibo Zou;Zhiping Shi;Jindong Tan",
        "authorids": "/37089194208;/37085555595;/37085888305;/37308153300;/37089194696;/37085742076;/37065245900;/37089194208;/37085555595;/37085888305;/37308153300;/37089194696;/37085742076;/37065245900",
        "aff": "College of Information Engineering, Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, China; College of Information Engineering, Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, China; Engineering College, The University of Tennessee, Knoxville, TN, USA; College of Information Engineering, Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, China; School of Optoelectronic Science and Engineering, Soochow University, China; College of Information Engineering, Beijing Key Laboratory of Light Industrial Robot and Safety Verification, Capital Normal University, Beijing, China; Engineering College, The University of Tennessee, Knoxville, TN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636042/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8530107285011583140&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;2;0;1",
        "aff_unique_norm": "Capital Normal University;University of Tennessee;Soochow University",
        "aff_unique_dep": "College of Information Engineering;Engineering College;School of Optoelectronic Science and Engineering",
        "aff_unique_url": "http://www.cnu.edu.cn;https://www.utk.edu;http://www.soochow.edu.cn",
        "aff_unique_abbr": "CNU;UT;",
        "aff_campus_unique_index": "0;0;1;0;0;1",
        "aff_campus_unique": "Beijing;Knoxville;",
        "aff_country_unique_index": "0;0;1;0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9636165",
        "title": "Fast-Learning Grasping and Pre-Grasping via Clutter Quantization and Q-map Masking",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping objects in cluttered scenarios is a challenging task in robotics. Performing pre-grasp actions such as pushing and shifting to scatter objects is a way to reduce clutter. Based on deep reinforcement learning, we propose a Fast-Learning Grasping (FLG) framework, that can integrate pre-grasping actions along with grasping to pick up objects from cluttered scenarios with reduced real-world training time. We associate rewards for performing moving actions with the change of environmental clutter and utilize a hybrid triggering method, leading to data-efficient learning and synergy. Then we use the output of an extended fully convolutional network as the value function of each pixel point of the workspace and establish an accurate estimation of the grasp probability for each action. We also introduce a mask function as prior knowledge to enable the agents to focus on the accurate pose adjustment to improve the effectiveness of collecting training data and, hence, to learn efficiently. We carry out pre-training of the FLG over simulated environment, and then the learnt model is transferred to the real world with minimal fine-tuning for further learning during actions. Experimental results demonstrate a 94% grasp success rate and the ability to generalize to novel objects. Compared to state-of-the-art approaches in the literature, the proposed FLG framework can achieve similar or higher grasp success rate with lesser amount of training in the real world. Supplementary video is available at https://youtu.be/KTGj1fGU6ho.",
        "primary_area": "",
        "author": "Dafa Ren;Xiaoqiang Ren;Xiaofan Wang;S. Tejaswi Digumarti;Guodong Shi;Dafa Ren;Xiaoqiang Ren;Xiaofan Wang;S. Tejaswi Digumarti;Guodong Shi",
        "authorids": "/37089194910;/37085369550;/37281387900;/37085517244;/37529174400;/37089194910;/37085369550;/37281387900;/37085517244;/37529174400",
        "aff": "School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China; School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China; School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China; Sydney Institute for Robotics and Intelligent Systems, The University of Sydney, Sydney, NSW, Australia; Sydney Institute for Robotics and Intelligent Systems, The University of Sydney, Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636165/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18239705190116125639&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "Shanghai University;University of Sydney",
        "aff_unique_dep": "School of Mechatronic Engineering and Automation;Sydney Institute for Robotics and Intelligent Systems",
        "aff_unique_url": "https://www.shu.edu.cn;https://www.sydney.edu.au",
        "aff_unique_abbr": "SHU;USYD",
        "aff_campus_unique_index": "0;0;0;1;1",
        "aff_campus_unique": "Shanghai;Sydney",
        "aff_country_unique_index": "0;0;0;1;1",
        "aff_country_unique": "China;Australia"
    },
    {
        "id": "9636481",
        "title": "Feasibility of Remote Landmark Identification for Cricothyrotomy Using Robotic Palpation",
        "track": "main",
        "status": "Poster",
        "abstract": "Cricothyrotomy is a life-saving emergency intervention that secures an alternate airway route after a neck injury or obstruction. The procedure starts with identifying the correct location (the cricothyroid membrane) for creating an incision to insert an endotracheal tube. This location is determined using a combination of visual and palpation cues. Enabling robot-assisted remote cricothyrotomy may extend this life-saving procedure to injured soldiers or patients who may not be readily accessible for on-site intervention during search-and-rescue scenarios. As a first step towards achieving this goal, this paper explores the feasibility of palpation-assisted landmark identification for cricothyrotomy. Using a cricothyrotomy training simulator, we explore several alternatives for in-situ remote localization of the cricothyroid membrane. These alternatives include a) unaided telemanipulation, b) telemanipulation with direct force feedback, c) telemanipulation with superimposed motion excitation for on-line stiffness estimation and display, and d) fully autonomous palpation scan initialized based on the user\u2019s understanding of key anatomical landmarks. Using the manually digitized cricothyroid membrane location as ground truth, we compare these four methods for accuracy and repeatability of identifying the landmark for cricothyrotomy, time of completion, and ease of use. These preliminary results suggest that the accuracy of remote cricothyrotomy landmark identification is improved when the user is aided with visual and force cues. They also show that, with proper user initialization, landmark identification using remote palpation is feasible - therefore satisfying a key prerequisite for future robotic solutions for remote cricothyrotomy.",
        "primary_area": "",
        "author": "Neel Shihora;Rashid Yasin;Ryan Walsh;Nabil Simaan;Neel Shihora;Rashid Yasin;Ryan Walsh;Nabil Simaan",
        "authorids": "/37089194036;/37085521566;/37089197032;/37282380300;/37089194036;/37085521566;/37089197032;/37282380300",
        "aff": "Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Emergency Medicine, Vanderbilt University Medical Center, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636481/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2927001863328751069&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Vanderbilt University;Vanderbilt University Medical Center",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Emergency Medicine",
        "aff_unique_url": "https://www.vanderbilt.edu;https://www.vumc.org",
        "aff_unique_abbr": "Vanderbilt;VUMC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636756",
        "title": "Feature-aided Bundle Adjustment Learning Framework for Self-supervised Monocular Visual Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Bundle adjustment refines scene geometry and relative camera poses simultaneously via reprojection error, computed by a set of images from different viewpoints, which is the gold standard for visual odometry. However, deep learning methods have not been well exploited within this area of study. This paper introduces a self-supervised learning framework for monocular visual odometry, inside which depth maps, relative camera poses, and dense feature maps (with the same resolution as images) are estimated and used for photometric, geometric, and feature-metric losses in bundle adjustment. In this manner, we consider that the learning of neural networks can be geometrically constrained by multi-view geometry. Furthermore, bundle adjustment is only required during the training time, allowing the networks to benefit from bundle adjustment without any additional computation burden during the inference time. To stabilize the training process, we apply a two-stage strategy that yields promising results. Finally, we carefully select the neural network architectures to ensure efficiency, and experimental results demonstrate the success of our proposed approach in terms of visual odometry accuracy and high speed.",
        "primary_area": "",
        "author": "Weijun Mai;Yoshihiro Watanabe;Weijun Mai;Yoshihiro Watanabe",
        "authorids": "/37089196370;/37277581700;/37089196370;/37277581700",
        "aff": "Department of Information and Communications Engineering, School of Engineering, Tokyo Institute of Technology, Japan; Department of Information and Communications Engineering, School of Engineering, Tokyo Institute of Technology, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636756/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14765459437014354799&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tokyo Institute of Technology",
        "aff_unique_dep": "Department of Information and Communications Engineering",
        "aff_unique_url": "https://www.titech.ac.jp",
        "aff_unique_abbr": "Titech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636770",
        "title": "Few-leaf Learning: Weed Segmentation in Grasslands",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous robotic weeding in grasslands requires robust weed segmentation. Deep learning models can provide solutions to this problem, but they need to be trained on large amounts of images, which in the case of grasslands are notoriously difficult to obtain and manually annotate. In this work we introduce Few-leaf Learning, a concept that facilitates the training of accurate weed segmentation models and can lead to easier generation of weed segmentation datasets with minimal human annotation effort. Our approach builds upon the fact that each plant species within the same field has relatively uniform visual characteristics due to similar environmental influences. Thus, we can train a field-and-day-specific weed segmentation model on synthetic training data stemming from just a handful of annotated weed leaves. We demonstrate the efficacy of our approach for different fields and for two common grassland weeds: Rumex obtusifolius (broad-leaved dock) and Cirsium vulgare (spear thistle). Our code is publicly available at https://github.com/RGring/WeedAnnotator.",
        "primary_area": "",
        "author": "Ronja G\u00fcldenring;Evangelos Boukas;Ole Ravn;Lazaros Nalpantidis;Ronja G\u00fcldenring;Evangelos Boukas;Ole Ravn;Lazaros Nalpantidis",
        "authorids": "/37088687358;/38232071900;/37347201700;/37304022500;/37088687358;/38232071900;/37347201700;/37304022500",
        "aff": "Department of Electrical Engineering, DTU - Technical University of Denmark, Kgs. Lyngby, Denmark; Department of Electrical Engineering, DTU - Technical University of Denmark, Kgs. Lyngby, Denmark; Department of Electrical Engineering, DTU - Technical University of Denmark, Kgs. Lyngby, Denmark; Department of Electrical Engineering, DTU - Technical University of Denmark, Kgs. Lyngby, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636770/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2184504135653950601&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technical University of Denmark",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.dtu.dk",
        "aff_unique_abbr": "DTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Kgs. Lyngby",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9636072",
        "title": "Finding Failures in High-Fidelity Simulation using Adaptive Stress Testing and the Backward Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "Validating the safety of autonomous systems generally requires the use of high-fidelity simulators that adequately capture the variability of real-world scenarios. However, it is generally not feasible to exhaustively search the space of simulation scenarios for failures. Adaptive stress testing (AST) is a method that uses reinforcement learning to find the most likely failure of a system. AST with a deep reinforcement learning solver has been shown to be effective in finding failures across a range of different systems. This approach generally involves running many simulations, which can be very expensive when using a high-fidelity simulator. To improve efficiency, we present a method that first finds failures in a low-fidelity simulator. It then uses the backward algorithm, which trains a deep neural network policy using a single expert demonstration, to adapt the low-fidelity failures to high-fidelity. We have created a series of autonomous vehicle validation case studies that represent some of the ways low-fidelity and high-fidelity simulators can differ, such as time discretization. We demonstrate in a variety of case studies that this new AST approach is able to find failures with significantly fewer high-fidelity simulation steps than are needed when just running AST directly in high-fidelity. As a proof of concept, we also demonstrate AST on NVIDIA\u2019s DriveSim simulator, an industry state-of-the-art high-fidelity simulator for finding failures in autonomous vehicles.",
        "primary_area": "",
        "author": "Mark Koren;Ahmed Nassar;Mykel J. Kochenderfer;Mark Koren;Ahmed Nassar;Mykel J. Kochenderfer",
        "authorids": "/37086486968;/37085755624;/37596929200;/37086486968;/37085755624;/37596929200",
        "aff": "Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Ahmed Nassar is with NVIDIA, Santa Clara, CA, USA; Aeronautics and Astronautics, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636072/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2045846812767086908&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Stanford University;NVIDIA",
        "aff_unique_dep": "Aeronautics and Astronautics;NVIDIA",
        "aff_unique_url": "https://www.stanford.edu;https://www.nvidia.com",
        "aff_unique_abbr": "Stanford;NVIDIA",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Stanford;Santa Clara",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636516",
        "title": "Finding Robust 2D-to-3D Correspondence with LSTM Score Estimation for Camera Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "2D-to-3D correspondence estimation is the key step of 3D model-based image localization, and most of the existing research in this field focuses on improving the feature matching performance. Even with the best feature matching method, there are still some outliers, and thus, almost all the methods simply apply the RANSAC algorithm to select the inliers and estimate the camera pose afterwards. However, the reliability of RANSAC depends considerably on the inlier ratio. Once the inlier ratio decreases, for example a challenging scenario occurs, it will be unable to select the inliers well and lead to a worse camera pose. In this study, we attempted to build a neural network to learn the geometric relationship between 2D images and the 3D model to select the correct correspondence from the initial 2D-to-3D matching results to improve the performance of camera localization. Because the number of inputs, i.e., the number of 2D-to-3D correspondences, is unknown and different for each image, we propose a PointNet-based Geometric Consistency Network (GCC-Net) for the correct correspondence estimation and an LSTM-based Hypothesis Rating Network (HR-Net) to enhance GCC-Net with the camera localization loss. Experimental results showed that the proposed method outperforms RANSAC considerably on the camera pose estimation, particularly when the inlier ratio of the initial correspondence was low.",
        "primary_area": "",
        "author": "Tsu-Kuan Huang;Po-Heng Chen;Li-Yang Wang;Kuan-Wen Chen;Tsu-Kuan Huang;Po-Heng Chen;Li-Yang Wang;Kuan-Wen Chen",
        "authorids": "/37089197842;/37088434052;/37089194517;/37557502900;/37089197842;/37088434052;/37089194517;/37557502900",
        "aff": "Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Electronic Engineering, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636516/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:WVQxU_KIGqAJ:scholar.google.com/&scioq=Finding+Robust+2D-to-3D+Correspondence+with+LSTM+Score+Estimation+for+Camera+Localization&hl=en&as_sdt=0,14",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Yang Ming Chiao Tung University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nctu.edu.tw",
        "aff_unique_abbr": "NYCU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636086",
        "title": "Finding Structure Configurations for Flying Modular Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Flying Modular Structures offer a versatile mechanism that can change the arrangement of constituent actuators according to task requirements. In this work, we extend a modular aerial platform that can expand its actuation capabilities depending on the configuration. Each module is composed of a quadrotor in a cage that can rigidly connect with other modules. The quadrotor is connected with the cage by a revolute joint that allows it to rotate with respect to the cage. Modules located in the structure are either parallel or perpendicular to one another. The task specification defines forces and moments needed during the execution. We propose two search methods to find a configuration that can satisfy the specification. The first approach consists of an exhaustive search that yields optimal structure configurations by exploring the whole search space. The second approach proposes a heuristic based on subgroup search, reducing the problem complexity from exponential to linear. We validate our proposed algorithms with several simulations. Our results show that the proposed heuristic is computationally efficient and finds a near-optimal configuration even for flying modular structures composed of a large number of modules.",
        "primary_area": "",
        "author": "Bruno Gabrich;David Salda\u00f1a;Mark Yim;Bruno Gabrich;David Salda\u00f1a;Mark Yim",
        "authorids": "/37086297954;/38543033800;/37274063600;/37086297954;/38543033800;/37274063600",
        "aff": "GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; Autonomous and Intelligent Robotics Laboratory -AIRLab-, Lehigh University, Bethlehem, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636086/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17625645729781144148&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Pennsylvania;Lehigh University",
        "aff_unique_dep": "GRASP Laboratory;Autonomous and Intelligent Robotics Laboratory -AIRLab-",
        "aff_unique_url": "https://www.upenn.edu;https://www.lehigh.edu",
        "aff_unique_abbr": "UPenn;Lehigh",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Philadelphia;Bethlehem",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636033",
        "title": "Fine-Grained Off-Road Semantic Segmentation and Mapping via Contrastive Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Road detection or traversability analysis has been a key technique for a mobile robot to traverse complex off-road scenes. The problem has been mainly formulated in early works as a binary classification one, e.g. associating pixels with road or non-road labels. Whereas understanding scenes with fine-grained labels are needed for off-road robots, as scenes are very diverse, and the various mechanical performance of off-road robots may lead to different definitions of safe regions to traverse. How to define and annotate fine-grained labels to achieve meaningful scene understanding for a robot to traverse off-road is still an open question. This research proposes a contrastive learning based method. With a set of human-annotated anchor patches, a feature representation is learned to discriminate regions with different traversability, a method of fine-grained semantic segmentation and mapping is subsequently developed for off-road scene understanding. Experiments are conducted on a dataset of three driving segments that represent very diverse off-road scenes. An anchor accuracy of 89.8% is achieved by evaluating the matching with human-annotated image patches in cross-scene validation. Examined by associated 3D LiDAR data, the fine-grained segments of visual images are demonstrated to have different levels of toughness and terrain elevation, which represents their semantical meaningfulness. The resultant maps contain both fine-grained labels and confidence values, providing rich information to support a robot traversing complex off-road scenes.",
        "primary_area": "",
        "author": "Biao Gao;Shaochi Hu;Xijun Zhao;Huijing Zhao;Biao Gao;Shaochi Hu;Xijun Zhao;Huijing Zhao",
        "authorids": "/37086964054;/37087103020;/37539423000;/37290336200;/37086964054;/37087103020;/37539423000;/37290336200",
        "aff": "Key Lab of Machine Perception (MOE), Peking University, Beijing, China; Key Lab of Machine Perception (MOE), Peking University, Beijing, China; China North Vehicle Research Institute, Beijing, China; Key Lab of Machine Perception (MOE), Peking University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636033/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15710001964887095645&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Peking University;China North Vehicle Research Institute",
        "aff_unique_dep": "Key Lab of Machine Perception (MOE);",
        "aff_unique_url": "http://www.pku.edu.cn;",
        "aff_unique_abbr": "PKU;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636445",
        "title": "FloMo: Tractable Motion Prediction with Normalizing Flows",
        "track": "main",
        "status": "Poster",
        "abstract": "The future motion of traffic participants is inherently uncertain. To plan safely, therefore, an autonomous agent must take into account multiple possible trajectory outcomes and prioritize them. Recently, this problem has been addressed with generative neural networks. However, most generative models either do not learn the true underlying trajectory distribution reliably, or do not allow predictions to be associated with likelihoods. In our work, we model motion prediction directly as a density estimation problem with a normalizing flow between a noise distribution and the future motion distribution. Our model, named FloMo, allows likelihoods to be computed in a single network pass and can be trained directly with maximum likelihood estimation. Furthermore, we propose a method to stabilize training flows on trajectory datasets and a new data augmentation transformation that improves the performance and generalization of our model. Our method achieves state-of-the-art performance on three popular prediction datasets, with a significant gap to most competing models.",
        "primary_area": "",
        "author": "Christoph Sch\u00f6ller;Alois Knoll;Christoph Sch\u00f6ller;Alois Knoll",
        "authorids": "/37087105852;/37276234100;/37087105852;/37276234100",
        "aff": "Research Institute of the Free State of Bavaria, Fortiss GmbH, Munich, Germany; The Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636445/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4246125806579807305&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Research Institute of the Free State of Bavaria;Technical University of Munich",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.tum.de",
        "aff_unique_abbr": ";TUM",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Munich",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636183",
        "title": "Flocking and Collision Avoidance for a Dynamic Squad of Fixed-Wing UAVs Using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Developing the flocking behavior for a dynamic squad of fixed-wing UAVs is still a challenge due to kinematic complexity and environmental uncertainty. In this paper, we deal with the decentralized flocking and collision avoidance problem through deep reinforcement learning (DRL). Specifically, we formulate a decentralized DRL-based decision making framework from the perspective of every follower, where a collision avoidance mechanism is integrated into the flocking controller. Then, we propose a novel reinforcement learning algorithm PS-CACER for training a shared control policy for all the followers. Besides, we design a plug-n-play embedding module based on convolutional neural networks and the attention mechanism. As a result, the variable-length system state can be encoded into a fixed-length embedding vector, which makes the learned DRL policy independent with the number and the order of followers. Finally, numerical simulation results demonstrate the effectiveness of the proposed method, and the learned policies can be directly transferred to semi-physical simulation without any parameter finetuning.",
        "primary_area": "",
        "author": "Chao Yan;Xiaojia Xiang;Chang Wang;Zhen Lan;Chao Yan;Xiaojia Xiang;Chang Wang;Zhen Lan",
        "authorids": "/37086440285;/37085698451;/37086476067;/37088935031;/37086440285;/37085698451;/37086476067;/37088935031",
        "aff": "College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636183/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16300535729896413972&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National University of Defense Technology",
        "aff_unique_dep": "College of Intelligence Science and Technology",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Changsha",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636027",
        "title": "Force Control With Friction Compensation In A Pneumatic Gripper",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots can grasp, even manipulate, objects with different shape, weight and size thanks to the their end-effectors. These are mostly constituted by two fingers, and are known as grippers. However, despite being quite simple for human beings, manipulation is not so straightforward to carry out on robotic systems. One of the main obstacles is the lack of reliable control methods: this is especially true for pneumatic grippers. Such devices are often mounted on industrial robots, though their behavior does not go beyond basic fully-open or fully-closed operations. This happens also as a consequence of the incapability of taking into account frictional effects limiting the pneumatic gripper performance. In this article, a new control strategy is delivered to solve this issue. The proposed strategy allows controlling the grasping force of a pneumatic gripper, without performance degradation due to friction. A pneumatic gripper was built and instrumented with several sensors to experimentally validate the proposed control strategy. The gripper was mechanically connected to a robotic arm and tested with different desired force profiles upon a wide range of force.",
        "primary_area": "",
        "author": "Rocco A. Romeo;Agata Zocco;Luca Fiorio;Daniele Pucci;M. Maggiali;Rocco A. Romeo;Agata Zocco;Luca Fiorio;Daniele Pucci;M. Maggiali",
        "authorids": "/37085705883;/37089194471;/37085446877;/37706167200;/37295800800;/37085705883;/37089194471;/37085446877;/37706167200;/37295800800",
        "aff": "iCub Tech Facility, Istituto Italiano di Tecnologia, Genoa, Italy; iCub Tech Facility, Istituto Italiano di Tecnologia, Genoa, Italy; iCub Tech Facility, Istituto Italiano di Tecnologia, Genoa, Italy; Dynamic Interaction Control, Istituto Italiano di Tecnologia, Genoa, Italy; iCub Tech Facility, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636027/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6171828519054842871&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "iCub Tech Facility",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636632",
        "title": "Force feedback on hand rest function in master manipulator for robotic surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "In robotic surgeries employing the master-slave operation scheme, various haptic devices have been adopted as master manipulators. The main challenge of the haptic device is to contribute to a sensitive reaction to external forces for operators. Since force perception on fingertips is impaired by unstable entire hand condition, stable hand condition helps to improve force perception. This study proposed a master manipulator that enables a force feedback at the gripping fingertips on a stable hand condition with a hand rest function. In this framework, the hand rest function was realized by switching the impedance value in admittance control for the translation section of the master manipulator and the displaying force was generated based on the pivot point, which depends on only the movement of the translation section. With master-slave operation, an 8-drawing experiment was performed under multiple force feedback and hand conditions after evaluating the effectiveness of a hand rest on sensitivity for external force in a preliminary experiment. The results showed that the hand rest function contributed to effective force feedback.",
        "primary_area": "",
        "author": "Solmon Jeong;Kotaro Tadano;Solmon Jeong;Kotaro Tadano",
        "authorids": "/37088504011;/37294712000;/37088504011;/37294712000",
        "aff": "Engineering Department, Tokyo Institute of Technology, Japan; Laboratory for Future Interdisciplinary Research of Science and Technology, Tokyo Institute of Technology, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636632/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4288638541911711190&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tokyo Institute of Technology",
        "aff_unique_dep": "Engineering Department",
        "aff_unique_url": "https://www.titech.ac.jp",
        "aff_unique_abbr": "Titech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636453",
        "title": "Force-based Formation Control of Omnidirectional Ground Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Formation control of multi-robot systems has been largely studied due to its wide application domain. Several methods in the literature rely on explicit communication among the robots, which in realistic scenarios may lead to reduced performance or even instability due to delays and packet loss or corruption. Nonetheless, multi-robot coordination based solely on implicit communication has been proposed in cooperative manipulation problems. Taking inspiration from this, we propose a method to solve the formation control problem for a group of ground robots not relying on direct communication among them. Instead, the robots are physically constrained to a common object through elastic cables in order to exploit forces as a means of indirect communication. After deriving the dynamic equations, the control and planning approaches are explained, and the stability of the controlled system is discussed using Lyapunov\u2019s stability theory. Numerical simulations are presented to support the method.",
        "primary_area": "",
        "author": "Chiara Gabellieri;Alessandro Palleschi;Lucia Pallottino;Chiara Gabellieri;Alessandro Palleschi;Lucia Pallottino",
        "authorids": "/37086361091;/37086919526;/37278580100;/37086361091;/37086919526;/37278580100",
        "aff": "Department of Information Engineering, Research Center \"E. Piaggio\", University of Pisa; Department of Information Engineering, Research Center \"E. Piaggio\", University of Pisa; Department of Information Engineering, Research Center \"E. Piaggio\", University of Pisa",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636453/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2053677489270972283&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pisa",
        "aff_unique_dep": "Department of Information Engineering",
        "aff_unique_url": "https://www.unipi.it",
        "aff_unique_abbr": "UNipi",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636634",
        "title": "Force-feedback based Whole-body Stabilizer for Position-Controlled Humanoid Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies stabilizer design for position-controlled humanoid robots. Stabilizers are an essential part for position-controlled humanoids, whose primary objective is to adjust the control input sent to the robot to assist the tracking controller to better follow the planned reference trajectory. To achieve this goal, this paper develops a novel force-feedback based whole-body stabilizer that fully exploits the six-dimensional force measurement information and the whole-body dynamics to improve tracking performance. Relying on rigorous analysis of whole-body dynamics of position-controlled humanoids under unknown contact, the developed stabilizer leverages quadratic-programming based technique that allows cooperative consideration of both the center-of-mass tracking and contact force tracking. The effectiveness of the proposed stabilizer is demonstrated on the UBTECH Walker robot in the MuJoCo simulator. Simulation validations show a significant improvement in various scenarios as compared to commonly adopted stabilizers based on the zero-moment-point feedback and the linear inverted pendulum model.",
        "primary_area": "",
        "author": "Shunpeng Yang;Hua Chen;Zhen Fu;Wei Zhang;Shunpeng Yang;Hua Chen;Zhen Fu;Wei Zhang",
        "authorids": "/37088996360;/37086195529;/37089197822;/37089656248;/37088996360;/37086195529;/37089197822;/37089656248",
        "aff": "Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636634/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6993536690019640133&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical and Energy Engineering",
        "aff_unique_url": "https://www.sustech.edu.cn",
        "aff_unique_abbr": "SUSTech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635951",
        "title": "Formalizing Trajectories in Human-Robot Encounters via Probabilistic STL Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we are interested in formalizing human trajectories in human-robot encounters. We consider a particular case where a human and a robot walk towards each other. A question that arises is whether, when, and how humans will deviate from their trajectory to avoid a collision. These human trajectories can then be used to generate socially acceptable robot trajectories. To model these trajectories, we propose a data-driven algorithm to extract a formal specification expressed in Signal Temporal Logic with probabilistic predicates. We evaluated our method on trajectories collected through an online study where participants had to avoid colliding with a robot in a shared environment. Further, we demonstrate that probabilistic STL is a suitable formalism to depict human behavior, choices and preferences in specific scenarios of social navigation.",
        "primary_area": "",
        "author": "Alexis Linard;Ilaria Torre;Anders Steen;Iolanda Leite;Jana Tumova;Alexis Linard;Ilaria Torre;Anders Steen;Iolanda Leite;Jana Tumova",
        "authorids": "/37087051755;/38228000400;/37089197103;/38576988500;/38230312900;/37087051755;/38228000400;/37089197103;/38576988500;/38230312900",
        "aff": "Division of Robotics, Perception and Learning and are Also Affiliated With Digital Future, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning and are Also Affiliated With Digital Future, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning and are Also Affiliated With Digital Future, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning and are Also Affiliated With Digital Future, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning and are Also Affiliated With Digital Future, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635951/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8379648132726550875&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "Division of Robotics, Perception and Learning",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9636129",
        "title": "Formalizing the Execution Context of Behavior Trees for Runtime Verification of Deliberative Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we enable automated property verification of deliberative components in robot control architectures. We focus on formalizing the execution context of Behavior Trees (BTs) to provide a scalable, yet formally grounded, methodology to enable runtime verification and prevent unexpected robot behaviors. To this end, we consider a message-passing model that accommodates both synchronous and asynchronous composition of parallel components, in which BTs and other components execute and interact according to the communication patterns commonly adopted in robotic software architectures. We introduce a formal property specification language to encode requirements and build runtime monitors. We performed a set of experiments, both on simulations and on the real robot, demonstrating the feasibility of our approach in a realistic application and its integration in a typical robot software architecture. We also provide an OS-level virtualization environment to reproduce the experiments in the simulated scenario.",
        "primary_area": "",
        "author": "Michele Colledanchise;Giuseppe Cicala;Daniele E. Domenichelli;Lorenzo Natale;Armando Tacchella;Michele Colledanchise;Giuseppe Cicala;Daniele E. Domenichelli;Lorenzo Natale;Armando Tacchella",
        "authorids": "/37085361393;/37089198138;/37085741193;/37542770000;/37299588700;/37085361393;/37089198138;/37085741193;/37542770000;/37299588700",
        "aff": "Istituto Italiano di Tecnologia, Genova; DIBRIS, Universit\u00e0 degli Studi di Genova; Istituto Italiano di Tecnologia, Genova; Istituto Italiano di Tecnologia, Genova; DIBRIS, Universit\u00e0 degli Studi di Genova",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636129/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9130759050981373680&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;Universit\u00e0 degli Studi di Genova",
        "aff_unique_dep": ";DIBRIS",
        "aff_unique_url": "https://www.iit.it;https://www.unige.it",
        "aff_unique_abbr": "IIT;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Genova;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636154",
        "title": "From Aerobatics to Hydrobatics: Agile Trajectory Planning and Tracking for Micro Underwater Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerobatic quadrotors have been a very active field of research for the last two decades. Their huge community boosted the development of computational light-weight planning and control algorithms. In contrast and despite recent progress, research on agile micro autonomous underwater vehicles (\u00b5AUV) is still in its infancy. Both vehicle classes share a close relationship. They achieve high speeds of multiple bodylengths per second. At the same time they are subject to limited onboard resources such as sensors and computing power.In this work, we explore and exploit the potential synergies between aerobatic drones and hydrobatic \u00b5AUVs. In order to demonstrate the possible transfer of concepts we build on a state-of-the-art quadrotor trajectory planning framework and extend it to incorporate hydrodynamic effects. Furthermore, we study in a series of experiments the performance of the transferred concepts and show that various quadrotor simplifications match well for hydrobatic \u00b5AUVs.",
        "primary_area": "",
        "author": "Daniel A Duecker;Christian Horst;Edwin Kreuzer;Daniel A Duecker;Christian Horst;Edwin Kreuzer",
        "authorids": "/37086262227;/37089197428;/37622316900;/37086262227;/37089197428;/37622316900",
        "aff": "Hamburg University of Technology, Germany; Hamburg University of Technology, Germany; Hamburg University of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636154/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5225793761652847260&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hamburg University of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tuhh.de/",
        "aff_unique_abbr": "TUHH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636402",
        "title": "From Agile Ground to Aerial Navigation: Learning from Learned Hallucination",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a self-supervised Learning from Learned Hallucination (LfLH) method to learn fast and reactive motion planners for ground and aerial robots to navigate through highly constrained environments. The recent Learning from Hallucination (LfH) paradigm for autonomous navigation executes motion plans by random exploration in completely safe obstacle-free spaces, uses hand-crafted hallucination techniques to add imaginary obstacles to the robot\u2019s perception, and then learns motion planners to navigate in realistic, highly-constrained, dangerous spaces. However, current hand-crafted hallucination techniques need to be tailored for specific robot types (e.g., a differential drive ground vehicle), and use approximations heavily dependent on certain assumptions (e.g., a short planning horizon). In this work, instead of manually designing hallucination functions, LfLH learns to hallucinate obstacle configurations, where the motion plans from random exploration in open space are optimal, in a self-supervised manner. LfLH is robust to different robot types and does not make assumptions about the planning horizon. Evaluated in both simulated and physical environments with a ground and an aerial robot, LfLH outperforms or performs comparably to previous hallucination approaches, along with sampling- and optimization-based classical methods.",
        "primary_area": "",
        "author": "Zizhao Wang;Xuesu Xiao;Alexander J Nettekoven;Kadhiravan Umasankar;Anika Singh;Sriram Bommakanti;Ufuk Topcu;Peter Stone;Zizhao Wang;Xuesu Xiao;Alexander J Nettekoven;Kadhiravan Umasankar;Anika Singh;Sriram Bommakanti;Ufuk Topcu;Peter Stone",
        "authorids": "/37088943546;/37086258082;/37087995402;/37089196633;/37089198289;/37089197687;/37299604900;/37269574900;/37088943546;/37086258082;/37087995402;/37089196633;/37089198289;/37089197687;/37299604900;/37269574900",
        "aff": "Department of Electrical and Computer Engineering; Computer Science; Mechanical Engineering; Aerospace Engineering and Engineering Mechanics, University of Texas at Austin, Austin, Texas; Department of Electrical and Computer Engineering; Aerospace Engineering and Engineering Mechanics, University of Texas at Austin, Austin, Texas; Aerospace Engineering and Engineering Mechanics, University of Texas at Austin, Austin, Texas; Sony AI.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636402/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15389436336793596981&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;3;0;3;3;4",
        "aff_unique_norm": "Unknown Institution;Computer Science;Mechanical Engineering;University of Texas at Austin;Sony AI",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Computer Science Department;Department of Mechanical Engineering;Aerospace Engineering and Engineering Mechanics;Sony AI",
        "aff_unique_url": ";;;https://www.utexas.edu;https://ai.sony",
        "aff_unique_abbr": ";;;UT Austin;Sony AI",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "1;1;1;2",
        "aff_country_unique": ";United States;Japan"
    },
    {
        "id": "9636631",
        "title": "Fully-Online Always-Adaptation of Transfer Functions and Its Application to Sound Source Localization and Separation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses fully-online always-adaptation of a transfer function for robot audition systems based on microphone array processing. The transfer function represents signal propagation characteristics between a microphone and a sound source, which provides essential information for real-world scene analysis, such as sound source localization and separation for robots. Although it is commonly defined as a stationary function, it should be considered together with room acoustics and their environmental changes for practical use, that is, it should be defined as a dynamically-changing function. To fulfill this requirement, we propose a fully-online always-adaptation method for a transfer function, by continuously estimating the transfer function from the observed signals in a passive manner, while performing sound source localization and separation. The proposed method was implemented on open source robot audition software HARK as modules which works online. These modules are applied to sound source localization and separation which are primary functions in robot audition. Experimental results showed that the proposed method successfully adapted to an office environment and improved the performance of sound source localization and separation at a close level to the transfer function recorded in the room.",
        "primary_area": "",
        "author": "Kazuhiro Nakadai;Masayuki Takigahira;Yusuke Kawai;Hirofumi Nakajima;Kazuhiro Nakadai;Masayuki Takigahira;Yusuke Kawai;Hirofumi Nakajima",
        "authorids": "/37274046900;/37089196782;/37089194424;/37555790500;/37274046900;/37089196782;/37089194424;/37555790500",
        "aff": "School of Engineering, Tokyo Institute of Technology; Honda Research Institute Japan Co., Ltd., Saitama, JAPAN; Department of Computer Science, Kogakuin University; Department of Computer Science, Kogakuin University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636631/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13367252492041781283&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "Tokyo Institute of Technology;Honda Research Institute Japan Co., Ltd.;Kogakuin University",
        "aff_unique_dep": "School of Engineering;;Department of Computer Science",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.honda-ri.jp/english/;https://www.kogakuin.ac.jp",
        "aff_unique_abbr": "Titech;HRI-JP;Kogakuin",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Saitama",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636383",
        "title": "Fundamental Challenges in Deep Learning for Stiff Contact Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Frictional contact has been extensively studied as the core underlying behavior of legged locomotion and manipulation, and its nearly-discontinuous nature makes planning and control difficult even when an accurate model of the robot is available. Here, we present empirical evidence that learning an accurate model in the first place can be confounded by contact, as modern deep learning approaches are not designed to capture this non-smoothness. We isolate the effects of contact\u2019s non-smoothness by varying the mechanical stiffness of a compliant contact simulator. Even for a simple system, we find that stiffness alone dramatically degrades training processes, generalization, and data-efficiency. Our results raise serious questions about simulated testing environments which do not accurately reflect the stiffness of rigid robotic hardware. Significant additional investigation will be necessary to fully understand and mitigate these effects, and we suggest several avenues for future study.",
        "primary_area": "",
        "author": "Mihir Parmar;Mathew Halm;Michael Posa;Mihir Parmar;Mathew Halm;Michael Posa",
        "authorids": "/37089500038;/37089196898;/37085767813;/37089500038;/37089196898;/37085767813",
        "aff": "GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636383/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2129558810940225045&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636425",
        "title": "Fuzzy PID Controller Based on Yaw Angle Prediction of a Spherical Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a fuzzy PID controller based on yaw angle prediction is applied to design an attitude controller for a spherical rolling robot. The robot consists of a 2-DOF pendulum located inside a spherical shell with freedom to rotate about the transversal and longitudinal axis. The proposed controller allows the robot to autonomously change its parameters to adapt to different environments based on current state. The past researches on the motion of spherical robots mostly focused on simulation or ideal experimental environment. But in this paper, a physical system is built and experiments are carried out to demonstrate the effectiveness, robustness and adaptability of the controller.",
        "primary_area": "",
        "author": "Yixu Wang;Xiaoqing Guan;Tao Hu;Ziang Zhang;You Wang;Zhan Wang;Yifan Liu;Guang Li;Yixu Wang;Xiaoqing Guan;Tao Hu;Ziang Zhang;You Wang;Zhan Wang;Yifan Liu;Guang Li",
        "authorids": "/37089196303;/37087031077;/37089194102;/37089195414;/37087030858;/37087030838;/37089195420;/37336261300;/37089196303;/37087031077;/37089194102;/37089195414;/37087030858;/37087030838;/37089195420;/37336261300",
        "aff": "State Key Laboratory of Industrial Control Technology, Institute of Cyber Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber Systems and Control, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636425/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8886064871767788513&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology, Institute of Cyber Systems and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636173",
        "title": "Fuzzy-Depth Objects Grasping Based on FSG Algorithm and a Soft Robotic Hand",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous grasping is an important factor for robots physically interacting with the environment and executing versatile tasks. However, a universally applicable, cost-effective, and rapidly deployable autonomous grasping approach is still limited by those target objects with fuzzy-depth information. Examples are transparent, specular, flat, and small objects whose depth is difficult to be accurately sensed. In this work, we present a solution to those fuzzy-depth objects. The framework of our approach includes two major components: one is a soft robotic hand and the other one is a Fuzzy-depth Soft Grasping (FSG) algorithm. The soft hand is replaceable for most existing soft hands/grippers with body compliance. FSG algorithm exploits both RGB and depth images to predict grasps while not trying to reconstruct the whole scene. Two grasping primitives are designed to further increase robustness. The proposed method outperforms reference baselines in unseen fuzzy-depth objects grasping experiments (84% success rate).",
        "primary_area": "",
        "author": "Hanwen Cao;Junda Huang;Yichuan Li;Jianshu Zhou;Yunhui Liu;Hanwen Cao;Junda Huang;Yichuan Li;Jianshu Zhou;Yunhui Liu",
        "authorids": "/37088951247;/37088953080;/37089195434;/37086011742;/37279412600;/37088951247;/37088953080;/37089195434;/37086011742;/37279412600",
        "aff": "The Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, HKSAR, China; The Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, HKSAR, China; The Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong, HKSAR, China; Hong Kong Center for Logistics Robotics (HKCLR); Hong Kong Center for Logistics Robotics (HKCLR)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636173/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14944252516714965687&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "Chinese University of Hong Kong;Hong Kong Center for Logistics Robotics",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;",
        "aff_unique_url": "https://www.cuhk.edu.hk;",
        "aff_unique_abbr": "CUHK;HKCLR",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636009",
        "title": "GPU-Accelerated Rapid Planar Region Extraction for Dynamic Behaviors on Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged robots require fast and accurate representation of their surrounding terrain to achieve behaviors such as running, push recovery, continuous walking, backflips, while also utilizing on-board computational resources efficiently. The desired tasks can be achieved efficiently by representing the environment using planar regions. However, existing methods for planar region extraction are either too slow or require significant compute time on the Central Processing Unit (CPU). In this work we exploit key properties of depth images and Graphical Processing Unit (GPU) to estimate planar regions around the robot at very high frame rates of 150-200 Hz. The proposed algorithm uses a set of fully customizable and interchangeable set of kernel layers on the GPU to process the depth map in parallel and generate a locally connected graph structure, which is later separated into planar components using a basic depth-first search. We test the proposed algorithm on the Atlas robot while performing different walking behaviors on oriented cinder blocks, as well as in simulation with simulated sensor and robot. The algorithm is open-sourced for research on legged robots and other fields.",
        "primary_area": "",
        "author": "Bhavyansh Mishra;Duncan Calvert;Sylvain Bertrand;Stephen McCrory;Robert Griffin;Hakki Erhan Sevil;Bhavyansh Mishra;Duncan Calvert;Sylvain Bertrand;Stephen McCrory;Robert Griffin;Hakki Erhan Sevil",
        "authorids": "/37086319200;/37088689927;/37089144753;/37085793385;/37085631429;/38073914300;/37086319200;/37088689927;/37089144753;/37085793385;/37085631429;/38073914300",
        "aff": "Florida Institute for Human and Machine Cognition, Pensacola, FL, United States; Florida Institute for Human and Machine Cognition, Pensacola, FL, United States; Florida Institute for Human and Machine Cognition, Pensacola, FL, United States; Florida Institute for Human and Machine Cognition, Pensacola, FL, United States; Florida Institute for Human and Machine Cognition, Pensacola, FL, United States; University of West Florida, Pensacola, FL, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636009/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5809906572756213377&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Florida Institute for Human and Machine Cognition;University of West Florida",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.uwf.edu",
        "aff_unique_abbr": ";UWF",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pensacola",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636232",
        "title": "GR-Fusion: Multi-sensor Fusion SLAM for Ground Robots with High Robustness and Low Drift",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a tightly coupled pipeline, which efficiently fuses measurements of LiDAR, camera, IMU, encoder, and GNSS to estimate the robot state and build a map even in challenging situations. The depth of visual features is extracted by projecting the LiDAR point cloud and ground plane into image. We select the tracked high-quality visual features and LiDAR features and tightly coupled the pre-integrated values of the IMU and the encoder to optimize the state increment of a robot. We use the estimated relative pose to re-evaluate the matching distance between features in the local window and remove dynamic objects and outliers. In the mapping node, we use refined features and tightly coupled the GNSS measurements, increment factors, and local ground constraints to further refine the robot\u2019s global state by aligning LiDAR features with the global map. Furthermore, the method can detect sensor degradation and automatically reconfigure the optimization process. Based on a six-wheeled ground robot, we perform extensive experiments in both indoor and outdoor environments and demonstrated that the proposed GR-Fusion outperforms state-of-the-art SLAM methods in terms of accuracy and robustness.",
        "primary_area": "",
        "author": "Ting Wang;Yun Su;Shiliang Shao;Chen Yao;Zhidong Wang;Ting Wang;Yun Su;Shiliang Shao;Chen Yao;Zhidong Wang",
        "authorids": "/37089656404;/37087235421;/37088689417;/37687111800;/37279258300;/37089656404;/37087235421;/37088689417;/37687111800;/37279258300",
        "aff": "Shenyang Institute of Automation, Institutes for Robotics and Intelligent Manufacturing, State Key Laboratory of Robotics, Chinese Academy of Sciences, Shenyang, China; Guangzhou Shiyuan Electronic Technology Company Limited, Guangzhou, China; Shenyang Institute of Automation, Institutes for Robotics and Intelligent Manufacturing, State Key Laboratory of Robotics, Chinese Academy of Sciences, Shenyang, China; Shenyang Institute of Automation, Institutes for Robotics and Intelligent Manufacturing, State Key Laboratory of Robotics, Chinese Academy of Sciences, Shenyang, China; Department of Advanced Robotics, Chiba Institute of Technology, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636232/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8330685943247984098&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "Shenyang Institute of Automation;Guangzhou Shiyuan Electronic Technology Company Limited;Chiba Institute of Technology",
        "aff_unique_dep": "Institutes for Robotics and Intelligent Manufacturing;;Department of Advanced Robotics",
        "aff_unique_url": "http://www.sia.cas.cn;;https://www.chibatech.ac.jp",
        "aff_unique_abbr": "SIA;;",
        "aff_campus_unique_index": "0;0;0;2",
        "aff_campus_unique": "Shenyang;;Chiba",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9636279",
        "title": "GRIT: Fast, Interpretable, and Verifiable Goal Recognition with Learned Decision Trees for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "It is important for autonomous vehicles to have the ability to infer the goals of other vehicles (goal recognition), in order to safely interact with other vehicles and predict their future trajectories. This is a difficult problem, especially in urban environments with interactions between many vehicles. Goal recognition methods must be fast to run in real time and make accurate inferences. As autonomous driving is safety- critical, it is important to have methods which are human interpretable and for which safety can be formally verified. Existing goal recognition methods for autonomous vehicles fail to satisfy all four objectives of being fast, accurate, interpretable and verifiable. We propose Goal Recognition with Interpre table Trees (GRIT), a goal recognition system which achieves these objectives. GRIT makes use of decision trees trained on vehicle trajectory data. We evaluate GRIT on two datasets, showing that GRIT achieved fast inference speed and comparable accuracy to two deep learning baselines, a planning-based goal recognition method, and an ablation of GRIT. We show that the learned trees are human interpretable and demonstrate how properties of GRIT can be formally verified using a satisfiability modulo theories (SMT) solver.",
        "primary_area": "",
        "author": "Cillian Brewitt;Balint Gyevnar;Samuel Garcin;Stefano V. Albrecht;Cillian Brewitt;Balint Gyevnar;Samuel Garcin;Stefano V. Albrecht",
        "authorids": "/37088995850;/37088998776;/37089194248;/37088996736;/37088995850;/37088998776;/37089194248;/37088996736",
        "aff": "School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; Five AI Ltd., UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636279/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=582916886895430998&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Edinburgh;Five AI Ltd.",
        "aff_unique_dep": "School of Informatics;",
        "aff_unique_url": "https://www.ed.ac.uk;",
        "aff_unique_abbr": "Edinburgh;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Edinburgh;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9635973",
        "title": "Gamma-Ray Imaging with Spatially Continuous Intensity Statistics",
        "track": "main",
        "status": "Poster",
        "abstract": "Novel methods for the inference of radiation intensity functions defined over known surfaces are proposed, intended for use in surveying applications with mobile spectrometers. Previous approaches, based on the maximum likelihood expectation maximization (ML-EM) framework with Poisson likelihoods, are extended to better handle spatially continuous intensity statistics using ideas from Gaussian filtering. The resulting algorithm is evaluated against a classical ML-EM method, and a recently proposed sparse additive point source localization (APSL) algorithm in a Monte-Carlo simulation study. The new generalized ASPL (GASPL) is shown to compare favorably in terms of estimation accuracy when the true intensity is not well described by a set of point sources. Finally, the GASPL is used in an experiment where a detector is mounted to an unmanned aerial vehicle to estimate the intensity and location of radioactive sources placed in a meadow.",
        "primary_area": "",
        "author": "Marcus Greiff;Emil Rofors;Anders Robertsson;Rolf Johansson;Rikard Tyllstr\u00f6m;Marcus Greiff;Emil Rofors;Anders Robertsson;Rolf Johansson;Rikard Tyllstr\u00f6m",
        "authorids": "/37086424520;/37089194173;/37301201800;/37301199800;/37089195783;/37086424520;/37089194173;/37301201800;/37301199800;/37089195783",
        "aff": "Department of Automatic Control, LU; Department of Nuclear Physics, LU; Department of Automatic Control, LU; Department of Automatic Control, LU; School of Aviation, LU",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635973/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13343609627149662755&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Lund University",
        "aff_unique_dep": "Department of Automatic Control",
        "aff_unique_url": "https://www.lth.se/inst/autkon/",
        "aff_unique_abbr": "LU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9636207",
        "title": "GateNet: An Efficient Deep Neural Network Architecture for Gate Perception Using Fish-Eye Camera in Autonomous Drone Racing",
        "track": "main",
        "status": "Poster",
        "abstract": "Fast and robust gate perception is of great importance in autonomous drone racing. We propose a convolutional neural network-based gate detector (GateNet1) that concurrently detects gate\u2019s center, distance, and orientation with respect to the drone using only images from a single fish-eye RGB camera. GateNet achieves a high inference rate (up to 60 Hz) on an onboard processor (Jetson TX2). Moreover, GateNet is robust to gate pose changes and background disturbances. The proposed perception pipeline leverages a fish-eye lens with a wide field-of-view and thus can detect multiple gates in close range, allowing a longer planning horizon even in tight environments. For benchmarking, we propose a comprehensive dataset (AU-DR) that focuses on gate perception. Throughout the experiments, GateNet shows its superiority when compared to similar methods while being efficient for onboard computers in autonomous drone racing. The effectiveness of the proposed framework is tested on a fully-autonomous drone that flies on previously-unknown track with tight turns and varying gate positions and orientations in each lap.",
        "primary_area": "",
        "author": "Huy Xuan Pham;Ilker Bozcan;Andriy Sarabakha;Sami Haddadin;Erdal Kayacan;Huy Xuan Pham;Ilker Bozcan;Andriy Sarabakha;Sami Haddadin;Erdal Kayacan",
        "authorids": "/37086293929;/37086455563;/37085894614;/37542865300;/37595300900;/37086293929;/37086455563;/37085894614;/37542865300;/37595300900",
        "aff": "Department of Electrical and Computer Engineering, Artificial Intelligence in Robotics Laboratory (Air Lab), Aarhus University, Aarhus C, Denmark; Department of Electrical and Computer Engineering, Artificial Intelligence in Robotics Laboratory (Air Lab), Aarhus University, Aarhus C, Denmark; Munich School of Robotics and Machine Intelligence, Technical University of Munich (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence, Technical University of Munich (TUM), Munich, Germany; Department of Electrical and Computer Engineering, Artificial Intelligence in Robotics Laboratory (Air Lab), Aarhus University, Aarhus C, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636207/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15357030140426922739&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Aarhus University;Technical University of Munich",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Munich School of Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.au.dk;https://www.tum.de",
        "aff_unique_abbr": "AU;TUM",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Aarhus;Munich",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "Denmark;Germany"
    },
    {
        "id": "9636562",
        "title": "Gaussian Process Regression for COP Trajectory Estimation in Healthy and Pathological Gait Using Instrumented Insoles",
        "track": "main",
        "status": "Poster",
        "abstract": "Research in powered prostheses and orthoses has relied on COP measurements to inform a device\u2019s controller about the body\u2019s progression through the gait cycle, and to provide sensory substitution for prosthesis users, thereby helping them maintain balance during locomotion. Obtaining accurate COP measurements in out-of-the-lab contexts currently requires pressure sensitive insoles with dense arrays of sensing elements, which are expensive and bulky, limiting the accessibility and scalability of this technology. In this paper, we present a new method to reconstruct COP trajectories in over-ground walking tasks, using an affordable sensor array with eight sensing elements embedded in shoe insoles. The method leverages Gaussian Process Regression (GPR) to perform predictions from raw sensor data using Bayesian inference. A preliminary validation was carried out with a convenience sample of healthy individuals and patients with neuromuscular disorders. Combined mediolateral (ML) and anteroposterior (AP) errors where 2% and 3% for healthy individuals and patients, respectively. The analysis evidenced larger stride-to-stride variability in the ML COP excursion for the patient group, suggesting higher levels of motor noise associated with selective muscle weakness. These promising results indicate the potential of the proposed method to accurately estimate COP trajectories for future applications in wearable robotics and out-of-the-lab clinical gait assessments.",
        "primary_area": "",
        "author": "Ton T. H. Duong;David Uher;Sally Dunaway Young;Tina Duong;Monica Sangco;Kayla Cornett;Jacqueline Montes;Damiano Zanotto;Ton T. H. Duong;David Uher;Sally Dunaway Young;Tina Duong;Monica Sangco;Kayla Cornett;Jacqueline Montes;Damiano Zanotto",
        "authorids": "/37086917671;/37089194967;/37089196808;/37089194620;/37089198221;/37088532637;/37678990400;/37887906100;/37086917671;/37089194967;/37089196808;/37089194620;/37089198221;/37088532637;/37678990400;/37887906100",
        "aff": "Dept. of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; Dept. of Rehabilitation & Regenerative Medicine, Columbia University Irving Medical Center, New York, NY, USA; Dept. of Neurology, Stanford University School of Medicine, Stanford, CA, USA; Dept. of Neurology, Stanford University School of Medicine, Stanford, CA, USA; Dept. of Neurology, Stanford University School of Medicine, Stanford, CA, USA; The University of Sydney & The Children\u2019s Hospital at Westmead, Sydney, Australia; Dept. of Rehabilitation & Regenerative Medicine, Columbia University Irving Medical Center, New York, NY, USA; Dept. of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636562/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8053345136046023650&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;2;2;3;1;0",
        "aff_unique_norm": "Stevens Institute of Technology;Columbia University Irving Medical Center;Stanford University;University of Sydney",
        "aff_unique_dep": "Dept. of Mechanical Engineering;Dept. of Rehabilitation & Regenerative Medicine;Dept. of Neurology;",
        "aff_unique_url": "https://www.stevens.edu;https://cumc.columbia.edu;https://www.stanford.edu;https://www.sydney.edu.au",
        "aff_unique_abbr": "SIT;CUIMC;Stanford;USYD",
        "aff_campus_unique_index": "0;1;2;2;2;3;1;0",
        "aff_campus_unique": "Hoboken;New York;Stanford;Sydney",
        "aff_country_unique_index": "0;0;0;0;0;1;0;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "9636490",
        "title": "Gaussian Process-based Interpretable Runtime Adaptation for Safe Autonomous Systems Operations in Unstructured Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles may not behave as expected when subject to environmental disturbances. For instance, control commands suitable for driving on dry, paved roads may lead to unsafe conditions and undesired deviations when on slippery dirt or icy roads. Furthermore, it becomes increasingly important to offer human-understandable explanations of autonomous robots\u2019 actions \u2013 especially when they operate in a space shared with humans such as public roads. In this work, we present an interpretable, risk-aware online adaptation approach that leverages a combination of Gaussian process regression and decision tree theory. Our approach predicts the system state in unknown environments using pre-trained models, which are continuously refined during runtime using a fast lookup table-based procedure. Every time the originally intended behavior is predicted to cause an unsafe state, our method computes a set of safe behaviors under the current model uncertainty and risk. The most suitable behavior is subsequently selected depending on mission requirements and a human-understandable explanation about the system\u2019s decision-making is delivered. The proposed framework is applied to unmanned ground vehicles and validated in simulations, in which we demonstrate a successful safety-critical cargo delivery through a priori unknown, rough and slippery terrain.",
        "primary_area": "",
        "author": "Christian Gall;Nicola Bezzo;Christian Gall;Nicola Bezzo",
        "authorids": "/37089197706;/37546843800;/37089197706;/37546843800",
        "aff": "Department of Aerospace Engineering and Geodesy, University of Stuttgart, Stuttgart, Germany; Departments of Engineering Systems and Environment and Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636490/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8784589857666764701&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Stuttgart;University of Virginia",
        "aff_unique_dep": "Department of Aerospace Engineering and Geodesy;Departments of Engineering Systems and Environment, Electrical and Computer Engineering",
        "aff_unique_url": "https://www.uni-stuttgart.de;https://www.virginia.edu",
        "aff_unique_abbr": ";UVA",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Stuttgart;Charlottesville",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9636482",
        "title": "Gear Ratio Optimization of a Multifunctional Walker Robot Using Dual-Motor Actuation",
        "track": "main",
        "status": "Poster",
        "abstract": "Optimization of gear ratios for dual-motor actuators is presented for the development of a walker-type assist robot. The robot is reconfigurable to provide an elderly user with multiple physical support functions; one is to assist sitto-stand transitions and the other is to serve as a walker to aid the user in walking. To avoid falling while walking, the robot must react quickly and reconfigure its footprint for supporting the user. This requires high speed actuators. In contrast, for assisting sit-to-stand transitions, high torque actuators are required. To meet the bimodal, conflicting load conditions, i.e. high-torque, low-speed v.s. high-speed, low-torque, this paper presents a dual-motor actuation solution, where two motors with diverse gear ratios are combined. The system is characterized with two key parameters: an internal gear ratio between a high-speed motor and a torque-booster, and an external gear ratio for connecting the dual motor actuator to the load. The internal and external gear ratios are optimized for performing both sit-to-stand assist and rapid foot reconfiguration.",
        "primary_area": "",
        "author": "John Bell;Emily Kamienski;Seiichi Teshigawara;Hirofumi Itagaki;H. Harry Asada;John Bell;Emily Kamienski;Seiichi Teshigawara;Hirofumi Itagaki;H. Harry Asada",
        "authorids": "/37086862997;/37089197780;/37089267372;/37089195120;/37279023100;/37086862997;/37089197780;/37089267372;/37089195120;/37279023100",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; NSK Ltd., Kanagawa, Japan; NSK Ltd., Kanagawa, Japan; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636482/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8039753661247271171&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;NSK Ltd.",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://web.mit.edu;https://www.nsk.com",
        "aff_unique_abbr": "MIT;NSK",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9636023",
        "title": "Generalization Through Hand-Eye Coordination: An Action Space for Learning Spatially-Invariant Visuomotor Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Imitation Learning (IL) is an effective framework to learn visuomotor skills from offline demonstration data. However, IL methods often fail to generalize to new scene configurations not covered by training data. On the other hand, humans can manipulate objects in varying conditions. Key to such capability is hand-eye coordination, a cognitive ability that enables humans to adaptively direct their movements at task-relevant objects and be invariant to the objects\u2019 absolute spatial location. In this work, we present a learnable action space, Hand-eye Action Networks (HAN) that learns coordinated hand-eye movements from human teleoperated demonstrations. Through a set of challenging multi-stage manipulation tasks, we show that a visuomotor policy equipped with HAN is able to inherit the key spatial invariance property of handeye coordination and achieve generalization to new scene configurations. Additional materials available at https://sites.google.com/stanford.edu/han",
        "primary_area": "",
        "author": "Chen Wang;Rui Wang;Ajay Mandlekar;Li Fei-Fei;Silvio Savarese;Danfei Xu;Chen Wang;Rui Wang;Ajay Mandlekar;Li Fei-Fei;Silvio Savarese;Danfei Xu",
        "authorids": "/37089197280;/37089195042;/37086331393;/38273560700;/37298502600;/37086228189;/37089197280;/37089195042;/37086331393;/38273560700;/37298502600;/37086228189",
        "aff": "Stanford Vision and Learning Lab; Stanford Vision and Learning Lab; Stanford Vision and Learning Lab; Stanford Vision and Learning Lab; Stanford Vision and Learning Lab; Stanford Vision and Learning Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636023/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12123284192340573359&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Vision and Learning Lab",
        "aff_unique_url": "https://vision.stanford.edu",
        "aff_unique_abbr": "Stanford V&L",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636643",
        "title": "Generating Active Explicable Plans in Human-Robot Teaming",
        "track": "main",
        "status": "Poster",
        "abstract": "Intelligent robots are redefining a multitude of critical domains but are still far from being fully capable of assisting human peers in day-to-day tasks. An important requirement of collaboration is for each teammate to maintain and respect an understanding of the others\u2019 expectations of itself. Lack of which may lead to serious issues such as loose coordination between teammates, reduced situation awareness, and ultimately teaming failures. Hence, it is important for robots to behave explicably by meeting the human\u2019s expectations. One of the challenges here is that the expectations of the human are often hidden and can change dynamically as the human interacts with the robot. However, existing approaches to generating explicable plans often assume that the human\u2019s expectations are known and static. In this paper, we propose the idea of active explicable planning to relax this assumption. We apply a Bayesian approach to model and predict dynamic human belief and expectations to make explicable planning more anticipatory. We hypothesize that active explicable plans can be more efficient and explicable at the same time, when compared to explicable plans generated by the existing methods. In our experimental evaluation, we verify that our approach generates more efficient explicable plans while successfully capturing the dynamic belief change of the human teammate.",
        "primary_area": "",
        "author": "Akkamahadevi Hanni;Yu Zhang;Akkamahadevi Hanni;Yu Zhang",
        "authorids": "/37085898064;/37086071738;/37085898064;/37086071738",
        "aff": "School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, Arizona, USA; School of Computing, Informatics, and Decision Systems Engineering, Arizona State University, Tempe, Arizona, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636643/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16878564544475715959&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School of Computing, Informatics, and Decision Systems Engineering",
        "aff_unique_url": "https://asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636068",
        "title": "Generation of Human-like Arm Motions using Sampling-based Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Natural and human-like arm motions are promising features to facilitate social understanding of humanoid robots. To this end, we integrate biophysical characteristics of human arm-motions into sampling-based motion planning. We show the generality of our method by evaluating it with multiple manipulators. Our first contribution is to introduce a set of cost functions to optimize for human-like arm postures during collision-free motion planning. In a subsequent step, an optimization phase is used to improve the human-likeness of the initial path. Additionally, we present an interpolation approach for generating obstacle-aware and multi-modal velocity profiles. We thus generate collision-free and human-like motions in narrow passages while allowing for natural acceleration in free space.",
        "primary_area": "",
        "author": "Carl G\u00e4bert;Sascha Kaden;Ulrike Thomas;Carl G\u00e4bert;Sascha Kaden;Ulrike Thomas",
        "authorids": "/37088503821;/37086454781;/37281523200;/37088503821;/37086454781;/37281523200",
        "aff": "Robotics and Human-MachineInteraction Lab, Chemnitz University of Technology; Robotics and Human-MachineInteraction Lab, Chemnitz University of Technology; Robotics and Human-MachineInteraction Lab, Chemnitz University of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636068/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10988236400236812845&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chemnitz University of Technology",
        "aff_unique_dep": "Robotics and Human-Machine Interaction Lab",
        "aff_unique_url": "https://www.tu-chemnitz.de",
        "aff_unique_abbr": "TUC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9635861",
        "title": "Geometric Motion Planning for a System on the Cylindrical Surface",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional geometric mechanics models used in locomotion analysis rely heavily on systems having symmetry in SE(2) (i.e., the dynamics and constraints are invariant with respect to a system\u2019s position and orientation) to simplify motion planning. As a result, the symmetry assumption prevents locomotion analysis on non-flat surfaces because the system dynamics may vary as a function of position and orientation. In this paper, we develop geometric motion planning strategies for a mobile system moving on a position space whose manifold structure is a cylinder: constant non-zero curvature in one dimension and zero curvature in another. To handle this non-flat position space, we adapt conventional geometric mechanics tools - in particular the system connection and the constraint curvature function - to depend on the system orientation. In addition, we introduce a novel constraint projection method to a variational gait optimizer and demonstrate how to design gaits that allow the example system to move on the cylinder with optimal efficiency.",
        "primary_area": "",
        "author": "Shuoqi Chen;Ruijie Fu;Ross Hatton;Howie Choset;Shuoqi Chen;Ruijie Fu;Ross Hatton;Howie Choset",
        "authorids": "/37089197196;/37089195227;/37542919100;/37281322200;/37089197196;/37089195227;/37542919100;/37281322200",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; School of Mechanical, Industrial, and Manufacturing Engineering, Oregon State University, Corvallis, OR, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635861/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16297227586264535880&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Oregon State University",
        "aff_unique_dep": "Robotics Institute;School of Mechanical, Industrial, and Manufacturing Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://oregonstate.edu",
        "aff_unique_abbr": "CMU;OSU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Pittsburgh;Corvallis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635981",
        "title": "Geometry-Based Grasping Pipeline for Bi-Modal Pick and Place",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an autonomous grasping pipeline that relies on geometric information extracted from segmented point cloud data. This is in contrast to many recent approaches leveraging deep learning and thus relying on a rather large amount of training samples. We argue that the proposed geometric approach facilitates task-level planning as the shape, size, and symmetry of objects can be directly taken into account during the planning process that utilizes the new MoveIt! Task Constructor (MTC) framework to define and plan action sequences composed of several inter-related sub-tasks. The efficiency of the proposed grasping pipeline is illustrated in pick-and-place scenarios, including a long-distance pick-and-place requiring a hand-over between two hands.",
        "primary_area": "",
        "author": "Robert Haschke;Guillaume Walck;Helge Ritter;Robert Haschke;Guillaume Walck;Helge Ritter",
        "authorids": "/37565751900;/37393489800;/37266153900;/37565751900;/37393489800;/37266153900",
        "aff": "Center of Excellence \"Cognitive Interaction Technology\" (CITEC), Bielefeld University, Germany; Center of Excellence \"Cognitive Interaction Technology\" (CITEC), Bielefeld University, Germany; Center of Excellence \"Cognitive Interaction Technology\" (CITEC), Bielefeld University, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635981/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=547341610638531656&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Bielefeld University",
        "aff_unique_dep": "Center of Excellence \"Cognitive Interaction Technology\" (CITEC)",
        "aff_unique_url": "https://www.uni-bielefeld.de",
        "aff_unique_abbr": "Uni Bielefeld",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636664",
        "title": "Geometry-Based Two-Contact Inverse Kinematic Solution for Whole Arm Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Whole-arm manipulation (WAM) is often used to manipulate large and bulky objects. Contact point-based methods for generating the robot configurations for WAM mostly search for suitable contact points and configurations simultaneously. However, in order to learn good contact points, or allow an operator to select them, inverse kinematics (IK) solvers are needed which take such points along with a surface normal into account. Therefore, we propose a geometry-based IK method for WAM generate robot configurations in contact with two specific points. The method is compared against two other methods, one numerical method and a commercial IK solver. We show our method to be the fastest.",
        "primary_area": "",
        "author": "Pascal Gliesche;Christian Kowalski;Max Pfingsthorn;Andreas Hein;Pascal Gliesche;Christian Kowalski;Max Pfingsthorn;Andreas Hein",
        "authorids": "/37088804806;/37088749769;/37391696500;/37297673800;/37088804806;/37088749769;/37391696500;/37297673800",
        "aff": "OFFIS Institute for Information Technology, Oldenburg, Germany; OFFIS Institute for Information Technology, Oldenburg, Germany; OFFIS Institute for Information Technology, Oldenburg, Germany; Carl von Ossietzky University of Oldenburg, Oldenburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636664/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6477165478721837678&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "OFFIS Institute for Information Technology;Carl von Ossietzky University of Oldenburg",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.offis.de/;https://www.uni-oldenburg.de/",
        "aff_unique_abbr": ";UvO",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Oldenburg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636530",
        "title": "Geometry-based Graph Pruning for Lifelong SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Lifelong SLAM considers long-term operation of a robot where already mapped locations are revisited many times in changing environments. As a result, traditional graph-based SLAM approaches eventually become extremely slow due to the continuous growth of the graph and the loss of sparsity. Both problems can be addressed by a graph pruning algorithm. It carefully removes vertices and edges to keep the graph size reasonable while preserving the information needed to provide good SLAM results. We propose a novel method that considers geometric criteria for choosing the vertices to be pruned. It is efficient, easy to implement, and leads to a graph with evenly spread vertices that remain part of the robot trajectory. Furthermore, we present a novel approach of marginalization that is more robust to wrong loop closures than existing methods. The proposed algorithm is evaluated on two publicly available real-world long-term datasets and compared to the unpruned case as well as ground truth. We show that even on a long dataset (25h), our approach manages to keep the graph sparse and the speed high while still providing good accuracy (40 times speed up, 6cm map error compared to unpruned case).",
        "primary_area": "",
        "author": "Gerhard Kurz;Matthias Holoch;Peter Biber;Gerhard Kurz;Matthias Holoch;Peter Biber",
        "authorids": "/37089696351;/37089195607;/37301850700;/37089696351;/37089195607;/37301850700",
        "aff": "Robert Bosch GmbH, Corporate Research, Germany; Robert Bosch GmbH, Corporate Research, Germany; Robert Bosch GmbH, Corporate Research, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636530/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10661049738891631562&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Robert Bosch GmbH",
        "aff_unique_dep": "Corporate Research",
        "aff_unique_url": "https://www.bosch.com",
        "aff_unique_abbr": "Bosch",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636459",
        "title": "GhostPose: Multi-view Pose Estimation of Transparent Objects for Robot Hand Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Pose estimation is a key challenge in robot manipulation and grasping task. Current object pose estimation approaches based on 3D models and depth sensor information have difficulties to handle transparent objects because of the limitation to capture the accurate depth information. To address these issues, we present a 6DoF pose estimation approach, called GhostPose, which utilizes a novel 3D bounding box prediction network and multi-view geometry with cameras on manipulator robot. Our 3D bounding box prediction network is simple and light-weight by adding a small branch to a one-stage object detector. The network detects 2D projections of 3D bounding box vertices. Then, 3D points are reconstructed from the 2D results of the multiple viewpoints with camera motion information, i.e. extrinsic parameters, calculated from the robot joint angles. We also present generalized pose definition to address pose ambiguity of symmetric objects and keep consistency of geometric properties around feature points across both of the symmetric and asymmetric objects. Comparing with the previous pose estimation approaches, GhostPose is more generalized to environments and object types, because it does not require 3D models, object specific key points, predefined stereo settings and depth map. In experiments, it outperforms a state-of-the-art approach and shows generalized properties by applying to a real manipulator robot grasping system.",
        "primary_area": "",
        "author": "Jaesik Chang;Minju Kim;Seongmin Kang;Heungwoo Han;Sunpyo Hong;Kyunghun Jang;Sungchul Kang;Jaesik Chang;Minju Kim;Seongmin Kang;Heungwoo Han;Sunpyo Hong;Kyunghun Jang;Sungchul Kang",
        "authorids": "/37089194622;/37088931844;/37089194004;/37089194280;/37089194433;/37089194559;/37089194001;/37089194622;/37088931844;/37089194004;/37089194280;/37089194433;/37089194559;/37089194001",
        "aff": "Samsung Research, Samsung Electronics Co., Ltd; Samsung Research, Samsung Electronics Co., Ltd; Samsung Research, Samsung Electronics Co., Ltd; Samsung Research, Samsung Electronics Co., Ltd; Samsung Research, Samsung Electronics Co., Ltd; Samsung Research, Samsung Electronics Co., Ltd; Samsung Research, Samsung Electronics Co., Ltd",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636459/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6377314102917928423&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "Samsung Research",
        "aff_unique_url": "https://www.samsung.com",
        "aff_unique_abbr": "Samsung",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636492",
        "title": "GloCAL: Glocalized Curriculum-Aided Learning of Multiple Tasks with Application to Robotic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "The domain of robotics is challenging to apply deep reinforcement learning due to the need for large amounts of data and for ensuring safety during learning. Curriculum learning has shown good performance in terms of sample-efficient deep learning. In this paper, we propose an algorithm (named GloCAL) that creates a curriculum for an agent to learn multiple discrete tasks, based on clustering tasks according to their evaluation scores. From the highest-performing cluster, a global task representative of the cluster is identified for learning a global policy that transfers to subsequently formed new clusters, while remaining tasks in the cluster are learnt as local policies. The efficacy and efficiency of our GloCAL algorithm are compared with other approaches in the domain of grasp learning for 49 objects with varied object complexity and grasp difficulty from the EGAD! dataset. The results show that GloCAL is able to learn to grasp 100% of the objects, whereas other approaches achieve at most 86% despite being given 1.5\u00d7 longer training time.",
        "primary_area": "",
        "author": "Anil Kurkcu;Cihan Acar;Domenico Campolo;Keng Peng Tee;Anil Kurkcu;Cihan Acar;Domenico Campolo;Keng Peng Tee",
        "authorids": "/37086554533;/37088854551;/37329581600;/37275857100;/37086554533;/37088854551;/37329581600;/37275857100",
        "aff": "Institute for Infocomm Research, A*STAR, Singapore; Institute for Infocomm Research, A*STAR, Singapore; Department of Mechanical & Aerospace Engineering, Nanyang Technological University, Singapore; Institute for Infocomm Research, A*STAR, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636492/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2114214453147217050&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Institute for Infocomm Research;Nanyang Technological University",
        "aff_unique_dep": ";Department of Mechanical & Aerospace Engineering",
        "aff_unique_url": "https://www.i2r.a-star.edu.sg;https://www.ntu.edu.sg",
        "aff_unique_abbr": "I2R;NTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9636660",
        "title": "Graph-based Task-specific Prediction Models for Interactions between Deformable and Rigid Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Capturing scene dynamics and predicting the future scene state is challenging but essential for robotic manipulation tasks, especially when the scene contains both rigid and deformable objects. In this work, we contribute a simulation environment and generate a novel dataset for task-specific manipulation, involving interactions between rigid objects and a deformable bag. The dataset incorporates a rich variety of scenarios including different object sizes, object numbers and manipulation actions. We approach dynamics learning by proposing an object-centric graph representation and two modules which are Active Prediction Module (APM) and Position Prediction Module (PPM) based on graph neural networks with an encode-process-decode architecture. At the inference stage, we build a two-stage model based on the learned modules for single time step prediction. We combine modules with different prediction horizons into a mixed-horizon model which addresses long-term prediction. In an ablation study, we show the benefits of the two-stage model for single time step prediction and the effectiveness of the mixed-horizon model for long-term prediction tasks. Supplementary material is available at https://github.com/wengzehang/deformable_rigid_interaction_prediction",
        "primary_area": "",
        "author": "Zehang Weng;Fabian Paus;Anastasiia Varava;Hang Yin;Tamim Asfour;Danica Kragic;Zehang Weng;Fabian Paus;Anastasiia Varava;Hang Yin;Tamim Asfour;Danica Kragic",
        "authorids": "/37089196346;/37086267483;/37086619259;/37088353838;/37295529100;/37281296000;/37089196346;/37086267483;/37086619259;/37088353838;/37295529100;/37281296000",
        "aff": "CAS/RPL, KTH, Royal Institute of Technology, Stocholm, Sweden; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; CAS/RPL, KTH, Royal Institute of Technology, Stocholm, Sweden; CAS/RPL, KTH, Royal Institute of Technology, Stocholm, Sweden; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; CAS/RPL, KTH, Royal Institute of Technology, Stocholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636660/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4507539565482012369&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;1;0",
        "aff_unique_norm": "Royal Institute of Technology;Karlsruhe Institute of Technology",
        "aff_unique_dep": "CAS/RPL;Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kth.se;https://www.kit.edu",
        "aff_unique_abbr": "KTH;KIT",
        "aff_campus_unique_index": "0;1;0;0;1;0",
        "aff_campus_unique": "Stocholm;Karlsruhe",
        "aff_country_unique_index": "0;1;0;0;1;0",
        "aff_country_unique": "Sweden;Germany"
    },
    {
        "id": "9636511",
        "title": "Grasp Pose Detection from a Single RGB Image",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasp pose detection generates the position and orientation of the robot end-effector to grasp objects from the RGB or RGB-D image. In this paper, we propose a novel grasp pose detection network that generates 3-DOF grasp poses using the RGB image. The network follows the anchor-based object detection pipeline and incorporates the angle detection unit. Furthermore, we redesign the grasp angle predictor with a classification unit to increase the accuracy of grasp pose rotation estimation. Our method classifies the prediction angle densely in contrast with the previous regression method or sparse classification method. Moreover, an angle smooth label is designed to avoid the sudden change of the angle regression loss caused by the periodic property of the angle. We validate our algorithm on Cornell Grasp Dataset and obtain a higher detection accuracy than the state-of-the-art method. The real scenario experiment also proves the effectiveness of our method. The robot equipped with the parallel gripper achieves a 96.4% grasp success rate.",
        "primary_area": "",
        "author": "Hu Cheng;Yingying Wang;Max Q.-H. Meng;Hu Cheng;Yingying Wang;Max Q.-H. Meng",
        "authorids": "/37086801643;/37088689053;/37274117000;/37086801643;/37088689053;/37274117000",
        "aff": "Robotics, Perception and Artificial Intelligence Lab in the Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; Robotics, Perception and Artificial Intelligence Lab in the Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; Shenzhen Research Institute of the Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636511/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=791897628234703485&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electronic Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636074",
        "title": "Grasping with Embedded Synergies through a Reconfigurable Electric Actuation Topology",
        "track": "main",
        "status": "Poster",
        "abstract": "Kinematic and force synergies can be used to reduce the complexity and dimensionality of the motion generation and control problem, as well as facilitate the mechanical implementation of robotic hands. In this paper we present a novel implementation of hardware synergies realized on the actuation level by leveraging a novel reconfigurable electric actuation topology principle. The proposed electric actuation topology enables different actuation synergies by changing the interconnections among the actuators at the electrical/motor driver level. We describe the synergies and their implementation in a port-based context, and elaborate how equivalent hard and soft synergies emerge from the electric power flow within different actuation topologies. We realize the reconfigurable electric actuation topology scheme in the HERI III hand, a novel robust and powerful robotic gripper, also introduced in this paper, resulting in easy to control behaviours like on industrial grippers or underactuated hands, but with the high grasping versatility of fully actuated hands. Finally we present grasping experiments performed on the HERI III hand that clearly show the desired behaviours and validate the innovative proposed scheme.",
        "primary_area": "",
        "author": "\u00c9amon Barrett;Zeyu Ren;Nikos Tsagarakis;\u00c9amon Barrett;Zeyu Ren;Nikos Tsagarakis",
        "authorids": "/37063138400;/37086332876;/37295830800;/37063138400;/37086332876;/37295830800",
        "aff": "Istituto Italiano di Tecnologia (IIT), Humanoids and Human Centered Mechatronics (HHCM), Genova, Italy; Rokae Robotics, Beijing, China; Istituto Italiano di Tecnologia (IIT), Humanoids and Human Centered Mechatronics (HHCM), Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636074/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Lda6xpJI1rcJ:scholar.google.com/&scioq=Grasping+with+Embedded+Synergies+through+a+Reconfigurable+Electric+Actuation+Topology&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;Rokae Robotics",
        "aff_unique_dep": "Humanoids and Human Centered Mechatronics;",
        "aff_unique_url": "https://www.iit.it;",
        "aff_unique_abbr": "IIT;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Genova;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Italy;China"
    },
    {
        "id": "9636591",
        "title": "Gridlock-free Autonomous Parking Lots for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Many cities suffer from a shortage of parking spaces. Research in high density parking (HDP) focuses on how to increase the capacity of parking lots by allowing vehicles to block each other but temporarily give way to other vehicles by driving autonomously upon request. Previous works on HDP did not consider mixing different parking strategies and ignored the possibility of gridlock when multiple vehicles move simultaneously. In this paper, we describe the design of autonomous parking lots, which allows the deployment of different parking strategies in different regions in a parking lot. We present algorithms for checking whether adding a vehicle to an autonomous parking lot can lead to gridlock. Our simulation shows that autonomous parking lots can hold 60% more vehicles given the same amount of space.",
        "primary_area": "",
        "author": "Tsz-Chiu Au;Tsz-Chiu Au",
        "authorids": "/37597553100;/37597553100",
        "aff": "Department of Computer Science and Engineering, Ulsan National Institute of Science and Technology, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636591/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3978973841572943422&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.unist.ac.kr",
        "aff_unique_abbr": "UNIST",
        "aff_country_unique_index": "0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636764",
        "title": "Ground Encoding: Learned Factor Graph-based Models for Localizing Ground Penetrating Radar",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of robot localization using ground penetrating radar (GPR) sensors. Current approaches for localization with GPR sensors require a priori maps of the system\u2019s environment as well as access to approximate global positioning (GPS) during operation. In this paper, we propose a novel, real-time GPR-based localization system for unknown and GPS-denied environments. We model the localization problem as an inference over a factor graph. Our approach combines 1D single-channel GPR measurements to form 2D image submaps. To use these GPR images in the graph, we need sensor models that can map noisy, high-dimensional image measurements into the state space. These are challenging to obtain a priori since image generation has a complex dependency on subsurface composition and radar physics, which itself varies with sensors and variations in subsurface electromagnetic properties. Our key idea is to instead learn relative sensor models directly from GPR data that map non-sequential GPR image pairs to relative robot motion. These models are incorporated as factors within the factor graph with relative motion predictions correcting for accumulated drift in the position estimates. We demonstrate our approach over datasets collected across multiple locations using a custom designed experimental rig. We show reliable, real-time localization using only GPR and odometry measurements for varying trajectories in three distinct GPS-denied environments.",
        "primary_area": "",
        "author": "Alexander Baikovitz;Paloma Sodhi;Michael Dille;Michael Kaess;Alexander Baikovitz;Paloma Sodhi;Michael Dille;Michael Kaess",
        "authorids": "/37089195428;/38469682300;/38241225200;/37324200400;/37089195428;/38469682300;/38241225200;/37324200400",
        "aff": "The Robotics Institute, Carnegie Mellon University; The Robotics Institute, Carnegie Mellon University; Intelligent Robotics Group, NASA Ames Research Center; The Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636764/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12790996750810643659&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;NASA Ames Research Center",
        "aff_unique_dep": "The Robotics Institute;Intelligent Robotics Group",
        "aff_unique_url": "https://www.cmu.edu;https://www.nasa.gov/ames",
        "aff_unique_abbr": "CMU;NASA Ames",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Moffett Field",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636172",
        "title": "Grounding Linguistic Commands to Navigable Regions",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans have a natural ability to effortlessly comprehend linguistic commands such as \u201cpark next to the yellow sedan\u201d and instinctively know which region of the road the vehicle should navigate. Extending this ability to autonomous vehicles is the next step towards creating fully autonomous agents that respond and act according to human commands. To this end, we propose the novel task of Referring Navigable Regions (RNR), i.e., grounding regions of interest for navigation based on the linguistic command. RNR is different from Referring Image Segmentation (RIS), which focuses on grounding an object referred to by the natural language expression instead of grounding a navigable region. For example, for a command \u201cpark next to the yellow sedan,\u201d RIS will aim to segment the referred sedan, and RNR aims to segment the suggested parking region on the road. We introduce a new dataset, Talk2Car-RegSeg, which extends the existing Talk2car [1] dataset with segmentation masks for the regions described by the linguistic commands. A separate test split with concise manoeuvre-oriented commands is provided to assess the practicality of our dataset. We benchmark the proposed dataset using a novel transformer-based architecture. We present extensive ablations and show superior performance over baselines on multiple evaluation metrics. A downstream path planner generating trajectories based on RNR outputs confirms the efficacy of the proposed framework.",
        "primary_area": "",
        "author": "Nivedita Rufus;Kanishk Jain;Unni Krishnan R Nair;Vineet Gandhi;K Madhava Krishna;Nivedita Rufus;Kanishk Jain;Unni Krishnan R Nair;Vineet Gandhi;K Madhava Krishna",
        "authorids": "/37088751102;/37089194367;/37088505408;/37075471000;/37395945400;/37088751102;/37089194367;/37088505408;/37075471000;/37395945400",
        "aff": "KCIS, International Institute of Information Technology, Hyderabad; KCIS, International Institute of Information Technology, Hyderabad; KCIS, International Institute of Information Technology, Hyderabad; KCIS, International Institute of Information Technology, Hyderabad; KCIS, International Institute of Information Technology, Hyderabad",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636172/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10981778399373508118&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "International Institute of Information Technology",
        "aff_unique_dep": "KCIS",
        "aff_unique_url": "https://iiit Hyderabad.ac.in",
        "aff_unique_abbr": "IIIT Hyderabad",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hyderabad",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9636702",
        "title": "Group Multi-Object Tracking for Dynamic Risk Map and Safe Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the group multi-object tracking (MOT) problem in dynamic pedestrian environments, with intended application to safe navigation for autonomous vehicles. We complete a full autonomous vehicle navigation pipeline from object detection, tracking, grouping, to risk map generation and safe path planning. Our main contribution is to instantiate a group multi-object tracking algorithm, which provides the crucial grouped activity information, i.e. group position, group velocity, group size, to the risk map generator, and therewith produce a stable and robust risk map for the downstream safe path planner. Experimental results with real world data show the socially acceptable, robust and stable performance of the proposed algorithm over its individual MOT counterpart.",
        "primary_area": "",
        "author": "Lyuyu Shen;Hongliang Guo;Yechao Bai;Lei Qin;Marcelo Ang;Daniela Rus;Lyuyu Shen;Hongliang Guo;Yechao Bai;Lei Qin;Marcelo Ang;Daniela Rus",
        "authorids": "/37088890746;/37085490043;/37088889343;/37088997571;/37279138700;/37279652300;/37088890746;/37085490043;/37088889343;/37088997571;/37279138700;/37279652300",
        "aff": "National University of Singapore, Singapore; Institute for Infocomm Research, A*STAR, Singapore; National University of Singapore, Singapore; Singapore-MIT Alliance for Research and Technology, Singapore; National University of Singapore, Singapore; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636702/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7932738473140693924&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;3",
        "aff_unique_norm": "National University of Singapore;Institute for Infocomm Research;Singapore-MIT Alliance for Research and Technology;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;;Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.i2r.a-star.edu.sg;;https://www.mit.edu",
        "aff_unique_abbr": "NUS;I2R;SMART;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "9635831",
        "title": "Guiding Robot Model Construction with Prior Features",
        "track": "main",
        "status": "Poster",
        "abstract": "Virtually all robot control methods benefit from the availability of an accurate mathematical model of the robot. However, obtaining a sufficient amount of informative data for constructing dynamic models can be difficult, especially when the models are to be learned during robot deployment. Under such circumstances, standard data-driven model learning techniques often yield models that do not comply with the physics of the robot. We extend a symbolic regression algorithm based on Single Node Genetic Programming by including the prior model information into the model construction process. In this way, symbolic regression automatically builds models that compensate for theoretical or empirical model deficiencies. We experimentally demonstrate the approach on two real-world systems: the TurtleBot 2 mobile robot and the Parrot Bebop 2 drone. The results show that the proposed model-learning algorithm produces realistic models that fit well the training data even when using small training sets. Passing the prior model information to the algorithm significantly improves the model accuracy while speeding up the search.",
        "primary_area": "",
        "author": "Erik Derner;Ji\u0159\u00ed Kubal\u00edk;Robert Babu\u0161ka;Erik Derner;Ji\u0159\u00ed Kubal\u00edk;Robert Babu\u0161ka",
        "authorids": "/37086454702;/37063769700;/37270682600;/37086454702;/37063769700;/37270682600",
        "aff": "Department of Control Engineering, Faculty of Electrical Engineering, Czech Technical University in Prague, Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics, Czech Technical University in Prague, Prague, Czech Republic; Czech Institute of Informatics, Robotics and Cybernetics, Czech Technical University in Prague, Prague, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635831/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10473000908596911677&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Department of Control Engineering",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "9636167",
        "title": "HARL-A: Hardware Agnostic Reinforcement Learning Through Adversarial Selection",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of reinforcement learning (RL) has led to huge advancements in the field of robotics. However data scarcity, brittle convergence and the gap between simulation & real world environments, mean that most common RL approaches are subject to over fitting and fail to generalise to unseen environments. Hardware agnostic policies would mitigate this by allowing a single network to operate in a variety of test domains, where dynamics vary due to changes in robotic morphologies or internal parameters. We utilise the idea that learning to adapt a known and successful control policy is easier and more flexible than jointly learning numerous control policies for different morphologies.This paper presents the idea of Hardware Agnostic Reinforcement Learning using Adversarial selection (HARL-A). In this approach training examples are sampled using a novel adversarial loss function. This is designed to self regulate morphologies based on their learning potential. Simply applying our learning potential based loss function to current state-of-the-art already provides ~ 30% improvement in performance. Meanwhile experiments using the full implementation of HARL-A report an average increase of 70% to a standard RL baseline and 55% compared with current state-of-the-art.",
        "primary_area": "",
        "author": "Lucy Jackson;Steve Eckersley;Pete Senior;Simon Hadfield;Lucy Jackson;Steve Eckersley;Pete Senior;Simon Hadfield",
        "authorids": "/37089194792;/37086937559;/37089198273;/38232557500;/37089194792;/37086937559;/37089198273;/38232557500",
        "aff": "University of Surrey; Surrey Satellite Technology Limited; Surrey Satellite Technology Limited; University of Surrey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636167/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15094483063672904515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Surrey;Surrey Satellite Technology Limited",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.surrey.ac.uk;https://www.sstl.co.uk",
        "aff_unique_abbr": "Surrey;SSTL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636108",
        "title": "HOPPY: An Open-source Kit for Education with Dynamic Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces HOPPY, an open-source, low-cost, robust, and modular kit for robotics education. The robot dynamically hops around a rotating gantry with a fixed base. The kit is intended to lower the entry barrier for studying dynamic robots and legged locomotion with real systems. It bridges the theoretical content of fundamental robotic courses with real dynamic robots by facilitating and guiding the software and hardware integration. This paper describes the topics which can be studied using the kit, lists its components, discusses preferred practices for implementation, presents results from experiments with the simulator and the real system, and suggests further improvements. A simple heuristic-based controller is described to achieve velocities up to 1.7m/s, navigate small objects, and mitigate external disturbances when the robot is aided by a counterweight. HOPPY was utilized as the subject of a semester-long project for the Robot Dynamics and Control course at the University of Illinois at Urbana-Champaign. The positive feedback from the students and instructors about the hands-on activities during the course motivates us to share this kit and continue improving it in the future.",
        "primary_area": "",
        "author": "Joao Ramos;Yanran Ding;Young-Woo Sim;Kevin Murphy;Daniel Block;Joao Ramos;Yanran Ding;Young-Woo Sim;Kevin Murphy;Daniel Block",
        "authorids": "/37085375922;/37086268690;/37086326431;/37089477145;/37276311800;/37085375922;/37086268690;/37086326431;/37089477145;/37276311800",
        "aff": "Department of Electrical & Computer Engineering, University of Illinois at Urbana-Champaign, USA; Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, USA; Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, USA; Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, USA; Department of Electrical & Computer Engineering, University of Illinois at Urbana-Champaign, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636108/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=787639873957904927&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical & Computer Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636228",
        "title": "HanGrawler 2: Super-high-speed and Large-payload Ceiling Mobile Robot Using Crawler",
        "track": "main",
        "status": "Poster",
        "abstract": "Ceiling mobile robots are anticipated for trans-porting component parts in production sites. In our previous study, we had developed a crawler-type ceiling mobile robot named \"HanGrawler.\" In this study, we aim to realize 1 m/s and 90\u00b0/s speed movement on par with existing ground carriers, and reveal the factors contributing to the improvement in speed and stabilization. Accordingly, we develop HanGrawler 2, which inherits the basic approach of HanGrawler. In HanGrawler 2, the mechanism for hanging from the ceiling moves faster, and the driving power of the linear and rotational movements is improved drastically. Newly installed sensors detect the hanging mechanism and robot body position relative to the ceiling plate. By calculating the insertion timing based on the position of the hanging mechanism, the certainty of insertion is improved. Support rollers pressed against the ceiling stabilize the traveling posture of HanGrawler 2. Performance evaluation experiments confirm that HanGrawler 2 can travel linearly at a speed of 1 m/s with a 40 kg load and turn at a rotational speed of 90\u00b0/s. Based on the experimental results, it is confirmed that the design solutions for HanGrawler 2 are effective in realizing reliable ceiling mobility and that the high-responsiveness inherited from the original HanGrawler mechanism contributes to the realization of high-speed movement.",
        "primary_area": "",
        "author": "Takehito Yoshida;Yudai Yamada;Shin\u2019Ichi Warisawa;Rui Fukui;Takehito Yoshida;Yudai Yamada;Shin\u2019Ichi Warisawa;Rui Fukui",
        "authorids": "/37089195149;/37087012269;/37279811100;/37328184200;/37089195149;/37087012269;/37279811100;/37328184200",
        "aff": "Department of Human and Engineered Environmental Studies, The Univ. of Tokyo, Chiba, Japan; Obayashi Corporation, Tokyo, Japan; Department of Human and Engineered Environmental Studies, The Univ. of Tokyo, Chiba, Japan; Department of Human and Engineered Environmental Studies, The Univ. of Tokyo, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636228/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4701499680458193771&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Tokyo;Obayashi Corporation",
        "aff_unique_dep": "Department of Human and Engineered Environmental Studies;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.obayashi.co.jp",
        "aff_unique_abbr": "UTokyo;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chiba;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636391",
        "title": "Hannes Prosthesis Control Based on Regression Machine Learning Algorithms",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "D. Di Domenico;A. Marinelli;N. Boccardo;M. Semprini;L. Lombardi;M. Canepa;S. Stedman;A. Dellacasa Bellingegni;M. Chiappalone;E. Gruppioni;M. Laffranchi;L. De Michieli;D. Di Domenico;A. Marinelli;N. Boccardo;M. Semprini;L. Lombardi;M. Canepa;S. Stedman;A. Dellacasa Bellingegni;M. Chiappalone;E. Gruppioni;M. Laffranchi;L. De Michieli",
        "authorids": "/37089194469;/37088534296;/37088533991;/38365455800;/37088532974;/37088533935;/37088534366;/37088534833;/37330529300;/37086383487;/37528362900;/37087850759;/37089194469;/37088534296;/37088533991;/38365455800;/37088532974;/37088533935;/37088534366;/37088534833;/37330529300;/37086383487;/37528362900;/37087850759",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636391/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4583365366391847667&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24
    },
    {
        "id": "9636314",
        "title": "Hiding Leader\u2019s Identity in Leader-Follower Navigation through Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Leader-follower navigation is a popular class of multi-robot algorithms where a leader robot leads the follower robots in a team. The leader has specialized capabilities or mission critical information (e.g. goal location) that the followers lack, and this makes the leader crucial for the mission\u2019s success. However, this also makes the leader a vulnerability -an external adversary who wishes to sabotage the robot team\u2019s mission can simply harm the leader and the whole robot team\u2019s mission would be compromised. Since robot motion generated by traditional leader-follower navigation algorithms can reveal the identity of the leader, we propose a defense mechanism of hiding the leader\u2019s identity by ensuring the leader moves in a way that behaviorally camouflages it with the followers, making it difficult for an adversary to identify the leader. To achieve this, we combine Multi-Agent Reinforcement Learning, Graph Neural Networks and adversarial training. Our approach enables the multi-robot team to optimize the primary task performance with leader motion similar to follower motion, behaviorally camouflaging it with the followers. Our algorithm outperforms existing work that tries to hide the leader\u2019s identity in a multi-robot team by tuning traditional leader-follower control parameters with Classical Genetic Algorithms. We also evaluated human performance in inferring the leader\u2019s identity and found that humans had lower accuracy when the robot team used our proposed navigation algorithm.",
        "primary_area": "",
        "author": "Ankur Deka;Wenhao Luo;Huao Li;Michael Lewis;Katia Sycara;Ankur Deka;Wenhao Luo;Huao Li;Michael Lewis;Katia Sycara",
        "authorids": "/37089193949;/37085748889;/37086606065;/37275839500;/37268476900;/37089193949;/37085748889;/37086606065;/37275839500;/37268476900",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; School of Computing and Information, University of Pittsburgh, Pittsburgh, USA; School of Computing and Information, University of Pittsburgh, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636314/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9062927304913777404&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Carnegie Mellon University;University of Pittsburgh",
        "aff_unique_dep": "Robotics Institute;School of Computing and Information",
        "aff_unique_url": "https://www.cmu.edu;https://www.pitt.edu",
        "aff_unique_abbr": "CMU;Pitt",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635913",
        "title": "Hierarchical Segment-based Optimization for SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a hierarchical segment-based optimization method for Simultaneous Localization and Mapping (SLAM) system. First we propose a reliable trajectory segmentation method that can be used to increase efficiency in the back-end optimization. Then we propose a buffer mechanism for the first time to improve the robustness of the segmentation. During the optimization, we use global information to optimize the frames with large error, and interpolation instead of optimization to update well-estimated frames to hierarchically allocate the amount of computation according to error of each frame. Comparative experiments on the benchmark show that our method greatly improves the efficiency of optimization with almost no drop in accuracy, and outperforms existing high-efficiency optimization method by a large margin.",
        "primary_area": "",
        "author": "Yuxin Tian;Yujie Wang;Ming Ouyang;Xuesong Shi;Yuxin Tian;Yujie Wang;Ming Ouyang;Xuesong Shi",
        "authorids": "/37088503927;/37087006825;/37088801988;/37086577986;/37088503927;/37087006825;/37088801988;/37086577986",
        "aff": "Intel Corporation, Beijing, China; Intel Corporation, Beijing, China; Intel Corporation, Beijing, China; Intel Corporation, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635913/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5603120454118881651&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Intel",
        "aff_unique_dep": "Intel Corporation",
        "aff_unique_url": "https://www.intel.com",
        "aff_unique_abbr": "Intel",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636738",
        "title": "Hierarchical Terrain-Aware Control for Quadrupedal Locomotion by Combining Deep Reinforcement Learning and Optimal Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadruped robots possess advantages on different terrains over other types of mobile robots by virtue of their flexible choices of foothold points. It is crucial to integrate terrain perception with motion planning to exploit the potential of quadruped robots. We propose a novel hierarchical terrain-aware control (HTC) framework, which leverages deep reinforcement learning (DRL) for the high-level planner and optimal control for the low-level controller. In general, traditional control methods yield better stability by using an optimization algorithm. In addition, DRL is able to offer more adaptive behavior. Our approach makes full use of the advantages of these two methods and possesses better adaptability and stability in challenging natural environments. Furthermore, the global height map of the terrain serves as visual information for the DRL, which determines the desired footholds for the robot\u2019s leg swings and body postures. Optimal control calculates the torque of the joints on the standing legs to maintain body balance. Our method is tested on various terrains both simulated and real environments. The experimental results show that HTC can effectively enhance the adaptability of the quadruped robot by coordinating body posture.",
        "primary_area": "",
        "author": "Qingfeng Yao;Jilong Wang;Donglin Wang;Shuyu Yang;Hongyin Zhang;Yinuo Wang;Zhengqing Wu;Qingfeng Yao;Jilong Wang;Donglin Wang;Shuyu Yang;Hongyin Zhang;Yinuo Wang;Zhengqing Wu",
        "authorids": "/37086958447;/37089194886;/37405353300;/37089197986;/37088595146;/37089195393;/37089194362;/37086958447;/37089194886;/37405353300;/37089197986;/37088595146;/37089195393;/37089194362",
        "aff": "Institute of Advanced Technology, Westlake Institute for Advanced Study, Hangzhou, China; MiLAB, Westlake University; Institute of Advanced Technology, Westlake Institute for Advanced Study, Hangzhou, China; Institute of Advanced Technology, Westlake Institute for Advanced Study, Hangzhou, China; Institute of Advanced Technology, Westlake Institute for Advanced Study, Hangzhou, China; Institute of Advanced Technology, Westlake Institute for Advanced Study, Hangzhou, China; Institute of Advanced Technology, Westlake Institute for Advanced Study, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636738/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3515269662707408668&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;0;0",
        "aff_unique_norm": "Westlake Institute for Advanced Study;Westlake University",
        "aff_unique_dep": "Institute of Advanced Technology;MiLAB",
        "aff_unique_url": "http://www.wias.org.cn/;https://www.westlake.edu.cn/",
        "aff_unique_abbr": "WIAS;",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636749",
        "title": "High Accuracy Three-Dimensional Self-Localization using Visual Markers and Inertia Measurement Unit",
        "track": "main",
        "status": "Poster",
        "abstract": "Technologies for estimating self-position and orientation are important for both humans and robots. These technologies allow robots to perform tasks such as carrying objects and allow people to reach their destinations. Although self-position estimation technologies using GPS and laser rangefinders have been developed, few methods can be used by both humans and robots. Therefore, we developed a method that can estimate three-dimensional position and orientation using visual markers and an inertia measurement unit (IMU). Self-position can be measured with high accuracy by using a visual marker and monocular camera, but such measurement data is discrete and sparse. In contrast, an IMU can continuously measure acceleration data, but data obtained from an acceleration sensor are double-integrated, which increases position error. By combining visual marker and IMU information, position error calculations based on the acceleration sensor can be corrected, and the movement path of the object can be estimated. In demonstration experiments, the proposed method accurately estimates the three-dimensional movement distance when a person walks about 13 m, with an average error of about 40.3mm.",
        "primary_area": "",
        "author": "Kunihiro Ogata;Hideyuki Tanaka;Yoshio Matsumoto;Kunihiro Ogata;Hideyuki Tanaka;Yoshio Matsumoto",
        "authorids": "/37647366000;/37676195700;/37272999900;/37647366000;/37676195700;/37272999900",
        "aff": "Human Augmentation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Chiba, Japan; Human Augmentation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Chiba, Japan; Human Augmentation Research Center, National Institute of Advanced Industrial Science and Technology (AIST), Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636749/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10528951919903314209&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Human Augmentation Research Center",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chiba",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636520",
        "title": "Human Motion Imitation using Optimal Control with Time-Varying Weights",
        "track": "main",
        "status": "Poster",
        "abstract": "Research in biomechanics hypothesizes that human motion is optimal with respect to an unknown cost function that varies depending on the action and/or task. This unknown cost function is often approximated as the weighted sum of a set of features or basis cost functions. As a person performs a sequence of actions, the weights associated to each of these basis functions are likely to vary over time. Given a human demonstration and the corresponding cost weight trajectory recovered via inverse optimal control (IOC), this paper proposes an optimal control (OC) method that can generate robot motion based on human movement using time-varying cost function weights. By using time-varying weights, the proposed optimal control method can handle changing optimization criteria without segmentation. The method is evaluated both in simulation and with recorded human data. Using human demonstration data, we demonstrate the reproduction of pick-and-place motions with an average end-effector error at the pick place location within 0.82 cm, which is significantly lower than the average trajectory error, indicating that the approach correctly prioritizes reaching the pick and place locations without manual segmentation.",
        "primary_area": "",
        "author": "Shouyo Ishida;Tatsuki Harada;Pamela Carreno-Medrano;Dana Kuli\u0107;Gentiane Venture;Shouyo Ishida;Tatsuki Harada;Pamela Carreno-Medrano;Dana Kuli\u0107;Gentiane Venture",
        "authorids": "/37089196199;/37088341510;/37085631152;/37547876700;/37546539800;/37089196199;/37088341510;/37085631152;/37547876700;/37546539800",
        "aff": "Department of Mechanical System Engineering, Tokyo University of Agriculture and Technology, Tokyo, Japan; Robotics Technology Dept., Technology Research Center, Sumitomo Heavy Industries, Ltd., Tokyo, Japan; Department of Electrical and Computer Systems Engineering, Monash University, Melbourne, Australia; Department of Electrical and Computer Systems Engineering, Monash University, Melbourne, Australia; Department of Mechanical System Engineering, Tokyo University of Agriculture and Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636520/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5266172490700685537&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;0",
        "aff_unique_norm": "Tokyo University of Agriculture and Technology;Sumitomo Heavy Industries, Ltd.;Monash University",
        "aff_unique_dep": "Department of Mechanical System Engineering;Robotics Technology Dept.;Department of Electrical and Computer Systems Engineering",
        "aff_unique_url": "https://www.tuat.ac.jp;https://www.shi.co.jp;https://www.monash.edu",
        "aff_unique_abbr": "TUAT;;Monash",
        "aff_campus_unique_index": "0;2;2;0",
        "aff_campus_unique": "Tokyo;;Melbourne",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "Japan;Australia"
    },
    {
        "id": "9636418",
        "title": "Human guided trajectory and impedance adaptation for tele-operated physical assistance",
        "track": "main",
        "status": "Poster",
        "abstract": "Human physical assistance requires the assistant to tune both his trajectory and impedance in order to assist an individual as well as be guided by him. In this study we propose a controller for teleoperated human assistance that allows the assistant to guide the assisting robot in both trajectory and impedance. We propose to use the inherent perturbations in the task, induced by the elderly or stroke patient, for impedance estimation, while a simple neuroscience based filter allows the reference estimation of the operator. We tested our impedance estimation and the controller as a whole in two experiments in which a human operator guided a robot suffering force perturbations that simulated a human patient.",
        "primary_area": "",
        "author": "Guillaume Gourmelen;Benjamin Navarro;Andrea Cherubini;Gowrishankar Ganesh;Guillaume Gourmelen;Benjamin Navarro;Andrea Cherubini;Gowrishankar Ganesh",
        "authorids": "/37089194401;/37085769132;/37594774400;/37274061900;/37089194401;/37085769132;/37594774400;/37274061900",
        "aff": "UM-Cnrs Laboratoire d\u2019Informatique de Robotique et de Microelectron-Ique de Montpellier (LIRMM), France; UM-Cnrs Laboratoire d\u2019Informatique de Robotique et de Microelectron-Ique de Montpellier (LIRMM), France; UM-Cnrs Laboratoire d\u2019Informatique de Robotique et de Microelectron-Ique de Montpellier (LIRMM), France; UM-Cnrs Laboratoire d\u2019Informatique de Robotique et de Microelectron-Ique de Montpellier (LIRMM), France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636418/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4193231250371431295&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Montpellier",
        "aff_unique_dep": "Laboratoire d\u2019Informatique de Robotique et de Microelectron-Ique de Montpellier",
        "aff_unique_url": "https://www.lirmm.fr",
        "aff_unique_abbr": "LIRMM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Montpellier",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636613",
        "title": "Human-Aware Navigation Planner for Diverse Human-Robot Interaction Contexts",
        "track": "main",
        "status": "Poster",
        "abstract": "As more robots are being deployed into human environments, a human-aware navigation planner needs to handle multiple contexts that occur in indoor and outdoor environments. In this paper, we propose a tunable human-aware robot navigation planner that can handle a variety of human-robot contexts. We present the architecture of the system and discuss the features along with some implementation details. Then we present a detailed analysis of various simulated human-robot contexts using the proposed planner. Further, we show that our system performs better when compared with an exiting human-aware planner in various contexts. Finally, we show the results in a real-world scenario after deploying our system on a real robot.",
        "primary_area": "",
        "author": "Phani Teja Singamaneni;Anthony Favier;Rachid Alami;Phani Teja Singamaneni;Anthony Favier;Rachid Alami",
        "authorids": "/37089194066;/37088448627;/37278643600;/37089194066;/37088448627;/37278643600",
        "aff": "LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636613/",
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6077528071803703305&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "LAAS-CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.laas.fr/",
        "aff_unique_abbr": "LAAS-CNRS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toulouse",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636463",
        "title": "Human-Inspired Multi-Agent Navigation using Knowledge Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite significant advancements in the field of multi-agent navigation, agents still lack the sophistication and intelligence that humans exhibit in multi-agent settings. In this paper, we propose a framework for learning a human-like general collision avoidance policy for agent-agent interactions in fully decentralized, multi-agent environments. Our approach uses knowledge distillation with reinforcement learning to shape the reward function based on expert policies extracted from human trajectory demonstrations through behavior cloning. We show that agents trained with our approach can take human-like trajectories in collision avoidance and goal-directed steering tasks not provided by the demonstrations, outperforming the experts as well as learning-based agents trained without knowledge distillation.",
        "primary_area": "",
        "author": "Pei Xu;Ioannis Karamouzas;Pei Xu;Ioannis Karamouzas",
        "authorids": "/37088544873;/38111249000;/37088544873;/38111249000",
        "aff": "School of Computing, Clemson University, South Carolina, USA; School of Computing, Clemson University, South Carolina, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636463/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8005194589225872012&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Clemson University",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.clemson.edu",
        "aff_unique_abbr": "Clemson",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "South Carolina",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635910",
        "title": "Human-Robot Collaboration for Heavy Object Manipulation: Kinesthetic Teaching of the Role of Wheeled Mobile Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot collaboration (HRC) significantly extends robotic systems\u2019 applications when working in spaces like houses, hospitals, or laboratories. However, new challenges appear during a close collaboration between humans and robots and imitating the movement of humans by robots. Learning from demonstration (LfD), or kinesthetic teaching, is a popular approach to help teach a robot human behavior by demonstrations without the need to explicitly reprogram the robot for different procedures. In this paper, we propose a method for object manipulation, including lifting, carrying, and lowering the object through a collaboration of a human with a wheeled mobile manipulator (WMM). The WMM is first trained with the help of a human demonstrator to collaborate with the user to execute the task. Then, the WMM will independently cooperate with the user by reproducing the learned skills to perform the same task. The redundancy of the WMM will also be employed to enhance its force exertion capability in the vertical direction to offset the object\u2019s weight. The advantages and effectiveness of the proposed method are investigated through experiments.",
        "primary_area": "",
        "author": "Hongjun Xing;Ali Torabi;Liang Ding;Haibo Gao;Weihua Li;Vivian K. Mushahwar;Mahdi Tavakoli;Hongjun Xing;Ali Torabi;Liang Ding;Haibo Gao;Weihua Li;Vivian K. Mushahwar;Mahdi Tavakoli",
        "authorids": "/37085871400;/37086366170;/37529158200;/37535800300;/37085392772;/37281914300;/37282400400;/37085871400;/37086366170;/37529158200;/37535800300;/37085392772;/37281914300;/37282400400",
        "aff": "Department of Electrical and Computer Engineering, University of Alberta, Alberta, Canada; Department of Electrical and Computer Engineering, University of Alberta, Alberta, Canada; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; Department of Medicine, Division of Physical Medicine and Rehabilitation, University of Alberta, Alberta, Canada; Department of Electrical and Computer Engineering, University of Alberta, Alberta, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635910/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6350116790804874007&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;1;0;0",
        "aff_unique_norm": "University of Alberta;Harbin Institute of Technology",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;State Key Laboratory of Robotics and System",
        "aff_unique_url": "https://www.ualberta.ca;http://www.hit.edu.cn/",
        "aff_unique_abbr": "UAlberta;HIT",
        "aff_campus_unique_index": "0;0;1;1;1;0;0",
        "aff_campus_unique": "Alberta;Harbin",
        "aff_country_unique_index": "0;0;1;1;1;0;0",
        "aff_country_unique": "Canada;China"
    },
    {
        "id": "9635894",
        "title": "Human-Robot greeting: tracking human greeting mental states and acting accordingly",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile social robots should be able to engage in interaction with people effectively. However, greeting someone is a complex task since it implies an exchange of social signals. Adam Kendon modeled human greetings as a set of six phases: initiation of approach, distance salutation, head dip, approach, final approach, and close salutation. Based on Kendon\u2019s model, we propose a system for mobile social robots that manages the greeting process through the exchange of social signals. A Hidden Markov Model keeps track of the greeting stage through the observation of the human gestures, while a behavior tree generates appropriate robot actions. We used publicly available datasets to train the Hidden Markov Model. Evaluation on test sets showed an average greeting phase estimation accuracy of 80.9%. We tested the full system (Hidden Markov Model + Behavior Tree) in simulation and in a real world pilot experiment using the Vizzy robot, and it recognized and replicated the correct phase with an accuracy of 91.8% and 53.8%, respectively.",
        "primary_area": "",
        "author": "Manuel Carvalho;Jo\u00e3o Avelino;Alexandre Bernardino;Rodrigo Ventura;Plinio Moreno;Manuel Carvalho;Jo\u00e3o Avelino;Alexandre Bernardino;Rodrigo Ventura;Plinio Moreno",
        "authorids": "/37089194973;/37086581004;/37442087500;/37376311800;/38274327100;/37089194973;/37086581004;/37442087500;/37376311800;/38274327100",
        "aff": "Instituto Superior T\u00e9cnico, Universidade de Lisboa; ISR-Lisboa, Instituto Superior T\u00e9cnico, Univ. Lisboa; ISR-Lisboa, Instituto Superior T\u00e9cnico, Univ. Lisboa; ISR-Lisboa, Instituto Superior T\u00e9cnico, Univ. Lisboa; ISR-Lisboa, Instituto Superior T\u00e9cnico, Univ. Lisboa",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635894/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13899338476496716117&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Universidade de Lisboa;Instituto Superior T\u00e9cnico",
        "aff_unique_dep": "Instituto Superior T\u00e9cnico;ISR-Lisboa",
        "aff_unique_url": "https://www IST.edu.pt;https://www.ist.utl.pt",
        "aff_unique_abbr": "IST;IST",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Lisboa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "9636269",
        "title": "Hybrid Data-Driven Modelling for Inverse Control of Hydraulic Excavators",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a comprehensive comparison of hybrid Data-Driven Control (DDC) applied on a hydraulic excavator. DDC offers a state-of-the-art, high performance control based on data and expert knowledge. On the one hand, expert knowledge is complex to adapt to each unique excavator requiring substantial engineering efforts. On the other hand, purely data based control overcomes this drawback by adapting a Neural Network (NN) inverse control directly on measured input/output data. Yet, coverage of the entire phase space and extrapolation to unknown situations is challenging for solely data-driven approaches. On a real demonstrator, we analyze expert white box methods, solely data-driven black box approaches and a hybrid grey box approach which combines a data-driven and simplified expert model. We examine trajectory tracking performance, engineering effort and safe exploration as goal criteria. Besides various experiments for testing safety, we apply a Support-Vector-Machine (SVM) to analyze the extrapolation fitness of the data-driven components to unknown data.",
        "primary_area": "",
        "author": "Jonas Weigand;Julian Raible;Nico Zantopp;Ozan Demir;Adrian Trachte;Achim Wagner;Martin Ruskowski;Jonas Weigand;Julian Raible;Nico Zantopp;Ozan Demir;Adrian Trachte;Achim Wagner;Martin Ruskowski",
        "authorids": "/37089195215;/37089197248;/37089197899;/37089197558;/37088331150;/37089194505;/37086405564;/37089195215;/37089197248;/37089197899;/37089197558;/37088331150;/37089194505;/37086405564",
        "aff": "German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; Chair of Machine Tools and Control Systems, Technical University, Kaiserslautern, Germany; Robert Bosch GmbH, Stuttgart, Germany; Robert Bosch GmbH, Stuttgart, Germany; Robert Bosch GmbH, Stuttgart, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636269/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4523538558914552418&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;2;2;0;0",
        "aff_unique_norm": "German Research Center for Artificial Intelligence;Technical University of Kaiserslautern;Robert Bosch GmbH",
        "aff_unique_dep": ";Chair of Machine Tools and Control Systems;",
        "aff_unique_url": "https://www.dFKI.de;https://www.uni-kl.de;https://www.bosch.com",
        "aff_unique_abbr": "DFKI;TU Kaiserslautern;Bosch",
        "aff_campus_unique_index": "0;0;1;1;1;0;0",
        "aff_campus_unique": "Kaiserslautern;Stuttgart",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636110",
        "title": "Hybrid Graph Convolutional Networks for Skeleton-Based and EEG-Based Jumping Action Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Kinematic information obtained directly from the skeletal model has been useful for jumping action recognition. Current research focuses on dynamic analysis based on the video stream. Although skeletal data can accurately capture the high-level information of human action, it ignores the brain\u2019s pre-execution command information, which plays a crucial role in identifying jumping action. Therefore, we proposed a hybrid model based on brain network and dynamic skeleton. Specifically, we used a brain network graph convolutional network (BNGCN) to encode brain command information. Also, a dynamic skeleton convolutional network (DSGCN) using the angular velocity of skeleton nodes instead of video is proposed, which can break the fixed experimental area\u2019s limitation. BNGCN and DSGCN are fused through three network nodes to construct an end-to-end Brain Network and Dynamic Skeleton Hybrid Model. Our contribution consists of three parts. First, we have created a data set that can be used for jumping action and its sub-phase recognition. Second, BNGCN is used to extract brain command information for jumping action recognition. Third, a hybrid model is proposed to incorporate brain command and skeleton kinematic information. The results show that our hybrid model can effectively capture the high-level features for jumping action recognition. The method outperforms compared methods for jumping action recognition.",
        "primary_area": "",
        "author": "Naishi Feng;Fo Hu;Hong Wang;Ziqi Zhao;Naishi Feng;Fo Hu;Hong Wang;Ziqi Zhao",
        "authorids": "/37086517677;/37086517743;/37716019300;/37089194685;/37086517677;/37086517743;/37716019300;/37089194685",
        "aff": "Department of Mechanical Engineering and Automation, Northeastern University, Shenyang, China; Department of Mechanical Engineering and Automation, Northeastern University, Shenyang, China; Department of Mechanical Engineering and Automation, Northeastern University, Shenyang, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636110/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16330048694385410156&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Northeastern University;Southern University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering and Automation;Department of Electrical and Electronic Engineering",
        "aff_unique_url": "http://www.neu.edu.cn/;https://www.sustech.edu.cn",
        "aff_unique_abbr": "NEU;SUSTech",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Shenyang;Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636600",
        "title": "Hybrid ICP",
        "track": "main",
        "status": "Poster",
        "abstract": "ICP algorithms typically involve a fixed choice of data association method and a fixed choice of error metric. In this paper, we propose Hybrid ICP, a novel and flexible ICP variant which dynamically optimises both the data association method and error metric based on the live image of an object and the current ICP estimate. We show that when used for object pose estimation, Hybrid ICP is more accurate and more robust to noise than other commonly used ICP variants. We also consider the setting where ICP is applied sequentially with a moving camera, and we study the trade-off between the accuracy of each ICP estimate and the number of ICP estimates available within a fixed amount of time.",
        "primary_area": "",
        "author": "Kamil Dreczkowski;Edward Johns;Kamil Dreczkowski;Edward Johns",
        "authorids": "/37089197660;/37602799000;/37089197660;/37602799000",
        "aff": "The Robot Learning Lab, Imperial College London; The Robot Learning Lab, Imperial College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636600/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16819210316275211996&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "The Robot Learning Lab",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636851",
        "title": "Hybrid Magnetic Force and Torque Actuation of Miniature Helical Robots Using Mobile Coils to Accelerate Blood Clot Removal",
        "track": "main",
        "status": "Poster",
        "abstract": "Mechanical rubbing of blood clot using miniature magnetic helical robots is a potential way for thrombolysis. In this paper, we report a new strategy for this issue based on mobile coils. Previously, we proposed the concept of magnetic actuation with parallel mobile coils, in which multiple coils can move in 3D space. Enabled by mobility of the coils, additional degree-of-freedom (DOF) could be utilized for actuation performance optimization. Besides the primary helical propulsion by rotating magnetic fields, our strategy aims to optimize the coil motion to make the magnetic force contributes the most to the helical robot forward motion. For this goal, modeling of the magnetic field and force of multiple mobile coils are presented, based on which an optimization algorithm is formulated to output the best coil motion. For validation, an enhanced mobile coil system having a workspace of \u03a6500 mm \u00d7150 mm is constructed based on the parallel mobile coil concept. Simulations show the effectiveness of the proposed strategy, whose effective workspace for a specific task can also be obtained. After implementing the proposed strategy, preliminary experiments using clot analog demonstrate that the removal speed is accelerated over 50% compared to that without coil motion optimization.",
        "primary_area": "",
        "author": "Lidong Yang;Moqiu Zhang;Haojin Yang;Zhengxin Yang;Li Zhang;Lidong Yang;Moqiu Zhang;Haojin Yang;Zhengxin Yang;Li Zhang",
        "authorids": "/37086079463;/37088704045;/37089198025;/37088506149;/37085379138;/37086079463;/37088704045;/37089198025;/37088506149;/37085379138",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong, China; Cuhk T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636851/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13512158848761832896&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636390",
        "title": "Hybrid Path Planning for UAV Traffic Management",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned Aircraft System Traffic Management (UTM) becomes a highly relevant complex challenge, as the UAV activity is rapidly growing bringing more amateur and professional drones to the urban skies. The main concern of managing such a system is safely navigating and controlling hundreds or thousands of drones simultaneously, flying in a crowded dense environments. This paper introduces an innovative approach of hybrid path planning, which tries to make the best out of the commonly used centralized and decentralized planning approaches. The Hybrid Path Planner (HPP) defines two configuration spaces: the Local Zone, which represents the crowded city zone with many obstacles and constrains, and the Global Zone, which represents the outer suburban zone, mostly open space with predefined flight corridors. The HPP server communicates with each UAV, assigning it a close-to-optimal path in the global zone, while leaving the relatively heavy-duty local zone path planning task to be performed by the UAV, mostly using stochastic methods like RRT*. This approach reduces the complex path panning task of the centralized server to a simpler task of calculating only the entry and exit points to and from the global zone. This robust approach supports handling a high number of UAVs, while keeping close to optimal performance.",
        "primary_area": "",
        "author": "Eyal Zehavi;Noa Agmon;Eyal Zehavi;Noa Agmon",
        "authorids": "/37089195073;/37695468400;/37089195073;/37695468400",
        "aff": "Faculty of Computer Science, Bar Ilan University, Ramat Gan, Israel; Faculty of Computer Science, Bar Ilan University, Ramat Gan, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636390/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6364070749223132540&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Bar-Ilan University",
        "aff_unique_dep": "Faculty of Computer Science",
        "aff_unique_url": "https://www.biu.ac.il",
        "aff_unique_abbr": "BIU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ramat Gan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9636450",
        "title": "Hybrid Volitional Control as a Framework for Lower-Limb Prosthetic Control: A Simulation Study",
        "track": "main",
        "status": "Poster",
        "abstract": "Realizing the potential of active lower-limb pros-theses to increase user mobility and efficiency requires safe, reliable, stable, and intuitive control strategies. The two prevailing classes of lower-limb prosthesis control can be categorized as volitional and non-volitional. Volitional control strategies (VCs) directly sense the user\u2019s intentions, but this generally intuitive approach can be quite demanding, leading to user fatigue and device misactivation. Non-volitional control strategies (NVCs) sense the state of the system instead, often taking advantage of the gait\u2019s cyclic nature to produce robust and reliable outputs. NVCs, however, do not give the user freedom to realize non-standard movements. This paper introduces a Hybrid Volitional Control (HVC) approach that operates across the entire gait cycle and seeks to balance the reliability, safety, and low demand of NVCs with the freedom and intuitive control of VCs. Through simulations of 2.5\u00b0 ramp descent, level ground walking, and 5\u00b0 ramp ascent, HVC shows an opportunity to reduce the torque error from an able-bodied reference in all cases compared to two NVCs (as much as 94%). Similarly, HVC shows an opportunity to reduce volitional demands compared to a pure VC (as much as 91%). Volitional thresholding is considered for users to ambulate reliably with minimal volitional input demands, while maintaining continuous freedom to alter the dynamics of the device. HVC could allow users to participate in a wider range of activities, helping to further erase the distinction between ability and disability from amputation.",
        "primary_area": "",
        "author": "Ryan R. Posh;James P. Schmiedeler;Patrick M. Wensing;Ryan R. Posh;James P. Schmiedeler;Patrick M. Wensing",
        "authorids": "/37089886270;/37282121600;/37946046300;/37089886270;/37282121600;/37946046300",
        "aff": "Department of Aerospace and Mechanical Engineering, 365 Fitzpatrick Hall of Engineering, University of Notre Dame, Notre Dame, Indiana; Department of Aerospace and Mechanical Engineering, 365 Fitzpatrick Hall of Engineering, University of Notre Dame, Notre Dame, Indiana; Department of Aerospace and Mechanical Engineering, 365 Fitzpatrick Hall of Engineering, University of Notre Dame, Notre Dame, Indiana",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636450/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1385422479626683123&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Aerospace and Mechanical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Notre Dame",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636651",
        "title": "HyperPlan: A Framework for Motion Planning Algorithm Selection and Parameter Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Over the years, many motion planning algorithms have been proposed. It is often unclear which algorithm might be best suited for a particular class of problems. The problem is compounded by the fact that algorithm performance can be highly dependent on parameter settings. This paper shows that hyperparameter optimization is an effective tool in both algorithm selection and parameter tuning over a given set of motion planning problems. We present different loss functions for optimization that capture different notions of optimality. The approach is evaluated on a broad range of scenes using two different manipulators, a Fetch and a Baxter. We show that optimized planning algorithm performance significantly improves upon baseline performance and generalizes broadly in the sense that performance improvements carry over to problems that are very different from the ones considered during optimization.",
        "primary_area": "",
        "author": "Mark Moll;Constantinos Chamzas;Zachary Kingston;Lydia E. Kavraki;Mark Moll;Constantinos Chamzas;Zachary Kingston;Lydia E. Kavraki",
        "authorids": "/596340879194260;/37086933748;/37085542480;/37279015600;/596340879194260;/37086933748;/37085542480;/37279015600",
        "aff": "Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636651/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14197419100520912944&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636429",
        "title": "I3SA: The Increased Step Size Stability Assessment Benchmark and its Application to the Humanoid Robot REEM-C",
        "track": "main",
        "status": "Poster",
        "abstract": "The implementation of stable locomotion on humanoid robots is a difficult task. This is complicated by the fact that there is no uniform method for analyzing a robot and its control architecture and for calculating indicators to quantify performance of flat ground walking. Moreover, there is no widely accepted indicator do distinct between a stable and unstable state of the robot. We propose the Increased Step Size Stability Assessment (I3SA) as a testing protocol and standardized procedure for data collection and evaluation of stability for locomotion on flat terrain. We apply this test to the humanoid robot REEM-C. The biped must cover a set distance of four meters with predefined step sizes. The initial step size is defined as 20% of the total leg length of the robot. After three successful trials, the step size is continuously increased until REEM-C\u2019s last successful trial at 40% of its total leg length, leading to REEM-C\u2019s I3SA rating of 40. The recorded data are evaluated using metrics known from the literature, such as the capture point, foot placement estimator, and the angular momentum acting at the center of mass. We illustrate the experimental setup, data collection and processing, the calculation of performance indicators for several step sizes and the trial which resulted in a fall of the robot. The trend towards decreasing stability with increased step size and the available key assumptions are reported.",
        "primary_area": "",
        "author": "Felix Aller;Monika Harant;Sebastian Sontag;Matthew Millard;Katja Mombaur;Felix Aller;Monika Harant;Sebastian Sontag;Matthew Millard;Katja Mombaur",
        "authorids": "/37087406688;/37086177020;/37089197246;/37086051711;/37324399400;/37087406688;/37086177020;/37089197246;/37086051711;/37324399400",
        "aff": "Optimization, Robotics and Biomechanics Chair, Institute of Computer Engineering, Heidelberg University, Heidelberg, Germany; Department of Mathematics for the Digital Factory, Fraunhofer Institute for Industrial Mathematics, Kaiserslautern, Germany; Optimization, Robotics and Biomechanics Chair, Institute of Computer Engineering, Heidelberg University, Heidelberg, Germany; Optimization, Robotics and Biomechanics Chair, Institute of Computer Engineering, Heidelberg University, Heidelberg, Germany; Canada Excellence Research Chair in Human-Centred Robotics and Machine Intelligence, Faculty of Engineering, University of Waterloo, Waterloo, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636429/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4357239127830473610&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;2",
        "aff_unique_norm": "Heidelberg University;Fraunhofer Institute for Industrial Mathematics;University of Waterloo",
        "aff_unique_dep": "Institute of Computer Engineering;Department of Mathematics for the Digital Factory;Faculty of Engineering",
        "aff_unique_url": "https://www.uni-heidelberg.de;https://www.fraunhofer.de/en/institutes/fraunhofer-institute-for-industrial-mathematics-itm.html;https://uwaterloo.ca",
        "aff_unique_abbr": "Uni HD;Fraunhofer ITM;UWaterloo",
        "aff_campus_unique_index": "0;1;0;0;2",
        "aff_campus_unique": "Heidelberg;Kaiserslautern;Waterloo",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Germany;Canada"
    },
    {
        "id": "9636710",
        "title": "ILoSA: Interactive Learning of Stiffness and Attractors",
        "track": "main",
        "status": "Poster",
        "abstract": "Teaching robots how to apply forces according to our preferences is still an open challenge that has to be tackled from multiple engineering perspectives. This paper studies how to learn variable impedance policies where both the Cartesian stiffness and the attractor can be learned from human demonstrations and corrections with a user-friendly interface. The presented framework, named ILoSA, uses Gaussian Processes for policy learning, identifying regions of uncertainty and allowing interactive corrections, stiffness modulation and active disturbance rejection. The experimental evaluation of the framework is carried out on a Franka-Emika Panda in four separate cases with unique force interaction properties: 1) pulling a plug wherein a sudden force discontinuity occurs upon successful removal of the plug, 2) pushing a box where a sustained force is required to keep the robot in motion, 3) wiping a whiteboard in which the force is applied perpendicular to the direction of movement, and 4) inserting a plug to verify the usability for precision-critical tasks in an experimental validation performed with non-expert users.",
        "primary_area": "",
        "author": "Giovanni Franzese;Anna M\u00e9sz\u00e1ros;Luka Peternel;Jens Kober;Giovanni Franzese;Anna M\u00e9sz\u00e1ros;Luka Peternel;Jens Kober",
        "authorids": "/37088418893;/37089195400;/37077670700;/37542833400;/37088418893;/37089195400;/37077670700;/37542833400",
        "aff": "Cognitive Robotics, Delft University of Technology, The Netherlands; Cognitive Robotics, Delft University of Technology, The Netherlands; Cognitive Robotics, Delft University of Technology, The Netherlands; Cognitive Robotics, Delft University of Technology, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636710/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11168566698860765447&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Cognitive Robotics",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TUDelft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9636109",
        "title": "ISSAFE: Improving Semantic Segmentation in Accidents by Fusing Event-based Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Ensuring the safety of all traffic participants is a prerequisite for bringing intelligent vehicles closer to practical applications. The assistance system should not only achieve high accuracy under normal conditions, but obtain robust perception against extreme situations. However, traffic accidents that involve object collisions, deformations, overturns, etc., yet unseen in most training sets, will largely harm the performance of existing semantic segmentation models. To tackle this issue, we present a rarely addressed task regarding semantic segmentation in accidental scenarios, along with an accident dataset DADA-seg. It contains 313 various accident sequences with 40 frames each, of which the time windows are located before and during a traffic accident. Every 11th frame is manually annotated for benchmarking the segmentation performance. Furthermore, we propose a novel event-based multi-modal segmentation architecture ISSAFE. Our experiments indicate that event-based data can provide complementary information to stabilize semantic segmentation under adverse conditions by preserving fine-grain motion of fast-moving foreground (crash objects) in accidents. Our approach achieves +8.2% mIoU performance gain on the proposed evaluation set, exceeding more than 10 state-of-the-art segmentation methods. The proposed ISSAFE architecture is demonstrated to be consistently effective for models learned on multiple source databases including Cityscapes, KITTI-360, BDD and ApolloScape.",
        "primary_area": "",
        "author": "Jiaming Zhang;Kailun Yang;Rainer Stiefelhagen;Jiaming Zhang;Kailun Yang;Rainer Stiefelhagen",
        "authorids": "/37088953062;/37086488716;/37269459200;/37088953062;/37086488716;/37269459200",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636109/",
        "gs_citation": 60,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9125724864883198053&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636004",
        "title": "Identifying Performance Regression Conditions for Testing & Evaluation of Autonomous Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of identifying whether/how a black-box autonomous system has regressed in performance when compared to previous versions. The approach analyzes performance datasets (typically gathered through simulation-based testing) and automatically extracts test parameter clusters of predicted performance regression. First, surrogate modeling with quantile random forests is used to predict regions of performance regression with high confidence. The predicted regression landscape is then clustered in both the output space and input space to produce groupings of test conditions ranked by performance regression severity. This approach is analyzed using randomized test functions as well as through a case study to detect performance regression in autonomous surface vessel software.",
        "primary_area": "",
        "author": "Paul Stankiewicz;Marin Kobilarov;Paul Stankiewicz;Marin Kobilarov",
        "authorids": "/37086190885;/37546944400;/37086190885;/37546944400",
        "aff": "Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636004/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12404255613274534691&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636742",
        "title": "Identifying Valid Robot Configurations via a Deep Learning Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Many state-of-art robotics applications require fast and efficient motion planning algorithms. Existing motion planning methods become less effective as the dimensionality of the robot and its workspace increases, especially the computational cost of collision detection routines. In this work, we present a framework to address the cost of expensive primitive operations in sampling-based motion planning. This framework determines the validity of a sample robot configuration through a novel combination of a Contractive AutoEncoder (CAE), which captures an occupancy grids representation of the robot's workspace, and a Multilayer Perceptron (MLP), which efficiently predicts the collision state of the robot using the output from the CAE. We evaluate our framework on multiple planning problems with a variety of robots in 2D and 3D workspaces. The results show that (1) the framework is computationally efficient in all investigated problems, and (2) the framework generalizes well to new workspaces.",
        "primary_area": "",
        "author": "Tuan Tran;Chinwe Ekenna;Tuan Tran;Chinwe Ekenna",
        "authorids": "/37086318218;/37085676589;/37086318218;/37085676589",
        "aff": "Department of Computer Science, University at Albany, SUNY, NY, USA; Department of Computer Science, University at Albany, SUNY, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636742/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2784112635147710563&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University at Albany, SUNY",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.albany.edu",
        "aff_unique_abbr": "UAlbany",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Albany",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636439",
        "title": "Image-Based Joint State Estimation Pipeline for Sensorless Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning is a largely solved problem for robot arms with joint state feedback, but remains an area of research for sensorless manipulators such as toy robot arms and heavy equipment such as excavators and cranes. A promising approach to this problem is deep learning, which employs a pre-trained convolutional neural network to identify manipulator links and estimate joint states from a monocular camera video feed. Whereas manual labeling of training image sets is tedious and non-transferable, a simulation environment can automatically generate labeled training image sets of any size. The issue is the gap between simulated and real-world images. This paper solves this problem by implementing a Generative Adversarial Network. The complete joint state estimation pipeline is implemented and tested in hardware experiments to validate our proposed approach.",
        "primary_area": "",
        "author": "Mingjie Han;Bowen Xie;Martin Barczyk;Alireza Bayat;Mingjie Han;Bowen Xie;Martin Barczyk;Alireza Bayat",
        "authorids": "/37088998699;/37088997299;/37544927400;/37089197253;/37088998699;/37088997299;/37544927400;/37089197253",
        "aff": "Department of Mechanical Engineering, University of Alberta, Edmonton, Canada; Department of Mechanical Engineering, University of Alberta, Edmonton, Canada; Department of Mechanical Engineering, University of Alberta, Edmonton, Canada; Department of Civil and Environmental Engineering, University of Alberta, Edmonton, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636439/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17800952866467839799&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Edmonton",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636303",
        "title": "Image-Based Online Command Adaptation and Guidance to Arbitrarily Shaped Objects for Robot-Assisted Medical Procedures",
        "track": "main",
        "status": "Poster",
        "abstract": "Imaging techniques are established aids in surgical procedures and have become indispensable in modern medicine. Combined with robot-assisted systems, significantly higher precision can already be achieved today and work steps can be simplified. We hypothesize that algorithms can make the operations of the future safer and easier. The paper introduces an approach for the control of a robotic manipulator that, based on standardized imaging techniques, monitors and adapts externally given movement commands. The physician controls the system, benefits from the robot\u2019s precision, and movements will be intervened in if unwanted contact with the environment would occur. This is important, e.g., when operating near sensitive tissue, nerves or bone that must not be injured. Objects from the image data are considered in the control scheme and may have arbitrary shape and size. Furthermore, since the approach can be in principle adapted to any shape it is shown how robot operations in confined spaces, that are challenging to achieve using an external controller, can be simplified by the introduced approach. The online evaluation takes place in Cartesian space and is then transformed into joint space using the inverse kinematics. The approach is implemented using GAZEBO and a simulation study is performed for the 6-DOF industrial manipulator St\u00e4ubli TX2-60.",
        "primary_area": "",
        "author": "Jan Reinhold;Jonas Olschewski;Sebastian Lippross;Thomas Meurer;Jan Reinhold;Jonas Olschewski;Sebastian Lippross;Thomas Meurer",
        "authorids": "/37087324162;/37089197093;/37089195928;/37299134300;/37087324162;/37089197093;/37089195928;/37299134300",
        "aff": "Chair of Automatic Control, Faculty of Engineering, Kiel University, Kiel, Germany; Chair of Automatic Control, Faculty of Engineering, Kiel University, Kiel, Germany; Department of Orthopaedics and Trauma, University Medical Center Schleswig-Holstein, Kiel, Germany; Chair of Automatic Control, Faculty of Engineering, Kiel University, Kiel, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636303/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4893946358727226343&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Kiel University;University Medical Center Schleswig-Holstein",
        "aff_unique_dep": "Chair of Automatic Control;Department of Orthopaedics and Trauma",
        "aff_unique_url": "https://www.kieli-university.de;https://www.uke.de",
        "aff_unique_abbr": "CAU;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Kiel",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636359",
        "title": "Imagination-enabled Robot Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Many of today\u2019s robot perception systems aim at accomplishing perception tasks that are too simplistic and too hard. They are too simplistic because they do not require the perception systems to provide all the information needed to accomplish manipulation tasks. Typically the perception results do not include information about the part structure of objects, articulation mechanisms and other attributes needed for adapting manipulation behavior. On the other hand, the perception problems stated are also too hard because \u2014 unlike humans\u2014 the perception systems cannot leverage the expectations about what they will see to their full potential. Therefore, we investigate a variation of robot perception tasks suitable for robots accomplishing everyday manipulation tasks, such as household robots or a robot in a retail store. In such settings it is reasonable to assume that robots know most objects and have detailed models of them. We propose a perception system that maintains its beliefs about its environment as a scene graph with physics simulation and visual rendering. When detecting objects, the perception system retrieves the model of the object and places it at the corresponding place in a VR-based environment model. The physics simulation ensures that object detections that are physically not possible are rejected and scenes can be rendered to generate expectations at the image level. The result is a perception system that can provide useful information for manipulation tasks.",
        "primary_area": "",
        "author": "Patrick Mania;Franklin Kenghagho Kenfack;Michael Neumann;Michael Beetz;Patrick Mania;Franklin Kenghagho Kenfack;Michael Neumann;Michael Beetz",
        "authorids": "/37085777705;/37088998470;/37089269792;/37279125900;/37085777705;/37088998470;/37089269792;/37279125900",
        "aff": "Institute for Artificial Intelligence (IAI), University of Bremen; Institute for Artificial Intelligence (IAI), University of Bremen; Institute for Artificial Intelligence (IAI), University of Bremen; Institute for Artificial Intelligence (IAI), University of Bremen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636359/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7076597267697406645&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Bremen",
        "aff_unique_dep": "Institute for Artificial Intelligence (IAI)",
        "aff_unique_url": "https://www.uni-bremen.de",
        "aff_unique_abbr": "Uni Bremen",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636797",
        "title": "Imitation Learning with Approximated Behavior Cloning Loss",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent Imitation Learning (IL) techniques focus on adversarial imitation learning algorithms to learn from a fixed set of expert demonstrations. While these approaches are theoretically sound, they suffer from a number of problems such as poor sample efficiency, poor stability, and a host of issues that Generative Adversarial Networks (GANs) suffer from. In this paper we introduce a generalization of Behavior Cloning (BC) that is applicable in any IL setting. Our algorithm first approximates behavior cloning loss using a neural network and then uses that loss network to generate a loss signal which is minimized using standard supervised learning. We call the resulting algorithm family Approximated Behavior Cloning (ABC), introduce variants for each IL setting, and demonstrate an order of magnitude improvement in sample efficiency and increased stability in standard imitation learning environments.",
        "primary_area": "",
        "author": "Corey A. Lowman;Joshua S. McClellan;Galen E. Mullins;Corey A. Lowman;Joshua S. McClellan;Galen E. Mullins",
        "authorids": "/37089197412;/37089197564;/37085701586;/37089197412;/37089197564;/37085701586",
        "aff": "Johns Hopkins University Applied Physics Laboratory, Maryland, USA; Johns Hopkins University Applied Physics Laboratory, Maryland, USA; Johns Hopkins University Applied Physics Laboratory, Maryland, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636797/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9883282155841015454&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Applied Physics Laboratory",
        "aff_unique_url": "https://www.jhuapl.edu",
        "aff_unique_abbr": "JHU APL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Maryland",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636094",
        "title": "Impact Invariant Control with Applications to Bipedal Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "When legged robots impact their environment, they undergo large changes in their velocities in a small amount of time. Measuring and applying feedback to these velocities is challenging, and is further complicated due to uncertainty in the impact model and impact timing. This work proposes a general framework for adapting feedback control during impact by projecting the control objectives to a subspace that is invariant to the impact event. The resultant controller is robust to uncertainties in the impact event while maintaining maximum control authority over the impact invariant subspace. We demonstrate the utility of the projection on a walking controller for a planar five-link-biped and on a jumping controller for a compliant 3D bipedal robot, Cassie. The effectiveness of our method is shown to translate well on hardware.",
        "primary_area": "",
        "author": "William Yang;Michael Posa;William Yang;Michael Posa",
        "authorids": "/37089194719;/37085767813;/37089194719;/37085767813",
        "aff": "GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636094/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15143043554641363068&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636472",
        "title": "Impedance Control for a Flexible Robot Enhanced with Energy Tanks in the port-Hamiltonian Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "In modern robotics, the manipulators are no longer isolated under fully controlled conditions but rather conceived to work in unconstrained environments. Under these operations, compliant control and passivity properties of the robot are of great importance, and thus the system\u2019s energy function plays a crucial role in the control design. In this work, we propose a new design of cartesian impedance control for a flexible robot whose dynamics is represented within the port-Hamiltonian framework. To improve the performance of the system and maximize the capabilities of the robot, the robotic control system is enhanced with energy tanks that allow for temporarily non-passive operations, but ensure the passivity of the extended system. In addition, a secondary controller is designed using the port-Hamiltonian approach to cover the case of redundant robotic manipulators. The performance of the full control system is tested via simulations of the Kuka iiwa manipulator in closed loop with the proposed passivity-based controller. The results show a satisfactory performance of the control system for set-point regulation, external forces, time-varying reference trajectories, and parametric uncertainty.",
        "primary_area": "",
        "author": "Martin Mujica;Alejandro Donaire;Mourad Benoussaad;Jean-Yves Fourquet;Martin Mujica;Alejandro Donaire;Mourad Benoussaad;Jean-Yves Fourquet",
        "authorids": "/37088506956;/38152314000;/37586646300;/37723070600;/37088506956;/38152314000;/37586646300;/37723070600",
        "aff": "LGP-ENIT, University of Toulouse, Tarbes, France; University of Newcastle, NSW, Australia; LGP-ENIT, University of Toulouse, Tarbes, France; LGP-ENIT, University of Toulouse, Tarbes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636472/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12021410193971379824&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Toulouse;University of Newcastle",
        "aff_unique_dep": "LGP-ENIT;",
        "aff_unique_url": "https://www.univ-toulouse.fr;https://www.newcastle.edu.au",
        "aff_unique_abbr": ";UON",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tarbes;",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "France;Australia"
    },
    {
        "id": "9636135",
        "title": "Impedance-Based Collision Reaction Strategy via Internal Stress Loading in Cooperative Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Cooperative manipulation systems inherently cause internal stress on the common object. Many works have proposed methods to eliminate this internal stress. However, in this paper, we show that this property can be cautiously leveraged to compensate for external disturbance on the cooperative system, particularly disturbances that occur due to collision along the links of one of the cooperating robots. We present an impedance-based scheme to control the level of compensation, thereby regulating the internal stress on the object due to the applied compensation wrenches. Previously, we introduced a method to compensate for collision with one arm of the system, but that approach sometimes caused untenable stress on the object. With the impedance-based compensation strategy presented in this paper, a suitable trade-off between maintaining the desired pose of the grasped object and limiting the permissible internal stress on the object, is achieved. We demonstrate our approach by using two kuka arms to cooperatively grasp and lift a rod in simulation.",
        "primary_area": "",
        "author": "Victor Aladele;Seth Hutchinson;Victor Aladele;Seth Hutchinson",
        "authorids": "/37088687995;/37282386200;/37088687995;/37282386200",
        "aff": "Department of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636135/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2303072095402745691&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636239",
        "title": "Improving Competence via Iterative State Space Refinement",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite considerable efforts by human designers, accounting for every unique situation that an autonomous robotic system deployed in the real world could face is often an infeasible task. As a result, many such deployed systems still rely on human assistance in various capacities to complete certain tasks while staying safe. Competence-aware systems (CAS) is a recently proposed model for reducing such reliance on human assistance while in turn optimizing the system\u2019s global autonomous operation by learning its own competence. However, such systems are limited by a fixed model of their environment and may perform poorly if their a priori planning model does not include certain features that emerge as important over the course of the system\u2019s deployment. In this paper, we propose a method for improving the competence of a CAS over time by identifying important state features missing from the system\u2019s model and incorporating them into its state representation, thereby refining its state space. Our approach exploits information that exists in the standard CAS model and adds no extra work to the human. The result is an agent that better predicts human involvement, improving its competence, reliability, and overall performance.",
        "primary_area": "",
        "author": "Connor Basich;Justin Svegliato;Allyson Beach;Kyle H. Wray;Stefan Witwicki;Shlomo Zilberstein;Connor Basich;Justin Svegliato;Allyson Beach;Kyle H. Wray;Stefan Witwicki;Shlomo Zilberstein",
        "authorids": "/37087105976;/37072711700;/37089196228;/37086208879;/37085709708;/37285091900;/37087105976;/37072711700;/37089196228;/37086208879;/37085709708;/37285091900",
        "aff": "College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA; Alliance Innovation Lab Silicon Valley, Santa Clara, CA, USA; Alliance Innovation Lab Silicon Valley, Santa Clara, CA, USA; College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636239/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7735152716910645179&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "University of Massachusetts Amherst;Alliance Innovation Lab",
        "aff_unique_dep": "College of Information and Computer Sciences;",
        "aff_unique_url": "https://www.umass.edu;",
        "aff_unique_abbr": "UMass Amherst;",
        "aff_campus_unique_index": "0;0;0;1;1;0",
        "aff_campus_unique": "Amherst;Silicon Valley",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636112",
        "title": "Improving Driver Situation Awareness Prediction using Human Visual Sensory and Memory Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "Situation awareness (SA) is generally considered as the perception, understanding, and projection of objects\u2019 properties and positions. We believe if the system can sense drivers\u2019 SA, it can appropriately provide warnings for objects that drivers are not aware of. To investigate drivers\u2019 awareness, in this study, a human-subject experiment of driving simulation was conducted for data collection. While a previous predictive model for drivers\u2019 situation awareness utilized drivers\u2019 gaze movement only, this work utilizes object properties, characteristics of human visual sensory and memory mechanism. As a result, the proposed driver SA prediction model achieves over 70% accuracy and outperforms the baselines.",
        "primary_area": "",
        "author": "Haibei Zhu;Teruhisa Misu;Sujitha Martin;Xingwei Wu;Kumar Akash;Haibei Zhu;Teruhisa Misu;Sujitha Martin;Xingwei Wu;Kumar Akash",
        "authorids": "/37089198285;/37085998814;/38494473300;/37088637106;/37086089589;/37089198285;/37085998814;/38494473300;/37088637106;/37086089589",
        "aff": "Honda Research Institute USA, Inc, San Jose, CA, USA; Honda Research Institute USA, Inc, San Jose, CA, USA; Honda Research Institute USA, Inc, San Jose, CA, USA; Honda Research Institute USA, Inc, San Jose, CA, USA; Honda Research Institute USA, Inc, San Jose, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636112/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9847052861490474607&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Honda Research Institute USA, Inc",
        "aff_unique_dep": "",
        "aff_unique_url": "https://honda-ri.com",
        "aff_unique_abbr": "HRI USA",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "San Jose",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636488",
        "title": "Improving Grasp Stability with Rotation Measurement from Tactile Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Rotational displacement about the grasping point is a common grasp failure when an object is grasped at a location away from its center of gravity. Tactile sensors with soft surfaces, such as GelSight sensors, can detect the rotation patterns on the contacting surfaces when the object rotates. In this work, we propose a model-based algorithm that detects those rotational patterns and measures rotational displacement using the GelSight sensor. We also integrate the rotation detection feedback into a closed-loop regrasping framework, which detects the rotational failure of grasp in an early stage and drives the robot to a stable grasp pose. We validate our proposed rotation detection algorithm and grasp-regrasp system on self-collected dataset and online experiments to show how our approach accurately detects the rotation and increases grasp stability.",
        "primary_area": "",
        "author": "Raj Kolamuri;Zilin Si;Yufan Zhang;Arpit Agarwal;Wenzhen Yuan;Raj Kolamuri;Zilin Si;Yufan Zhang;Arpit Agarwal;Wenzhen Yuan",
        "authorids": "/37089195406;/37089194088;/37089195809;/37089000833;/37085486405;/37089195406;/37089194088;/37089195809;/37089000833;/37085486405",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636488/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10528309886514972988&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636657",
        "title": "Improving Kinodynamic Planners for Vehicular Navigation with Learned Goal-Reaching Controllers",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper aims to improve the path quality and computational efficiency of sampling-based kinodynamic planners for vehicular navigation. It proposes a learning framework for identifying promising controls during the expansion process of sampling-based planners. Given a dynamics model, a reinforcement learning process is trained offline to return a low-cost control that reaches a local goal state (i.e., a waypoint) in the absence of obstacles. By focusing on the system\u2019s dynamics and not knowing the environment, this process is data-efficient and takes place once for a robotic system. In this way, it can be reused in different environments. The planner generates online local goal states for the learned controller in an informed manner to bias towards the goal and consecutively in an exploratory, random manner. For the informed expansion, local goal states are generated either via (a) medial axis information in environments with obstacles, or (b) wavefront information for setups with traversability costs. The learning process and the resulting planning framework are evaluated for a first and second-order differential drive system, as well as a physically simulated Segway robot. The results show that the proposed integration of learning and planning can produce higher quality paths than sampling-based kinodynamic planning with random controls in fewer iterations and computation time.",
        "primary_area": "",
        "author": "Aravind Sivaramakrishnan;Edgar Granados;Seth Karten;Troy McMahon;Kostas E. Bekris;Aravind Sivaramakrishnan;Edgar Granados;Seth Karten;Troy McMahon;Kostas E. Bekris",
        "authorids": "/37089195641;/37088505477;/37086587263;/37085505504;/37282424700;/37089195641;/37088505477;/37086587263;/37085505504;/37282424700",
        "aff": "Dept. of Computer Science, Rutgers, NJ, USA; Dept. of Computer Science, Rutgers, NJ, USA; Dept. of Computer Science, Rutgers, NJ, USA; Dept. of Computer Science, Rutgers, NJ, USA; Dept. of Computer Science, Rutgers, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636657/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8131409972710673838&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636546",
        "title": "Improving Monocular Depth Estimation by Semantic Pre-training",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowing the distance to nearby objects is crucial for autonomous cars to navigate safely in everyday traffic. In this paper, we investigate monocular depth estimation, which advanced substantially within the last years and is providing increasingly more accurate results while only requiring a single camera image as input. In line with recent work, we use an encoder-decoder structure with so-called packing layers to estimate depth values in a self-supervised fashion. We propose integrating a joint pre-training of semantic segmentation plus depth estimation on a dataset providing semantic labels. By using a separate semantic decoder that is only needed for pre-training, we can keep the network comparatively small. Our extensive experimental evaluation shows that the addition of such pre-training improves the depth estimation performance substantially. Finally, we show that we achieve competitive performance on the KITTI dataset despite using a much smaller and more efficient network.",
        "primary_area": "",
        "author": "Peter Rottmann;Thorbj\u00f6rn Posewsky;Andres Milioto;Cyrill Stachniss;Jens Behley;Peter Rottmann;Thorbj\u00f6rn Posewsky;Andres Milioto;Cyrill Stachniss;Jens Behley",
        "authorids": "/37089197051;/37086078985;/37086400161;/37329668600;/37593243900;/37089197051;/37086078985;/37086400161;/37329668600;/37593243900",
        "aff": "University of Bonn, Germany; Ibeo Automotive Systems GmbH, Hamburg, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636546/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7443010119059073172&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University of Bonn;Ibeo Automotive Systems GmbH",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-bonn.de;https://www.ibeo-as.com",
        "aff_unique_abbr": "UBonn;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636502",
        "title": "Improving Object Permanence using Agent Actions and Reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "Object permanence in psychology means knowing that objects still exist even if they are no longer visible. It is a crucial concept for robots to operate autonomously in uncontrolled environments. Existing approaches learn object permanence from low-level perception, but perform poorly on more complex scenarios, like when objects are contained and carried by others. Knowledge about manipulation actions performed on an object prior to its disappearance allows us to reason about its location, e.g., that the object has been placed in a carrier. In this paper we argue that object permanence can be improved when the robot uses knowledge about executed actions and describe an approach to infer hidden object states from agent actions. We show that considering agent actions not only improves rule-based reasoning models but also purely neural approaches, showing its general applicability. Then, we conduct quantitative experiments on a snitch localization task using a dataset of 1,371 synthesized videos, where we compare the performance of different object permanence models with and without action annotations. We demonstrate that models with action annotations can significantly increase performance of both neural and rule-based approaches. Finally, we evaluate the usability of our approach in real-world applications by conducting qualitative experiments with two Universal Robots (UR5 and UR16e) in both lab and industrial settings. The robots complete benchmark tasks for a gearbox assembly and demonstrate the object permanence capabilities with real sensor data in an industrial environment.",
        "primary_area": "",
        "author": "Ying Siu Liang;Chen Zhang;Dongkyu Choi;Kenneth Kwok;Ying Siu Liang;Chen Zhang;Dongkyu Choi;Kenneth Kwok",
        "authorids": "/37086296915;/37089196467;/37088998738;/37088996704;/37086296915;/37089196467;/37088998738;/37088996704",
        "aff": "Social and Cognitive Computing at the Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore; Social and Cognitive Computing at the Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore; Social and Cognitive Computing at the Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore; Social and Cognitive Computing at the Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636502/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8099014693666200672&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Agency for Science, Technology and Research",
        "aff_unique_dep": "Social and Cognitive Computing at the Institute of High Performance Computing",
        "aff_unique_url": "https://www.a-star.edu.sg",
        "aff_unique_abbr": "A*STAR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9636595",
        "title": "Improving Robot Localisation by Ignoring Visual Distraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Attention is an important component of modern deep learning. However, less emphasis has been put on its inverse: ignoring distraction. Our daily lives require us to explicitly avoid giving attention to salient visual features that confound the task we are trying to accomplish. This visual prioritisation allows us to concentrate on important tasks while ignoring visual distractors.In this work, we introduce Neural Blindness, which gives an agent the ability to completely ignore objects or classes that are deemed distractors. More explicitly, we aim to render a neural network completely incapable of representing specific chosen classes in its latent space. In a very real sense, this makes the network \"blind\" to certain classes, allowing and agent to focus on what is important for a given task, and demonstrates how this can be used to improve localisation.",
        "primary_area": "",
        "author": "Oscar Mendez;Matthew Vowels;Richard Bowden;Oscar Mendez;Matthew Vowels;Richard Bowden",
        "authorids": "/37710939600;/37088454542;/37268872100;/37710939600;/37088454542;/37268872100",
        "aff": "University of Surrey; University of Surrey; University of Surrey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636595/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8679845674711521977&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Surrey",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.surrey.ac.uk",
        "aff_unique_abbr": "Surrey",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9635954",
        "title": "In-air Knotting of Rope using Dual-Arm Robot based on Deep Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we report the successful execution of in-air knotting of rope using a dual-arm two-finger robot based on deep learning. Owing to its flexibility, the state of the rope was in constant flux during the operation of the robot. This required the robot control system to dynamically correspond to the state of the object at all times. However, a manual description of appropriate robot motions corresponding to all object states is difficult to be prepared in advance. To resolve this issue, we constructed a model that instructed the robot to perform bowknots and overhand knots based on two deep neural networks trained using the data gathered from its sensorimotor, including visual and proximity sensors. The resultant model was verified to be capable of predicting the appropriate robot motions based on the sensory information available online. In addition, we designed certain task motions based on the Ian knot method using the dual-arm two-fingers robot. The designed knotting motions do not require a dedicated workbench or robot hand, thereby enhancing the versatility of the proposed method. Finally, experiments were performed to estimate the knotting performance of the real robot while executing overhand knots and bowknots on rope and its success rate. The experimental results established the effectiveness and high performance of the proposed method.",
        "primary_area": "",
        "author": "Kanata Suzuki;Momomi Kanamura;Yuki Suga;Hiroki Mori;Tetsuya Ogata;Kanata Suzuki;Momomi Kanamura;Yuki Suga;Hiroki Mori;Tetsuya Ogata",
        "authorids": "/37086050797;/37088235702;/37273974700;/37086432927;/37273829100;/37086050797;/37088235702;/37273974700;/37086432927;/37273829100",
        "aff": "National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan; Institute for AI and Robotics, Future Robotics Organization, Waseda University, Tokyo, Japan; National Institute of Advanced Industrial Science and Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635954/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6931071844242766861&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology;Waseda University",
        "aff_unique_dep": ";Institute for AI and Robotics",
        "aff_unique_url": "https://www.aist.go.jp;https://www.waseda.jp/top",
        "aff_unique_abbr": "AIST;Waseda",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636096",
        "title": "Inclined Quadrotor Landing using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Landing a quadrotor on an inclined surface is a challenging maneuver. The final state of any inclined landing trajectory is not an equilibrium, which precludes the use of most conventional control methods. We propose a deep reinforcement learning approach to design an autonomous landing controller for inclined surfaces. Using the proximal policy optimization (PPO) algorithm with sparse rewards and a tailored curriculum learning approach, an inclined landing policy can be trained in simulation in less than 90 minutes on a standard laptop. The policy then directly runs on a real Crazyflie 2.1 quadrotor and successfully performs real inclined landings in a flying arena. A single policy evaluation takes approximately 2.5 ms, which makes it suitable for a future embedded implementation on the quadrotor.",
        "primary_area": "",
        "author": "Jacob E. Kooi;Robert Babu\u0161ka;Jacob E. Kooi;Robert Babu\u0161ka",
        "authorids": "/37089195702;/37270682600;/37089195702;/37270682600",
        "aff": "Department of Cognitive Robotics, Delft Center for Systems and Control, Delft University of Technology, Delft, The Netherlands; Czech Institute of Informatics, Robotics, and Cybernetics, Czech Technical University, Prague, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636096/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9848329980410084294&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Delft University of Technology;Czech Technical University",
        "aff_unique_dep": "Department of Cognitive Robotics;Czech Institute of Informatics, Robotics, and Cybernetics",
        "aff_unique_url": "https://www.tudelft.nl;https://www.cvut.cz",
        "aff_unique_abbr": "TUDelft;CTU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Delft;Prague",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Netherlands;Czech Republic"
    },
    {
        "id": "9635868",
        "title": "Indoor Future Person Localization from an Egocentric Wearable Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate prediction of future person location and movement trajectory from an egocentric wearable camera can benefit a wide range of applications, such as assisting visually impaired people in navigation, and the development of mobility assistance for people with disability. In this work, a new egocentric dataset was constructed using a wearable camera, with 8,250 short clips of a targeted person either walking 1) toward, 2) away, or 3) across the camera wearer in indoor environments, or 4) staying still in the scene, and 13,817 person bounding boxes were manually labelled. Apart from the bounding boxes, the dataset also contains the estimated pose of the targeted person as well as the IMU signal of the wearable camera at each time point. An LSTM-based encoder-decoder framework was designed to predict the future location and movement trajectory of the targeted person in this egocentric setting. Extensive experiments have been conducted on the new dataset, and have shown that the proposed method is able to reliably and better predict future person location and trajectory in egocentric videos captured by the wearable camera compared to three baselines.",
        "primary_area": "",
        "author": "Jianing Qiu;Frank P.-W. Lo;Xiao Gu;Yingnan Sun;Shuo Jiang;Benny Lo;Jianing Qiu;Frank P.-W. Lo;Xiao Gu;Yingnan Sun;Shuo Jiang;Benny Lo",
        "authorids": "/37086922591;/37086362655;/37086360965;/37086007834;/37086100516;/38183567000;/37086922591;/37086362655;/37086360965;/37086007834;/37086100516;/38183567000",
        "aff": "The Hamlyn Centre, Imperial College London; The Hamlyn Centre, Imperial College London; The Hamlyn Centre, Imperial College London; The Hamlyn Centre, Imperial College London; College of Electronics and Information Engineering, Tongji University; The Hamlyn Centre, Imperial College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635868/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13203755730031007802&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Imperial College London;Tongji University",
        "aff_unique_dep": "The Hamlyn Centre;College of Electronics and Information Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.tongji.edu.cn",
        "aff_unique_abbr": "Imperial College;Tongji",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9636551",
        "title": "Inferring Goals with Gaze during Teleoperated Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Assistive robot manipulators help people with upper motor impairments perform tasks by themselves. However, teleoperating a robot to perform complex tasks is difficult. Shared control algorithms make this easier: these algorithms predict the user\u2019s goal, autonomously generate a plan to accomplish the goal, and fuse that plan with the user\u2019s input. To accurately predict the user\u2019s goal, these algorithms typically use the user\u2019s input command (e.g., joystick input) directly. We use another sensing modality: the user\u2019s natural eye gaze behavior, which is highly task-relevant and informative early in the task. We develop an algorithm using hidden Markov models to infer goals from natural eye gaze behavior that appears while users are teleoperating a robot. We show that gaze-based predictions outperform goal prediction based on the control input and that our sequence model improves the prediction quality relative to gaze-based aggregate models.",
        "primary_area": "",
        "author": "Reuben M. Aronson;Nadia Almutlak;Henny Admoni;Reuben M. Aronson;Nadia Almutlak;Henny Admoni",
        "authorids": "/37086579350;/37089197049;/38570430500;/37086579350;/37089197049;/38570430500",
        "aff": "Human and Robot Partners Lab, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States of America; Columbia University, New York, NY, United States of America; Human and Robot Partners Lab, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States of America",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636551/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5899022895321148146&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Columbia University",
        "aff_unique_dep": "Robotics Institute;",
        "aff_unique_url": "https://www.cmu.edu;https://www.columbia.edu",
        "aff_unique_abbr": "CMU;Columbia",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pittsburgh;New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636125",
        "title": "Insect-Inspired Odor Intake Method for Chemical Plume Tracing in an Outdoor Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we propose an insect-inspired odor intake method for carrying out chemical plume tracing (CPT) in an outdoor environment and experimentally investigated the relationship between the intake state and behavioral states of search. Tracking chemical plumes is important because it facilitates the identification of an odor source. Previous studies have focused on the development of CPT algorithms to improve CPT performance. However, there is still inadequate discussion on the effect of the amount of odor acquisition, which is an important factor in determining the state of searching behavior, on CPT performance. To address this issue, we first designed and developed an insect-inspired odor-intake device. To evaluate the performance of the device, we conducted CPT experiments in an outdoor environment. An insect-inspired CPT algorithm that relies only on odor information was adopted because the purpose of this study was to evaluate the performance of the odor intake device. As a result of the outdoor CPT experiment, it was found that by setting the appropriate combination of the odor intake state and the behavioral state, certain search performances can be maintained even in highly unpredictable environments, such as outdoors. This suggests that in order to improve the CPT performance, it is important not only to improve the algorithm but also to devise an odor intake method and to combine it with the behavioral state appropriately.",
        "primary_area": "",
        "author": "Shunsuke Shigaki;Kei Okajima;Kazushi Sanada;Daisuke Kurabayashi;Shunsuke Shigaki;Kei Okajima;Kazushi Sanada;Daisuke Kurabayashi",
        "authorids": "/37085895425;/37086861924;/37275323500;/37329890400;/37085895425;/37086861924;/37275323500;/37329890400",
        "aff": "Department of Systems Innovation, Osaka University, Japan; Construction Equipment Solution Division, Komatsu Ltd., Japan; Division of Systems Research, Yokohama National University, Japan; Department of Systems and Control Engineering, Tokyo Institute of Technology, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636125/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17959326426529625296&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Osaka University;Komatsu Ltd.;Yokohama National University;Tokyo Institute of Technology",
        "aff_unique_dep": "Department of Systems Innovation;Construction Equipment Solution Division;Division of Systems Research;Department of Systems and Control Engineering",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.komatsu.com;https://www.yokohama-nu.ac.jp;https://www.titech.ac.jp",
        "aff_unique_abbr": "Osaka U;Komatsu;;Titech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9635833",
        "title": "Intelligent Execution through Plan Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Intelligent robots need to generate and execute plans. In order to deal with the complexity of real environments, planning makes some assumptions about the world. When executing plans, the assumptions are usually not met. Most works have focused on the negative impact of this fact and the use of replanning after execution failures. Instead, we focus on the positive impact, or opportunities to find better plans. When planning, the proposed technique finds and stores those opportunities. Later, during execution, the monitoring system can use them to focus perception and repair the plan, instead of replanning from scratch. Experiments in several paradigmatic robotic tasks show how the approach outperforms standard replanning strategies.",
        "primary_area": "",
        "author": "Daniel Borrajo;Manuela Veloso;Daniel Borrajo;Manuela Veloso",
        "authorids": "/37284262900;/37274032100;/37284262900;/37274032100",
        "aff": "J. P. Morgan AI Research, New York, NY, USA; J. P. Morgan AI Research, New York, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635833/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=345337922888419261&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "J. P. Morgan AI Research",
        "aff_unique_dep": "AI Research",
        "aff_unique_url": "https://www.jpmorgan.com/global/research",
        "aff_unique_abbr": "JPM AI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636143",
        "title": "Interaction-Based Trajectory Prediction Over a Hybrid Traffic Graph",
        "track": "main",
        "status": "Poster",
        "abstract": "Behavior prediction of traffic actors is an essential component of any real-world self-driving system. Actors\u2019 long-term behaviors tend to be governed by their interactions with other actors or traffic elements (traffic lights, stop signs) in the scene. To capture this highly complex structure of interactions, we propose to use a hybrid graph whose nodes represent both the traffic actors as well as the static and dynamic traffic elements present in the scene. The different modes of temporal interaction (e.g., stopping and going) among actors and traffic elements are explicitly modeled by graph edges. This explicit reasoning about discrete interaction types not only helps in predicting future motion, but also enhances the interpretability of the model, which is important for safety-critical applications such as autonomous driving. We predict actors\u2019 trajectories and interaction types using a graph neural network, which is trained in a semi-supervised manner. We show that our proposed model, TrafficGraphNet, achieves state-of-the-art trajectory prediction accuracy while maintaining a high level of interpretability.",
        "primary_area": "",
        "author": "Sumit Kumar;Yiming Gu;Jerrick Hoang;Galen Clark Haynes;Micol Marchetti-Bowick;Sumit Kumar;Yiming Gu;Jerrick Hoang;Galen Clark Haynes;Micol Marchetti-Bowick",
        "authorids": "/37089196816;/37089197175;/37089197629;/37089406900;/37088504056;/37089196816;/37089197175;/37089197629;/37089406900;/37088504056",
        "aff": "Aurora Innovation, USA; Google, USA; Aurora Innovation, USA; Aurora Innovation, USA; Aurora Innovation, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636143/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9129663363702691265&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Aurora Innovation;Google",
        "aff_unique_dep": ";Google",
        "aff_unique_url": "https://aurora.tech;https://www.google.com",
        "aff_unique_abbr": "Aurora;Google",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635903",
        "title": "Interpretable Goal Recognition in the Presence of Occluded Factors for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Recognising the goals or intentions of observed vehicles is a key step towards predicting the long-term future behaviour of other agents in an autonomous driving scenario. When there are unseen obstacles or occluded vehicles in a scenario, goal recognition may be confounded by the effects of these unseen entities on the behaviour of observed vehicles. Existing prediction algorithms that assume rational behaviour with respect to inferred goals may fail to make accurate long-horizon predictions because they ignore the possibility that the behaviour is influenced by such unseen entities. We introduce the Goal and Occluded Factor Inference (GOFI) algorithm which bases inference on inverse-planning to jointly infer a probabilistic belief over goals and potential occluded factors. We then show how these beliefs can be integrated into Monte Carlo Tree Search (MCTS). We demonstrate that jointly inferring goals and occluded factors leads to more accurate beliefs with respect to the true world state and allows an agent to safely navigate several scenarios where other baselines take unsafe actions leading to collisions.",
        "primary_area": "",
        "author": "Josiah P. Hanna;Arrasy Rahman;Elliot Fosong;Francisco Eiras;Mihai Dobre;John Redford;Subramanian Ramamoorthy;Stefano V. Albrecht;Josiah P. Hanna;Arrasy Rahman;Elliot Fosong;Francisco Eiras;Mihai Dobre;John Redford;Subramanian Ramamoorthy;Stefano V. Albrecht",
        "authorids": "/37088467292;/37089197697;/37089194704;/37086581181;/37085732104;/37089197964;/37529920500;/37088996736;/37088467292;/37089197697;/37089194704;/37086581181;/37085732104;/37089197964;/37529920500;/37088996736",
        "aff": "Computer Sciences Department, University of Wisconsin\u2013Madison; School of Informatics, University of Edinburgh, U.K.; School of Informatics, University of Edinburgh, U.K.; Department of Engineering Science, University of Oxford, U.K.; Five AI Ltd., U.K.; Five AI Ltd., U.K.; School of Informatics, University of Edinburgh, U.K.; School of Informatics, University of Edinburgh, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635903/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16169199058659616185&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;2;3;3;1;1",
        "aff_unique_norm": "University of Wisconsin\u2013Madison;University of Edinburgh;University of Oxford;Five AI Ltd.",
        "aff_unique_dep": "Computer Sciences Department;School of Informatics;Department of Engineering Science;",
        "aff_unique_url": "https://www.wisc.edu;https://www.ed.ac.uk;https://www.ox.ac.uk;",
        "aff_unique_abbr": "UW\u2013Madison;Edinburgh;Oxford;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Madison;",
        "aff_country_unique_index": "0;1;1;1;1;1;1;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9636282",
        "title": "Interpretable Run-Time Prediction and Planning in Co-Robotic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile robots are traditionally developed to be reactive and avoid collisions with surrounding humans, often moving in unnatural ways without following social protocols, forcing people to behave very differently from human-human interaction rules. Humans, on the other hand, are seamlessly able to understand why they may interfere with surrounding humans and change their behavior based on their reasoning, resulting in smooth, intuitive avoiding behaviors. In this paper, we propose an approach for a mobile robot to avoid interfering with the desired paths of surrounding humans. We leverage a library of previously observed trajectories to design a decision-tree based interpretable monitor that: i) predicts whether the robot is interfering with surrounding humans, ii) explains what behaviors are causing either prediction, and iii) plans corrective behaviors if interference is predicted. We also propose a validation scheme to improve the predictive model at run-time. The proposed approach is validated with simulations and experiments involving an unmanned ground vehicle (UGV) performing go-to-goal operations in the presence of humans, demonstrating non-interfering behaviors and run-time learning.",
        "primary_area": "",
        "author": "Rahul Peddi;Nicola Bezzo;Rahul Peddi;Nicola Bezzo",
        "authorids": "/37086941760;/37546843800;/37086941760;/37546843800",
        "aff": "Department of Systems and Information Engineering and the Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA; Department of Systems and Information Engineering and the Charles L. Brown Department of Electrical and Computer Engineering, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636282/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=493916955265472468&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "Department of Systems and Information Engineering",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Charlottesville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636580",
        "title": "Interpretable Trade-offs Between Robot Task Accuracy and Compute Efficiency",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot can invoke heterogeneous computation resources such as CPUs, cloud GPU servers, or even human computation for achieving a high-level goal. The problem of invoking an appropriate computation model so that it will successfully complete a task while keeping its compute and energy costs within a budget is called a model selection problem. In this paper, we present an optimal solution to the model selection problem with two compute models, the first being fast but less accurate, and the second being slow but more accurate. The main insight behind our solution is that a robot should invoke the slower compute model only when the benefits from the gain in accuracy outweigh the computational costs. We show that such cost-benefit analysis can be performed by leveraging the statistical correlation between the accuracy of fast and slow compute models. We demonstrate the broad applicability of our approach to diverse problems such as perception using neural networks and safe navigation of a simulated Mars rover.",
        "primary_area": "",
        "author": "Bineet Ghosh;Sandeep Chinchali;Parasara Sridhar Duggirala;Bineet Ghosh;Sandeep Chinchali;Parasara Sridhar Duggirala",
        "authorids": "/37089197516;/37089002336;/37595727500;/37089197516;/37089002336;/37595727500",
        "aff": "Department of Computer Science, The University of North Carolina at Chapel Hill, USA; Department of Electrical and Computer Engineering, The University of Texas at Austin, USA; Department of Computer Science, The University of North Carolina at Chapel Hill, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636580/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5580094007545662105&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of North Carolina at Chapel Hill;University of Texas at Austin",
        "aff_unique_dep": "Department of Computer Science;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.unc.edu;https://www.utexas.edu",
        "aff_unique_abbr": "UNC Chapel Hill;UT Austin",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Chapel Hill;Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636098",
        "title": "Iterative Coarse-to-Fine 6D-Pose Estimation Using Back-propagation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a 6D pose estimation method for an object from a single RGB image for a robotic grasping task. Many approaches estimate pose parameters from images taken from other viewpoints and use deep learning to achieve high accuracy. However, most of these methods are not robust to changes in object texture, and there is a possibility that the correct pose cannot be estimated by only one-time inference. Our aims are to reduce the number of failure cases and improve the accuracy by a novel architecture using the iterative backpropagation of a pose decoder network and pose estimation on intermediate representation. The error between random and target pose parameters are backpropagated to a neural network and the gradient for approaching the target pose is obtained. The pose parameter is updated using the obtained gradient, the error is calculated again, and backpropagation is re-performed. Repeating this process, we estimate a more accurate pose. Experiments using our own dataset show that estimation accuracy is improved and the number of failure cases is reduced. Furthermore, estimation by coarse-to-fine iterative processing is more accurate and faster. We also experiment with grasping using a UR5 robot and show that the robot can grasp objects without depth information when using the pose estimated by the proposed method.",
        "primary_area": "",
        "author": "Ryosuke Araki;Kohsuke Mano;Tadanori Hirano;Tsubasa Hirakawa;Takayoshi Yamashita;Hironobu Fujiyoshi;Ryosuke Araki;Kohsuke Mano;Tadanori Hirano;Tsubasa Hirakawa;Takayoshi Yamashita;Hironobu Fujiyoshi",
        "authorids": "/37086382640;/37086935101;/37089197751;/37085517612;/37085338365;/37270300700;/37086382640;/37086935101;/37089197751;/37085517612;/37085338365;/37270300700",
        "aff": "Machine Perception and Robotics Group, Chubu University, Kasugai-shi, Aichi, JP; Machine Perception and Robotics Group, Chubu University, Kasugai-shi, Aichi, JP; CKD Corporation, Komaki-shi, Aichi, JP; Machine Perception and Robotics Group, Chubu University, Kasugai-shi, Aichi, JP; Machine Perception and Robotics Group, Chubu University, Kasugai-shi, Aichi, JP; Machine Perception and Robotics Group, Chubu University, Kasugai-shi, Aichi, JP",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636098/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3870965826231380146&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Chubu University;CKD Corporation",
        "aff_unique_dep": "Machine Perception and Robotics Group;",
        "aff_unique_url": "https://www.chubu-u.ac.jp;",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Kasugai-shi;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636540",
        "title": "Iterative Program Synthesis for Adaptable Social Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot social navigation is influenced by human preferences and environment-specific scenarios such as elevators and doors, thus necessitating end-user adaptability. State-of-the-art approaches to social navigation fall into two categories: model-based social constraints and learning-based approaches. While effective, these approaches have fundamental limitations \u2013 model-based approaches require constraint and parameter tuning to adapt to preferences and new scenarios, while learning-based approaches require reward functions, significant training data, and are hard to adapt to new social scenarios or new domains with limited demonstrations.In this work, we propose Iterative Dimension Informed Program Synthesis (IDIPS) to address these limitations by learning and adapting social navigation in the form of human-readable symbolic programs. IDIPS works by combining pro-gram synthesis, parameter optimization, predicate repair, and iterative human demonstration to learn and adapt model-free action selection policies from orders of magnitude less data than learning-based approaches. We introduce a novel predicate repair technique that can accommodate previously unseen social scenarios or preferences by growing existing policies.We present experimental results showing that IDIPS: 1) synthesizes effective policies that model user preference, 2) can adapt existing policies to changing preferences, 3) can extend policies to handle novel social scenarios such as locked doors, and 4) generates policies that can be transferred from simulation to real-world robots with minimal effort.",
        "primary_area": "",
        "author": "Jarrett Holtz;Simon Andrews;Arjun Guha;Joydeep Biswas;Jarrett Holtz;Simon Andrews;Arjun Guha;Joydeep Biswas",
        "authorids": "/37086307815;/37089195543;/38548628800;/37538259200;/37086307815;/37089195543;/38548628800;/37538259200",
        "aff": "University of Texas at Austin; University of Massachusetts, Amherst; Northeastern University; University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636540/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3834094895659677832&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Texas at Austin;University of Massachusetts Amherst;Northeastern University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.utexas.edu;https://www.umass.edu;https://www.northeastern.edu",
        "aff_unique_abbr": "UT Austin;UMass Amherst;NEU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Austin;Amherst;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636071",
        "title": "Iterative Refinement for Real-Time Multi-Robot Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the iterative refinement of path planning for multiple robots, known as multi-agent pathfinding (MAPF). Given a graph, agents, their initial locations, and destinations, a solution of MAPF is a set of paths without collisions. Iterative refinement for MAPF is desirable for three reasons: 1) optimization is intractable, 2) sub-optimal solutions can be obtained instantly, and 3) it is anytime planning, desired in online scenarios where time for deliberation is limited. Despite the high demand, this is under-explored in MAPF because finding good neighborhoods has been unclear so far. Our proposal uses a sub-optimal MAPF solver to obtain an initial solution quickly, then iterates the two procedures: 1) select a subset of agents, 2) use an optimal MAPF solver to refine paths of selected agents while keeping other paths unchanged. Since the optimal solvers are used on small instances of the problem, this scheme yields efficient-enough solutions rapidly while providing high scalability. We also present reasonable candidates on how to select a subset of agents. Evaluations in various scenarios show that the proposal is promising; the convergence is fast, scalable, and with reasonable quality.",
        "primary_area": "",
        "author": "Keisuke Okumura;Yasumasa Tamura;Xavier D\u00e9fago;Keisuke Okumura;Yasumasa Tamura;Xavier D\u00e9fago",
        "authorids": "/37086500021;/37087281003;/37265172200;/37086500021;/37087281003;/37265172200",
        "aff": "School of Computing, Tokyo Institute of Technology, Tokyo, Japan; School of Computing, Tokyo Institute of Technology, Tokyo, Japan; School of Computing, Tokyo Institute of Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636071/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2807657654371367177&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.titech.ac.jp",
        "aff_unique_abbr": "Titech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636617",
        "title": "JCopter: Reliable UAV Software Through Managed Languages",
        "track": "main",
        "status": "Poster",
        "abstract": "UAVs are deployed in various applications including disaster search-and-rescue, precision agriculture, law enforcement and first response. As UAV software systems grow more complex, the drawbacks of developing them in low-level languages become more pronounced. For example, the lack of memory safety in C implies poor isolation between the UAV autopilot and other concurrent tasks. As a result, the most crucial aspect of UAV reliability-timely control of the flight-could be adversely impacted by other tasks such as perception or planning. We introduce JCopter, an autopilot framework for UAVs developed in a managed language, i.e., a high-level language with built-in safe memory and timing management. Through detailed simulation as well as flight testing, we demonstrate how JCopter retains the timeliness of C-based autopilots while also providing the reliability of managed languages.",
        "primary_area": "",
        "author": "Adam Czerniejewski;John Henry Burns;Farshad Ghanei;Karthik Dantu;Yu David Liu;Lukasz Ziarek;Adam Czerniejewski;John Henry Burns;Farshad Ghanei;Karthik Dantu;Yu David Liu;Lukasz Ziarek",
        "authorids": "/37086362524;/37088897647;/37086186312;/37328608800;/37089444103;/37085720925;/37086362524;/37088897647;/37086186312;/37328608800;/37089444103;/37085720925",
        "aff": "Department of Computer Science, Suny Buffalo; Department of Computer Science, Suny Binghamton; Department of Computer Science, Suny Buffalo; Department of Computer Science, Suny Buffalo; Department of Computer Science, Suny Binghamton; Department of Computer Science, Suny Buffalo",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636617/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2968885980445369607&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;1;0",
        "aff_unique_norm": "State University of New York at Buffalo;State University of New York at Binghamton",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.buffalo.edu;https://www.binghamton.edu",
        "aff_unique_abbr": "SUNY Buffalo;SUNY Binghamton",
        "aff_campus_unique_index": "0;1;0;0;1;0",
        "aff_campus_unique": "Buffalo;Binghamton",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636508",
        "title": "Joint Depth and Normal Estimation from Real-world Time-of-flight Raw Data",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel approach to joint depth and normal estimation for time-of-flight (ToF) sensors. Our model learns to predict the high-quality depth and normal maps jointly from ToF raw sensor data. To achieve this, we meticulously constructed the first large-scale dataset (named ToF-100) with paired raw ToF data and ground-truth high-resolution depth maps provided by an industrial depth camera. In addition, we also design a simple but effective framework for joint depth and normal estimation, applying a robust Chamfer loss via jittering to improve the performance of our model. Our experiments demonstrate that our proposed method can efficiently reconstruct high-resolution depth and normal maps and significantly outperforms state-of-the-art approaches.",
        "primary_area": "",
        "author": "Rongrong Gao;Na Fan;Changlin Li;Wentao Liu;Qifeng Chen;Rongrong Gao;Na Fan;Changlin Li;Wentao Liu;Qifeng Chen",
        "authorids": "/37088457529;/37089195092;/37089197350;/37089194385;/37087230927;/37088457529;/37089195092;/37089197350;/37089194385;/37087230927",
        "aff": "Department of Computer Science and Engineering, HKUST; Department of Computer Science and Engineering, HKUST; Department of Computer Science and Engineering, HKUST; Sensetime; Department of Computer Science and Engineering, HKUST",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636508/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5605240755930254017&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;SenseTime",
        "aff_unique_dep": "Department of Computer Science and Engineering;",
        "aff_unique_url": "https://www.hkust.edu.hk;https://www.sensetime.com",
        "aff_unique_abbr": "HKUST;SenseTime",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636241",
        "title": "Joint Intention and Trajectory Prediction Based on Transformer",
        "track": "main",
        "status": "Poster",
        "abstract": "Although autonomous driving technology has made tremendous progress in recent years, it is still challenging to predict the intentions and trajectories of pedestrians. The state-of-the-art methods suffer from two problems. (1) Existing works consider these two tasks separately, ignoring the connection between them. (2) The selection and integration of inputs for these tasks are not well designed. In this paper, these two tasks are taken into consideration in a unified model. In this way, the information provided by the labels of each other is shared, improving the performance of both tasks. Besides, in addition to the bounding boxes and speeds, orientation and road semantic segmentation features are taken into consideration to show the potential intention and road context of the pedestrian. And all the inputs are weighted by an attention module before integration. Meanwhile, a Transformer encoder is applied in our method to extract the temporal information from the fused feature sequence. Our method outperforms all previous models for both trajectory prediction and intention prediction tasks on the JAAD dataset and PIE dataset.",
        "primary_area": "",
        "author": "Ze Sui;Yue Zhou;Xu Zhao;Ao Chen;Yiyang Ni;Ze Sui;Yue Zhou;Xu Zhao;Ao Chen;Yiyang Ni",
        "authorids": "/37089196019;/37089612179;/37293146900;/37089194725;/37089196194;/37089196019;/37089612179;/37293146900;/37089194725;/37089196194",
        "aff": "School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University; School of Electronic Information and Electrical Engineering, Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636241/",
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10385771193832644574&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "School of Electronic Information and Electrical Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636311",
        "title": "Joint Multi-Object Detection and Tracking with Camera-LiDAR Fusion for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-object tracking (MOT) with camera-LiDAR fusion demands accurate results of object detection, affinity computation and data association in real time. This paper presents an efficient multi-modal MOT framework with online joint detection and tracking schemes and robust data association for autonomous driving applications. The novelty of this work includes: (1) development of an end-to-end deep neural network for joint object detection and correlation using 2D and 3D measurements; (2) development of a robust affinity computation module to compute occlusion-aware appearance and motion affinities in 3D space; (3) development of a comprehensive data association module for joint optimization among detection confidences, affinities and start-end probabilities. The experiment results on the KITTI tracking benchmark demonstrate the superior performance of the proposed method in terms of both tracking accuracy and processing speed.",
        "primary_area": "",
        "author": "Kemiao Huang;Qi Hao;Kemiao Huang;Qi Hao",
        "authorids": "/37089194360;/37403530000;/37089194360;/37403530000",
        "aff": "Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Pazhou Lab, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636311/",
        "gs_citation": 91,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11636170209116828488&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Southern University of Science and Technology;Pazhou Lab",
        "aff_unique_dep": "Department of Computer Science and Engineering;",
        "aff_unique_url": "https://www.sustech.edu.cn;",
        "aff_unique_abbr": "SUSTech;",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Shenzhen;Guangzhou",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636064",
        "title": "Joint Sampling and Trajectory Optimization over Graphs for Online Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Among the most prevalent motion planning techniques, sampling and trajectory optimization have emerged successful due to their ability to handle tight constraints and high-dimensional systems, respectively. However, limitations in sampling in higher dimensions and local minima issues in optimization have hindered their ability to excel beyond static scenes in offline settings. Here we consider highly dynamic environments with long horizons that necessitate a fast on-line solution. We present a unified approach that leverages the complementary strengths of sampling and optimization, and interleaves them both in a manner that is well suited to this challenging problem. With benchmarks in multiple synthetic and realistic simulated environments, we show that our approach performs significantly better on various metrics against baselines that employ either only sampling or only optimization. Project page: https://sites.google.com/view/jistplanner",
        "primary_area": "",
        "author": "Kalyan Vasudev Alwala;Mustafa Mukadam;Kalyan Vasudev Alwala;Mustafa Mukadam",
        "authorids": "/37085530170;/37085562050;/37085530170;/37085562050",
        "aff": "Facebook AI Research; Facebook AI Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636064/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8131258402224173184&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Meta",
        "aff_unique_dep": "Facebook AI Research",
        "aff_unique_url": "https://research.facebook.com",
        "aff_unique_abbr": "FAIR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636477",
        "title": "Joint Space Control via Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The dominant way to control a robot manipulator uses hand-crafted differential equations leveraging some form of inverse kinematics / dynamics. We propose a simple, versatile joint-level controller that dispenses with differential equations entirely. A deep neural network, trained via model-free reinforcement learning, is used to map from task space to joint space. Experiments show the method capable of achieving similar error to traditional methods, while greatly simplifying the process by automatically handling redundancy, joint limits, and acceleration / deceleration profiles. The basic technique is extended to avoid obstacles by augmenting the input to the network with information about the nearest obstacles. Results are shown both in simulation and on a real robot via sim-to-real transfer of the learned policy. We show that it is possible to achieve sub-centimeter accuracy, both in simulation and the real world, with a moderate amount of training.",
        "primary_area": "",
        "author": "Visak Kumar;David Hoeller;Balakumar Sundaralingam;Jonathan Tremblay;Stan Birchfield;Visak Kumar;David Hoeller;Balakumar Sundaralingam;Jonathan Tremblay;Stan Birchfield",
        "authorids": "/37086312258;/37088846413;/37086455625;/37086455314;/37371627300;/37086312258;/37088846413;/37086455625;/37086455314;/37371627300",
        "aff": "NVIDIA; NVIDIA; NVIDIA; NVIDIA; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636477/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1178045737669141139&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "NVIDIA",
        "aff_unique_dep": "NVIDIA Corporation",
        "aff_unique_url": "https://www.nvidia.com",
        "aff_unique_abbr": "NVIDIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636442",
        "title": "KB-Tree: Learnable and Continuous Monte-Carlo Tree Search for Autonomous Driving Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel learnable and continuous Monte-Carlo Tree Search method, named as KB-Tree, for motion planning in autonomous driving. The proposed method utilizes an asymptotical PUCB based on Kernel Regression (KR-AUCB) as a novel UCB variant, to improve the exploitation and exploration performance. In addition, we further optimize the sampling in continuous space by adapting Bayesian Optimization (BO) in the selection process of MCTS. Moreover, we use a customized Graph Neural Network (GNN) as our feature extractor to improve the learning performance. To the best of our knowledge, we are the first to apply the continuous MCTS method in autonomous driving. To validate our method, we conduct extensive experiments under several weakly and strongly interactive scenarios. The results show that our proposed method performs well in all tasks, and outperforms the learning-based continuous MCTS method and the state-of-the-art Reinforcement Learning (RL) baseline.",
        "primary_area": "",
        "author": "Lanxin Lei;Ruiming Luo;Renjie Zheng;Jingke Wang;JianWei Zhang;Cong Qiu;Liulong Ma;Liyang Jin;Ping Zhang;Junbo Chen;Lanxin Lei;Ruiming Luo;Renjie Zheng;Jingke Wang;JianWei Zhang;Cong Qiu;Liulong Ma;Liyang Jin;Ping Zhang;Junbo Chen",
        "authorids": "/37089197195;/37086800475;/37089198061;/37088687291;/37089197921;/37089196838;/37089194516;/37089196690;/37089194699;/37089196396;/37089197195;/37086800475;/37089198061;/37088687291;/37089197921;/37089196838;/37089194516;/37089196690;/37089194699;/37089196396",
        "aff": "Department of Autonomous Driving Lab, Alibaba DAMO Academy, Hangzhou, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Department of Autonomous Driving Lab, Alibaba DAMO Academy, Hangzhou, China; Department of Autonomous Driving Lab, Alibaba DAMO Academy, Hangzhou, China; Department of Autonomous Driving Lab, Alibaba DAMO Academy, Hangzhou, China; Department of Autonomous Driving Lab, Alibaba DAMO Academy, Hangzhou, China; Department of Autonomous Driving Lab, Alibaba DAMO Academy, Hangzhou, China; Department of Autonomous Driving Lab, Alibaba DAMO Academy, Hangzhou, China; Department of Autonomous Driving Lab, Alibaba DAMO Academy, Hangzhou, China; Department of Autonomous Driving Lab, Alibaba DAMO Academy, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636442/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14715127919762491150&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Alibaba DAMO Academy;Zhejiang University",
        "aff_unique_dep": "Department of Autonomous Driving Lab;College of Computer Science and Technology",
        "aff_unique_url": "https://damo.alibaba.com;http://www.zju.edu.cn",
        "aff_unique_abbr": "Alibaba DAMO;ZJU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636489",
        "title": "KDFNet: Learning Keypoint Distance Field for 6D Object Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present KDFNet, a novel method for 6D object pose estimation from RGB images. To handle occlusion, many recent works have proposed to localize 2D keypoints through pixel-wise voting and solve a Perspective-n-Point (PnP) problem for pose estimation, which achieves leading performance. However, such voting process is direction-based and cannot handle long and thin objects where the direction intersections cannot be robustly found. To address this problem, we propose a novel continuous representation called Keypoint Distance Field (KDF) for projected 2D keypoint locations. Formulated as a 2D array, each element of the KDF stores the 2D Euclidean distance between the corresponding image pixel and a specified projected 2D keypoint. We use a fully convolutional neural network to regress the KDF for each keypoint. Using this KDF encoding of projected object keypoint locations, we propose to use a distance-based voting scheme to localize the keypoints by calculating circle intersections in a RANSAC fashion. We validate the design choices of our framework by extensive ablation experiments. Our proposed method achieves state-of-the-art performance on Occlusion LINEMOD dataset with an average ADD(-S) accuracy of 50.3% and TOD dataset mug subset with an average ADD accuracy of 75.72%. Extensive experiments and visualizations demonstrate that the proposed method is able to robustly estimate the 6D pose in challenging scenarios including occlusion.",
        "primary_area": "",
        "author": "Xingyu Liu;Shun Iwase;Kris M. Kitani;Xingyu Liu;Shun Iwase;Kris M. Kitani",
        "authorids": "/37087231673;/37089196116;/37294510900;/37087231673;/37089196116;/37294510900",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636489/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12274703788646771384&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635859",
        "title": "Kalibrot: A Simple-To-Use Matlab Package for Robot Kinematic Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot modelling is an essential part to properly understand how a robotic system moves and how to control it. The kinematic model of a robot is usually obtained by using Denavit-Hartenberg convention, which relies on a set of parameters to describe the end-effector pose in a Cartesian space. These parameters are assigned based on geometrical considerations of the robotic structure, however, the assigned values may be inaccurate. The purpose of robot kinematic calibration is therefore to find optimal parameters which improve the accuracy of the robot model. In this work we present Kalibrot, an open source Matlab package for robot kinematic calibration. Kalibrot has been designed to simplify robot calibration and easily assess the calibration results. Beside computing the optimal parameters, Kalibrot provides a visualization layer showing the values of the calibrated parameters, what parameters can be identified, and the calibrated robotic structure. The capabilities of the package are here shown through simulated and real world experiments.",
        "primary_area": "",
        "author": "Francesco Cursi;Weibang Bai;Petar Kormushev;Francesco Cursi;Weibang Bai;Petar Kormushev",
        "authorids": "/37086145777;/37088505005;/37590229500;/37086145777;/37088505005;/37590229500",
        "aff": "Robot Intelligence Lab, Imperial College London, London, UK; Hamlyn Centre, Imperial College London, London, UK; Robot Intelligence Lab, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635859/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9356384195829097936&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Robot Intelligence Lab",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636277",
        "title": "Keeping It Simple: Bio-Inspired Threshold-Based Strain Sensing for Micro-Aerial Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Moths use hundreds of strain sensors (campaniform sensilla) on each wing to quickly respond to perturbations that may otherwise destabilize the moth during flight. A similar sensing approach could help stabilize micro-aerial vehicles (MAVs), but large sensor arrays are challenging due to the wiring and large latency that exists when capturing data from many traditional strain sensors. This work introduces a simplified bio-inspired strain sensor; the sensor interface and kinematics were inspired by campaniform sensilla that output a spike only in response to signals of interest. The engineered sensor outputs a discrete analog signal representing strain thresholds. A kinematic model of the sensor design is developed and describes the measured strain in terms of the sensor\u2019s geometric parameters. This model is used to understand trade-offs between sensor resolution and range, and is validated using a finite element model (FEM) of the sensor. The sensor was designed with ease of fabrication in mind, using simple techniques and commercially available components. Fabricated sensors were tested in a four-point flexural test, and the data from the analytical and FEM model show good agreement with the experimental results. The sensors demonstrate resolutions of 83, 158, and 281 microstrain for the different designs tested. A sensor is placed on a model wing to illustrate future applications to MAVs as well as the sensor\u2019s ability to sense both compressive and tensile strains.",
        "primary_area": "",
        "author": "Regan Kubicek;Mahnoush Babaei;Sarah Bergbreiter;Regan Kubicek;Mahnoush Babaei;Sarah Bergbreiter",
        "authorids": "/37088690293;/37088359355;/37542605000;/37088690293;/37088359355;/37542605000",
        "aff": "Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636277/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10122791002644235531&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636872",
        "title": "Knee-stretched Biped Gait Generation along Spatially Quantized Curves",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method for biped gait generation along a predefined curve with fully stretched knees. First, we design a spatial gait pattern as a function of the traveled distance on the path without considering dynamics. Then, a consistent dynamic walking motion is obtained by optimization that minimizes the zero-moment point and the speed errors while considering the trade-off between kinematics and dynamics. This method generalizes the spatially quantized dynamics-based gait generation, which is our former method restricted to straight paths, to walk on arbitrary curves. The generated gaits are validated by dynamic simulation.",
        "primary_area": "",
        "author": "Yuki Onishi;Shuuji Kajita;Tatsuya Ibuki;Mitsuji Sampei;Yuki Onishi;Shuuji Kajita;Tatsuya Ibuki;Mitsuji Sampei",
        "authorids": "/37089196986;/37269097500;/37572237900;/37270726000;/37089196986;/37269097500;/37572237900;/37270726000",
        "aff": "Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, Meguro, Tokyo, Japan; Dept. of Robotic Science and Technology, Chubu University, Kasugai-shi, Aichi, Japan; Department of Electronics and Bioinformatics, School of Science and Technology, Meiji University, Kanagawa, Japan; Department of Systems and Control Engineering, School of Engineering, Tokyo Institute of Technology, Meguro, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636872/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13346896550564206218&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Tokyo Institute of Technology;Chubu University;Meiji University",
        "aff_unique_dep": "Department of Systems and Control Engineering;Dept. of Robotic Science and Technology;Department of Electronics and Bioinformatics",
        "aff_unique_url": "https://www.titech.ac.jp;https://www.chubu-u.ac.jp;https://www.meiji.ac.jp",
        "aff_unique_abbr": "Titech;Chubu U;Meiji",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Meguro, Tokyo;Kasugai-shi;Kanagawa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636360",
        "title": "Knowledge Transfer across Imaging Modalities Via Simultaneous Learning of Adaptive Autoencoders for High-Fidelity Mobile Robot Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "Enabling mobile robots for solving challenging and diverse shape, texture, and motion related tasks with high fidelity vision requires the integration of novel multimodal imaging sensors and advanced fusion techniques. However, it is associated with high cost, power, hardware modification, and computing requirements which limit its scalability. In this paper, we propose a novel Simultaneously Learned Auto Encoder Domain Adaptation (SAEDA)-based transfer learning technique to empower noisy sensing with advanced sensor suite capabilities. In this regard, SAEDA trains both source and target auto-encoders together on a single graph to obtain the domain invariant feature space between the source and target domains on simultaneously collected data. Then, it uses the domain invariant feature space to transfer knowledge between different signal modalities. The evaluation has been done on two collected datasets (LiDAR and Radar) and one existing dataset (LiDAR, Radar and Video) which provides a significant improvement in quadruped robot-based classification (home floor and human activity recognition) and regression (surface roughness estimation) problems. We also integrate our sensor suite and SAEDA framework on two real-time systems (vacuum cleaning and Mini-Cheetah quadruped robots) for studying the feasibility and usability.",
        "primary_area": "",
        "author": "Md Mahmudur Rahman;Tauhidur Rahman;Donghyun Kim;Mohammad Arif Ul Alam;Md Mahmudur Rahman;Tauhidur Rahman;Donghyun Kim;Mohammad Arif Ul Alam",
        "authorids": "/37088983938;/37088949546;/37085554176;/37089195195;/37088983938;/37088949546;/37085554176;/37089195195",
        "aff": "University of Massachusetts Lowell; University of Massachusetts Amherst; University of Massachusetts Amherst; University of Massachusetts Lowell",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636360/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12116175700015317684&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Massachusetts Lowell;University of Massachusetts Amherst",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uml.edu;https://www.umass.edu",
        "aff_unique_abbr": "UMass Lowell;UMass Amherst",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Lowell;Amherst",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636025",
        "title": "Kohonen Self-Organizing Map based Route Planning: A Revisit",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we revisit the long-standing Traveling Salesman Problem (TSP) and focus on the challenging, yet practical route planning problem with limited computational resources. We make contributions to TSP, one of the most famous NP-hard problems by providing a new improved approximate solution, which we term TOpology Preserving Self-Organizing Map (TOPSOM). TOPSOM well preserves the topology of the node map to be traversed by maintaining the continuity of nodes and the distances between them. In addition, to satisfy the requirements of convex hull, we design an elastic competitive Hebbian learning rule. TOPSOM can solve large-scale TSPs with high precision and high efficiency with limited computational costs. Extensive experimental results on mainstream route planning benchmarks including TSPLIB and National TSP\u2019s show that our method consistently outperforms baseline methods, by up to 7.7% in terms of the Percent Deviation of Mean solution to best known solution.",
        "primary_area": "",
        "author": "Qingshu Guan;Xiaopeng Hong;Wei Ke;Liangfei Zhang;Guanghui Sun;Yihong Gong;Qingshu Guan;Xiaopeng Hong;Wei Ke;Liangfei Zhang;Guanghui Sun;Yihong Gong",
        "authorids": "/37089194365;/38548258300;/38235504700;/37088478404;/37596858200;/37085448236;/37089194365;/38548258300;/38235504700;/37088478404;/37596858200;/37085448236",
        "aff": "School of Software Engineering, Xi\u2019an Jiaotong University, China; School of Cyber Science and Engineering, Xi\u2019an Jiaotong University, China; School of Software Engineering, Xi\u2019an Jiaotong University, China; School of Computer Science, University of St Andrews, UK; Harbin Insititute of Technology, China; School of Software Engineering, Xi\u2019an Jiaotong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636025/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17814253149374313234&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "Xi'an Jiao Tong University;University of St Andrews;Harbin Institute of Technology",
        "aff_unique_dep": "School of Software Engineering;School of Computer Science;",
        "aff_unique_url": "http://www.xjtu.edu.cn;https://www.st-andrews.ac.uk;http://www.hit.edu.cn/",
        "aff_unique_abbr": "XJTU;St Andrews;HIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Xi'an;",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9636035",
        "title": "LaneRCNN: Distributed Representations for Graph-Centric Motion Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Forecasting the future behaviors of dynamic actors is an important task in many robotics applications such as self-driving. It is extremely challenging as actors have latent intentions and their trajectories are governed by complex interactions between the other actors, themselves, and the map. In this paper, we propose LaneRCNN, a graph-centric motion forecasting model that captures the actor-to-actor and the actor-to-map relations in a distributed and structured manner. Relying on a specially designed graph encoder, we learn a local graph representation per actor (LaneRoI) to encode its past motions and the local map topology. We further develop an interaction module which permits efficient message passing among local graph representations within a shared global lane graph. Moreover, we parameterize the output trajectories based on lane graphs, a more amenable prediction parameterization. We demonstrate the effectiveness of our approach on the challenging Argoverse [1] motion forecasting benchmark and achieve state-of-the-art performance.",
        "primary_area": "",
        "author": "Wenyuan Zeng;Ming Liang;Renjie Liao;Raquel Urtasun;Wenyuan Zeng;Ming Liang;Renjie Liao;Raquel Urtasun",
        "authorids": "/37087234351;/37087231216;/37086272063;/37269502900;/37087234351;/37087231216;/37086272063;/37269502900",
        "aff": "University of Toronto; Waabi; University of Toronto; University of Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636035/",
        "gs_citation": 220,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16292488398920977689&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Toronto;Waabi",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utoronto.ca;",
        "aff_unique_abbr": "U of T;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada;"
    },
    {
        "id": "9635943",
        "title": "Large-Area Conformable Sensor for Proximity, Light Touch, and Pressure-Based Gesture Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a capacitance-based sensor array for physical human-robot interaction (pHRI) applications that can measure the proximity, near-zero-force (NZF) contacts, and pressure between a robot and human body. The top segment including the electrodes is made of soft, stretchable materials, while the bottom segment consists of electrodes patterned from a thin copper film. The resulting device is soft and conformable to smooth curved surfaces of robot links while ensuring high signal integrity. It can be fabricated in different sizes from fingertips to torso because the fabrication process employs conventional, scalable methods. Using this sensor, we investigate the problem of recognizing gentle contact gestures often seen in affectionate physical interactions. The output of this multi-modal sensor is a 2D array compatible with machine learning algorithms used for pressure and image-based recognition problems. We utilize the spatio-temporal information of the 2D capacitance data by applying two existing deep neural network architectures. The highest accuracy achieved is over 99% in 7-class recognition of contact gestures involving proximity, NZF contacts, and medium pressure.",
        "primary_area": "",
        "author": "Mirza S. Sarwar;Katsu Yamane;Mirza S. Sarwar;Katsu Yamane",
        "authorids": "/37856314700;/37291289300;/37856314700;/37291289300",
        "aff": "University of British Columbia, Vancouver, Canada; Robert Bosch LLC, Sunnyvale, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635943/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16262411031525061927&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of British Columbia;Robert Bosch LLC",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ubc.ca;https://www.bosch.com",
        "aff_unique_abbr": "UBC;Bosch",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Vancouver;Sunnyvale",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9636458",
        "title": "Laser-Based Side-by-Side Following for Human-Following Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "A mobile robot that follows behind humans in structured environments has to face the challenge of full occlusion caused by the walls when the target person makes a turn at the corridor intersections. This may result in short-term, even a permanent loss of the target from the field of view of the Human-Following Robots (HFRs). Concerning this issue, a novel side-by-side following method for HFRs is addressed. In this paper, HFRs detect the legs of target person and different types of corridor intersections using the onboard laser scanner at first. Then, we provide a corridor detector method to cluster the geometric structure constraint between the target and corridor intersections. At last, a Side-by-side Following Leg Tracker (SFLT) is designed by integrating the laser information, in order to increase the visible time of the target person, while the target is turning at the corridor intersections. The corridor detector method and SFLT method have been simulated in MATLAB. Moreover, the approach of side-by-side following has been implemented in the Robot Operating System (ROS) of real-life robots in the corridor environment. The results from simulation and practical experiment show that, by using our method, HFRs were able to successfully follow the human92.0% while a mobile robot meeting potential occlusions at corridor intersections.",
        "primary_area": "",
        "author": "Hanchen Yao;Houde Dai;Enhao Zhao;Penghua Liu;Ran Zhao;Hanchen Yao;Houde Dai;Enhao Zhao;Penghua Liu;Ran Zhao",
        "authorids": "/37089194302;/37085718591;/37089196157;/37088997331;/37085818230;/37089194302;/37085718591;/37089196157;/37088997331;/37085818230",
        "aff": "Quanzhou Institute of Equipment Manufacturing, Haixi Institutes, Chinese Academy of Sciences, Jinjiang, China; Quanzhou Institute of Equipment Manufacturing, Haixi Institutes, Chinese Academy of Sciences, Jinjiang, China; Harbin Institute of Technology, Harbin, China; Xiamen University of Technology, Xiamen, China; Quanzhou Institute of Equipment Manufacturing, Haixi Institutes, Chinese Academy of Sciences, Jinjiang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636458/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17757176539028235090&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Chinese Academy of Sciences;Harbin Institute of Technology;Xiamen University of Technology",
        "aff_unique_dep": "Institute of Equipment Manufacturing;;",
        "aff_unique_url": "http://www.cas.cn;http://www.hit.edu.cn/;http://www.xmut.edu.cn",
        "aff_unique_abbr": "CAS;HIT;",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Jinjiang;Harbin;Xiamen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636449",
        "title": "Latent Attention Augmentation for Robust Autonomous Driving Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "Model-free reinforcement learning has become a viable approach for vision-based robot control. However, sample complexity and adaptability to domain shifts remain persistent challenges when operating in high-dimensional observation spaces (images, LiDAR), such as those that are involved in autonomous driving. In this paper, we propose a flexible framework by which a policy\u2019s observations are augmented with robust attention representations in the latent space to guide the agent\u2019s attention during training. Our method encodes local and global descriptors of the augmented state representations into a compact latent vector, and scene dynamics are approximated by a recurrent network that processes the latent vectors in sequence. We outline two approaches for constructing attention maps; a supervised pipeline leveraging semantic segmentation networks, and an unsupervised pipeline relying only on classical image processing techniques. We conduct our experiments in simulation and test the learned policy against varying seasonal effects and weather conditions. Our design decisions are supported in a series of ablation studies. The results demonstrate that our state augmentation method both improves learning efficiency and encourages robust domain adaptation when compared to common end-to-end frameworks and methods that learn directly from intermediate representations.",
        "primary_area": "",
        "author": "Ran Cheng;Christopher Agia;Florian Shkurti;David Meger;Gregory Dudek;Ran Cheng;Christopher Agia;Florian Shkurti;David Meger;Gregory Dudek",
        "authorids": "/37086574786;/37088414901;/37706697200;/37542891800;/37274057100;/37086574786;/37088414901;/37706697200;/37542891800;/37274057100",
        "aff": "Mobile Robotics Lab (MRL), McGill University, Montreal, Quebec, Canada; Robot Vision and Learning Lab (RVL), University of Toronto, Toronto, Ontario, Canada; Robot Vision and Learning Lab (RVL), University of Toronto, Toronto, Ontario, Canada; Mobile Robotics Lab (MRL), McGill University, Montreal, Quebec, Canada; Mobile Robotics Lab (MRL), McGill University, Montreal, Quebec, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636449/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7929212648073984033&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "McGill University;University of Toronto",
        "aff_unique_dep": "Mobile Robotics Lab (MRL);Robot Vision and Learning Lab (RVL)",
        "aff_unique_url": "https://www.mcgill.ca;https://www.utoronto.ca",
        "aff_unique_abbr": "McGill;U of T",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Montreal;Toronto",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636491",
        "title": "Learn to Differ: Sim2Real Small Defection Segmentation Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent studies on deep-learning-based small defection segmentation approaches are trained in specific settings and tend to be limited by fixed context. Throughout the training, the network inevitably learns the representation of the background of the training data before figuring out the defection. They underperform in the inference stage once the context changed and can only be solved by training in every new settings. This eventually leads to the limitation in practical robotic applications where contexts keep varying. To cope with this, instead of training a network context by context and hoping it to generalize, why not stop misleading it with any limited context and start training it with pure simulation? In this paper, we propose the network SSDS that learns a way of distinguishing small defections between two images regardless of the context, so that the network can be trained once for all. A small defection detection layer utilizing the pose sensitivity of phase correlation between images is introduced and is followed by an outlier masking layer. The network is trained on randomly generated simulated data with simple shapes and is generalized across the real world. Finally, SSDS is validated on real-world collected data and demonstrates the ability that even when trained in cheap simulation, SSDS can still find small defections in the real world showing the effectiveness and its potential for practical applications. Code is available here",
        "primary_area": "",
        "author": "Zexi Chen;Zheyuan Huang;Hongxiang Yu;Zhongxiang Zhou;Yunkai Wang;Xuecheng Xu;Qimeng Tan;Yue Wang;Rong Xiong;Zexi Chen;Zheyuan Huang;Hongxiang Yu;Zhongxiang Zhou;Yunkai Wang;Xuecheng Xu;Qimeng Tan;Yue Wang;Rong Xiong",
        "authorids": "/37088601253;/37088073899;/37086345520;/37088809302;/37088600631;/37087245452;/37086355678;/37072299700;/37271511300;/37088601253;/37088073899;/37086345520;/37088809302;/37088600631;/37087245452;/37086355678;/37072299700;/37271511300",
        "aff": "State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, P.R.China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, P.R.China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, P.R.China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, P.R.China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, P.R.China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, P.R.China; Beijing Key Laboratory of Intelligent Space Robotic System Technology and Applications, Beijing Institute of Spacecraft System Engineering, Beijing, P.R.China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, P.R.China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, P.R.China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636491/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:61gUUAdFuV4J:scholar.google.com/&scioq=Learn+to+Differ:+Sim2Real+Small+Defection+Segmentation+Network&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;1;0;0",
        "aff_unique_norm": "Zhejiang University;Beijing Institute of Spacecraft System Engineering",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control;Beijing Key Laboratory of Intelligent Space Robotic System Technology and Applications",
        "aff_unique_url": "http://www.zju.edu.cn;",
        "aff_unique_abbr": "ZJU;",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;0;0",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636873",
        "title": "Learning Connectivity for Data Distribution in Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "Many algorithms for control of multi-robot teams operate under the assumption that low-latency, global state information necessary to coordinate agent actions can readily be disseminated among the team. However, in harsh environments with no existing communication infrastructure, robots must form ad-hoc networks, forcing the team to operate in a distributed fashion. To overcome this challenge, we propose a task-agnostic, decentralized, low-latency method for data distribution in ad-hoc networks using Graph Neural Networks (GNN). Our approach enables multi-agent algorithms based on global state information to function by ensuring it is available at each robot. To do this, agents glean information about the topology of the network from packet transmissions and feed it to a GNN running locally which instructs the agent when and where to transmit the latest state information. We train the distributed GNN communication policies via reinforcement learning using the average Age of Information as the reward function and show that it improves training stability compared to task-specific reward functions. Our approach performs favorably compared to industry-standard methods for data distribution such as random flooding and round robin. We also show that the trained policies generalize to larger teams of both static and mobile agents.",
        "primary_area": "",
        "author": "Ekaterina Tolstaya;Landon Butler;Daniel Mox;James Paulos;Vijay Kumar;Alejandro Ribeiro;Ekaterina Tolstaya;Landon Butler;Daniel Mox;James Paulos;Vijay Kumar;Alejandro Ribeiro",
        "authorids": "/37086432156;/37089197424;/37086936236;/37085335548;/37280341400;/37266493600;/37086432156;/37089197424;/37086936236;/37085335548;/37280341400;/37266493600",
        "aff": "Dept. of Electrical and Systems Eng., University of Pennsylvania, USA; Dept. of Electrical and Systems Eng., University of Pennsylvania, USA; Dept. of Mechanical Eng. and Applied Mechanics, University of Pennsylvania, USA; Dept. of Mechanical Eng. and Applied Mechanics, University of Pennsylvania, USA; Dept. of Mechanical Eng. and Applied Mechanics, University of Pennsylvania, USA; Dept. of Electrical and Systems Eng., University of Pennsylvania, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636873/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9814656910044877773&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Dept. of Electrical and Systems Eng.",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636547",
        "title": "Learning Contact-Rich Assembly Skills Using Residual Admittance Policy",
        "track": "main",
        "status": "Poster",
        "abstract": "Contact-rich assembly tasks may result in large and unpredictable forces and torques when the locations of the contacting parts are uncertain. The ability to correct the trajectory in response to haptic feedback and accomplish the task despite location uncertainties is an important skill. We hypothesize that this skill would facilitate generalization and support direct transfer from simulations to real world. To reduce sample complexity, we propose to learn a residual admittance policy (RAP). RAP is learned to correct the movements generated by a baseline policy in the framework of dynamic movement primitives. Given the reference trajectories generated by the baseline policy, the action space of RAP is limited to the admittance parameters. Using deep reinforcement learning, a deep neural network is trained to map task specifications to proper admittance parameters. We demonstrate that RAP handles uncertainties in board location, generalizes well over space, size and shape, and facilitates quick transfer learning. Most impressively, we demonstrate that the policy learned in simulations achieves similar robustness to uncertainties, generalization and performance when deployed on an industrial robot (UR5e) without further training. See accompanying video for demonstrations.",
        "primary_area": "",
        "author": "Oren Spector;Miriam Zacksenhouse;Oren Spector;Miriam Zacksenhouse",
        "authorids": "/37088872507;/37265222800;/37088872507;/37265222800",
        "aff": "Faculty of Mechanical Engineering, Technion, Israel; Technion Autonomous Systems Program and the Faculty of Mechanical Engineering, Technion, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636547/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14158475368598260707&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion",
        "aff_unique_dep": "Faculty of Mechanical Engineering",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9636139",
        "title": "Learning Continuous Cost-to-Go Functions for Non-holonomic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a supervised learning method to generate continuous cost-to-go functions of non-holonomic systems directly from the workspace description. Supervision from informative examples reduces training time and improves network performance. The manifold representing the optimal trajectories of a non-holonomic system has high-curvature regions which can not be efficiently captured with uniform sampling. To address this challenge, we present an adaptive sampling method which makes use of sampling based planners along with local, closed-form solutions to generate training samples. The cost-to-go function over a specific workspace is represented as a neural network whose weights are generated by a second, higher order network. The networks are trained in an end-to-end fashion. In our previous work, this architecture was shown to successfully learn to generate the cost-to-go functions of holonomic systems using uniform sampling. In this work, we show that uniform sampling fails for non-holonomic systems. However, with the proposed adaptive sampling methodology, our network can generate near-optimal trajectories for non-holonomic systems while avoiding obstacles. Experiments show that our method is two orders of magnitude faster compared to traditional approaches in cluttered environments.",
        "primary_area": "",
        "author": "Jinwook Huh;Daniel D. Lee;Volkan Isler;Jinwook Huh;Daniel D. Lee;Volkan Isler",
        "authorids": "/37085775953;/37280609600;/37298487800;/37085775953;/37280609600;/37298487800",
        "aff": "Samsung AI Center NY, New York; Samsung AI Center NY, New York; Samsung AI Center NY, New York",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636139/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4778388491593230342&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "SAC NY",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636444",
        "title": "Learning Environment Constraints in Collaborative Robotics: A Decentralized Leader-Follower Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a leader-follower hierarchical strategy for two robots collaboratively transporting an object in a partially known environment with obstacles. Both robots sense the local surrounding environment and react to obstacles in their proximity. We consider no explicit communication, so the local environment information and the control actions are not shared between the robots. At any given time step, the leader solves a model predictive control (MPC) problem with its known set of obstacles and plans a feasible trajectory to complete the task. The follower estimates the inputs of the leader and uses a policy to assist the leader while reacting to obstacles in its proximity. The leader infers obstacles in the follower\u2019s vicinity by using the difference between the predicted and the real-time estimated follower control action. A method to switch the leader-follower roles is used to improve the control performance in tight environments. The efficacy of our approach is demonstrated with detailed comparisons to two alternative strategies, where it achieves the highest success rate, while completing the task fastest.",
        "primary_area": "",
        "author": "Monimoy Bujarbaruah;Yvonne R. St\u00fcrz;Conrad Holda;Karl H. Johansson;Francesco Borrelli;Monimoy Bujarbaruah;Yvonne R. St\u00fcrz;Conrad Holda;Karl H. Johansson;Francesco Borrelli",
        "authorids": "/37086351739;/37085870626;/37086448991;/37270842500;/37299856800;/37086351739;/37085870626;/37086448991;/37270842500;/37299856800",
        "aff": "MPC Lab, UC Berkeley, USA; MPC Lab, UC Berkeley, USA; MPC Lab, UC Berkeley, USA; School of EECS, KTH, Stockholm, Sweden; MPC Lab, UC Berkeley, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636444/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11647330671488928550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;KTH Royal Institute of Technology",
        "aff_unique_dep": "MPC Lab;School of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.berkeley.edu;https://www.kth.se",
        "aff_unique_abbr": "UC Berkeley;KTH",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Berkeley;Stockholm",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;Sweden"
    },
    {
        "id": "9636828",
        "title": "Learning Forceful Manipulation Skills from Multi-modal Human Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from Demonstration (LfD) provides an intuitive and fast approach to program robotic manipulators. Task parameterized representations allow easy adaptation to new scenes and online observations. However, this approach has been limited to pose-only demonstrations and thus only skills with spatial and temporal features. In this work, we extend the LfD framework to address forceful manipulation skills, which are of great importance for industrial processes such as assembly. For such skills, multi-modal demonstrations including robot end-effector poses, force and torque readings, and operation scene are essential. Our objective is to reproduce such skills reliably according to the demonstrated pose and force profiles within different scenes. The proposed method combines our previous work on task-parameterized optimization and attractor-based impedance control. The learned skill model consists of (i) the attractor model that unifies the pose and force features, and (ii) the stiffness model that optimizes the stiffness for different stages of the skill. Furthermore, an online execution algorithm is proposed to adapt the skill execution to real-time observations of robot poses, measured forces, and changed scenes. We validate this method rigorously on a 7-DoF robot arm over several steps of an E-bike motor assembly process, which require different types of forceful interaction such as insertion, sliding and twisting.",
        "primary_area": "",
        "author": "An T. Le;Meng Guo;Niels van Duijkeren;Leonel Rozo;Robert Krug;Andras G. Kupcsik;Mathias B\u00fcrger;An T. Le;Meng Guo;Niels van Duijkeren;Leonel Rozo;Robert Krug;Andras G. Kupcsik;Mathias B\u00fcrger",
        "authorids": "/37088946746;/38237113400;/37087342328;/38228060200;/37601462700;/37086548878;/37528853600;/37088946746;/38237113400;/37087342328;/38228060200;/37601462700;/37086548878;/37528853600",
        "aff": "University of Stuttgart; Bosch Center for Artificial Intelligence (BCAI), Germany; Bosch Corporate Research, Germany; Bosch Center for Artificial Intelligence (BCAI), Germany; Bosch Corporate Research, Germany; Bosch Center for Artificial Intelligence (BCAI), Germany; Bosch Center for Artificial Intelligence (BCAI), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636828/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4494286070477540039&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;1;2;1;1",
        "aff_unique_norm": "University of Stuttgart;Bosch Center for Artificial Intelligence;Bosch Corporate Research",
        "aff_unique_dep": ";Artificial Intelligence;",
        "aff_unique_url": "https://www.uni-stuttgart.de;https://www.bosch-ai.com;https://research.bosch.com",
        "aff_unique_abbr": "USTuttgart;BCAI;BCR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636653",
        "title": "Learning Human Rewards by Inferring Their Latent Intelligence Levels in Multi-Agent Games: A Theory-of-Mind Approach with Application to Driving Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Reward function, as an incentive representation that recognizes humans\u2019 agency and rationalizes humans\u2019 actions, is particularly appealing for modeling human behavior in human-robot interaction. Inverse Reinforcement Learning is an effective way to retrieve reward functions from demonstrations. However, it has always been challenging when applying it to multi-agent settings since the mutual influence between agents has to be appropriately modeled. To tackle this challenge, previous work either exploits equilibrium solution concepts by assuming humans as perfectly rational optimizers with unbounded intelligence or pre-assigns humans\u2019 interaction strategies a priori. In this work, we advocate that humans are bounded rational and have different intelligence levels when reasoning about others\u2019 decision-making process, and such an inherent and latent characteristic should be accounted for in reward learning algorithms. Hence, we exploit such insights from Theory-of-Mind and propose a new multi-agent Inverse Reinforcement Learning framework that reasons about humans\u2019 latent intelligence levels during learning. We validate our approach in both zero-sum and general-sum games with synthetic agents, and illustrate a practical application to learning human drivers\u2019 reward functions from real driving data. We compare our approach with two baseline algorithms. The results show that by reasoning about humans\u2019 latent intelligence levels, the proposed approach has more flexibility and capability to retrieve reward functions that explain humans\u2019 driving behaviors better.",
        "primary_area": "",
        "author": "Ran Tian;Masayoshi Tomizuka;Liting Sun;Ran Tian;Masayoshi Tomizuka;Liting Sun",
        "authorids": "/37085997198;/37281933000;/37085425729;/37085997198;/37281933000;/37085425729",
        "aff": "University of California, Berkeley; University of California, Berkeley; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636653/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3287341320333575195&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636070",
        "title": "Learning Linear Policies for Robust Bipedal Locomotion on Terrains with Varying Slopes",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, with a view toward deployment of light-weight control frameworks for bipedal walking robots, we realize end-foot trajectories that are shaped by a single linear feedback policy. We learn this policy via a model-free and a gradient free learning algorithm, Augmented Random Search (ARS), in the two robot platforms Rabbit and Digit. Our contributions are two-fold: a) By using torso and support plane orientation as inputs, we achieve robust walking on slopes of upto 20\u00b0 in simulation. b) We demonstrate additional behaviors like walking backwards, stepping-in-place, and recovery from external pushes of upto 120 N. The end-result is a robust and a fast feedback control law for bipedal walking on terrains with varying slopes. Towards the end, we also provide preliminary results of hardware transfer to Digit.",
        "primary_area": "",
        "author": "Lokesh Krishna;Utkarsh A. Mishra;Guillermo A. Castillo;Ayonga Hereid;Shishir Kolathaya;Lokesh Krishna;Utkarsh A. Mishra;Guillermo A. Castillo;Ayonga Hereid;Shishir Kolathaya",
        "authorids": "/37089194571;/37088490178;/37086936437;/37077055000;/37060909000;/37089194571;/37088490178;/37086936437;/37077055000;/37060909000",
        "aff": "Department of Electronics Engineering, Indian Institute of Technology (BHU), Varanasi, India; Mechanical and Industrial Engineering Department, Indian Institute of Technology, Roorkee, India; Department of Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH, USA; Department of Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH, USA; Department of Computer Science and Automation and the Centre for Cyber-Physical Systems, Indian Institute of Science, Bengaluru, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636070/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7735851316226943850&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;3",
        "aff_unique_norm": "Indian Institute of Technology (BHU);Indian Institute of Technology Roorkee;Ohio State University;Indian Institute of Science",
        "aff_unique_dep": "Department of Electronics Engineering;Mechanical and Industrial Engineering Department;Department of Mechanical and Aerospace Engineering;Department of Computer Science and Automation",
        "aff_unique_url": "https://www.iitbhu.ac.in;https://www.iitr.ac.in;https://www.osu.edu;https://www.iisc.ac.in",
        "aff_unique_abbr": "IIT (BHU);IIT Roorkee;OSU;IISc",
        "aff_campus_unique_index": "0;1;2;2;3",
        "aff_campus_unique": "Varanasi;Roorkee;Columbus;Bengaluru",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "9635911",
        "title": "Learning Navigation Skills for Legged Robots with Learned Robot Embeddings",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work has shown results on learning navigation policies for idealized cylinder agents in simulation and transferring them to real wheeled robots. Deploying such navigation policies on legged robots can be challenging due to their complex dynamics, and the large dynamical difference between cylinder agents and legged systems. In this work, we learn hierarchical navigation policies that account for the low-level dynamics of legged robots, such as maximum speed, slipping, contacts, and learn to successfully navigate cluttered indoor environments. To enable transfer of policies learned in simulation to new legged robots and hardware, we learn dynamics-aware navigation policies across multiple robots with robot-specific embeddings. The learned embedding is optimized on new robots, while the rest of the policy is kept fixed, allowing for quick adaptation. We train our policies across three legged robots in simulation - 2 quadrupeds (A1, AlienGo) and a hexapod (Daisy). At test time, we study the performance of our learned policy on two new legged robots in simulation (Laikago, 4-legged Daisy), and one real-world quadrupedal robot (A1). Our experiments show that our learned policy can sample-efficiently generalize to previously unseen robots, and enable sim-to-real transfer of navigation policies for legged robots.",
        "primary_area": "",
        "author": "Joanne Truong;Denis Yarats;Tianyu Li;Franziska Meier;Sonia Chernova;Dhruv Batra;Akshara Rai;Joanne Truong;Denis Yarats;Tianyu Li;Franziska Meier;Sonia Chernova;Dhruv Batra;Akshara Rai",
        "authorids": "/37088473406;/37089194287;/37086934041;/38227805500;/37283184200;/37294512800;/37085480350;/37088473406;/37089194287;/37086934041;/38227805500;/37283184200;/37294512800;/37085480350",
        "aff": "Georgia Institute of Technology; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635911/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12792453667535004019&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;1;1",
        "aff_unique_norm": "Georgia Institute of Technology;Meta",
        "aff_unique_dep": ";Facebook AI Research",
        "aff_unique_url": "https://www.gatech.edu;https://research.facebook.com",
        "aff_unique_abbr": "Georgia Tech;FAIR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636790",
        "title": "Learning Robotic Contact Juggling",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic contact juggling is a challenging task in which robots must control the movement of a ball rapidly and indirectly without holding it while keeping the ball in and sometimes out of contact with the robot\u2019s body. In this work, we address the problem of learning such robotic contact juggling from trial and error via model-based reinforcement learning (MBRL). The key insight is that complex robot-ball interactions of the contact juggling actually consist of a small set of simple dynamics that each corresponds to a distinct interaction \"primitive\" such as touching and releasing the ball. Accordingly, we develop a tailored MBRL method that incrementally fits a set of simple dynamics models to the movements of a robot and a ball while also learning a switching model that can select a proper dynamics model depending on the current state and action. The learned model can then be used in an MBRL framework to seek optimal juggling control. We demonstrated the effectiveness of our approach on a simulator of contact juggling performed by a robotic arm.",
        "primary_area": "",
        "author": "Kazutoshi Tanaka;Masashi Hamaya;Devwrat Joshi;Felix von Drigalski;Ryo Yonetani;Takamitsu Matsubara;Yoshihisa Ijiri;Kazutoshi Tanaka;Masashi Hamaya;Devwrat Joshi;Felix von Drigalski;Ryo Yonetani;Takamitsu Matsubara;Yoshihisa Ijiri",
        "authorids": "/37088507484;/37085532024;/37087323475;/37086063905;/37085641524;/37533262700;/37085621887;/37088507484;/37085532024;/37087323475;/37086063905;/37085641524;/37533262700;/37085621887",
        "aff": "OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan; OMRON SINIC X Corporation, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636790/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12327022653742576796&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "OMRON SINIC X Corporation;Nara Institute of Science and Technology",
        "aff_unique_dep": ";Graduate School of Information Science",
        "aff_unique_url": ";https://www.nist.go.jp",
        "aff_unique_abbr": ";NIST",
        "aff_campus_unique_index": "0;0;0;0;0;1;0",
        "aff_campus_unique": "Tokyo;Nara",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636407",
        "title": "Learning State-Dependent Sensor Measurement Models with Limited Sensor Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a two-stage transfer learning method for training state-dependent sensor measurement models (SDSMMs) with limited sensor data. This method can alleviate collecting sizeable sensor and ground truth data to learn accurate sensor models, especially when we must learn many sensor models (for example, a fleet of autonomous cars, drones, or warehouse robots). In the first stage, we use prior knowledge of the sensor (such as a physical model) to generate a sizeable artificial dataset. Then the artificial dataset is used to pre-train an SDSMM. The second stage fine-tunes the pre-trained SDSMM using a \"small\" number of data collected by our target real sensor. To our knowledge, we are the first to learn measurement distributions using data generated from a physical model and data from a real sensor. We evaluated our proposed method using the Extended Kalman Particle Filter and a real-world localization dataset collected by several robots. Compared to the prior method, the proposed method achieved comparable performance with as little as ~19% of the real training data.",
        "primary_area": "",
        "author": "Troi Williams;Yu Sun;Troi Williams;Yu Sun",
        "authorids": "/37087323394;/37291603500;/37087323394;/37291603500",
        "aff": "Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA; Department of Computer Science and Engineering, University of South Florida, Tampa, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636407/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7718319504123760899&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of South Florida",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.usf.edu",
        "aff_unique_abbr": "USF",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tampa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635941",
        "title": "Learning Symbolic Operators for Task and Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic planning problems in hybrid state and action spaces can be solved by integrated task and motion planners (TAMP) that handle the complex interaction between motion-level decisions and task-level plan feasibility. TAMP approaches rely on domain-specific symbolic operators to guide the task-level search, making planning efficient. In this work, we formalize and study the problem of operator learning for TAMP. Central to this study is the view that operators define a lossy abstraction of the transition model of a domain. We then propose a bottom-up relational learning method for operator learning and show how the learned operators can be used for planning in a TAMP system. Experimentally, we provide results in three domains, including long-horizon robotic planning tasks. We find our approach to substantially outperform several baselines, including three graph neural network-based model-free approaches from the recent literature. Video: https://youtu.be/iVfpX9BpBRo. Code: https://git.io/JCT0g",
        "primary_area": "",
        "author": "Tom Silver;Rohan Chitnis;Joshua Tenenbaum;Leslie Pack Kaelbling;Tom\u00e1s Lozano-P\u00e9rez;Tom Silver;Rohan Chitnis;Joshua Tenenbaum;Leslie Pack Kaelbling;Tom\u00e1s Lozano-P\u00e9rez",
        "authorids": "/37088687048;/37085544593;/37622583000;/37269373600;/38273814000;/37088687048;/37085544593;/37622583000;/37269373600;/38273814000",
        "aff": "MIT Computer Science and Artificial Intelligence Laboratory; MIT Computer Science and Artificial Intelligence Laboratory; MIT Computer Science and Artificial Intelligence Laboratory; MIT Computer Science and Artificial Intelligence Laboratory; MIT Computer Science and Artificial Intelligence Laboratory",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635941/",
        "gs_citation": 108,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4870612684512966797&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT CSAIL",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636864",
        "title": "Learning When to Quit: Meta-Reasoning for Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Anytime motion planners are widely used in robotics. However, the relationship between their solution quality and computation time is not well understood, and thus, determining when to quit planning and start execution is unclear. In this paper, we address the problem of deciding when to stop deliberation under bounded computational capacity, so called meta-reasoning, for anytime motion planning. We propose data-driven learning methods, model-based and model-free meta-reasoning, that are applicable to different environment distributions and agnostic to the choice of anytime motion planners. As a part of the framework, we design a convolutional neural network-based optimal solution predictor that predicts the optimal path length from a given 2D workspace image. We empirically evaluate the performance of the proposed methods in simulation in comparison with baselines.",
        "primary_area": "",
        "author": "Yoonchang Sung;Leslie Pack Kaelbling;Tom\u00e1s Lozano-P\u00e9rez;Yoonchang Sung;Leslie Pack Kaelbling;Tom\u00e1s Lozano-P\u00e9rez",
        "authorids": "/38235977600;/37269373600;/38273814000;/38235977600;/37269373600;/38273814000",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636864/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=49083938994149619&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636233",
        "title": "Learning When to Switch: Composing Controllers to Traverse a Sequence of Terrain Artifacts",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged robots often use separate control policies that are highly engineered for traversing difficult terrain such as stairs, gaps, and steps, where switching between policies is only possible when the robot is in a region that is common to adjacent controllers. Deep Reinforcement Learning (DRL) is a promising alternative to hand-crafted control design, though typically requires the full set of test conditions to be known before training. DRL policies can result in complex (often unrealistic) behaviours that have few or no overlapping regions between adjacent policies, making it difficult to switch behaviours. In this work we develop multiple DRL policies with Curriculum Learning (CL), each that can traverse a single respective terrain condition, while ensuring an overlap between policies. We then train a network for each destination policy that estimates the likelihood of successfully switching from any other policy. We evaluate our switching method on a previously unseen combination of terrain artifacts and show that it performs better than heuristic methods. While our method is trained on individual terrain types, it performs comparably to a Deep Q Network trained on the full set of terrain conditions. This approach allows the development of separate policies in constrained conditions with embedded prior knowledge about each behaviour, that is scalable to any number of behaviours, and prepares DRL methods for applications in the real world.",
        "primary_area": "",
        "author": "Brendan Tidd;Akansel Cosgun;J\u00fcrgen Leitner;Nicolas Hudson;Brendan Tidd;Akansel Cosgun;J\u00fcrgen Leitner;Nicolas Hudson",
        "authorids": "/37089198244;/38230493900;/37885671300;/37407757300;/37089198244;/38230493900;/37885671300;/37407757300",
        "aff": "Robotics and Autonomous Systems Group, CSIRO, Pullenvale, QLD, Australia; Monash University, Australia; LYRO Robotics Pty Ltd, Australia; Robotics and Autonomous Systems Group, CSIRO, Pullenvale, QLD, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636233/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10478052462137300273&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "CSIRO;Monash University;LYRO Robotics",
        "aff_unique_dep": "Robotics and Autonomous Systems Group;;",
        "aff_unique_url": "https://www.csiro.au;https://www.monash.edu;",
        "aff_unique_abbr": "CSIRO;Monash;LYRO",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pullenvale;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9636623",
        "title": "Learning a Generative Transition Model for Uncertainty-Aware Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot learning of real-world manipulation tasks remains challenging and time consuming, even though actions are often simplified by single-step manipulation primitives. In order to compensate the removed time dependency, we additionally learn an image-to-image transition model that is able to predict a next state including its uncertainty. We apply this approach to bin picking, the task of emptying a bin using grasping as well as pre-grasping manipulation as fast as possible. The transition model is trained with up to 42 000 pairs of real-world images before and after a manipulation action. Our approach enables two important skills: First, for applications with flange-mounted cameras, picks per hours (PPH) can be increased by around 15 % by skipping image measurements. Second, we use the model to plan action sequences ahead of time and optimize time-dependent rewards, e.g. to minimize the number of actions required to empty the bin. We evaluate both improvements with real-robot experiments and achieve over 700 PPH in the YCB Box and Blocks Test.",
        "primary_area": "",
        "author": "Lars Berscheid;Pascal Mei\u00dfner;Torsten Kr\u00f6ger;Lars Berscheid;Pascal Mei\u00dfner;Torsten Kr\u00f6ger",
        "authorids": "/37085380166;/37086908496;/37283223400;/37085380166;/37086908496;/37283223400",
        "aff": "Karlsruhe Institute of Technology (KIT); University of Aberdeen; Karlsruhe Institute of Technology (KIT)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636623/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18161092057342947809&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology;University of Aberdeen",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.kit.edu;https://www.abdn.ac.uk",
        "aff_unique_abbr": "KIT;Aberdeen",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "9636047",
        "title": "Learning and Interactive Design of Shared Control Templates",
        "track": "main",
        "status": "Poster",
        "abstract": "Controlling a robotic arm to achieve manipulation tasks is challenging for humans. Especially if only low-dimensional input signals can be provided, as is often the case for users with motor impairments. Using shared control to provide task-specific guidance and constraints facilitates control \u2013 for instance with the Shared Control Templates (SCT) framework \u2013 and enables even complex activities of daily living to be performed successfully. However, designing SCTs is a laborious task requiring robotic expertise. To make such design easier and faster, we propose a method for semi-automatically designing SCTs on the basis of demonstrations. Furthermore, we propose two similarity metrics, and demonstrate how these can be used to transfer knowledge from one SCT to another. We demonstrate that the SCTs so acquired can be successfully used in shared control for everyday tasks such as opening a drawer or a cupboard on our assistive robot EDAN.",
        "primary_area": "",
        "author": "Gabriel Quere;Samuel Bustamante;Annette Hagengruber;J\u00f6rn Vogel;Franz Steinmetz;Freek Stulp;Gabriel Quere;Samuel Bustamante;Annette Hagengruber;J\u00f6rn Vogel;Franz Steinmetz;Freek Stulp",
        "authorids": "/37086933696;/37088505028;/37086040849;/37602887100;/37085752163;/37681682200;/37086933696;/37088505028;/37086040849;/37602887100;/37085752163;/37681682200",
        "aff": "German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636047/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1206538579927493795&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "German Aerospace Center (DLR)",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636080",
        "title": "Learning by Watching: Physical Imitation of Manipulation Skills from Human Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from visual data opens the potential to accrue a large range of manipulation behaviors by leveraging human demonstrations without specifying each of them mathe-matically, but rather through natural task specification. In this paper, we present Learning by Watching (LbW), an algorithmic framework for policy learning through imitation from a single video specifying the task. The key insights of our method are two-fold. First, since the human arms may not have the same morphology as robot arms, our framework learns unsupervised human to robot translation to overcome the morphology mis-match issue. Second, to capture the details in salient regions that are crucial for learning state representations, our model performs unsupervised keypoint detection on the translated robot videos. The detected keypoints form a structured representation that contains semantically meaningful information and can be used directly for computing reward and policy learning. We evaluate the effectiveness of our LbW framework on five robot manipulation tasks, including reaching, pushing, sliding, coffee making, and drawer closing. Extensive experimental evaluations demonstrate that our method performs favorably against the state-of-the-art approaches. More results and analysis are available at pair.toronto.edu/lbw-kp/.",
        "primary_area": "",
        "author": "Haoyu Xiong;Quanzhou Li;Yun-Chun Chen;Homanga Bharadhwaj;Samarth Sinha;Animesh Garg;Haoyu Xiong;Quanzhou Li;Yun-Chun Chen;Homanga Bharadhwaj;Samarth Sinha;Animesh Garg",
        "authorids": "/37089197599;/37089197507;/37086337884;/37086638775;/37087231268;/37086330576;/37089197599;/37089197507;/37086337884;/37086638775;/37087231268;/37086330576",
        "aff": "Tianjin University; University of Toronto & Vector Institute; University of Toronto & Vector Institute; University of Toronto & Vector Institute; University of Toronto & Vector Institute; Nvidia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636080/",
        "gs_citation": 91,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11212680408179966442&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;2",
        "aff_unique_norm": "Tianjin University;University of Toronto;NVIDIA",
        "aff_unique_dep": ";;NVIDIA Corporation",
        "aff_unique_url": "http://www.tju.edu.cn;https://www.utoronto.ca;https://www.nvidia.com",
        "aff_unique_abbr": "TJU;U of T;NVIDIA",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Toronto",
        "aff_country_unique_index": "0;1;1;1;1;2",
        "aff_country_unique": "China;Canada;United States"
    },
    {
        "id": "9636832",
        "title": "Learning compliant grasping and manipulation by teleoperation with adaptive force control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we focus on improving the robot\u2019s dexterous capability by exploiting visual sensing and adaptive force control. TeachNet, a vision-based teleoperation learning framework, is exploited to map human hand postures to a multi-fingered robot hand. We augment TeachNet, which is originally based on an imprecise kinematic mapping and position-only servoing, with a biomimetic learning-based compliance control algorithm for dexterous manipulation tasks. This compliance controller takes the mapped robotic joint angles from TeachNet as the desired goal, computes the desired joint torques. It is derived from a computational model of the biomimetic control strategy in human motor learning, which allows adapting the control variables (impedance and feedforward force) online during the execution of the reference joint angle trajectories. The simultaneous adaptation of the impedance and feedforward profiles enables the robot to interact with the environment in a compliant manner. Our approach has been verified in multiple tasks in physics simulation, i.e., grasping, opening-a-door, turning-a-cap, and touching-a-mouse, and has shown more reliable performances than the existing position control and the fixed-gain-based force control approaches.",
        "primary_area": "",
        "author": "Chao Zeng;Shuang Li;Yiming Jiang;Qiang Li;Zhaopeng Chen;Chenguang Yang;Jianwei Zhang;Chao Zeng;Shuang Li;Yiming Jiang;Qiang Li;Zhaopeng Chen;Chenguang Yang;Jianwei Zhang",
        "authorids": "/37086296547;/37086938152;/37085825335;/38238874000;/37404312400;/37404783000;/37281460600;/37086296547;/37086938152;/37085825335;/38238874000;/37404312400;/37404783000;/37281460600",
        "aff": "Department of Informatics, TAMS Group (Technical Aspects of Multimodal Systems), Universitat Hamburg, Germany; Department of Informatics, TAMS Group (Technical Aspects of Multimodal Systems), Universitat Hamburg, Germany; National Engineering Laboratory for Robot Visual Perception and Control, Hunan University, China; Center for Cognitive Interaction Technology, Bielefeld University, Germany; Department of Informatics, TAMS Group (Technical Aspects of Multimodal Systems), Universitat Hamburg, Germany; Bristol Robotics Laboratory, University of the West of England, UK; Department of Informatics, TAMS Group (Technical Aspects of Multimodal Systems), Universitat Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636832/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11300343560218400360&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;0;3;0",
        "aff_unique_norm": "Universitat Hamburg;Hunan University;Bielefeld University;University of the West of England",
        "aff_unique_dep": "Department of Informatics;National Engineering Laboratory for Robot Visual Perception and Control;Center for Cognitive Interaction Technology;Bristol Robotics Laboratory",
        "aff_unique_url": "https://www.uni-hamburg.de;;https://www.uni-bielefeld.de/;https://www.uwe.ac.uk",
        "aff_unique_abbr": ";;;UWE",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Bristol",
        "aff_country_unique_index": "0;0;1;0;0;2;0",
        "aff_country_unique": "Germany;China;United Kingdom"
    },
    {
        "id": "9636679",
        "title": "Learning from Successful and Failed Demonstrations via Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from Demonstration (LfD) is a popular approach that allows humans to teach robots new skills by showing the correct way(s) of performing the desired skill. Human-provided demonstrations, however, are not always optimal and the teacher usually addresses this issue by discarding or replacing sub-optimal (noisy or faulty) demonstrations. We propose a novel LfD representation that learns from both successful and failed demonstrations of a skill. Our approach encodes the two subsets of captured demonstrations (labeled by the teacher) into a statistical skill model, constructs a set of quadratic costs, and finds an optimal reproduction of the skill under novel problem conditions (i.e. constraints). The optimal reproduction balances convergence towards successful examples and divergence from failed examples. We evaluate our approach through several 2D and 3D experiments in real-world using a UR5e manipulator arm and also show that it can reproduce a skill from only failed demonstrations. The benefits of exploiting both failed and successful demonstrations are shown through comparison with two existing LfD approaches. We also compare our approach against an existing skill refinement method and show its capabilities in a multi-coordinate setting.",
        "primary_area": "",
        "author": "Brendan Hertel;S. Reza Ahmadzadeh;Brendan Hertel;S. Reza Ahmadzadeh",
        "authorids": "/37089194524;/38180433100;/37089194524;/38180433100",
        "aff": "Persistent Autonomy and Robot Learning (PeARL) Lab, University of Massachusetts Lowell, Lowell, MA; Persistent Autonomy and Robot Learning (PeARL) Lab, University of Massachusetts Lowell, Lowell, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636679/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16186613738546934271&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Massachusetts Lowell",
        "aff_unique_dep": "Persistent Autonomy and Robot Learning (PeARL) Lab",
        "aff_unique_url": "https://www.uml.edu",
        "aff_unique_abbr": "UMass Lowell",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Lowell",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636456",
        "title": "Learning initial trajectory using sequence-to-sequence approach to warm start an optimization-based motion planner",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, optimization-based motion planners have shown that they can provide a fast, smooth, and locally optimal trajectory even for a higher dimension planning problem. Their convergence rate depends on the given initial trajectory. The proper selection of an initial trajectory is crucially important: if it is not within the basin of attraction of the optimum, it will take longer to convergence or even get stuck in local minima. This paper presents a neural network-based initial trajectory predictor, which utilizes the power of the sequence-to-sequence (Seq2Seq) learning method to predict a good initial trajectory for an optimization-based motion planner even in an unseen environment. The proposed model learns the mapping between the tasks and the optimal trajectories from a database. Given a start and a goal configuration of a manipulator along with the environment information in the form of a voxel grid, the proposed model predicts a good initial trajectory, which was learned from previously seen situations. The learned model is evaluated in a 6 degree of freedom (DOF) manipulator planning in two different environments. The results show that by using the predicted initial trajectory, there is a significant improvement in the convergence rate and the planning time of an optimization-based motion planner, even in an unseen environment.",
        "primary_area": "",
        "author": "Sankaranarayanan Natarajan;Sankaranarayanan Natarajan",
        "authorids": "/37089270828;/37089270828",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636456/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15389482923723167225&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2
    },
    {
        "id": "9636292",
        "title": "Learning of Parameters in Behavior Trees for Movement Skills",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement Learning (RL) is a powerful mathematical framework that allows robots to learn complex skills by trial-and-error. Despite numerous successes in many applications, RL algorithms still require thousands of trials to converge to high-performing policies, can produce dangerous behaviors while learning, and the optimized policies (usually modeled as neural networks) give almost zero explanation when they fail to perform the task. For these reasons, the adoption of RL in industrial settings is not common. Behavior Trees (BTs), on the other hand, can provide a policy representation that a) supports modular and composable skills, b) allows for easy interpretation of the robot actions, and c) provides an advantageous low-dimensional parameter space. In this paper, we present a novel algorithm that can learn the parameters of a BT policy in simulation and then generalize to the physical robot without any additional training. We leverage a physical simulator with a digital twin of our workstation, and optimize the relevant parameters with a black-box optimizer. We showcase the efficacy of our method with a 7-DOF KUKAiiwa manipulator in a task that includes obstacle avoidance and a contact-rich insertion (peg-in-hole), in which our method outperforms the baselines.",
        "primary_area": "",
        "author": "Matthias Mayr;Konstantinos Chatzilygeroudis;Faseeh Ahmad;Luigi Nardi;Volker Krueger;Matthias Mayr;Konstantinos Chatzilygeroudis;Faseeh Ahmad;Luigi Nardi;Volker Krueger",
        "authorids": "/37086546552;/37086325361;/37089194147;/37085408295;/37085807708;/37086546552;/37086325361;/37089194147;/37085408295;/37085807708",
        "aff": "Department of Computer Science, Faculty of Engineering (LTH), Lund University, Lund, Sweden; Computer Engineering and Informatics Department (CEID), University of Patras, Greece; Department of Computer Science, Faculty of Engineering (LTH), Lund University, Lund, Sweden; Department of Computer Science and Electrical Engineering, Stanford University, CA, USA; Department of Computer Science, Faculty of Engineering (LTH), Lund University, Lund, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636292/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=85198717177212423&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "Lund University;University of Patras;Stanford University",
        "aff_unique_dep": "Department of Computer Science;Computer Engineering and Informatics Department (CEID);Department of Computer Science and Electrical Engineering",
        "aff_unique_url": "https://www.lth.se;https://www.upatras.gr;https://www.stanford.edu",
        "aff_unique_abbr": "LU;UPatras;Stanford",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "Lund;;Stanford",
        "aff_country_unique_index": "0;1;0;2;0",
        "aff_country_unique": "Sweden;Greece;United States"
    },
    {
        "id": "9636049",
        "title": "Learning to Arbitrate Human and Robot Control using Disagreement between Sub-Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "In the context of teleoperation, arbitration refers to deciding how to blend between human and autonomous robot commands. We present a reinforcement learning solution that learns an optimal arbitration strategy that allocates more control authority to the human when the robot comes across a decision point in the task. A decision point is where the robot encounters multiple options (sub-policies), such as having multiple paths to get around an obstacle or deciding between two candidate goals. By expressing each directional sub-policy as a von Mises distribution, we identify the decision points by observing the modality of the mixture distribution. Our reward function reasons on this modality and prioritizes to match its learned policy to either the user or the robot accordingly. We report teleoperation experiments on reach-and-grasping objects using a robot manipulator arm with different simulated human controllers. Results indicate that our shared control agent outperforms direct control and improves the teleoperation performance among different users. Using our reward term enables flexible blending between human and robot commands while maintaining safe and accurate teleoperation.",
        "primary_area": "",
        "author": "Yoojin Oh;Marc Toussaint;Jim Mainprice;Yoojin Oh;Marc Toussaint;Jim Mainprice",
        "authorids": "/37088528506;/37528418600;/37947362900;/37088528506;/37528418600;/37947362900",
        "aff": "Machine Learning and Robotics Lab, University of Stuttgart, Germany; Max Planck Institute for Intelligent Systems ; MPI-IS, T\u00fcbingen/Stuttgart, Germany; Max Planck Institute for Intelligent Systems ; MPI-IS, T\u00fcbingen/Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636049/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5931702123620494350&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "University of Stuttgart;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Machine Learning and Robotics Lab;Intelligent Systems",
        "aff_unique_url": "https://www.ira.uka.de;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": ";MPI-IS",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";T\u00fcbingen/Stuttgart",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636786",
        "title": "Learning to Control an Unstable System with One Minute of Data: Leveraging Gaussian Process Differentiation in Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a straightforward and efficient way to control unstable robotic systems using an estimated dynamics model. Specifically, we show how to exploit the differentiability of Gaussian Processes to create a state-dependent linearized approximation of the true continuous dynamics that can be integrated with model predictive control. Our approach is compatible with most Gaussian process approaches for system identification, and can learn an accurate model using modest amounts of training data. We validate our approach by learning the dynamics of an unstable system such as a segway with a 7-D state space and 2-D input space (using only one minute of data), and we show that the resulting controller is robust to unmodelled dynamics and disturbances, while state-of-the-art control methods based on nominal models can fail under small perturbations. Code is open sourced at https://github.com/learning-and-control/core.",
        "primary_area": "",
        "author": "Ivan D. Jimenez Rodriguez;Ugo Rosolia;Aaron D. Ames;Yisong Yue;Ivan D. Jimenez Rodriguez;Ugo Rosolia;Aaron D. Ames;Yisong Yue",
        "authorids": "/37089197749;/37086108959;/37300877900;/37085390468;/37089197749;/37086108959;/37300877900;/37085390468",
        "aff": "California Institute of Technology, Pasadena, USA; California Institute of Technology, Pasadena, USA; California Institute of Technology, Pasadena, USA; California Institute of Technology, Pasadena, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636786/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3928185783129658253&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636280",
        "title": "Learning to Design and Construct Bridge without Blueprint",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous assembly has been a desired functionality of many intelligent robot systems. We study a new challenging assembly task, designing and constructing a bridge without a blueprint. In this task, the robot needs to first design a feasible bridge architecture for arbitrarily wide cliffs and then manipulate the blocks reliably to construct a stable bridge according to the proposed design. In this paper, we propose a bi-level approach to tackle this task. At the high level, the system learns a bridge blueprint policy in a physical simulator using deep reinforcement learning and curriculum learning. A policy is represented as an attention-based neural network with object-centric input, which enables generalization to different number of blocks and cliff widths. For low-level control, we implement a motion-planning-based policy for real-robot motion control, which can be directly combined with a trained blueprint policy for real-world bridge construction without tuning. In our field study, our bi-level robot system demonstrates the capability of manipulating blocks to construct a diverse set of bridges with different architectures.",
        "primary_area": "",
        "author": "Yunfei Li;Tao Kong;Lei Li;Yifeng Li;Yi Wu;Yunfei Li;Tao Kong;Lei Li;Yifeng Li;Yi Wu",
        "authorids": "/37089195348;/37085802024;/37088997323;/37089195379;/37089194863;/37089195348;/37085802024;/37088997323;/37089195379;/37089194863",
        "aff": "Institute for Interdisciplinary Information Sciences, Tsinghua University, Beijing, China; ByteDance AI Lab, Beijing, China; University of California Santa Barbara; ByteDance AI Lab, Beijing, China; Shanghai Qi Zhi Institute, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636280/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8488383479090541931&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;3",
        "aff_unique_norm": "Tsinghua University;ByteDance;University of California, Santa Barbara;Shanghai Qi Zhi Institute",
        "aff_unique_dep": "Institute for Interdisciplinary Information Sciences;AI Lab;;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.bytedance.com;https://www.ucsb.edu;",
        "aff_unique_abbr": "Tsinghua;;UCSB;",
        "aff_campus_unique_index": "0;0;1;0;2",
        "aff_campus_unique": "Beijing;Santa Barbara;Shanghai",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9636876",
        "title": "Learning to Detect Multi-Modal Grasps for Dexterous Grasping in Dense Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an approach to multi-modal grasp detection that jointly predicts the probabilities that several types of grasps succeed at a given grasp pose. Given a partial point cloud of a scene, the algorithm proposes a set of feasible grasp candidates, then estimates the probabilities that a grasp of each type would succeed at each candidate pose. Predicting grasp success probabilities directly from point clouds makes our approach agnostic to the number and placement of depth sensors at execution time. We evaluate our system both in simulation and on a real robot with a Robotiq 3-Finger Adaptive Gripper and compare our network against several baselines that perform fewer types of grasps. Our experiments show that a system that explicitly models grasp type achieves an object retrieval rate 8.5% higher in a complex cluttered environment than our highest-performing baseline.",
        "primary_area": "",
        "author": "Matt Corsaro;Stefanie Tellex;George Konidaris;Matt Corsaro;Stefanie Tellex;George Konidaris",
        "authorids": "/37089001880;/37402794800;/38318614200;/37089001880;/37402794800;/38318614200",
        "aff": "Department of Computer Science, Brown University; Department of Computer Science, Brown University; Department of Computer Science, Brown University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636876/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10790162587953683451&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Brown University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.brown.edu",
        "aff_unique_abbr": "Brown",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636747",
        "title": "Learning to Drop Points for LiDAR Scan Synthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "3D laser scanning by LiDAR sensors plays an important role for mobile robots to understand their surroundings. Nevertheless, not all systems have high resolution and accuracy due to hardware limitations, weather conditions, and so on. Generative modeling of LiDAR data as scene priors is one of the promising solutions to compensate for unreliable or incomplete observations. In this paper, we propose a novel generative model for learning LiDAR data based on generative adversarial networks. As in the related studies, we process LiDAR data as a compact yet lossless representation, a cylindrical depth map. However, despite the smoothness of real-world objects, many points on the depth map are dropped out through the laser measurement, which causes learning difficulty on generative models. To circumvent this issue, we introduce measurement uncertainty into the generation process, which allows the model to learn a disentangled representation of the underlying shape and the dropout noises from a collection of real LiDAR data. To simulate the lossy measurement, we adopt a differentiable sampling framework to drop points based on the learned uncertainty. We demonstrate the effectiveness of our method on synthesis and reconstruction tasks using two datasets. We further showcase potential applications by restoring LiDAR data with various types of corruption.",
        "primary_area": "",
        "author": "Kazuto Nakashima;Ryo Kurazume;Kazuto Nakashima;Ryo Kurazume",
        "authorids": "/37085376805;/37271916800;/37085376805;/37271916800",
        "aff": "Faculty of Information Science and Electrical Engineering, Kyushu University, Motoka Fukuoka, Japan; Faculty of Information Science and Electrical Engineering, Kyushu University, Motoka Fukuoka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636747/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1926027671981466811&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Kyushu University",
        "aff_unique_dep": "Faculty of Information Science and Electrical Engineering",
        "aff_unique_url": "https://www.kyushu-u.ac.jp",
        "aff_unique_abbr": "Kyushu U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Motoka Fukuoka",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9635857",
        "title": "Learning to Fly\u2014a Gym Environment with PyBullet Physics for Reinforcement Learning of Multi-agent Quadcopter Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic simulators are crucial for academic research and education as well as the development of safety-critical applications. Reinforcement learning environments\u2014 simple simulations coupled with a problem specification in the form of a reward function\u2014are also important to standardize the development (and benchmarking) of learning algorithms. Yet, full-scale simulators typically lack portability and paral-lelizability. Vice versa, many reinforcement learning environments trade-off realism for high sample throughputs in toy-like problems. While public data sets have greatly benefited deep learning and computer vision, we still lack the software tools to simultaneously develop\u2014and fairly compare\u2014control theory and reinforcement learning approaches. In this paper, we propose an open-source OpenAI Gym-like environment for multiple quadcopters based on the Bullet physics engine. Its multi-agent and vision-based reinforcement learning interfaces, as well as the support of realistic collisions and aerodynamic effects, make it, to the best of our knowledge, a first of its kind. We demonstrate its use through several examples, either for control (trajectory tracking with PID control, multi-robot flight with downwash, etc.) or reinforcement learning (single and multi-agent stabilization tasks), hoping to inspire future research that combines control theory and machine learning.",
        "primary_area": "",
        "author": "Jacopo Panerati;Hehui Zheng;SiQi Zhou;James Xu;Amanda Prorok;Angela P. Schoellig;Jacopo Panerati;Hehui Zheng;SiQi Zhou;James Xu;Amanda Prorok;Angela P. Schoellig",
        "authorids": "/37074257700;/37087413218;/37086264310;/37089197788;/37542741000;/38488605800;/37074257700;/37087413218;/37086264310;/37089197788;/37542741000;/38488605800",
        "aff": "Vector Institute for Artificial Intelligence in Toronto; Prorok Lab and the Department of Computer Science and Technology, University of Cambridge, Cambridge, United Kingdom; Vector Institute for Artificial Intelligence in Toronto; Dynamic Systems Lab, Institute for Aerospace Studies, University of Toronto, Canada; Prorok Lab and the Department of Computer Science and Technology, University of Cambridge, Cambridge, United Kingdom; Vector Institute for Artificial Intelligence in Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635857/",
        "gs_citation": 226,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2002882025632168597&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;1;0",
        "aff_unique_norm": "Vector Institute for Artificial Intelligence;University of Cambridge;University of Toronto",
        "aff_unique_dep": "Artificial Intelligence;Department of Computer Science and Technology;Institute for Aerospace Studies",
        "aff_unique_url": "https://vectorinstitute.ai;https://www.cam.ac.uk;https://www.utoronto.ca",
        "aff_unique_abbr": "Vector Institute;Cambridge;U of T",
        "aff_campus_unique_index": "0;1;0;0;1;0",
        "aff_campus_unique": "Toronto;Cambridge",
        "aff_country_unique_index": "0;1;0;0;1;0",
        "aff_country_unique": "Canada;United Kingdom"
    },
    {
        "id": "9636607",
        "title": "Learning to Guide Human Attention on Mobile Telepresence Robots with 360\u00b0 Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile telepresence robots (MTRs) allow people to navigate and interact with a remote environment that is in a place other than the person\u2019s true location. Thanks to the recent advances in 360\u00b0 vision, many MTRs are now equipped with an all-degree visual perception capability. However, people\u2019s visual field horizontally spans only about 120\u00b0 of the visual field captured by the robot. To bridge this observability gap toward human-MTR shared autonomy, we have developed a framework, called GHAL360, to enable the MTR to learn a goal-oriented policy from reinforcements for guiding human attention using visual indicators. Three telepresence environments were constructed using datasets that are extracted from Matterport3D and collected from a real robot respectively. Experimental results show that GHAL360 outperformed the baselines from the literature in the efficiency of a human-MTR team completing target search tasks. A demo video is available: https://youtu.be/aGbTxCGJSDM",
        "primary_area": "",
        "author": "Kishan Chandan;Jack Albertson;Xiaohan Zhang;Xiaoyang Zhang;Yao Liu;Shiqi Zhang;Kishan Chandan;Jack Albertson;Xiaohan Zhang;Xiaoyang Zhang;Yao Liu;Shiqi Zhang",
        "authorids": "/37088997296;/37089195731;/37088687363;/37088750495;/37085620802;/37086294744;/37088997296;/37089195731;/37088687363;/37088750495;/37085620802;/37086294744",
        "aff": "State University of New York (SUNY) at Binghamton, Binghamton, NY, USA; State University of New York (SUNY) at Binghamton, Binghamton, NY, USA; State University of New York (SUNY) at Binghamton, Binghamton, NY, USA; State University of New York (SUNY) at Binghamton, Binghamton, NY, USA; State University of New York (SUNY) at Binghamton, Binghamton, NY, USA; State University of New York (SUNY) at Binghamton, Binghamton, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636607/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11196586554553726099&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "State University of New York at Binghamton",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.binghamton.edu",
        "aff_unique_abbr": "SUNY Binghamton",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Binghamton",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635976",
        "title": "Learning to Hit: A statistical Dynamical System based approach",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a manipulation scheme based on learning the motion of objects after being hit by a robotic end-effector. This allows for the object to be positioned at a desired location outside the physical workspace of the robot. An estimate of the object dynamics under friction and collisions is learnt and used to predict the desired hitting parameters (speed and direction), given the initial and desired location of the object. Based on the obtained hitting parameters, the desired pre-impact velocity of the end-effector is generated using a stable dynamical system. The performance of the proposed DS is validated in simulation and and is used to learn a model for hitting using real robot. The approach is tested on real robot with a KUKA LBR IIWA robot.",
        "primary_area": "",
        "author": "Harshit Khurana;Michael Bombile;Aude Billard;Harshit Khurana;Michael Bombile;Aude Billard",
        "authorids": "/37086860509;/37086286260;/37273980800;/37086860509;/37086286260;/37273980800",
        "aff": "Learning Algorithms and Systems Laboratory, EPFL, Lausanne, Switzerland; Learning Algorithms and Systems Laboratory, EPFL, Lausanne, Switzerland; Learning Algorithms and Systems Laboratory, EPFL, Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635976/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6983428457554617198&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "Learning Algorithms and Systems Laboratory",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636370",
        "title": "Learning to Navigate in a VUCA Environment: Hierarchical Multi-expert Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite decades of efforts, robot navigation in a real scenario with volatility, uncertainty, complexity, and ambiguity (VUCA for short), remains a challenging topic. Inspired by the central nervous system (CNS), we propose a hierarchical multi-expert learning framework for autonomous navigation in a VUCA environment. With a heuristic exploration mechanism considering target location, path cost, and safety level, the upper layer performs simultaneous map exploration and route-planning to avoid trapping in a blind alley, similar to the cerebrum in the CNS. Using a local adaptive model fusing multiple discrepant strategies, the lower layer pursuits a balance between collision-avoidance and go-straight strategies, acting as the cerebellum in the CNS. We conduct simulation and real-world experiments on multiple platforms, including legged and wheeled robots. Experimental results demonstrate our algorithm outperforms the existing methods in terms of task achievement, time efficiency, and security. A video of our results is available at https://youtu.be/lAnW4QIWDoU.",
        "primary_area": "",
        "author": "Wenqi Zhang;Kai Zhao;Peng Li;Xiao Zhu;Faping Ye;Weijie Jiang;Huiqiao Fu;Tao Wang;Wenqi Zhang;Kai Zhao;Peng Li;Xiao Zhu;Faping Ye;Weijie Jiang;Huiqiao Fu;Tao Wang",
        "authorids": "/37089195751;/37089194767;/38540280300;/37089195663;/37089196018;/37089194231;/37086869852;/37086286575;/37089195751;/37089194767;/38540280300;/37089195663;/37089196018;/37089194231;/37086869852;/37086286575",
        "aff": "Advanced Institute of Information Technology, Peking University; Advanced Institute of Information Technology, Peking University; Advanced Institute of Information Technology, Peking University; Advanced Institute of Information Technology, Peking University; Advanced Institute of Information Technology, Peking University; Advanced Institute of Information Technology, Peking University; Advanced Institute of Information Technology, Peking University; Department of Computer Science and Technology, Peking University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636370/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1319352909704645675&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Peking University",
        "aff_unique_dep": "Advanced Institute of Information Technology",
        "aff_unique_url": "http://www.pku.edu.cn",
        "aff_unique_abbr": "PKU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636454",
        "title": "Learning to Optimize Control Policies and Evaluate Reproduction Performance from Human Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "We are interested in learning from demonstration (LfD) that can both learn and execute a trajectory and evaluate the quality of a previously unseen trajectory in the domain of assistive robotics. To this end, we propose a novel continuous inverse optimal control (IOC) formulation that simultaneously learns an optimal time-invariant controller and an evaluation metric from human demonstrations. We assume that the expert\u2019s objective function is a weighted combination of physically meaningful basis objective functions. The evaluation metric is derived from the learned expert\u2019s objective function. The benefit of this approach is twofold: 1) the controller can be optimized with respect to the learned evaluation metric and subject to the robot\u2019s dynamic limitations and 2) the evaluation metric can evaluate the quality of a demonstrated trajectory. We validate our approach with two experiments in a robot guided therapy setting: 1) evaluating demonstrated exercises with the learned metric and 2) reproducing both unconstrained trajectories and trajectories subject to the robot\u2019s dynamic constraints.",
        "primary_area": "",
        "author": "Paul Gesel;Dain LaRoche;Sajay Arthanat;Momotaz Begum;Paul Gesel;Dain LaRoche;Sajay Arthanat;Momotaz Begum",
        "authorids": "/37086936045;/37088690465;/37088691474;/37293898900;/37086936045;/37088690465;/37088691474;/37293898900",
        "aff": "Department of Computer Science, University of New Hampshire, USA; Department of Kinesiology, University of New Hampshire, USA; Department of Occupational Therapy, University of New Hampshire, USA; Department of Computer Science, University of New Hampshire, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636454/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2459471542678470480&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of New Hampshire",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.unh.edu",
        "aff_unique_abbr": "UNH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635959",
        "title": "Learning to Play Pursuit-Evasion with Visibility Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of pursuit-evasion for a single pursuer and an evader in polygonal environments where the players have visibility constraints. The pursuer is tasked with catching the evader as quickly as possible while the evader tries to avoid being captured. We formalize this problem as a zero-sum game where the players have private observations and conflicting objectives.One of the challenging aspects of this game is due to limited visibility. When a player, for example, the pursuer does not see the evader, it needs to reason about all possible locations of the evader. This causes an exponential increase in the size of the state space as compared to the arena size. To overcome the challenges associated with large state spaces, we introduce a new learning-based method that compresses the game state and uses it to plan actions for the players. The results indicate that our method outperforms the existing reinforcement learning methods, and performs competitively against the current state-of-the-art randomized strategy in complex environments.",
        "primary_area": "",
        "author": "Selim Engin;Qingyuan Jiang;Volkan Isler;Selim Engin;Qingyuan Jiang;Volkan Isler",
        "authorids": "/37086938133;/37089198278;/37298487800;/37086938133;/37089198278;/37298487800",
        "aff": "University of Minnesota; University of Minnesota; University of Minnesota",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635959/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16047359720522549846&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.minnesota.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636046",
        "title": "Learning to Play Soccer From Scratch: Sample-Efficient Emergent Coordination Through Curriculum-Learning and Competition",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes a scheme that allows learning complex multi-agent behaviors in a sample efficient manner, applied to 2v2 soccer. The problem is formulated as a Markov game, and solved using deep reinforcement learning. We propose a basic multi-agent extension of TD3 for learning the policy of each player, in a decentralized manner. To ease learning, the task of 2v2 soccer is divided in three stages: 1v0, 1v1 and 2v2. The process of learning in multi-agent stages (1v1 and 2v2) uses agents trained in a previous stage as fixed opponents. In addition, we propose using experience sharing, a method that shares experience from a fixed opponent, trained in a previous stage, for training the agent currently learning, and a form of frame-skipping, to raise performance significantly. Our results show that high quality soccer play can be obtained with our approach in just under 40M interactions. A summarized video of the resulting game play can be found in https://youtu.be/pScrKNqfELE.",
        "primary_area": "",
        "author": "Pavan Samtani;Francisco Leiva;Javier Ruiz-del-Solar;Pavan Samtani;Francisco Leiva;Javier Ruiz-del-Solar",
        "authorids": "/37089196129;/37086421166;/38278125800;/37089196129;/37086421166;/38278125800",
        "aff": "Department of Electrical Engineering, Universidad de Chile, Santiago, Chile; Advanced Mining Technology Center (AMTC), Universidad de Chile, Santiago, Chile; Advanced Mining Technology Center (AMTC), Universidad de Chile, Santiago, Chile",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636046/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5669325189758766286&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universidad de Chile",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.uchile.cl",
        "aff_unique_abbr": "UCH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Santiago",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Chile"
    },
    {
        "id": "9636748",
        "title": "Learning to Share Autonomy Across Repeated Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Wheelchair-mounted robotic arms (and other assistive robots) should help their users perform everyday tasks. One way robots can provide this assistance is shared autonomy. Within shared autonomy, both the human and robot maintain control over the robot\u2019s motion: as the robot becomes confident it understands what the human wants, it increasingly intervenes to automate the task. But how does the robot know what tasks the human may want to perform in the first place? Today\u2019s shared autonomy approaches often rely on prior knowledge: for example, the robot must know the set of possible human goals a priori. In the long-term, however, this prior knowledge will inevitably break down \u2014 sooner or later the human will reach for a goal that the robot did not expect. In this paper we propose a learning approach to shared autonomy that takes advantage of repeated interactions. Learning to assist humans would be impossible if they performed completely different tasks at every interaction: but our insight is that users living with physical disabilities repeat important tasks on a daily basis (e.g., opening the fridge, making coffee, and having dinner). We introduce an algorithm that exploits these repeated interactions to recognize the human\u2019s task, replicate similar demonstrations, and return control when unsure. As the human repeatedly works with this robot, our approach continually learns to assist tasks that were never specified beforehand: these tasks include both discrete goals (e.g., reaching a cup) and continuous skills (e.g., opening a drawer). Across simulations and an in-person user study, we demonstrate that robots leveraging our approach match existing shared autonomy methods for known goals, and outperform imitation learning baselines on new tasks. See videos here: https://youtu.be/NazeLVbQ2og",
        "primary_area": "",
        "author": "Ananth Jonnavittula;Dylan P. Losey;Ananth Jonnavittula;Dylan P. Losey",
        "authorids": "/37088998510;/37085812055;/37088998510;/37085812055",
        "aff": "Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA; Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636748/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5542312301218928328&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636333",
        "title": "Learning-based 3D Occupancy Prediction for Autonomous Navigation in Occluded Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In autonomous navigation, sensors suffer from massive occlusion in cluttered environments, leaving a significant amount of space unknown. In practice, treating the unknown space in optimistic or pessimistic ways both set limitations on planning performance. Therefore, aggressiveness and safety cannot be satisfied at the same time. Mimicking human behavior, in this paper, we propose a method based on deep neural network to predict occupancy distribution of unknown space. Specifically, the proposed method utilizes contextual information of environments and prior knowledge to predict obstacle distributions in the occluded space. Our self-supervised learning method use unlabeled and no-ground-truth data and augments the data by simulating navigation trajectories. Our Occupancy Prediction Network is faster than current SOTA scene completion models and is successfully applied to unseen test environments without any refinement. Results show that our predictor leverages the performance of a kinodynamic planner by improving security with no reduction of speed in cluttered environments.",
        "primary_area": "",
        "author": "Lizi Wang;Hongkai Ye;Qianhao Wang;Yuman Gao;Chao Xu;Fei Gao;Lizi Wang;Hongkai Ye;Qianhao Wang;Yuman Gao;Chao Xu;Fei Gao",
        "authorids": "/37089194136;/37086811929;/37089197978;/37089194623;/37404060100;/37086045143;/37089194136;/37086811929;/37089197978;/37089194623;/37404060100;/37086045143",
        "aff": "Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China; Huzhou Institute of Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636333/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3659704729877147380&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Huzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636147",
        "title": "Learning-based Contact Status Recognition for Peg-in-Hole Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "Opening a lock without vision sensors remains a challenge for robots. Inspired by the ability of a human to open a lock through touch and intuition, a peg-in-hole assembly method for recognizing the relative position and inclination angle of a hole is proposed. We use supervised learning to generate a contact-state model to judge the relative contact state and introduce force control strategies that ensure stable and safe interaction with the environment. Adaptive impedance control is adopted to ensure the stability of the alignment and insertion process. The proposed method is not restricted by the object shape. The system can learn an effective classification model with a small volume of force and torque data and predict the relative contact state of a peg and hole. The proposed method is verified in an experiment in which a bicycle lock is opened at different inclination angles. The proposed method has potential application in the field of industrial assembly.",
        "primary_area": "",
        "author": "Chaojie Yan;Jun Wu;Qiuguo Zhu;Chaojie Yan;Jun Wu;Qiuguo Zhu",
        "authorids": "/37089194610;/170654254534521;/38238164400;/37089194610;/170654254534521;/38238164400",
        "aff": "State Key Laboratory of Industrial Control and Technology, Zhejiang University, Institute of Cyber-System and Control, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Institute of Cyber-System and Control, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Institute of Cyber-System and Control, Zhejiang University, Hangzhou, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636147/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1685593178534256218&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology, Institute of Cyber-System and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636381",
        "title": "Let\u2019s Play for Action: Recognizing Activities of Daily Living by Learning from Life Simulation Video Games",
        "track": "main",
        "status": "Poster",
        "abstract": "Recognizing Activities of Daily Living (ADL) is a vital process for intelligent assistive robots, but collecting large annotated datasets requires time-consuming temporal labeling and raises privacy concerns, e.g., if the data is collected in a real household. In this work, we explore the concept of constructing training examples for ADL recognition by playing life simulation video games and introduce the SIMS4ACTION dataset created with the popular commercial game THE SIMS 4. We build SIMS4ACTION by specifically executing actions-of-interest in a \"top-down\" manner, while the gaming circumstances allow us to freely switch between environments, camera angles and subject appearances. While ADL recognition on gaming data is interesting from the theoretical perspective, the key challenge arises from transferring it to the real-world applications, such as smart-homes or assistive robotics. To meet this requirement, SIMS4ACTION is accompanied with a GAMING\u2192REAL benchmark, where the models are evaluated on real videos derived from an existing ADL dataset. We integrate two modern algorithms for video-based activity recognition in our framework, revealing the value of life simulation video games as an inexpensive and far less intrusive source of training data. However, our results also indicate that tasks involving a mixture of gaming and real data are challenging, opening a new research direction. We will make our dataset publicly available at https://github.com/aroitberg/sims4action.",
        "primary_area": "",
        "author": "Alina Roitberg;David Schneider;Aulia Djamal;Constantin Seibold;Simon Rei\u00df;Rainer Stiefelhagen;Alina Roitberg;David Schneider;Aulia Djamal;Constantin Seibold;Simon Rei\u00df;Rainer Stiefelhagen",
        "authorids": "/37085584903;/37089194574;/37089195038;/37088874684;/37088448581;/37269459200;/37085584903;/37089194574;/37089195038;/37088874684;/37088448581;/37269459200",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636381/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3700679047686373926&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636694",
        "title": "LiDAR Degradation Quantification for Autonomous Driving in Rain",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous driving in rainy conditions remains a big challenge. One of the issues is sensor degradation. LiDAR is commonly used in autonomous driving systems to perceive and understand surrounding environments. However, LiDAR performance can be degraded by rain, thereby influencing other system performance (e.g., perception or localization). Therefore, knowing how much degradation exists in current LiDAR measurements is necessary. Most existing methods can only measure LiDAR degradation in controlled environments (e.g., a chamber with simulated rain); how to quantify LiDAR degradation in dynamic environments while the autonomous vehicle is moving is still a difficult problem. In this work, we propose a novel approach to address this problem using an anomaly detection method. Our method has been evaluated on simulated and real-world data. Experimental results demonstrate the effectiveness of our method to capture LiDAR degradation and yield reasonable degradation estimations. Our experimental data and codes are accessible from http://rain.smart.mit.edu/smartrain/.",
        "primary_area": "",
        "author": "Chen Zhang;Zefan Huang;Marcelo H. Ang;Daniela Rus;Chen Zhang;Zefan Huang;Marcelo H. Ang;Daniela Rus",
        "authorids": "/37089258978;/37087323099;/37279138700;/37279652300;/37089258978;/37087323099;/37279138700;/37279652300",
        "aff": "National University of Singapore, Singapore; Singapore-MIT Alliance for Research and Technology; National University of Singapore, Singapore; Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636694/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11847511630819931704&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "National University of Singapore;Singapore-MIT Alliance for Research and Technology;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.nus.edu.sg;https://smart.singapore.edu.sg;https://www.mit.edu",
        "aff_unique_abbr": "NUS;SMART;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "9636299",
        "title": "LiDAR-Based Object-Level SLAM for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous localization and mapping (SLAM) is an essential technique for autonomous driving. Recently, combining image recognition technology to generate semantically meaningful maps has become a new trend in visual SLAM research. However, in the field of LiDAR SLAM, this potential has not been fully explored. We propose a novel object-level SLAM system using 3D LiDARs for autonomous vehicles. We detect and track poles, walls, and parked cars, which are common along urban roads. This paper presents how we process the measurement data of three different shapes of objects to build a graph-based optimization system and facilitate the geometric distribution of poles to detect loops. Experiments were carried out on datasets collected with a test vehicle in city traffic. The results show that our object-level SLAM system can build precise and semantically meaningful maps and produce more accurate pose estimations compared to the state-of-the-art systems on our datasets.",
        "primary_area": "",
        "author": "Bingyi Cao;Ricardo Carrillo Mendoza;Andreas Philipp;Daniel G\u00f6hring;Bingyi Cao;Ricardo Carrillo Mendoza;Andreas Philipp;Daniel G\u00f6hring",
        "authorids": "/37088597862;/37089197638;/37086935408;/37572499300;/37088597862;/37089197638;/37086935408;/37572499300",
        "aff": "Department of Mathematics and Computer Science, Freie Universit\u00e4t Berlin, Berlin, Germany; Department of Mathematics and Computer Science, Freie Universit\u00e4t Berlin, Berlin, Germany; Department of Mathematics and Computer Science, Freie Universit\u00e4t Berlin, Berlin, Germany; Department of Mathematics and Computer Science, Freie Universit\u00e4t Berlin, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636299/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11456573586737973910&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Freie Universit\u00e4t Berlin",
        "aff_unique_dep": "Department of Mathematics and Computer Science",
        "aff_unique_url": "https://www.fu-berlin.de",
        "aff_unique_abbr": "FU Berlin",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636289",
        "title": "LiDAR-based Drivable Region Detection for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "For autonomous driving, drivable region detection is one of the most basic and essential tasks. In this paper, a novel LiDAR-based drivable region detection algorithm which could output a complete, accurate and stable result is proposed. To promote the completeness of the detection result, the Bayesian generalized kernel inference and bilateral filtering are utilized to estimate the attribute of those unobserved cells. To ensure the traversability, a region growing operator is performed on the normal vector map which reflects the slope of the terrain, thus closely related to the traversability of the vehicle. To improve the result\u2019s stability, information from multiple frames are fused together in the Kalman Filter framework. Experiments are performed both on public dataset and our own dataset. Experimental results show that the proposed algorithm could run in real-time and outperforms state-of-the-art approaches.",
        "primary_area": "",
        "author": "Hanzhang Xue;Hao Fu;Ruike Ren;Jintao Zhang;Bokai Liu;Yiming Fan;Bin Dai;Hanzhang Xue;Hao Fu;Ruike Ren;Jintao Zhang;Bokai Liu;Yiming Fan;Bin Dai",
        "authorids": "/37087886876;/37085437222;/37086046189;/37089197938;/37089198219;/37089193978;/37397374200;/37087886876;/37085437222;/37086046189;/37089197938;/37089198219;/37089193978;/37397374200",
        "aff": "Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, P.R. China; Laboratory of Science and Technology on Integrated Logistics Support, National University of Defense Technology, Changsha, P.R. China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, P.R. China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, P.R. China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, P.R. China; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, P.R. China; Unmanned Systems Research Center, National Innovation Institute of Defense Technology, Beijing, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636289/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7466743084810449408&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;1;0",
        "aff_unique_norm": "National Innovation Institute of Defense Technology;National University of Defense Technology",
        "aff_unique_dep": "Unmanned Systems Research Center;Laboratory of Science and Technology on Integrated Logistics Support",
        "aff_unique_url": ";http://www.nudt.edu.cn",
        "aff_unique_abbr": ";NUDT",
        "aff_campus_unique_index": "0;1;1;1;1;1;0",
        "aff_campus_unique": "Beijing;Changsha",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636011",
        "title": "Linear Policies are Sufficient to Enable Low-Cost Quadrupedal Robots to Traverse Rough Terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "The availability of inexpensive 3D-printed quadrupedal robots motivates the development of learning-based methods compatible with low-cost embedded processors and position-controlled hobby servos. In this work, we show that a linear policy is sufficient to modulate an open-loop trajectory generator, enabling a quadruped to walk over rough, unknown terrain, with limited sensing. The policy is trained in simulation using randomized terrain and dynamics and directly deployed on the robot. We show that the resulting controller can be implemented on resource-constrained systems. We demonstrate the results by deploying the policy on the OpenQuadruped, an open-source 3D-printed robot equipped with hobby servos and an embedded microprocessor.",
        "primary_area": "",
        "author": "Maurice Rahme;Ian Abraham;Matthew L. Elwin;Todd D. Murphey;Maurice Rahme;Ian Abraham;Matthew L. Elwin;Todd D. Murphey",
        "authorids": "/37089195851;/37085549466;/37085438713;/37329499800;/37089195851;/37085549466;/37085438713;/37329499800",
        "aff": "Department of Mechanical Engineering, Northwestern University, Evanston, IL; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Department of Mechanical Engineering, Northwestern University, Evanston, IL; Department of Mechanical Engineering, Northwestern University, Evanston, IL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636011/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4500825864164460165&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Northwestern University;Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering;Robotics Institute",
        "aff_unique_url": "https://www.northwestern.edu;https://www.cmu.edu",
        "aff_unique_abbr": "NU;CMU",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Evanston;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636192",
        "title": "Local Memory Attention for Fast Video Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel neural network module that transforms an existing single-frame semantic segmentation model into a video semantic segmentation pipeline. In contrast to prior works, we strive towards a simple, fast, and general module that can be integrated into virtually any single-frame architecture. Our approach aggregates a rich representation of the semantic information in past frames into a memory module. Information stored in the memory is then accessed through an attention mechanism. In contrast to previous memory-based approaches, we propose a fast local attention layer, providing temporal appearance cues in the local region of prior frames. We further fuse these cues with an encoding of the current frame through a second attention-based module. The segmentation decoder processes the fused representation to predict the final semantic segmentation. We integrate our approach into two popular semantic segmentation networks: ERFNet and PSPNet. We observe an improvement in segmentation performance on Cityscapes by 1.7% and 2.1% in mIoU respectively, while increasing inference time of ERFNet by only 1.5ms. Source code is available at https://github.com/mattpfr/lmanet.",
        "primary_area": "",
        "author": "Matthieu Paul;Martin Danelljan;Luc Van Gool;Radu Timofte;Matthieu Paul;Martin Danelljan;Luc Van Gool;Radu Timofte",
        "authorids": "/37088400511;/37085558596;/37266870700;/37393691200;/37088400511;/37085558596;/37266870700;/37393691200",
        "aff": "Vision Lab, ETH Z\u00fcrich, Switzerland; Vision Lab, ETH Z\u00fcrich, Switzerland; Vision Lab, ETH Z\u00fcrich, Switzerland; Vision Lab, ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636192/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14022732703548554790&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Vision Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636254",
        "title": "Local to Global Plane Regularity Aggregation for Dense Surfel Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel local to global plane regularity aggregation framework for dense surfel mapping, aiming for real-time reconstruction of high-quality 3D global models in both indoor and urban environments. Different from prior works that directly localize surfels globally, we investigate three interplanar geometric relations: {coplanarity, parallelism, orthogonality} from local to global scales as additional structural regularities in reconstruction, promoting the performance in plane-dominated scenes remarkably. Given a monocular RGB-D video as input, our framework extracts and utilizes the interplanar relations in three stages: local surfel creation, local to global relation propagation, and global plane-guided re-localization. In the first stage, surfels are created and refined within the current frame by aggregating temporal and spatial cues. The interplanar relations are adopted to regulate the normal and position of each surfel. Then in the second stage, we simultaneously establish correspondences between the created surfels and global model and propagate the interplanar relations from local to global. Finally, the positions of surfels are further relocated and optimized in a larger scale, based on the global interplanar relation priors aggregated across all local frames. Extensive experiments on datasets of different scales demonstrate that our framework achieves superior performance in terms of consistency and accuracy of the reconstructed global model. Meanwhile, the capability of our framework in the real-time 3D reconstruction on CPU opens the door to practical application.",
        "primary_area": "",
        "author": "Jiexiang Tan;Xiangyang Ji;Jiexiang Tan;Xiangyang Ji",
        "authorids": "/37087086869;/37271425200;/37087086869;/37271425200",
        "aff": "Department of Automation and BNRist, Tsinghua University; Department of Automation and BNRist, Tsinghua University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636254/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Ezi74mDZJ6kJ:scholar.google.com/&scioq=Local+to+Global+Plane+Regularity+Aggregation+for+Dense+Surfel+Mapping&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Automation and BNRist",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636441",
        "title": "Localization and Control of Magnetic Suture Needles in Cluttered Surgical Site with Blood and Tissue",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time visual localization of needles is necessary for various surgical applications, including surgical automation and visual feedback. In this study we investigate localization and autonomous robotic control of needles in the context of our magneto-suturing system. Our system holds the potential for surgical manipulation with the benefit of minimal invasiveness and reduced patient side effects. However, the nonlinear magnetic fields produce unintuitive forces and demand delicate position-based control that exceeds the capabilities of direct human manipulation. This makes automatic needle localization a necessity. Our localization method combines neural network-based segmentation and classical techniques, and we are able to consistently locate our needle with 0.73mm RMS error in clean environments and 2.72mm RMS error in challenging environments with blood and occlusion. The average localization RMS error is 2.16 mm for all environments we used in the experiments. We combine this localization method with our closed-loop feedback control system to demonstrate the further applicability of localization to autonomous control. Our needle is able to follow a running suture path in (1) no blood, no tissue; (2) heavy blood, no tissue; (3) no blood, with tissue; and (4) heavy blood, with tissue environments. The tip position tracking error ranges from 2.6mm to 3.7mm RMS, opening the door towards autonomous suturing tasks.",
        "primary_area": "",
        "author": "Will Pryor;Yotam Barnoy;Suraj Raval;Xiaolong Liu;Lamar Mair;Daniel Lerner;Onder Erin;Gregory D. Hager;Yancy Diaz-Mercado;Axel Krieger;Will Pryor;Yotam Barnoy;Suraj Raval;Xiaolong Liu;Lamar Mair;Daniel Lerner;Onder Erin;Gregory D. Hager;Yancy Diaz-Mercado;Axel Krieger",
        "authorids": "/37086104864;/37086936578;/37089192051;/37089394631;/37086156608;/37086698289;/37085907037;/37276163200;/38352376400;/38484449800;/37086104864;/37086936578;/37089192051;/37089394631;/37086156608;/37086698289;/37085907037;/37276163200;/38352376400;/38484449800",
        "aff": "Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA; Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, University of Maryland, College Park, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Weinberg Medical Physics, Inc., North Bethesda, MD, USA; Department of Mechanical Engineering, University of Maryland, College Park, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, University of Maryland, College Park, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636441/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17159234372343822491&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;1;0;2;1;0;0;1;0",
        "aff_unique_norm": "Johns Hopkins University;University of Maryland;Weinberg Medical Physics, Inc.",
        "aff_unique_dep": "Department of Computer Science;Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.jhu.edu;https://www/umd.edu;",
        "aff_unique_abbr": "JHU;UMD;",
        "aff_campus_unique_index": "0;0;1;0;1;0;0;1;0",
        "aff_campus_unique": "Baltimore;College Park;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636122",
        "title": "Localization with Directional Coordinates",
        "track": "main",
        "status": "Poster",
        "abstract": "A coordinate system is proposed that replaces the usual three-dimensional Cartesian x, y, z position coordinates, for use in robotic localization applications. Range, azimuth, and elevation measurement models become greatly simplified, and, unlike spherical coordinates, the proposed coordinates do not suffer from the same kinematic singularities and angle wraparound. When compared to Cartesian coordinates, the proposed coordinate system results in a significantly enhanced ability to represent the true distribution of robot positions, ultimately leading to large improvements in state estimation consistency.",
        "primary_area": "",
        "author": "Charles Champagne Cossette;Mohammed Shalaby;David Saussi\u00e9;James Richard Forbes;Charles Champagne Cossette;Mohammed Shalaby;David Saussi\u00e9;James Richard Forbes",
        "authorids": "/37087407589;/37089049261;/37547798200;/37543396800;/37087407589;/37089049261;/37547798200;/37543396800",
        "aff": "Department of Mech. Engineering, McGill University; Department of Mech. Engineering, McGill University; Department of Electrical Engineering, Polytechnique Montr\u00e9al; Department of Mech. Engineering, McGill University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636122/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12978596801606619239&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "McGill University;Polytechnique Montr\u00e9al",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electrical Engineering",
        "aff_unique_url": "https://www.mcgill.ca;https://www.polymtl.ca",
        "aff_unique_abbr": "McGill;Polytechnique",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Montr\u00e9al",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636529",
        "title": "Look Before You Act: Boosting Pseudo-LiDAR with Online Semantic Embedding",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision-based 3D object detection is a research focus in the field of autonomous driving system. While recently proposed pseudo-LiDAR is a promising solution, its performance is severely restricted by the image-based depth estimator, leading to a considerable performance gap against the LiDAR-based counterparts. In this paper, substantial advances are developed along an orthogonal direction to the previous efforts in the pseudo-LiDAR pipeline. Concretely, we propose a plug- and-play module, called Online Semantic Embedding (OSE), aligning image semantics with the pseudo-LiDAR detection in an end-to-end manner. On the KITTI object detection benchmark, existing stereo-based baselines integrated with our approach show impressive improvements without bells and whistles. Furthermore, we emphasize that OSE works in retrieving the performance under geometric imperfection conditions.",
        "primary_area": "",
        "author": "Liangjun Zhang;Tao Song;Tao Jiang;Di Xie;Shiliang Pu;Liangjun Zhang;Tao Song;Tao Jiang;Di Xie;Shiliang Pu",
        "authorids": "/37088642847;/37089194643;/37089196042;/37086055192;/37085657816;/37088642847;/37089194643;/37089196042;/37086055192;/37085657816",
        "aff": "Hikvision Research Institute, Hangzhou, China; Hikvision Research Institute, Hangzhou, China; Hikvision Research Institute, Hangzhou, China; Hikvision Research Institute, Hangzhou, China; Hikvision Research Institute, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636529/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:F1k_s_ce6NwJ:scholar.google.com/&scioq=Look+Before+You+Act:+Boosting+Pseudo-LiDAR+with+Online+Semantic+Embedding&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Hikvision Research Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.hikvision.com/cn/",
        "aff_unique_abbr": "HRI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636683",
        "title": "Loosely Synchronized Search for Multi-agent Path Finding with Asynchronous Actions",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent path finding (MAPF) determines an ensemble of collision-free paths for multiple agents between their respective start and goal locations. Among the available MAPF planners for workspace modeled as a graph, A*-based approaches have been widely investigated due to their guarantees on completeness and solution optimality, and have demonstrated their efficiency in many scenarios. However, almost all of these A*-based methods assume that each agent executes an action concurrently in that all agents start and stop together. This article presents a natural generalization of MAPF with asynchronous actions (MAPF-AA) where agents do not necessarily start and stop concurrently. The main contribution of the work is a proposed approach called Loosely Synchronized Search (LSS) that extends A*-based MAPF planners to handle asynchronous actions. We show LSS is complete and finds an optimal solution if one exists. We also combine LSS with other existing MAPF methods that aims to trade-off optimality for computational efficiency. Numerical results are presented to corroborate the performance of LSS and the applicability of the proposed method is verified in the Robotarium, a remotely accessible swarm robotics research platform.",
        "primary_area": "",
        "author": "Zhongqiang Ren;Sivakumar Rathinam;Howie Choset;Zhongqiang Ren;Sivakumar Rathinam;Howie Choset",
        "authorids": "/37086293378;/37268809800;/37281322200;/37086293378;/37268809800;/37281322200",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, USA; Texas A&M University, College Station, TX; Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636683/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16731273173829486169&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Texas A&M University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://www.tamu.edu",
        "aff_unique_abbr": "CMU;TAMU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pittsburgh;College Station",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635936",
        "title": "Low Dimensional State Representation Learning with Robotics Priors in Continuous Action Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning algorithms have proven to be capable of solving complicated robotics tasks in an end-to-end fashion without any need for hand-crafted features or policies. Especially in the context of robotics, in which the cost of real-world data is usually extremely high, Reinforcement Learning solutions achieving high sample efficiency are needed. In this paper, we propose a framework combining the learning of a low-dimensional state representation, from high-dimensional observations coming from the robot\u2019s raw sensory readings, with the learning of the optimal policy, given the learned state representation. We evaluate our framework in the context of mobile robot navigation in the case of continuous state and action spaces. Moreover, we study the problem of transferring what learned in the simulated virtual environment to the real robot without further retraining using real-world data in the presence of visual and depth distractors, such as lighting changes and moving obstacles. A video of our experiments can be found at: https://youtu.be/rUdGPKr2Wuo.",
        "primary_area": "",
        "author": "Nicol\u00f2 Botteghi;Khaled Alaa;Mannes Poel;Beril Sirmacek;Christoph Brune;Abeje Mersha;Stefano Stramigioli;Nicol\u00f2 Botteghi;Khaled Alaa;Mannes Poel;Beril Sirmacek;Christoph Brune;Abeje Mersha;Stefano Stramigioli",
        "authorids": "/37088854522;/37086134789;/37602934800;/37541698600;/38185938500;/37887690800;/37282439300;/37088854522;/37086134789;/37602934800;/37541698600;/38185938500;/37887690800;/37282439300",
        "aff": "Faculty of Electrical Engineering, Mathematics and Computer Science, University of Twente, Enschede, The Netherlands; Intelligent Driving Functions R&D Center, IAV GmbH (Volkswagen Group), Berlin, Germany; Faculty of Electrical Engineering, Mathematics and Computer Science, University of Twente, Enschede, The Netherlands; Department of Computer Science, J\u00f6nk\u00f6ping University, J\u00f6nk\u00f6ping, Sweden; Faculty of Electrical Engineering, Mathematics and Computer Science, University of Twente, Enschede, The Netherlands; Research Group of Mechatronics, Saxion University of Applied Sciences, Enschede, The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science, University of Twente, Enschede, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635936/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12340864184045585122&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;0;3;0",
        "aff_unique_norm": "University of Twente;IAV GmbH;J\u00f6nk\u00f6ping University;Saxion University of Applied Sciences",
        "aff_unique_dep": "Faculty of Electrical Engineering, Mathematics and Computer Science;Intelligent Driving Functions R&D Center;Department of Computer Science;Research Group of Mechatronics",
        "aff_unique_url": "https://www.utwente.nl;https://www.iav.de;https://ju.se;https://www.saxion.nl",
        "aff_unique_abbr": "UT;IAV;JU;",
        "aff_campus_unique_index": "0;1;0;2;0;0;0",
        "aff_campus_unique": "Enschede;Berlin;J\u00f6nk\u00f6ping",
        "aff_country_unique_index": "0;1;0;2;0;0;0",
        "aff_country_unique": "Netherlands;Germany;Sweden"
    },
    {
        "id": "9636372",
        "title": "Low-level Pose Control of Tilting Multirotor for Wall Perching Tasks Using Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, needs for unmanned aerial vehicles (UAVs) that are attachable to the wall have been highlighted. As one of the ways to address the need, researches on various tilting multirotors that can increase maneuverability has been employed. Unfortunately, existing studies on the tilting multirotors require considerable amounts of prior information on the complex dynamic model. Meanwhile, reinforcement learning on quadrotors has been studied to mitigate this issue. Yet, these are only been applied to standard quadrotors, whose systems are less complex than those of tilting multirotors. In this paper, a novel reinforcement learning-based method is proposed to control a tilting multirotor on real-world applications, which is the first attempt to apply reinforcement learning to a tilting multirotor. To do so, we propose a novel reward function for a neural network model that takes power efficiency into account. The model is initially trained over a simulated environment and then fine-tuned using real-world data in order to overcome the sim-to-real gap issue. Furthermore, a novel, efficient state representation with respect to the goal frame that helps the network learn optimal policy better is proposed. As verified on real-world experiments, our proposed method shows robust controllability by overcoming the complex dynamics of tilting multirotors.",
        "primary_area": "",
        "author": "Hyungyu Lee;Myeongwoo Jeong;Chanyoung Kim;Hyungtae Lim;Changgue Park;Sungwon Hwang;Hyun Myung;Hyungyu Lee;Myeongwoo Jeong;Chanyoung Kim;Hyungtae Lim;Changgue Park;Sungwon Hwang;Hyun Myung",
        "authorids": "/37088970270;/37088971325;/37088968738;/37086920570;/37087321807;/37088566289;/37424926900;/37088970270;/37088971325;/37088968738;/37086920570;/37087321807;/37088566289;/37424926900",
        "aff": "Urban Robotics Lab, KAIST; Urban Robotics Lab, KAIST; Urban Robotics Lab, KAIST; Urban Robotics Lab, KAIST; Korea Electronics Technology Institute(KETI); Urban Robotics Lab, KAIST; Urban Robotics Lab, KAIST",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636372/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18022847301592719792&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "KAIST;Korea Electronics Technology Institute",
        "aff_unique_dep": "Urban Robotics Lab;",
        "aff_unique_url": "https://www.kaist.edu;http://www.keti.re.kr",
        "aff_unique_abbr": "KAIST;KETI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9635905",
        "title": "Lvio-Fusion: A Self-adaptive Multi-sensor Fusion SLAM Framework Using Actor-critic Method",
        "track": "main",
        "status": "Poster",
        "abstract": "State estimation with sensors is essential for mobile robots. Due to different performance of sensors in different environments, how to fuse measurements of various sensors is a problem. In this paper, we propose a tightly coupled multi-sensor fusion framework, Lvio-Fusion, which fuses stereo camera, Lidar, IMU, and GPS based on the graph optimization. Especially for urban traffic scenes, we introduce a segmented global pose graph optimization with GPS and loop-closure, which can eliminate accumulated drifts. Additionally, we creatively use a actor-critic method in reinforcement learning to adaptively adjust sensors\u2019 weight. After training, actor-critic agent can provide the system better and dynamic sensors\u2019 weight. We evaluate the performance of our system on public datasets and compare it with other state-of-the-art methods, which shows that the proposed method achieves high estimation accuracy and robustness to various environments. And our implementations are open source and highly scalable.",
        "primary_area": "",
        "author": "Yupeng Jia;Haiyong Luo;Fang Zhao;Guanlin Jiang;Yuhang Li;Jiaquan Yan;Zhuqing Jiang;Zitian Wang;Yupeng Jia;Haiyong Luo;Fang Zhao;Guanlin Jiang;Yuhang Li;Jiaquan Yan;Zhuqing Jiang;Zitian Wang",
        "authorids": "/37089194678;/37401608500;/37877380700;/37089193911;/37089196226;/37089194818;/37085864026;/37089197457;/37089194678;/37401608500;/37877380700;/37089193911;/37089196226;/37089194818;/37085864026;/37089197457",
        "aff": "School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications, Beijing, China; Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, China; School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications, Beijing, China; School of Computer Science (National Pilot Software Engineering School), Beijing University of Posts and Telecommunications, Beijing, China; School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China; School of Artificial Intelligence, Beijing Technology and Business University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635905/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16897822295305910979&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;0;0;0;2",
        "aff_unique_norm": "Beijing University of Posts and Telecommunications;Chinese Academy of Sciences;Beijing Technology and Business University",
        "aff_unique_dep": "School of Computer Science;Institute of Computing Technology;School of Artificial Intelligence",
        "aff_unique_url": "http://www.bupt.edu.cn;http://www.ict.cas.cn;http://www.btbu.edu.cn",
        "aff_unique_abbr": "BUPT;CAS;BTBU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635836",
        "title": "MAMBPO: Sample-efficient multi-robot reinforcement learning using learned world models",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-robot systems can benefit from reinforcement learning (RL) algorithms that learn behaviours in a small number of trials, a property known as sample efficiency. This research thus investigates the use of learned world models to improve sample efficiency. We present a novel multi-agent model-based RL algorithm: Multi-Agent Model-Based Policy Optimization (MAMBPO), utilizing the Centralized Learning for Decentralized Execution (CLDE) framework. CLDE algorithms allow a group of agents to act in a fully decentralized manner after training. This is a desirable property for many systems comprising of multiple robots. MAMBPO uses a learned world model to improve sample efficiency compared to model-free Multi-Agent Soft Actor-Critic (MASAC). We demonstrate this on two simulated multi-robot tasks, where MAMBPO achieves a similar performance to MASAC, but requires far fewer samples to do so. Through this, we take an important step towards making real-life learning for multi-robot systems possible.",
        "primary_area": "",
        "author": "Dani\u00ebl Willemsen;Mario Coppola;Guido C.H.E. de Croon;Dani\u00ebl Willemsen;Mario Coppola;Guido C.H.E. de Croon",
        "authorids": "/37089194046;/37086289143;/37698062600;/37089194046;/37086289143;/37698062600",
        "aff": "MAVLab, Control & Operations Department, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; MAVLab, Control & Operations Department, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; MAVLab, Control & Operations Department, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635836/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7216084473096435172&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Control & Operations Department",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TUDelft",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9636404",
        "title": "MBAPose: Mask and Bounding-Box Aware Pose Estimation of Surgical Instruments with Photorealistic Domain Randomization",
        "track": "main",
        "status": "Poster",
        "abstract": "Surgical robots are usually controlled using a priori models based on the robots\u2019 geometric parameters, which are calibrated before the surgical procedure. One of the challenges in using robots in real surgical settings is that those parameters can change over time, consequently deteriorating control accuracy. In this context, our group has been investigating online calibration strategies without added sensors. In one step toward that goal, we have developed an algorithm to estimate the pose of the instruments\u2019 shafts in endoscopic images. In this study, we build upon that earlier work and propose a new framework to more precisely estimate the pose of a rigid surgical instrument. Our strategy is based on a novel pose estimation model called MBAPose and the use of synthetic training data. Our experiments demonstrated an improvement of 21 % for translation error and 26 % for orientation error on synthetic test data with respect to our previous work. Results with real test data provide a baseline for further research.",
        "primary_area": "",
        "author": "Masakazu Yoshimura;Murilo M. Marinho;Kanako Harada;Mamoru Mitsuishi;Masakazu Yoshimura;Murilo M. Marinho;Kanako Harada;Mamoru Mitsuishi",
        "authorids": "/37088420806;/38519488300;/37556612000;/37278679300;/37088420806;/38519488300;/37556612000;/37278679300",
        "aff": "Department of Mechanical Engineering, the University of Tokyo, Tokyo, Japan; Department of Mechanical Engineering, the University of Tokyo, Tokyo, Japan; Department of Mechanical Engineering, the University of Tokyo, Tokyo, Japan; Department of Mechanical Engineering, the University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636404/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14639049785159310064&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636827",
        "title": "MDN-VO: Estimating Visual Odometry with Confidence",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual Odometry (VO) is used in many applications including robotics and autonomous systems. However, traditional approaches based on feature matching are computationally expensive and do not directly address failure cases, instead relying on heuristic methods to detect failure. In this work, we propose a deep learning-based VO model to efficiently estimate 6-DoF poses, as well as a confidence model for these estimates. We utilise a CNN - RNN hybrid model to learn feature representations from image sequences. We then employ a Mixture Density Network (MDN) which estimates camera motion as a mixture of Gaussians, based on the extracted spatio-temporal representations. Our model uses pose labels as a source of supervision, but derives uncertainties in an unsupervised manner. We evaluate the proposed model on the KITTI and nuScenes datasets and report extensive quantitative and qualitative results to analyse the performance of both pose and uncertainty estimation. Our experiments show that the proposed model exceeds state-of-the-art performance in addition to detecting failure cases using the predicted pose uncertainty.",
        "primary_area": "",
        "author": "Nimet Kaygusuz;Oscar Mendez;Richard Bowden;Nimet Kaygusuz;Oscar Mendez;Richard Bowden",
        "authorids": "/37089003434;/37710939600;/37268872100;/37089003434;/37710939600;/37268872100",
        "aff": "University of Surrey; University of Surrey; University of Surrey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636827/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5913689966345142724&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Surrey",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.surrey.ac.uk",
        "aff_unique_abbr": "Surrey",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636687",
        "title": "MR-iSAM2: Incremental Smoothing and Mapping with Multi-Root Bayes Tree for Multi-Robot SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "We present multi-robot iSAM2 (MR-iSAM2), an efficient incremental smoothing and mapping (iSAM) algorithm to solve multi-robot simultaneous localization and mapping (SLAM) inference problems. MR-iSAM2 is based on a novel data structure multi-root Bayes tree (MRBT), which packs multiple Bayes trees with the same undirected clique structure. In multi-robot scenarios, the MRBT enables new measurements from different robots to be updated in different root branches, while all updates are performed around the single root of the Bayes tree in the original iSAM2 algorithm. As a result, the MRBT better reveals the underlying sparsity and information flow in multi-robot SLAM inference problems than the Bayes tree. Based on this insight, we further develop MR-iSAM2 to incrementally update and maintain the sparsity structure of the MRBT and enable efficient information propagation among the roots for inter-robot inference. We analyze the properties of the MR-iSAM2 algorithm, and show with both synthetic and real world datasets that it significantly outperforms iSAM2 in efficiency when solving multi-robot SLAM problems.",
        "primary_area": "",
        "author": "Yetong Zhang;Ming Hsiao;Jing Dong;Jakob Engel;Frank Dellaert;Yetong Zhang;Ming Hsiao;Jing Dong;Jakob Engel;Frank Dellaert",
        "authorids": "/37088998216;/37089397066;/37088451595;/38541523200;/37282902200;/37088998216;/37089397066;/37088451595;/38541523200;/37282902200",
        "aff": "College of Computing, Georgia Institute of Technology, Atlanta, USA; Facebook Reality Labs Research, Redmond, USA; Facebook Reality Labs Research, Redmond, USA; Facebook Reality Labs Research, Redmond, USA; College of Computing, Georgia Institute of Technology, Atlanta, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636687/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6994196032374869191&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Meta",
        "aff_unique_dep": "College of Computing;Research",
        "aff_unique_url": "https://www.gatech.edu;https://www.facebook.com/realitylabs",
        "aff_unique_abbr": "Georgia Tech;FRL",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Atlanta;Redmond",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635946",
        "title": "MV-FractalDB: Formula-driven Supervised Learning for Multi-view Image Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper proposes a method for automatic multi-view dataset construction based on formula-driven supervised learning (FDSL). Although data collection and human annotation of 3D objects are labor-intensive, we automatically generate their training data and labels in the proposed multi-view dataset. To create a large-scale multi-view dataset, we employ fractal geometry, which is considered the background information of many objects in the real world. We project in a circle from the rendered 3D fractal models to construct the Multi-view Fractal DataBase (MV-FractalDB), which is then used to make a pre-trained CNN model. According to the experimental results, the MV-FractalDB pre-trained model surpasses the accuracies with self-supervised methods (e.g., SimCLR and MoCo) and is close to supervised methods (e.g., ImageNet) in terms of performance rates on multi-view image datasets. We demonstrate the potential of FDSL for multi-view image recognition.",
        "primary_area": "",
        "author": "Ryosuke Yamada;Ryo Takahashi;Ryota Suzuki;Akio Nakamura;Yusuke Yoshiyasu;Ryusuke Sagawa;Hirokatsu Kataoka;Ryosuke Yamada;Ryo Takahashi;Ryota Suzuki;Akio Nakamura;Yusuke Yoshiyasu;Ryusuke Sagawa;Hirokatsu Kataoka",
        "authorids": "/37089157567;/37089404329;/37086563171;/37274192600;/37392153300;/37298519900;/37845110800;/37089157567;/37089404329;/37086563171;/37274192600;/37392153300;/37298519900;/37845110800",
        "aff": "Graduate School of Science and Technology for Future Life, Tokyo Denki University (TDU); Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST); Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST); Graduate School of Science and Technology for Future Life, Tokyo Denki University (TDU); Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST); Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST); Artificial Intelligence Research Center, National Institute of Advanced Industrial Science and Technology (AIST)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635946/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12210225599229196582&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;0;1;1;1",
        "aff_unique_norm": "Tokyo Denki University;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Graduate School of Science and Technology for Future Life;Artificial Intelligence Research Center",
        "aff_unique_url": "https://www.tdu.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "TDU;AIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636875",
        "title": "Maneuver-based Trajectory Prediction for Self-driving Cars Using Spatio-temporal Convolutional Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to predict the future movements of other vehicles is a subconscious and effortless skill for humans and key to safe autonomous driving. Therefore, trajectory prediction for autonomous cars has gained a lot of attention in recent years. It is, however, still a hard task to achieve human-level performance. Interdependencies between vehicle behaviors and the multimodal nature of future intentions in a dynamic and complex driving environment render trajectory prediction a challenging problem. In this work, we propose a new, datadriven approach for predicting the motion of vehicles in a road environment. The model allows for inferring future intentions from the past interaction among vehicles in highway driving scenarios. Using our neighborhood-based data representation, the proposed system jointly exploits correlations in the spatial and temporal domain using convolutional neural networks. Our system considers multiple possible maneuver intentions and their corresponding motion and predicts the trajectory for five seconds into the future. We implemented our approach and evaluated it on two highway datasets taken in different countries and are able to achieve a competitive prediction performance.",
        "primary_area": "",
        "author": "Benedikt Mersch;Thomas H\u00f6llen;Kun Zhao;Cyrill Stachniss;Ribana Roscher;Benedikt Mersch;Thomas H\u00f6llen;Kun Zhao;Cyrill Stachniss;Ribana Roscher",
        "authorids": "/37088917207;/37089196923;/37089194750;/37329668600;/37847038100;/37088917207;/37089196923;/37089194750;/37329668600;/37847038100",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; Aptiv Services Deutschland GmbH, Wuppertal, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636875/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=858506471234384383&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Bonn;Aptiv Services Deutschland GmbH",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-bonn.de;",
        "aff_unique_abbr": "UBonn;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Wuppertal",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636137",
        "title": "Manifold Trial Selection to Reduce Negative Transfer in Motor Imagery-based Brain\u2013Computer Interface",
        "track": "main",
        "status": "Poster",
        "abstract": "A major challenge in electroencephalogram (EEG) signal classification is that the EEG signals recorded from different subjects are drawn from different distributions. When the unlabeled EEG data of the new subject arrive, called target domain, classifying them with a classifier trained on prerecorded EEG data of other subjects, called source domain, will greatly decrease the classification accuracy. Being able to use the classifiers trained on data of source domain to accurately classify the data of target domain could reduce the time of the calibration phase in the actual application of the brain-computer interface. This study considers an offline cross-subject classification scenario. We propose a novel manifold trial selection method, which reduces the distribution distance between the source and target domains by manifold transformation and domain adaptation. The proposed method provides a trial selection strategy to suppress negative transfer by removing some abnormal samples. The proposed method is applied to the motor imagery-based brain\u2013computer interface and compared with several existing algorithms. Experimental results show that the proposed method outperforms the state-of-the-art methods.",
        "primary_area": "",
        "author": "Zilin Liang;Zheng Zheng;Weihai Chen;Jianhua Wang;Jianbin Zhang;Jianer Chen;Zuobing Chen;Zilin Liang;Zheng Zheng;Weihai Chen;Jianhua Wang;Jianbin Zhang;Jianer Chen;Zuobing Chen",
        "authorids": "/37089196666;/37292753300;/37279188000;/37539004800;/37293685500;/37089196406;/37088953899;/37089196666;/37292753300;/37279188000;/37539004800;/37293685500;/37089196406;/37088953899",
        "aff": "Hangzhou Innovation Institute, Beihang University, Hangzhou, China; Hangzhou Innovation Institute, Beihang University, Hangzhou, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Hangzhou Innovation Institute, Beihang University, Hangzhou, China; School of Mechanical Engineering and Automation, Beihang University, Beijing, China; Department of Geriatric Rehabilitation, The First Affiliated Hospital, Zhejiang Chinese Medical University, Hangzhou, China; Department of Rehabilitation Medicine, The First Affiliated Hospital, College of Medicine, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636137/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7555591141185032370&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;2",
        "aff_unique_norm": "Beihang University;Zhejiang Chinese Medical University;Zhejiang University",
        "aff_unique_dep": "Hangzhou Innovation Institute;Department of Geriatric Rehabilitation;Department of Rehabilitation Medicine",
        "aff_unique_url": "http://www.buaa.edu.cn;;http://www.zju.edu.cn",
        "aff_unique_abbr": ";;ZJU",
        "aff_campus_unique_index": "0;0;1;0;1;0;0",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636257",
        "title": "Manipulating a Whip in 3D via Dynamic Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "A prominent challenge in the field of robotics is manipulation of flexible objects. One major factor that makes this task difficult is the complex dynamics emerging from its high-dimensional structure. This argues against the use of popular optimization-based approaches, which scale poorly with system dimension (the \"curse of dimensionality\"). Nevertheless, almost indifferent to this complexity, humans handle it on a daily basis, without any apparent difficulty.Inspired by human motor control, we propose that encoding movements based on dynamic primitives can simplify the task of manipulating flexible objects and provides a way around the curse of dimensionality. Using an extreme example \u2014 manipulating a whip \u2014 we tested in simulation whether targets at various locations could be reached with a whip by using a controller based on dynamic primitives. Regardless of the target location, this approach successfully managed the complexity of a 54 degree-of-freedom system (yielding a 108-dimensional state-space representation) and identified an upper-limb movement that achieved the task. This approach did not require a detailed model of the whip, which thereby significantly simplified the computational complexity of the control task. We believe that this approach may facilitate robotic manipulation of flexible materials, and in general afford a simplified way to control dynamically complex objects.",
        "primary_area": "",
        "author": "Moses C. Nah;Aleksei Krotov;Marta Russo;Dagmar Sternad;Neville Hogan;Moses C. Nah;Aleksei Krotov;Marta Russo;Dagmar Sternad;Neville Hogan",
        "authorids": "/37086093366;/37088534574;/37088532758;/38469397700;/37298867300;/37086093366;/37088534574;/37088532758;/38469397700;/37298867300",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Bioengineering, Northeastern University, Boston, MA, USA; Department of Biology, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Department of Physics, Institute for Experiential Robotics, Northeastern University, Boston, MA, USA; Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636257/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4545686041019454677&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Northeastern University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Bioengineering",
        "aff_unique_url": "https://web.mit.edu;https://www.northeastern.edu",
        "aff_unique_abbr": "MIT;NU",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Cambridge;Boston",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636001",
        "title": "Many-Joint Robot Arm Control with Recurrent Spiking Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "In the paper, we show how scalable, low-cost trunk-like robotic arms can be constructed using only basic 3D-printing equipment and simple electronics. The design is based on uniform, stackable joint modules with three degrees of freedom each. Moreover, we present an approach for controlling these robots with recurrent spiking neural networks. At first, a spiking forward model learns motor-pose correlations from movement observations. After training, intentions can be projected back through unrolled spike trains of the forward model essentially routing the intention-driven motor gradients towards the respective joints, which unfolds goal-direction navigation. We demonstrate that spiking neural networks can thus effectively control trunk-like robotic arms with up to 75 articulated degrees of freedom with near millimeter accuracy.",
        "primary_area": "",
        "author": "Manuel Traub;Robert Legenstein;Sebastian Otte;Manuel Traub;Robert Legenstein;Sebastian Otte",
        "authorids": "/37089197555;/37086154758;/38547583000;/37089197555;/37086154758;/38547583000",
        "aff": "NeuroCognitive Modeling Group of the Computer Science Department, University of T\u00fcbingen, T\u00fcbingen, Germany; Faculty of Computer Science and Biomedical Engineering, Graz University of Technology, Graz, Austria; NeuroCognitive Modeling Group of the Computer Science Department, University of T\u00fcbingen, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636001/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10519477376772973571&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of T\u00fcbingen;Graz University of Technology",
        "aff_unique_dep": "Computer Science Department;Faculty of Computer Science and Biomedical Engineering",
        "aff_unique_url": "https://www.uni-tuebingen.de;https://www.tugraz.at",
        "aff_unique_abbr": "Uni T\u00fcbingen;TU Graz",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "T\u00fcbingen;Graz",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Germany;Austria"
    },
    {
        "id": "9636789",
        "title": "Map Compressibility Assessment for LiDAR Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "We aim to assess the performance of LiDAR-to-map registration on compressive maps. Modern autonomous vehicles utilize pre-built HD (High-Definition) maps to perform sensor-to-map registration, which recovers pose estimation failures and reduces drift in a large-scale environment. However, sensor-to-map registration is usually realized by registering the sensor to a dense 3D model, which occupies massive storage space in the HD map and requires much data processing overhead. Although smaller 3D models are preferable, the optimal compressive map format for preservation of the best registration performance remains unclear.In this paper, we propose a novel and challenging benchmark to evaluate existing LiDAR-to-map registration methods from three perspectives: map compressibility, robustness, and precision. We compared various map formats, including raw points, hierarchical GMMs, and feature points, and show their performance trade-offs between compressibility and robustness on real-world LiDAR datasets: KITTI Odometry Dataset and Argoverse Tracking Dataset. Our benchmark reveals that state-of-the-art deep feature point based methods outperform traditional methods significantly when the map size budget is high. However, when map size budget is low, deep methods are outperformed by the methods using simpler models in Argoverse Tracking Dataset due to poor spatial coverage. In addition, we observe that the recently published TEASER++ significantly outperforms RANSAC for the feature point methods. Our analysis provides a valuable reference for the community to design budgeted real-world systems and find potential research opportunities. We will release the benchmark for public use.",
        "primary_area": "",
        "author": "Ming-Fang Chang;Wei Dong;Joshua Mangelson;Michael Kaess;Simon Lucey;Ming-Fang Chang;Wei Dong;Joshua Mangelson;Michael Kaess;Simon Lucey",
        "authorids": "/37086391653;/37086933483;/37086109836;/37324200400;/37266130100;/37086391653;/37086933483;/37086109836;/37324200400;/37266130100",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Brigham Young University; Carnegie Mellon University; Australian Insitute of Machine Learning (AIML), The University of Adelaide",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636789/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4000573159919087084&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "Carnegie Mellon University;Brigham Young University;University of Adelaide",
        "aff_unique_dep": ";;Australian Insitute of Machine Learning (AIML)",
        "aff_unique_url": "https://www.cmu.edu;https://www.byu.edu;https://www.adelaide.edu.au",
        "aff_unique_abbr": "CMU;BYU;Adelaide",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "9636461",
        "title": "Map-Aided Train Navigation with IMU Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous train navigation using only a low-cost MEMS IMU and a track map is considered in this paper. The approach is designed for urban rail or subway environments where GNSS measurements are unreliable or unavailable, and is intended as a baseline against which more complex sensor fusion approaches can be compared to ensure the consistency of the estimates. The estimator exploits the track motion constraint and information about position and velocity derived from centripetal acceleration and angular velocity measurements to improve the dead-reckoning solution and keep error and uncertainty bounded. In experimental validation over a 6 km run of a subway train during commuter service, the proposed approach had a maximum error of 6.0 m, validating the approach as an independent estimator.",
        "primary_area": "",
        "author": "Marc-Antoine Lavoie;James Richard Forbes;Marc-Antoine Lavoie;James Richard Forbes",
        "authorids": "/37566755700;/37089194921;/37566755700;/37089194921",
        "aff": "Department of Mechanical Engineering, McGill University, Montreal, Canada; Department of Mechanical Engineering, McGill University, Montreal, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636461/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7557426057918794575&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "McGill University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mcgill.ca",
        "aff_unique_abbr": "McGill",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636724",
        "title": "MapFusion: A General Framework for 3D Object Detection with HDMaps",
        "track": "main",
        "status": "Poster",
        "abstract": "3D object detection is a key perception component in autonomous driving. Most recent approaches are based on LiDAR sensors only or fused with cameras. Maps (e.g., High Definition Maps), a basic infrastructure for intelligent vehicles, however, have not been well exploited for boosting object detection tasks. In this paper, we propose a simple but effective framework - MapFusion to integrate the map information into modern 3D object detector pipelines. In particular, we design a FeatureAgg module for HD Map feature extraction and fusion, and a MapSeg module as an auxiliary segmentation head for the detection backbone. Our proposed MapFusion is detector independent and can be easily integrated into different detectors. The experimental results of three different baselines on large public autonomous driving dataset demonstrate the superiority of the proposed framework. By fusing the map information, we can achieve 1.27 to 2.79 points improvements for mean Average Precision (mAP) on three strong 3D object detection baselines.",
        "primary_area": "",
        "author": "Jin Fang;Dingfu Zhou;Xibin Song;Liangjun Zhang;Jin Fang;Dingfu Zhou;Xibin Song;Liangjun Zhang",
        "authorids": "/37087078022;/37086567721;/37086034432;/37088642847;/37087078022;/37086567721;/37086034432;/37088642847",
        "aff": "National Engineering Laboratory of Deep Learning Technology and Application, China; National Engineering Laboratory of Deep Learning Technology and Application, China; National Engineering Laboratory of Deep Learning Technology and Application, China; National Engineering Laboratory of Deep Learning Technology and Application, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636724/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4344650054140864835&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Engineering Laboratory of Deep Learning Technology and Application",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636593",
        "title": "Mapless Humanoid Navigation Using Learned Latent Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel Deep Reinforcement Learning approach to address the mapless navigation problem, in which the locomotion actions of a humanoid robot are taken online based on the knowledge encoded in learned models. Planning happens by generating open-loop trajectories in a learned latent space that captures the dynamics of the environment. Our planner considers visual (RGB images) and non-visual observations (e.g., attitude estimations). This confers the agent upon awareness not only of the scenario, but also of its own state. In addition, we incorporate a termination likelihood predictor model as an auxiliary loss function of the control policy, which enables the agent to anticipate terminal states of success and failure. In this manner, the sample efficiency of the approach for episodic tasks is increased. Our model is evaluated on the NimbRo-OP2X humanoid robot that navigates in scenes avoiding collisions efficiently in simulation and with the real hardware.",
        "primary_area": "",
        "author": "Andr\u00e9 Brandenburger;Diego Rodriguez;Sven Behnke;Andr\u00e9 Brandenburger;Diego Rodriguez;Sven Behnke",
        "authorids": "/37086601407;/37086373727;/37295987100;/37086601407;/37086373727;/37295987100",
        "aff": "Autonomous Intelligent Systems (AIS) Group, Computer Science Institute VI, University of Bonn, Germany; Autonomous Intelligent Systems (AIS) Group, Computer Science Institute VI, University of Bonn, Germany; Autonomous Intelligent Systems (AIS) Group, Computer Science Institute VI, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636593/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4794558289668687761&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Computer Science Institute VI",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "Uni Bonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636159",
        "title": "Marine Autonomous Navigation for Biomimetic Underwater Robots Based on Deep Stereo Attention Network",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a multi-objective visionbased navigation network for biomimetic underwater robots to cope with scientific observation, target selection, and obstacle avoidance in marine missions. Structurally, a stereo block attention module is first constructed to serially extract the channel and spatial attention portion of the real-time visual feedback. Next, the parallax attention mechanism is introduced to enable the network to excavate implicit parallax information in stereo pairs, effectively eliminating the oscillation of the network output in the presence of ambiguous visual input. Further, with the assistance of other low-cost sensors, the proposed navigation network can be expanded in some largescale application scenarios, such as sparse coral observation. Finally, underwater simulations reveal that the proposed method obtains significantly improved control effect and real-time ability, compared with other related works. In particular, based on a self-developed biomimetic robotic dolphin, collision-free simulations with a cumulative distance beyond 1000 m were carried out and validated the effectiveness and the superiority of the navigation network, where both dense and sparse targets were fully tested. The robotic dolphin can not only successfully conduct accurate coral observation without collision, but also quest the observation targets as much as possible in the area where the observation targets are concentrated. The proposed network provides an intelligent and efficient navigation scheme for autonomous underwater operation of small-size underwater robots.",
        "primary_area": "",
        "author": "Shuaizheng Yan;Zhengxing Wu;Jian Wang;Min Tan;Junzhi Yu;Shuaizheng Yan;Zhengxing Wu;Jian Wang;Min Tan;Junzhi Yu",
        "authorids": "/37086599945;/38580572600;/37086447299;/37274596200;/37278401500;/37086599945;/38580572600;/37086447299;/37274596200;/37278401500",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Department of Mechanics and Engineering Science, State Key Laboratory for Turbulence and Complex Systems, BIC-ESAT, College of Engineering, Peking University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636159/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3253799223172290288&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Peking University",
        "aff_unique_dep": "School of Artificial Intelligence;Department of Mechanics and Engineering Science",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.pku.edu.cn",
        "aff_unique_abbr": "UCAS;PKU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636286",
        "title": "Market-based Multi-robot coordination with HTN planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a decentralized approach that simultaneously allocates and decomposes high level tasks among various robots. The approach exploits HTN structures and algorithms, that are used within an auction-based allocation scheme, and aims at dealing with complex tasks with causal or temporal relations. The paper formalizes the approach, and depicts how HTN planning processes are used to estimate bids and distribute tasks. Results on a statistical series of coverage problems are presented and their performance is assessed through a comparison with a state of the art algorithm.",
        "primary_area": "",
        "author": "Antoine Milot;Estelle Chauveau;Simon Lacroix;Charles Lesire;Antoine Milot;Estelle Chauveau;Simon Lacroix;Charles Lesire",
        "authorids": "/37089197729;/37087039494;/37278650100;/38275129600;/37089197729;/37087039494;/37278650100;/38275129600",
        "aff": "ONERA/DTIS, Universit\u00e9 de Toulouse, Toulouse, France; NAVAL GROUP, Ollioules, France; LAAS-CNRS, Universit\u00e9 de Toulouse, Toulouse, France; ONERA/DTIS, Universit\u00e9 de Toulouse, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636286/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9307456419595562054&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "ONERA;NAVAL GROUP;Universit\u00e9 de Toulouse",
        "aff_unique_dep": "DTIS;;LAAS-CNRS",
        "aff_unique_url": "https://www.onera.fr;https://www.naval-group.com;https://www.univ-toulouse.fr",
        "aff_unique_abbr": "ONERA;;UT",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Ollioules;Toulouse",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636584",
        "title": "Measurement-Robust Control Barrier Functions: Certainty in Safety with Uncertainty in State",
        "track": "main",
        "status": "Poster",
        "abstract": "The increasing complexity of modern robotic systems and the environments they operate in necessitates the formal consideration of safety in the presence of imperfect measurements. In this paper we propose a rigorous framework for safety-critical control of systems with erroneous state estimates. We develop this framework by leveraging Control Barrier Functions (CBFs) and unifying the method of Backup Sets for synthesizing control invariant sets with robustness requirements\u2014the end result is the synthesis of Measurement-Robust Control Barrier Functions (MR-CBFs). This provides theoretical guarantees on safe behavior in the presence of imperfect measurements and improved robustness over standard CBF approaches. We demonstrate the efficacy of this framework both in simulation and experimentally on a Segway platform using an onboard stereo-vision camera for state estimation.",
        "primary_area": "",
        "author": "Ryan K. Cosner;Andrew W. Singletary;Andrew J. Taylor;Tamas G. Molnar;Katherine L. Bouman;Aaron D. Ames;Ryan K. Cosner;Andrew W. Singletary;Andrew J. Taylor;Tamas G. Molnar;Katherine L. Bouman;Aaron D. Ames",
        "authorids": "/37088901068;/37086449553;/37087322409;/38152008100;/37972984900;/37300877900;/37088901068;/37086449553;/37087322409;/38152008100;/37972984900;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636584/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6799443718181578310&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636128",
        "title": "Mechanical Design and Evaluation of a Selectively-actuated MRI-compatible Continuum Neurosurgical Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "The combination of a dexterous continuum robot and magnetic resonance imaging can potentially improve surgical precision and minimize brain manipulation in a minimally invasive neurosurgical procedure. In this work, a seven degree-of-freedom (DoF) continuum neurosurgical robot was developed. The main innovation lies in the design of a safe and robust switching mechanism and gear-based quick-connect mechanism that, respectively, allow selective actuation of the 6-DoF end effector using only three motors and highly efficient end effector exchange. Its performance has been validated in experiments involving multi-segment dexterous motion. We also evaluated the robotic system on a human cadaver head in a clinical 3-Tesla MRI. The entire workflow of robotic system set-up was implemented, confirming its clinical feasibility. The signal-to-noise ratio (SNR) drop was consistently less than 6% throughout various stages of end effector motion.",
        "primary_area": "",
        "author": "Shing Shin Cheng;Xuefeng Wang;Seokhwan Jeong;Matt Kole;Steven Roys;Rao P. Gullapalli;Shing Shin Cheng;Xuefeng Wang;Seokhwan Jeong;Matt Kole;Steven Roys;Rao P. Gullapalli",
        "authorids": "/37085474625;/37086320410;/37087324027;/37089198123;/37089196832;/37542850000;/37085474625;/37086320410;/37087324027;/37089198123;/37089196832;/37542850000",
        "aff": "Department of Mechanical and Automation Engineering and T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; College of Engineering, Peking University, China; Department of Mechanical Engineering, Sogang University, Seoul, Republic of Korea; Department of Neurosurgery, University of Texas Health Science Center at Houston, Houston, Texas, USA; University of Maryland School of Medicine, Baltimore, Maryland, USA; University of Maryland School of Medicine, Baltimore, Maryland, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636128/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13477483816629489552&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;4;4",
        "aff_unique_norm": "Chinese University of Hong Kong;Peking University;Sogang University;University of Texas Health Science Center at Houston;University of Maryland School of Medicine",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;College of Engineering;Department of Mechanical Engineering;Department of Neurosurgery;School of Medicine",
        "aff_unique_url": "https://www.cuhk.edu.hk;http://www.pku.edu.cn;http://www.sogang.ac.kr;https://www.uth.edu;https://som.umaryland.edu",
        "aff_unique_abbr": "CUHK;Peking U;Sogang;UTHealth Houston;UM SOM",
        "aff_campus_unique_index": "0;2;3;4;4",
        "aff_campus_unique": "Hong Kong SAR;;Seoul;Houston;Baltimore",
        "aff_country_unique_index": "0;0;1;2;2;2",
        "aff_country_unique": "China;South Korea;United States"
    },
    {
        "id": "9636629",
        "title": "Mechanical Search on Shelves using Lateral Access X-RAY",
        "track": "main",
        "status": "Poster",
        "abstract": "Finding an occluded object in a lateral access environment such as a shelf or cabinet is a problem that arises in many contexts such as warehouses, retail, healthcare, shipping, and homes. While this problem, known as mechanical search, is well-studied in overhead access environments, lateral access environments introduce constraints on the poses of objects and on available grasp actions, and pushing actions are preferred to preserve the environment structure. We propose LAX-RAY (Lateral Access maXimal Reduction in support Area of occupancY distribution): a system that combines target object occupancy distribution prediction with a mechanical search policy that sequentially pushes occluding objects to reveal a given target object. For scenarios with extruded polygonal objects, we introduce two lateral-access search policies that encode a history of predicted target distributions and can plan up to three actions into the future. We introduce a First-Order Shelf Simulator (FOSS) and use it to evaluate these policies in 800 simulated random shelf environments per policy. We also evaluate in 5 physical shelf environments using a Fetch robot with an embedded PrimeSense RGBD Camera and an attached pushing blade. The policies outperform baselines by up to 25% in simulation and up to 60% in physical experiments. Additionally, the two-step prediction policy is the highest performing in simulation for 8 objects with a 69% success rate, suggesting a tradeoff between future information and prediction errors. Code, videos, and supplementary material can be found at https://sites.google.com/berkeley.edu/lax-ray.",
        "primary_area": "",
        "author": "Huang Huang;Marcus Dominguez-Kuhne;Vishal Satish;Michael Danielczuk;Kate Sanders;Jeffrey Ichnowski;Andrew Lee;Anelia Angelova;Vincent Vanhoucke;Ken Goldberg;Huang Huang;Marcus Dominguez-Kuhne;Vishal Satish;Michael Danielczuk;Kate Sanders;Jeffrey Ichnowski;Andrew Lee;Anelia Angelova;Vincent Vanhoucke;Ken Goldberg",
        "authorids": "/37088985585;/37088686805;/37086692059;/37086541913;/37088083633;/38541287200;/37088732588;/37295407600;/37426058000;/37273026700;/37088985585;/37088686805;/37086692059;/37086541913;/37088083633;/38541287200;/37088732588;/37295407600;/37426058000;/37273026700",
        "aff": "The AUTOLab, University of California, Berkeley; The California Institute of Technology; The AUTOLab, University of California, Berkeley; The AUTOLab, University of California, Berkeley; The AUTOLab, University of California, Berkeley; The AUTOLab, University of California, Berkeley; The AUTOLab, University of California, Berkeley; Robotics at Google; Robotics at Google; The AUTOLab, University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636629/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5064927483125183327&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;0;0;0;0;0;2;2;0",
        "aff_unique_norm": "University of California, Berkeley;California Institute of Technology;Google",
        "aff_unique_dep": "The AUTOLab;;Robotics",
        "aff_unique_url": "https://www.berkeley.edu;https://www.caltech.edu;https://www.google.com",
        "aff_unique_abbr": "UC Berkeley;Caltech;Google Robotics",
        "aff_campus_unique_index": "0;1;0;0;0;0;0;2;2;0",
        "aff_campus_unique": "Berkeley;Pasadena;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636140",
        "title": "Memory-based Deep Reinforcement Learning for POMDPs",
        "track": "main",
        "status": "Poster",
        "abstract": "A promising characteristic of Deep Reinforcement Learning (DRL) is its capability to learn optimal policy in an end-to-end manner without relying on feature engineering. However, most approaches assume a fully observable state space, i.e. fully observable Markov Decision Processes (MDPs). In real-world robotics, this assumption is unpractical, because of issues such as sensor sensitivity limitations and sensor noise, and the lack of knowledge about whether the observation design is complete or not. These scenarios lead to Partially Observable MDPs (POMDPs). In this paper, we propose Long-Short-Term-Memory-based Twin Delayed Deep Deterministic Policy Gradient (LSTM-TD3) by introducing a memory component to TD3, and compare its performance with other DRL algorithms in both MDPs and POMDPs. Our results demonstrate the significant advantages of the memory component in addressing POMDPs, including the ability to handle missing and noisy observation data.",
        "primary_area": "",
        "author": "Lingheng Meng;Rob Gorbet;Dana Kuli\u0107;Lingheng Meng;Rob Gorbet;Dana Kuli\u0107",
        "authorids": "/37088853468;/37355760600;/37547876700;/37088853468;/37355760600;/37547876700",
        "aff": "Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Departments of Knowledge Integration and Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Faculty of Engineering, Monash University, Melbourne, Victoria, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636140/",
        "gs_citation": 133,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3493725812485131391&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Waterloo;Monash University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Faculty of Engineering",
        "aff_unique_url": "https://uwaterloo.ca;https://www.monash.edu",
        "aff_unique_abbr": "UW;Monash",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Waterloo;Melbourne",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Canada;Australia"
    },
    {
        "id": "9636620",
        "title": "Memory-based Semantic Segmentation for Off-road Unstructured Natural Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "With the availability of many datasets tailored for autonomous driving in real-world urban scenes, semantic segmentation for urban driving scenes achieves significant progress. However, semantic segmentation for off-road, unstructured environments is not widely studied. Directly applying existing segmentation networks often results in performance degradation as they cannot overcome intrinsic problems in such environments, such as illumination changes. In this paper, a built-in memory module for semantic segmentation is proposed to overcome these problems. The memory module stores significant representations of training images as memory items. In addition to the encoder embedding like items together, the proposed memory module is specifically designed to cluster together instances of the same class even when there are significant variances in embedded features. Therefore, it makes segmentation networks better deal with unexpected illumination changes. A triplet loss is used in training to minimize redundancy in storing discriminative representations of the memory module. The proposed memory module is general so that it can be adopted in a variety of networks. We conduct experiments on the Robot Unstructured Ground Driving (RUGD) dataset and RELLIS dataset, which are collected from off-road, unstructured natural environments. Experimental results show that the proposed memory module improves the performance of existing segmentation networks and contributes to capturing unclear objects over various off-road, unstructured natural scenes with equivalent computational cost and network parameters. As the proposed method can be integrated into compact networks, it presents a viable approach for resource-limited small autonomous platforms.",
        "primary_area": "",
        "author": "Youngsaeng Jin;David Han;Hanseok Ko;Youngsaeng Jin;David Han;Hanseok Ko",
        "authorids": "/37086915316;/37588964400;/37275585000;/37086915316;/37588964400;/37275585000",
        "aff": "School of Electrical Engineering, Korea University, Seoul, South Korea; Electrical and Computer Engineering, Drexel University, Philadelphia, PA; School of Electrical Engineering, Korea University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636620/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8095271223826930515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Korea University;Drexel University",
        "aff_unique_dep": "School of Electrical Engineering;Electrical and Computer Engineering",
        "aff_unique_url": "http://www.korea.ac.kr;https://drexel.edu",
        "aff_unique_abbr": "KU;Drexel",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Seoul;Philadelphia",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "9636515",
        "title": "Meta Preference Learning for Fast User Adaptation in Human-Supervisory Multi-Robot Deployments",
        "track": "main",
        "status": "Poster",
        "abstract": "As multi-robot systems (MRS) are widely used in various tasks such as natural disaster response and social security, people enthusiastically expect an MRS to be ubiquitous that a general user without heavy training can easily operate. However, humans have various preferences on balancing between task performance and safety, imposing different requirements onto MRS control. Failing to comply with preferences makes people feel difficult in operation and decreases human willingness of using an MRS. Therefore, to improve social acceptance as well as performance, there is an urgent need to adjust MRS behaviors according to human preferences before triggering human corrections, which increases cognitive load. In this paper, a novel Meta Preference Learning (MPL) method was developed to enable an MRS to fast adapt to user preferences. MPL based on meta learning mechanism can quickly assess human preferences from limited instructions; then, a neural network based preference model adjusts MRS behaviors for preference adaption. To validate method effectiveness, a task scenario \"An MRS searches victims in an earthquake disaster site\" was designed; 20 human users were involved to identify preferences as {\"aggressive\", \"medium\", \"reserved\"}; based on user guidance and domain knowledge, about 20,000 preferences were simulated to cover different operations related to {\"task quality\", \"task progress\", \"robot safety\"}. The effectiveness of MPL in preference adaption was validated by the reduced duration and frequency of human interventions.",
        "primary_area": "",
        "author": "Chao Huang;Wenhao Luo;Rui Liu;Chao Huang;Wenhao Luo;Rui Liu",
        "authorids": "/37088947285;/37085748889;/37087237782;/37088947285;/37085748889;/37087237782",
        "aff": "Cognitive Robotics and AI Lab (CRAI), College of Aeronautics and Engineering, Kent State University, Kent, OH, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Cognitive Robotics and AI Lab (CRAI), College of Aeronautics and Engineering, Kent State University, Kent, OH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636515/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4249795286833781995&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Kent State University;Carnegie Mellon University",
        "aff_unique_dep": "College of Aeronautics and Engineering;Robotics Institute",
        "aff_unique_url": "https://www.kent.edu;https://www.cmu.edu",
        "aff_unique_abbr": "KSU;CMU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Kent;Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635840",
        "title": "Meta-Learning for Fast Adaptive Locomotion with Uncertainties in Environments and Robot Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "This work developed meta-learning control policies to achieve fast online adaptation to different changing conditions, which generate diverse and robust locomotion. The proposed method updates the interaction model constantly, samples feasible sequences of actions of estimated state-action trajectories, and then applies the optimal actions to maximize the reward. To achieve online model adaptation, our proposed method learns different latent vectors of each training condition, which is selected online based on newly collected data from the past 10 samples within 0.2s. Our work designs appropriate state space and reward functions, and optimizes feasible actions in an MPC fashion which are sampled directly in the joint space with constraints, hence requiring no prior design or training of specific gaits. We further demonstrated the robot\u2019s capability of detecting unexpected changes during the interaction and adapting the control policy in less than 0.2s. The extensive validation on the SpotMicro robot in a physics simulation shows adaptive and robust locomotion skills under changing ground friction, external pushes, and different robot dynamics including motor failures and the whole leg amputation.",
        "primary_area": "",
        "author": "Timoth\u00e9e Anne;Jack Wilkinson;Zhibin Li;Timoth\u00e9e Anne;Jack Wilkinson;Zhibin Li",
        "authorids": "/37088691039;/37089195437;/37857029500;/37088691039;/37089195437;/37857029500",
        "aff": "ENS, Rennes, France; School of Informatics, the University of Edinburgh, UK; School of Informatics, the University of Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635840/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16245414194601791349&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "\u00c9cole Normale Sup\u00e9rieure;University of Edinburgh",
        "aff_unique_dep": ";School of Informatics",
        "aff_unique_url": "https://www.ens-rennes.fr;https://www.ed.ac.uk",
        "aff_unique_abbr": "ENS;Edinburgh",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Rennes;Edinburgh",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "France;United Kingdom"
    },
    {
        "id": "9636686",
        "title": "Method for the Determination of Relative Joint Axes for Wearable Inertial Sensor Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Wearable IMU sensing systems have widely been used in the study of human motion. For example, gait analysis using wearable inertial sensor systems is a tool used by clinicians to discriminate between typical and pathological walking. Similarly, key descriptors can be identified in spontaneous kicking to distinguish between typical and atypical motor development in infants. Oftentimes in human applications, precise placement of inertial sensors is difficult due to the irregular shape of human limbs. Without precise placement and alignment of the inertial sensors, meaningful joint kinematic data are difficult to extract as the orientation of the joint axes are unknown in the sensor's local frame. So, for applications where precise alignment may not be possible, a necessary first step is to identify the joint axes with respect to the local frame.In this work, we propose a method for the identification of joint axes for multiple degree of freedom (multi-DOF) joints in a kinematic chain using acceleration and angular rate data. This method couples a thresholding activity detection algorithm with a principal component analysis (PCA) dimensionality reduction technique. Furthermore, this method is validated on mimicked kicking data from a NAO robot. This method can determine joint axes of a kinematic chain from simultaneous movement data within an error ratio of 0.09.",
        "primary_area": "",
        "author": "Katelyn E. Fry;Yu-Ping Chen;Ayanna Howard;Katelyn E. Fry;Yu-Ping Chen;Ayanna Howard",
        "authorids": "/37085503812;/37085572732;/37290423600;/37085503812;/37085572732;/37290423600",
        "aff": "Katelyn E. Fry; Yu-Ping Chen; Ayanna Howard",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636686/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8212899611394329505&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9636229",
        "title": "Microspine-rubber composite for high friction on smooth, rough, and wet surfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "As robotic technologies advance and robots move out of factories and labs into the real world, grip on a variety of surfaces (e.g. smooth or rough) in a variety of conditions (e.g. dry or wet) becomes increasingly important. Bioinspired \"microspines\" have been previously explored, but primarily for vertical climbing applications or for small-scale robots applying low forces (less than 1 N). Further, these works primarily focused on rough surfaces. To advance this area of research, we present a composite material comprising high- friction rubber and compliant nitinol microspines which can passively retract below the surface of the rubber. We show that the composite can support large loads (greater than 75 N) with a high coefficient of friction on both smooth and rough surfaces (p > 1.1), outperforming microspines alone on smooth surfaces and rubber alone on rough surfaces, especially when wet and oily. Further, due to the retraction of the microspines, the composite does not damage relatively soft, smooth surfaces, like wood flooring. We also test durability, and show that it is improved by microspine compliance, and test the effects of varying microspine diameter, angle, and tip shape. Finally, we demonstrate that a small RC car can climb steeper slopes and stop more quickly in wet conditions with microspines.",
        "primary_area": "",
        "author": "Constance C. Berdan;Bryan G. Johnson;Elliot W. Hawkes;Constance C. Berdan;Bryan G. Johnson;Elliot W. Hawkes",
        "authorids": "/37089195630;/37089196264;/37681388800;/37089195630;/37089196264;/37681388800",
        "aff": "Department of Mechanical Engineering, University of California, Santa Barbara, CA; Abbott Vascular, Temecula, CA; Department of Mechanical Engineering, University of California, Santa Barbara, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636229/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9394416315281984301&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Santa Barbara;Abbott Vascular",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.ucsb.edu;https://www.abbottvascular.com",
        "aff_unique_abbr": "UCSB;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Santa Barbara;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636079",
        "title": "Mind Control of a Service Robot with Visual Servoing",
        "track": "main",
        "status": "Poster",
        "abstract": "In the growing elderly population globally, patients with severe movement disorders account for a large proportion. Moreover, the development of intelligent service equipment can better assist them in their daily. This paper proposes a new service robot control system. The brain-computer interface (BCI) based on Steady-State Visual Evoked Potentials (SSVEP) is used to acquire and process electroencephalogram(EEG) signals and output various control commands accordingly. Then, considering the visual fatigue of SSVEP-BCI, we added an object detection method based on Yolov3-tiny and saliency prediction to identify the patient\u2019s selection intention intelligently. The results show that the subject can successfully complete the object delivery task with an average accuracy of 90.3%. The proposed control system can help the patients control a service robot in a more intelligent and friendly way to realize some daily tasks.",
        "primary_area": "",
        "author": "Lina Zhang;Zhe Sun;Feng Duan;Chi Zhu;Hiroshi Yokoi;Lina Zhang;Zhe Sun;Feng Duan;Chi Zhu;Hiroshi Yokoi",
        "authorids": "/37089195788;/37086638406;/38295033800;/37289715600;/37285419100;/37089195788;/37086638406;/38295033800;/37289715600;/37285419100",
        "aff": "Department of College of Artificial Intelligence, Nankai University, Tianjin, China; Department of Computational Engineering Applications Unit, Head Office for Information Systems and Cybersecurity, RIKEN, Saitama, Japan; Department of College of Artificial Intelligence, Nankai University, Tianjin, China; Department of System Life Engineering, Maebashi Institute of Technology, Maebashi, Japan; Department of Mechanics and Intelligence, The University of Electro-Communications, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636079/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2216101700878673570&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;3",
        "aff_unique_norm": "Nankai University;RIKEN;Maebashi Institute of Technology;University of Electro-Communications",
        "aff_unique_dep": "College of Artificial Intelligence;Department of Computational Engineering Applications Unit, Head Office for Information Systems and Cybersecurity;Department of System Life Engineering;Department of Mechanics and Intelligence",
        "aff_unique_url": "http://www.nankai.edu.cn;https://www.riken.jp;;https://www.uec.ac.jp",
        "aff_unique_abbr": "Nankai;RIKEN;;UEC",
        "aff_campus_unique_index": "0;1;0;2;3",
        "aff_campus_unique": "Tianjin;Saitama;Maebashi;Tokyo",
        "aff_country_unique_index": "0;1;0;1;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9636847",
        "title": "Minimizing Safety Interference for Safe and Comfortable Automated Driving with Distributional Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite recent advances in reinforcement learning (RL), its application in safety critical domains like autonomous vehicles is still challenging. Although penalizing RL agents for risky situations can help to learn safe policies, it may also lead to highly conservative behavior. In this paper, we propose a distributional RL framework in order to learn adaptive policies which allow to tune their level of conservativity at run-time based on the desired comfort and utility. Using a proactive safety verification approach, the proposed framework can guarantee that actions generated from RL are failsafe according to the worst-case assumptions. Concurrently, the policy is encouraged to minimize safety interference and generate more comfortable behavior. We trained and evaluated the proposed approach and baseline policies using a high level simulator with a variety of randomized scenarios including several corner cases which rarely happen in reality but are very crucial. In light of our experiments, the behavior of policies learned using distributional RL is adaptive at run-time and robust to the environment uncertainty. Quantitatively, the learned distributional RL agent reduces the average driving time more than 50% compared to the normal DQN policy. It also requires 83% less safety interference compared to the rule-based policy while only slightly increasing the average driving time. We also study sensitivity of the learned policy in environments with higher perception noise and show that our algorithm learns policies that can still drive reliable when the perception noise is two times higher than in the training configuration in automated merging and crossing at occluded intersections.",
        "primary_area": "",
        "author": "Danial Kamran;Tizian Engelgeh;Marvin Busch;Johannes Fischer;Christoph Stiller;Danial Kamran;Tizian Engelgeh;Marvin Busch;Johannes Fischer;Christoph Stiller",
        "authorids": "/37085746321;/37089194525;/37089194080;/37089195294;/37284652100;/37085746321;/37089194525;/37089194080;/37089195294;/37284652100",
        "aff": "Institute of Measurement and Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Institute of Measurement and Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Institute of Measurement and Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636847/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7602554252731509207&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute of Measurement and Control Systems",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636114",
        "title": "Mobile 3D Printing Robot Simulation with Viscoelastic Fluids",
        "track": "main",
        "status": "Poster",
        "abstract": "The system design and algorithm development of mobile 3D printing robots need a realistic simulation. They require a mobile robot simulation platform to interoperate with a physics-based material simulation for handling interactions between the time-variant deformable 3D printing materials and other simulated rigid bodies in the environment, which is not available for roboticists yet. To bridge this gap and enable the real-time simulation of mobile 3D printing processes, we develop a simulation framework that includes particle-based viscoelastic fluid simulation and particle-to-mesh conversion in the widely adopted Gazebo robotics simulator, avoiding the bottlenecks of traditional additive manufacturing simulation approaches. This framework is the first of its kind that enables the simulation of robot arms or mobile manipulators together with viscoelastic fluids. The method is tested using various material properties and multiple collaborating robots to demonstrate its simulation ability for the robots to plan and control the printhead trajectories and to visually sense at the same time the printed fluid materials as a free-form mesh. The scalability as a function of available material particles in the simulation was also studied. A simulation with an average of 5 FPS was achieved on a regular desktop computer.",
        "primary_area": "",
        "author": "Uljad Berdica;Yuewei Fu;Yuchen Liu;Emmanouil Angelidis;Chen Feng;Uljad Berdica;Yuewei Fu;Yuchen Liu;Emmanouil Angelidis;Chen Feng",
        "authorids": "/37089194330;/37089194890;/149273849162738;/37088825719;/37086391326;/37089194330;/37089194890;/149273849162738;/37088825719;/37086391326",
        "aff": "New York University, Abu Dhabi, NY, UAE; New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636114/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6702927750397389797&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Abu Dhabi;Brooklyn",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "United Arab Emirates;United States"
    },
    {
        "id": "9636178",
        "title": "Mobile Manipulation\u2013based Deployment of Micro Aerial Robot Scouts through Constricted Aperture-like Ingress Points",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel strategy for the autonomous deployment of Micro Aerial Vehicle scouts through constricted aperture-like ingress points, by narrowly fitting and launching them with a high-precision Mobile Manipulation robot. A significant problem during exploration and reconnaissance into highly unstructured environments, such as indoor collapsed ones, is the encountering of impassable areas due to their constricted and rigid nature. We propose that a heterogeneous robotic system-of-systems armed with manipulation capabilities while also ferrying a fleet of microsized aerial agents, can deploy the latter through constricted apertures that marginally fit them in size, thus allowing them to act as scouts and resume the reconnaissance mission. This work\u2019s contribution is twofold: first, it proposes active-vision based aperture detection to locate candidate ingress points and a hierarchical search-based aperture profile analysis to position a MAV\u2019s body through them, and secondly it presents and experimentally demonstrates the novelty of a system-of-systems approach which leverages mobile manipulation to deploy other robots which are otherwise incapable of entering through extremely narrow openings.",
        "primary_area": "",
        "author": "Prateek Arora;Christos Papachristos;Prateek Arora;Christos Papachristos",
        "authorids": "/37085797792;/37681703400;/37085797792;/37681703400",
        "aff": "Robotic Workers (RoboWork) Lab, University of Nevada, Reno, NV, USA; Robotic Workers (RoboWork) Lab, University of Nevada, Reno, NV, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636178/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8682658335685870495&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Nevada, Reno",
        "aff_unique_dep": "Robotic Workers (RoboWork) Lab",
        "aff_unique_url": "https://www.unr.edu",
        "aff_unique_abbr": "UNR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Reno",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636078",
        "title": "Mobile Recharger Path Planning and Recharge Scheduling in a Multi-Robot Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "In many multi-robot applications, mobile worker robots are often engaged in performing some tasks repetitively by following pre-computed trajectories. As these robots are battery-powered, they need to get recharged at regular intervals. We envision that, in the future, a few mobile recharger robots will be employed to supply charge to the energy-deficient worker robots recurrently to keep the overall efficiency of the system optimized. In this setup, we need to find the time instants and locations for the meeting of the worker robots and recharger robots optimally. We present a Satisfiability Modulo Theory (SMT)-based approach that captures the activities of the robots in the form of constraints in a sufficiently long finite-length time window (hypercycle) whose repetitions provide their perpetual behavior. Our SMT encoding ensures that for a chosen length of the hypercycle, the total waiting time of the worker robots due to charge constraints is minimized under certain condition, and close to optimal when the condition does not hold. Moreover, the recharger robots follow the most energy-efficient trajectories. We show the efficacy of our approach by comparing it with another variant of the SMT-based method which is not scalable but provides an optimal solution globally, and with a greedy algorithm.",
        "primary_area": "",
        "author": "Tanmoy Kundu;Indranil Saha;Tanmoy Kundu;Indranil Saha",
        "authorids": "/37086455111;/37542496500;/37086455111;/37542496500",
        "aff": "Department of Computer Science and Engineering, Indian Institute of Technology Kanpur; Department of Computer Science and Engineering, Indian Institute of Technology Kanpur",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636078/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3389014604877503348&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Technology Kanpur",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.iitk.ac.in",
        "aff_unique_abbr": "IIT Kanpur",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kanpur",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9636367",
        "title": "Mobile Robot Yielding Cues for Human-Robot Spatial Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile robots are increasingly being deployed in public spaces such as shopping malls, airports, and urban sidewalks. Most of these robots are designed with human-aware motion planning capabilities but are not designed to communicate with pedestrians. Pedestrians encounter these robots without prior understanding of the robots\u2019 behaviour, which can cause discomfort, confusion, and delayed social acceptance. In this research, we explore the common human-robot interaction at a doorway or bottleneck in a structured environment. We designed and evaluated communication cues used by a robot when yielding to a pedestrian in this scenario. We conducted an online user study with 102 participants using videos of a set of robot-to-human yielding cues. Results show that a Robot Retreating cue was the most socially acceptable cue. Repeated measures and Friedman\u2019s ANOVAs on components of social acceptability were statistically significant (p = .01) and had small and medium effect sizes (\u03b7p2 = .04, \u03b7p2 = .08). The results of this work help guide the development of mobile robots for public spaces.",
        "primary_area": "",
        "author": "Nicholas J. Hetherington;Ryan Lee;Marlene Haase;Elizabeth A. Croft;H. F. Machiel Van der Loos;Nicholas J. Hetherington;Ryan Lee;Marlene Haase;Elizabeth A. Croft;H. F. Machiel Van der Loos",
        "authorids": "/37086937954;/37089196662;/37089196768;/37283199500;/37085374287;/37086937954;/37089196662;/37089196768;/37283199500;/37085374287",
        "aff": "Department of Mechanical Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Mechanical Engineering, University of British Columbia, Vancouver, BC, Canada; Human Factors Engineering, Technical University of Munich, BY, Germany; Departments of Mechanical and Aerospace Engineering and Electrical and Computer Systems Engineering, Monash University, Melbourne, VIC, Australia; Department of Mechanical Engineering, University of British Columbia, Vancouver, BC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636367/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5240206487203209503&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "University of British Columbia;Technical University of Munich;Monash University",
        "aff_unique_dep": "Department of Mechanical Engineering;Human Factors Engineering;Departments of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ubc.ca;https://www.tum.de;https://www.monash.edu",
        "aff_unique_abbr": "UBC;TUM;Monash",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Vancouver;Munich;Melbourne",
        "aff_country_unique_index": "0;0;1;2;0",
        "aff_country_unique": "Canada;Germany;Australia"
    },
    {
        "id": "9636838",
        "title": "Mobile Teleoperation: Feasibility of Wireless Wearable Sensing of the Operator\u2019s Arm Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "Teleoperation platforms often require the user to be situated at a fixed location to both visualize and control the movement of the robot and thus do not provide the operator with much mobility. One example is in existing robotic surgery solutions that require the surgeons to be away from the patient, attached to consoles where their heads must be fixed and their arms can only move in a limited space. This creates a barrier between physicians and patients that does not exist in normal surgery. To address this issue, we propose a mobile telesurgery solution where the surgeons are no longer mechanically limited to control consoles and are able to teleoperate the robots from the patient bedside, using their arms equipped with wireless sensors and viewing the endoscope video via optical see-through head-mounted displays (HMDs). We evaluate the feasibility and efficiency of our user interaction method compared to a standard surgical robotic manipulator via two tasks with different levels of required dexterity. The results indicate that with sufficient training our proposed platform can attain similar efficiency while providing added mobility for the operator.",
        "primary_area": "",
        "author": "Guanhao Fu;Ehsan Azimi;Peter Kazanzides;Guanhao Fu;Ehsan Azimi;Peter Kazanzides",
        "authorids": "/37089193987;/37680228800;/37375173500;/37089193987;/37680228800;/37375173500",
        "aff": "Dept. of Mechanical Engineering, Johns Hopkins University, Baltimore, USA; Dept. of Computer Science, Johns Hopkins University, Baltimore, USA; Dept. of Computer Science, Johns Hopkins University, Baltimore, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636838/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15370151008678077631&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636206",
        "title": "Model Adaptation through Hypothesis Transfer with Gradual Knowledge Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to adapt their perception to changing environments is a core characterization of intelligent robots. At present, Unsupervised Domain Adaptation (UDA) methods are used to address this problem where the adaptation task is formulated as a transfer problem from a well-described scenario (source domain) to a new scenario (target domain). In order to implement the domain adaptation, these methods require access to the source data for achieving the distribution matching between both domains. However, in many real-world applications, the source data is inaccessible and only a source model pre-trained on the source domain is available during the transfer process. Therefore, the traditional UDA methods cannot support the challenging setting. This paper developed a new hypothesis transfer method to achieve model adaptation with gradual knowledge distillation. Specifically, we first prepare a source model through training a deep network on the labeled source domain by supervised learning. Then, we transfer the source model to the unlabeled target domain by self-training. To implement gradual knowledge distillation, we sliced the self-training into several epochs and then used the soft pseudo-labels from the latest epoch to guide the current epoch. In this process, the soft labels were generated by a semantic fusion on a proposed geometry of the neighborhood. To regulate the self-training, we developed a new objective constructed on the neighborhood. Experiments on three benchmarks have confirmed the state-of-the-art results of our method.",
        "primary_area": "",
        "author": "Song Tang;Yuji Shi;Zhiyuan Ma;Jian Li;Jianzhi Lyu;Qingdu Li;Jianwei Zhang;Song Tang;Yuji Shi;Zhiyuan Ma;Jian Li;Jianzhi Lyu;Qingdu Li;Jianwei Zhang",
        "authorids": "/37087324926;/37089196628;/37089195654;/37089197303;/37087323631;/37089197601;/37281460600;/37087324926;/37089196628;/37089195654;/37089197303;/37087323631;/37089197601;/37281460600",
        "aff": "Department of Informatics, TAMS Group, University of Hamburg, Hamburg, Germany; Department of Informatics, TAMS Group, University of Hamburg, Hamburg, Germany; Department of Informatics, TAMS Group, University of Hamburg, Hamburg, Germany; College of Intelligence Science and Technology, National University of Defense Technology, Changsha, China; Department of Informatics, TAMS Group, University of Hamburg, Hamburg, Germany; Department of Informatics, TAMS Group, University of Hamburg, Hamburg, Germany; Department of Informatics, TAMS Group, University of Hamburg, Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636206/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4710151422345198774&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;0;0",
        "aff_unique_norm": "University of Hamburg;National University of Defense Technology",
        "aff_unique_dep": "Department of Informatics;College of Intelligence Science and Technology",
        "aff_unique_url": "https://www.uni-hamburg.de;",
        "aff_unique_abbr": "UHH;",
        "aff_campus_unique_index": "0;0;0;1;0;0;0",
        "aff_campus_unique": "Hamburg;Changsha",
        "aff_country_unique_index": "0;0;0;1;0;0;0",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "9636000",
        "title": "Model-Based Trajectory Prediction and Hitting Velocity Control for a New Table Tennis Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Currently, most table tennis robots concentrate on the canonical position control problem while ignoring the actual velocity control requirements. In this paper, we consider these requirements and propose a new table tennis robot framework. First, a tailor-made mechanical structure is designed such that the robot can reach large workspaces. Thereafter, in the table tennis trajectory prediction process, a clustering algorithm is introduced to screen the heterogeneous predicted hitting points and filter the invalid ones, thereby significantly improving the prediction accuracy. By using quintic polynomial trajectory planning, smooth and stable high-speed control of the robot hitting motion can be obtained. Finally, a position-based strategy and a velocity-based strategy are devised for returning the table tennis. Extensive experiments demonstrate that the accuracy of the ball's trajectory prediction algorithm is more than 92%. The success rate of returning the ball exceeds 95% at the ball velocity of 3-7 m/s, and the velocity-based strategy performs better compared with the position-based approach at the ball velocity of 7-9 m/s.",
        "primary_area": "",
        "author": "Yunfeng Ji;Xiaoyi Hu;Yutao Chen;Yue Mao;Gang Wang;Qingdu Li;Jianwei Zhang;Yunfeng Ji;Xiaoyi Hu;Yutao Chen;Yue Mao;Gang Wang;Qingdu Li;Jianwei Zhang",
        "authorids": "/37087324684;/37089196818;/37088646255;/37089195981;/37089613641;/37089197601;/37281460600;/37087324684;/37089196818;/37088646255;/37089195981;/37089613641;/37089197601;/37281460600",
        "aff": "Institute of Machine Intelligence; Institute of Machine Intelligence; School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, China; Institute of Machine Intelligence; Institute of Machine Intelligence; Institute of Machine Intelligence; Department of Informatics, University of Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636000/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17911907989678843213&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;0;2",
        "aff_unique_norm": "Institute of Machine Intelligence;University of Shanghai for Science and Technology;University of Hamburg",
        "aff_unique_dep": ";School of Optical-Electrical and Computer Engineering;Department of Informatics",
        "aff_unique_url": ";https://www.usst.edu.cn;https://www.uni-hamburg.de",
        "aff_unique_abbr": ";USST;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shanghai",
        "aff_country_unique_index": "1;2",
        "aff_country_unique": ";China;Germany"
    },
    {
        "id": "9636468",
        "title": "Model-based Constrained Reinforcement Learning using Generalized Control Barrier Function",
        "track": "main",
        "status": "Poster",
        "abstract": "Model information can be used to predict future trajectories, so it has huge potential to avoid dangerous regions when applying reinforcement learning (RL) on real-world tasks, like autonomous driving. However, existing studies mostly use model-free constrained RL, which causes inevitable constraint violations. This paper proposes a model-based feasibility enhancement technique of constrained RL, which enhances the feasibility of policy using generalized control barrier function (GCBF) defined on the distance to constraint boundary. By using the model information, the policy can be optimized safely without violating actual safety constraints, and the sample efficiency is increased. The infeasibility in solving the constrained policy gradient is handled by an adaptive coefficient mechanism. We evaluate the proposed method in both simulations and real vehicle experiments in a complex autonomous driving collision avoidance task. The proposed method achieves up to four times fewer constraint violations and converges 3.36 times faster than baseline constrained RL approaches.",
        "primary_area": "",
        "author": "Haitong Ma;Jianyu Chen;Shengbo Eben;Ziyu Lin;Yang Guan;Yangang Ren;Sifa Zheng;Haitong Ma;Jianyu Chen;Shengbo Eben;Ziyu Lin;Yang Guan;Yangang Ren;Sifa Zheng",
        "authorids": "/37088573386;/37086004703;/37089195930;/37088400942;/37088555204;/37088554692;/37086475843;/37088573386;/37086004703;/37089195930;/37088400942;/37088555204;/37088554692;/37086475843",
        "aff": "School of Vehicle and Mobility, Tsinghua University; Shanghai Qizhi Institute; School of Vehicle and Mobility, Tsinghua University; School of Vehicle and Mobility, Tsinghua University; School of Vehicle and Mobility, Tsinghua University; School of Vehicle and Mobility, Tsinghua University; School of Vehicle and Mobility, Tsinghua University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636468/",
        "gs_citation": 86,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16900428962678886116&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University;Shanghai Qizhi Institute",
        "aff_unique_dep": "School of Vehicle and Mobility;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.qizhi-institute.org",
        "aff_unique_abbr": "Tsinghua;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636202",
        "title": "Model-free Vehicle Tracking and State Estimation in Point Cloud Sequences",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating the states of surrounding traffic participants stays at the core of autonomous driving. In this paper, we study a novel setting of this problem: model-free single-object tracking (SOT), which takes the object state in the first frame as input, and jointly solves state estimation and tracking in subsequent frames. The main purpose for this new setting is to break the strong limitation of the popular \"detection and tracking\" scheme in multi-object tracking. Moreover, we notice that shape completion by overlaying the point clouds, which is a by-product of our proposed task, not only improves the performance of state estimation but also has numerous applications. As no benchmark for this task is available so far, we construct a new dataset LiDAR-SOT and corresponding evaluation protocols based on the Waymo Open dataset [29]. We then propose an optimization-based algorithm called SOTracker involving point cloud registration, vehicle shapes, correspondence, and motion priors. Our quantitative and qualitative results prove the effectiveness of our SOTracker and reveal the challenging cases for SOT in point clouds, including the sparsity of LiDAR data, abrupt motion variation, etc. Finally, we also explore how the proposed task and algorithm may benefit other autonomous driving applications, including simulating LiDAR scans, generating motion data, and annotating optical flow. The code and protocols for our benchmark and algorithm are available at https://github.com/TuSimple/LiDAR_SOT/. A video demonstration is at https://www.youtube.com/watch?v=BpHixKs91i8.",
        "primary_area": "",
        "author": "Ziqi Pang;Zhichao Li;Naiyan Wang;Ziqi Pang;Zhichao Li;Naiyan Wang",
        "authorids": "/37088954343;/37088691225;/37085671305;/37088954343;/37088691225;/37085671305",
        "aff": "TuSimple; TuSimple; TuSimple",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636202/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2607747532688868849&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "TuSimple",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tusimple.com",
        "aff_unique_abbr": "TuSimple",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636633",
        "title": "Modeling and Analysis of Tensegrity Robot for Passive Dynamic Walking",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a planar tensegrity robot that walks passively and cyclically on a gentle downhill, where its gait versatility can be strengthened by applying actuation forces on the connection cables. The novelty of this work is that we design the structure of this passive robot inspired by the rimless wheel, which naturally generates cyclic locomotion. Consequently, its mathematical model is analytically derived based on passive dynamic walking. Besides, the limb support conditions and dynamics effects induced by the collisions can be precisely determined accordingly. Moreover, numerical simulation is performed to show the typical gait pattern, and resonance phenomenon is observed. Finally, a preliminary experimental study is conducted to prove the validity of the mathematical model. The robot we developed and the mathematical model we derived enable further extensions on the gait analysis and model-based control by conveniently adopting efficient passivemimic walking techniques.",
        "primary_area": "",
        "author": "Yanqiu Zheng;Longchuan Li;Fumihiko Asano;Cong Yan;Xindi Zhao;Haosong Chen;Yanqiu Zheng;Longchuan Li;Fumihiko Asano;Cong Yan;Xindi Zhao;Haosong Chen",
        "authorids": "/37086076012;/37086240920;/37278753600;/37087242941;/37089197311;/37089197996;/37086076012;/37086240920;/37278753600;/37087242941;/37089197311;/37089197996",
        "aff": "School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; Department of Mechanical Engineering, Ritsumeikan University, Shiga, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636633/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17431596921664521249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Japan Advanced Institute of Science and Technology;Ritsumeikan University",
        "aff_unique_dep": "School of Information Science;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jaist.ac.jp;https://www.ritsumeikan.ac.jp",
        "aff_unique_abbr": "JAIST;Ritsumeikan",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Ishikawa;Shiga",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9635841",
        "title": "Modeling and Control of PANTHERA Self-Reconfigurable Pavement Sweeping Robot under Actuator Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "The focus of this paper is (i) to derive a suitable dynamic model for a self-reconfigurable pavement sweeping robot PANTHERA and (ii) to design a robust controller for the same to tackle uncertainties stemming from the reconfiguration process, external disturbances and from actuator saturation. To meet the first objective, an Euler-Lagrangian dynamic model is proposed to incorporate the effects of configuration changes on the system dynamics. Based on this model, the second objective is met via designing a singular perturbation based robust controller which can tackle the aforementioned uncertainties without violating the actuation limits. To circumvent the vulnerability toward actuator saturation, the proposed controller is built on contraction theory, which, compared to a conventional Lyapunov theory based design, allows to improve closed-loop tracking performance without reducing the singular perturbation parameter. Experimental results on the PANTHERA reconfigurable robot validate the effectiveness of the proposed controller over the state of the art.",
        "primary_area": "",
        "author": "Madan Mohan Rayguru;M. R. Elara;A. A. Hayat;B. Ramalingam;Spandan Roy;Madan Mohan Rayguru;M. R. Elara;A. A. Hayat;B. Ramalingam;Spandan Roy",
        "authorids": "/37085753898;/37546093700;/37085563101;/37088490181;/37085547823;/37085753898;/37546093700;/37085563101;/37088490181;/37085547823",
        "aff": "Department of Electrical Engineering, Delhi Technological University, Delhi, India; Department of Electrical Engineering, Delhi Technological University, Delhi, India; Department of Electrical Engineering, Delhi Technological University, Delhi, India; Department of Electrical Engineering, Delhi Technological University, Delhi, India; Engineering Product Development Pillar in Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635841/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2957339192808950873&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Delhi Technological University;Singapore University of Technology and Design",
        "aff_unique_dep": "Department of Electrical Engineering;Engineering Product Development Pillar",
        "aff_unique_url": "https://www.dtu.ac.in;https://www.sutd.edu.sg",
        "aff_unique_abbr": "DTU;SUTD",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Delhi;Singapore",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "India;Singapore"
    },
    {
        "id": "9636606",
        "title": "Modeling and Trajectory Optimization for Standing Long Jumping of a Quadruped with A Preloaded Elastic Prismatic Spine",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel methodology to model and optimize trajectories of a quadrupedal robot with spinal compliance to improve standing jump performance compared to quadrupeds with a rigid spine. We introduce an elastic model for a prismatic robotic spine that is actively preloaded and mechanically lock-enabled at initial and maximum length, and develop a constrained trajectory optimization method to cooptimize the elastic parameters and motion trajectories toward enhanced jumping distance. Results reveal that a less stiff spring is likely to facilitate jumping performance not as a direct propelling source but as a means to unleash more motor power for propelling by trading-off overall energy efficiency. We also visualize the impact of spring coefficients on the overall optimization routine from energetic perspectives to identify the suitable parameter region.",
        "primary_area": "",
        "author": "Keran Ye;Konstantinos Karydis;Keran Ye;Konstantinos Karydis",
        "authorids": "/37088987345;/38252121900;/37088987345;/38252121900",
        "aff": "Dept. of Electrical and Computer Engineering, University of California, Riverside; Dept. of Electrical and Computer Engineering, University of California, Riverside",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636606/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15036981549131927514&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Riverside",
        "aff_unique_dep": "Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucr.edu",
        "aff_unique_abbr": "UCR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Riverside",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636693",
        "title": "Modeling of Bilayer Hydrogel Springs for Microrobots with Adaptive Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Adaptive locomotion of microrobots can be achieved by using a smart polymer such as a hydrogel. For hydrogel-based bilayer helical microrobots, the change of environment such as temperature and pH can result in shape deformation into helical shapes differing from their initial state and hence swimming performance. In this work, we proposed a model for studying the parameters that affect the shape deformation of a hydrogel-based bilayer helical microrobot. Moreover, the dynamics of some examples of responsive helical swimming are compared before and after stimulation.",
        "primary_area": "",
        "author": "Liyuan Tan;David J. Cappelleri;Liyuan Tan;David J. Cappelleri",
        "authorids": "/37089197535;/37568757700;/37089197535;/37568757700",
        "aff": "School of Mechanical Engineering, Purdue University, West Lafayette, IN, USA; Faculty of Mechanical Engineering, Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636693/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18330550625422779088&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635853",
        "title": "Modular Pipe Climber III with Three-Output Open Differential",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper introduces the novel Modular Pipe Climber III with a Three-Output Open Differential (3-OOD) mechanism to eliminate slipping of the tracks due to the changing cross-sections of the pipe. This will be achieved in any orientation of the robot. Previous pipe climbers use three-wheel/track modules, each with an individual driving mechanism to achieve stable traversing. Slipping of tracks is prevalent in such robots when it encounters the pipe turns. Thus, active control of each module\u2019s speed is employed to mitigate the slip, thereby requiring substantial control effort. The proposed pipe climber implements the 3-OOD to address this issue by allowing the robot to mechanically modulate the track speeds as it encounters a turn. The proposed 3-OOD is the first three-output differential to realize the functional abilities of a traditional two-output differential.",
        "primary_area": "",
        "author": "Rama Vadapalli;Saharsh Agarwal;Vishnu Kumar;Kartik Suryavanshi;Nagamanikandan G;K Madhava Krishna;Rama Vadapalli;Saharsh Agarwal;Vishnu Kumar;Kartik Suryavanshi;Nagamanikandan G;K Madhava Krishna",
        "authorids": "/37088505622;/37088853862;/37088853494;/37088504794;/37089196636;/38201465600;/37088505622;/37088853862;/37088853494;/37088504794;/37089196636;/38201465600",
        "aff": "Robotics Research Center, International Institute of Information Technology, Hyderabad, India; Robotics Research Center, International Institute of Information Technology, Hyderabad, India; Robotics Research Center, International Institute of Information Technology, Hyderabad, India; Robotics Research Center, International Institute of Information Technology, Hyderabad, India; Robotics Research Center, International Institute of Information Technology, Hyderabad, India; Robotics Research Center, International Institute of Information Technology, Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635853/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1535921689229895389&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "International Institute of Information Technology",
        "aff_unique_dep": "Robotics Research Center",
        "aff_unique_url": "https://iiit Hyderabad.ac.in",
        "aff_unique_abbr": "IIIT Hyderabad",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hyderabad",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9636752",
        "title": "Momentum based Whole-Body Optimal Planning for a Single-Spherical-Wheeled Balancing Mobile Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a planning and control framework for dynamic, whole-body motions for dynamically stable shape-accelerating mobile manipulators. This class of robots are inherently unstable and require careful coordination between the upper and lower body to maintain balance while performing arm motion tasks. Solutions to this problem either use a complex, full-body nonlinear dynamic model of the robot or a highly simplified model of the robot. Here we explore the use of centroidal dynamics which has recently become a popular approach for designing balancing controllers for humanoid robots. We describe a framework where we first solve a trajectory optimization problem offline. We define balancing for a ballbot in terms of the centroidal momentum instead of other approaches like ZMP or angular velocity that are more commonly used. The generated motion is tracked using a PD-PID cascading balancing controller for the body and torque controller for the arms. We demonstrate that this framework is capable of generating dynamic motion plans and control inputs with examples on the CMU ballbot, a single-spherical-wheeled balancing mobile manipulator.",
        "primary_area": "",
        "author": "Roberto Shu;Ralph Hollis;Roberto Shu;Ralph Hollis",
        "authorids": "/37086184712;/37277029900;/37086184712;/37277029900",
        "aff": "The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636752/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8292552644479090981&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "The Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636713",
        "title": "Monitoring Object Detection Abnormalities via Data-Label and Post-Algorithm Abstractions",
        "track": "main",
        "status": "Poster",
        "abstract": "While object detection modules are essential functionalities for any autonomous vehicle, the performance of such modules that are implemented using deep neural networks can be, in many cases, unreliable. In this paper, we develop abstraction-based monitoring as a logical framework for filtering potentially erroneous detection results. Concretely, we consider two types of abstraction, namely data-label abstraction and post-algorithm abstraction. Operated on the training dataset, the construction of data-label abstraction iterates each input, aggregates region-wise information over its associated labels, and stores the vector under a finite history length. Post-algorithm abstraction builds an abstract transformer for the tracking algorithm. Elements being associated together by the abstract transformer can be checked against consistency over their original values. We have implemented the overall framework to a research prototype and validated it using publicly available object detection datasets.",
        "primary_area": "",
        "author": "Yuhang Chen;Chih-Hong Cheng;Jun Yan;Rongjie Yan;Yuhang Chen;Chih-Hong Cheng;Jun Yan;Rongjie Yan",
        "authorids": "/37087027830;/37086835874;/37293579900;/37086392499;/37087027830;/37086835874;/37293579900;/37086392499",
        "aff": "University of Chinese Academy of Sciences, China; DENSO Automotive Deutschland GmbH, Germany; State Key Laboratory of Computer Science, ISCAS, China; State Key Laboratory of Computer Science, ISCAS, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636713/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6309025763753522154&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "University of Chinese Academy of Sciences;DENSO Automotive Deutschland GmbH;Institute of Computing Technology, Chinese Academy of Sciences",
        "aff_unique_dep": ";;State Key Laboratory of Computer Science",
        "aff_unique_url": "http://www.ucas.ac.cn;https://www.denso.de;http://www.ict.ac.cn",
        "aff_unique_abbr": "UCAS;;ICT, CAS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "9636497",
        "title": "Monitoring and Diagnosability of Perception Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Perception is a critical component of high-integrity applications of robotics and autonomous systems, such as self-driving vehicles. In these applications, failure of perception systems may put human life at risk, and a broad adoption of these technologies requires the development of methodologies to guarantee and monitor safe operation. Despite the paramount importance of perception systems, currently there is no formal approach for system-level monitoring. In this work, we propose a mathematical model for runtime monitoring and fault detection and identification in perception systems. Towards this goal, we draw connections with the literature on diagnosability in multiprocessor systems, and generalize it to account for modules with heterogeneous outputs that interact over time. The resulting temporal diagnostic graphs (i) provide a framework to reason over the consistency of perception outputs \u2013across modules and over time\u2013 thus enabling fault detection, (ii) allow us to establish formal guarantees on the maximum number of faults that can be uniquely identified in a given perception system, and (iii) enable the design of efficient algorithms for fault identification. We demonstrate our monitoring system, dubbed PerSyS, in realistic simulations using the LGSVL self-driving simulator and the Apollo Auto autonomy software stack, and show that PerSyS is able to detect failures in challenging scenarios (including scenarios that have caused self-driving car accidents in recent years), and is able to correctly identify faults while entailing a minimal computation overhead (< 5 ms on a single-core CPU).",
        "primary_area": "",
        "author": "Pasquale Antonante;David I. Spivak;Luca Carlone;Pasquale Antonante;David I. Spivak;Luca Carlone",
        "authorids": "/37087323827;/37086209997;/37545784100;/37087323827;/37086209997;/37545784100",
        "aff": "Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636497/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17299533594560273392&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information & Decision Systems",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636384",
        "title": "Monocular 3D Vehicle Detection Using Uncalibrated Traffic Cameras through Homography",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a method to extract the position and pose of vehicles in the 3D world from a single traffic camera. Most previous monocular 3D vehicle detection algorithms focused on cameras on vehicles from the perspective of a driver, and assumed known intrinsic and extrinsic calibration. On the contrary, this paper focuses on the same task using uncalibrated monocular traffic cameras. We observe that the homography between the road plane and the image plane is essential to 3D vehicle detection and the data synthesis for this task, and the homography can be estimated without the camera intrinsics and extrinsics. We conduct 3D vehicle detection by estimating the rotated bounding boxes (r-boxes) in the bird\u2019s eye view (BEV) images generated from inverse perspective mapping. We propose a new regression target called tailed r-box and a dual-view network architecture which boosts the detection accuracy on warped BEV images. Experiments show that the proposed method can generalize to new camera and environment setups despite not seeing imaged from them during training.",
        "primary_area": "",
        "author": "Minghan Zhu;Songan Zhang;Yuanxin Zhong;Pingping Lu;Huei Peng;John Lenneman;Minghan Zhu;Songan Zhang;Yuanxin Zhong;Pingping Lu;Huei Peng;John Lenneman",
        "authorids": "/37087996520;/37086546502;/37088637735;/37087995162;/37273793500;/37089195824;/37087996520;/37086546502;/37088637735;/37087995162;/37273793500;/37089195824",
        "aff": "University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; Collaborative Safety Research Center at the Toyota Motor North America Research & Development, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636384/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10995855718349872736&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "University of Michigan;Toyota Motor North America Research & Development",
        "aff_unique_dep": ";Collaborative Safety Research Center",
        "aff_unique_url": "https://www.umich.edu;https://www.toyota.com",
        "aff_unique_abbr": "UM;Toyota",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635912",
        "title": "Monocular Teach-and-Repeat Navigation using a Deep Steering Network with Scale Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel monocular teach-and-repeat navigation system with the capability of scale awareness, i.e. the absolute distance between observation and goal images. It decomposes the navigation task into a sequence of visual servoing sub-tasks to approach consecutive goal/node images in a topological map. To be specific, a novel hybrid model, named deep steering network is proposed to infer the navigation primitives according to the learned local feature and scale for each visual servoing sub-task. A novel architecture, Scale-Transformer, is developed to estimate the absolute scale between the observation and goal image pair from a set of matched deep representations to assist repeating navigation. The experiments demonstrate that our scale-aware teach-and-repeat method achieves satisfying navigation accuracy, and converges faster than the monocular methods without scale correction given an inaccurate initial pose. The proposed network is integrated into an onboard system deployed on a real robot to achieve real-time navigation in a real environment. A demonstration video can be found online: https://youtu.be/ctlwDaMKnHw",
        "primary_area": "",
        "author": "Cheng Zhao;Li Sun;Tom\u00e1\u0161 Krajn\u00edk;Tom Duckett;Zhi Yan;Cheng Zhao;Li Sun;Tom\u00e1\u0161 Krajn\u00edk;Tom Duckett;Zhi Yan",
        "authorids": "/37085614336;/37086401506;/38547272600;/37419160900;/37086432956;/37085614336;/37086401506;/38547272600;/37419160900;/37086432956",
        "aff": "Department of Engineering Science, University of Oxford, UK; Visual Computing Group, University of Sheffield, UK; AI Center, Czech Technical University in Prague, Czechia; Lincoln Centre for Autonomous Systems, University of Lincoln, UK; CIAD UMR7533, Univ. Bourgogne Franche-Comt\u00e9, UTBM, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635912/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11630120280480206652&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "University of Oxford;University of Sheffield;Czech Technical University in Prague;University of Lincoln;University Bourgogne Franche-Comt\u00e9",
        "aff_unique_dep": "Department of Engineering Science;Visual Computing Group;AI Center;Lincoln Centre for Autonomous Systems;CIAD UMR7533",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.sheffield.ac.uk;https://www.cvut.cz;https://www.lincoln.ac.uk;",
        "aff_unique_abbr": "Oxford;;CTU;;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Prague",
        "aff_country_unique_index": "0;0;1;0;2",
        "aff_country_unique": "United Kingdom;Czechia;France"
    },
    {
        "id": "9636426",
        "title": "Monolithic vs. hybrid controller for multi-objective Sim-to-Real learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Simulation to real (Sim-to-Real) is an attractive approach to construct controllers for robotic tasks that are easier to simulate than to analytically solve. Working Sim-to-Real solutions have been demonstrated for tasks with a clear single objective such as \"reach the target\". Real world applications, however, often consist of multiple simultaneous objectives such as \"reach the target\" but \"avoid obstacles\". A straightforward solution in the context of reinforcement learning (RL) is to combine multiple objectives into a multi-term reward function and train a single monolithic controller. Recently, a hybrid solution based on pre-trained single objective controllers and a switching rule between them was proposed. In this work, we compare these two approaches in the multi-objective setting of a robot manipulator to reach a target while avoiding an obstacle. Our findings show that the training of a hybrid controller is easier and obtains a better success-failure trade-off than a monolithic controller. The controllers trained in simulator were verified by a real set-up.",
        "primary_area": "",
        "author": "Atakan Dag;Alexandre Angleraud;Wenyan Yang;Nataliya Strokina;Roel S. Pieters;Minna Lanz;Joni-Kristian K\u00e4m\u00e4r\u00e4inen;Atakan Dag;Alexandre Angleraud;Wenyan Yang;Nataliya Strokina;Roel S. Pieters;Minna Lanz;Joni-Kristian K\u00e4m\u00e4r\u00e4inen",
        "authorids": "/37089195075;/37086512332;/37088505300;/38548263900;/37086512826;/37712495100;/37268498700;/37089195075;/37086512332;/37088505300;/38548263900;/37086512826;/37712495100;/37268498700",
        "aff": "Computing Sciences, Tampere University, Finland; Automation Technology and Mechanical Engineering, Tampere University, Finland; Computing Sciences, Tampere University, Finland; Computing Sciences, Tampere University, Finland; Automation Technology and Mechanical Engineering, Tampere University, Finland; Automation Technology and Mechanical Engineering, Tampere University, Finland; Computing Sciences, Tampere University, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636426/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16902540427632929048&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Tampere University",
        "aff_unique_dep": "Computing Sciences",
        "aff_unique_url": "https://www.tuni.fi",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "9636465",
        "title": "Monte-Carlo Localization in Underground Parking Lots using Parking Slot Numbers",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous Valet Parking (AVP) in an under- ground garage is an emerging smart vehicle solution that the community believes to be solvable with close-to-market sensors. Absence of GPS signals and a high degree of self-similarity however render global visual localization in such environments a highly challenging problem. We present a novel underground parking localization method that relies on text recognition in the wild as well as optical character recognition (OCR) to automatically detect parking slot numbers. The detected numbers are then correlated with both geometric as well as semantic information extracted from an offline map of the environment. The resulting measurement model is embedded into a probabilistic Monte-Carlo localization framework. The success of our method is demonstrated on multiple real-world sequences in one of the largest underground parking garages in Shanghai.",
        "primary_area": "",
        "author": "Li Cui;Chunyan Rong;Jingyi Huang;Andre Rosendo;Laurent Kneip;Li Cui;Chunyan Rong;Jingyi Huang;Andre Rosendo;Laurent Kneip",
        "authorids": "/37089197664;/37089195808;/37089196185;/37845873600;/37569040300;/37089197664;/37089195808;/37089196185;/37845873600;/37569040300",
        "aff": "Mobile Perception Lab (MPL), SIST ShanghaiTech University; Living Machines Lab (LIMA), SIST ShanghaiTech University; Living Machines Lab (LIMA), SIST ShanghaiTech University; Living Machines Lab (LIMA), SIST ShanghaiTech University; Mobile Perception Lab (MPL), SIST ShanghaiTech University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636465/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9590836596872676784&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ShanghaiTech University",
        "aff_unique_dep": "Mobile Perception Lab",
        "aff_unique_url": "http://www.shanghaitech.edu.cn",
        "aff_unique_abbr": "ShanghaiTech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636769",
        "title": "Motion Field Consensus with Locality Preservation: A Geometric Confirmation Strategy for Loop Closure Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Loop closure detection (LCD), which aims to deal with the drift emerging when robots travel around the route, plays a key role in a simultaneous localization and mapping system. Unlike most current methods which focus on seeking an appropriate representation of images, we propose a novel two-stage pipeline dominated by the estimation of spatial geometric relationship. When a query image occurs, we select semantically similar images based on the SuperPoint network and the aggregated selective match kernel in the first stage, and then conduct robust geometric confirmation to verify true loop-closing pairs in the second stage. Based on the potential property of motion field in the LCD scene, a robust feature matching algorithm, termed as motion field consensus with locality preservation (MFC-LP), is proposed. In particular, we exploit the smoothness prior to guide the learning of the motion field for an image pair in a reproducing kernel Hilbert space (RKHS). Meanwhile, to enhance the local relevance of motion vectors, we design a locality preservation mechanism thus making the learned motion field more accurate. Extensive experiments on several publicly available datasets reveal that MFC-LP has a good performance in the general feature matching task and the proposed pipeline outperforms the current state-of-the-art approaches in the LCD task.",
        "primary_area": "",
        "author": "Kaining Zhang;Xingyu Jiang;Xiaoguang Mei;Huabing Zhou;Jiayi Ma;Kaining Zhang;Xingyu Jiang;Xiaoguang Mei;Huabing Zhou;Jiayi Ma",
        "authorids": "/37089000357;/37086562472;/37085754824;/37085579500;/37966025300;/37089000357;/37086562472;/37085754824;/37085579500;/37966025300",
        "aff": "Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636769/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16759524879578027836&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Wuhan University",
        "aff_unique_dep": "Electronic Information School",
        "aff_unique_url": "http://www.whu.edu.cn/",
        "aff_unique_abbr": "WHU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Wuhan",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636480",
        "title": "Motion Planning for Autonomous Vehicles in the Presence of Uncertainty Using Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning under uncertainty is one of the main challenges in developing autonomous driving vehicles. In this work, we focus on the uncertainty in sensing and perception, resulted from a limited field of view, occlusions, and sensing range. This problem is often tackled by considering hypothetical hidden objects in occluded areas or beyond the sensing range to guarantee passive safety. However, this may result in conservative planning and expensive computation, particularly when numerous hypothetical objects need to be considered. We propose a reinforcement learning (RL) based solution to manage uncertainty by optimizing for the worst case outcome. This approach is in contrast to traditional RL, where the agents try to maximize the average expected reward. The proposed approach is built on top of the Distributional RL with its policy optimization maximizing the stochastic outcomes\u2019 lower bound. This modification can be applied to a range of RL algorithms. As a proof-of-concept, the approach is applied to two different RL algorithms, Soft Actor-Critic and DQN. The approach is evaluated against two challenging scenarios of pedestrians crossing with occlusion and curved roads with a limited field of view. The algorithm is trained and evaluated using the SUMO traffic simulator. The proposed approach yields much better motion planning behavior compared to conventional RL algorithms and behaves comparably to humans driving style.",
        "primary_area": "",
        "author": "Kasra Rezaee;Peyman Yadmellat;Simon Chamorro;Kasra Rezaee;Peyman Yadmellat;Simon Chamorro",
        "authorids": "/38491501500;/37078570200;/37089031838;/38491501500;/37078570200;/37089031838",
        "aff": "Noah\u2019s Ark Lab., Huawei Technologies, Markham, Ontario, Canada; Noah\u2019s Ark Lab., Huawei Technologies, Markham, Ontario, Canada; ECE Department, Universit\u00e9 de Sherbrooke, Sherbrooke, Quebec, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636480/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11678867961201752405&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Huawei;Universit\u00e9 de Sherbrooke",
        "aff_unique_dep": "Noah\u2019s Ark Lab.;ECE Department",
        "aff_unique_url": "https://www.huawei.com;https://www.usherbrooke.ca",
        "aff_unique_abbr": "Huawei;",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Markham;Sherbrooke",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9635854",
        "title": "Motion Strategy Using Opponent Player\u2019s Serial Learning for Air-Hockey Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, there have been many studies on sports robots that can play against humans, including studies on the strategies that sports robots use by taking into account the physical conditions of their opponents. However, there have been few studies on strategies that take into account psychological conditions of the opponents, such as carelessness and habituation. This paper proposes a motion strategy for an air-hockey robot that intentionally coaxes the opponent to learn the robot\u2019s attack sequence and then uses a different attack sequence to catch the opponent off guard. We explicitly model the change in reaction time during serial learning and represent the opponent\u2019s reaction as an evaluation function. By applying this evaluation function to a game tree and selecting the optimal motion, the robot could catch the opponent by surprise. Actual experiments with several subjects confirmed the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Shotaro Fukuda;Koichiro Tadokoro;Akio Namiki;Shotaro Fukuda;Koichiro Tadokoro;Akio Namiki",
        "authorids": "/37089196751;/37089197437;/37273962400;/37089196751;/37089197437;/37273962400",
        "aff": "Graduate School of Science and Engineering, Chiba University, Chiba City, Japan; Graduate School of Science and Engineering, Chiba University, Chiba City, Japan; Graduate School of Science and Engineering, Chiba University, Chiba City, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635854/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13713044570423006787&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chiba University",
        "aff_unique_dep": "Graduate School of Science and Engineering",
        "aff_unique_url": "https://www.chiba-u.ac.jp",
        "aff_unique_abbr": "Chiba U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chiba City",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636103",
        "title": "Motion and Force Planning for Manipulating Heavy Objects by Pivoting",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulation of objects by exploiting their contact with the environment can enhance both the dexterity and payload capability of robotic manipulators. A common way to manipulate heavy objects beyond the payload capability of a robot is to use a sequence of pivoting motions, wherein, an object is moved while some contact points between the object and a support surface are kept fixed. The goal of this paper is to develop an algorithmic approach for automated plan generation for object manipulation with a sequence of pivoting motions. A plan for manipulating a heavy object consists of a sequence of joint angles of the manipulator, the corresponding object poses, as well as the joint torques required to move the object. The constraint of maintaining object contact with the ground during manipulation results in nonlinear constraints in the configuration space of the robot, which is challenging for motion planning algorithms. Exploiting the fact that pivoting motion corresponds to movements in a subgroup of the group of rigid body motions, SE(3), we present a novel task-space based planning approach for computing a motion plan for both the manipulator and the object while satisfying contact constraints. We also combine our motion planning algorithm with a grasping force synthesis algorithm to ensure that friction constraints at the contacts and actuator torque constraints are satisfied. We present simulation results with a dual-armed Baxter robot to demonstrate our approach.",
        "primary_area": "",
        "author": "Amin Fakhari;Aditya Patankar;Nilanjan Chakraborty;Amin Fakhari;Aditya Patankar;Nilanjan Chakraborty",
        "authorids": "/37088377881;/312854643498475;/37314871600;/37088377881;/312854643498475;/37314871600",
        "aff": "Department of Mechanical Engineering, Stony Brook University, Stony Brook, NY, USA; Department of Mechanical Engineering, Stony Brook University, Stony Brook, NY, USA; Department of Mechanical Engineering, Stony Brook University, Stony Brook, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636103/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12332911510361362138&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stony Brook University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stonybrook.edu",
        "aff_unique_abbr": "SBU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stony Brook",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636224",
        "title": "Moving Forward in Formation: A Decentralized Hierarchical Learning Approach to Multi-Agent Moving Together",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent path finding in formation has many potential real-world applications like mobile warehouse robotics. However, previous multi-agent path finding (MAPF) methods hardly take formation into consideration. Further-more, they are usually centralized planners and require the whole state of the environment. Other decentralized partially observable approaches to MAPF are reinforcement learning (RL) methods. However, these RL methods encounter difficulties when learning path finding and formation problems at the same time. In this paper, we propose a novel decentralized partially observable RL algorithm that uses a hierarchical structure to decompose the multi-objective task into unrelated ones. It also calculates a theoretical weight that makes each tasks reward has equal influence on the final RL value function. Additionally, we introduce a communication method that helps agents cooperate with each other. Experiments in simulation show that our method outperforms other end-to-end RL methods and our method can naturally scale to large world sizes where centralized planner struggles. We also deploy and validate our method in a real-world scenario.",
        "primary_area": "",
        "author": "Shanqi Liu;Licheng Wen;Jinhao Cui;Xuemeng Yang;Junjie Cao;Yong Liu;Shanqi Liu;Licheng Wen;Jinhao Cui;Xuemeng Yang;Junjie Cao;Yong Liu",
        "authorids": "/37088939307;/37088458076;/37088688571;/37088455828;/37088457540;/37066946100;/37088939307;/37088458076;/37088688571;/37088455828;/37088457540;/37066946100",
        "aff": "State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China; State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control, Zhejiang University, Zhejiang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636224/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6822366856511086452&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control Technology and Institute of Cyber-Systems and Control",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636075",
        "title": "Moving SLAM: Fully Unsupervised Deep Learning in Non-Rigid Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new deep learning framework to decompose monocular videos into 3D geometry (camera pose and depth), moving objects, and their motions, with no supervision. We build upon the idea of view synthesis, which uses classical camera geometry to re-render a source image from a different point-of-view to obtain supervisory signals, specified by a predicted relative 6-degree-of-freedom pose and depth map. However, the typical view synthesis equations rely on a strong assumption: that objects in scenes do not move. This rigid-world assumption limits the predictive power, and rules out learning about objects automatically. We propose a simple solution: minimize the synthesis error on small local regions of the image instead. While the scene as a whole may be non-rigid, it is always possible to find small regions that are approximately rigid, such as inside a moving object. Our network can learn a dense pose map describing poses for each local region. This represents a significantly richer model, including 6D object motions, with little additional complexity. We establish very competitive results on unsupervised odometry and depth prediction on KITTI. We also demonstrate new capabilities on EPIC-Kitchens, a challenging dataset of indoor videos, where there is no ground truth information for depth, odometry, object segmentation or motion - yet all are recovered automatically by our approach.",
        "primary_area": "",
        "author": "Dan Xu;Andrea Vedaldi;Jo\u00e3o F. Henriques;Dan Xu;Andrea Vedaldi;Jo\u00e3o F. Henriques",
        "authorids": "/37086110882;/37398040100;/37587754900;/37086110882;/37398040100;/37587754900",
        "aff": "Department of Computer Science and Engineering, Hong Kong University of Science and Technology, HK; Visual Geometry Group (VGG), University of Oxford, UK; Visual Geometry Group (VGG), University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636075/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14762313007968681570&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Hong Kong University of Science and Technology;University of Oxford",
        "aff_unique_dep": "Department of Computer Science and Engineering;Visual Geometry Group (VGG)",
        "aff_unique_url": "https://www.ust.hk;https://www.ox.ac.uk",
        "aff_unique_abbr": "HKUST;Oxford",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Hong Kong SAR;Oxford",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9636284",
        "title": "Moving-Platform Pose Estimation for Cable-Driven Parallel Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Cable-Driven Parallel Robots (CDPRs) are parallel robots with rigid links replaced by cables. As for most parallel robots the determination of the analytical solutions to the direct geometrico-static model (DGSM) is a difficult task that is often not feasible online. However, the knowledge of the moving-platform (MP) pose is necessary in order to control the CDPR, e.g. with visual servoing. When the MP pose measurement is not available, an estimation can be sufficient. This paper compares three estimation methods: (a) control-based; (b) image-based; and (c) model-based. The three methods are implemented experimentally with an open-loop velocity controller and a closed-loop visual servoing controller. Overall, very good results are shown with model-based and control-based methods for both controllers. Finally, it is shown that the visual servoing controller leads to a better accuracy of the robot than the velocity controller.",
        "primary_area": "",
        "author": "Zane Zake;Fran\u00e7ois Chaumette;Nicol\u00f2 Pedemonte;St\u00e9phane Caro;Zane Zake;Fran\u00e7ois Chaumette;Nicol\u00f2 Pedemonte;St\u00e9phane Caro",
        "authorids": "/37086640797;/37265186700;/37086037541;/37589701400;/37086640797;/37265186700;/37086037541;/37589701400",
        "aff": "Inria, Univ Rennes, CNRS, IRISA, Rennes, France; IRT Jules Verne, Chemin du Chaffault, Bouguenais, France; Inria, Univ Rennes, CNRS, IRISA, Rennes, France; Centre National de la Recherche Scientifique (CNRS), Nantes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636284/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5322197306250467683&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "INRIA;IRT Jules Verne;Centre National de la Recherche Scientifique",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.inria.fr;;https://www.cnrs.fr",
        "aff_unique_abbr": "Inria;;CNRS",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Rennes;;Nantes",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9635898",
        "title": "Multi-Agent Reinforcement Learning for Visibility-based Persistent Monitoring",
        "track": "main",
        "status": "Poster",
        "abstract": "The Visibility-based Persistent Monitoring (VPM) problem seeks to find a set of trajectories (or controllers) for robots to persistently monitor a changing environment. Each robot has a sensor, such as a camera, with a limited field-of-view that is obstructed by obstacles in the environment. The robots may need to coordinate with each other to ensure no point in the environment is left unmonitored for long periods of time. We model the problem such that there is a penalty that accrues every time step if a point is left unmonitored. However, the dynamics of the penalty are unknown to us. We present a Multi-Agent Reinforcement Learning (MARL) algorithm for the VPM problem. Specifically, we present a Multi-Agent Graph Attention Proximal Policy Optimization (MA-G-PPO) algorithm that takes as input the local observations of all agents combined with a low resolution global map to learn a policy for each agent. The graph attention allows agents to share their information with others leading to an effective joint policy. Our main focus is to understand how effective MARL is for the VPM problem. We investigate five research questions with this broader goal. We find that MA-G-PPO is able to learn a better policy than the non-RL baseline in most cases, the effectiveness depends on agents sharing information with each other, and the policy learnt shows emergent behavior for the agents.",
        "primary_area": "",
        "author": "Jingxi Chen;Amrish Baskaran;Zhongshun Zhang;Pratap Tokekar;Jingxi Chen;Amrish Baskaran;Zhongshun Zhang;Pratap Tokekar",
        "authorids": "/37089196225;/37089195228;/37085989946;/37546532700;/37089196225;/37089195228;/37085989946;/37546532700",
        "aff": "University of Maryland, USA; University of Maryland, USA; University of Maryland, USA; University of Maryland, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635898/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14799402972372457626&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635915",
        "title": "Multi-Modal Loop Closing in Unstructured Planetary Environments with Visually Enriched Submaps",
        "track": "main",
        "status": "Poster",
        "abstract": "Future planetary missions will rely on rovers that can autonomously explore and navigate in unstructured environments. An essential element is the ability to recognize places that were already visited or mapped. In this work, we leverage the ability of stereo cameras to provide both visual and depth information, guiding the search and validation of loop closures from a multi-modal perspective. We propose to augment submaps that are created by aggregating stereo point clouds, with visual keyframes. Point clouds matches are found by comparing CSHOT descriptors and validated by clustering, while visual matches are established by comparing keyframes using Bag-of-Words (BoW) and ORB descriptors. The relative transformations resulting from both keyframe and point cloud matches are then fused to provide pose constraints between submaps in our graph-based SLAM framework. Using the LRU rover, we performed several tests in both an indoor laboratory environment as well as a challenging planetary analog environment on Mount Etna, Italy, consisting of areas where either keyframes or point clouds alone failed to provide adequate matches demonstrating the benefit of the proposed multi-modal approach.",
        "primary_area": "",
        "author": "Riccardo Giubilato;Mallikarjuna Vayugundla;Wolfgang St\u00fcrzl;Martin J. Schuster;Armin Wedler;Rudolph Triebel;Riccardo Giubilato;Mallikarjuna Vayugundla;Wolfgang St\u00fcrzl;Martin J. Schuster;Armin Wedler;Rudolph Triebel",
        "authorids": "/37085829294;/37087246489;/37598170500;/37604581900;/37946067800;/37542908700;/37085829294;/37087246489;/37598170500;/37604581900;/37946067800;/37542908700",
        "aff": "German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635915/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13537330180684629518&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "German Aerospace Center (DLR)",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636777",
        "title": "Multi-Object Grasping \u2013 Estimating the Number of Objects in a Robotic Grasp",
        "track": "main",
        "status": "Poster",
        "abstract": "A human hand can grasp a desired number of objects at once from a pile based solely on tactile sensing. To do so, a robot needs to make a grasp in a pile, sense the number of objects in the grasp before lifting, and predict how many will remain in the grasp after lifting. It is a very challenging problem because when making the prediction, the robotic hand is still in the pile and the objects in the grasp are not observable to vision systems. Moreover, some objects in the hand before lifting may fall out the grasp when the lifting starts because they were supported by other objects in the pile instead of the fingers. A robotic hand should sense how many objects are in a grasp using its tactile sensors before lifting. This paper presents novel multi-object grasping analyzing methods to solve this problem. They include a grasp volume calculation, tactile force analysis, and a data-driven deep learning approach. The methods have been implemented on a Barrett hand and then evaluated in simulations and a real setup with a robotic system. The evaluation results conclude that once the Barrett hand grasps multiple objects in the pile, the data-driven models can make a good prediction before lifting on how many objects will remain in the hand after lifting. The root-mean-square errors are 0.74 for balls and 0.58 for cubes in simulations, and 1.06 for balls and 1.45 for cubes in the real system.",
        "primary_area": "",
        "author": "Tianze Chen;Adheesh Shenoy;Anzhelika Kolinko;Syed Shah;Yu Sun;Tianze Chen;Adheesh Shenoy;Anzhelika Kolinko;Syed Shah;Yu Sun",
        "authorids": "/37087323523;/37089196538;/37089197589;/37089197550;/37291603500;/37087323523;/37089196538;/37089197589;/37089197550;/37291603500",
        "aff": "Robot Perception and Action Lab (RPAL) of Computer Science and Engineering Department, University of South Florida, Tampa, FL, USA; Robot Perception and Action Lab (RPAL) of Computer Science and Engineering Department, University of South Florida, Tampa, FL, USA; Robot Perception and Action Lab (RPAL) of Computer Science and Engineering Department, University of South Florida, Tampa, FL, USA; Robot Perception and Action Lab (RPAL) of Computer Science and Engineering Department, University of South Florida, Tampa, FL, USA; Robot Perception and Action Lab (RPAL) of Computer Science and Engineering Department, University of South Florida, Tampa, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636777/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7064217023698293525&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of South Florida",
        "aff_unique_dep": "Computer Science and Engineering Department",
        "aff_unique_url": "https://www.usf.edu",
        "aff_unique_abbr": "USF",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tampa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636507",
        "title": "Multi-Resolution Elevation Mapping and Safe Landing Site Detection with Applications to Planetary Rotorcraft",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a resource-efficient approach to provide an autonomous UAV with an on-board perception method to detect safe, hazard-free landing sites during flights over complex 3D terrain. We aggregate 3D measurements acquired from a sequence of monocular images by a Structure-from-Motion approach into a local, robot-centric, multi-resolution elevation map of the overflown terrain, which fuses depth measurements according to their lateral surface resolution (pixel-footprint) in a probabilistic framework based on the concept of dynamic Level of Detail. Map aggregation only requires depth maps and the associated poses, which are obtained from an on-board Visual Odometry algorithm. An efficient landing site detection method then exploits the features of the underlying multi-resolution map to detect safe landing sites based on slope, roughness, and quality of the reconstructed terrain surface. The evaluation of the performance of the mapping and landing site detection modules are analyzed independently and jointly in simulated and real-world experiments in order to establish the efficacy of the proposed approach.",
        "primary_area": "",
        "author": "Pascal Schoppmann;Pedro F. Proen\u00e7a;Jeff Delaune;Michael Pantic;Timo Hinzmann;Larry Matthies;Roland Siegwart;Roland Brockers;Pascal Schoppmann;Pedro F. Proen\u00e7a;Jeff Delaune;Michael Pantic;Timo Hinzmann;Larry Matthies;Roland Siegwart;Roland Brockers",
        "authorids": "/37088884269;/37086315258;/37086592626;/37087468483;/37085820525;/37270488400;/37281398300;/37266435300;/37088884269;/37086315258;/37086592626;/37087468483;/37085820525;/37270488400;/37281398300;/37266435300",
        "aff": "Autonomous Systems Lab, ETH Zurich, Switzerland; Jet Propulsion Laboratory / California Institute of Technology, Pasadena, CA, USA; Jet Propulsion Laboratory / California Institute of Technology, Pasadena, CA, USA; Autonomous Systems Lab, ETH Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Switzerland; Jet Propulsion Laboratory / California Institute of Technology, Pasadena, CA, USA; Autonomous Systems Lab, ETH Zurich, Switzerland; Jet Propulsion Laboratory / California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636507/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11154280555815967723&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;0;0;1;0;1",
        "aff_unique_norm": "ETH Zurich;California Institute of Technology",
        "aff_unique_dep": "Autonomous Systems Lab;Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.ethz.ch;https://www.caltech.edu",
        "aff_unique_abbr": "ETHZ;Caltech",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Pasadena",
        "aff_country_unique_index": "0;1;1;0;0;1;0;1",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "9636737",
        "title": "Multi-Resolution POMDP Planning for Multi-Object Search in 3D",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots operating in households must find objects on shelves, under tables, and in cupboards. In such environments, it is crucial to search efficiently at 3D scale while coping with limited field of view and the complexity of searching for multiple objects. Principled approaches to object search frequently use Partially Observable Markov Decision Process (POMDP) as the underlying framework for computing search strategies, but constrain the search space in 2D. In this paper, we present a POMDP formulation for multi-object search in a 3D region with a frustum-shaped field-of-view. To efficiently solve this POMDP, we propose a multi-resolution planning algorithm based on online Monte-Carlo tree search. In this approach, we design a novel octree-based belief representation to capture uncertainty of the target objects at different resolution levels, then derive abstract POMDPs at lower resolutions with dramatically smaller state and observation spaces. Evaluation in a simulated 3D domain shows that our approach finds objects more efficiently and successfully compared to a set of baselines without resolution hierarchy in larger instances under the same computational requirement. We demonstrate our approach on a mobile robot to find objects placed at different heights in two 10m2\u00d72m regions by moving its base and actuating its torso.",
        "primary_area": "",
        "author": "Kaiyu Zheng;Yoonchang Sung;George Konidaris;Stefanie Tellex;Kaiyu Zheng;Yoonchang Sung;George Konidaris;Stefanie Tellex",
        "authorids": "/37087321724;/38235977600;/38318614200;/37402794800;/37087321724;/38235977600;/38318614200;/37402794800",
        "aff": "Brown University, Providence, RI; MIT Csail, Cambridge, MA; Brown University, Providence, RI; Brown University, Providence, RI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636737/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=953136745792670595&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Brown University;Massachusetts Institute of Technology",
        "aff_unique_dep": ";Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.brown.edu;https://www.csail.mit.edu",
        "aff_unique_abbr": "Brown;MIT CSAIL",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Providence;Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636675",
        "title": "Multi-Robot Coverage and Exploration using Spatial Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "The multi-robot coverage problem is an essential building block for systems that perform tasks like inspection, exploration, or search and rescue. We discretize the coverage problem to induce a spatial graph of locations and represent robots as nodes in the graph. Then, we train a Graph Neural Network controller that leverages the spatial equivariance of the task to imitate an expert open-loop routing solution. This approach generalizes well to much larger maps and larger teams that are intractable for the expert. In particular, the model generalizes effectively to a simulation of ten quadrotors and dozens of buildings in an urban setting. We also demonstrate the GNN controller can surpass planning-based approaches in an exploration task.",
        "primary_area": "",
        "author": "Ekaterina Tolstaya;James Paulos;Vijay Kumar;Alejandro Ribeiro;Ekaterina Tolstaya;James Paulos;Vijay Kumar;Alejandro Ribeiro",
        "authorids": "/37086432156;/37085335548;/37280341400;/37266493600;/37086432156;/37085335548;/37280341400;/37266493600",
        "aff": "Dept. of Electrical and Systems Eng., University of Pennsylvania, USA; Dept. of Mechanical Eng. and Applied Mechanics, University of Pennsylvania, USA; Dept. of Mechanical Eng. and Applied Mechanics, University of Pennsylvania, USA; Dept. of Electrical and Systems Eng., University of Pennsylvania, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636675/",
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5146761791696764782&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Dept. of Electrical and Systems Eng.",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636287",
        "title": "Multi-Robot Task Planning under Individual and Collaborative Temporal Logic Specifications",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates the task coordination of multi-robot where each robot has a private individual temporal logic task specification; and also has to jointly satisfy a globally given collaborative temporal logic task specification. To efficiently generate feasible and optimized task execution plans for the robots, we propose a hierarchical multi-robot temporal task planning framework, in which a central server allocates the collaborative tasks to the robots, and then individual robots can independently synthesize their task execution plans in a decentralized manner. Furthermore, we propose an execution plan adjusting mechanism that allows the robots to iteratively modify their execution plans via privacy-preserved inter-agent communication, to improve the expected actual execution performance by reducing waiting time in collaborations for the robots. The correctness and efficiency of the proposed method are analyzed and also verified by extensive simulation experiments.",
        "primary_area": "",
        "author": "Ruofei Bai;Ronghao Zheng;Meiqin Liu;Senlin Zhang;Ruofei Bai;Ronghao Zheng;Meiqin Liu;Senlin Zhang",
        "authorids": "/37089195512;/37074209000;/37401511300;/37535987900;/37089195512;/37074209000;/37401511300;/37535987900",
        "aff": "College of Electrical Engineering, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636287/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4951564777807912938&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Hangzhou Dianzi University;Zhejiang University",
        "aff_unique_dep": "College of Electrical Engineering;State Key Laboratory of Industrial Control Technology",
        "aff_unique_url": "http://www.hdu.edu.cn/;http://www.zju.edu.cn",
        "aff_unique_abbr": "HGHDU;ZJU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636717",
        "title": "Multi-Scale Aggregation with Self-Attention Network for Modeling Electrical Motor Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling induction motor dynamics is a crucial problem in the industry. The previous works mainly model the dynamics based on the physical model assumption and state equation. However, due to the complex internal structure of motors, the traditional methods cannot estimate dynamics precisely. To address this issue, we adopt a deep learning-based approach that takes the time-series motor data measured from the sensor to estimate the dynamics without making any assumptions about the motor\u2019s interior. In this paper, we propose a multi-scale feature aggregation with self-attention network (MASNet) to deal with modeling motor dynamics. First, our model extracts multi-scale features from motor signals by various convolutional kernel sizes. Then, the proposed adaptive feature aggregation module fuses different receptive signals effectively. To further refine these high-level motor features, two-stream components, containing Bidirectional LSTM and self-attention module, are applied to improve motor contextual information. Moreover, we present a novel temporal relative loss to enhance consecutive signal consistency, which improves the performance of modeling dynamics. To deploy the service in the real-world scenario, our network is very lightweight and reduces the number of parameters from 0.62M to 0.09M (around 85% reduction) but outperforms state-of-the-art algorithms by extensive experiments on simulation and real-world motor datasets.",
        "primary_area": "",
        "author": "Kuan-Chih Huang;Hao-Hsiang Yang;Wei-Ting Chen;Kuan-Chih Huang;Hao-Hsiang Yang;Wei-Ting Chen",
        "authorids": "/37088999620;/37087245013;/37086524660;/37088999620;/37087245013;/37086524660",
        "aff": "ASUS Intelligent Cloud Services, Taipei, Taiwan; ASUS Intelligent Cloud Services, Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636717/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11177847446164635091&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "ASUS Intelligent Cloud Services;National Taiwan University",
        "aff_unique_dep": ";Graduate Institute of Electronics Engineering",
        "aff_unique_url": "https://www.asus.com;https://www.ntu.edu.tw",
        "aff_unique_abbr": "ASUS;NTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636113",
        "title": "Multi-Scenario Contacts Handling for Collaborative Robots Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "The goal of this work is to propose a way of dealing with physical interactions for collaborative robots that will ensure the safety of a human operator and improve the performance of a common task by implementing multiple robot behavior scenarios. In this scope, all collisions of a robotic arm are detected and analyzed to chooses an appropriate reaction strategy. The points of contact on the robot\u2019s surface for each collision are estimated, the external forces are identified and collisions are classified by the set of predefined categories. Based on these categories and the current robot state, the algorithm chose an appropriate behavior scenario.All presented algorithms are based only on proprioceptive sensors information and were tested in a simulated environment and on the real collaborative robots KUKA iiwa and Universal Robots UR10e. The result for contact localization showed 4 cm mean accuracy, the classification algorithm was able to identify collisions with hard and soft objects with 98% accuracy for KUKA iiwa 14.",
        "primary_area": "",
        "author": "Dmitry Popov;Stanislav Mikhel;Rauf Yagfarov;Alexandr Klimchik;Anatol Pashkevich;Dmitry Popov;Stanislav Mikhel;Rauf Yagfarov;Alexandr Klimchik;Anatol Pashkevich",
        "authorids": "/38542269000;/37086571457;/37086563068;/37077323100;/37365908800;/38542269000;/37086571457;/37086563068;/37077323100;/37365908800",
        "aff": "Laboratoire des Sciences du Num\u00b4Erique de Nantes (LS2N), Nantes, France; Center for Technologies in Robotics and Mechatronics Components, Innopolis University, Innopolis, Russia; Center for Technologies in Robotics and Mechatronics Components, Innopolis University, Innopolis, Russia; Center for Technologies in Robotics and Mechatronics Components, Innopolis University, Innopolis, Russia; Laboratoire des Sciences du Num\u00b4Erique de Nantes (LS2N), Nantes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636113/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4419053345978683740&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Laboratoire des Sciences du Num\u00e9rique de Nantes;Innopolis University",
        "aff_unique_dep": "LS2N;Center for Technologies in Robotics and Mechatronics Components",
        "aff_unique_url": ";https://www.innopolis.ru/en",
        "aff_unique_abbr": "LS2N;",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Nantes;Innopolis",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "France;Russian Federation"
    },
    {
        "id": "9636561",
        "title": "Multi-Stage Energy-Aware Motion Control with Exteroception-Defined Dynamic Safety Metric",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of motion control for safe physical interaction, and in particular finding new ways for impedance controller parameters\u2019 adaptation to ensure better safety with minimum possible lose in robot performance. We propose an exteroception-based dynamically updated safety metric that takes into account current robot state and inertia as well as external objects\u2019 mass, shape, material properties, velocity, sensor confidence and existing sampling rates. We also present how this metric can be applied to design a finite state machine of the multi-stage controller, which allows us to prioritize either safety of performance by setting different energy and power constraints with smooth transition in between free motion and interaction modes.",
        "primary_area": "",
        "author": "Kirill Artemov;Sergey Kolyubin;Stefano Stramigioli;Kirill Artemov;Sergey Kolyubin;Stefano Stramigioli",
        "authorids": "/37086405025;/37887676700;/37282439300;/37086405025;/37887676700;/37282439300",
        "aff": "Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, St. Petersburg, Russia; Biomechatronics and Energy-Efficient Robotics Lab, ITMO University, St. Petersburg, Russia; Department of Electrical Engineering, Mathematics and Computer Science, University of Twente, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636561/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2579283065114455250&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "ITMO University;University of Twente",
        "aff_unique_dep": "Biomechatronics and Energy-Efficient Robotics Lab;Department of Electrical Engineering, Mathematics and Computer Science",
        "aff_unique_url": "https://www.itmo.ru;https://www.utwente.nl",
        "aff_unique_abbr": "ITMO;UT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "St. Petersburg;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Russian Federation;Netherlands"
    },
    {
        "id": "9636556",
        "title": "Multi-Variable State Prediction: HMM Based Approach for Real-Time Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting the motion of observed entities benefits humans almost seamlessly. The same benefits can be proliferated to mobile autonomous systems if we have a reliable, real-time solution to predict the motion of any object of interest, be it the host\u2019s own motion or that of an observed foreign object. In this work, a novel Multi-Variable State Prediction (MVSP) methodology is devised for real-time trajectory prediction. MVSP incorporates cascaded stages of HMM with Viterbi algorithm and probabilistic quantization for accurately predicting the motion characteristics of the moving object. The overall scheme is employed to predict the motion of moving objects in a 3D space. The proposed approach is verified on both synthetically generated data sequences and data-sets captured from real-life experiments. For a practical scenario, the experiments resulted in an RMS error of 0.6m for a predicted distance of ~18m demonstrating the effectiveness and accuracy of the proposed methodology.",
        "primary_area": "",
        "author": "Ankit;Karthik Narayanan;Dibyendu Ghosh;Vinayak Honkote;Ganeshram Nandakumar;Ankit;Karthik Narayanan;Dibyendu Ghosh;Vinayak Honkote;Ganeshram Nandakumar",
        "authorids": "/37089196363;/37086700819;/37086702221;/37400592800;/38116644500;/37089196363;/37086700819;/37086702221;/37400592800;/38116644500",
        "aff": "Apple Inc. Pvt Ltd; Silicon and Systems Prototyping Lab, Intel Corporation, India; Silicon and Systems Prototyping Lab, Intel Corporation, India; Silicon and Systems Prototyping Lab, Intel Corporation, India; Tunga Aerospace Industries (P) Ltd, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636556/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7498890445208807287&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;2",
        "aff_unique_norm": "Apple;Intel;Tunga Aerospace Industries",
        "aff_unique_dep": "Apple Inc.;Silicon and Systems Prototyping Lab;",
        "aff_unique_url": "https://www.apple.com;https://www.intel.com;",
        "aff_unique_abbr": "Apple;Intel;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "9636636",
        "title": "Multi-agent Collaborative Learning with Relational Graph Reasoning in Adversarial Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a collaborative policy framework via relational graph reasoning for multi-agent systems to accomplish adversarial tasks. A relational graph reasoning module consisting of an agent graph reasoning module and an opponent graph module, is designed to enable each agent to learn mixture state representation to enhance the effectiveness of the policy. In particular, for each agent, the agent graph reasoning module is designed to infer different underlying influences from different opponents and generate agent-level state representation. The opponent graph reasoning module is creatively designed for the opponents to reason relations from their surrounding objects including the agents and the opponents based on their latent features and then predict the future state of the opponents. It forms an opponent-level state representation. Besides, in order to effectively predict the state of the opponents, an intrinsic reward based on prediction error is designed to motivate the policy learning. Furthermore, interactions among agents are utilized to transmit messages and fuse information to promote the cooperative behaviors among the agents. Finally, various representative simulations on two multi-agent adversarial tasks are conducted to demonstrate the superiority and effectiveness of the proposed framework by comparison with existing methods.",
        "primary_area": "",
        "author": "Shiguang Wu;Tenghai Qiu;Zhiqiang Pu;Jianqiang Yi;Shiguang Wu;Tenghai Qiu;Zhiqiang Pu;Jianqiang Yi",
        "authorids": "/37087045549;/37087053504;/37956875200;/37277001200;/37087045549;/37087053504;/37956875200;/37277001200",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636636/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11748626508112312154&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_unique_dep": "School of Artificial Intelligence;Institute of Automation",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.ia.cas.cn",
        "aff_unique_abbr": "UCAS;CAS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636871",
        "title": "Multi-layer VI-GNSS Global Positioning Framework with Numerical Solution aided MAP Initialization",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by the goal of achieving long-term drift-free camera pose estimation in complex scenarios, we propose a global positioning framework fusing visual, inertial and Global Navigation Satellite System (GNSS) measurements in multiple layers. Different from previous loosely- and tightly-coupled methods, the proposed multi-layer fusion allows us to delicately correct the drift of visual odometry and keep reliable positioning while GNSS degrades. In particular, local motion estimation is conducted in the inner-layer, solving the problem of scale drift and inaccurate bias estimation in visual odometry by fusing the velocity of GNSS, pre-integration of Inertial Measurement Unit (IMU) and camera measurement in a tightly-coupled way. The global localization is achieved in the outer-layer, where the local motion is further fused with GNSS position and course in a long-term period in a loosely-coupled way. Furthermore, a dedicated initialization method is proposed to guarantee fast and accurate estimation for all state variables and parameters. We give exhaustive tests of the proposed framework on indoor and outdoor public datasets. The mean localization error is reduced up to 63%, with a promotion of 69% in initialization accuracy compared with state-of-the-art works. We have applied the algorithm to Augmented Reality (AR) navigation, crowd sourcing high-precision map update and other large-scale applications.",
        "primary_area": "",
        "author": "Bing Han;Zhongyang Xiao;Shuai Huang;Tao Zhang;Bing Han;Zhongyang Xiao;Shuai Huang;Tao Zhang",
        "authorids": "/37089195830;/37086349781;/37089197796;/37089196691;/37089195830;/37086349781;/37089197796;/37089196691",
        "aff": "Alibaba Group, Beijing, China; Alibaba Group, Beijing, China; Alibaba Group, Beijing, China; Alibaba Group, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636871/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16903686835812202031&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Alibaba Group",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.alibaba.com",
        "aff_unique_abbr": "Alibaba",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636142",
        "title": "Multi-modal Scene-compliant User Intention Estimation in Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "A multi-modal framework to generate user intention distributions when operating a mobile vehicle is proposed in this work. The model learns from past observed trajectories and leverages traversability information derived from the visual surroundings to produce a set of future trajectories, suitable to be directly embedded into a perception-action shared control strategy on a mobile agent, or as a safety layer to supervise the prudent operation of the vehicle. We base our solution on a conditional Generative Adversarial Network with Long-Short Term Memory cells to capture trajectory distributions conditioned on past trajectories, further fused with traversability probabilities derived from visual segmentation with a Convolutional Neural Network. The proposed data-driven framework results in a significant reduction in error of the predicted trajectories (versus the ground truth) from comparable strategies in the literature (e.g. Social-GAN) that fail to account for information other than the agent\u2019s past history. Experiments were conducted on a dataset collected with a custom wheelchair model built onto the open-source urban driving simulator CARLA, proving also that the proposed framework can be used with a small, unannotated dataset.",
        "primary_area": "",
        "author": "Kavindie Katuwandeniya;Stefan H. Kiss;Lei Shi;Jaime Valls Miro;Kavindie Katuwandeniya;Stefan H. Kiss;Lei Shi;Jaime Valls Miro",
        "authorids": "/37086555084;/37088995973;/37589838200;/37085957321;/37086555084;/37088995973;/37589838200;/37085957321",
        "aff": "Robotics Institute, University of Technology Sydney, Australia; Robotics Institute, University of Technology Sydney, Australia; Robotics Institute, University of Technology Sydney, Australia; Robotics Institute, University of Technology Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636142/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=256360921594631810&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9636854",
        "title": "Multi-robot Scheduling for Environmental Monitoring as a Team Orienteering Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an evolutionary algorithm for solving the multi-robot orienteering problem where a team of cooperative robots aims to maximize the total information collected by visiting a subset of given nodes within a fixed budget on travel costs. Multi-robot orienteering problems are relevant to applications such as logistic delivery services, precision agriculture, and environmental sampling and monitoring. We consider the case where the information gain at each node is related to the service time each robot spends at the node. As such, we address a variant of the Orienteering Problem where the collected rewards are a function of the time a robot spends at a given location. We present a genetic algorithm solver to this cooperative Team Orienteering Problem with service-time dependent rewards. We evaluate the approach over a diverse set of node configurations and for different team sizes. Lastly, we evaluate the effects of team heterogeneity on overall task performance through numerical simulations.",
        "primary_area": "",
        "author": "Ariella Mansfield;Sandeep Manjanna;Douglas G. Macharet;M. Ani Hsieh;Ariella Mansfield;Sandeep Manjanna;Douglas G. Macharet;M. Ani Hsieh",
        "authorids": "/37088688381;/37072300900;/37590114800;/37085672471;/37088688381;/37072300900;/37590114800;/37085672471",
        "aff": "GRASP Laboratory, University of Pennsylvania, Philadelphia, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, USA; Computer Science Department, Computer Vision and Robotics Laboratory (VeRLab), Universidade Federal de Minas Gerais, MG, Brazil; GRASP Laboratory, University of Pennsylvania, Philadelphia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636854/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10987346206028800212&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Pennsylvania;Universidade Federal de Minas Gerais",
        "aff_unique_dep": "GRASP Laboratory;Computer Science Department",
        "aff_unique_url": "https://www.upenn.edu;http://www.ufmg.br",
        "aff_unique_abbr": "UPenn;UFMG",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Philadelphia;MG",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Brazil"
    },
    {
        "id": "9636719",
        "title": "Multi-robot Task Assignment for Aerial Tracking with Viewpoint Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of assigning a team of drones to autonomously capture a set desired shots of a dynamic target in the presence of obstacles. We present a two-stage planning pipeline that generates offline an assignment of drone to shots and locally optimizes online the viewpoint. Given desired shot parameters, the high-level planner uses a visibility heuristic to predict good times for capturing each shot and uses an Integer Linear Program to compute drone assignments. An online Model Predictive Control algorithm uses the assignments as reference to capture the shots. The algorithm is validated in hardware with a pair of drones and a remote controlled car.",
        "primary_area": "",
        "author": "Aaron Ray;Alyssa Pierson;Hai Zhu;Javier Alonso-Mora;Daniela Rus;Aaron Ray;Alyssa Pierson;Hai Zhu;Javier Alonso-Mora;Daniela Rus",
        "authorids": "/37086573512;/37085345711;/37086618561;/38271697300;/37279652300;/37086573512;/37085345711;/37086618561;/38271697300;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Cognitive Robotics, Delft University of Technology, Delft, Netherlands; Cognitive Robotics, Delft University of Technology, Delft, Netherlands; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636719/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4000043323824611541&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Delft University of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;Cognitive Robotics",
        "aff_unique_url": "https://www.mit.edu;https://www.tudelft.nl",
        "aff_unique_abbr": "MIT;TUDelft",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Cambridge;Delft",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "United States;Netherlands"
    },
    {
        "id": "9636857",
        "title": "Multi-scale Laplacian-based FMM for shape control",
        "track": "main",
        "status": "Poster",
        "abstract": "Shape control has become a prominent research field as it enables the automation of tasks in many applications. Overall, deforming an object to a desired target shape by using few grippers is a major challenge. The limited information about the object dynamics, the need to combine small and large deformations in order to achieve certain target shapes and the non-linear nature of most deformable objects are factors that significantly hamper shape control performance. In this paper, we propose a shape control method for multi-robot manipulation of large-strain deformable objects. Our approach is based on multi-scale Laplacian descriptors that feed an FMM (Fast Marching Method) for elastic shape contour matching. The FMM's resulting path and the Laplacian operator are used to define a control strategy for the robot grippers. Simulation experiments carried out with an ARAP (As Rigid As Possible) deformation model provide satisfactory results.",
        "primary_area": "",
        "author": "Ignacio Cuiral-Zueco;Gonzalo L\u00f3pez-Nicol\u00e1s;Ignacio Cuiral-Zueco;Gonzalo L\u00f3pez-Nicol\u00e1s",
        "authorids": "/37088489245;/37546413100;/37088489245;/37546413100",
        "aff": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n, Universidad de Zaragoza, Spain; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n, Universidad de Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636857/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8664403907747801948&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universidad de Zaragoza",
        "aff_unique_dep": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Arag\u00f3n",
        "aff_unique_url": "https://www.unizar.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9636464",
        "title": "Multi-sensor Fusion Incorporating Adaptive Transformation for Reconfigurable Pavement Sweeping Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "An efficient sensors fusion framework in an autonomous robot is necessary for various functions like object detection and perception enhancement. Multi-sensor calibration techniques are used to fuse multiple static sensors into a single frame of reference. However, for reconfigurable robots, sensors can change pose during reconfiguration need a robust adaptive sensor fusion to account for the relative change in sensor position and orientation. We propose an adaptive sensor fusion framework that can be implemented on any reconfiguration robot to adjust calibration parameters. Our paper formulated an adaptive sensor fusion method, implemented it in real-time on an autonomous reconfigurable pavement sweeping robot called Panthera, and demonstrated qualitatively the accuracy of the proposed sensor fusion framework for environment perception during robot reconfiguring on the pavement.",
        "primary_area": "",
        "author": "A.P. Povendhan;Lim Yi;A. A. Hayat;Anh Vu Le;K. L. J. Kai;B. Ramalingam;M. R. Elara;A.P. Povendhan;Lim Yi;A. A. Hayat;Anh Vu Le;K. L. J. Kai;B. Ramalingam;M. R. Elara",
        "authorids": "/37089000428;/37088429249;/37085563101;/37086917297;/37089193925;/37088490181;/37546093700;/37089000428;/37088429249;/37085563101;/37086917297;/37089193925;/37088490181;/37546093700",
        "aff": "Research Fellow at SUTD in ROAR Lab; Research Fellow at SUTD in ROAR Lab; Research Fellow at SUTD in ROAR Lab; Research Fellow at SUTD in ROAR Lab; Research Fellow at SUTD in ROAR Lab; Research Fellow at SUTD in ROAR Lab; Research Fellow at SUTD in ROAR Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636464/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2405998844068269702&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Singapore University of Technology and Design",
        "aff_unique_dep": "ROAR Lab",
        "aff_unique_url": "https://www.sutd.edu.sg",
        "aff_unique_abbr": "SUTD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9635994",
        "title": "Multi-view Fusion for Multi-level Robotic Scene Understanding",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a system for multi-level scene awareness for robotic manipulation. Given a sequence of camera-inhand RGB images, the system calculates three types of information: 1) a point cloud representation of all the surfaces in the scene, for the purpose of obstacle avoidance. 2) the rough pose of unknown objects from categories corresponding to primitive shapes (e.g., cuboids and cylinders), and 3) full 6-DoF pose of known objects. By developing and fusing recent techniques in these domains, we provide a rich scene representation for robot awareness. We demonstrate the importance of each of these modules, their complementary nature, and the potential benefits of the system in the context of robotic manipulation.",
        "primary_area": "",
        "author": "Yunzhi Lin;Jonathan Tremblay;Stephen Tyree;Patricio A. Vela;Stan Birchfield;Yunzhi Lin;Jonathan Tremblay;Stephen Tyree;Patricio A. Vela;Stan Birchfield",
        "authorids": "/37088506366;/37086455314;/37074894100;/37329553400;/37371627300;/37088506366;/37086455314;/37074894100;/37329553400;/37371627300",
        "aff": "Georgia Institute of Technology; NVIDIA; NVIDIA; Georgia Institute of Technology; NVIDIA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635994/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5164833132292992074&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Georgia Institute of Technology;NVIDIA",
        "aff_unique_dep": ";NVIDIA Corporation",
        "aff_unique_url": "https://www.gatech.edu;https://www.nvidia.com",
        "aff_unique_abbr": "Georgia Tech;NVIDIA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636237",
        "title": "Multiclass Terrain Classification using Sound and Vibration from Mobile Robot Terrain Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Offroad mobile robot perception systems must be able to learn robust terrain classification models. Models built from computer vision often fail in their ability to generalize to new environments where appearance characteristics change. Sound and vibration signals from robot-terrain interaction can be used to classify the terrain from characteristics that vary less between environments. Previous work using sound and vibration for terrain classification has only classified ground terrain types. We extend here to building a 7-class multiclass classifier that can classify both ground and above-ground terrain types in challenging outdoor off-road settings, thereby increasing the semantic richness of the terrain classification. Our contributions include: 1) We instrument a robotic vehicle with a variety of sound and vibration sensors mounted at different vehicle locations and directions, as well as color cameras. 2) We collect interactive and visual field data from many outdoor off-road sites with different environments. 3) We build multiclass classifiers for different combinations of sound and vibration signals, and we autonomously learn the optimal signal combination. We compare this against a single microphone from our previous work [1]. 4) We benchmark both of these results against a state-of-the art vision system. All of these multiclass classifiers are tested at different locations from where they are trained. By using one microphone instead of the vision system, we increase balanced accuracy from 70% to 82%. By using the optimal sound and vibration combination, we increase balanced accuracy from 82% to 87%. All four of these contributions are field robotics in nature: we build a sensor system and then we use that system to collect new field data that allows for a comparative evaluation of different modules of the system. Such datasets do not exist that include these varying sensors on varying field terrain. We are also contributing to machine learning research by ... Show More",
        "primary_area": "",
        "author": "Jacqueline Libby;Anthony Stentz;Jacqueline Libby;Anthony Stentz",
        "authorids": "/37967901700;/37281481700;/37967901700;/37281481700",
        "aff": "Jacqueline Libby; Anthony Stentz",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636237/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12812954415607667568&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9636437",
        "title": "Multifunctional Robotic Glove with Active-Passive Training Modes for Hand Rehabilitation and Assistance",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robotic gloves have shown great advantages in assisting individuals with hand pathologies to perform continuous exercises to restore their hand functions, which could considerably accelerate the rehabilitation process and reduce the costs. However, single rehabilitation mode, difficulty in achieving multiple degrees-of-freedom (DoF) motion, and the lack of high-fidelity feedback still challenge the development of soft robotic gloves. In this paper, we propose a novel design of a robotic glove based on soft-rigid hybrid joint actuators and minimal clutches. We first introduce structures and working principles of the proposed bending joint actuator in detail and then characterize the single joint actuator. Furthermore, we present a performance evaluation of the whole robotic glove in both active and passive modes. Preliminary experimental results showed that (1) in the active training mode, the tested human hand\u2019s muscle effort needed to conduct gross finger flexion increased from 11.16% to 42.60% of the maximum value when the air pressure inside the minimal clutches changed from 0 kPa to 200 kPa; (2) in the passive mode, the 10-DoF robotic glove could assist the tested hand to perform various training exercises and grasp various objects with different hand postures. This paper focuses on the integrated design of multi-DoF structures and variable stiffness mechanisms, which will have an impact on the development of multifunctional soft robots and wearable devices.",
        "primary_area": "",
        "author": "Yongkang Jiang;Diansheng Chen;Junlin Ma;Zhe Liu;Yazhe Luo;Jian Li;Yingtian Li;Yongkang Jiang;Diansheng Chen;Junlin Ma;Zhe Liu;Yazhe Luo;Jian Li;Yingtian Li",
        "authorids": "/37086353777;/37400197000;/37088599701;/37086357302;/37089194986;/37086414611;/37085702749;/37086353777;/37400197000;/37088599701;/37086357302;/37089194986;/37086414611;/37085702749",
        "aff": "Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Institute of Robotics, Beihang University, Beijing, China; Institute of Robotics, Beihang University, Beijing, China; Institute of Robotics, Beihang University, Beijing, China; Institute of Robotics, Beihang University, Beijing, China; National Research Center for Rehabilitation Technical Aids, Beijing, China; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636437/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17396810852895166629&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;2;0",
        "aff_unique_norm": "Shenzhen Institute of Advanced Technology;Beihang University;National Research Center for Rehabilitation Technical Aids",
        "aff_unique_dep": "Chinese Academy of Sciences;Institute of Robotics;",
        "aff_unique_url": "http://www.siat.cas.cn;http://www.buaa.edu.cn;",
        "aff_unique_abbr": "SIAT;BUAA;",
        "aff_campus_unique_index": "0;1;1;1;1;0",
        "aff_campus_unique": "Shenzhen;Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636394",
        "title": "Multimodal VAE Active Inference Controller",
        "track": "main",
        "status": "Poster",
        "abstract": "Active inference, a theoretical construct inspired by brain processing, is a promising alternative to control artificial agents. However, current methods do not yet scale to high-dimensional inputs in continuous control. Here we present a novel active inference torque controller for industrial arms that maintains the adaptive characteristics of previous proprioceptive approaches but also enables large-scale multimodal integration (e.g., raw images). We extended our previous mathematical formulation by including multimodal state representation learning using a linearly coupled multimodal variational autoencoder. We evaluated our model on a simulated 7DOF Franka Emika Panda robot arm and compared its behavior with a previous active inference baseline and the Panda built-in optimized controller. Results showed improved tracking and control in goal-directed reaching due to the increased representation power, high robustness to noise and adaptability in changes on the environmental conditions and robot parameters without the need to relearn the generative models nor parameters retuning.",
        "primary_area": "",
        "author": "Cristian Meo;Pablo Lanillos;Cristian Meo;Pablo Lanillos",
        "authorids": "/37089194346;/37681228000;/37089194346;/37681228000",
        "aff": "Department of Cognitive Robotics, Faculty of Mechanical Engineering, Delft University of Technology, Delft, The Netherlands; Department of Artificial Intelligence, Donders Institute for Brain, Cognition and Behavior, Radboud University, Nijmegen, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636394/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9000896283135945891&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Delft University of Technology;Radboud University",
        "aff_unique_dep": "Department of Cognitive Robotics;Department of Artificial Intelligence",
        "aff_unique_url": "https://www.tudelft.nl;https://www.ru.nl",
        "aff_unique_abbr": "TUDelft;RU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Delft;Nijmegen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9636221",
        "title": "Multitask Variational Autoencoding of Human-to-Human Object Handover",
        "track": "main",
        "status": "Poster",
        "abstract": "Assistive robots that operate alongside humans require the ability to understand and replicate human behaviours during a handover. A handover is defined as a joint action between two participants in which a giver hands an object over to the receiver. In this paper, we present a method for learning human-to-human handovers observed from motion capture data. Given the giver and receiver pose from a single timestep, and the object label in the form of a word embedding, our Multitask Variational Autoencoder jointly forecasts their pose as well as the orientation of the object held by the giver at handover. Our method is in large contrast to existing works for human pose forecasting that employ deep autoregressive models requiring a sequence of inputs. Furthermore, our method is novel in that it learns both the human pose and object orientation in a joint manner. Experimental results on the publicly available Handover Orientation and Motion Capture Dataset show that our proposed method outperforms the autoregressive baselines for handover pose forecasting by approximately 20% while being on-par for object orientation prediction with a runtime that is 5x faster. a",
        "primary_area": "",
        "author": "Haziq Razali;Yiannis Demiris;Haziq Razali;Yiannis Demiris",
        "authorids": "/37086341171;/37296338900;/37086341171;/37296338900",
        "aff": "Dept of EEE, Personal Robotics Laboratory, Imperial College London, UK; Dept of EEE, Personal Robotics Laboratory, Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636221/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=545266163317448490&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Dept of EEE",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636052",
        "title": "Multitask and Transfer Learning of Geometric Robot Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "When a learning solution is needed for different robots, a model is often trained for each robot geometry, even if the robotic task is the same and the robots are structurally similar. In this paper, we address the problem of transfer learning of swept volume predictors for the motion of articulated robots with similar geometric structure. The swept volume is a scalar value corresponding to the space occupied by an entire motion of the robot. Swept volume has many applications, including being an ideal distance measure for sampling based motion planners, but it is expensive to compute. We address this learning problem through a multitask network where a common input is used to learn multiple related tasks. In this work a single network learns the kinematic-geometric information common among robots. In order to identify the properties of our multitask network favorable for transfer, we evaluate transfer properties of several shared layers, number of robots in multitask training, and feature layers. We demonstrate positive transfer results with a training set that is a fraction of the data size used in the multitask and baseline training. All the robots considered are 7-DOF manipulators with links with a variety of lengths and shapes. We also present a study of the weights and activations of the trained networks that show high correlation with the transferability patterns we observed.",
        "primary_area": "",
        "author": "Satomi Sugaya;Mohammad R. Yousefi;Andrew R. Ferdinand;Marco Morales;Lydia Tapia;Satomi Sugaya;Mohammad R. Yousefi;Andrew R. Ferdinand;Marco Morales;Lydia Tapia",
        "authorids": "/37087323775;/37088689191;/37089009677;/37701227800;/37564283100;/37087323775;/37088689191;/37089009677;/37701227800;/37564283100",
        "aff": "Department of Computer Science, University of New Mexico, Albuquerque, USA; Department of Computer Science, University of New Mexico, Albuquerque, USA; Department of Physics, University of Colorado Boulder, Boulder, CO, USA; University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Computer Science, University of New Mexico, Albuquerque, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636052/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:judjO6kuGyAJ:scholar.google.com/&scioq=Multitask+and+Transfer+Learning+of+Geometric+Robot+Motion&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "University of New Mexico;University of Colorado Boulder;University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Computer Science;Department of Physics;",
        "aff_unique_url": "https://www.unm.edu;https://www.colorado.edu;https://illinois.edu",
        "aff_unique_abbr": "UNM;CU Boulder;UIUC",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Albuquerque;Boulder;Urbana",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636696",
        "title": "Muscle synergies enable accurate joint moment prediction using few electromyography sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "There is an increasing demand for accurate prediction of joint moments using wearable sensors for robotic exoskeletons to achieve precise control and for rehabilitation care to remotely monitor users\u2019 condition. In this study, we used electromyography (EMG) signals to first identify muscle synergies, then used them to train of a long short-term memory network to predict knee joint moments during walking. Kinematics, ground reaction forces and EMG from 10 muscles on the right limb were collected from 6 able-bodied subjects during normal gait. Between 4 and 6 muscle synergies were extracted from the EMG signals, generating two outputs - the muscle synergies weight matrix and the time-dependent muscle synergies action signals. The muscle synergies action signals and measured knee joint moments from inverse dynamics were then used as inputs to train the joint moment prediction model using a long short-term memory network. For testing, between 4 and 7 EMG signals were used to estimate the muscle synergies action signals with the extracted muscle synergies weights matrix. The estimated muscle synergies action signals were then used to predict knee joint moments. Knee joint moments were also predicted directly from all 10 EMGs, then from 4-7 EMG signals using another long short-term memory network. Prediction accuracy from the synergies-trained network vs. the EMG-trained network were compared, using the same number of EMG signals in each. Prediction error with respect to moments measured via inverse dynamics was computed for both networks. Knee moments predicted with as few as 4 EMGs was at least as accurate as moments predicted from all 10 EMGs when muscle synergies were exploited. Predicted knee moments from muscle synergies achieved an average of 4.63% root mean square error from 4 EMG signals, which was lower than error when predicted directly from 4 EMG signals (5.63%).",
        "primary_area": "",
        "author": "Yi-Xing Liu;Elena M. Gutierrez-Farewik;Yi-Xing Liu;Elena M. Gutierrez-Farewik",
        "authorids": "/37088887242;/37086601009;/37088887242;/37086601009",
        "aff": "Department of Engineering Mechanics and KTH BioMEx Center, KTH MoveAbility Lab, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Women\u2019s and Children\u2019s Health, Karolinska Institutet, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636696/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4045097732419719324&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "KTH Royal Institute of Technology;Karolinska Institutet",
        "aff_unique_dep": "Department of Engineering Mechanics;Department of Women\u2019s and Children\u2019s Health",
        "aff_unique_url": "https://www.kth.se;https://ki.se",
        "aff_unique_abbr": "KTH;KI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9636780",
        "title": "Muscle-reflex model of human locomotion entrains to mechanical perturbations",
        "track": "main",
        "status": "Poster",
        "abstract": "Prior experiments have shown that human gait synchronizes to periodic torque pulses applied about the hip and ankle joints by robotic exoskeletons. Importantly, entrainment occurred even when the pulse period differed slightly from the user\u2019s preferred stride period, making it a viable approach to increase gait speed. As gait speed is an important outcome of gait therapy, gait entrainment to mechanical perturbations may serve as a promising new method of robot-aided therapy. Still, an understanding of the underlying neuromechanical processes that give rise to gait entrainment is needed to fully evaluate its therapeutic potential. To gain such insight, the goal of this paper was to evaluate whether an existing neuromechanical model of human locomotion exhibited entrainment behavior similar to that observed in the prior human experiments. Simulation results showed that the model entrained to pulses applied at both the ankle and hip joints. The convergence of relative phase between model gait and hip perturbations was similar to that observed with the human gait, but differed slightly for ankle perturbations. Thus, models that can more accurately describe neuromechanical interactions between human gait and robotic exoskeletons are still needed. Nevertheless, the simulation results support the notion that the limit-cycle behavior observed during locomotion does not require supra-spinal control or a self-sustaining oscillatory neural network, which has important implications for improving gait therapy.",
        "primary_area": "",
        "author": "Banu Abdikadirova;Jongwoo Lee;Neville Hogan;Meghan E. Huber;Banu Abdikadirova;Jongwoo Lee;Neville Hogan;Meghan E. Huber",
        "authorids": "/37088537667;/37085770535;/37298867300;/37085363999;/37088537667;/37085770535;/37298867300;/37085363999",
        "aff": "Department of Mechanical and Industrial Engineering, University of Massachusetts Amherst, Amherst, MA, USA; Departments of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Brain and Cognitive Sciences, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical and Industrial Engineering, University of Massachusetts Amherst, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636780/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5451431209157521539&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Massachusetts Amherst;Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Industrial Engineering;Departments of Mechanical Engineering",
        "aff_unique_url": "https://www.umass.edu;https://web.mit.edu",
        "aff_unique_abbr": "UMass Amherst;MIT",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Amherst;Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636802",
        "title": "NMPC-MP: Real-time Nonlinear Model Predictive Control for Safe Motion Planning in Manipulator Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion control and planning for the manipulator are critical components in manipulator teleoperation. Online (real-time) motion control is challenging for active obstacle avoidance and often results in fluctuating and unsafe motion. Offline motion planning, on the other hand, generates precise and secure trajectories for complex manipulation. In this paper, a real-time nonlinear model predictive control based motion planner (NMPC-MP) is designed for teleoperated manipulation. In contrast to traditional NMPC-based approaches, our model considers a complex environment with dynamic obstacles. Our multi-threaded NMPC-MP allows for real-time planning, including dynamic objects. We evaluate our approach both in a simulated environment and with real-world experiments using the Kinova\u00ae Movo platform. The comparison to state-of-the-art approaches (e.g., RRT-Connect, CHOMP, and STOMP) shows a significant improvement in real-time motion planning using NMPC-MP. In real-world tests, the proposed planner was applied on a human-shaped dual manipulator setup. Our results show that the NMPC-MP runs in real-time and generates smooth and reliable trajectories. The experiments validate that the planner is able to precisely track active goals from the teleoperator while avoiding self-collision and obstacles.",
        "primary_area": "",
        "author": "Siqi Hu;Edwin Babaians;Mojtaba Karimi;Eckehard Steinbach;Siqi Hu;Edwin Babaians;Mojtaba Karimi;Eckehard Steinbach",
        "authorids": "/37089196124;/37085653235;/38667191100;/37273225600;/37089196124;/37085653235;/38667191100;/37273225600",
        "aff": "Department of Electrical and Computer Engineering, Chair of Media Technology (LMT) and Munich Institute of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Germany; Department of Electrical and Computer Engineering, Chair of Media Technology (LMT) and Munich Institute of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Germany; Department of Electrical and Computer Engineering, Chair of Media Technology (LMT) and Munich Institute of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Germany; Department of Electrical and Computer Engineering, Chair of Media Technology (LMT) and Munich Institute of Robotics and Machine Intelligence (MSRM), Technical University of Munich (TUM), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636802/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14023648473860994586&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636640",
        "title": "NYU-VPR: Long-Term Visual Place Recognition Benchmark with View Direction and Data Anonymization Influences",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual place recognition (VPR) is critical in not only localization and mapping for autonomous driving vehicles, but also assistive navigation for the visually impaired population. To enable a long-term VPR system on a large scale, several challenges need to be addressed. First, different applications could require different image view directions, such as front views for self-driving cars while side views for the low vision people. Second, VPR in metropolitan scenes can often cause privacy concerns due to the imaging of pedestrian and vehicle identity information, calling for the need for data anonymization before VPR queries and database construction. Both factors could lead to VPR performance variations that are not well understood yet. To study their influences, we present the NYU-VPR dataset that contains more than 200,000 images over a 2km\u00d72km area near the New York University campus, taken within the whole year of 2016. We present benchmark results on several popular VPR algorithms showing that side views are significantly more challenging for current VPR methods while the influence of data anonymization is almost negligible, together with our hypothetical explanations and in-depth analysis.",
        "primary_area": "",
        "author": "Diwei Sheng;Yuxiang Chai;Xinru Li;Chen Feng;Jianzhe Lin;Claudio Silva;John-Ross Rizzo;Diwei Sheng;Yuxiang Chai;Xinru Li;Chen Feng;Jianzhe Lin;Claudio Silva;John-Ross Rizzo",
        "authorids": "/37089194297;/37089196657;/37089195318;/37086391326;/37086180037;/37275249200;/37086000958;/37089194297;/37089196657;/37089195318;/37086391326;/37086180037;/37275249200;/37086000958",
        "aff": "New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636640/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8176771779705200663&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Brooklyn",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636471",
        "title": "NaturalNets: Simplified Biological Neural Networks for Learning Complex Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new neural network architecture, called NaturalNet, which uses a simplified biological neuron model and consists of a set of nonlinear ordinary differential equations. We model the membrane potential of each neuron by integrating the in-flowing currents, but we do not consider ion channels, nor individual spikes. To keep the membrane potential within a defined value range, we introduce a suitable clipping mechanism. With our approach, we aim to develop agents solving complex tasks by providing a higher biological plausibility than commonly used neural networks for deep learning applications, while also offering low computational complexity to enable fast training. To demonstrate the learning capabilities of NaturalNets, we use the virtual robotic environments of the OpenAI Gym framework, a widely-used toolkit for developing and comparing reinforcement learning algorithms. We compared a variety of different widespread neural network architectures, including long short-term memory (LSTM), gated recurrent units (GRUs), feedforward, and Elman networks. Our experiments show that NaturalNets were able to perform well for all considered virtual robotic control tasks, where we apply the covariance matrix adaptation evolutionary strategy (CMAES) for training.",
        "primary_area": "",
        "author": "Daniel Zimmermann;Bj\u00f6rn J\u00fcrgens;Patrick Deubel;Anne Koziolek;Daniel Zimmermann;Bj\u00f6rn J\u00fcrgens;Patrick Deubel;Anne Koziolek",
        "authorids": "/37089197182;/37089196706;/37089194048;/38507196100;/37089197182;/37089196706;/37089194048;/38507196100",
        "aff": "FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; FZI Research Center for Information Technology, Karlsruhe, Germany; Institute for Program Structures and Data Organization, Karlsruhe Institute of Technology, Karlsruhe",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636471/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14372065283564503978&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "FZI Research Center for Information Technology;Karlsruhe Institute of Technology",
        "aff_unique_dep": ";Institute for Program Structures and Data Organization",
        "aff_unique_url": "https://www.fzi.de;https://www.kit.edu",
        "aff_unique_abbr": "FZI;KIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636185",
        "title": "NavTuner: Learning a Scene-Sensitive Family of Navigation Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "The advent of deep learning has inspired research into end-to-end learning for a variety of problem domains in robotics. For navigation, the resulting methods may not have the generalization properties desired let alone match the performance of traditional methods. Instead of learning a navigation policy, we explore learning an adaptive policy in the parameter space of an existing navigation module. Having adaptive parameters provides the navigation module with a family of policies that can be dynamically reconfigured based on the local scene structure and addresses the common assertion in machine learning that engineered solutions are inflexible. Of the methods tested, reinforcement learning (RL) is shown to provide a significant performance boost to a modern navigation method through reduced sensitivity of its success rate to environmental clutter. The outcomes indicate that RL as a meta-policy learner, or dynamic parameter tuner, effectively robustifies algorithms sensitive to external, measurable nuisance factors.",
        "primary_area": "",
        "author": "Haoxin Ma;Justin S. Smith;Patricio A. Vela;Haoxin Ma;Justin S. Smith;Patricio A. Vela",
        "authorids": "/37089195760;/37085636293;/37329553400;/37089195760;/37085636293;/37329553400",
        "aff": "College of Computing, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636185/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3643851675727922067&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "College of Computing",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635983",
        "title": "Neural Motion Prediction for In-flight Uneven Object Catching",
        "track": "main",
        "status": "Poster",
        "abstract": "In-flight objects capture is extremely challenging. The robot is required to complete trajectory prediction, interception position calculation and motion planning within tens of milliseconds. As in-flight uneven objects are affected by various kinds of forces, which leads to the time-varying acceleration, motion prediction for them is difficult. In order to compensate the system\u2019s non-linearity, we propose using a recurrent neural network model, which we call the Neural Acceleration Estimator (NAE), to estimate the varying acceleration by observing a small fragment of previous deflected trajectory without any prior information. Moreover, end-to-end training with Differantiable Filter (NAE-DF) gives a supervision for measurement uncertainty and further improves the prediction accuracy. Experimental results show that motion prediction with NAE and NAE-DF is superior to other methods and has a good generalization performance on unseen objects. We test our methods on a robot, performing velocity control in real world and respectively achieve 83.3% and 86.7% success rate on a ploy urethane banana and a gourd. We also release an object in-flight dataset containing 1,500 trajectorys for uneven objects, which can be found on the project website:https://sites.google.com/view/neural-motion-prediction.",
        "primary_area": "",
        "author": "Hongxiang Yu;Dashun Guo;Huan Yin;Anzhe Chen;Kechun Xu;Zexi Chen;Minhang Wang;Qimeng Tan;Yue Wang;Rong Xiong;Hongxiang Yu;Dashun Guo;Huan Yin;Anzhe Chen;Kechun Xu;Zexi Chen;Minhang Wang;Qimeng Tan;Yue Wang;Rong Xiong",
        "authorids": "/37086345520;/37089196655;/37086355830;/37089194727;/37088916597;/37088601253;/37088662584;/37086355678;/37072299700;/37271511300;/37086345520;/37089196655;/37086355830;/37089194727;/37088916597;/37088601253;/37088662584;/37086355678;/37072299700;/37271511300",
        "aff": "State Key Laboratory of Industrial Control and Technology, and the Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, and the Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, and the Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, and the Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, and the Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, and the Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Application Innovate Lab, Huawei Incorporated Company, P.R. China; Beijing Key Laboratory of Intelligent Space Robotic System Technology and Applications, Beijing Institute of Spacecraft System Engineering CAST, Beijing, P.R. China; State Key Laboratory of Industrial Control and Technology, and the Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; State Key Laboratory of Industrial Control and Technology, and the Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635983/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3564239843339203798&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;1;2;0;0",
        "aff_unique_norm": "Zhejiang University;Huawei;Beijing Institute of Spacecraft System Engineering",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology, Institute of Cyber-Systems and Control;Application Innovate Lab;Beijing Key Laboratory of Intelligent Space Robotic System Technology and Applications",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.huawei.com;",
        "aff_unique_abbr": "ZJU;Huawei;CAST",
        "aff_campus_unique_index": "0;0;0;0;0;0;2;0;0",
        "aff_campus_unique": "Hangzhou;;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636089",
        "title": "Neurointerface implemented with Oscillator Motifs",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a definition of a neurointerface architecture combined from two main parts (1) neuroport (a hardware device) that implements a neuro protocol, generated and managed by a (2) neuroterminal (a software). The proposed architecture was created by analogy with OSI network architecture. We also present the neuroterminal as an oscillator motif real-time neurosimulation and results of the comparison of a bio-plausible motor pattern generated by oscillator motifs with square pulses of 20 \u2013 40 Hz used as the neuro protocol for the output neuroport and measured their discomfort rate and efficacy according to an angle of subject fingers deflection. We determined that the most effective is the five oscillator motifs generated pattern for a median nerve stimulation, whereas for a muscle simulation 20 and 40 Hz are more effective. We indicate that the oscillator motif generated pattern feels more natural than square pulses 20 \u2013 40 Hz, which feel like a spasm.",
        "primary_area": "",
        "author": "Max Talanov;Alina Suleimanova;Alexey Leukhin;Yulia Mikhailova;Alexander Toschev;Alena Militskova;Igor Lavrov;Evgeni Magid;Max Talanov;Alina Suleimanova;Alexey Leukhin;Yulia Mikhailova;Alexander Toschev;Alena Militskova;Igor Lavrov;Evgeni Magid",
        "authorids": "/37085413009;/37088873225;/37089197160;/37089195214;/37086311129;/37089196719;/37705503300;/37590248000;/37085413009;/37088873225;/37089197160;/37089195214;/37086311129;/37089196719;/37705503300;/37590248000",
        "aff": "Neuromorphic computing and Neurosimulations laboratory, ITIS, Kazan Federal University, Russian Federation; Neuromorphic computing and Neurosimulations laboratory, ITIS, Kazan Federal University, Russian Federation; Neuromorphic computing and Neurosimulations laboratory, ITIS, Kazan Federal University, Russian Federation; Neuromorphic computing and Neurosimulations laboratory, ITIS, Kazan Federal University, Russian Federation; Neuromorphic computing and Neurosimulations laboratory, ITIS, Kazan Federal University, Russian Federation; Institute of Fundamental Medicine and Biology, Kazan Federal University, Russian Federation; Department of Neurologic Surgery, Department of Physiology and Biomedical Engineering, Department of Neurology, Mayo Clinic, USA; Intelligent Robotic Systems Laboratory (LIRS), ITIS, Kazan Federal University, Russian Federation",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636089/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5729112850055785121&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;1;0",
        "aff_unique_norm": "Kazan Federal University;Mayo Clinic",
        "aff_unique_dep": "Neuromorphic computing and Neurosimulations laboratory, ITIS;Department of Neurologic Surgery",
        "aff_unique_url": "https://kpfu.ru;https://www.mayoclinic.org",
        "aff_unique_abbr": ";Mayo Clinic",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Kazan",
        "aff_country_unique_index": "0;0;0;0;0;0;1;0",
        "aff_country_unique": "Russian Federation;United States"
    },
    {
        "id": "9636322",
        "title": "New Metrics for Industrial Depth Sensors Evaluation for Precise Robotic Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Precise perception is one of the key enablers of autonomous robotic operations. The right selection of sensors significantly influences the overall performance of the system. This paper provides a systematic approach for evaluation of various sensors available on the market. The main focus is to assess the performance in use cases of short to medium distance operations, especially relevant for precise manipulation and/or quality control. The evaluation is based solely on depth data (point clouds). We use six metrics to evaluate the sensors and propose a novel approach for low-cost fabrication of benchmark targets. The evaluation experiments are conducted on different materials to simulate various industrial environments. Our results provide a qualitative and quantitative comparison of different characteristics of various sensors and can be used to select an appropriate device for specific conditions.",
        "primary_area": "",
        "author": "Konrad P Cop;Arne Peters;Bare L \u017dagar;Daniel Hettegger;Alois C Knoll;Konrad P Cop;Arne Peters;Bare L \u017dagar;Daniel Hettegger;Alois C Knoll",
        "authorids": "/37086454788;/37087466503;/37089195933;/37089197581;/37276234100;/37086454788;/37087466503;/37089195933;/37089197581;/37276234100",
        "aff": "Department of Informatics, Technical University of Munich (TUM), Garching, Germany; Department of Informatics, Technical University of Munich (TUM), Garching, Germany; Department of Informatics, Technical University of Munich (TUM), Garching, Germany; Department of Informatics, Technical University of Munich (TUM), Garching, Germany; Department of Informatics, Technical University of Munich (TUM), Garching, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636322/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1387909556503400336&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Informatics",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Garching",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636191",
        "title": "NimbRo Avatar: Interactive Immersive Telepresence with Force-Feedback Telemanipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic avatars promise immersive teleoperation with human-like manipulation and communication capabilities. We present such an avatar system, based on the key components of immersive 3D visualization and transparent force-feedback telemanipulation. Our avatar robot features an anthropomorphic bimanual arm configuration with dexterous hands. The remote human operator drives the arms and fingers through an exoskeleton-based operator station, which provides force feedback both at the wrist and for each finger. The robot torso is mounted on a holonomic base, providing locomotion capability in typical indoor scenarios, controlled using a 3D rudder device. Finally, the robot features a 6D movable head with stereo cameras, which stream images to a VR HMD worn by the operator. Movement latency is hidden using spherical rendering. The head also carries a telepresence screen displaying a synthesized image of the operator with facial animation, which enables direct interaction with remote persons. We evaluate our system successfully both in a user study with untrained operators as well as a longer and more complex integrated mission. We discuss lessons learned from the trials and possible improvements.",
        "primary_area": "",
        "author": "Max Schwarz;Christian Lenz;Andre Rochow;Michael Schreiber;Sven Behnke;Max Schwarz;Christian Lenz;Andre Rochow;Michael Schreiber;Sven Behnke",
        "authorids": "/37085593752;/38468570500;/37088600649;/37298914700;/37295987100;/37085593752;/38468570500;/37088600649;/37298914700;/37295987100",
        "aff": "Autonomous Intelligent Systems Group of University of Bonn, Germany; Autonomous Intelligent Systems Group of University of Bonn, Germany; Autonomous Intelligent Systems Group of University of Bonn, Germany; Autonomous Intelligent Systems Group of University of Bonn, Germany; Autonomous Intelligent Systems Group of University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636191/",
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3996470204211263941&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Autonomous Intelligent Systems Group",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636820",
        "title": "Non-Prehensile Manipulation of Cuboid Objects Using a Catenary Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Transporting objects using quadrotors with cables has been widely studied in the literature. However, most of those approaches assume that the cables are previously attached to the load by human intervention. In tasks where multiple objects need to be moved, the efficiency of the robotic system is constrained by the requirement of manual labor. Our approach uses a non-stretchable cable connected to two quadrotors, which we call the catenary robot, that fully automates the transportation task. Using the cable, we can roll and drag the cuboid object (box) on planar surfaces. Depending on the surface type, we choose the proper action, dragging for low friction, and rolling for high friction. Therefore, the transportation process does not require any human intervention as we use the cable to interact with the box without requiring fastening. We validate our control design in simulation and with actual robots, where we show them rolling and dragging boxes to track desired trajectories.",
        "primary_area": "",
        "author": "Gustavo A. Cardona;Diego S. D\u2019Antonio;Cristian-Ioan Vasile;David Salda\u00f1a;Gustavo A. Cardona;Diego S. D\u2019Antonio;Cristian-Ioan Vasile;David Salda\u00f1a",
        "authorids": "/37085799776;/37088760719;/37085532895;/38543033800;/37085799776;/37088760719;/37085532895;/38543033800",
        "aff": "Autonomous and Intelligent Robotics Laboratory -AIRLab- at Lehigh University, PA, USA; Autonomous and Intelligent Robotics Laboratory -AIRLab- at Lehigh University, PA, USA; Autonomous and Intelligent Robotics Laboratory -AIRLab- at Lehigh University, PA, USA; Autonomous and Intelligent Robotics Laboratory -AIRLab- at Lehigh University, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636820/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11005901621663648097&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Lehigh University",
        "aff_unique_dep": "Autonomous and Intelligent Robotics Laboratory",
        "aff_unique_url": "https://www.lehigh.edu",
        "aff_unique_abbr": "Lehigh",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "PA",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636107",
        "title": "Non-local Graph Convolutional Network for joint Activity Recognition and Motion Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "3D skeleton-based motion prediction and activity recognition are two interwoven tasks in human behaviour analysis. In this work, we propose a motion context modeling methodology that provides a new way to combine the advantages of both graph convolutional neural networks and recurrent neural networks for joint human motion prediction and activity recognition. Our approach is based on using an LSTM encoder-decoder and a non-local feature extraction attention mechanism to model the spatial correlation of human skeleton data and temporal correlation among motion frames. The proposed network can easily include two output branches, one for Activity Recognition and one for Future Motion Prediction, which can be jointly trained for enhanced performance. Experimental results on Human 3.6M, CMU Mocap and NTU RGB-D datasets show that our proposed approach provides the best prediction capability among baseline LSTM-based methods, while achieving comparable performance to other state-of-the-art methods.",
        "primary_area": "",
        "author": "Dianhao Zhang;Ngo Anh Vien;Mien Van;Se\u00e1n McLoone;Dianhao Zhang;Ngo Anh Vien;Mien Van;Se\u00e1n McLoone",
        "authorids": "/37089194282;/37838848600;/37086013765;/37268007900;/37089194282;/37838848600;/37086013765;/37268007900",
        "aff": "Queen\u2019s University Belfast, UK; Bosch Center for Artificial Intelligence, Germany; Queen\u2019s University Belfast, UK; Queen\u2019s University Belfast, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636107/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11786580313520532171&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Queen's University Belfast;Bosch Center for Artificial Intelligence",
        "aff_unique_dep": ";Artificial Intelligence",
        "aff_unique_url": "https://www.qub.ac.uk;https://www.bosch-ai.com",
        "aff_unique_abbr": "QUB;BCAI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "id": "9636331",
        "title": "Not all users are the same: Providing personalized explanations for sequential decision making problems",
        "track": "main",
        "status": "Poster",
        "abstract": "There is a growing interest in designing robots that can work alongside humans. Such robots will undoubtedly be expected to explain their behavior and decisions. While generating explanations is an actively researched topic, most works tend to focus on methods that generate explanations that are one size fits all. As in the specifics of the user-model are completely ignored. The handful of works that look at tailoring their explanation to the user\u2019s background rely on having specific models of the users (either analytic models or learned labeling models). The goal of this work is thus to propose an end-to-end adaptive explanation generation system that begins by learning the different types of users that the robot could interact with. Then during the interaction with the target user, it is tasked with identifying the type on the fly and adjust its explanations accordingly. The former is achieved by a data-driven clustering approach while for the latter, we compile our explanation generation problem into a POMDP. We demonstrate the usefulness of our system on two domains using state-of-the-art POMDP solvers. We also report the results of a user study that investigates the benefits of providing personalized explanations in a human-robot interaction setting.",
        "primary_area": "",
        "author": "Utkarsh Soni;Sarath Sreedharan;Subbarao Kambhampati;Utkarsh Soni;Sarath Sreedharan;Subbarao Kambhampati",
        "authorids": "/37088655778;/37085994795;/37283197000;/37088655778;/37085994795;/37283197000",
        "aff": "School of CS and AI, Arizona State University; School of CS and AI, Arizona State University; School of CS and AI, Arizona State University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636331/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1864242373251879909&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School of CS and AI",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636339",
        "title": "Novel Variable Stiffness Spring Mechanism: Modulating Stiffness Independent of the Energy Stored by the Spring",
        "track": "main",
        "status": "Poster",
        "abstract": "Theory suggests a linear relation between stiffness and the energy stored by a linear helical spring at constant deformation. This relation implies that increasing the stiffness of a helical spring upon deformation requires more energy at larger deformations. State-of-the-art variable stiffness spring actuators, used to drive robots and human assistive and augmentation devices, are characterized by a similar relation: increasing stiffness as the spring is deformed costs more energy as more energy is stored by the spring. This feature imposes an apparently fundamental limitation on variable stiffness spring actuation in demanding tasks, such as lifting more, jumping higher, or running faster, because, in all these tasks, the variable stiffness spring should store a considerable amount of energy and provide different stiffness to accommodate different weights in lifting, heights in jumping, and speeds in running. Here, we present an innovative variable stiffness spring design, where the energy cost of changing stiffness is independent of the energy stored by the spring. The key element of the new design is a novel floating spring which changes stiffness without changing the energy stored by the spring. Springs possessing the aforementioned feature could pave the way towards variable stiffness robot actuation and human augmentation using smaller motors and smaller battery packs.",
        "primary_area": "",
        "author": "Sung Y. Kim;David J. Braun;Sung Y. Kim;David J. Braun",
        "authorids": "/37088506795;/37609773600;/37088506795;/37609773600",
        "aff": "Department of Mechanical Engineering, Vanderbilt University, Nashville, Tennessee, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, Tennessee, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636339/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6547327790911491679&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Vanderbilt University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635832",
        "title": "NudgeSeg: Zero-Shot Object Segmentation by Repeated Physical Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in object segmentation have demonstrated that deep neural networks excel at object segmentation for specific classes in color and depth images. However, their performance is dictated by the number of classes and objects used for training, thereby hindering generalization to never seen objects or zero-shot samples. To exacerbate the problem further, object segmentation using image frames rely on recognition and pattern matching cues. Instead, we utilize the \u2018active\u2019 nature of a robot and their ability to \u2018interact\u2019 with the environment to induce additional geometric constraints for segmenting zero-shot samples.In this paper, we present the first framework to segment unknown objects in a cluttered scene by repeatedly \u2018nudging\u2019 at the objects and moving them to obtain additional motion cues at every step using only a monochrome monocular camera. We call our framework NudgeSeg. These motion cues are used to refine the segmentation masks. We successfully test our approach to segment novel objects in various cluttered scenes and provide an extensive study with image and motion segmentation methods. We show an impressive average detection rate of over 86% on zero-shot objects.",
        "primary_area": "",
        "author": "Chahat Deep Singh;Nitin J. Sanket;Chethan M. Parameshwara;Cornelia Ferm\u00fcller;Yiannis Aloimonos;Chahat Deep Singh;Nitin J. Sanket;Chethan M. Parameshwara;Cornelia Ferm\u00fcller;Yiannis Aloimonos",
        "authorids": "/37086392092;/37086390746;/37086581058;/37269887600;/37282631400;/37086392092;/37086390746;/37086581058;/37269887600;/37282631400",
        "aff": "Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland; Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland; Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland; Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland; Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies, University of Maryland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635832/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18361054389318336918&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "Perception and Robotics Group, University of Maryland Institute for Advanced Computer Studies",
        "aff_unique_url": "https://www.umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635829",
        "title": "ODIP: Towards Automatic Adaptation for Object Detection by Interactive Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Object detection plays a deep role in visual systems by identifying instances for downstream algorithms. In industrial scenarios, however, a slight change in manufacturing systems would lead to costly data re-collection and human annotation processes to re-train models. Existing solutions such as semi-supervised and few-shot methods either rely on numerous human annotations or suffer low performance. In this work, we explore a novel object detector based on interactive perception (ODIP), which can be adapted to novel domains in an automated manner. By interacting with a grasping system, ODIP accumulates visual observations of novel objects, learning to identify previously unseen instances without humanannotated data. Extensive experiments show ODIP outperforms both the generic object detector and state-of-the-art few-shot object detector fine-tuned in traditional manners. A demo video is provided to further illustrate the idea [1].",
        "primary_area": "",
        "author": "Tung-I Chen;Jen-Wei Wang;Winston H. Hsu;Tung-I Chen;Jen-Wei Wang;Winston H. Hsu",
        "authorids": "/37089195262;/37089194406;/37272584600;/37089195262;/37089194406;/37272584600",
        "aff": "National Taiwan University, Taipei; National Taiwan University, Taipei; Mobile Drive Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635829/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:oBncPPcIRPUJ:scholar.google.com/&scioq=ODIP:+Towards+Automatic+Adaptation+for+Object+Detection+by+Interactive+Perception&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "National Taiwan University;Mobile Drive Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ntu.edu.tw;",
        "aff_unique_abbr": "NTU;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Taiwan;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China;"
    },
    {
        "id": "9636835",
        "title": "OHPL: One-shot Hand-eye Policy Learner",
        "track": "main",
        "status": "Poster",
        "abstract": "The control of a robot for manipulation tasks generally relies on object detection and pose estimation. An attractive alternative is to learn control policies directly from raw input data. However, this approach is time-consuming and expensive since learning the policy requires many trials with robot actions in the physical environment. To reduce the training cost, the policy can be learned in simulation with a large set of synthetic images. The limit of this approach is the domain gap between the simulation and the robot workspace. In this paper, we propose to learn a policy for robot reaching movements from a single image captured directly in the robot workspace from a camera placed on the end-effector (a hand-eye camera). The idea behind the proposed policy learner is that view changes seen from the hand-eye camera produced by actions in the robot workspace are analogous to locating a region-of-interest in a single image by performing sequential object localisation. This similar view change enables training of object reaching policies using reinforcement-learning-based sequential object localisation. To facilitate the adaptation of the policy to view changes in the robot workspace, we further present a dynamic filter that learns to bias an input state to remove irrelevant information for an action decision. The proposed policy learner can be used as a powerful representation for robotic tasks, and we validate it on static and moving object reaching tasks.",
        "primary_area": "",
        "author": "Changjae Oh;Yik Lung Pang;Andrea Cavallaro;Changjae Oh;Yik Lung Pang;Andrea Cavallaro",
        "authorids": "/37086933301;/37088945554;/37273747900;/37086933301;/37088945554;/37273747900",
        "aff": "Centre for Intelligent Sensing, Queen Mary University of London, London, United Kingdom; Centre for Intelligent Sensing, Queen Mary University of London, London, United Kingdom; Centre for Intelligent Sensing, Queen Mary University of London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636835/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14955675707792283173&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queen Mary University of London",
        "aff_unique_dep": "Centre for Intelligent Sensing",
        "aff_unique_url": "https://www.qmul.ac.uk",
        "aff_unique_abbr": "QMUL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636830",
        "title": "OPEn: An Open-ended Physics Environment for Learning Without a Task",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans have mental models that allow them to plan, experiment, and reason in the physical world. How should an intelligent agent go about learning such models? In this paper, we will study if models of the world learned in an open-ended physics environment, without any specific tasks, can be reused for downstream physics reasoning tasks. To this end, we build a benchmark Open-ended Physics Environment (OPEn) and also design several tasks to test learning representations in this environment explicitly. This setting reflects the conditions in which real agents (i.e. rolling robots) find themselves, where they may be placed in a new kind of environment and must adapt without any teacher to tell them how this environment works. This setting is challenging because it requires solving an exploration problem in addition to a model building and representation learning problem. We test several existing RL-based exploration methods on this benchmark and find that an agent using unsupervised contrastive learning for representation learning, and impact-driven learning for exploration, achieved the best results. However, all models still fall short in sample efficiency when transferring to the downstream tasks. We expect that OPEn will encourage the development of novel rolling robot agents that can build reusable mental models of the world that facilitate many tasks.",
        "primary_area": "",
        "author": "Chuang Gan;Abhishek Bhandwaldar;Antonio Torralba;Joshua B. Tenenbaum;Phillip Isola;Chuang Gan;Abhishek Bhandwaldar;Antonio Torralba;Joshua B. Tenenbaum;Phillip Isola",
        "authorids": "/37085611353;/37089194363;/38183107900;/37622583000;/37945396900;/37085611353;/37089194363;/38183107900;/37622583000;/37945396900",
        "aff": "MIT-IBM Watson AI Lab; MIT-IBM Watson AI Lab; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636830/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8879101636402637340&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "IBM Watson AI Lab",
        "aff_unique_url": "https://www.mitibmwatsonailab.org",
        "aff_unique_abbr": "MIT-IBM AI Lab",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635950",
        "title": "ORBBuf: A Robust Buffering Method for Remote Visual SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "The data loss caused by unreliable network seriously impacts the results of remote visual SLAM systems. From our experiment, a loss of less than 1 second of data can cause a visual SLAM algorithm to lose tracking. We present a novel buffering method, ORBBuf, to reduce the impact of data loss on remote visual SLAM systems. We model the buffering problem as an optimization problem by introducing a similarity metric between frames. To solve the buffering problem, we present an efficient greedy algorithm to discard the frames that have the least impact on the quality of SLAM results. We implement our ORBBuf method on ROS, a widely used middleware framework. Through an extensive evaluation on real-world scenarios and tens of gigabytes of datasets, we demonstrate that our ORBBuf method can be applied to different state-estimation algorithms (DSO and VINS-Fusion), different sensor data (both monocular images and stereo images), different scenes (both indoor and outdoor), and different network environments (both WiFi networks and 4G networks). Our experimental results indicate that the network losses indeed affect the SLAM results, and our ORBBuf method can reduce the RMSE up to 50 times comparing with the Drop-Oldest and Random buffering methods.",
        "primary_area": "",
        "author": "Yu-Ping Wang;Zi-Xin Zou;Cong Wang;Yue-Jiang Dong;Lei Qiao;Dinesh Manocha;Yu-Ping Wang;Zi-Xin Zou;Cong Wang;Yue-Jiang Dong;Lei Qiao;Dinesh Manocha",
        "authorids": "/37085396500;/37089198099;/37089197698;/37089194195;/37089442770;/37267825600;/37085396500;/37089198099;/37089197698;/37089194195;/37089442770;/37267825600",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Beijing Institute of Control Engineering, Beijing, China; Department of Computer Science, University of Maryland, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635950/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17589286266423022658&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "Tsinghua University;Beijing Institute of Control Engineering;University of Maryland",
        "aff_unique_dep": "Department of Computer Science and Technology;;Department of Computer Science",
        "aff_unique_url": "https://www.tsinghua.edu.cn;;https://www.umd.edu",
        "aff_unique_abbr": "THU;;UMD",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Beijing;College Park",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9635865",
        "title": "ORCHID: Optimisation of Robotic Control and Hardware In Design using Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The successful performance of any system is dependant on the hardware of the agent, which is typically immutable during RL training. In this work, we present ORCHID (Optimisation of Robotic Control and Hardware In Design) which allows for truly simultaneous optimisation of hardware and control parameters in an RL pipeline. We show that by forming a complex differential path through a trajectory rollout we can leverage a vast amount of information from the system that was previously lost in the \u2018black-box\u2019 environment. Combining this with a novel hardware-conditioned critic network minimises variance during training and ensures stable updates are made. This allows for refinements to be made to both the morphology and control parameters simultaneously. The result is an efficient and versatile approach to holistic robot design, that brings the final system nearer to true optimality. We show improvements in performance across 4 different test environments with two different control algorithms - in all experiments the maximum performance achieved with ORCHID is shown to be unattainable using only policy updates with the default design. We also show how re-designing a robot using ORCHID in simulation, transfers to a vast improvement in the performance of a real-world robot.",
        "primary_area": "",
        "author": "Lucy Jackson;Celyn Walters;Steve Eckersley;Pete Senior;Simon Hadfield;Lucy Jackson;Celyn Walters;Steve Eckersley;Pete Senior;Simon Hadfield",
        "authorids": "/37089194792;/37087323095;/37086937559;/37089198273;/38232557500;/37089194792;/37087323095;/37086937559;/37089198273;/38232557500",
        "aff": "GU2, University of Surrey; GU2, University of Surrey; Tycho House, GU2, Surrey Satellite Technology Limited; Tycho House, GU2, Surrey Satellite Technology Limited; GU2, University of Surrey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635865/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14162269655609660026&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "University of Surrey;Surrey Satellite Technology Limited",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.surrey.ac.uk;https://www.sstl.co.uk",
        "aff_unique_abbr": "Surrey;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9635869",
        "title": "ORStereo: Occlusion-Aware Recurrent Stereo Matching for 4K-Resolution Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Stereo reconstruction models trained on small images do not generalize well to high-resolution data. Training a model on high-resolution image size faces difficulties of data availability and is often infeasible due to limited computing resources. In this work, we present the Occlusion-aware Recurrent binocular Stereo matching (ORStereo), which deals with these issues by only training on available low disparity range stereo images. ORStereo generalizes to unseen high-resolution images with large disparity ranges by formulating the task as residual updates and refinements of an initial prediction. ORStereo is trained on images with disparity ranges limited to 256 pixels, yet it can operate 4K-resolution input with over 1000 disparities using limited GPU memory. We test the model\u2019s capability on both synthetic and real-world high-resolution images. Experimental results demonstrate that ORStereo achieves comparable performance on 4K-resolution images compared to state-of-the-art methods trained on large disparity ranges. Compared to the baseline methods that are only trained on low-resolution images, our method has 60% or less error on 4K-resolution images.",
        "primary_area": "",
        "author": "Yaoyu Hu;Wenshan Wang;Huai Yu;Weikun Zhen;Sebastian Scherer;Yaoyu Hu;Wenshan Wang;Huai Yu;Weikun Zhen;Sebastian Scherer",
        "authorids": "/37086920250;/37087322184;/37086223088;/37086162020;/37584159000;/37086920250;/37087322184;/37086223088;/37086162020;/37584159000",
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635869/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2138528454627977167&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635884",
        "title": "Object Learning for 6D Pose Estimation and Grasping from RGB-D Videos of In-hand Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Object models are highly useful for robots as they enable tasks such as detection, pose estimation and manipulation. However, models are not always easily available, especially in real-world domains of operation such as peoples\u2019 homes. This work presents a pipeline to generate high-quality object reconstructions from human in-hand manipulation to alleviate the necessity of specialised or expensive hardware. Missing data, due to occlusion or unseen sides, is explicitly handled by incorporating shape completion. We demonstrate the usability of the reconstructions by applying a model-based as well as a CNN-based object pose estimator that is trained on synthetic images by employing state-of-the-art texture synthesis. Using our pipeline to cheaply generate object models and synthetic RGB images for training, we achieve competitive performance compared to baselines that require an elaborate set-up to construct models or large amounts of annotated data. Object grasping is also enabled by learning with the reconstructions in simulation, then executing with a real robot. These evaluations show that our reconstructions are comparable to those made under near-perfect conditions and enable 6D object pose estimation as well as real-world grasping.",
        "primary_area": "",
        "author": "Timothy Patten;Kiru Park;Markus Leitner;Kevin Wolfram;Markus Vincze;Timothy Patten;Kiru Park;Markus Leitner;Kevin Wolfram;Markus Vincze",
        "authorids": "/37085763735;/37086331055;/37089000063;/37089196275;/37269163100;/37085763735;/37086331055;/37089000063;/37089196275;/37269163100",
        "aff": "Robotics Institute, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Automation and Control Institute, Faculty of Electrical Engineering and Information Technology, TU Wien, Vienna, Austria; Automation and Control Institute, Faculty of Electrical Engineering and Information Technology, TU Wien, Vienna, Austria; Automation and Control Institute, Faculty of Electrical Engineering and Information Technology, TU Wien, Vienna, Austria; Automation and Control Institute, Faculty of Electrical Engineering and Information Technology, TU Wien, Vienna, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635884/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6491254430458159396&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "University of Technology Sydney;TU Wien",
        "aff_unique_dep": "Robotics Institute, Faculty of Engineering and Information Technology;Faculty of Electrical Engineering and Information Technology",
        "aff_unique_url": "https://www.uts.edu.au;https://www.tuwien.ac.at",
        "aff_unique_abbr": "UTS;TU Wien",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Ultimo;Vienna",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Australia;Austria"
    },
    {
        "id": "9636354",
        "title": "Object Picking Using a Two-Fingered Gripper Measuring the Deformation and Slip Detection Based on a 3-Axis Tactile Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Object picking with two-fingered grippers is widely used in practice. However, the deformability and slipperiness of the target object still remain a challenge, and not resolving them might lead to breaking or dropping of the grasped objects. To prevent such instances, tactile sensing plays an important role because it can directly detect even the subtle changes that occur during grasping. Mechanoreceptors in the human skin detect such events by the change in the skin shape and/or vibration. Using a similar approach, a combined deformation and slip detection system using a distributed 3axis tactile information with various time-scales is proposed. Specifically, the tactile information includes the z-axis data, which denotes the deformation of the skin perpendicular to the finger\u2019s surface and the x- and y-axes, which measure deformations tangential to the surface. The perpendicular and tangential tactile information are used to determine the deformation and slip, respectively. The system is based on a multilayer perceptron (MLP) that outputs detection results from a 3-axis tactile information. Results showed that, the perpendicular and tangential tactile information with an appropriate timescale were effective for deformation and slip detection with over 89% and 95% recognition rates, respectively, measured for 40 different objects. Moreover, 195 out of 200 real-time untrained grasping states were successful detected. Finally, 10 untrained objects were successfully picked.",
        "primary_area": "",
        "author": "Satoshi Funabashi;Yuta Kage;Hiroyuki Oka;Yoshihiro Sakamoto;Shigeki Sugano;Satoshi Funabashi;Yuta Kage;Hiroyuki Oka;Yoshihiro Sakamoto;Shigeki Sugano",
        "authorids": "/37085727304;/37089196165;/37089195569;/37590942000;/37274050800;/37085727304;/37089196165;/37089195569;/37590942000;/37274050800",
        "aff": "Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Tokyo Robotics Inc., Tokyo, Japan; Tokyo Robotics Inc., Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636354/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9720129265055166691&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Waseda University;Tokyo Robotics Inc.",
        "aff_unique_dep": "Dept. of Modern Mechanical Engineering;",
        "aff_unique_url": "https://www.waseda.jp/top;",
        "aff_unique_abbr": "Waseda;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636034",
        "title": "Object-Augmented RGB-D SLAM for Wide-Disparity Relocalisation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel object-augmented RGB-D SLAM system that is capable of constructing a consistent object map and performing relocalisation based on centroids of objects in the map. The approach aims to overcome the view dependence of appearance-based relocalisation methods using point features or images. During the map construction, we use a pre-trained neural network to detect objects and estimate 6D poses from RGB-D data. An incremental probabilistic model is used to aggregate estimates over time to create the object map. Then in relocalisation, we use the same network to extract objects-of-interest in the \u2018lost\u2019 frames. Pairwise geometric matching finds correspondences between map and frame objects, and probabilistic absolute orientation followed by application of iterative closest point to dense depth maps and object centroids gives relocalisation. Results of experiments in desktop environments demonstrate very high success rates even for frames with widely different viewpoints from those used to construct the map, significantly outperforming two appearance- based methods.",
        "primary_area": "",
        "author": "Yuhang Ming;Xingrui Yang;Andrew Calway;Yuhang Ming;Xingrui Yang;Andrew Calway",
        "authorids": "/37089196703;/37085952161;/37326243500;/37089196703;/37085952161;/37326243500",
        "aff": "Department of Computer Science, Visual Information Laboratory, University of Bristol, Bristol, U.K; Department of Computer Science, Visual Information Laboratory, University of Bristol, Bristol, U.K; Department of Computer Science, Visual Information Laboratory, University of Bristol, Bristol, U.K",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636034/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3056019598455063528&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bristol",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bristol.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bristol",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636700",
        "title": "Object-to-Scene: Learning to Transfer Object Knowledge to Indoor Scene Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate perception of the surrounding scene is helpful for robots to make reasonable judgments and behaviours. Therefore, developing effective scene representation and recognition methods are of significant importance in robotics. Currently, a large body of research focuses on developing novel auxiliary features and networks to improve indoor scene recognition ability. However, few of them focus on directly constructing object features and relations for indoor scene recognition. In this paper, we analyze the weaknesses of current methods and propose an Object-to-Scene (OTS) method, which extracts object features and learns object relations to recognize indoor scenes. The proposed OTS first extracts object features based on the segmentation network and the proposed object feature aggregation module (OFAM). Afterwards, the object relations are calculated and the scene representation is constructed based on the proposed object attention module (OAM) and global relation aggregation module (GRAM). The final results in this work show that OTS successfully extracts object features and learns object relations from the segmentation network. Moreover, OTS outperforms the state-of-the-art methods by more than 2% on indoor scene recognition without using any additional streams. Code is publicly available at: https://github.com/FreeformRobotics/OTS.",
        "primary_area": "",
        "author": "Bo Miao;Liguang Zhou;Ajmal Saeed Mian;Tin Lun Lam;Yangsheng Xu;Bo Miao;Liguang Zhou;Ajmal Saeed Mian;Tin Lun Lam;Yangsheng Xu",
        "authorids": "/37086248032;/37086212444;/37283914600;/37571111600;/37277722000;/37086248032;/37086212444;/37283914600;/37571111600;/37277722000",
        "aff": "School of Physics, Mathematics and Computing, The University of Western Australia; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen; School of Physics, Mathematics and Computing, The University of Western Australia; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society, The Chinese University of Hong Kong, Shenzhen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636700/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3743241477943814159&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;1",
        "aff_unique_norm": "University of Western Australia;Chinese University of Hong Kong",
        "aff_unique_dep": "School of Physics, Mathematics and Computing;Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_url": "https://www.uwa.edu.au;https://www.cuhk.edu.cn",
        "aff_unique_abbr": "UWA;CUHK",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Shenzhen",
        "aff_country_unique_index": "0;1;0;1;1",
        "aff_country_unique": "Australia;China"
    },
    {
        "id": "9635901",
        "title": "Obstacle Avoidance onboard MAVs using a FMCW Radar",
        "track": "main",
        "status": "Poster",
        "abstract": "Micro Air Vehicles (MAVs) are increasingly being used for complex or hazardous tasks in enclosed and cluttered environments such as surveillance or search and rescue. With this comes the necessity for sensors that can operate in poor visibility conditions to facilitate with navigation and avoidance of objects or people. Radar sensors in particular can provide more robust sensing of the environment when traditional sensors such as cameras fail in the presence of dust, fog or smoke. While extensively used in autonomous driving, miniature FMCW radars on MAVs have been relatively unexplored. This study aims to investigate to what extent this sensor is of use in these environments by employing traditional signal processing such as multi-target tracking and velocity obstacles. The viability of the solution is evaluated with an implementation on board a MAV by running trial tests in an indoor environment containing obstacles and by comparison with a human pilot, demonstrating the potential for the sensor to provide a more robust sense and avoid function in fully autonomous MAVs.",
        "primary_area": "",
        "author": "Nikhil Wessendorp;Raoul Dinaux;Julien Dupeyroux;Guido C. H. E. de Croon;Nikhil Wessendorp;Raoul Dinaux;Julien Dupeyroux;Guido C. H. E. de Croon",
        "authorids": "/37088941143;/37088940154;/37086222518;/37698062600;/37088941143;/37088940154;/37086222518;/37698062600",
        "aff": "Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635901/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16311071067030968946&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Faculty of Aerospace Engineering",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9636230",
        "title": "Occlusion-Aware Search for Object Retrieval in Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the manipulation task of retrieving a target object from a cluttered shelf. When the target object is hidden, the robot must search through the clutter for retrieving it. Solving this task requires reasoning over the likely locations of the target object. It also requires physics reasoning over multi-object interactions and future occlusions. In this work, we present a data-driven hybrid planner for generating occlusion-aware actions in closed-loop. The hybrid planner explores likely locations of the occluded target object as predicted by a learned distribution from the observation stream. The search is guided by a heuristic trained with reinforcement learning to act on observations with occlusions. We evaluate our approach in different simulation and real-world settings (video available on https://youtu.be/dY7YQ3LUVQg). The results validate that our approach can search and retrieve a target object in near real time in the real world while only being trained in simulation.",
        "primary_area": "",
        "author": "Wissam Bejjani;Wisdom C. Agboh;Mehmet R. Dogar;Matteo Leonetti;Wissam Bejjani;Wisdom C. Agboh;Mehmet R. Dogar;Matteo Leonetti",
        "authorids": "/37086605415;/37086208399;/37591140400;/37593250400;/37086605415;/37086208399;/37591140400;/37593250400",
        "aff": "School of Computing, University of Leeds, United Kingdom; School of Computing, University of Leeds, United Kingdom; School of Computing, University of Leeds, United Kingdom; School of Computing, University of Leeds, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636230/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17428633808718973309&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Leeds",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.leeds.ac.uk",
        "aff_unique_abbr": "Leeds",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9635980",
        "title": "Odometry Model Calibration for Self-Driving Vehicles with Noise Correction",
        "track": "main",
        "status": "Poster",
        "abstract": "In the era of self-driving vehicles, state estimation has 3 main contradictory requirements, such as accuracy, robustness, and cost-effectiveness. To satisfy all of them, the integration of the wheel encoder measurements is a proper choice besides the generally applied GNSS, inertial and visual-odometry methods. The wheel odometry is a robust and cost-effective method, but the accuracy of the estimation is limited by the proper knowledge of the vehicle parameter values. However, the calibration of the nonlinear odometry model in the presence of noise remains an open problem in the context of autonomous vehicles yet. This paper presents an algorithm that takes advantage of the assumption that more measurements are available in a self-driving vehicle for accurate parameter estimation. With the proposed architecture, the measurements with distortion effects are detected, and also the noise is corrected to reach unbiased model calibration. The performance of the developed algorithm and the accuracy of the parameter estimation are demonstrated with detailed validation and test with a real vehicle.",
        "primary_area": "",
        "author": "M\u00e1t\u00e9 Fazekas;P\u00e9ter G\u00e1sp\u00e1r;Bal\u00e1zs N\u00e9meth;M\u00e1t\u00e9 Fazekas;P\u00e9ter G\u00e1sp\u00e1r;Bal\u00e1zs N\u00e9meth",
        "authorids": "/37086440727;/37373814100;/37529068900;/37086440727;/37373814100;/37529068900",
        "aff": "Institute for Computer Science and Control (SZTAKI), E\u00f6tv\u00f6s Lor\u00e1nd Research Network (ELKH), Budapest, Hungary; Institute for Computer Science and Control (SZTAKI), E\u00f6tv\u00f6s Lor\u00e1nd Research Network (ELKH), Budapest, Hungary; Institute for Computer Science and Control (SZTAKI), E\u00f6tv\u00f6s Lor\u00e1nd Research Network (ELKH), Budapest, Hungary",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635980/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2298567625308618475&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Institute for Computer Science and Control",
        "aff_unique_dep": "Computer Science and Control",
        "aff_unique_url": "",
        "aff_unique_abbr": "SZTAKI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Hungary"
    },
    {
        "id": "9636608",
        "title": "Offset-free Model Predictive Control: A Ball Catching Application with a Spherical Soft Robotic Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an offset-free model predictive controller for fast and accurate control of a spherical soft robotic arm. In this control scheme, a linear model is combined with an online disturbance estimation technique to systematically compensate model deviations. Dynamic effects such as material relaxation resulting from the use of soft materials can be addressed to achieve offset-free tracking. The tracking error can be reduced by 35% when compared to a standard model predictive controller without a disturbance compensation scheme. The improved tracking performance enables the realization of a ball catching application, where the spherical soft robotic arm can catch a ball thrown by a human.",
        "primary_area": "",
        "author": "Yaohui Huang;Matthias Hofer;Raffaello D\u2019Andrea;Yaohui Huang;Matthias Hofer;Raffaello D\u2019Andrea",
        "authorids": "/37089197150;/37085792603;/38525077800;/37089197150;/37085792603;/38525077800",
        "aff": "Institute for Dynamic Systems and Control, ETH Z\u00fcrich, Switzerland; Institute for Dynamic Systems and Control, ETH Z\u00fcrich, Switzerland; Institute for Dynamic Systems and Control, ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636608/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5417465144680408206&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Institute for Dynamic Systems and Control",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9635977",
        "title": "On Assessing the Usefulness of Proxy Domains for Developing and Evaluating Embodied Agents",
        "track": "main",
        "status": "Poster",
        "abstract": "In many situations it is either impossible or impractical to develop and evaluate agents entirely on the target domain on which they will be deployed. This is particularly true in robotics, where doing experiments on hardware is much more arduous than in simulation. This has become arguably more so in the case of learning-based agents. To this end, considerable recent effort has been devoted to developing increasingly realistic and higher fidelity simulators. However, we lack any principled way to evaluate how good a \"proxy domain\" is, specifically in terms of how useful it is in helping us achieve our end objective of building an agent that performs well in the target domain. In this work, we investigate methods to address this need. We begin by clearly separating two uses of proxy domains that are often conflated: 1) their ability to be a faithful predictor of agent performance and 2) their ability to be a useful tool for learning. In this paper, we attempt to clarify the role of proxy domains and establish new proxy usefulness (PU) metrics to compare the usefulness of different proxy domains. We propose the relative predictive PU to assess the predictive ability of a proxy domain and the learning PU to quantify the usefulness of a proxy as a tool to generate learning data. Furthermore, we argue that the value of a proxy is conditioned on the task that it is being used to help solve. We demonstrate how these new metrics can be used to optimize parameters of the proxy domain for which obtaining ground truth via system identification is not trivial.",
        "primary_area": "",
        "author": "Anthony Courchesne;Andrea Censi;Liam Paull;Anthony Courchesne;Andrea Censi;Liam Paull",
        "authorids": "/37088688218;/37398994000;/37935956000;/37088688218;/37398994000;/37935956000",
        "aff": "Montr\u00e9al Robotics and Embodied AI Lab (REAL) at Universit\u00e9 de Mont\u00e9al, Mila; ETH Z\u00fcrich, Switzerland; Montr\u00e9al Robotics and Embodied AI Lab (REAL) at Universit\u00e9 de Mont\u00e9al, Mila",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635977/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4386637906059165496&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Universit\u00e9 de Montr\u00e9al;ETH Zurich",
        "aff_unique_dep": "Montr\u00e9al Robotics and Embodied AI Lab (REAL);",
        "aff_unique_url": "https://www.umontreal.ca;https://www.ethz.ch",
        "aff_unique_abbr": "UdeM;ETHZ",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Montr\u00e9al;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Canada;Switzerland"
    },
    {
        "id": "9636380",
        "title": "On Explainability and Sensor-Adaptability of a Robot Tactile Texture Representation Using a Two-Stage Recurrent Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to simultaneously distinguish objects, materials, and their associated physical properties is one fundamental function of the sense of touch. Recent advances in the development of tactile sensors and machine learning techniques allow more accurate and complex modelling of robotic tactile sensations. However, many state-of-the-art (SotA) approaches focus solely on constructing black-box models to achieve ever higher classification accuracy and fail to adapt across sensors with unique spatial-temporal data formats. In this work, we propose an Explainable and Sensor-Adaptable Recurrent Networks (ExSARN) model for tactile texture representation. The ExSARN model consists of a two-stage recurrent networks fed by a sensor-specific header network. The first stage recurrent network emulates our human touch receptors and decouples sensor-specific tactile sensations into different frequency response bands, while the second stage codes the overall temporal signature as a variational recurrent autoen-coder. We infuse the latent representation with ternary labels to qualitatively represent texture properties (e.g. roughness and stiffness), which facilitates representation learning and provide explainability to the latent space. The ExSARN model is tested on texture datasets collected with two different tactile sensors. Our results show that the proposed model not only achieves higher accuracy, but also provides adaptability across sensors with different sampling frequencies and data formats. The addition of the crudely obtained qualitative property labels offers a practical approach to enhance the interpretability of the latent space, facilitate property inference on unseen materials, and improve the overall performance of the model.",
        "primary_area": "",
        "author": "Ruihan Gao;Tian Tian;Zhiping Lin;Yan Wu;Ruihan Gao;Tian Tian;Zhiping Lin;Yan Wu",
        "authorids": "/37086880837;/37089197540;/37277999300;/37085344977;/37086880837;/37089197540;/37277999300;/37085344977",
        "aff": "Robotics & Autonomous Systems Department, A*STAR Insti-tute for Infocomm Research, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Robotics & Autonomous Systems Department, A*STAR Insti-tute for Infocomm Research, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636380/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10809338907708814149&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "A*STAR Institute for Infocomm Research;Nanyang Technological University",
        "aff_unique_dep": "Robotics & Autonomous Systems Department;School of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.aistar.edu.sg;https://www.ntu.edu.sg",
        "aff_unique_abbr": "A*STAR I2R;NTU",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Singapore",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9636741",
        "title": "On Fault Classification in Connected Autonomous Vehicles Using Supervised Machine Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Different health-monitoring techniques were considered in the literature to enhance the safety and stability of Connected Autonomous Vehicle (CAV) platoons. The health-monitoring processes include fault detection, localization, and mitigation. It is evident that mitigating these faults is faster and more reliable if the fault structure is known. To this end, we consider classifying the fault class using supervised machine learning. We first model a heterogeneous CAV platoon with three different common faults separately. These faults are bounded actuator disturbances (namely, engine bearing knock), False Data Injection (FDI) attack, and communication time delay. We consider two supervised machine learning classifiers, the first classifier determines whether the fault is bounded disturbances or communication delay, and the second classifier determines whether the disturbances are in the physical or cyber layer. We have compared four machine learning techniques for each classifier, Support Vector Machine (SVM), Naive Bayes (NB), Quadratic Discriminant (QD), and K-Nearest Neighbors (KNN). The classifiers are trained firstly on the simulation model, then are tested on a different set of observations and tested experimentally on a platoon of three autonomous robots. The highest accuracy was achieved by considering SVM for the first classifier and QD for the second classifier. The overall classification accuracy achieved is 96.8% for the simulation test and 92.1% for the experiment.",
        "primary_area": "",
        "author": "Abdelrahman Khalil;Mohammad Al Janaideh;Abdelrahman Khalil;Mohammad Al Janaideh",
        "authorids": "/37088482852;/37542671600;/37088482852;/37542671600",
        "aff": "Department of Mechanical Engineering, Memorial University, St. John\u2019s, Canada; Department of Mechanical Engineering, Memorial University, St. John\u2019s, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636741/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9366408855002729923&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Memorial University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mun.ca",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "St. John\u2019s",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636016",
        "title": "On Step-and-Scan Trajectories used in Wafer Scanners in Semiconductor Manufacturing",
        "track": "main",
        "status": "Poster",
        "abstract": "Adopting the ideal reliable machine model, the throughput of a lithography machine can be given as the reciprocal of the operation time. This time can be defined at the die level where the actual exposure process takes place as the time unit per die. A closer look at the motion profiles, namely step-and-scan trajectories, suggests that a multi-disciplinary design optimization should be involved when such profiles are selected or designed. Being the reference motion used, the step-and-scan trajectories not only affect the machine performance, but also affect its throughput and to an extent the die yield as well. Structural vibration, and thermal loading at the actuators due to friction and repetitive motion may build up because of following the reference motion. Moreover, since the exposure process and equipment are synchronized with the reference motion, deformation and thermal stress may affect the reticle, the wafer and the projection elements if the exposure high-energy duration and frequency are not taken into consideration while designing the reference motion. From dynamics point of view, reference motion with higher-order derivatives enhances the tracking performance of the machine, however, its operational cost is usually overlooked. In this paper, we present a case-study that outlines the aforementioned aspects using three step-and-scan profiles of the same order. We conclude by posing the following research question: what is the best combination of orders of the step and the scan trajectories that jointly meet the desired performance and operating conditions?",
        "primary_area": "",
        "author": "Yazan M. Al-Rawashdeh;Mohammad Al Janaideh;Marcel Heertjes;Yazan M. Al-Rawashdeh;Mohammad Al Janaideh;Marcel Heertjes",
        "authorids": "/37085842482;/37542671600;/37300976100;/37085842482;/37542671600;/37300976100",
        "aff": "Department of Mechanical Engineering, Memorial University, St. John\u2019s, Canada; Department of Mechanical Engineering, Memorial University, St. John\u2019s, Canada; ASML and Department of Mechanical Engineering, Eindhoven University of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636016/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6679254580303163934&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Memorial University;Eindhoven University of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mun.ca;https://www.tue.nl",
        "aff_unique_abbr": ";TU/e",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "St. John\u2019s;Eindhoven",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Canada;Netherlands"
    },
    {
        "id": "9636081",
        "title": "On compliance and safety with torque-control for robots with high reduction gears and no joint-torque feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we report the safety-oriented framework for controlling the torque in the case of robots with high reduction gears and having no joint torque feedback. This kind of robots suffer from high joint friction and low backdrivability, requiring high gains and integral feedback, which can be dangerous. Our optimization-based framework includes feasibility and safety features borrowed from position control, and we introduce novel ones. We show how we limit the integral terms using a QP-based anti-windup which produces the optimal torque that maintains the best performances under safety limits. We show also a new controller for null-space compliance, providing strong guarantees of convergence in the task-space and ignoring the corresponding null-space where the robot can be moved freely. We validate these features with experiments on one 9 DoF arm of the robot HRP-5P performing a Cartesian task, and then a dual Cartesian / admittance task.",
        "primary_area": "",
        "author": "Mehdi Benallegue;Rafael Cisneros;Abdelaziz Benallegue;Arnaud Tanguy;Adrien Escande;Mitsuharu Morisawa;Fumio Kanehiro;Mehdi Benallegue;Rafael Cisneros;Abdelaziz Benallegue;Arnaud Tanguy;Adrien Escande;Mitsuharu Morisawa;Fumio Kanehiro",
        "authorids": "/37571999700;/38580560800;/37301307100;/37086000416;/37542914500;/37295668600;/37283667500;/37571999700;/38580560800;/37301307100;/37086000416;/37542914500;/37295668600;/37283667500",
        "aff": "CNRS-AIST JRL (Joint Robotics Laboratory), IRL, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan; CNRS-AIST JRL (Joint Robotics Laboratory), IRL, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan; Laboratoire d\u2019Ing\u00e9nierie des Syst\u00e8mes de Versailles, France; CNRS-AIST JRL (Joint Robotics Laboratory), IRL, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan; CNRS-AIST JRL (Joint Robotics Laboratory), IRL, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan; CNRS-AIST JRL (Joint Robotics Laboratory), IRL, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan; CNRS-AIST JRL (Joint Robotics Laboratory), IRL, National Institute of Advanced Industrial Science and Technology (AIST), Tsukuba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636081/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15165044441369506479&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology;Laboratoire d\u2019Ing\u00e9nierie des Syst\u00e8mes",
        "aff_unique_dep": "Joint Robotics Laboratory;Ing\u00e9nierie des Syst\u00e8mes",
        "aff_unique_url": "https://www.aist.go.jp;",
        "aff_unique_abbr": "AIST;",
        "aff_campus_unique_index": "0;0;1;0;0;0;0",
        "aff_campus_unique": "Tsukuba;Versailles",
        "aff_country_unique_index": "0;0;1;0;0;0;0",
        "aff_country_unique": "Japan;France"
    },
    {
        "id": "9636826",
        "title": "On connected deployment of delay-critical FANETs",
        "track": "main",
        "status": "Poster",
        "abstract": "Many safety critical scenarios, including post-disaster areas, or military fields, require prompt area monitoring and fast detection of events of interest. Flying Ad-hoc Networks (FANETs) provide a powerful tool to search the area, and locate anomalies. Nevertheless, wide-area deployment of FANETs poses a number of challenges. Existing long range communication technologies are inadequate to meet the data rate and delay requirements of a safety critical application. To face this challenge, we formulate the connected deployment problem, where we require the FANET to create connected formations to ensure multi-hop low-latency communications while performing the monitoring task. We show that addressing the above problem with the aim of maximizing event coverage is NP-hard. We propose a polynomial time solution, called Greedy Connected Deployment (GCD), based on a two phase approximation of the problem. By means of extensive simulations and real field experiments, we show that our approach outperforms existing solutions to related problems, both in terms of monitoring accuracy and system responsiveness.",
        "primary_area": "",
        "author": "Novella Bartolini;Andrea Coletta;Matteo Prata;Camilla Serino;Novella Bartolini;Andrea Coletta;Matteo Prata;Camilla Serino",
        "authorids": "/37281557300;/37087080695;/37088983566;/37089196026;/37281557300;/37087080695;/37088983566;/37089196026",
        "aff": "Department of Computer Science, Sapienza University of Rome, Italy; Department of Computer Science, Sapienza University of Rome, Italy; Department of Computer Science, Sapienza University of Rome, Italy; Department of Computer Science, Sapienza University of Rome, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636826/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9910430900245773190&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Sapienza University of Rome",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uniroma1.it",
        "aff_unique_abbr": "Sapienza",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Rome",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636698",
        "title": "On the descriptive power of LiDAR intensity images for segment-based loop closing in 3-D SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an extension to the segment-based global localization method for LiDAR SLAM using descriptors learned considering the visual context of the segments. A new architecture of the deep neural network is presented that learns the visual context acquired from synthetic LiDAR intensity images. This approach allows a single multi-beam LiDAR to produce rich and highly descriptive location signatures. The method is tested on two public datasets, demonstrating an improved descriptiveness of the new descriptors, and more reliable loop closure detection in SLAM. Attention analysis of the network is used to show the importance of focusing on the broader context rather than only on the 3-D segment.",
        "primary_area": "",
        "author": "Jan Wietrzykowski;Piotr Skrzypczy\u0144ski;Jan Wietrzykowski;Piotr Skrzypczy\u0144ski",
        "authorids": "/37085495377;/37611911500;/37085495377;/37611911500",
        "aff": "Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poz\u0144an, Poland; Institute of Robotics and Machine Intelligence, Poznan University of Technology, Poz\u0144an, Poland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636698/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5619240255930465811&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Poznan University of Technology",
        "aff_unique_dep": "Institute of Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.put.poznan.pl/",
        "aff_unique_abbr": "PUT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Poznan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Poland"
    },
    {
        "id": "9636164",
        "title": "OneVision: Centralized to Distributed Controller Synthesis with Delay Compensation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new algorithm to simplify the controller development for distributed robotic systems subject to external observations, disturbances, and communication delays. Unlike prior approaches that propose specialized solutions to handling communication latency for specific robotic applications, our algorithm uses an arbitrary centralized controller as the specification and automatically generates distributed controllers with communication management and delay compensation. We formulate our goal as nonlinear optimal control\u2014 using a regret minimizing objective that measures how much the distributed agents behave differently from the delay-free centralized response\u2014and solve for optimal actions w.r.t. local estimations of this objective using gradient-based optimization. We analyze our proposed algorithm\u2019s behavior under a linear time-invariant special case and prove that the closed-loop dynamics satisfy a form of input-to-state stability w.r.t. unexpected disturbances and observations. Our experimental results on both simulated and real-world robotic tasks demonstrate the practical usefulness of our approach and show significant improvement over several baseline approaches.",
        "primary_area": "",
        "author": "Jiayi Wei;Tongrui Li;Swarat Chaudhuri;Isil Dillig;Joydeep Biswas;Jiayi Wei;Tongrui Li;Swarat Chaudhuri;Isil Dillig;Joydeep Biswas",
        "authorids": "/37089197655;/37089196282;/37072408200;/37086228218;/37538259200;/37089197655;/37089196282;/37072408200;/37086228218;/37538259200",
        "aff": "Computer Science Department, University of Texas at Austin, USA; Computer Science Department, University of Texas at Austin, USA; Computer Science Department, University of Texas at Austin, USA; Computer Science Department, University of Texas at Austin, USA; Computer Science Department, University of Texas at Austin, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636164/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4529074762295321250&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636565",
        "title": "Online High-Level Model Estimation for Efficient Hierarchical Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We would like to enable a robot to navigate efficiently and robustly in known, structured environments that are large enough to cause traditional planning approaches to incur considerable computational cost. Hierarchical planners are a promising way to increase planning efficiency in such environments because high-level abstract plans can be used to reduce the size of the search space over which detailed planning occurs. However, useful high-level representations of planning problems can be challenging to generate without prior domain knowledge. In this work, we propose a high-level planning representation which can be learned from previous plans considered in the environment and used online during hierarchical, multi-query robot navigation. We treat previous planning results as noisy measurements of high-level navigation properties, then update these properties over time using recursive estimation. We test our approach in standard and risk-aware hierarchical planning schemes, and demonstrate up to an 86% decrease in the number of nodes expanded and a 66% decrease in wallclock time as compared to a baseline A* planner while finding plans that are only 2-10% more expensive.",
        "primary_area": "",
        "author": "Martina Stadler;Katherine Liu;Nicholas Roy;Martina Stadler;Katherine Liu;Nicholas Roy",
        "authorids": "/37088503932;/37086454373;/37274058700;/37088503932;/37086454373;/37274058700",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology in Cambridge, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology in Cambridge, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology in Cambridge, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636565/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18118136263467498200&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636663",
        "title": "Online Impedance Adaptation Facilitates Manipulating a Whip",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulation of flexible objects is one of the major challenges in robotics as the nonlinear dynamics of the high-dimensional object structure makes it difficult to apply current control methods. A previous simulation study showed that control with few pre-structured joint trajectories coupled with joint impedance (dynamic primitives) could control a 25-dimensional whip to hit a target. This was possible even though the impedance values were constant. This paper explores whether time-varying impedance throughout the movement may further enhance performance. We present an online impedance adaptation (OIA) controller that modulates the joint impedances of a two-joint actuator in real time for the same task. Results showed that the OIA control method increased the speed of optimization and resulted in smaller deviation from the zero-torque joint trajectories compared to the controller with constant joint impedances. This novel way to modulate both motion and impedance of a manipulator may facilitate the control of flexible objects with significant dynamics.",
        "primary_area": "",
        "author": "Xiaofeng Xiong;Moses C. Nah;Aleksei Krotov;Dagmar Sternad;Xiaofeng Xiong;Moses C. Nah;Aleksei Krotov;Dagmar Sternad",
        "authorids": "/37086356526;/37086093366;/37088534574;/38469397700;/37086356526;/37086093366;/37088534574;/38469397700",
        "aff": "SDU Biorobotics, the M\u00e6rsk Mc-Kinney M\u00f8ller Institute, University of Southern Denmark, Odence, Denmark; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Bioengineering, Northeastern University, Boston, MA, USA; Departments of Biology, Electrical & Computer Engineering, and Physics, Northeastern University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636663/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12918111225222497276&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "University of Southern Denmark;Massachusetts Institute of Technology;Northeastern University",
        "aff_unique_dep": "SDU Biorobotics;Department of Mechanical Engineering;Department of Bioengineering",
        "aff_unique_url": "https://www.sdu.dk;https://web.mit.edu;https://www.northeastern.edu",
        "aff_unique_abbr": "SDU;MIT;NU",
        "aff_campus_unique_index": "0;1;2;2",
        "aff_campus_unique": "Odense;Cambridge;Boston",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Denmark;United States"
    },
    {
        "id": "9636325",
        "title": "Online Information-Aware Motion Planning with Inertial Parameter Learning for Robotic Free-Flyers",
        "track": "main",
        "status": "Poster",
        "abstract": "Space free-flyers like the Astrobee robots currently operating aboard the International Space Station must operate with inherent system uncertainties. Parametric uncertainties like mass and moment of inertia are especially important to quantify in these safety-critical space systems and can change in scenarios such as on-orbit cargo movement, where unknown grappled payloads significantly change the system dynamics. Cautiously learning these uncertainties en route can potentially avoid time- and fuel-consuming pure system identification maneuvers. Recognizing this, this work proposes RATTLE, an online information-aware motion planning algorithm that explicitly weights parametric model-learning coupled with real-time replanning capability that can take advantage of improved system models. The method consists of a two-tiered (global and local) planner, a low-level model predictive controller, and an online parameter estimator that produces estimates of the robot\u2019s inertial properties for more informed control and replanning on-the-fly; all levels of the planning and control feature online update-able models. Simulation results of RAT-TLE for the Astrobee free-flyer grappling an uncertain payload are presented alongside results of a hardware demonstration showcasing the ability to explicitly encourage model parametric learning while achieving otherwise useful motion.",
        "primary_area": "",
        "author": "Monica Ekal;Keenan Albee;Brian Coltin;Rodrigo Ventura;Richard Linares;David W. Miller;Monica Ekal;Keenan Albee;Brian Coltin;Rodrigo Ventura;Richard Linares;David W. Miller",
        "authorids": "/37086391382;/37086406826;/37592328000;/37376311800;/37845468200;/37277086400;/37086391382;/37086406826;/37592328000;/37376311800;/37845468200;/37277086400",
        "aff": "Institute for Systems and Robotics, Instituto Superior T\u00e9cnico; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology; NASA Ames Research Center, SGT Inc.; Institute for Systems and Robotics, Instituto Superior T\u00e9cnico; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636325/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13603996894499159233&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;1;1",
        "aff_unique_norm": "Instituto Superior T\u00e9cnico;Massachusetts Institute of Technology;NASA Ames Research Center",
        "aff_unique_dep": "Institute for Systems and Robotics;Department of Aeronautics and Astronautics;",
        "aff_unique_url": "https://www.ist.utl.pt;https://web.mit.edu;https://ames.nasa.gov",
        "aff_unique_abbr": "IST;MIT;NASA Ames",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;1;1;0;1;1",
        "aff_country_unique": "Portugal;United States"
    },
    {
        "id": "9636659",
        "title": "Online Kinematic and Dynamic Parameter Estimation for Autonomous Surface and Underwater Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the main challenges in underwater robot localization is the scarcity of external positioning references. Therefore, accurate inertial localization in between external position updates is crucial for applications such as underwater environmental sampling. In this paper, we present a framework for estimating kinematic and dynamic model parameters used for inertial navigation. Accurate values of these parameters result in better trajectory estimation. Our approach can run online as well as offline, with either choice providing different advantages. Further, our framework can correct errors in the past trajectory at each estimation step. By doing so, we are able to provide improved geo-references for past as well as future spatial measurements made by the robots. This has an impact on adaptive sampling methods, which use geo-tagged measurements for building local spatial distributions and choose future sampling points. We present results from field experiments and demonstrate improvement in trajectory estimation accuracy. We also experimentally show that with optimal parameter estimates, robots can tolerate longer intervals in external positioning updates for a specified acceptable level of estimation error.",
        "primary_area": "",
        "author": "Anwar Quraishi;Alcherio Martinoli;Anwar Quraishi;Alcherio Martinoli",
        "authorids": "/37086204472;/37325252600;/37086204472;/37325252600",
        "aff": "Distributed Intelligent Systems and Algorithms Laboratory (DISAL), School of Architecture, Civil and Environmental Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Distributed Intelligent Systems and Algorithms Laboratory (DISAL), School of Architecture, Civil and Environmental Engineering, \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636659/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9389573583924556313&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "School of Architecture, Civil and Environmental Engineering",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9635940",
        "title": "Online Monitoring of Object Detection Performance During Deployment",
        "track": "main",
        "status": "Poster",
        "abstract": "During deployment, an object detector is expected to operate at a similar performance level reported on its testing dataset. However, when deployed onboard mobile robots that operate under varying and complex environmental conditions, the detector\u2019s performance can fluctuate and occasionally degrade severely without warning. Undetected, this can lead the robot to take unsafe and risky actions based on low-quality and unreliable object detections. We address this problem and introduce a cascaded neural network that monitors the performance of the object detector by predicting the quality of its mean average precision (mAP) on a sliding window of the input frames. The proposed cascaded network exploits the internal features from the deep neural network of the object detector. We evaluate our proposed approach using different combinations of autonomous driving datasets and object detectors.",
        "primary_area": "",
        "author": "Quazi Marufur Rahman;Niko S\u00fcnderhauf;Feras Dayoub;Quazi Marufur Rahman;Niko S\u00fcnderhauf;Feras Dayoub",
        "authorids": "/37087324639;/37563890800;/37866588000;/37087324639;/37563890800;/37866588000",
        "aff": "Australian Centre for Robotic Vision at Queensland University of Technology (QUT), Brisbane, QLD, Australia; Australian Centre for Robotic Vision at Queensland University of Technology (QUT), Brisbane, QLD, Australia; Australian Centre for Robotic Vision at Queensland University of Technology (QUT), Brisbane, QLD, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635940/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8630125164645994682&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queensland University of Technology",
        "aff_unique_dep": "Australian Centre for Robotic Vision",
        "aff_unique_url": "https://www.qut.edu.au",
        "aff_unique_abbr": "QUT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9636272",
        "title": "Online Recognition of Bimanual Coordination Provides Important Context for Movement Data in Bimanual Teleoperated Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "An important problem in designing human-robot systems is the integration of human intent and performance in the robotic control loop, especially during complex tasks. Bimanual coordination is a complex human behavior that is critical in many fine motor tasks, including robot-assisted surgery. To fully leverage the capabilities of the robot as an intelligent and assistive agent, online recognition of bimanual coordination could be important. Robotic assistance for a suturing task, for example, will be fundamentally different during phases when the suture is wrapped around the instrument (i.e., making a c-loop), than when the ends of the suture are pulled apart. In this study, we develop an online recognition method of bimanual coordination modes (i.e., the directions and symmetries of right and left hand movements) using geometric descriptors of hand motion. We (1) develop this framework based on ideal trajectories obtained during virtual 2D bimanual path following tasks performed by human subjects operating Geomagic Touch haptic devices, (2) test the offline recognition accuracy of bimanual direction and symmetry from human subject movement trials, and (3) evalaute how the framework can be used to characterize 3D trajectories of the da Vinci Surgical System\u2019s surgeon-side manipulators during bimanual surgical training tasks. In the human subject trials, our geometric bimanual movement classification accuracy was 92.3% for movement direction (i.e., hands moving together, parallel, or away) and 86.0% for symmetry (e.g., mirror or point symmetry). We also show that this approach can be used for online classification of different bimanual coordination modes during needle transfer, making a C loop, and suture pulling gestures on the da Vinci system, with results matching the expected modes. Finally, we discuss how these online estimates are sensitive to task environment factors and surgeon expertise, and thus inspire future work that could leverage adaptive control strat... Show More",
        "primary_area": "",
        "author": "Jacob R. Boehm;Nicholas P. Fey;Ann Majewicz Fey;Jacob R. Boehm;Nicholas P. Fey;Ann Majewicz Fey",
        "authorids": "/37088559401;/37085470083;/37086366505;/37088559401;/37085470083;/37086366505",
        "aff": "Walker Department of Mechanical Engineering, Cockrell School of Engineering, The University of Texas at Austin, Austin, TX, USA; Walker Department of Mechanical Engineering, Cockrell School of Engineering, The University of Texas at Austin, Austin, TX, USA; Department of Surgery, University of Texas Southwestern Medical Center, Dallas, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636272/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5767161782329224363&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Texas at Austin;University of Texas Southwestern Medical Center",
        "aff_unique_dep": "Walker Department of Mechanical Engineering;Department of Surgery",
        "aff_unique_url": "https://www.utexas.edu;https://www.utsouthwestern.edu",
        "aff_unique_abbr": "UT Austin;UT Southwestern",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Austin;Dallas",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636625",
        "title": "Online Spatio-temporal Calibration of Tightly-coupled Ultrawideband-aided Inertial Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "The combination of ultrawideband (UWB) radios and inertial measurement units (IMU) can provide accurate positioning in environments where the Global Positioning System (GPS) service is either unavailable or has unsatisfactory performance. The two sensors, IMU and UWB radio, are often not co-located on a moving system. The UWB radio is typically located at the extremities of the system to ensure reliable communication, whereas the IMUs are located closer to its center of gravity. Furthermore, without hardware or software synchronization, data from heterogeneous sensors can arrive at different time instants resulting in temporal offsets. If uncalibrated, these spatial and temporal offsets can degrade the positioning performance. In this paper, using observability and identifiability criteria, we derive the conditions required for successfully calibrating the spatial and the temporal offset parameters of a tightly-coupled UWB-IMU system. We also present an online method for jointly calibrating these offsets. The results show that our calibration approach results in improved positioning accuracy while simultaneously estimating (i) the spatial offset parameters to millimeter precision and (ii) the temporal offset parameter to millisecond precision.",
        "primary_area": "",
        "author": "Abhishek Goudar;Angela P. Schoellig;Abhishek Goudar;Angela P. Schoellig",
        "authorids": "/37089198200;/38488605800;/37089198200;/38488605800",
        "aff": "Vector Institute for Artificial Intelligence in Toronto; Vector Institute for Artificial Intelligence in Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636625/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7855582386190252636&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Vector Institute for Artificial Intelligence",
        "aff_unique_dep": "Artificial Intelligence",
        "aff_unique_url": "https://vectorinstitute.ai",
        "aff_unique_abbr": "Vector Institute",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636610",
        "title": "Online Verification of Impact-Force-Limiting Control for Physical Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans must remain unharmed during their interaction with robots. We present a new method guaranteeing impact force limits when humans and robots share a workspace. Formal guarantees are realized using an online verification method, which plans and verifies fail-safe maneuvers through predicting reachable impact forces by considering all future possible scenarios. We model collisions as a coupled human-robot dynamical system with uncertainties and identify reachset-conforming models based on real-world collision experiments. The effectiveness of our approach for human-robot co-existence is demonstrated for the human hand interacting with the end effector of a six-axis robot manipulator with force sensing. By integrating a human pose detection system, the efficiency of robot movements increases.",
        "primary_area": "",
        "author": "Stefan B. Liu;Matthias Althoff;Stefan B. Liu;Matthias Althoff",
        "authorids": "/37086297522;/37541135900;/37086297522;/37541135900",
        "aff": "Department of Informatics, Cyber-Physical Systems Group, Technical University of Munich, Garching, Germany; Department of Informatics, Cyber-Physical Systems Group, Technical University of Munich, Garching, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636610/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3029742708315303650&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Informatics",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Garching",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636791",
        "title": "Ontology-Assisted Generalisation of Robot Action Execution Knowledge",
        "track": "main",
        "status": "Poster",
        "abstract": "When an autonomous robot learns how to execute actions, it is of interest to know if and when the execution policy can be generalised to variations of the learning scenarios. This can inform the robot about the necessity of additional learning, as using incomplete or unsuitable policies can lead to execution failures. Generalisation is particularly relevant when a robot has to deal with a large variety of objects and in different contexts. In this paper, we propose and analyse a strategy for generalising parameterised execution models of manipulation actions over different objects based on an object ontology. In particular, a robot transfers a known execution model to objects of related classes according to the ontology, but only if there is no other evidence that the model may be unsuitable. This allows using ontological knowledge as prior information that is then refined by the robot\u2019s own experiences. We verify our algorithm for two actions - grasping and stowing everyday objects - such that we show that the robot can deduce cases in which an existing policy can generalise to other objects and when additional execution knowledge has to be acquired.",
        "primary_area": "",
        "author": "Alex Mitrevsk;Paul G. Pl\u00f6ger;Gerhard Lakemeyer;Alex Mitrevsk;Paul G. Pl\u00f6ger;Gerhard Lakemeyer",
        "authorids": "/37089193947;/37344552000;/38533030900;/37089193947;/37344552000;/38533030900",
        "aff": "Department of Computer Science, Hochschule Bonn-Rhein-Sieg, Sankt Augustin, Germany; Department of Computer Science, Hochschule Bonn-Rhein-Sieg, Sankt Augustin, Germany; Department of Computer Science, RWTH Aachen University, Aachen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636791/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8281622134181012123&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Hochschule Bonn-Rhein-Sieg;RWTH Aachen University",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.h-brs.de;https://www.rwth-aachen.de",
        "aff_unique_abbr": ";RWTH",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Sankt Augustin;Aachen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636564",
        "title": "Open-Loop Magnetic Actuation of Helical Robots using Position-Constrained Rotating Dipole Field",
        "track": "main",
        "status": "Poster",
        "abstract": "Control of tetherless magnetically actuated helical robots using rotating dipole fields has a wide variety of medical applications. The most promising technique in manipulation of these robots involves a rotating permanent magnet controlled by a robotic manipulator. In this work, we study the open-loop response of helical robots (in viscous fluids characterized by low Reynolds numbers) in the presence of position constraints on the actuating rotating permanent magnet. We first derive a mapping between the space of the manipulator\u2019s joints, the produced magnetic fields in three-dimensional space, and the translational and rotational velocities of the helical robot. Then, we constrain the 3D position of the rotating dipole field and predict the response of the helical robot by controlling its angular velocity using the constrained mapping. We demonstrate open-loop control and gravity compensation of the robot using the angular velocities of the actuating permanent magnet while enforcing constraints on the end-effector position.",
        "primary_area": "",
        "author": "Ritwik Avaneesh;Roberto Venezian;Chang-Sei Kim;Jong-Oh Park;Sarthak Misra;Islam S. M. Khalil;Ritwik Avaneesh;Roberto Venezian;Chang-Sei Kim;Jong-Oh Park;Sarthak Misra;Islam S. M. Khalil",
        "authorids": "/37089194629;/37089195998;/37422426900;/37281010400;/37536488800;/37409115400;/37089194629;/37089195998;/37422426900;/37281010400;/37536488800;/37409115400",
        "aff": "Department of Biomechanical Engineering, Faculty of Engineering Technology, Surgical Robotics Laboratory, University of Twente, Enschede, AE, The Netherlands; Department of Biomechanical Engineering, Faculty of Engineering Technology, Surgical Robotics Laboratory, University of Twente, Enschede, AE, The Netherlands; School of Mechanical Engineering, Chonnam National University, Gwangju, Republic of Korea; Korea Institute of Medical Micro-Robotics, Gwangju, Republic of Korea; Department of Biomedical Engineering, University of Groningen and University Medical Center Groningen, Groningen, GZ, The Netherlands; Department of Biomechanical Engineering, Faculty of Engineering Technology, Surgical Robotics Laboratory, University of Twente, Enschede, AE, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636564/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5796659969183125728&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;3;0",
        "aff_unique_norm": "University of Twente;Chonnam National University;Korea Institute of Medical Micro-Robotics;University of Groningen",
        "aff_unique_dep": "Department of Biomechanical Engineering;School of Mechanical Engineering;;Department of Biomedical Engineering",
        "aff_unique_url": "https://www.utwente.nl;http://www.chonnam.ac.kr;;https://www.rug.nl",
        "aff_unique_abbr": "UT;CNU;;RUG",
        "aff_campus_unique_index": "0;0;1;1;2;0",
        "aff_campus_unique": "Enschede;Gwangju;Groningen",
        "aff_country_unique_index": "0;0;1;1;0;0",
        "aff_country_unique": "Netherlands;South Korea"
    },
    {
        "id": "9636118",
        "title": "Optimal scheduling and non-cooperative distributed model predictive control for multiple robotic manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Application of multiple robotic manipulators in a shared workspace is still restricted to repetitive tasks limiting their flexible deployment for production systems. Still, existing motion control algorithms cannot be performed online for arbitrary environments in case of multiple manipulators cooperating with each other. In this work we propose a scalable and real-time capable motion control algorithm based on non-cooperative distributed model predictive control. Furthermore, we propose an optimal scheduling algorithm, which provides optimal setpoints to each robot\u2019s motion controller that prevents possible deadlocks beforehand. We validate our approach on a simulative setup of four robotic manipulators for multiple pick and place scenarios.",
        "primary_area": "",
        "author": "Nigora Gafur;Vassilios Yfantis;Martin Ruskowski;Nigora Gafur;Vassilios Yfantis;Martin Ruskowski",
        "authorids": "/37089194557;/37089197159;/37086405564;/37089194557;/37089197159;/37086405564",
        "aff": "Department of Mechanical and Process Engineering, Chair of Machine Tools and Control Systems, Technische Universit\u00e4t Kaiserslautern and German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; Department of Mechanical and Process Engineering, Chair of Machine Tools and Control Systems, Technische Universit\u00e4t Kaiserslautern and German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany; Department of Mechanical and Process Engineering, Chair of Machine Tools and Control Systems, Technische Universit\u00e4t Kaiserslautern and German Research Center for Artificial Intelligence (DFKI), Kaiserslautern, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636118/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6371894480971693072&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Kaiserslautern",
        "aff_unique_dep": "Department of Mechanical and Process Engineering, Chair of Machine Tools and Control Systems",
        "aff_unique_url": "https://www.uni-kl.de",
        "aff_unique_abbr": "TU Kaiserslautern",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kaiserslautern",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636029",
        "title": "Optimization-Based Robot Team Exploration Considering Attrition and Communication Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Exploring robots may fail due to environmental hazards. Thus, robots need to account for the possibility of failure to plan the best exploration paths. Optimizing expected utility enables robots to find plans that balance achievable reward with the inherent risks of exploration. Moreover, when robots rendezvous and communicate to exchange observations, they increase the probability that at least one robot is able to return with the map. Optimal exploration is NP-hard, so we apply a constraint-based approach to enable highly-engineered solution techniques. We model exploration under the possibility of robot failure and communication constraints as an integer, linear program and a generalization of the Vehicle Routing Problem. Empirically, we show that for several scenarios, this formulation produces paths within 50% of a theoretical optimum and achieves twice as much reward as a baseline greedy approach.",
        "primary_area": "",
        "author": "Matthew A. Schack;John G. Rogers;Qi Han;Neil T. Dantam;Matthew A. Schack;John G. Rogers;Qi Han;Neil T. Dantam",
        "authorids": "/37088841151;/37533731800;/37289404800;/37546520000;/37088841151;/37533731800;/37289404800;/37546520000",
        "aff": "Department of Computer Science, Colorado School of Mines, USA; United States Army Research Laboratory, Adelphi, MD, USA; Department of Computer Science, Colorado School of Mines, USA; United States Army Research Laboratory, Adelphi, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636029/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5575685017756173497&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Colorado School of Mines;United States Army Research Laboratory",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.mines.edu;https://www.arl.army.mil",
        "aff_unique_abbr": "CSM;ARL",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Adelphi",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636240",
        "title": "Optimizing Requests for Support in Context-Restricted Autonomy",
        "track": "main",
        "status": "Poster",
        "abstract": "Adjustable Autonomy is gaining interest as it alleviates robot management costs, which often restrain non-routine applications. Whereas it seems straightforward to account for the availability of helpers when making plans that involve being granted for support in the future, no existing research covers this issue. As a solution, we formalize the first human-centric model that accounts for operator support dynamics when generating adjustable-autonomy plans. We formalize Restricted Autonomy Levels (RAL) within a Markov-based framework for representing when and what level of support the robot should ask for. This model is combined with a formalization of usual aspects of man-machine collaboration: operator availability, risk of denial and withdrawal, effect of teleoperation, risks and consequences for violating RAL restrictions and backup procedures, should violations occur. We empirically demonstrate, through a detailed example and the deployment on a professional-grade security robot, that the generated plans deeply combine the problem-solving activities of the robot with the management of requested human support, leading to improved performance and decreased operator effort. We also analyse the computational costs of computing policies that ensure a zero-chance of RAL violation.",
        "primary_area": "",
        "author": "Lo\u00efs Vanh\u00e9e;Laurent Jeanpierre;Abdel-Illah Mouaddib;Lo\u00efs Vanh\u00e9e;Laurent Jeanpierre;Abdel-Illah Mouaddib",
        "authorids": "/37888580700;/37402787800;/37282448000;/37888580700;/37402787800;/37282448000",
        "aff": "GREYC, Universit\u00e9 de Caen, Caen, France; GREYC, Universit\u00e9 de Caen, Caen, France; GREYC, Universit\u00e9 de Caen, Caen, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636240/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4712557333147060720&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universit\u00e9 de Caen",
        "aff_unique_dep": "GREYC",
        "aff_unique_url": "https://www.unicaen.fr",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Caen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636389",
        "title": "Organization and Understanding of a Tactile Information Dataset TacAct For Physical Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Human touching the robot to convey intentions or emotions is an essential communication pathway during physical Human-Robot Interaction (pHRI). Therefore, advanced service robots require superior tactile intelligence to guarantee naturalness and safety when making physical contact with human subjects. Tactile intelligence is the capability to percept and recognize tactile information from touch behaviors, in which understanding the physical meaning of touching actions is crucial. For this purpose, this report introduces a recently collected and organized dataset \"TacAct\" that encloses real-time tactile information when human subjects touched the test device mimicking a robot forearm. The dataset contains 12 types of 24,000 touch actions from 50 subjects. The dataset details are described, the data are preliminarily analyzed, and the validity of the dataset is tested through a convolutional neural network LeNet-5 which classifying different types of touch actions. We believe that the TacAct dataset would be beneficial for the community to understand the touch intention under various circumstances and to develop learning-based intelligent algorithms for different applications.",
        "primary_area": "",
        "author": "Peng Wang;Jixiao Liu;Funing Hou;Dicai Chen;Zihou Xia;Shijie Guo;Peng Wang;Jixiao Liu;Funing Hou;Dicai Chen;Zihou Xia;Shijie Guo",
        "authorids": "/37087007664;/37087007842;/37088373895;/37089195312;/37089194002;/37086276620;/37087007664;/37087007842;/37088373895;/37089195312;/37089194002;/37086276620",
        "aff": "Hebei Key Laboratory of Smart Sensing and Human-Robot Interaction, Hebei University of Technology, Tianjin; Hebei Key Laboratory of Smart Sensing and Human-Robot Interaction, Hebei University of Technology, Tianjin; Hebei Key Laboratory of Smart Sensing and Human-Robot Interaction, Hebei University of Technology, Tianjin; Hebei Key Laboratory of Smart Sensing and Human-Robot Interaction, Hebei University of Technology, Tianjin; Hebei Key Laboratory of Smart Sensing and Human-Robot Interaction, Hebei University of Technology, Tianjin; Hebei Key Laboratory of Smart Sensing and Human-Robot Interaction, Hebei University of Technology, Tianjin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636389/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10388735334626352789&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Hebei University of Technology",
        "aff_unique_dep": "Hebei Key Laboratory of Smart Sensing and Human-Robot Interaction",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tianjin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636051",
        "title": "Orientation-Aware Planning for Parallel Task Execution of Omni-Directional Mobile Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Omni-directional mobile robot (OMR) systems have been very popular in academia and industry for their superb maneuverability and flexibility. Yet their potential has not been fully exploited, where the extra degree of freedom in OMR can potentially enable the robot to carry out extra tasks. For instance, gimbals or sensors on robots may suffer from a limited field of view or be constrained by the inherent mechanical design, which will require the chassis to be orientation-aware and respond in time. To solve this problem and further develop the OMR systems, in this paper, we categorize the tasks related to OMR chassis into orientation transition tasks and position transition tasks, where the two tasks can be carried out at the same time. By integrating the parallel task goals in a single planning problem, we proposed an orientation-aware planning architecture for OMR systems to execute the orientation transition and position transition in a unified and efficient way. A modified trajectory optimization method called orientation-aware timed-elastic-band (OATEB) is introduced to generate the trajectory that satisfies the requirements of both tasks. Experiments in both 2D simulated environments and real scenes are carried out. A four-wheeled OMR is deployed to conduct the real scene experiment and the results demonstrate that the proposed method is capable of simultaneously executing parallel tasks and is applicable to real-life scenarios.",
        "primary_area": "",
        "author": "Cheng Gong;Zirui Li;Xingyu Zhou;Jiachen Li;Junhui Zhou;Jianwei Gong;Cheng Gong;Zirui Li;Xingyu Zhou;Jiachen Li;Junhui Zhou;Jianwei Gong",
        "authorids": "/37086964205;/37086488565;/37089611478;/37086309095;/37089195739;/37290570400;/37086964205;/37086488565;/37089611478;/37086309095;/37089195739;/37290570400",
        "aff": "School of Mechanical Engineering, Beijing Institute of Technology, Beijing, China; Department of Transport and Planning, Faculty of Civil Engineering and Geosciences, Delft University of Technology, Delft, The Netherlands; School of Aerospace Engineering, Beijing Institute of Technology, Beijing, China; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; School of Aerospace Engineering, Beijing Institute of Technology, Beijing, China; School of Mechanical Engineering, Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636051/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17445372541407723938&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;0",
        "aff_unique_norm": "Beijing Institute of Technology;Delft University of Technology;University of California, Berkeley",
        "aff_unique_dep": "School of Mechanical Engineering;Department of Transport and Planning;Department of Mechanical Engineering",
        "aff_unique_url": "http://www.bit.edu.cn;https://www.tudelft.nl;https://www.berkeley.edu",
        "aff_unique_abbr": "BIT;TUDelft;UC Berkeley",
        "aff_campus_unique_index": "0;1;0;2;0;0",
        "aff_campus_unique": "Beijing;Delft;Berkeley",
        "aff_country_unique_index": "0;1;0;2;0;0",
        "aff_country_unique": "China;Netherlands;United States"
    },
    {
        "id": "9636420",
        "title": "Origami Logic Gates for Printable Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Origami robots\u2013often called \"printable\" robots\u2013 created using folding processes have gained extensive attention due to their potential for rapid and accessible design and fabrication through simple structures with complex functionalities. However, almost all origami robots require conventional rigid electronics for control, which may hinder the integration and restrict the potential of these origami systems. Here we introduce origami logic gates that can be built through folding. The major enabling technology is a bistable switch that can switch between two different circuits to control the electrical flow. Based on the origami switch, we develop NOT, AND, and OR logic gates (showing functional completeness) and demonstrate these logic gates through sufficiently powering low-current LEDs. These logic gates are fabricated using cut-and-fold manufacturing and offer a potential way of integrating logic functions directly into origami machines without electronics.",
        "primary_area": "",
        "author": "Wenzhong Yan;Chang Liu;Ankur Mehta;Wenzhong Yan;Chang Liu;Ankur Mehta",
        "authorids": "/37087323423;/37086303084;/37086302574;/37087323423;/37086303084;/37086302574",
        "aff": "Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, University of California, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636420/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14966628246451042603&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636761",
        "title": "Overcoming Obstructions via Bandwidth-Limited Multi-Agent Spatial Handshaking",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address bandwidth-limited and obstruction-prone collaborative perception, specifically in the context of multi-agent semantic segmentation. This setting presents several key challenges, including processing and ex-changing unregistered robotic swarm imagery. To be successful, solutions must effectively leverage multiple non-static and intermittently-overlapping RGB perspectives, while heeding bandwidth constraints and overcoming unwanted foreground obstructions. As such, we propose an end-to-end learn-able Multi-Agent Spatial Handshaking network (MASH) to process, compress, and propagate visual information across a robotic swarm. Our distributed communication module operates directly (and exclusively) on raw image data, without additional input requirements such as pose, depth, or warping data. We demonstrate superior performance of our model compared against several baselines in a photo-realistic multi-robot AirSim environment, especially in the presence of image occlusions. Our method achieves an absolute 11% IoU improvement over strong baselines.",
        "primary_area": "",
        "author": "Nathaniel Glaser;Yen-Cheng Liu;Junjiao Tian;Zsolt Kira;Nathaniel Glaser;Yen-Cheng Liu;Junjiao Tian;Zsolt Kira",
        "authorids": "/37088459369;/37086334253;/37088456016;/37681676600;/37088459369;/37086334253;/37088456016;/37681676600",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636761/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13890366480308929360&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636833",
        "title": "Overlap Displacement Error: Are Your SLAM Poses Map-Consistent?",
        "track": "main",
        "status": "Poster",
        "abstract": "Localization is an essential module that supports many intelligent functions of a mobile robot such as transportation or inspection. However, justifying that a localization module is sufficiently accurate for supporting all downstream tasks is one of the most difficult questions to answer in practice. To overcome this problem, we move away from the traditional calculation of pose errors and propose a new approach that instead evaluates the potential map inconsistency introduced by those pose errors.For this purpose, we propose a new metric, which we call Overlap Displacement Error (ODE). This metric measures the relative displacements between multiple overlapping sensor frustums with respect to the ground truth. All you need to compute this metric are a query trajectory, a ground truth trajectory and the sensor frustum used for mapping. Having the sensor frustum and the map representation as part of the metric, the ODE is customized to the hardware configuration and the mapping strategy. This design allows the analysis of pose accuracy in a space that matters to map creation, and also allows the identification of problems sitting in the interplay between localization and mapping. We demonstrate the potential of this new analysis tool on synthetic and the real-world sequences.",
        "primary_area": "",
        "author": "Christian Mostegel;Jianbo Ye;Yu Luo;Yang Liu;Christian Mostegel;Jianbo Ye;Yu Luo;Yang Liu",
        "authorids": "/37085585012;/37089196289;/37089194979;/37089195072;/37085585012;/37089196289;/37089194979;/37089195072",
        "aff": "Amazon; Amazon; Amazon; Amazon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636833/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7040469339405283197&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Amazon",
        "aff_unique_dep": "Amazon.com, Inc.",
        "aff_unique_url": "https://www.amazon.com",
        "aff_unique_abbr": "Amazon",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636483",
        "title": "PCTMA-Net: Point Cloud Transformer with Morphing Atlas-based Point Generation Network for Dense Point Cloud Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "Inferring a complete 3D geometry given an in-complete point cloud is essential in many vision and robotics applications. Previous work mainly relies on a global feature extracted by a Multi-layer Perceptron (MLP) for predicting the shape geometry. This suffers from a loss of structural details, as its point generator fails to capture the detailed topology and structure of point clouds using only the global features. The irregular nature of point clouds makes this task more challenging. This paper presents a novel method for shape completion to address this problem. The Transformer structure is currently a standard approach for natural language processing tasks and its inherent nature of permutation invariance makes it well suited for learning point clouds. Furthermore, the Transformer\u2019s attention mechanism can effectively capture the local context within a point cloud and efficiently exploit its incomplete local structure details. A morphing-atlas-based point generation network further fully utilizes the extracted point Transformer feature to predict the missing region using charts defined on the shape. Shape completion is achieved via the concatenation of all predicting charts on the surface. Extensive experiments on the Completion3D and KITTI data sets demonstrate that the proposed PCTMA-Net outperforms the state-of-the-art shape completion approaches and has a 10% relative improvement over the next best-performing method.",
        "primary_area": "",
        "author": "Jianjie Lin;Markus Rickert;Alexander Perzylo;Alois Knoll;Jianjie Lin;Markus Rickert;Alexander Perzylo;Alois Knoll",
        "authorids": "/37088691130;/37681876600;/38016028000;/37276234100;/37088691130;/37681876600;/38016028000;/37276234100",
        "aff": "Department of Informatics, Robotics, Artificial Intelligence and Real-Time Systems, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Department of Informatics, Robotics, Artificial Intelligence and Real-Time Systems, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Department of Informatics, Robotics, Artificial Intelligence and Real-Time Systems, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Department of Informatics, Robotics, Artificial Intelligence and Real-Time Systems, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636483/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14404672207986299096&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen",
        "aff_unique_dep": "Department of Informatics, Robotics, Artificial Intelligence and Real-Time Systems",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636134",
        "title": "PG-RRT: A Gaussian Mixture Model Driven, Kinematically Constrained Bi-directional RRT for Robot Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Path planning and smooth trajectory generation are critical capabilities for efficient navigation of mobile robots operating in challenging and cluttered environments. For real time and autonomous operations of mobile robots, intelligent algorithms, efficient and light-weight compute, and smooth trajectory are key components. In this work, we propose an intelligent, probabilistic Gaussian mixture model driven Bi-RRT (PG-RRT) algorithm which generates nodes in the most probable regions for faster convergence. The proposed algorithm is tested in various simulated environments including highly cluttered obstacles. The experimental results of PG-RRT are compared with state-of-the-art path planning algorithms. The results show significant improvement in the number of iterations (up to 26X) and runtime (up to 17.5X) demonstrating the superiority of the proposed PG-RRT algorithm.",
        "primary_area": "",
        "author": "Paras Sharma;Ankit Gupta;Dibyendu Ghosh;Vinayak Honkote;Ganeshram Nandakumar;Debasish Ghose;Paras Sharma;Ankit Gupta;Dibyendu Ghosh;Vinayak Honkote;Ganeshram Nandakumar;Debasish Ghose",
        "authorids": "/37089196570;/37086345862;/37086702221;/37400592800;/38116644500;/37282785700;/37089196570;/37086345862;/37086702221;/37400592800;/38116644500;/37282785700",
        "aff": "Indraprastha Institute of Information Technology, Delhi, India; Silicon and Systems Prototyping Lab, Intel Technology, India; Silicon and Systems Prototyping Lab, Intel Technology, India; Silicon and Systems Prototyping Lab, Intel Technology, India; Tunga Aerospace Industries (P) Ltd., India; Indian Institute of Science, Bangalore, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636134/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11182123948453939270&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;2;3",
        "aff_unique_norm": "Indraprastha Institute of Information Technology;Intel;Tunga Aerospace Industries;Indian Institute of Science",
        "aff_unique_dep": ";Silicon and Systems Prototyping Lab;;",
        "aff_unique_url": "http://www.iiitd.ac.in;https://www.intel.com;;https://www.iisc.ac.in",
        "aff_unique_abbr": "IIIT-D;Intel;;IISc",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Delhi;;Bangalore",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9636862",
        "title": "PILOT: Efficient Planning by Imitation Learning and Optimisation for Safe Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Achieving a proper balance between planning quality, safety and efficiency is a major challenge for autonomous driving. Optimisation-based motion planners are capable of producing safe, smooth and comfortable plans, but often at the cost of runtime efficiency. On the other hand, na\u00efvely deploying trajectories produced by efficient-to-run deep imitation learning approaches might risk compromising safety. In this paper, we present PILOT a planning framework that comprises an imitation neural network followed by an efficient optimiser that actively rectifies the network\u2019s plan, guaranteeing fulfilment of safety and comfort requirements. The objective of the efficient optimiser is the same as the objective of an expensive-to-run optimisation-based planning system that the neural network is trained offline to imitate. This efficient optimiser provides a key layer of online protection from learning failures or deficiency in out-of-distribution situations that might compromise safety or comfort. Using a state-of-the-art, runtime-intensive optimisation-based method as the expert, we demonstrate in simulated autonomous driving experiments in CARLA that PILOT achieves a seven-fold reduction in runtime when compared to the expert it imitates without sacrificing planning quality.",
        "primary_area": "",
        "author": "Henry Pulver;Francisco Eiras;Ludovico Carozza;Majd Hawasly;Stefano V. Albrecht;Subramanian Ramamoorthy;Henry Pulver;Francisco Eiras;Ludovico Carozza;Majd Hawasly;Stefano V. Albrecht;Subramanian Ramamoorthy",
        "authorids": "/37089195065;/37086581181;/37089403706;/37086376387;/37088996736;/37529920500;/37089195065;/37086581181;/37089403706;/37086376387;/37088996736;/37529920500",
        "aff": "Five AI Ltd., United Kingdom; University of Oxford, United Kingdom; Five AI Ltd., United Kingdom; Five AI Ltd., United Kingdom; University of Edinburgh, United Kingdom; University of Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636862/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5857895074649905676&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;2;2",
        "aff_unique_norm": "Five AI Ltd.;University of Oxford;University of Edinburgh",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";https://www.ox.ac.uk;https://www.ed.ac.uk",
        "aff_unique_abbr": ";Oxford;Edinburgh",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9635875",
        "title": "PLUMENet: Efficient 3D Object Detection from Stereo Images",
        "track": "main",
        "status": "Poster",
        "abstract": "3D object detection is a key component of many robotic applications such as self-driving vehicles. While many approaches rely on expensive 3D sensors such as LiDAR to produce accurate 3D estimates, methods that exploit stereo cameras have recently shown promising results at a lower cost. Existing approaches tackle this problem in two steps: first depth estimation from stereo images is performed to produce a pseudo LiDAR point cloud, which is then used as input to a 3D object detector. However, this approach is suboptimal due to the representation mismatch, as the two tasks are optimized in two different metric spaces. In this paper we propose a model that unifies these two tasks and performs them in the same metric space. Specifically, we directly construct a pseudo LiDAR feature volume (PLUME) in 3D space, which is then used to solve both depth estimation and object detection tasks. Our approach achieves state-of-the-art performance with much faster inference times when compared to existing methods on the challenging KITTI benchmark [1].",
        "primary_area": "",
        "author": "Yan Wang;Bin Yang;Rui Hu;Ming Liang;Raquel Urtasun;Yan Wang;Bin Yang;Rui Hu;Ming Liang;Raquel Urtasun",
        "authorids": "/37086565708;/37399884400;/37087232841;/37087231216;/37269502900;/37086565708;/37399884400;/37087232841;/37087231216;/37269502900",
        "aff": "Cornell University; University of Toronto; Waabi; Waabi; University of Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635875/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10263898106673486339&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;1",
        "aff_unique_norm": "Cornell University;University of Toronto;Waabi",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.cornell.edu;https://www.utoronto.ca;",
        "aff_unique_abbr": "Cornell;U of T;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;Canada;"
    },
    {
        "id": "9636234",
        "title": "PNS: Population-Guided Novelty Search for Reinforcement Learning in Hard Exploration Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement Learning (RL) has made remarkable achievements, but it still suffers from inadequate exploration strategies, sparse reward signals, and deceptive reward functions. To alleviate these problems, a Population-guided Novelty Search (PNS) parallel learning method is proposed in this paper. In PNS, the population is divided into multiple sub-populations, each of which has one chief agent and several exploring agents. The chief agent evaluates the policies learned by exploring agents and shares the optimal policy with all sub-populations. The exploring agents learn their policies in collaboration with the guidance of the optimal policy and, simultaneously, upload their policies to the chief agent. To balance exploration and exploitation, the Novelty Search (NS) is employed in every chief agent to encourage policies with high novelty while maximizing per-episode performance. We apply PNS to the twin delayed deep deterministic (TD3) policy gradient algorithm. The effectiveness of PNS to promote exploration and improve performance in continuous control domains is demonstrated in the experimental section. Notably, PNS-TD3 achieves rewards that far exceed the SOTA methods in environments with sparse or delayed reward signals. We also demonstrate that PNS enables robotic agents to learn control policies directly from pixels for sparse-reward manipulation in both simulated and real-world settings.",
        "primary_area": "",
        "author": "Qihao Liu;Yujia Wang;Xiaofeng Liu;Qihao Liu;Yujia Wang;Xiaofeng Liu",
        "authorids": "/37089195223;/37089195088;/37089195487;/37089195223;/37089195088;/37089195487",
        "aff": "Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636234/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8860682673759927567&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635866",
        "title": "POMP++: Pomcp-based Active Visual Search in unknown indoor environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we focus on the problem of learning online an optimal policy for Active Visual Search (AVS) of objects in unknown indoor environments. We propose POMP++, a planning strategy that introduces a novel formulation on top of the classic Partially Observable Monte Carlo Planning (POMCP) framework, to allow training-free online policy learning in unknown environments. We present a new belief reinvigoration strategy that enables the use of POMCP with a dynamically growing state space to address the online generation of the floor map. We evaluate our method on two public benchmark datasets, AVD that is acquired by real robotic platforms and Habitat ObjectNav that is rendered from real 3D scene scans, achieving the best success rate with an improvement of >10% over the state-of-the-art methods.",
        "primary_area": "",
        "author": "Francesco Giuliari;Alberto Castellini;Riccardo Berra;Alessio Del Bue;Alessandro Farinelli;Marco Cristani;Francesco Setti;Yiming Wang;Francesco Giuliari;Alberto Castellini;Riccardo Berra;Alessio Del Bue;Alessandro Farinelli;Marco Cristani;Francesco Setti;Yiming Wang",
        "authorids": "/37088855203;/37086137344;/37087103705;/38527901400;/37266396700;/37269169100;/37887481900;/37088909595;/37088855203;/37086137344;/37087103705;/38527901400;/37266396700;/37269169100;/37887481900;/37088909595",
        "aff": "Visual Geometry and Modelling (VGM) and Pattern Analysis and Computer Vision (PAVIS), Fondazione Istituto Italiano di Tecnologia, Italy; Department of Computer Science, University of Verona, Italy; Department of Computer Science, University of Verona, Italy; Visual Geometry and Modelling (VGM) and Pattern Analysis and Computer Vision (PAVIS), Fondazione Istituto Italiano di Tecnologia, Italy; Department of Computer Science, University of Verona, Italy; Department of Computer Science, University of Verona, Italy; Department of Computer Science, University of Verona, Italy; Deep Visual Learning (DVL) Unit, Fondazione Bruno Kessler, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635866/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1957975281367384796&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;0;1;1;1;2",
        "aff_unique_norm": "Fondazione Istituto Italiano di Tecnologia;University of Verona;Fondazione Bruno Kessler",
        "aff_unique_dep": "Visual Geometry and Modelling (VGM), Pattern Analysis and Computer Vision (PAVIS);Department of Computer Science;Deep Visual Learning (DVL) Unit",
        "aff_unique_url": "https://www.iit.it;https://www.univr.it;https://www.fbk.eu",
        "aff_unique_abbr": "IIT;;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636821",
        "title": "PTT: Point-Track-Transformer Module for 3D Single Object Tracking in Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "3D single object tracking is a key issue for robotics. In this paper, we propose a transformer module called Point-Track-Transformer (PTT) for point cloud-based 3D single object tracking. PTT module contains three blocks for feature embedding, position encoding, and self-attention feature computation. Feature embedding aims to place features closer in the embedding space if they have similar semantic information. Position encoding is used to encode coordinates of point clouds into high dimension distinguishable features. Self-attention generates refined attention features by computing attention weights. Besides, we embed the PTT module into the open-source state-of-the-art method P2B to construct PTT-Net. Experiments on the KITTI dataset reveal that our PTT-Net surpasses the state-of-the-art by a noticeable margin \\left( {\\sim 10\\% } \\right)\\left( {\\sim 10\\% } \\right). Additionally, PTT-Net could achieve real-time performance (~40FPS) on NVIDIA 1080Ti GPU. Our code is open-sourced for the robotics community at https://github.com/shanjiayao/PTT.",
        "primary_area": "",
        "author": "Jiayao Shan;Sifan Zhou;Zheng Fang;Yubo Cui;Jiayao Shan;Sifan Zhou;Zheng Fang;Yubo Cui",
        "authorids": "/37089197299;/37088646039;/37401391100;/37088641365;/37089197299;/37088646039;/37401391100;/37088641365",
        "aff": "Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636821/",
        "gs_citation": 96,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12288702026819898849&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Faculty of Robot Science and Engineering",
        "aff_unique_url": "http://www.neu.edu.cn/",
        "aff_unique_abbr": "NEU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenyang",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635914",
        "title": "PackerBot: Variable-Sized Product Packing with Heuristic Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Product packing is a typical application in ware-house automation that aims to pick objects from unstructured piles and place them into bins with optimized placing policy. However, it still remains a significant challenge to finish the product packing tasks in general logistics scenarios where the objects are variable-sized and the configurations are complex. In this work, we present the PackerBot, a complete robotic pipeline for performing variable-sized product packing in unstructured scenes. First, by leveraging the imperfect experience of human packer, we propose a heuristic DRL framework for learning optimal online 3D bin packing policy. Then we integrate it with a 6-DoF suction-based picking module and a product size estimation module, leading to a complete product packing system, namely the PackerBot. Extensive experimental results show that our method achieves the state-of-the-art performance in both simulated and real-world tests. The video demonstration is available at: https://vsislab.github.io/packerbot.",
        "primary_area": "",
        "author": "Zifei Yang;Shuo Yang;Shuai Song;Wei Zhang;Ran Song;Jiyu Cheng;Yibin Li;Zifei Yang;Shuo Yang;Shuai Song;Wei Zhang;Ran Song;Jiyu Cheng;Yibin Li",
        "authorids": "/37089170351;/37087322435;/37089194140;/37085379581;/37546859100;/37086026328;/37279897500;/37089170351;/37087322435;/37089194140;/37085379581;/37546859100;/37086026328;/37279897500",
        "aff": "School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635914/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16884419152694375748&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Shandong University",
        "aff_unique_dep": "School of Control Science and Engineering",
        "aff_unique_url": "http://www.sdu.edu.cn",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Jinan",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636671",
        "title": "Pain Expression-based Visual Feedback Method for Care Training Assistant Robot with Musculoskeletal Symptoms",
        "track": "main",
        "status": "Poster",
        "abstract": "A human patient simulator (HPS) can achieve effective visual-, auditory-, text-, and alarm-based feedback methods in care or nursing education. Among these, the method of visual feedback is important to design an HPS that can express emotions or feelings of pain like an actual human does because this method allows an immediate reaction between robots and humans. This study aims to develop an avatar-based visual feedback method for a care training assistant robot that can express pain states in joint care education. First, this study introduces its own pain facial expression database from Ritsumeikan University (RU-PITENS) for an avatar with pain expression. The RU-PITENS database contains pain images of 41 Japanese people in their 20s, 30s, 40s, and 60s, and an experiment of pain stimulus is conducted based on transcutaneous electrical nerve stimulation, which is low-cost and easy to use in daily life. Based on the pain images in the RU-PITENS database, we generated an avatar with pain expression to achieve the goal of our study. Since the RUPITENS database does not contain the quantitative pain level, the Siamese network was used to calculate the pain intensity. In addition, the care training assistant robot (CaTARo) developed in our previous study reproduces symptoms of musculoskeletal diseases, and the pain of CaTARo was measured using fuzzy logic theory. As a result, a visual feedback system was constructed to express five types of pain (no pain at all, very faint, weak, moderate, and strong pain) with avatars according to the intensity of the pain output of CaTARo in care training environments.",
        "primary_area": "",
        "author": "Miran Lee;Dinh Tuan Tran;Joo-Ho Lee;Miran Lee;Dinh Tuan Tran;Joo-Ho Lee",
        "authorids": "/37086919626;/38236147000;/37089611788;/37086919626;/38236147000;/37089611788",
        "aff": "The Graduate School of Information Science and Engineering, Ritsumeikan University, Shiga, Japan; The Faculty of Information Science and Engineering, Ritsumeikan University, Shiga, Japan; The Graduate School of Information Science and Engineering, Ritsumeikan University, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636671/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8077816414780788198&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "Graduate School of Information Science and Engineering",
        "aff_unique_url": "https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shiga",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636184",
        "title": "Pairwise Preferences-Based Optimization of a Path-Based Velocity Planner in Robotic Sealing Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Production plants are being re-designed to implement human-centered solutions. Especially considering high added-value operations, robots are required to optimize their behavior to achieve a task quality at least comparable to the one obtained by the skilled operators. A manual programming and tuning of the manipulator is not an efficient solution, requiring to adopt towards automated strategies. Adding external sensors (e.g., cameras) increases the robotic cell complexity and it doesn\u2019t solve the issue since it is usually difficult to build explicit reward functions measuring the robot performance, while it is easier for the user to define a qualitative comparison between two experiments. According to these needs, in this paper, the recently-developed preferences-based optimization approach GLISp is employed and adapted to tune the novel developed path-based velocity planner. The implemented solution defines an intuitive human-centered procedure, capable of transferring (through pairwise preferences between experiments) the task knowledge from the operator to the manipulator. A Franka EMIKA panda robot has been employed as a test platform to perform a robotic sealing task (i.e., material deposition task), validating the proposed methodology. The proposed approach has been compared with a programming by demonstration approach, and with the manual tuning of the path-based velocity planner. Achieved results demonstrate the improved deposition quality obtained with the proposed optimized path-based velocity planner methodology in a limited number of experimental trials (20).",
        "primary_area": "",
        "author": "Loris Roveda;Beatrice Maggioni;Elia Marescotti;Asad Ali Shahid;Andrea Maria Zanchettin;Alberto Bemporad;Dario Piga;Loris Roveda;Beatrice Maggioni;Elia Marescotti;Asad Ali Shahid;Andrea Maria Zanchettin;Alberto Bemporad;Dario Piga",
        "authorids": "/37085412592;/37088917134;/37088915488;/37088586062;/37546427600;/37300848100;/37398458800;/37085412592;/37088917134;/37088915488;/37088586062;/37546427600;/37300848100;/37398458800",
        "aff": "Istituto Dalle Molle di Studi Sull\u2019Intelligenza Artificiale (IDSIA), USI-SUPSI, Lugano, Switzerland; Department of Mechanical Engineering, Politecnico di Milano, Milano, Italy; Department of Mechanical Engineering, Politecnico di Milano, Milano, Italy; Istituto Dalle Molle di Studi Sull\u2019Intelligenza Artificiale (IDSIA), USI-SUPSI, Lugano, Switzerland; Department of Mechanical Engineering, Politecnico di Milano, Milano, Italy; IMT School for Advanced Studies Lucca, Lucca, Italy; Istituto Dalle Molle di Studi Sull\u2019Intelligenza Artificiale (IDSIA), USI-SUPSI, Lugano, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636184/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17514292363056776585&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;0;1;2;0",
        "aff_unique_norm": "Istituto Dalle Molle di Studi Sull\u2019Intelligenza Artificiale;Politecnico di Milano;IMT School for Advanced Studies",
        "aff_unique_dep": ";Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.idsia.ch;https://www.polimi.it;https://www.imtlucca.it",
        "aff_unique_abbr": "IDSIA;Politecnico di Milano;IMT",
        "aff_campus_unique_index": "0;1;1;0;1;2;0",
        "aff_campus_unique": "Lugano;Milano;Lucca",
        "aff_country_unique_index": "0;1;1;0;1;1;0",
        "aff_country_unique": "Switzerland;Italy"
    },
    {
        "id": "9636270",
        "title": "Pallet detection and docking strategy for autonomous pallet truck AGV operation",
        "track": "main",
        "status": "Poster",
        "abstract": "Automated guided vehicles operation in human populated factory environments is a challenging task, especially when there is a demand to operate without following fixed paths defined by guide wires, magnetic tape, magnets, or transponders embedded in the floor. The paper at hand introduces a vision-based method enabling safe and autonomous operation of pallet moving vehicles that accommodate pallet detection, pose estimation, docking control and pallet pick up in such industrial environments. A dedicated perception topology relying on monocular vision and laser-based measurements has been applied and installed on-board a novel robotic pallet truck. Pallet detection and pose estimation are performed in two steps. Firstly, a deep neural network is used for the fast isolation of pallets' regions of interest and, secondly, model-based geometrical pattern matching on point cloud data is applied to extract the pallet pose. Robot alignment with candidate pallet is performed with a dedicated visual servoing controller. The developed method has been extensively evaluated both in simulated and real industrial environments with the pallet truck and proved to have real-time performance achieving increased accuracy in navigation, pallet detection and pick-up.",
        "primary_area": "",
        "author": "Efthimios Tsiogas;Ioannis Kleitsiotis;Ioannis Kostavelis;Andreas Kargakos;Dimitris Giakoumis;Marc Bosch-Jorge;Raquel Julia Ros;Rafa L\u00f3pez Taraz\u00f3n;Spyridon Likothanassis;Dimitrios Tzovaras;Efthimios Tsiogas;Ioannis Kleitsiotis;Ioannis Kostavelis;Andreas Kargakos;Dimitris Giakoumis;Marc Bosch-Jorge;Raquel Julia Ros;Rafa L\u00f3pez Taraz\u00f3n;Spyridon Likothanassis;Dimitrios Tzovaras",
        "authorids": "/37087083726;/37089194463;/38480784400;/37085561299;/37546562700;/37089195115;/37410240600;/37089197895;/37325941900;/37269764300;/37087083726;/37089194463;/38480784400;/37085561299;/37546562700;/37089195115;/37410240600;/37089197895;/37325941900;/37269764300",
        "aff": "Centre for Research and Technology Hellas - Information Technologies Institute (CERTH/ITI), Thessaloniki, Greece; Computer Engineering and Informatics, Large Scale Machine Learning and Cloud Data Engineering Lab, University of Patras, Greece; Centre for Research and Technology Hellas - Information Technologies Institute (CERTH/ITI), Thessaloniki, Greece; Centre for Research and Technology Hellas - Information Technologies Institute (CERTH/ITI), Thessaloniki, Greece; Centre for Research and Technology Hellas - Information Technologies Institute (CERTH/ITI), Thessaloniki, Greece; Robotnik Automation S. L. L., Valencia, Spain; Robotnik Automation S. L. L., Valencia, Spain; Robotnik Automation S. L. L., Valencia, Spain; Computer Engineering and Informatics, Large Scale Machine Learning and Cloud Data Engineering Lab, University of Patras, Greece; Centre for Research and Technology Hellas - Information Technologies Institute (CERTH/ITI), Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636270/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11614574773852614559&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;0;0;0;2;2;2;1;0",
        "aff_unique_norm": "Centre for Research and Technology Hellas;University of Patras;Robotnik Automation",
        "aff_unique_dep": "Information Technologies Institute;Computer Engineering and Informatics;",
        "aff_unique_url": "https://www.certh.gr;https://www.upatras.gr;",
        "aff_unique_abbr": "CERTH;;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Thessaloniki;",
        "aff_country_unique_index": "0;0;0;0;0;1;1;1;0;0",
        "aff_country_unique": "Greece;Spain"
    },
    {
        "id": "9636249",
        "title": "Parallel Variable Stiffness Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce a new type of compliant actuator named the Parallel Variable Stiffness Actuator (PVSA) which consists of a variable stiffness spring placed in parallel with a direct-drive motor. Parallel variable stiffness actuators provide (i) high-fidelity force control and (ii) controllable energy storage, as they inherit the benefits of direct-drive motors and variable stiffness springs. We present a compact design of the PVSA using a flat motor connected to an adjustable mechanical advantage torsional spring. We show that this PVSA is (1) not subject to the fundamental force control bandwidth limitation of series elastic and variable stiffness actuators, and most notably, (2) enables resonant energy accumulation despite the limited deformation of the spring and the constrained motion of the load attached to the actuator. The latter differentiates parallel variable stiffness actuators from fixed-stiffness parallel elastic actuators. PVSAs may be used with smaller direct-drive motors to match the peak power of larger motors without compromising force control fidelity. PVSAs may be used to implement resonant forcing under joint angle limitations in walking, jumping, running, swimming robots, or robotic exoskeletons used to augmented human motion in the aforementioned tasks.",
        "primary_area": "",
        "author": "Chase W. Mathews;David J. Braun;Chase W. Mathews;David J. Braun",
        "authorids": "/37089195363;/37609773600;/37089195363;/37609773600",
        "aff": "Department of Mechanical Engineering, Advanced Robotics and Control Laboratory Within the Center for Rehabilitation Engineering and Assistive Technology, Vanderbilt University, Nashville, Tennessee, USA; Department of Mechanical Engineering, Advanced Robotics and Control Laboratory Within the Center for Rehabilitation Engineering and Assistive Technology, Vanderbilt University, Nashville, Tennessee, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636249/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8346043863669729902&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Vanderbilt University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635887",
        "title": "Part-Aware Data Augmentation for 3D Object Detection in Point Cloud",
        "track": "main",
        "status": "Poster",
        "abstract": "Data augmentation has greatly contributed to improving the performance in image recognition tasks, and a lot of related studies have been conducted. However, data augmentation on 3D point cloud data has not been much explored. 3D label has more sophisticated and rich structural information than the 2D label, so it enables more diverse and effective data augmentation. In this paper, we propose part-aware data augmentation (PA-AUG) that can better utilize rich information of 3D label to enhance the performance of 3D object detectors. PA-AUG divides objects into partitions and stochastically applies five augmentation methods to each local region. It is compatible with existing point cloud data augmentation methods and can be used universally regardless of the detector\u2019s architecture. PA-AUG has improved the performance of state-of-the-art 3D object detector for all classes of the KITTI dataset and has the equivalent effect of increasing the train data by about 2.5\u00d7. We also show that PA-AUG not only increases performance for a given dataset but also is robust to corrupted data. The code is available at https://github.com/sky77764/pa-aug.pytorch",
        "primary_area": "",
        "author": "Jaeseok Choi;Yeji Song;Nojun Kwak;Jaeseok Choi;Yeji Song;Nojun Kwak",
        "authorids": "/37085648258;/37089195857;/37337755300;/37085648258;/37089195857;/37337755300",
        "aff": "Graduate School of Convergence Science and Technology, Seoul National University, Seoul, South Korea; Graduate School of Convergence Science and Technology, Seoul National University, Seoul, South Korea; Graduate School of Convergence Science and Technology, Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635887/",
        "gs_citation": 78,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1777136977226569913&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Graduate School of Convergence Science and Technology",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636368",
        "title": "Partial Formation of Hydroxyapatite on Poly (Vinyl Alcohol) Hydrogel for Intensive Motions of Biomimetic Soft Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The fabrication method to utilize poly (vinyl alcohol) hydrogels with additional stiff parts in a single structure for hydrogel-based soft robots to realize an intensive motion with elastic energy is proposed in this paper. An inorganic material which is often seen in the hard tissues of our body; hydroxyapatite, was partially formed on a hydrogel with a simple procedure of alternatingly soaking a hydrogel with a covering device into two salt liquids. With this bioinspired structure, the whole hydrogel was able to change its physical properties while maintaining its whole structure as one. We succeeded in flicking motion of this structure only by bias displacement. This structure will help soft robots to move more intensively in a simple fabrication.",
        "primary_area": "",
        "author": "Towa Ueno;Haruka Oda;Yuya Morimoto;Shoji Takeuchi;Towa Ueno;Haruka Oda;Yuya Morimoto;Shoji Takeuchi",
        "authorids": "/37089196195;/37087049319;/37834933100;/37275286500;/37089196195;/37087049319;/37834933100;/37275286500",
        "aff": "Department of Mechanoinformatics, Faculty of Engineering, The University of Tokyo, Tokyo, Japan; Department of Mechanoinformatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechanoinformatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechanoinformatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636368/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:0cIJ0PBgF94J:scholar.google.com/&scioq=Partial+Formation+of+Hydroxyapatite+on+Poly+(Vinyl+Alcohol)+Hydrogel+for+Intensive+Motions+of+Biomimetic+Soft+Robots&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Mechanoinformatics",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9635967",
        "title": "Particle MPC for Uncertain and Learning-Based Control",
        "track": "main",
        "status": "Poster",
        "abstract": "As robotic systems move from highly structured environments to open worlds, incorporating uncertainty from dynamics learning or state estimation into the control pipeline is essential for robust performance. In this paper we present a nonlinear particle model predictive control (PMPC) approach to control under uncertainty, which directly incorporates any particle-based uncertainty representation, such as those common in robotics. Our approach builds on scenario methods for MPC, but in contrast to existing approaches, which either constrain all or only the first timestep to share actions across scenarios, we investigate the impact of a partial consensus horizon. Implementing this optimization for nonlinear dynamics by leveraging sequential convex optimization, our approach yields an efficient framework that can be tuned to the particular information gain dynamics of a system to mitigate both over-conservatism and over-optimism. We investigate our approach for two robotic systems across three problem settings: time-varying, partially observed dynamics; sensing uncertainty; and model-based reinforcement learning, and show that our approach improves performance over baselines in all settings.",
        "primary_area": "",
        "author": "Robert Dyro;James Harrison;Apoorva Sharma;Marco Pavone;Robert Dyro;James Harrison;Apoorva Sharma;Marco Pavone",
        "authorids": "/37089195632;/37085474390;/37086934207;/37307912900;/37089195632;/37085474390;/37086934207;/37307912900",
        "aff": "Stanford University, Stanford, CA, USA; Stanford University, Stanford, CA, USA; Stanford University, Stanford, CA, USA; Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635967/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=136332980682936156&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636773",
        "title": "Passing Through Narrow Gaps with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The DARPA subterranean challenge requires teams of robots to traverse difficult and diverse underground environments. Traversing small gaps is one of the challenging scenarios that robots encounter. Imperfect sensor information makes it difficult for classical navigation methods, where behaviours require significant manual fine tuning. In this paper we present a deep reinforcement learning method for autonomously navigating through small gaps, where contact between the robot and the gap may be required. We first learn a gap behaviour policy to get through small gaps (only centimeters wider than the robot). We then learn a goal-conditioned behaviour selection policy that determines when to activate the gap behaviour policy. We train our policies in simulation and demonstrate their effectiveness with a large tracked robot in simulation and on the real platform. In simulation experiments, our approach achieves 93% success rate when the gap behaviour is activated manually by an operator, and 63% with autonomous activation using the behaviour selection policy. In real robot experiments, our approach achieves a success rate of 73% with manual activation, and 40% with autonomous behaviour selection. While we show the feasibility of our approach in simulation, the difference in performance between simulated and real world scenarios highlight the difficulty of direct sim-to-real transfer for deep reinforcement learning policies. In both the simulated and real world environments alternative methods were unable to traverse the gap.",
        "primary_area": "",
        "author": "Brendan Tidd;Akansel Cosgun;J\u00fcrgen Leitner;Nicolas Hudson;Brendan Tidd;Akansel Cosgun;J\u00fcrgen Leitner;Nicolas Hudson",
        "authorids": "/37089198244;/38230493900;/37885671300;/37407757300;/37089198244;/38230493900;/37885671300;/37407757300",
        "aff": "Robotics and Autonomous Systems Group, CSIRO, Pullenvale, QLD, Australia; Monash University, Australia; LYRO Robotics Pty Ltd, Australia; Robotics and Autonomous Systems Group, CSIRO, Pullenvale, QLD, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636773/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5553567469805229504&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "CSIRO;Monash University;LYRO Robotics",
        "aff_unique_dep": "Robotics and Autonomous Systems Group;;",
        "aff_unique_url": "https://www.csiro.au;https://www.monash.edu;",
        "aff_unique_abbr": "CSIRO;Monash;LYRO",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pullenvale;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9636642",
        "title": "Passivity-based control for haptic teleoperation of a legged manipulator in presence of time-delays",
        "track": "main",
        "status": "Poster",
        "abstract": "When dealing with the haptic teleoperation of multi-limbed mobile manipulators, the problem of mitigating the destabilizing effects arising from the communication link between the haptic device and the remote robot has not been properly addressed. In this work, we propose a passive control architecture to haptically teleoperate a legged mobile manipulator, while remaining stable in the presence of time delays and frequency mismatches in the master and slave controllers. At the master side, a discrete-time energy modulation of the control input is proposed. At the slave side, passivity constraints are included in an optimization-based whole-body controller to satisfy the energy limitations. A hybrid teleoperation scheme allows the human operator to remotely operate the robot\u2019s end- effector while in stance mode, and its base velocity in locomotion mode. The resulting control architecture is demonstrated on a quadrupedal robot with an artificial delay added to the network.",
        "primary_area": "",
        "author": "Mattia Risiglione;Jean-Pierre Sleiman;Maria Vittoria Minniti;Burak \u00c7izmeci;Douwe Dresscher;Marco Hutter;Mattia Risiglione;Jean-Pierre Sleiman;Maria Vittoria Minniti;Burak \u00c7izmeci;Douwe Dresscher;Marco Hutter",
        "authorids": "/37089195410;/37087322472;/37086923041;/37569333500;/38246460200;/37545251000;/37089195410;/37087322472;/37086923041;/37569333500;/38246460200;/37545251000",
        "aff": "Dynamic Legged Systems Lab, Istituto Italiano di Tecnologia (IIT); Robotics System Lab (RSL), ETH Zurich, Switzerland; Robotics System Lab (RSL), ETH Zurich, Switzerland; Robotics System Lab (RSL), ETH Zurich, Switzerland; Faculty of Electrical Engineering, Mathematics and Computer Science, University of Twente, The Netherlands; Robotics System Lab (RSL), ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636642/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=105382816976404505&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;2;1",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;ETH Zurich;University of Twente",
        "aff_unique_dep": "Dynamic Legged Systems Lab;Robotics System Lab;Faculty of Electrical Engineering, Mathematics and Computer Science",
        "aff_unique_url": "https://www.iit.it;https://www.ethz.ch;https://www.utwente.nl",
        "aff_unique_abbr": "IIT;ETHZ;UT",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Zurich",
        "aff_country_unique_index": "0;1;1;1;2;1",
        "aff_country_unique": "Italy;Switzerland;Netherlands"
    },
    {
        "id": "9635934",
        "title": "Path Optimization for Cooperative Mapping Using Multiple Robots with Limited Sensing Capabilities",
        "track": "main",
        "status": "Poster",
        "abstract": "This study addresses the problem of path optimization for conducting a mapping mission using a multi-robot system with limited sensing capability, which aims to ensure efficient mapping with emphasis on the cooperative aspect of the mission. To achieve the cooperative mapping, a new path planning algorithm is proposed which can take advantage of the multi-robot system while dealing with the lack of observability due to the nature of bearing-only or range-only sensing. The Fisher information matrix is used to estimate the mapping uncertainty affected by the robots\u2019 geometric configuration. Also, a simple method to predict the convergence rate of the uncertainty over a short time horizon is presented for efficient path planning. The performance of the proposed algorithm is shown through simulations and compared with other path planning algorithms.",
        "primary_area": "",
        "author": "Kyungseo Kim;Jinwhan Kim;Kyungseo Kim;Jinwhan Kim",
        "authorids": "/37292681500;/38241886900;/37292681500;/38241886900",
        "aff": "Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635934/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7511197569875947835&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636730",
        "title": "Path Planning for Robotic Manipulators in Dynamic Environments Using Distance Information",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel algorithm \u2013 DRGBT (Dynamic Rapidly-exploring Generalized Bur Tree), intended for motion planning in dynamic environments. The main idea behind DRGBT lies in a so-called adaptive horizon, consisting of a set of prospective target nodes that belong to a predefined \\mathcal{C}C\\mathcal{C}-space path, which originates from the current node. Each node is assigned a weight that depends on relative distances and captured changes in the environment. The algorithm continuously uses a suitable horizon assessment to decide when to trigger the replanning procedure. A comprehensive simulation study is performed, covering a variety of manipulators, where DRGBT is compared to a state-of-the-art algorithm. Results indicate some promising features of the proposed method.",
        "primary_area": "",
        "author": "Nermin Covic;Bakir Lacevic;Dinko Osmankovic;Nermin Covic;Bakir Lacevic;Dinko Osmankovic",
        "authorids": "/37088355141;/37565739200;/37085534049;/37088355141;/37565739200;/37085534049",
        "aff": "Faculty of Electrical Engineering Sarajevo, University of Sarajevo, Bosnia and Herzegovina; Faculty of Electrical Engineering Sarajevo, University of Sarajevo, Bosnia and Herzegovina; Faculty of Electrical Engineering Sarajevo, University of Sarajevo, Bosnia and Herzegovina",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636730/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16208931693490453642&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Sarajevo",
        "aff_unique_dep": "Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.unsa.ba",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sarajevo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Bosnia and Herzegovina"
    },
    {
        "id": "9636674",
        "title": "Path-constrained optimal trajectory planning for robot manipulators with obstacle avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we develop a novel path-constrained and collision-free optimal trajectory planning algorithm for robot manipulators in the presence of obstacles for the following problem: Given a desired sequence of discrete waypoints of robot configurations, a set of robot kinematic and dynamic constraints, and a set of obstacles, determine a time and jerk optimal and collision-free trajectory for the robot passing through the given waypoints with constant speed. Our approach in developing the robot path through the waypoints relies on the orthogonal collocation method where the states are represented with Legendre polynomials in the Barycentric form; the transcription process efficiently converts the continuous-time formulation of the optimal control problem (both time and jerk optimal) into a discrete non-linear program. In addition, we provide an efficient method for avoiding robot self-collisions (of joints and links) and collisions with workspace obstacles by modeling them as the union of spheres and cylinders in the workspace. The resulting collision free optimal trajectory provides smooth and constrained motion for the robot passing through all the waypoints in the given prescribed sequence. The proposed method is validated using numerical simulations and experiments on a six degree-of-freedom robot.",
        "primary_area": "",
        "author": "Yalun Wen;Prabhakar R. Pagilla;Yalun Wen;Prabhakar R. Pagilla",
        "authorids": "/37086934269;/37279144800;/37086934269;/37279144800",
        "aff": "Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA; Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636674/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13520030123988863785&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636302",
        "title": "Perceptive Autonomous Stair Climbing for Quadrupedal Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies autonomous stair climbing for quadrupedal robots with perception. Enabling quadrupeds to reliably climb staircases greatly expands their applicability in practical scenarios. For this structured task, we develop a simple yet effective perception and control framework for autonomous quadrupedal stair climbing. By exploiting the structural knowledge about the staircases, the proposed framework first extracts the geometric information about the staircase from measurements of the perception system. Then, the climbing velocity and associated foothold references during stair climbing are generated via simple optimization algorithms based on the geometric information about the staircase. Given these references, we use model predictive control based approach to generate input joint torques for controlling the quadruped to complete the whole stair climbing task. Simulation validations using the full dynamic model of the Unitree\u2019s Aliengo quadruped with the MuJoCo simulator are performed, which demonstrate successful autonomous climbing of various staircases with different geometries. Effectiveness of the proposed strategy is further validated through hardware experiments on the real Aliengo robot with different real-world staircases.",
        "primary_area": "",
        "author": "Shuhao Qi;Wenchun Lin;Zejun Hong;Hua Chen;Wei Zhang;Shuhao Qi;Wenchun Lin;Zejun Hong;Hua Chen;Wei Zhang",
        "authorids": "/37089972576;/37089196921;/37088653661;/37086195529;/37089656248;/37089972576;/37089196921;/37088653661;/37086195529;/37089656248",
        "aff": "Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636302/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8791288042215059887&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical and Energy Engineering",
        "aff_unique_url": "https://www.sustech.edu.cn",
        "aff_unique_abbr": "SUSTech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636105",
        "title": "Personalization of Human-Robot Gestural Communication through Voice Interaction Grounding",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we develop a gestural communication perception system for a social robot companion that is able to autonomously learn novel gestures on-the-fly. The system constantly tracks human gestural activities with a camera and evaluates the performed gestures under an open-set assumption. This allows for the identification of unknown gestures. Once detected, the system stores motion sequences of the novel gesture class and employs a dialogue interaction with the human to automatically label the unknown gesture. Subsequently, the gestural model is updated, grounding the unknown gesture through dialog interaction. In our experiment, we evaluate a neural network with varying threshold values for the open gesture recognition with unknown detection. Results show that the general classifier reaches an accuracy of more than 83%, and an f1-score of 0.79 in an open-ended scenario. The method is furthermore tested in a first in-lab interaction setting, which shows the system usability and its potential for future personalized human-robot gestural communication.",
        "primary_area": "",
        "author": "Heike Brock;Randy Gomez;Heike Brock;Randy Gomez",
        "authorids": "/37086009097;/37979526500;/37086009097;/37979526500",
        "aff": "Honda Research Institute Japan Co., Ltd., Wako-shi, Saitama, Japan; Honda Research Institute Japan Co., Ltd., Wako-shi, Saitama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636105/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11366723252467634787&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Honda Research Institute Japan Co., Ltd.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.honda-ri.jp/english/",
        "aff_unique_abbr": "HRI-JP",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Wako-shi",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636772",
        "title": "Persuasion Strategies for Social Robot to Keep Humans Accepting Daily Different Recommendations",
        "track": "main",
        "status": "Poster",
        "abstract": "Social robots are used in daily life. One of the applications of social robots is as recommendation systems. Previous research has mainly investigated how persuasive recommendations can be improved by focusing on the non-verbal/verbal behavior of robots. However, to use robots as recommendation systems every day, it is extremely important to examine the persistence of repeated persuasion over a long term, rather than the effect of one-time persuasion. Therefore, the objective of this study was to investigate the persistence of repeated persuasive of robots. For this purpose, robots with three types of behavior (Expert Behavior, Local Behavior, and Growth Behavior) recommended nutrition bars in a situation of daily consumption behavior for two weeks. We could confirm significant differences in the persistent persuasiveness in each behavior. The results suggested that the combination of value co-creation using local information and meta-trust expression had a significant impact on the persistence of the repeated persuasiveness of the robots in the longitudinal period. However, the acceptance of the recommendation robot system decreased due to the increase in the amount of information during recommendation; therefore, a new recommend system to solve this problem is desired.",
        "primary_area": "",
        "author": "Yuki Okafuji;Jun Baba;Junya Nakanishi;Joichiro Amada;Yuichiro Yoshikawa;Hiroshi Ishiguro;Yuki Okafuji;Jun Baba;Junya Nakanishi;Joichiro Amada;Yuichiro Yoshikawa;Hiroshi Ishiguro",
        "authorids": "/37085677004;/37086804031;/37085769525;/37088945781;/37286859300;/37274136400;/37085677004;/37086804031;/37085769525;/37088945781;/37286859300;/37274136400",
        "aff": "School of Information Science and Engineering, Ritsumeikan University; Graduation School of Engineering Science, Osaka University, Osaka, Japan; Graduation School of Engineering Science, Osaka University, Osaka, Japan; School of Information Science and Engineering, Ritsumeikan University; Graduation School of Engineering Science, Osaka University, Osaka, Japan; Graduation School of Engineering Science, Osaka University, Osaka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636772/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7134091399300204901&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;1;1",
        "aff_unique_norm": "Ritsumeikan University;Osaka University",
        "aff_unique_dep": "School of Information Science and Engineering;Graduation School of Engineering Science",
        "aff_unique_url": "https://www.ritsumei.ac.jp;https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "Ritsumeikan;OU",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Osaka",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636457",
        "title": "Phase-SLAM: Mobile Structured Light Illumination for Full Body 3D Scanning",
        "track": "main",
        "status": "Poster",
        "abstract": "Full body scanning plays an important role in automated industrial manufacture and inspection. It requires the fusion of multi-view point cloud data and consumes large computational resources when the geometry of corresponding point clouds are unknown. Structured Light Illumination (SLI) is one of the most promising indoor 3D imaging techniques, but also has the same weakness for fusing the multi-view point clouds. This work proposes a mobile SLI system to alleviate this problem for full body 3D scanning. We derive the geometric relation between the phase and the motion of the mobile system, and develop an optimization approach to estimate the pose by comparing the phase image pair before and after the motion. Further more, a graph-based Simultaneous Localization And Mapping (SLAM) framework is built to improve the global accuracy of the pose estimation. By using the 2D phase comparison, the proposed method is more accurate than the normal 2D image feature point matching, and has lower computational complexity than the 3D point registration. The proposed system is experimented in both 3D Simulator and real environment. The yielded full body scan results demonstrated its higher accuracy and more efficiency than the current methods.",
        "primary_area": "",
        "author": "Xi Zheng;Rui Ma;Rui Gao;Qi Hao;Xi Zheng;Rui Ma;Rui Gao;Qi Hao",
        "authorids": "/37089197569;/38469487600;/37089197744;/37403530000;/37089197569;/38469487600;/37089197744;/37403530000",
        "aff": "Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636457/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12391909764239427721&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.sustech.edu.cn",
        "aff_unique_abbr": "SUSTech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636180",
        "title": "Phase-Variable Control of a Powered Knee-Ankle Prosthesis over Continuously Varying Speeds and Inclines",
        "track": "main",
        "status": "Poster",
        "abstract": "Most controllers for lower-limb robotic prostheses require individually tuned parameter sets for every combination of speed and incline that the device is designed for. Because ambulation occurs over a continuum of speeds and inclines, this design paradigm requires tuning of a potentially prohibitively large number of parameters. This limitation motivates an alternative control framework that enables walking over a range of speeds and inclines while requiring only a limited number of tunable parameters. In this work, we present the implementation of a continuously varying kinematic controller on a custom powered knee-ankle prosthesis. The controller uses a phase variable derived from the residual thigh angle, along with real-time estimates of ground inclination and walking speed, to compute the appropriate knee and ankle joint angles from a continuous model of able-bodied kinematic data. We modify an existing phase variable architecture to allow for changes in speeds and inclines, quantify the closed-loop accuracy of the speed and incline estimation algorithms for various references, and experimentally validate the controller by observing that it replicates kinematic trends seen in able-bodied gait as speed and incline vary.",
        "primary_area": "",
        "author": "T. Kevin Best;Kyle R. Embry;Elliott J. Rouse;Robert D. Gregg;T. Kevin Best;Kyle R. Embry;Elliott J. Rouse;Robert D. Gregg",
        "authorids": "/37089197029;/37085899810;/37991140400;/37547699100;/37089197029;/37085899810;/37991140400;/37547699100",
        "aff": "Department of Electrical Engineering and Computer Science and the Robotics Institute, University of Michigan, Ann Arbor, MI; Department of Physical Medicine and Rehabilitation, Max Nader Lab for Rehabilitation Technologies and Outcomes Research, Shirley Ryan AbilityLab, Northwestern University, Chicago, IL; Department of Mechanical Engineering and the Robotics Institute, University of Michigan, Ann Arbor, MI; Department of Electrical Engineering and Computer Science and the Robotics Institute, University of Michigan, Ann Arbor, MI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636180/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17266532694997334752&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Michigan;Northwestern University",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science;Department of Physical Medicine and Rehabilitation",
        "aff_unique_url": "https://www.umich.edu;https://www.northwestern.edu",
        "aff_unique_abbr": "UM;NU",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Ann Arbor;Chicago",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636146",
        "title": "PiPo-Net: A Semi-automatic and Polygon-based Annotation Method for Pathological Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Metastatic involvement of lymph nodes is one of the most important prognostic variables for many cancers. Several deep learning based algorithms have been developed to segment metastatic regions in pathological images to help predict prognosis. However, the training of these methods requires a large amount of annotated data, and the labeling task is an extremely time-consuming process for human annotators. In order to reduce the annotation burden, we for the first time propose a semi-automatic annotation method (PiPo-Net) for the labeling of pathological images. The method is comprised of two subnetworks, a pixel-wise segmentation network (Pi-Net) and a polygon-based annotation network (Po-Net). The Pi-Net adopts an improved encoder-decoder architecture and can effectively aggregate multi-scale image features. The Po-Net is built on the Pi-Net and leverages a two-layer recurrent neural network to generate tight-bounded polygons for the metastatic regions. Corresponding to the proposed network architecture, a loss function called PiPo-loss is introduced to help optimize the whole network. The main advantage of our method is that it integrates human annotators into the prediction loop, allowing to iteratively refine the predictions according to the suggestions from human annotators. We evaluate our method on Camelyon16 database and achieve a Dice score of 91% in the initial annotation attempt. We also demonstrate the effectiveness of the human-network collaborative annotation, which achieves promising labeling results, verifying the advantages of our proposed method.",
        "primary_area": "",
        "author": "Yuqi Fang;Delong Zhu;Niyun Zhou;Li Liu;Jianhua Yao;Yuqi Fang;Delong Zhu;Niyun Zhou;Li Liu;Jianhua Yao",
        "authorids": "/37086493133;/37086137408;/37086881880;/37086313226;/37086886757;/37086493133;/37086137408;/37086881880;/37086313226;/37086886757",
        "aff": "Tencent AI Lab, Shenzhen, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, New Territories, Hong Kong SAR, China; Tencent AI Lab, Shenzhen, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, New Territories, Hong Kong SAR, China; Tencent AI Lab, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636146/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5680501551966322698&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "Tencent;Chinese University of Hong Kong",
        "aff_unique_dep": "AI Lab;Department of Electronic Engineering",
        "aff_unique_url": "https://ai.tencent.com;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "Tencent AI Lab;CUHK",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Shenzhen;Shatin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636544",
        "title": "PlanSys2: A Planning System Framework for ROS2",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous robots need to plan the tasks they carry out to fulfill their missions. The missions\u2019 increasing complexity does not let human designers anticipate all the possible situations, so traditional control systems based on state machines are not enough. This paper contains a description of the ROS2 Planning System (PlanSys2 in short), a framework for symbolic planning that incorporates novel approaches for execution on robots working in demanding environments. PlanSys2 aims to be the reference task planning framework in ROS2, the latest version of the de facto standard in robotics software development. Among its main features, it can be highlighted the optimized execution, based on Behavior Trees, of plans through a new actions auction protocol and its multi-robot planning capabilities. It already has a small but growing community of users and developers, and this document is a summary of the design and capabilities of this project.",
        "primary_area": "",
        "author": "Francisco Mart\u00edn;Jonatan Gin\u00e9s Clavero;Vicente Matell\u00e1n;Francisco J. Rodr\u00edguez;Francisco Mart\u00edn;Jonatan Gin\u00e9s Clavero;Vicente Matell\u00e1n;Francisco J. Rodr\u00edguez",
        "authorids": "/37292303000;/37088687838;/37296887900;/37080860300;/37292303000;/37088687838;/37296887900;/37080860300",
        "aff": "Intelligent Robotics Lab, Rey Juan Carlos University; Intelligent Robotics Lab, Rey Juan Carlos University; Robotics Group, University of Le\u00f3n; Robotics Group, University of Le\u00f3n",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636544/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16715939521764030056&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "Rey Juan Carlos University;University of Le\u00f3n",
        "aff_unique_dep": "Intelligent Robotics Lab;Robotics Group",
        "aff_unique_url": "https://www.urjc.es;https://www.unileon.es",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9635930",
        "title": "Plane Segmentation Using Depth-Dependent Flood Fill",
        "track": "main",
        "status": "Poster",
        "abstract": "The detection of planar surfaces in a point cloud is a popular technique for the extraction of drivable or walkable surfaces and for tabletop segmentation. Unfortunately, RGB-D sensors are quite noisy and provide incomplete data, which makes the extraction of surfaces more challenging. Also, it is desirable to process the point cloud data in real time, which at a rate of approximately 30 Hz, leaves only a small amount of computation time per frame. We have already developed a real time-capable plane segmentation method [1] that exploits the organized structure of RGB-D point clouds in order to implement a computationally efficient region growing algorithm. It uses the point-plane distance to assign points to their segments rather than inherently unreliable surface normals. Now we are presenting an improvement where we adapt thresholds and other parameters of our algorithm to the measured depth in order to account for an increasing scatter of the points at larger distances from the camera. We estimate a minimum detectable plane size in pixels dependent on the measured depth. This enables us to stride in pixel coordinates with larger steps that are adaptive to the measured depth and to implement more robust sanity checks of depth-dependent size. Apart from a speed-up of the runtime of our algorithm, the segmentation quality also increased. We show a comparison between our improvement, our previous version, and other state-of-the-art methods evaluated on multiple commonly available datasets.",
        "primary_area": "",
        "author": "Arindam Roychoudhury;Marceli Missura;Maren Bennewitz;Arindam Roychoudhury;Marceli Missura;Maren Bennewitz",
        "authorids": "/37088690601;/37947347600;/37324765000;/37088690601;/37947347600;/37324765000",
        "aff": "Humanoid Robots Lab, University of Bonn, Germany; Humanoid Robots Lab, University of Bonn, Germany; Humanoid Robots Lab, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635930/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8107048920507046004&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Humanoid Robots Lab",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636190",
        "title": "PlannerFlows: Learning Motion Samplers with Normalising Flows",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based motion planning is the predominant paradigm in many real-world robotic applications, but its performance is immensely dependent on the quality of the samples. The majority of traditional planners are inefficient as they use uninformative sampling distributions instead of exploiting structures and patterns in the problem to guide better sampling strategies. Moreover, most current learning-based planners are susceptible to posterior collapse or mode collapse due to the sparsity and highly varying nature of C-Space and motion plan configurations. This work introduces a conditional normalising flow-based distribution learned through previous experiences, which improves existing methods\u2019 sampling scheme. Our distribution can be conditioned on the current problem instance to provide informative prior to sample configurations within promising regions. When we train our sampler with an expert planner, the resulting distribution is often near-optimal, and the planner can find a solution faster, with less invalid samples and less initial cost. The normalising flow-based distribution uses simple invertible transformations that are very computationally efficient, and our optimisation formulation explicitly avoids mode collapse in contrast to other existing learning-based sampler. Finally, we provide a formulation and theoretical foundation to sample from the distribution efficiently. Experimentally we demonstrate utilising the flow-based distribution in a sampling-based motion planner allows a solution to be found faster, with fewer samples and better overall runtime performance.",
        "primary_area": "",
        "author": "Tin Lai;Fabio Ramos;Tin Lai;Fabio Ramos",
        "authorids": "/37086935412;/37285364500;/37086935412;/37285364500",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636190/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11354823070322539324&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4
    },
    {
        "id": "9636782",
        "title": "Planning Robotic Manipulation with Tight Environment Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In many real-world manipulation problems, the constraints imposed by the environment on an object are tight. In these cases, most state-of-the-art planners struggle to fit satisfactorily in low dimensional sub-manifolds, while still ensuring geometric and force feasibility. On the other hand, humans are at ease with such situations and indeed exploit constraints to manipulate objects proficiently.To face this challenge, we propose to merge state-of-art randomized grasp planning methods with model-based grasp analysis. We use the partial form-closure analysis framework to find the geometrically feasible motions of the object. Then, to ensure that the desired motions are physically realizable by the robot, we resort to an extension of the force-closure analysis framework accounting also for dynamic friction. We use these instruments to construct a random tree in a simplified planning space containing only object-robot configurations that are reachable through effectively applicable contact forces. The algorithm, validated in simulation and in preliminary experiments with a collaborative robot, features the ability to compute solutions for heavily constrained real-world manipulation problems.",
        "primary_area": "",
        "author": "George Jose Pollayil;Giorgio Grioli;M. Bonilla;Antonio Bicchi;George Jose Pollayil;Giorgio Grioli;M. Bonilla;Antonio Bicchi",
        "authorids": "/37089196805;/37590311700;/37085432587;/37278626700;/37089196805;/37590311700;/37085432587;/37278626700",
        "aff": "Soft Robotics for Human Cooperation and Rehabilitation, Istituto Italiano di Tecnologia, Italy; Soft Robotics for Human Cooperation and Rehabilitation, Istituto Italiano di Tecnologia, Italy; Research Center \"Enrico Piaggio\" and Dipartimento di Ingegneria Dell\u2019Informazione, University of Pisa; Soft Robotics for Human Cooperation and Rehabilitation, Istituto Italiano di Tecnologia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636782/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7957798621574795278&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;University of Pisa",
        "aff_unique_dep": "Soft Robotics for Human Cooperation and Rehabilitation;Dipartimento di Ingegneria Dell\u2019Informazione",
        "aff_unique_url": "https://www.iit.it;https://www.unipi.it",
        "aff_unique_abbr": "IIT;UNIPi",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636549",
        "title": "Planning for Aerial Robot Teams for Wide-Area Biometric and Phenotypic Data Collection",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents an efficient and implementable solution to the problem of joint task allocation and path planning in a multi-UAV platform. The sensing requirement associated with the task gives rise to an uncanny variant of the traditional vehicle routing problem with coverage/sensing constraints. As is the case in several multi-robot path-planning problems, our problem reduces to an mTSP problem. In order to tame the computational challenges associated with the problem, we propose a hierarchical solution that decouples the vehicle routing problem from the target allocation problem. As a tangible solution to the allocation problem, we use a clustering-based technique that incorporates temporal uncertainty in the cardinality and position of the robots. Finally, we implement the proposed techniques on our multi-quadcopter platforms.",
        "primary_area": "",
        "author": "Shashwata Mandal;Tianshuang Gao;Sourabh Bhattacharya;Shashwata Mandal;Tianshuang Gao;Sourabh Bhattacharya",
        "authorids": "/37089196313;/37086016876;/37275362500;/37089196313;/37086016876;/37275362500",
        "aff": "Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Mechanical Engineering, Iowa State University, Ames, IA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636549/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9107399397506175024&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Iowa State University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.iastate.edu",
        "aff_unique_abbr": "ISU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ames",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636699",
        "title": "Plenaries and keynotes",
        "track": "main",
        "status": "Poster",
        "abstract": "Provides an abstract for each of the invited presentations and may include a brief professional biography of each presenter. The complete presentations were not made available for publication as part of the conference proceedings.",
        "primary_area": "",
        "author": "",
        "authorids": "",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636699/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1
    },
    {
        "id": "9636863",
        "title": "PointSiamRCNN: Target-aware Voxel-based Siamese Tracker for Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Currently, there have been many kinds of pointbased 3D trackers, while voxel-based methods are still underexplored. In this paper, we first propose a voxel-based tracker, named PointSiamRCNN, improving tracking performance by embedding target information into the search region. Our framework is composed of two parts for achieving proposal generation and proposal refinement, which fully releases the potential of the two-stage object tracking. Specifically, it takes advantage of efficient feature learning of the voxel-based Siamese network and high-quality proposal generation of the Siamese region proposal network head. In the search region, the groundtruth annotations are utilized to realize semantic segmentation, which leads to more discriminative feature learning with pointwise supervisions. Furthermore, we propose the Self and Cross Attention Module for embedding target information into the search region. Finally, the multi-scale RoI pooling module is proposed to obtain compact representations from target-aware features for proposal refinement. Exhaustive experiments on the KITTI tracking dataset demonstrate that our framework reaches the competitive performance with the state-of-the-art 3D tracking methods and achieves the state-of-the-art in terms of BEV tracking.",
        "primary_area": "",
        "author": "Hao Zou;Chujuan Zhang;Yong Liu;Wanlong Li;Feng Wen;Hongbo Zhang;Hao Zou;Chujuan Zhang;Yong Liu;Wanlong Li;Feng Wen;Hongbo Zhang",
        "authorids": "/37088690615;/37088689834;/37066946100;/37088687641;/37088690190;/37859161500;/37088690615;/37088689834;/37066946100;/37088687641;/37088690190;/37859161500",
        "aff": "Institute of CyberSystems and Control, Zhejiang University, Hangzhou, China; Institute of CyberSystems and Control, Zhejiang University, Hangzhou, China; Institute of CyberSystems and Control, Zhejiang University, Hangzhou, China; Huawei Noah\u2019s Ark lab; Huawei Noah\u2019s Ark lab; Huawei Noah\u2019s Ark lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636863/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9531474363820713231&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;1",
        "aff_unique_norm": "Zhejiang University;Huawei",
        "aff_unique_dep": "Institute of CyberSystems and Control;Noah\u2019s Ark lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.huawei.com",
        "aff_unique_abbr": "ZJU;Huawei",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hangzhou;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636866",
        "title": "Policy Learning for Visually Conditioned Tactile Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work on robot learning with visual observations has shown great success in solving many manipulation tasks. While visual observations contain rich information about the environment and the robot, they can be unreliable in the presence of visual noise or occlusions. In these cases, we can leverage tactile observations generated by the interaction between the robot and the environment. In this paper, we propose a framework for learning manipulation policies that fuse visual and tactile feedback. The control problems considered in this work are to localize a gripper with respect to the environment image and navigate to desired states. Our method uses a learned Bayes filter to estimate the state of a gripper by conditioning the tactile observations on the environment image. We use deep reinforcement learning for solving the localization and navigation problems provided with the belief of the gripper\u2019s state and the environment image. We compare our method against two baselines where the agent uses tactile observation directly with a recurrent neural network or uses a point estimate of the state instead of the full belief state. We also transfer the policies to the real world and validate them on a physical robot.",
        "primary_area": "",
        "author": "Tar\u0131k Kele\u015ftemur;Ta\u015fk\u0131n Pad\u0131r;Robert Platt;Tar\u0131k Kele\u015ftemur;Ta\u015fk\u0131n Pad\u0131r;Robert Platt",
        "authorids": "/37086935384;/38496444600;/37273991200;/37086935384;/38496444600;/37273991200",
        "aff": "College of Engineering, Northeastern University, Boston, Massauchusetts, USA; College of Engineering, Northeastern University, Boston, Massauchusetts, USA; Khoury College of Computer Sciences, Northeastern University, Boston, Massauchusetts, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636866/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18222441153445348183&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "College of Engineering",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NEU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636839",
        "title": "Pose Estimation from RGB Images of Highly Symmetric Objects using a Novel Multi-Pose Loss and Differential Rendering",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel multi-pose loss function to train a neural network for 6D pose estimation, using synthetic data and evaluating it on real images. Our loss is inspired by the VSD (Visible Surface Discrepancy) metric and relies on a differentiable renderer and CAD models. This novel multi-pose approach produces multiple weighted pose estimates to avoid getting stuck in local minima. Our method resolves pose ambiguities without using predefined symmetries. It is trained only on synthetic data. We test on real-world RGB images from the T-LESS dataset, containing highly symmetric objects common in industrial settings. We show that our solution can be used to replace the codebook in a state-of-the-art approach. So far, the codebook approach has had the shortest inference time in the field. Our approach reduces inference time further while a) avoiding discretization, b) requiring a much smaller memory footprint and c) improving pose recall.3",
        "primary_area": "",
        "author": "Stefan Hein Bengtson;Hampus \u00c5str\u00f6m;Thomas B. Moeslund;Elin A. Topp;Volker Krueger;Stefan Hein Bengtson;Hampus \u00c5str\u00f6m;Thomas B. Moeslund;Elin A. Topp;Volker Krueger",
        "authorids": "/37086568254;/37089235648;/37299539100;/37281297500;/37085807708;/37086568254;/37089235648;/37299539100;/37281297500;/37085807708",
        "aff": "Visual Analysis and Perception (VAP) Laboratory, Aalborg University; Department of Computer Science, Robotics and Semantic Systems, Lund University; Visual Analysis and Perception (VAP) Laboratory, Aalborg University; Department of Computer Science, Robotics and Semantic Systems, Lund University; Department of Computer Science, Robotics and Semantic Systems, Lund University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636839/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5347439599951457616&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;1",
        "aff_unique_norm": "Aalborg University;Lund University",
        "aff_unique_dep": "Visual Analysis and Perception (VAP) Laboratory;Department of Computer Science, Robotics and Semantic Systems",
        "aff_unique_url": "https://www.aau.dk;https://www.lunduniversity.lu.se",
        "aff_unique_abbr": "AAU;LU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;1;1",
        "aff_country_unique": "Denmark;Sweden"
    },
    {
        "id": "9636658",
        "title": "PoseFusion2: Simultaneous Background Reconstruction and Human Shape Recovery in Real-time",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic environments that include unstructured moving objects pose a hard problem for Simultaneous Localization and Mapping (SLAM) performance. The motion of rigid objects can be typically tracked by exploiting their texture and geometric features. However, humans moving in the scene are often one of the most important, interactive targets \u2013 they are very hard to track and reconstruct robustly due to non-rigid shapes. In this work, we present a fast, learning-based human object detector to isolate the dynamic human objects and realise a real-time dense background reconstruction framework. We go further by estimating and reconstructing the human pose and shape. The final output environment maps not only provide the dense static backgrounds but also contain the dynamic human meshes and their trajectories. Our Dynamic SLAM system runs at around 26 frames per second (fps) on GPUs, while additionally turning on accurate human pose estimation can be executed at up to 10 fps.",
        "primary_area": "",
        "author": "Huayan Zhang;Tianwei Zhang;Tin Lun Lam;Sethu Vijayakumar;Huayan Zhang;Tianwei Zhang;Tin Lun Lam;Sethu Vijayakumar",
        "authorids": "/37088446376;/37086443242;/37571111600;/37295595500;/37088446376;/37086443242;/37571111600;/37295595500",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society, Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society, Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636658/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16229351899718370276&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Chinese University of Hong Kong;Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "Shenzhen Institute of Artificial Intelligence and Robotics for Society;Artificial Intelligence and Robotics",
        "aff_unique_url": "https://www.cuhk.edu.hk;http://www.airs.shenzhen.gov.cn/",
        "aff_unique_abbr": "CUHK;AIRS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635966",
        "title": "Position Control and Variable-Height Trajectory Tracking of a Soft Pneumatic Legged Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft pneumatic legged robots show promise in their ability to traverse a range of different types of terrain, including natural unstructured terrain met in applications like precision agriculture. They can adapt their body morphology to the intricacies of the terrain at hand, thus enabling robust and resilient locomotion. In this paper we capitalize upon recent developments on soft pneumatic legged robots to introduce a closed-loop trajectory tracking control scheme for operation over flat ground. Closed-loop pneumatic actuation feedback is achieved via a compact and portable pneumatic regulation board. Experimental results reveal that our soft legged robot can precisely control its body height and orientation while in quasi-static operation based on a geometric model. The robot can track both straight line and curved trajectories as well as variable-height trajectories. This work lays the basis to enable autonomous navigation for soft legged robots.",
        "primary_area": "",
        "author": "Zhichao Liu;Konstantinos Karydis;Zhichao Liu;Konstantinos Karydis",
        "authorids": "/37088505148;/38252121900;/37088505148;/38252121900",
        "aff": "Dept. of Electrical and Computer Engineering, University of California, Riverside; Dept. of Electrical and Computer Engineering, University of California, Riverside",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635966/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16759571556334807552&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Riverside",
        "aff_unique_dep": "Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucr.edu",
        "aff_unique_abbr": "UCR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Riverside",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636824",
        "title": "Powerline Tracking with Event Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous inspection of powerlines with quadrotors is challenging. Flights require persistent perception to keep a close look at the lines. We propose a method that uses event cameras to robustly track powerlines. Event cameras are inherently robust to motion blur, have low latency, and high dynamic range. Such properties are advantageous for autonomous inspection of powerlines with drones, where fast motions and challenging illumination conditions are ordinary. Our method identifies lines in the stream of events by detecting planes in the spatio-temporal signal, and tracks them through time. The implementation runs onboard and is capable of detecting multiple distinct lines in real time with rates of up to 320 thousand events per second. The performance is evaluated in real-world flights along a powerline. The tracker is able to persistently track the powerlines, with a mean lifetime of the line 10\u00d7 longer than existing approaches.",
        "primary_area": "",
        "author": "Alexander Dietsche;Giovanni Cioffi;Javier Hidalgo-Carri\u00f3;Davide Scaramuzza;Alexander Dietsche;Giovanni Cioffi;Javier Hidalgo-Carri\u00f3;Davide Scaramuzza",
        "authorids": "/37089196010;/37088488451;/37085369829;/37397688400;/37089196010;/37088488451;/37085369829;/37397688400",
        "aff": "Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Department of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636824/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1039253672376182297&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Zurich",
        "aff_unique_dep": "Department of Neuroinformatics",
        "aff_unique_url": "https://www.unizh.ch",
        "aff_unique_abbr": "UZH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636285",
        "title": "Pre-operative Offline Optimization of Insertion Point Location for Safe and Accurate Surgical Task Execution",
        "track": "main",
        "status": "Poster",
        "abstract": "In robotically assisted surgical procedures the surgical tool is usually inserted in the patient\u2019s body through a small incision, which acts as a constraint for the motion of the robot, known as remote center of Motion (RCM). The location of the insertion point on the patient\u2019s body has huge effects on the performances of the surgical robot. In this work we present an offline pre-operative framework to identify the optimal insertion point location in order to guarantee accurate and safe surgical task execution. The approach is validated using a serial-link manipulator in conjunction with a surgical robotic tool to perform a tumor resection task, while avoiding nearby organs. Results show that the framework is capable of identifying the best insertion point ensuring high dexterity, high tracking accuracy, and safety in avoiding nearby organs.",
        "primary_area": "",
        "author": "Francesco Cursi;Petar Kormushev;Francesco Cursi;Petar Kormushev",
        "authorids": "/37086145777;/37590229500;/37086145777;/37590229500",
        "aff": "Robot Intelligence Lab, Imperial College London, London, UK; Robot Intelligence Lab, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636285/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3904887773038170904&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Robot Intelligence Lab",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9635945",
        "title": "Precise Control of Magnetized Macrophage Cell Robot for Targeted Drug Delivery",
        "track": "main",
        "status": "Poster",
        "abstract": "Micro-nano-robots are considered to be a promising platform for drug delivery in biological organisms, but there are still urgent technical problems in biocompatibility and degradability of 3D-printed-based micro-robots that need to be solved. Therefore, in this paper, we design a magnetized bio-hybrid robot, which uses mouse macrophages as carriers, and allowed it to swallow Fe2O3 particles with a diameter of 10 nm. The robot takes advantage of macrophage\u2019s natural biocompatibility and targeting characteristics to reach and function in complex environments such as: eye, knee, tumor, etc., and finally being able to be actively metabolized by the organism. More importantly, the cell robot can move precisely along a preplanned path under the control of a three-dimensional magnetic control system built in this study, and be delivered accurately to the vicinity of cancer cells in vitro environment. In future work, cellular robots could be allowed to carry anti-cancer drugs and release them in a targeted manner at the lesion. These microrobots have shown great potential for tumor reginal targeted drug delivery.",
        "primary_area": "",
        "author": "Luyao Wang;Yuguo Dai;Hongyan Sun;Li Song;Lina Jia;Chiju Jiang;Fumihito Arai;Lin Feng;Luyao Wang;Yuguo Dai;Hongyan Sun;Li Song;Lina Jia;Chiju Jiang;Fumihito Arai;Lin Feng",
        "authorids": "/37089151698;/37086561173;/37089154851;/37087124252;/37089152102;/37089197057;/37274069600;/37403324400;/37089151698;/37086561173;/37089154851;/37087124252;/37089152102;/37089197057;/37274069600;/37403324400",
        "aff": "School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Energy and Power Engineering, Beihang University, Beijing, China; Department of Mechanical Engineering, The University of Tokyo, Tokyo, Japan; Beijing Advanced Innovation Center for Biomedical Engineering, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635945/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9950820739385529515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;1;0",
        "aff_unique_norm": "Beihang University;University of Tokyo",
        "aff_unique_dep": "School of Mechanical Engineering & Automation;Department of Mechanical Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "Beihang;UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;0",
        "aff_campus_unique": "Beijing;Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;1;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9635926",
        "title": "Precise Object Placement with Pose Distance Estimations for Different Objects and Grippers",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a novel approach for the grasping and precise placement of various known rigid objects using multiple grippers within highly cluttered scenes. Using a single depth image of the scene, our method estimates multiple 6D object poses together with an object class, a pose distance for object pose estimation, and a pose distance from a target pose for object placement for each automatically obtained grasp pose with a single forward pass of a neural network.By incorporating model knowledge into the system, our approach has higher success rates for grasping than state-of-the-art model-free approaches. Furthermore, our method chooses grasps that result in significantly more precise object placements than prior model-based work.",
        "primary_area": "",
        "author": "Kilian Kleeberger;Jonathan Schnitzler;Muhammad Usman Khalid;Richard Bormann;Werner Kraus;Marco F. Huber;Kilian Kleeberger;Jonathan Schnitzler;Muhammad Usman Khalid;Richard Bormann;Werner Kraus;Marco F. Huber",
        "authorids": "/37087323129;/37089196159;/37089401678;/38541025900;/37357181400;/37392400600;/37087323129;/37089196159;/37089401678;/38541025900;/37357181400;/37392400600",
        "aff": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635926/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17966932715164231517&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ipa.fraunhofer.de",
        "aff_unique_abbr": "Fraunhofer IPA",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636374",
        "title": "Predicting the Future Motion of Divers for Enhanced Underwater Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous Underwater Vehicles (AUVs) can be effective collaborators to human scuba divers in many applications, such as environmental surveying, mapping, or infrastructure repair. However, for these applications to be realized in the real world, it is essential that robots are able to both lead and follow their human collaborators. Current algorithms for diver following are not robust to non-uniform changes in the motion of the diver, and no framework currently exists for robots to lead divers. One method to improve the robustness of diver following and enable the capability of diver leading is to predict the future motion of a diver. In this paper, we present a vision-based approach for AUVs to predict the future motion trajectory of divers, utilizing the Vanilla-LSTM and Social-LSTM temporal deep neural networks. We also present a dense optical flow-based method to stabilize the input annotations from the dataset and reduce the effects of camera ego-motion. We analyze the results of these models on scenarios ranging from swimming pools to the open ocean and present the model\u2019s accuracy at varying prediction lengths. We find that our LSTM models can generate predictions with significant accuracy 1.5 seconds into the future and that stabilizing LSTM models significantly improves trajectory prediction performance.",
        "primary_area": "",
        "author": "Tanmay Agarwal;Michael Fulton;Junaed Sattar;Tanmay Agarwal;Michael Fulton;Junaed Sattar",
        "authorids": "/37089005772;/37086541498;/37546394500;/37089005772;/37086541498;/37546394500",
        "aff": "Department of Computer Science and Engineering and the Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering and the Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering and the Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636374/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6277444359885936084&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota Twin Cities",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636199",
        "title": "Prioritized Indoor Exploration with a Dynamic Deadline",
        "track": "main",
        "status": "Poster",
        "abstract": "Indoor exploration using mobile robots has typically focused on exploring the entire environment without considering deadlines. This paper introduces a priority-based exploration algorithm for situations with an initially unknown and dynamically assigned deadline. The goal of our exploration strategy is to determine the geometric structure of an unknown environment as rapidly as possible and return to the home location. This is necessary for dangerous environments where an initial rapid robot exploration provides critical information about the layout for subsequent operations. For example, firefighters, for whom time is of the essence, can utilize the map generated by this robotic exploration to navigate a building on fire. We present a three-part strategy to solve this problem. First, we represent the physical environment as an exploration graph, whose vertices represent the local environment with its geometric and semantic information. Second, we assign priority values to these vertices based on their environment regions. Third, we present a graph exploration algorithm that employs the vertex priorities. Simulation experiments on a set of graph environments and Gazebo environments demonstrate that, in contrast to prior approaches that ignore the semantic information, our priority-based exploration algorithm enables the robot to efficiently explore more of the environment while satisfying its deadline constraints.",
        "primary_area": "",
        "author": "Sayantan Datta;Srinivas Akella;Sayantan Datta;Srinivas Akella",
        "authorids": "/37089194827;/37280235600;/37089194827;/37280235600",
        "aff": "Department of Computer Science, University of North Carolina at Charlotte, NC, USA; Department of Computer Science, University of North Carolina at Charlotte, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636199/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=632042622280571542&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of North Carolina at Charlotte",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uncc.edu",
        "aff_unique_abbr": "UNCC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Charlotte",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636685",
        "title": "Probabilistic Inference in Planning for Partially Observable Long Horizon Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "For autonomous service robots to successfully perform long horizon tasks in the real world, they must act intelligently in partially observable environments. Most Task and Motion Planning approaches assume full observability of their state space, making them ineffective in stochastic and partially observable domains that reflect the uncertainties in the real world. We propose an online planning and execution approach for performing long horizon tasks in partially observable domains. Given the robot\u2019s belief and a plan skeleton composed of symbolic actions, our approach grounds each symbolic action by inferring continuous action parameters needed to execute the plan successfully. To achieve this, we formulate the problem of joint inference of action parameters as a Hybrid Constraint Satisfaction Problem (H-CSP) and solve the H-CSP using Belief Propagation. The robot executes the resulting parameterized actions, updates its belief of the world and replans when necessary. Our approach is able to efficiently solve partially observable tasks in a realistic kitchen simulation environment. Our approach outperformed an adaptation of the state-of-the-art method across our experiments.",
        "primary_area": "",
        "author": "Alphonsus Adu-Bredu;Nikhil Devraj;Pin-Han Lin;Zhen Zeng;Odest Chadwicke Jenkins;Alphonsus Adu-Bredu;Nikhil Devraj;Pin-Han Lin;Zhen Zeng;Odest Chadwicke Jenkins",
        "authorids": "/37088518276;/37089194381;/37089195135;/37086281797;/37297252400;/37088518276;/37089194381;/37089195135;/37086281797;/37297252400",
        "aff": "Robotics Institute and Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; Robotics Institute and Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; Robotics Institute and Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA; J.P. Morgan AI Research; Robotics Institute and Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636685/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14513975336637020410&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Michigan;J.P. Morgan",
        "aff_unique_dep": "Robotics Institute and Department of Electrical Engineering and Computer Science;AI Research",
        "aff_unique_url": "https://www.umich.edu;https://www.jpmorgan.com",
        "aff_unique_abbr": "UM;JPM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636295",
        "title": "Probabilistic Iterative LQR for Short Time Horizon MPC",
        "track": "main",
        "status": "Poster",
        "abstract": "Optimal control is often used in robotics for planning a trajectory to achieve some desired behavior, as expressed by the cost function. Most works in optimal control focus on finding a single optimal trajectory, which is then typically tracked by another controller. In this work, we instead consider trajectory distribution as the solution of an optimal control problem, resulting in better tracking performance and a more stable controller. A Gaussian distribution is first obtained from an iterative Linear Quadratic Regulator (iLQR) solver. A short horizon Model Predictive Control (MPC) is then used to track this distribution. We show that tracking the distribution is more cost-efficient and robust as compared to tracking the mean or using iLQR feedback control. The proposed method is validated with kinematic control of 7-DoF Panda manipulator and dynamic control of 6-DoF quadcopter in simulation.",
        "primary_area": "",
        "author": "Teguh Santoso Lembono;Sylvain Calinon;Teguh Santoso Lembono;Sylvain Calinon",
        "authorids": "/37085616225;/37295947200;/37085616225;/37295947200",
        "aff": "EPFL, Lausanne, Switzerland; EPFL, Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636295/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18112190969338525460&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636712",
        "title": "Probabilistic Specification Learning for Planning with Safety Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a framework for learning task specifications from demonstrations, while ensuring that the learned specifications do not violate safety constraints. Furthermore, we show how these specifications can be used in a planning problem to control the robot under environments that can be different from those encountered during the learning phase. We formulate the specification learning problem as a grammatical inference problem, using probabilistic automata to represent specifications. The edge probabilities of the resulting automata represent the demonstrator's preferences. The main novelty in our approach is to incorporate the safety property during the learning process. We prove that the resulting automaton always respects a pre-specified safety property, and furthermore, the proposed method can easily be included in any Evidence-Driven State Merging (EDSM)-based automaton learning scheme. Finally, we introduce a planning algorithm that produces the most desirable plan by maximizing the probability of an accepting trace of the automaton. Case studies show that our algorithm learns the true probability distribution most accurately while maintaining safety. Since, specification is detached from the robot's environment model, a satisfying plan can be synthesized for a variety of different robots and environments including both mobile robots and manipulators.",
        "primary_area": "",
        "author": "Kandai Watanabe;Nicholas Renninger;Sriram Sankaranarayanan;Morteza Lahijanian;Kandai Watanabe;Nicholas Renninger;Sriram Sankaranarayanan;Morteza Lahijanian",
        "authorids": "/37089198237;/37089197044;/37409120700;/37398443600;/37089198237;/37089197044;/37409120700;/37398443600",
        "aff": "Departments of Computer Science and Aerospace Engineering Sciences, University of Colorado Boulder, Boulder, Colorado; MITRE Corporation; Departments of Computer Science and Aerospace Engineering Sciences, University of Colorado Boulder, Boulder, Colorado; Departments of Computer Science and Aerospace Engineering Sciences, University of Colorado Boulder, Boulder, Colorado",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636712/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5876283927954889160&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Colorado Boulder;MITRE Corporation",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.colorado.edu;https://www.mitre.org",
        "aff_unique_abbr": "CU Boulder;MITRE",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boulder;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636003",
        "title": "Probabilistic Trajectory Prediction with Structural Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This work addresses the problem of predicting the motion trajectories of dynamic objects in the environment. Recent advances in predicting motion patterns often rely on machine learning techniques to extrapolate motion patterns from observed trajectories, with no mechanism to directly incorporate known rules. We propose a novel framework, which combines probabilistic learning and constrained trajectory optimisation. The learning component of our framework provides a distribution over future motion trajectories conditioned on observed past coordinates. This distribution is then used as a prior to a constrained optimisation problem which enforces chance constraints on the trajectory distribution. This results in constraint-compliant trajectory distributions which closely resemble the prior. In particular, we focus our investigation on collision constraints, such that extrapolated future trajectory distributions conform to the environment structure. We empirically demonstrate on real-world and simulated datasets the ability of our framework to learn complex probabilistic motion trajectories for motion data, while directly enforcing constraints to improve generalisability, producing more robust and higher quality trajectory distributions.",
        "primary_area": "",
        "author": "Weiming Zhi;Lionel Ott;Fabio Ramos;Weiming Zhi;Lionel Ott;Fabio Ramos",
        "authorids": "/37086936558;/38251784400;/37285364500;/37086936558;/38251784400;/37285364500",
        "aff": "School of Computer Science, the University of Sydney, Australia; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; NVIDIA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636003/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6861880749896512789&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Sydney;ETH Zurich;NVIDIA",
        "aff_unique_dep": "School of Computer Science;Autonomous Systems Lab;NVIDIA",
        "aff_unique_url": "https://www.sydney.edu.au;https://www.ethz.ch;https://www.nvidia.com",
        "aff_unique_abbr": "USYD;ETHZ;NV",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Sydney;Zurich;",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "Australia;Switzerland;United States"
    },
    {
        "id": "9636340",
        "title": "Probabilistic Visual Navigation with Bidirectional Image Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans can robustly follow a visual trajectory defined by a sequence of images (i.e. a video) regardless of substantial changes in the environment or the presence of obstacles. We aim at endowing similar visual navigation capabilities to mobile robots solely equipped with a RGB fisheye camera. We propose a novel probabilistic visual navigation system that learns to follow a sequence of images with bidirectional visual predictions conditioned on possible navigation velocities. By predicting bidirectionally (from start towards goal and vice versa) our method extends its predictive horizon enabling the robot to go around unseen large obstacles that are not visible in the video trajectory. Learning how to react to obstacles and potential risks in the visual field is achieved by imitating human teleoperators. Since the human teleoperation commands are diverse, we propose a probabilistic representation of trajectories that we can sample to find the safest path. We evaluate our navigation system quantitatively and qualitatively in multiple simulated and real environments and compare to state-of-the-art baselines. Our approach outperforms the most recent visual navigation methods with a large margin with regard to goal arrival rate, subgoal coverage rate, and success weighted by path length (SPL). Our method also generalizes to new robot embodiments never used during training.",
        "primary_area": "",
        "author": "Noriaki Hirose;Shun Taguchi;Fei Xia;Roberto Mart\u00edn-Mart\u00edn;Kosuke Tahara;Masanori Ishigaki;Silvio Savarese;Noriaki Hirose;Shun Taguchi;Fei Xia;Roberto Mart\u00edn-Mart\u00edn;Kosuke Tahara;Masanori Ishigaki;Silvio Savarese",
        "authorids": "/37574851500;/37391684000;/37086564490;/37085788640;/37087107692;/37544854900;/37298502600;/37574851500;/37391684000;/37086564490;/37085788640;/37087107692;/37544854900;/37298502600",
        "aff": "TOYOTA Central R&D Labs., INC, Japan; TOYOTA Central R&D Labs., INC, Japan; Department of Computer Science, Stanford University, CA, USA; Department of Computer Science, Stanford University, CA, USA; TOYOTA Central R&D Labs., INC, Japan; TOYOTA Central R&D Labs., INC, Japan; Department of Computer Science, Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636340/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8213311434794239066&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;0;0;1",
        "aff_unique_norm": "Toyota Central R&D Labs., Inc.;Stanford University",
        "aff_unique_dep": ";Department of Computer Science",
        "aff_unique_url": "https://www.toyota-global.com/company/profile.html;https://www.stanford.edu",
        "aff_unique_abbr": "Toyota CRDL;Stanford",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;0;1;1;0;0;1",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "9636598",
        "title": "Probabilistically Guaranteed Satisfaction of Temporal Logic Constraints During Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel constrained reinforcement learning method for finding optimal policies in Markov Decision Processes while satisfying temporal logic constraints with a desired probability throughout the learning process. An automata-theoretic approach is proposed to ensure the probabilistic satisfaction of the constraint in each episode, which is different from penalizing violations to achieve constraint satisfaction after a sufficiently large number of episodes. The proposed approach is based on computing a lower bound on the probability of constraint satisfaction and adjusting the exploration behavior as needed. We present theoretical results on the probabilistic constraint satisfaction achieved by the proposed approach. We also numerically demonstrate the proposed idea in a drone scenario, where the constraint is to perform periodically arriving pick-up and delivery tasks and the objective is to fly over high-reward zones to simultaneously perform aerial monitoring.",
        "primary_area": "",
        "author": "Derya Aksaray;Yasin Yaz\u0131c\u0131o\u011flu;Ahmet Semi Asarkaya;Derya Aksaray;Yasin Yaz\u0131c\u0131o\u011flu;Ahmet Semi Asarkaya",
        "authorids": "/37072799400;/37088649088;/37088917710;/37072799400;/37088649088;/37088917710",
        "aff": "Department of Aerospace Engineering and Mechanics, University of Minnesota, Minneapolis, MN; Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN; Department of Aerospace Engineering and Mechanics, University of Minnesota, Minneapolis, MN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636598/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16685625269796239807&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Aerospace Engineering and Mechanics",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636668",
        "title": "Q-learning with Long-term Action-space Shaping to Model Complex Behavior for Autonomous Lane Changes",
        "track": "main",
        "status": "Poster",
        "abstract": "In autonomous driving applications, reinforcement learning agents often have to perform complex behavior, which can translate into optimizing multiple objectives while following certain rules. Encoding traffic rules and desires such as safety and comfort via classical methods based on reward shaping (i.e. a weighted combination of different objectives in the reward signal) or Lagrangian methods (including auxiliary losses in the optimization) can be very hard and cumbersome. In this work, we propose to instead shape the action-space at the maximization step of Q-learning. We further introduce a formulation for fixed-horizon estimation of auxiliary costs under the current target-policy based on truncated value- functions to encode the desire of comfortable driving ensuring interpretable behavior. We compare our algorithm to reward shaping and Lagrangian methods in the application of high- level decision making in autonomous driving, considering rules for safety, keeping right and comfort. We train and evaluate our agent in the open-source simulator SUMO on a variety of scenarios with different driver types and traffic situations. Additionally, we apply our method on the real HighD data set, showing the real-world applicability and simplicity of Q- learning with Action-space Shaping.",
        "primary_area": "",
        "author": "Gabriel Kalweit;Maria Huegle;Moritz Werling;Joschka Boedecker;Gabriel Kalweit;Maria Huegle;Moritz Werling;Joschka Boedecker",
        "authorids": "/37087323482;/37087322877;/37542759200;/37888921900;/37087323482;/37087322877;/37542759200;/37888921900",
        "aff": "Dept. of Computer Science, University of Freiburg, Germany; Dept. of Computer Science, University of Freiburg, Germany; BMWGroup, Germany; Cluster of Excellence BrainLinks-BrainTools, Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636668/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5798893166385071047&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Freiburg;BMW Group",
        "aff_unique_dep": "Dept. of Computer Science;",
        "aff_unique_url": "https://www.uni-freiburg.de;https://www.bmwgroup.com",
        "aff_unique_abbr": "Uni Freiburg;BMW",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Freiburg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636716",
        "title": "QoE-driven Delay-adaptive Control Scheme Switching for Time-delayed Bilateral Teleoperation with Haptic Data Reduction",
        "track": "main",
        "status": "Poster",
        "abstract": "Teleoperation systems with haptic feedback allow a human user to remotely interact with a dangerous or inac-cessible environment, perform various tasks, and perceive the haptic feedback. To ensure system stability while maintaining the best possible quality of experience (QoE), different teleoperation control schemes and haptic communication strategies need to be selected to adapt to varying network conditions and teleoperation tasks. In this paper, we propose a QoE-driven control scheme switching approach, which adaptively selects the control scheme that provides the best possible QoE for varying communication delay. A transition period is designed to moderate the artifacts during the switching phase. Haptic data reduction approaches are developed for the switching strategy to match the characteristics of each control scheme. Our experiments verify the feasibility of the proposed scheme. Subjective tests confirm that the proposed adaptive switching scheme is able to achieve a superior user QoE in contrast to a fixed control scheme in the presence of varying communication delay up to 200 ms.",
        "primary_area": "",
        "author": "Xiao Xu;Siyuan Zhang;Qian Liu;Eckehard Steinbach;Xiao Xu;Siyuan Zhang;Qian Liu;Eckehard Steinbach",
        "authorids": "/38238310400;/37089198294;/37713756900;/37273225600;/38238310400;/37089198294;/37713756900;/37273225600",
        "aff": "Chair of Media Technology, Technical University of Munich, Germany; Chair of Media Technology, Technical University of Munich, Germany; Dalian University of Technology, Dalian, China; Chair of Media Technology, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636716/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5612743344703466006&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Technical University of Munich;Dalian University of Technology",
        "aff_unique_dep": "Chair of Media Technology;",
        "aff_unique_url": "https://www.tum.de;http://www.dlut.edu.cn/",
        "aff_unique_abbr": "TUM;DUT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Dalian",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "9636120",
        "title": "Quadruped Robot Hopping on Two Legs",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a control strategy for quadruped robots to hop on their rear legs in three-dimensional space. The proposed approach generates nominal center of mass (CoM) trajectories based on a template spring-loaded inverted pendulum (SLIP) model. Tracking this reference remains a challenge due to the underactauted nature of balance with point feet. To address this challenge, a control-Lyapunov function based quadratic programming (CLF-QP) controller is proposed, which modulates nominal ground reaction forces (GRFs) to balance the torso while considering friction limits. The CLF construction is guided by a variational-based linearization (VBL) applied to a reduced-order single-rigid-body (SRB) model, and treats underactuation via solving a Riccati equation to obtain the CLF. A new balance control approach is presented that effectively decouples sagittal plane control (via re-planning) with lateral and rotational control (via the CLF and VBL). The proposed approach shows more robust balancing performance than the conventional CLF-QP approach. Simulations of the Mini Cheetah demonstrate in-place hopping with up to a 0.71m apex height.",
        "primary_area": "",
        "author": "Shenggao Li;Hua Chen;Wei Zhang;Patrick M. Wensing;Shenggao Li;Hua Chen;Wei Zhang;Patrick M. Wensing",
        "authorids": "/37089195720;/37086195529;/37089656248;/37946046300;/37089195720;/37086195529;/37089656248;/37946046300",
        "aff": "University of Notre Dame, South Bend, US; Southern University of Science and Technology, Shenzhen, China; Southern University of Science and Technology, Shenzhen, China; University of Notre Dame, South Bend, US",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636120/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5385403918282408094&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Notre Dame;Southern University of Science and Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.nd.edu;https://www.sustech.edu.cn",
        "aff_unique_abbr": "Notre Dame;SUSTech",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "South Bend;Shenzhen",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9635974",
        "title": "Quadrupedal template model for parametric stability analysis of trotting gaits",
        "track": "main",
        "status": "Poster",
        "abstract": "Simple template models have proven useful for understanding the underlying dynamics of legged locomotion. The most common one, the SLIP model, considers the legs as linear springs with constant stiffness, and it explains well the radial dynamics of the legs. However, in order to study the influence of the leg swing dynamics and leg segmentation on gait stability, more complex models are required. This paper introduces a novel template model for quadrupedal gait, which considers these additional aspects. The dynamic behavior of the model is analyzed via numerical simulation, using a continuation approach. By conducting a parametric analysis on the trotting gait and analyzing its stability, we identify the influence of the main model parameters, leading to marginally unstable limit cycles. These numerical results are applicable to the design of more efficient elastic quadrupedal robots.",
        "primary_area": "",
        "author": "Lorenzo Boffa;Anna Sesselmann;M\u00e1ximo A. Roa;Lorenzo Boffa;Anna Sesselmann;M\u00e1ximo A. Roa",
        "authorids": "/37089196021;/37088806799;/37628512100;/37089196021;/37088806799;/37628512100",
        "aff": "Politecnico di Milano, Milan, Italy; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635974/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7951596814140890309&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Politecnico di Milano;German Aerospace Center",
        "aff_unique_dep": ";Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.polimi.it;https://www.dlr.de",
        "aff_unique_abbr": "Polimi;DLR",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Milan;Wessling",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Italy;Germany"
    },
    {
        "id": "9636073",
        "title": "Quasi-static motion of a new serial snake-like robot on a water surface: a geometrical approach",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper reports methods to compute the equilibrium stances of a new snake-like robot designed to stabilize its head on a free water surface. To adjust rapidly the stability of the robot, this bio-inspired robot can rotate independently each body-shell, and modify the level of immersion of each module. To predict the stable stance accessible by this additional degree of freedom, a model is developed to compute the equilibrium configurations of the robot from a given parametrization of the body shape. Then, an algorithm is introduced to compute a sequence of controlled body deformations, such that the head configuration relatively to the water surface remains unchanged. Finally, we explore in simulation stances and quasi-static gaits, and investigate to what extent the buoyancy and the body deformations can be used to stabilize the head of the snake-like robot.",
        "primary_area": "",
        "author": "Xiao Xie;Johann Herault;\u00c9tienne Clement;Vincent Lebastard;Fr\u00e9d\u00e9ric Boyer;Xiao Xie;Johann Herault;\u00c9tienne Clement;Vincent Lebastard;Fr\u00e9d\u00e9ric Boyer",
        "authorids": "/37089194653;/37089198050;/37089196698;/37273798400;/37348112600;/37089194653;/37089198050;/37089196698;/37273798400;/37348112600",
        "aff": "IMT Atlantique, LS2N, UMR CNRS 6004, Nantes, France; IMT Atlantique, LS2N, UMR CNRS 6004, Nantes, France; IMT Atlantique, LS2N, UMR CNRS 6004, Nantes, France; IMT Atlantique, LS2N, UMR CNRS 6004, Nantes, France; IMT Atlantique, LS2N, UMR CNRS 6004, Nantes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636073/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6084689384583548258&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "IMT Atlantique",
        "aff_unique_dep": "LS2N, UMR CNRS 6004",
        "aff_unique_url": "https://www.imt-atlantique.fr",
        "aff_unique_abbr": "IMT Atlantique",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Nantes",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636718",
        "title": "R-SNN: An Analysis and Design Methodology for Robustifying Spiking Neural Networks against Adversarial Attacks through Noise Filters for Dynamic Vision Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Spiking Neural Networks (SNNs) aim at providing energy-efficient learning capabilities when implemented on neuromorphic chips with event-based Dynamic Vision Sensors (DVS). This paper studies the robustness of SNNs against adversarial attacks on such DVS-based systems, and proposes R-SNN, a novel methodology for robustifying SNNs through efficient DVS-noise filtering. We are the first to generate adversarial attacks on DVS signals (i.e., frames of events in the spatio-temporal domain) and to apply noise filters for DVS sensors in the quest for defending against adversarial attacks. Our results show that the noise filters effectively prevent the SNNs from being fooled. The SNNs in our experiments provide more than 90% accuracy on the DVS-Gesture and NMNIST datasets under different adversarial threat models.",
        "primary_area": "",
        "author": "Alberto Marchisio;Giacomo Pira;Maurizio Martina;Guido Masera;Muhammad Shafique;Alberto Marchisio;Giacomo Pira;Maurizio Martina;Guido Masera;Muhammad Shafique",
        "authorids": "/37086480693;/37088974360;/37296189500;/37296188300;/37408660000;/37086480693;/37088974360;/37296189500;/37296188300;/37408660000",
        "aff": "Institute of Computer Engineering, Technische Universit\u00e4t Wien, Vienna, Austria; Department of Electronics and Telecommunication, Politecnico di Torino, Turin, Italy; Department of Electronics and Telecommunication, Politecnico di Torino, Turin, Italy; Department of Electronics and Telecommunication, Politecnico di Torino, Turin, Italy; Division of Engineering, New York University, Abu Dhabi, UAE",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636718/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4276546220318799445&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;2",
        "aff_unique_norm": "Technische Universit\u00e4t Wien;Politecnico di Torino;New York University",
        "aff_unique_dep": "Institute of Computer Engineering;Department of Electronics and Telecommunication;Division of Engineering",
        "aff_unique_url": "https://www.tuwien.ac.at;https://www.polito.it;https://www.nyu.edu",
        "aff_unique_abbr": "TU Wien;Politecnico di Torino;NYU",
        "aff_campus_unique_index": "0;1;1;1;2",
        "aff_campus_unique": "Vienna;Turin;Abu Dhabi",
        "aff_country_unique_index": "0;1;1;1;2",
        "aff_country_unique": "Austria;Italy;United Arab Emirates"
    },
    {
        "id": "9636611",
        "title": "REAL: Rapid Exploration with Active Loop-Closing toward Large-Scale 3D Mapping using UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "Exploring an unknown environment without colliding with obstacles is one of the essentials of autonomous vehicles to perform diverse missions such as structural inspections, rescues, deliveries, and so forth. Therefore, unmanned aerial vehicles (UAVS), which are fast, agile, and have high degrees of freedom, have been widely used. However, previous approaches have two limitations: a) First, they may not be appropriate for exploring large-scale environments because they mainly depend on random sampling-based path planning that causes unnecessary movements. b) Second, they assume the pose estimation is accurate enough, which is the most critical factor in obtaining an accurate map. In this paper, to explore and map unknown large-scale environments rapidly and accurately, we propose a novel exploration method that combines the pre-calculated Peacock Trajectory with graph-based global exploration and active loop-closing. Because the two-step trajectory that considers the kinodynamics of UAVs is used, obstacle avoidance is guaranteed in the receding-horizon manner. In addition, local exploration that considers the frontier and global exploration based on the graph maximizes the speed of exploration by minimizing unnecessary revisiting. In addition, by actively closing the loop based on the likelihood, pose estimation performance is improved. The proposed method\u2019s performance is verified by exploring 3D simulation environments in comparison with the state-of-the-art methods. Finally, the proposed approach is validated in a real-world experiment.",
        "primary_area": "",
        "author": "Eungchang Mason Lee;Junho Choi;Hyungtae Lim;Hyun Myung;Eungchang Mason Lee;Junho Choi;Hyungtae Lim;Hyun Myung",
        "authorids": "/37088856362;/37088691491;/37086920570;/37424926900;/37088856362;/37088691491;/37086920570;/37424926900",
        "aff": "School of Electrical Engineering, KI-AI, and KI-R, KAIST (Korea Advanced Institute of Science and Technology), Daejeon, Republic of Korea; School of Electrical Engineering, KI-AI, and KI-R, KAIST (Korea Advanced Institute of Science and Technology), Daejeon, Republic of Korea; School of Electrical Engineering, KI-AI, and KI-R, KAIST (Korea Advanced Institute of Science and Technology), Daejeon, Republic of Korea; School of Electrical Engineering, KI-AI, and KI-R, KAIST (Korea Advanced Institute of Science and Technology), Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636611/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3092162563043278118&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "KAIST (Korea Advanced Institute of Science and Technology)",
        "aff_unique_dep": "School of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636624",
        "title": "RF-LIO: Removal-First Tightly-coupled Lidar Inertial Odometry in High Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous Localization and Mapping (SLAM) is considered to be an essential capability for intelligent vehicles and mobile robots. However, most of the current lidar SLAM approaches are based on the assumption of a static environment. Hence the localization in a dynamic environment with multiple moving objects is actually unreliable. The paper proposes a dynamic SLAM framework RF-LIO, building on LIO-SAM, which adds adaptive multi-resolution range images and uses tightly-coupled lidar inertial odometry to first remove moving objects, and then match lidar scan to the submap. Thus, it can obtain accurate poses even in high dynamic environments. The proposed RF-LIO is evaluated on both self-collected datasets and open Urbanloco datasets. The experimental results in high dynamic environments demonstrate that, compared with LOAM and LIO-SAM, the absolute trajectory accuracy of the proposed RF-LIO can be improved by 90% and 70%, respectively. RF-LIO is one of the state-of-the-art SLAM systems in high dynamic environments.",
        "primary_area": "",
        "author": "",
        "authorids": "",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636624/",
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15225117040641715258&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1
    },
    {
        "id": "9635871",
        "title": "ROBI: A Multi-View Dataset for Reflective Objects in Robotic Bin-Picking",
        "track": "main",
        "status": "Poster",
        "abstract": "In robotic bin-picking applications, the perception of texture-less, highly reflective parts is a valuable but challenging task. The high glossiness can introduce fake edges in RGB images and inaccurate depth measurements, especially in heavily cluttered bin scenarios. In this paper, we present the ROBI (Reflective Objects in BIns) dataset, a public dataset for 6D object pose estimation and multi-view depth fusion in robotic bin-picking scenarios. The ROBI dataset includes a total of 63 bin-picking scenes captured with two active stereo cameras: a high-cost Ensenso sensor and a low-cost RealSense sensor. For each scene, the monochrome/RGB images and depth maps are captured from sampled view spheres around the scene, and are annotated with accurate 6D poses of visible objects and an associated visibility score. For evaluating the performance of depth fusion, we captured the ground truth depth maps by high-cost Ensenso camera with objects coated in anti-reflective scanning spray. To show the utility of the dataset, we evaluated the representative algorithms of 6D object pose estimation and multi-view depth fusion on the full dataset. Evaluation results demonstrate the difficulty of highly reflective objects, especially in difficult cases due to the degradation of depth data quality, severe occlusions, and cluttered scenes. The ROBI dataset is available online at https://www.trailab.utias.utoronto.ca/robi.",
        "primary_area": "",
        "author": "Jun Yang;Yizhou Gao;Dong Li;Steven L. Waslander;Jun Yang;Yizhou Gao;Dong Li;Steven L. Waslander",
        "authorids": "/37088838125;/37089194587;/37088838506;/37301169100;/37088838125;/37089194587;/37088838506;/37301169100",
        "aff": "University of Toronto Institute for Aerospace Studies and Robotics Institute; Epson Canada; Epson Canada; University of Toronto Institute for Aerospace Studies and Robotics Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635871/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13729360365894755845&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Toronto;Epson",
        "aff_unique_dep": "Institute for Aerospace Studies and Robotics Institute;",
        "aff_unique_url": "https://www.utoronto.ca;https://www.epson.ca",
        "aff_unique_abbr": "U of T;Epson",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636816",
        "title": "ROS for Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Integrating real-time, complex social signal processing into robotic systems \u2013 especially in real-world, multi-party interaction situations \u2013 is a challenge faced by many in the Human-Robot Interaction (HRI) community. The difficulty is compounded by the lack of any standard model for human representation that would facilitate the development and interoperability of social perception components and pipelines. We introduce in this paper a set of conventions and standard interfaces for HRI scenarios, designed to be used with the Robot Operating System (ROS). It directly aims at promoting interoperability and re-usability of core functionality between the many HRI-related software tools, from skeleton tracking, to face recognition, to natural language processing. Importantly, these interfaces are designed to be relevant to a broad range of HRI applications, from high-level crowd simulation, to group-level social interaction modelling, to detailed modelling of human kinematics. We demonstrate these interfaces by providing a reference pipeline implementation, packaged to be easily downloaded and evaluated by the community.",
        "primary_area": "",
        "author": "Youssef Mohamed;S\u00e9verin Lemaignan;Youssef Mohamed;S\u00e9verin Lemaignan",
        "authorids": "/37088884361;/38482927400;/37088884361;/38482927400",
        "aff": "KTH Royal Institute of Technology, Stockholm, Sweden; Bristol Robotics Laboratory, University of the West of England, Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636816/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18445039785888030906&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "KTH Royal Institute of Technology;University of the West of England",
        "aff_unique_dep": ";Bristol Robotics Laboratory",
        "aff_unique_url": "https://www.kth.se;https://www.uwe.ac.uk",
        "aff_unique_abbr": "KTH;UWE",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Stockholm;Bristol",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Sweden;United Kingdom"
    },
    {
        "id": "9636522",
        "title": "RP-VIO: Robust Plane-based Visual-Inertial Odometry for Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern visual-inertial navigation systems (VINS) are faced with a critical challenge in real-world deployment: they need to operate reliably and robustly in highly dynamic environments. Current best solutions merely filter dynamic objects as outliers based on the semantics of the object category. Such an approach does not scale as it requires semantic classifiers to encompass all possibly-moving object classes; this is hard to define, let alone deploy. On the other hand, many realworld environments exhibit strong structural regularities in the form of planes such as walls and ground surfaces, which are also crucially static. We present RP-VIO, a monocular visual-inertial odometry system that leverages the simple geometry of these planes for improved robustness and accuracy in challenging dynamic environments. Since existing datasets have a limited number of dynamic elements, we also present a highly-dynamic, photorealistic synthetic dataset for a more effective evaluation of the capabilities of modern VINS systems. We evaluate our approach on this dataset, and three diverse sequences from standard datasets including two real-world dynamic sequences and show a significant improvement in robustness and accuracy over a state-of-the-art monocular visual-inertial odometry system. We also show in simulation an improvement over a simple dynamic-features masking approach. Our code and dataset are publicly available\u2020.",
        "primary_area": "",
        "author": "Karnik Ram;Chaitanya Kharyal;Sudarshan S. Harithas;K. Madhava Krishna;Karnik Ram;Chaitanya Kharyal;Sudarshan S. Harithas;K. Madhava Krishna",
        "authorids": "/37089194925;/37089197889;/37088551179;/37395945400;/37089194925;/37089197889;/37088551179;/37395945400",
        "aff": "Robotics Research Center, IIIT Hyderabad, India; Robotics Research Center, IIIT Hyderabad, India; Robotics Research Center, IIIT Hyderabad, India; Robotics Research Center, IIIT Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636522/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9972913656854323678&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "IIIT Hyderabad",
        "aff_unique_dep": "Robotics Research Center",
        "aff_unique_url": "https://www.iiit Hyderabad.ac.in",
        "aff_unique_abbr": "IIIT-H",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hyderabad",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9635876",
        "title": "RRT-Based Path Planning for Follow-the-Leader Motion of Hyper-Redundant Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Hyper-redundant manipulators with slender body and high dexterity are widely applied for operations in confined spaces. Among the motion planning methods for these operations, the follow-the-leader motion controller is generally developed to avoid the obstacles, while the path trajectories are usually given. In this paper, we present an autonomous motion planner with a specialized rapidly exploring random tree (Sp-RRT) approach for follow-the-leader motion of hyper-redundant manipulators. Starting from the target pose in the workspace, the exploring tree can expand to multiple entrances while guaranteeing the final pose of the manipulator\u2019s end-effector. Meanwhile, the dexterity of hyper-redundant manipulators (even with different segments) can be utilized sufficiently with customized expanding parameters. Simulation results compared with existing methods are conducted to demonstrate the aforementioned characteristics and effectiveness. For further validation, we experimentally verify the development with our custom-built hyper-redundant manipulator to realize the generated path with follow-the-leader motion.",
        "primary_area": "",
        "author": "Hanghang Wei;Yang Zheng;Guoying Gu;Hanghang Wei;Yang Zheng;Guoying Gu",
        "authorids": "/37089194100;/37087244586;/37404380300;/37089194100;/37087244586;/37404380300",
        "aff": "State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635876/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15692671245914362741&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "State Key Laboratory of Mechanical System and Vibration",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636290",
        "title": "RTVS: A Lightweight Differentiable MPC Framework for Real-Time Visual Servoing",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent data-driven approaches to visual servoing have shown improved performances over classical methods due to precise feature matching and depth estimation. Some recent servoing approaches use a model predictive control (MPC) framework which generalise well to novel environments and are capable of incorporating dynamic constraints, but are computationally intractable in real-time, making it difficult to deploy in real-world scenarios. On the contrary, single-step methods optimise greedily and achieve high servoing rates, but lack the benefits of the MPC multi-step ahead formulation. In this paper, we make the best of both worlds and propose a lightweight visual servoing MPC framework which generates optimal control near real-time at a frequency of 10.52 Hz. This work utilises the differential cross-entropy sampling method for quick and effective control generation along with a lightweight neural network, significantly improving the servoing frequency. We also propose a flow depth normalisation layer which ameliorates the issue of inferior predictions of two view depth from the flow network. We conduct extensive experimentation on the Habitat simulator and show a notable decrease in servoing time in comparison with other approaches that optimise over a time horizon. We achieve the right balance between time and performance for visual servoing in six degrees of freedom (6DoF), while retaining the advantageous MPC formulation. Our code and dataset are publicly available\u2020.",
        "primary_area": "",
        "author": "M. Nomaan Qureshi;Pushkal Katara;Abhinav Gupta;Harit Pandya;Y V S Harish;AadilMehdi Sanchawala;Gourav Kumar;Brojeshwar Bhowmick;K. Madhava Krishna;M. Nomaan Qureshi;Pushkal Katara;Abhinav Gupta;Harit Pandya;Y V S Harish;AadilMehdi Sanchawala;Gourav Kumar;Brojeshwar Bhowmick;K. Madhava Krishna",
        "authorids": "/37089195208;/37086858700;/37089197928;/37085346690;/37085955535;/37088538330;/37086099285;/37571664300;/38201465600;/37089195208;/37086858700;/37089197928;/37085346690;/37085955535;/37088538330;/37086099285;/37571664300;/38201465600",
        "aff": "Robotics Research Center, IIIT Hyderabad, India; Robotics Research Center, IIIT Hyderabad, India; Robotics Research Center, IIIT Hyderabad, India; Cambridge Research Laboratory, Toshiba Europe, UK; Robotics Research Center, IIIT Hyderabad, India; Robotics Research Center, IIIT Hyderabad, India; TCS Research, Kolkata, India; TCS Research, Kolkata, India; Robotics Research Center, IIIT Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636290/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2222070732732324112&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;1;0;0;2;2;0",
        "aff_unique_norm": "IIIT Hyderabad;Toshiba Europe;Tata Consultancy Services",
        "aff_unique_dep": "Robotics Research Center;Cambridge Research Laboratory;Research",
        "aff_unique_url": "https://www.iiit Hyderabad.ac.in;https://www.toshiba.eu;https://www.tcs.com",
        "aff_unique_abbr": "IIIT-H;Toshiba;TCS",
        "aff_campus_unique_index": "0;0;0;1;0;0;2;2;0",
        "aff_campus_unique": "Hyderabad;Cambridge;Kolkata",
        "aff_country_unique_index": "0;0;0;1;0;0;0;0;0",
        "aff_country_unique": "India;United Kingdom"
    },
    {
        "id": "9636083",
        "title": "RV-FuseNet: Range View Based Fusion of Time-Series LiDAR Data for Joint 3D Object Detection and Motion Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust real-time detection and motion forecasting of traffic participants is necessary for autonomous vehicles to safely navigate urban environments. In this paper, we present RV-FuseNet, a novel end-to-end approach for joint detection and trajectory estimation directly from time-series LiDAR data. Instead of the widely used bird\u2019s eye view (BEV) representation, we utilize the native range view (RV) representation of LiDAR data. The RV preserves the full resolution of the sensor by avoiding the voxelization used in the BEV. Furthermore, RV can be processed efficiently due to its compactness. Previous approaches project time-series data to a common viewpoint for temporal fusion, and often this viewpoint is different from where it was captured. This is sufficient for BEV methods, but for RV methods, this can lead to loss of information and data distortion which has an adverse impact on performance. To address this challenge we propose a simple yet effective novel architecture, Incremental Fusion, that minimizes the information loss by sequentially projecting each RV sweep into the viewpoint of the next sweep in time. We show that our approach significantly improves motion forecasting performance over the existing state-of-the-art. Furthermore, we demonstrate that our sequential fusion approach is superior to alternative RV based fusion methods on multiple datasets.",
        "primary_area": "",
        "author": "Ankit Laddha;Shivam Gautam;Gregory P. Meyer;Carlos Vallespi-Gonzalez;Carl K. Wellington;Ankit Laddha;Shivam Gautam;Gregory P. Meyer;Carlos Vallespi-Gonzalez;Carl K. Wellington",
        "authorids": "/37085627818;/37088638511;/37087232268;/37087231633;/37283625600;/37085627818;/37088638511;/37087232268;/37087231633;/37283625600",
        "aff": "Aurora Innovation, Pittsburgh, USA; Aurora Innovation, Pittsburgh, USA; Uber Advanced Technologies Group, Pittsburgh; Aurora Innovation, Pittsburgh, USA; Aurora Innovation, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636083/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14637583445138393049&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Aurora Innovation;Uber",
        "aff_unique_dep": ";Advanced Technologies Group",
        "aff_unique_url": "https://www.aurorai.com;https://www.uber.com",
        "aff_unique_abbr": ";Uber ATG",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636248",
        "title": "RaP-Net: A Region-wise and Point-wise Weighting Network to Extract Robust Features for Indoor Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Feature extraction plays an important role in visual localization. Unreliable features on dynamic objects or repetitive regions will interfere with feature matching and challenge indoor localization greatly. To address the problem, we propose a novel network, RaP-Net, to simultaneously predict region-wise invariability and point-wise reliability, and then extract features by considering both of them. We also introduce a new dataset, named OpenLORIS-Location, to train the proposed network. The dataset contains 1553 images from 93 indoor locations. Various appearance changes between images of the same location are included and can help the model to learn the invariability in typical indoor scenes. Experimental results show that the proposed RaP-Net trained with OpenLORIS-Location dataset achieves excellent performance in the feature matching task and significantly outperforms state-of-the-arts feature algorithms in indoor localization. The RaPNet code and dataset are available at https://github.com/ivipsourcecode/RaP-Net.",
        "primary_area": "",
        "author": "Dongjiang Li;Jinyu Miao;Xuesong Shi;Yuxin Tian;Qiwei Long;Tianyu Cai;Ping Guo;Hongfei Yu;Wei Yang;Haosong Yue;Qi Wei;Fei Qiao;Dongjiang Li;Jinyu Miao;Xuesong Shi;Yuxin Tian;Qiwei Long;Tianyu Cai;Ping Guo;Hongfei Yu;Wei Yang;Haosong Yue;Qi Wei;Fei Qiao",
        "authorids": "/37088395695;/37087325080;/37086577986;/37088503927;/37088394848;/37089197429;/37086575742;/37089196217;/37276965400;/37851695500;/37582779500;/37272195200;/37088395695;/37087325080;/37086577986;/37088503927;/37088394848;/37089197429;/37086575742;/37089196217;/37276965400;/37851695500;/37582779500;/37272195200",
        "aff": "Beijing Jiaotong University, Beijing, China; Beihang University, Beijing, China; Intel Labs China, Beijing, China; Beihang University, Beijing, China; Beijing Jiaotong University, Beijing, China; Shanghai Jiao Tong University, China; Intel Labs China, Beijing, China; Tsinghua University, Beijing, China; Beijing Jiaotong University, Beijing, China; Beihang University, Beijing, China; Tsinghua University, Beijing, China; Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636248/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8473591749565303151&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;1;2;1;0;3;2;4;0;1;4;4",
        "aff_unique_norm": "Beijing Jiao Tong University;Beihang University;Intel;Shanghai Jiao Tong University;Tsinghua University",
        "aff_unique_dep": ";;Intel Labs China;;",
        "aff_unique_url": "http://www.bjtu.edu.cn;http://www.buaa.edu.cn/;https://www.intel.cn;https://www.sjtu.edu.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "BJTU;BUAA;Intel China;SJTU;THU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636170",
        "title": "Radar Based Target Tracking and Classification for Efficient Robot Speed Control in Fenceless Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Awareness of its surroundings is a crucial capability for a robot meant to be working alongside other robots or human operators. When considering safety norms and modalities, in particular the Speed and Separation Monitoring (SSM), proper proximity information can make the difference in the overall efficiency of a use case, for example avoiding unnecessary penalizations in the cycle-time. This paper presents a method to exploit the proximity perception capabilities of radar sensors to construct a continuous speed control algorithm for a UR10 robot. With respect to standard implementations of the SSM in industrial and collaborative environments, the proposed speed control is enhanced by the addition of direct human\u2019s velocity measurement, full direction of travel and target classification. The results are evalauted according to the SSM metrics for safety and productivity, showing an overall increase in efficiency while still maintaining safety level requirements.",
        "primary_area": "",
        "author": "Barnaba Ubezio;Christian Sch\u00f6ffmann;Lucas Wohlhart;Stephan M\u00fclbacher-Karrer;Hubert Zangl;Michael Hofbaur;Barnaba Ubezio;Christian Sch\u00f6ffmann;Lucas Wohlhart;Stephan M\u00fclbacher-Karrer;Hubert Zangl;Michael Hofbaur",
        "authorids": "/37088506657;/37088840357;/37089196846;/37089196709;/37273010900;/37282896000;/37088506657;/37088840357;/37089196846;/37089196709;/37273010900;/37282896000",
        "aff": "Robotics and Mechatronics, Joanneum Research Robotics, Klagenfurt am W\u00f6rthersee, Austria; Sensors and Actuators Department, Institute of Smart System Technologies, Alpen-Adria-Universit\u00e4t, Klagenfurt am W\u00f6rthersee, Austria; Robotics and Mechatronics, Joanneum Research Robotics, Klagenfurt am W\u00f6rthersee, Austria; Robotics and Mechatronics, Joanneum Research Robotics, Klagenfurt am W\u00f6rthersee, Austria; Sensors and Actuators Department, Institute of Smart System Technologies, Alpen-Adria-Universit\u00e4t, Klagenfurt am W\u00f6rthersee, Austria; Robotics and Mechatronics, Joanneum Research Robotics, Klagenfurt am W\u00f6rthersee, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636170/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1422076311524972635&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;1;0",
        "aff_unique_norm": "JOANNEUM RESEARCH;Alpen-Adria-Universit\u00e4t",
        "aff_unique_dep": "Robotics and Mechatronics;Sensors and Actuators Department, Institute of Smart System Technologies",
        "aff_unique_url": "https://www.joanneum.at;https://www.aau.at",
        "aff_unique_abbr": "JR;",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Klagenfurt am W\u00f6rthersee",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9636799",
        "title": "Radar Visual Inertial Odometry and Radar Thermal Inertial Odometry: Robust Navigation even in Challenging Visual Conditions",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose to fuse radar measurements with Visual Inertial Odometry (RVIO) or Thermal Inertial Odometry (RTIO). FMCW radar sensor data enables to estimate the 3D ego velocity independent of the visual conditions. Fusion with VIO or TIO heavily improves the robustness in challenging conditions such as darkness, direct sunlight or fog.Specifically, we propose RRxIO: An extension to the state of the art filter based VIO framework Robust Visual Inertial Odometry (ROVIO) to fuse radar sensor data. Due to the drift free 3D radar ego velocity estimates, scale errors are reduced and only a small number of features needs to be tracked to achieve good results. This yields faster runtimes while outperforming state of the art VIO frameworks regarding accuracy. RVIO is able to bridge phases of degraded or even no visual features resulting in a low cost system even for poor visual conditions. RTIO is robust even in environments with small temperature gradients and bridges phases of no thermal images caused by Non-Uniformity Corrections (NUCs).We evaluated our system with various experiments in different environments and visual conditions. Comparison to other state of the art dual domain approaches including radar-inertial, visual-inertial and thermal-inertial proves superior performance of our approach regarding accuracy and processing time.",
        "primary_area": "",
        "author": "Christopher Doer;Gert F. Trommer;Christopher Doer;Gert F. Trommer",
        "authorids": "/37086428351;/37424084700;/37086428351;/37424084700",
        "aff": "Institute of Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Department of Information and Navigation Systems, ITMO University, Saint Petersburg, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636799/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8091255536773639044&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Karlsruhe Institute of Technology;ITMO University",
        "aff_unique_dep": "Institute of Control Systems;Department of Information and Navigation Systems",
        "aff_unique_url": "https://www.kit.edu;https://www.itmo.ru",
        "aff_unique_abbr": "KIT;ITMO",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Karlsruhe;Saint Petersburg",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Germany;Russian Federation"
    },
    {
        "id": "9636819",
        "title": "Random Fourier Features based SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "This work is dedicated to simultaneous continuous-time trajectory estimation and mapping based on Gaussian Processes (GP). State-of-the-art GP-based models for Simultaneous Localization and Mapping (SLAM) are computationally efficient but can only be used with a restricted class of kernel functions. This paper provides the algorithm based on GP with Random Fourier Features (RFF) approximation for SLAM without any constraints. The advantages of RFF for continuous-time SLAM are that we can consider a broader class of kernels and, at the same time, maintain computational complexity at reasonably low level by operating in the Fourier space of features. The accuracy-speed trade-off can be controlled by the number of features. Our experimental results on synthetic and real-world benchmarks demonstrate the cases in which our approach provides better results compared to the current state-of-the-art.",
        "primary_area": "",
        "author": "Yermek Kapushev;Anastasia Kishkun;Gonzalo Ferrer;Evgeny Burnaev;Yermek Kapushev;Anastasia Kishkun;Gonzalo Ferrer;Evgeny Burnaev",
        "authorids": "/37089197546;/37086588728;/38469245200;/37085999324;/37089197546;/37086588728;/38469245200;/37085999324",
        "aff": "Sber AI Lab, Moscow, Russia; Skolkovo Institute of Science and Technology, Moscow, Russia; Skolkovo Institute of Science and Technology, Moscow, Russia; Skolkovo Institute of Science and Technology, Moscow, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636819/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7693561933319733958&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Sberbank;Skolkovo Institute of Science and Technology",
        "aff_unique_dep": "Sber AI Lab;",
        "aff_unique_url": "https://sberbank.ru;https://www.skoltech.ru",
        "aff_unique_abbr": "Sber;Skoltech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Moscow",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "9635856",
        "title": "Rapid Convex Optimization of Centroidal Dynamics using Block Coordinate Descent",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we explore the use of block coordinate descent (BCD) to optimize the centroidal momentum dynamics for dynamically consistent multi-contact behaviors. The centroidal dynamics have recently received a large amount of attention in order to create physically realizable motions for robots with hands and feet while being computationally more tractable than full rigid body dynamics models. Our contribution lies in exploiting the structure of the dynamics in order to simplify the original non-convex problem into two convex subproblems. We iterate between these two subproblems for a set number of iterations or until a consensus is reached. We explore the properties of the proposed optimization method for the centroidal dynamics and verify in simulation that motions generated by our approach can be tracked by the quadruped Solo12. In addition, we compare our method to a recently proposed convexification using a sequence of convex relaxations as well as a more standard interior point method used in the off-the-shelf solver IPOPT to show that our approach finds similar, if not better, trajectories (in terms of cost), and is more than four times faster than both approaches. Finally, compared to previous approaches, we note its practicality due to the convex nature of each subproblem which allows our method to be used with any off-the-shelf quadratic programming solver.",
        "primary_area": "",
        "author": "Paarth Shah;Avadesh Meduri;Wolfgang Merkt;Majid Khadiv;Ioannis Havoutis;Ludovic Righetti;Paarth Shah;Avadesh Meduri;Wolfgang Merkt;Majid Khadiv;Ioannis Havoutis;Ludovic Righetti",
        "authorids": "/37089197319;/37088355351;/37086118415;/38667118200;/37542879900;/37295828600;/37089197319;/37088355351;/37086118415;/38667118200;/37542879900;/37295828600",
        "aff": "Oxford Robotics Institute, University of Oxford, England; Tandon School of Engineering, New York University, Brooklyn, USA; Oxford Robotics Institute, University of Oxford, England; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Oxford Robotics Institute, University of Oxford, England; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635856/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4200319301361228785&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;2",
        "aff_unique_norm": "University of Oxford;New York University;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Oxford Robotics Institute;Tandon School of Engineering;",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.nyu.edu;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "Oxford;NYU;MPI-IS",
        "aff_campus_unique_index": "0;1;0;2;0;2",
        "aff_campus_unique": "Oxford;Brooklyn;T\u00fcbingen",
        "aff_country_unique_index": "0;1;0;2;0;2",
        "aff_country_unique": "United Kingdom;United States;Germany"
    },
    {
        "id": "9636141",
        "title": "Rapid Recovery from Robot Failures in Multi-Robot Visibility-Based Pursuit-Evasion",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the visibility-based pursuit-evasion problem where a team of pursuer robots operating in a two-dimensional polygonal space seek to establish visibility of an arbitrarily fast evader. This is a computationally challenging task for which the best known complete algorithm takes time doubly exponential in the number of robots. However, recent advances that utilize sampling-based methods have shown progress in generating feasible solutions. An aspect of this problem that has yet to be explored concerns how to ensure that the robots can recover from catastrophic failures which leave one or more robots unexpectedly incapable of continuing to contribute to the pursuit of the evader. To address this issue, we propose an algorithm that can rapidly recover from catastrophic failures. When such failures occur, a replanning occurs, leveraging both the information retained from the previous iteration and the partial progress of the search completed before the failure to generate a new motion strategy for the reduced team of pursuers. We describe an implementation of this algorithm and provide quantitative results that show that the proposed method is able to recover from robot failures more rapidly than a baseline approach that plans from scratch.",
        "primary_area": "",
        "author": "Trevor Olsen;Nicholas M. Stiffler;Jason M. O\u2019Kane;Trevor Olsen;Nicholas M. Stiffler;Jason M. O\u2019Kane",
        "authorids": "/37089000508;/37947254000;/37279835400;/37089000508;/37947254000;/37279835400",
        "aff": "Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science, University of Dayton, Dayton, OH, USA; Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636141/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8658482317678856207&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of South Carolina;University of Dayton",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.sc.edu;https://www.udayton.edu",
        "aff_unique_abbr": "USC;UD",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Columbia;Dayton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636474",
        "title": "Rapid Stability Margin Estimation for Contact-Rich Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "The efficient evaluation the dynamic stability of legged robots on non-coplanar terrains is important when developing motion planning and control policies. The inference time of this measure has a strong influence on how fast a robot can react to unexpected events, plan its future footsteps or its body trajectory. Existing approaches suitable for real-time decision making are either limited to flat ground or to quasi-static locomotion. Furthermore, joint-space feasibility constraints are usually not considered in receding-horizon planning as their high dimensionality prohibits this. In this paper we propose the usage of a stability criterion for dynamic locomotion on rough terrain based on the Feasible Region (FR) and the Instantaneous Capture Point (ICP) and we leverage a Neural Network (NN) to quickly estimate it. We show that our network achieves satisfactory accuracy with respect to its analytical counterpart with a speed up of three orders-of-magnitude. It also enables the evaluation of the stability margin's gradient. We demonstrate this learned stability margin in two diverse applications - Reinforcement Learning (RL) and nonlinear Trajectory Optimization (TO) for legged robots. We demonstrate on a full-sized quadruped robot that the network enables the computation of physically-realizable Center of Mass (CoM) trajectories and foothold locations satisfying friction constraints and joint-torque limits in a receding-horizon fashion and on non-coplanar terrains.",
        "primary_area": "",
        "author": "Romeo Orsolino;Siddhant Gangapurwala;Oliwier Melon;Mathieu Geisert;Ioannis Havoutis;Maurice Fallon;Romeo Orsolino;Siddhant Gangapurwala;Oliwier Melon;Mathieu Geisert;Ioannis Havoutis;Maurice Fallon",
        "authorids": "/37086265101;/37088356748;/37088506627;/37085514664;/37542879900;/37540365100;/37086265101;/37088356748;/37088506627;/37085514664;/37542879900;/37540365100",
        "aff": "Dynamic Robots Systems (DRS) Group, Oxford Robotics Institute, University of Oxford, UK; Dynamic Robots Systems (DRS) Group, Oxford Robotics Institute, University of Oxford, UK; Dynamic Robots Systems (DRS) Group, Oxford Robotics Institute, University of Oxford, UK; Dynamic Robots Systems (DRS) Group, Oxford Robotics Institute, University of Oxford, UK; Dynamic Robots Systems (DRS) Group, Oxford Robotics Institute, University of Oxford, UK; Dynamic Robots Systems (DRS) Group, Oxford Robotics Institute, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636474/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10938793212303233939&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636510",
        "title": "Re-Attention Is All You Need: Memory-Efficient Scene Text Detection via Re-Attention on Uncertain Regions",
        "track": "main",
        "status": "Poster",
        "abstract": "Scene text detection plays an important role on vision-based robot navigation to many potential landmarks such as nameplates, information signs, floor button in the elevators. Recently, scene text detection with segmentation-based methods has been receiving more and more attention. The segmentation results can be used to efficiently predict scene text of various shapes, such as irregular text in most scene text images. However, two kinds of texts remain unsolved: 1) tiny and 2) blurry instances. Moreover, the annotations for tiny/blurry texts are usually ignored during training, while tiny/blurry texts can still offer visual auxiliaries for robots to understand the world. Therefore, in this paper, we propose a new approach to effectively detect both clear and blurry texts. Specifically, we propose a re-attention module without increasing the learnable parameters, which first predicts the region of texts as the candidate region and leverages the same network to detect the candidate region again for reducing the required memory. Moreover, to avoid the errors from the first detection propagating to the re-attended area, we propose a new fusion module that learns to integrate the results of the re-attended regions and the first prediction. Experimental results manifest that the proposed method outperforms state-of-the-art methods on four challenging datasets.",
        "primary_area": "",
        "author": "Hsiang-Chun Chang;Hung-Jen Chen;Yu-Chia Shen;Hong-Han Shuai;Wen-Huang Cheng;Hsiang-Chun Chang;Hung-Jen Chen;Yu-Chia Shen;Hong-Han Shuai;Wen-Huang Cheng",
        "authorids": "/37089195705;/37089504946;/37089195519;/37085448081;/37964446100;/37089195705;/37089504946;/37089195519;/37085448081;/37964446100",
        "aff": "Department of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Taiwan; Department of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Taiwan; Institute of Electronics, National Yang Ming Chiao Tung Univresity, Hsinchu, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636510/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3753519101763060576&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "National Yang Ming Chiao Tung University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.nctu.edu.tw",
        "aff_unique_abbr": "NYCU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636809",
        "title": "Reactive Control for Bipedal Running Over Random Discrete Terrain Under Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a reactive control framework for robotic bipedal running over random discrete terrain using a shift-invariant funnel library that can be composed into motion plans. The main contribution of the paper is the formalization of the funnel library and the introduction of a receding-horizon reactive planner that utilizes this funnel library. The proposed controller generates a robust motion plan on the fly, without the need for predefined footholds or center of mass trajectory, via sequential-composition of pre-computed funnels. The proposed method utilizes three layers of robustness: high-level reactive planning, low-level robust control, and funnel-based, pre-computed, performance guarantees. For clarity, we provide a detailed example, using the 5 degrees-of-freedom sagittal biped model. We demonstrate in simulation the ability of the framework to overcome uncertainty in sensing and model parameters.",
        "primary_area": "",
        "author": "Omer Nir;Amir Degani;Omer Nir;Amir Degani",
        "authorids": "/37086310094;/37542443600;/37086310094;/37542443600",
        "aff": "Technion Autonomous Systems Program, Technion \u2013 Israel Institute of Technology, Haifa, ISRAEL; Faculty of Civil and Environmental Engineering and With the Technion Autonomous Systems Program, Technion \u2013 Israel Institute of Technology, Haifa, ISRAEL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636809/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1402377614760517121&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technion \u2013 Israel Institute of Technology",
        "aff_unique_dep": "Technion Autonomous Systems Program",
        "aff_unique_url": "https://www.technion.ac.il",
        "aff_unique_abbr": "Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Haifa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "9636037",
        "title": "Reactive Long Horizon Task Execution via Visual Skill and Precondition Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Zero-shot execution of unseen robotic tasks is important to allowing robots to perform a wide variety of tasks in human environments, but collecting the amounts of data necessary to train end-to-end policies in the real-world is often infeasible. We describe an approach for sim-to-real training that can accomplish unseen robotic tasks using models learned in simulation to ground components of a simple task planner. We learn a library of parameterized skills, along with a set of predicates-based preconditions and termination conditions, entirely in simulation. We explore a block-stacking task because it has a clear structure, where multiple skills must be chained together, but our methods are applicable to a wide range of other problems and domains, and can transfer from simulation to the real-world with no fine tuning. The system is able to recognize failures and accomplish long-horizon tasks from perceptual input, which is critical for real-world execution. We evaluate our proposed approach in both simulation and in the real-world, showing an increase in success rate from 91.6% to 98% in simulation and from 10% to 80% success rate in the real-world as compared with naive baselines. For experiment videos including both real-world and simulation, see: https://www.youtube.com/playlist?list=PL-oD0xHUngeLfQmpngYkGFZarstfPOXqX",
        "primary_area": "",
        "author": "Shohin Mukherjee;Chris Paxton;Arsalan Mousavian;Adam Fishman;Maxim Likhachev;Dieter Fox;Shohin Mukherjee;Chris Paxton;Arsalan Mousavian;Adam Fishman;Maxim Likhachev;Dieter Fox",
        "authorids": "/37089197730;/37085403975;/37085404794;/37088690696;/37309318800;/37284329000;/37089197730;/37085403975;/37085404794;/37088690696;/37309318800;/37284329000",
        "aff": "Carnegie Mellon University, USA; NVIDIA, USA; NVIDIA, USA; University of Washington, USA; Carnegie Mellon University, USA; University of Washington, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636037/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1888306049585790182&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;0;2",
        "aff_unique_norm": "Carnegie Mellon University;NVIDIA;University of Washington",
        "aff_unique_dep": ";NVIDIA;",
        "aff_unique_url": "https://www.cmu.edu;https://www.nvidia.com;https://www.washington.edu",
        "aff_unique_abbr": "CMU;NV;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636214",
        "title": "Reactive Visual Odometry Scheduling Based on Noise Analysis using an Adaptive Extended Kalman Filter",
        "track": "main",
        "status": "Poster",
        "abstract": "A new strategy is proposed for scheduling Visual Odometry (VO) measurements for wheeled ground vehicles. Rather than having a fixed interval or distance between image acquisitions, we propose to trigger VO based on covariances from an Adaptive Extended Kalman Filter. The adopted model uses process noise to drive wheel slip estimation, which, when correctly identified, can be used with Wheel Odometry to provide frequent position estimates. When more dynamic terrain is detected, more VO measurements are scheduled to maintain localization accuracy. On the other hand, when the terrain is stable, VO usage is limited. The system is validated in a simple one-dimensional case using data captured during field trials using a representative rover. The results are promising as trajectories that were subjected to large errors are corrected.",
        "primary_area": "",
        "author": "Mateusz Tomasz Malinowski;Arthur Richards;Mark Woods;Mateusz Tomasz Malinowski;Arthur Richards;Mark Woods",
        "authorids": "/37089196994;/37299756300;/37089194947;/37089196994;/37299756300;/37089194947",
        "aff": "Autonomy and Robotics Group, CGI IT UK Ltd., Bristol, UK; Department of Aerospace Engineering, University of Bristol, Bristol, UK; Autonomy and Robotics Group, CGI IT UK Ltd., Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636214/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1033335762063903649&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "CGI IT UK Ltd.;University of Bristol",
        "aff_unique_dep": "Autonomy and Robotics Group;Department of Aerospace Engineering",
        "aff_unique_url": "https://www.cgi.com;https://www.bristol.ac.uk",
        "aff_unique_abbr": "CGI;UoB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bristol",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636568",
        "title": "Reactive and Safe Road User Simulations using Neural Barrier Certificates",
        "track": "main",
        "status": "Poster",
        "abstract": "Reactive and safe agent modellings are important for nowadays traffic simulator designs and safe planning applications. In this work, we proposed a reactive agent model which can ensure safety without comprising the original purposes, by learning only high-level decisions from expert data and a low level decentralized controller guided by the jointly learned decentralized barrier certificates. Empirical results show that our learned road user simulation models can achieve a significant improvement in safety comparing to state-of-the-art imitation learning and pure control-based methods, while being similar to human agents by having smaller error to the expert data. Moreover, our learned reactive agents are shown to generalize better to unseen traffic conditions, and react better to other road users and therefore can help understand challenging planning problems pragmatically.",
        "primary_area": "",
        "author": "Yue Meng;Zengyi Qin;Chuchu Fan;Yue Meng;Zengyi Qin;Chuchu Fan",
        "authorids": "/37089197843;/37089197144;/38564621900;/37089197843;/37089197144;/38564621900",
        "aff": "Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636568/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6032706597834193389&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636410",
        "title": "Real-Time Hamilton-Jacobi Reachability Analysis of Autonomous System With An FPGA",
        "track": "main",
        "status": "Poster",
        "abstract": "Hamilton-Jacobi (HJ) reachability analysis is a powerful technique used to verify the safety of autonomous systems. HJ reachability is ideal for analysing nonlinear systems with disturbances and flexible set representations. A drawback to this approach is that it suffers from the curse of dimensionality, which prevents real-time deployment on safety-critical systems. In this paper, we show that a customized hardware design on an Field Programmable Gate Array (FPGA) could accelerate 4D grid-based HJ reachability analysis up to 14 times compared to an optimized implementation and 103 times compared to state-of-the-art MATLAB toolboxes on a 16-thread CPU. Because of this, we are able to achieve guaranteed real- time collision avoidance in dynamic environments that abruptly change with a 4D car model by re-solving the HJ partial differential equation (PDE) at a frequency of 4Hz on an FPGA. Our design can overcome the complex data access pattern while taking advantage of the parallel nature of the computations for solving the HJ PDE. The low latency of our computation is consistent, which is crucial for safety-critical systems. The methodology presented here is without loss of generality: it can potentially be applied to different systems dynamics, and more- over, leveraged for higher dimensional systems. We validate our approach in real world collision avoidance experiments with a robot car in a changing environment. We also provide the code of our hardware design and an AWS AFI image.",
        "primary_area": "",
        "author": "Minh Bui;Michael Lu;Reza Hojabr;Mo Chen;Arrvindh Shriraman;Minh Bui;Michael Lu;Reza Hojabr;Mo Chen;Arrvindh Shriraman",
        "authorids": "/37085789398;/37089196998;/37086196482;/37085494765;/37424625400;/37085789398;/37089196998;/37086196482;/37085494765;/37424625400",
        "aff": "School of Computing Science, Simon Fraser University; School of Computing Science, Simon Fraser University; School of Computing Science, Simon Fraser University; School of Computing Science, Simon Fraser University; School of Computing Science, Simon Fraser University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636410/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12671165946296101965&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Simon Fraser University",
        "aff_unique_dep": "School of Computing Science",
        "aff_unique_url": "https://www.sfu.ca",
        "aff_unique_abbr": "SFU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Burnaby",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636518",
        "title": "Real-Time Monocular Human Depth Estimation and Segmentation on Embedded Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating a scene\u2019s depth to achieve collision avoidance against moving pedestrians is a crucial and fundamental problem in the robotic field. This paper proposes a novel, low complexity network architecture for fast and accurate human depth estimation and segmentation in indoor environments, aiming to applications for resource-constrained platforms (including battery-powered aerial, micro-aerial, and ground vehicles) with a monocular camera being the primary perception module. Following the encoder-decoder structure, the proposed framework consists of two branches, one for depth prediction and another for semantic segmentation. Moreover, network structure optimization is employed to improve its forward inference speed. Exhaustive experiments on three self-generated datasets prove our pipeline\u2019s capability to execute in real-time, achieving higher frame rates than contemporary state-of-the-art frameworks (114.6 frames per second on an NVIDIA Jetson Nano GPU with TensorRT) while maintaining comparable accuracy.",
        "primary_area": "",
        "author": "Shan An;Fangru Zhou;Mei Yang;Haogang Zhu;Changhong Fu;Konstantinos A. Tsintotas;Shan An;Fangru Zhou;Mei Yang;Haogang Zhu;Changhong Fu;Konstantinos A. Tsintotas",
        "authorids": "/37086923915;/37089184724;/37089198171;/37086553313;/37086797986;/37086455006;/37086923915;/37089184724;/37089198171;/37086553313;/37086797986;/37086455006",
        "aff": "School of Computer Science and Engineering, Beihang University, Beijing, China; Tech & Data Center, JD.COM Inc, Beijing, China; Tech & Data Center, JD.COM Inc, Beijing, China; School of Computer Science and Engineering, Beihang University, Beijing, China; School of Mechanical Engineering, Tongji University, Shanghai, China; Department of Production and Management Engineering, Democritus University of Thrace, Xanthi, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636518/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11546223054062458310&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;2;3",
        "aff_unique_norm": "Beihang University;JD.COM Inc;Tongji University;Democritus University of Thrace",
        "aff_unique_dep": "School of Computer Science and Engineering;Tech & Data Center;School of Mechanical Engineering;Department of Production and Management Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn;https://www.jd.com;https://www.tongji.edu.cn;https://www.duth.gr",
        "aff_unique_abbr": "BUAA;JD;Tongji;",
        "aff_campus_unique_index": "0;0;0;0;1;2",
        "aff_campus_unique": "Beijing;Shanghai;Xanthi",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;Greece"
    },
    {
        "id": "9635965",
        "title": "Real-Time Motion Planning of a Hydraulic Excavator using Trajectory Optimization and Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Automation of excavation tasks requires real-time trajectory planning satisfying various constraints. To guarantee both constraint feasibility and real-time trajectory re-plannability, we present an integrated framework for real-time optimization-based trajectory planning of a hydraulic excavator. The proposed framework is composed of two main modules: a global planner and a real-time local planner. The global planner computes the entire global trajectory considering excavation volume and energy minimization while the local counterpart tracks the global trajectory in a receding horizon manner, satisfying dynamic feasibility, physical constraints, and disturbance-awareness. We validate the proposed planning algorithm in a simulation environment where two types of operations are conducted in the presence of emulated disturbance from hydraulic friction and soil-bucket interaction: shallow and deep excavation. The optimized global trajectories are obtained in an order of a second, which is tracked by the local planner at faster than 30 Hz. To the best of our knowledge, this work presents the first real-time motion planning framework that satisfies constraints of a hydraulic excavator, such as force/torque, power, cylinder displacement, and flow rate limits.",
        "primary_area": "",
        "author": "Dongjae Lee;Inkyu Jang;Jeonghyun Byun;Hoseong Seo;H. Jin Kim;Dongjae Lee;Inkyu Jang;Jeonghyun Byun;Hoseong Seo;H. Jin Kim",
        "authorids": "/37086933985;/37087499137;/37089194964;/37085446499;/37599626400;/37086933985;/37087499137;/37089194964;/37085446499;/37599626400",
        "aff": "Department of Aerospace Engineering, Automation and Systems Research Institute (ASRI), Seoul National University (SNU), Seoul, South Korea; Department of Aerospace Engineering, Automation and Systems Research Institute (ASRI), Seoul National University (SNU), Seoul, South Korea; Department of Aerospace Engineering, Automation and Systems Research Institute (ASRI), Seoul National University (SNU), Seoul, South Korea; Department of Aerospace Engineering, Automation and Systems Research Institute (ASRI), Seoul National University (SNU), Seoul, South Korea; Department of Aerospace Engineering, Automation and Systems Research Institute (ASRI), Seoul National University (SNU), Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635965/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11778510879072437824&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636246",
        "title": "Real-Time Physically-Accurate Simulation of Robotic Snap Connection Process",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel real-time physically-accurate simulation framework for the snap connection process. For this, we first notice the peculiarities of the process, namely, small/smooth deformation, stiff connector and segmented contact. We then design our simulation to fully exploit these peculiarities by adopting the following strategies: 1) the technique of passive midpoint integration (PMI [1]), which allows for stable simulation of arbitrarily light/stiff system by enforcing discrete-time passivity; 2) linear finite element method (FEM [2]) modeling, which is adequate to deal with the small snap connector deformation while providing much faster speed as compared to nonlinear FEM; 3) segmentation of the snap connector FEM model and solving of each segment individually with their coupling analytically eliminated, thereby, further speeding up the simulation; 4) balanced model reduction (BMR [3]) to further reduce the dimension of each segment purely analytically without any prior experiment or simulation; and 5) parallelized data-driven collision detection, which turns out to further significantly speed up our simulation. Experimentally-verified simulations are also performed to show the efficacy of our proposed simulation framework.",
        "primary_area": "",
        "author": "Minji Lee;Jeongmin Lee;Jaemin Yoon;Dongjun Lee;Minji Lee;Jeongmin Lee;Jaemin Yoon;Dongjun Lee",
        "authorids": "/37086549787;/37088998350;/37085562778;/37077171500;/37086549787;/37088998350;/37085562778;/37077171500",
        "aff": "Department of Mechanical Engineering, IAMD and IER, Seoul National University, Seoul, Republic of Korea; Department of Mechanical Engineering, IAMD and IER, Seoul National University, Seoul, Republic of Korea; Department of Mechanical Engineering, IAMD and IER, Seoul National University, Seoul, Republic of Korea; Department of Mechanical Engineering, IAMD and IER, Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636246/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=36048092254499713&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636794",
        "title": "Real-Time Safety and Control of Robotic Manipulators with Torque Saturation in Operational Space",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a real-time safety and control for robot manipulators using control barrier functions and control Lyapunov functions in operational space. We first define the operational space in terms of system dynamics, jacobian, and torques and then ensure safety by designing Control Barrier Functions (CBF) around the body links of the robotic manipulator. The control barrier function provides provable collision-free behavior for the robotic manipulator by modifying the nominal control in a minimally invasive manner to formally satisfy the safety constraints. CBFs are formulated as a quadratic programming problem, which can be solved in real-time. We also design a controller based on Rapidly Exponentially Stabilizing Control Lyapunov Function (RESCLF) and quadratic programming to meet multiple objectives while ensuring exponential convergence. We then extend our formulation to solve RESCLF and CBF in a unified formulation to design the controller while ensuring the safety of manipulators and guaranteeing the torque saturation. The efficacy of the proposed approach is shown on 7 Degree of Freedom (DoF) KUKA LBR iiwa robot using Dynamic Animation and Robotics Toolkit (DART) physics engine.",
        "primary_area": "",
        "author": "Muhammad Ali Murtaza;Sergio Aguilera;Vahid Azimi;Seth Hutchinson;Muhammad Ali Murtaza;Sergio Aguilera;Vahid Azimi;Seth Hutchinson",
        "authorids": "/37088316016;/37085576930;/38507757500;/37282386200;/37088316016;/37085576930;/38507757500;/37282386200",
        "aff": "Institute of Robotics and Intelligent Machines, The Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines, The Georgia Institute of Technology, Atlanta, GA, USA; Department of Energy Resources Engineering, Stanford University, CA; Institute of Robotics and Intelligent Machines, The Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636794/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17722783162380616340&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Stanford University",
        "aff_unique_dep": "Institute of Robotics and Intelligent Machines;Department of Energy Resources Engineering",
        "aff_unique_url": "https://www.gatech.edu;https://www.stanford.edu",
        "aff_unique_abbr": "Georgia Tech;Stanford",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Atlanta;California",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635986",
        "title": "Real-Time Volumetric-Semantic Exploration and Mapping: An Uncertainty-Aware Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we propose a holistic framework for autonomous aerial inspection tasks, using semantically-aware, yet, computationally efficient planning and mapping algorithms. The system leverages state-of-the-art receding horizon exploration techniques for next-best-view (NBV) planning with geometric and semantic segmentation information provided by state-of-the-art deep convolutional neural networks (DCNNs), with the goal of enriching environment representations. The contributions of this article are threefold, first we propose an efficient sensor observation model, and a reward function that encodes the expected information gains from the observations taken from specific view points. Second, we extend the reward function to incorporate not only geometric but also semantic probabilistic information, provided by a DCNN for semantic segmentation that operates in real-time. The incorporation of semantic information in the environment representation allows biasing exploration towards specific objects, while ignoring task-irrelevant ones during planning. Finally, we employ our approaches in an autonomous drone shipyard inspection task. A set of simulations in realistic scenarios demonstrate the efficacy and efficiency of the proposed framework when compared with the state-of-the-art.",
        "primary_area": "",
        "author": "Rui Pimentel de Figueiredo;Jonas le Fevre Sejersen;Jakob Grimm Hansen;Martim Brand\u00e3o;Erdal Kayacan;Rui Pimentel de Figueiredo;Jonas le Fevre Sejersen;Jakob Grimm Hansen;Martim Brand\u00e3o;Erdal Kayacan",
        "authorids": "/37077493200;/37088995681;/37089196524;/38542529000;/37595300900;/37077493200;/37088995681;/37089196524;/38542529000;/37595300900",
        "aff": "the Department of Electrical and Computer Engineering, Artificial Intelligence in Robotics Laboratory (AiR Lab), Aarhus University, Aarhus C, Denmark; the Department of Electrical and Computer Engineering, Artificial Intelligence in Robotics Laboratory (AiR Lab), Aarhus University, Aarhus C, Denmark; the Department of Electrical and Computer Engineering, Artificial Intelligence in Robotics Laboratory (AiR Lab), Aarhus University, Aarhus C, Denmark; King\u2019s College London (KCL), London, UK; the Department of Electrical and Computer Engineering, Artificial Intelligence in Robotics Laboratory (AiR Lab), Aarhus University, Aarhus C, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635986/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11295375387136866684&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Aarhus University;King's College London",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.au.dk;https://www.kcl.ac.uk",
        "aff_unique_abbr": "AU;KCL",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Aarhus;London",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Denmark;United Kingdom"
    },
    {
        "id": "9636647",
        "title": "Real-time 3D Navigation-based Semi-Automatic Surgical Robotic System for Pelvic Fracture Reduction",
        "track": "main",
        "status": "Poster",
        "abstract": "Pelvic fracture is a serious high-energy injury with highest disability and mortality rate among all fractures. At present, the reduction of pelvic fracture is still completely dependent on surgeons' experience, which may lead to poor effect of pelvic reduction, thus seriously affecting surgical treatment and postoperative rehabilitation of patients. Based on this, a new robotic system for pelvic fracture reduction was developed and tested. Withdrawing on the optical tracking system, the real-time 3D navigation of pelvic position during operation was realized through Nonrigid ICP method. The target position for fracture reduction was obtained through pelvic symmetry reduction method based on structural symmetry of the pelvis. The shortest reduction path was planned automatically, which could be adjusted by surgeons manually. Finally, the pelvic fracture reduction operation was completed through the robot. System accuracy and effectiveness were demonstrated through laboratory trials and preliminary cadaveric trials. The system resulted in high fracture reduction reliability with the registration accuracy of 1.3749 \u00b1 0.6311mm, and the robot reduction accuracy of 2.8925 \u00b1 0.8647mm. Preliminary cadaveric trials also provided a positive and favorable outcome pointing to the usability of the system in the operating theatre, potentially enhancing the capacity of pelvic fracture surgeries.",
        "primary_area": "",
        "author": "Chao Shi;Xiangrui Zhao;Xinbao Wu;Chunpeng Zhao;Gang Zhu;Shuchang Shi;Yu Wang;Chao Shi;Xiangrui Zhao;Xinbao Wu;Chunpeng Zhao;Gang Zhu;Shuchang Shi;Yu Wang",
        "authorids": "/37088476548;/37089197315;/37089180485;/37089178601;/37088478566;/37089197117;/37086105784;/37088476548;/37089197315;/37089180485;/37089178601;/37088478566;/37089197117;/37086105784",
        "aff": "School of Biological Science and Medical Engineering, Beihang University, Beijing, China; Beijing RossumRobot Technology Co., Ltd., Beijing, China; Department of Orthopedics, Beijing Jishuitan Hospital, The Fourth Medical College, Peking University, Beijing, China; Department of Orthopedics, Beijing Jishuitan Hospital, The Fourth Medical College, Peking University, Beijing, China; Beijing RossumRobot Technology Co., Ltd., Beijing, China; Beijing RossumRobot Technology Co., Ltd., Beijing, China; School of Biological Science and Medical Engineering, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636647/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2285657655185185134&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;2;1;1;0",
        "aff_unique_norm": "Beihang University;RossumRobot Technology;Peking University",
        "aff_unique_dep": "School of Biological Science and Medical Engineering;;Department of Orthopedics",
        "aff_unique_url": "http://www.buaa.edu.cn;;http://www.pku.edu.cn",
        "aff_unique_abbr": "Beihang;;PKU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636705",
        "title": "Real-time Geo-localization Using Satellite Imagery and Topography for Unmanned Aerial Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "The capabilities of autonomous flight with unmanned aerial vehicles (UAVs) have significantly increased in recent times. However, basic problems such as fast and robust geo-localization in GPS-denied environments still remain unsolved. Existing research has primarily concentrated on improving the accuracy of localization at the cost of long and varying computation time in various situations, which often necessitates the use of powerful ground station machines. In order to make image-based geo-localization online and pragmatic for lightweight embedded systems on UAVs, we propose a framework that is reliable in changing scenes, flexible about computing resource allocation and adaptable to common camera placements. The framework is comprised of two stages: offline database preparation and online inference. At the first stage, color images and depth maps are rendered as seen from potential vehicle poses quantized over the satellite and topography maps of anticipated flying areas. A database is then populated with the global and local descriptors of the rendered images. At the second stage, for each captured real-world query image, top global matches are retrieved from the database and the vehicle pose is further refined via local descriptor matching. We present field experiments of image-based localization on two different UAV platforms to validate our results.",
        "primary_area": "",
        "author": "Shuxiao Chen;Xiangyu Wu;Mark W. Mueller;Koushil Sreenath;Shuxiao Chen;Xiangyu Wu;Mark W. Mueller;Koushil Sreenath",
        "authorids": "/37088660463;/37086448421;/37086448968;/37563179200;/37088660463;/37086448421;/37086448968;/37563179200",
        "aff": "Shuxiao Chen; Xiangyu Wu; Mark W. Mueller; Koushil Sreenath",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636705/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17539673043087603223&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9636763",
        "title": "Real-time Multi-Adaptive-Resolution-Surfel 6D LiDAR Odometry using Continuous-time Trajectory Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous Localization and Mapping (SLAM) is an essential capability for autonomous robots, but due to high data rates of 3D LiDARs real-time SLAM is challenging. We propose a real-time method for 6D LiDAR odometry. Our approach combines a continuous-time B-Spline trajectory representation with a Gaussian Mixture Model (GMM) formulation to jointly align local multi-resolution surfel maps. Sparse voxel grids and permutohedral lattices ensure fast access to map surfels, and an adaptive resolution selection scheme effectively speeds up registration. A thorough experimental evaluation shows the performance of our approach on multiple datasets and during real-robot experiments.",
        "primary_area": "",
        "author": "Jan Quenzel;Sven Behnke;Jan Quenzel;Sven Behnke",
        "authorids": "/37085907349;/37295987100;/37085907349;/37295987100",
        "aff": "Autonomous Intelligent Systems, Institute for Computer Science VI, University of Bonn, Bonn, Germany; Autonomous Intelligent Systems, Institute for Computer Science VI, University of Bonn, Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636763/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=634848409505021532&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Institute for Computer Science VI",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bonn",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9635897",
        "title": "Recalling Direct 2D-3D Matches for Large-Scale Visual Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating the 6-DoF camera pose of an image with respect to a 3D scene model, known as visual localization, is a fundamental problem in many computer vision and robotics tasks. Among various visual localization methods, the direct 2D-3D matching method has become the preferred method for many practical applications due to its computational efficiency. When using direct 2D-3D matching methods in large-scale scenes, a vocabulary tree can be used to accelerate the matching process, which will also induce the quantization artifacts leading to reduce the inlier ratio and decrease the localization accuracy. To this end, in this paper two simple and effective mechanisms, called visibility-based recalling and space-based recalling, are proposed to recover lost matches caused by the quantization artifacts, thus can largely improve the localization accuracy and success rate without increasing too much computational time. Experimental results on long-term visual localization benchmarks demonstrate the effectiveness of our method compared with state-of-the-arts.",
        "primary_area": "",
        "author": "Zhuo Song;Chuting Wang;Yuqian Liu;Shuhan Shen;Zhuo Song;Chuting Wang;Yuqian Liu;Shuhan Shen",
        "authorids": "/37089197732;/37089197200;/37088998282;/37397055200;/37089197732;/37089197200;/37088998282;/37397055200",
        "aff": "CASIA-SenseTime Research Group; School of Information and Electronics, Beijing Institute of Technology, Beijing, China; SenseTime Research, Hangzhou, China; CASIA-SenseTime Research Group",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635897/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16373226285883319863&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Chinese Academy of Sciences;Beijing Institute of Technology;SenseTime Research",
        "aff_unique_dep": "CASIA-SenseTime Research Group;School of Information and Electronics;",
        "aff_unique_url": "http://www.casia.ac.cn;http://www.bit.edu.cn;https://www.sensetime.com",
        "aff_unique_abbr": "CASIA;BIT;SenseTime",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Beijing;Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636534",
        "title": "Reconfiguring Metamorphic Robots via SMT: Is It a Viable Way?",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new approach to tackle the problem of lattice-type metamorphic robots reconfiguration. We base our approach on a reduction to satisfiability modulo theory (SMT). Unlike the current state-of-the-art solutions, we consider the spatial limitations of the modules themselves and produce collision-free plans. We give an in-depth description of the reduction and discuss several optimizations for our technique. We also show an experimental evaluation of our approach and list possible future improvements to our technique.",
        "primary_area": "",
        "author": "Jan Mr\u00e1zek;Martin Jon\u00e1\u0161;Ji\u0159\u00ed Barnat;Jan Mr\u00e1zek;Martin Jon\u00e1\u0161;Ji\u0159\u00ed Barnat",
        "authorids": "/37085536357;/37089195966;/37063396900;/37085536357;/37089195966;/37063396900",
        "aff": "Faculty of Informatics, Masaryk University, Brno, Czech Republic; Collaborated on the Research While he had Been PhD Student at Faculty of Informatics, Masaryk University; Faculty of Informatics, Masaryk University, Brno, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636534/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8145774281662697543&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Masaryk University",
        "aff_unique_dep": "Faculty of Informatics",
        "aff_unique_url": "https://www.muni.cz",
        "aff_unique_abbr": "MU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Brno;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "9636160",
        "title": "Reduced State Value Iteration for Multi-Drone Persistent Surveillance with Charging Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents Reduced State Value Iteration (RSVI), an algorithm to compute policies for Markov Decision Processes (MDPs) that have natural checkpoints, allowing for a solution based on a reduced state space. The algorithm is applied to find policies for multiple drones to persistently surveil an environment subject to charging constraints. RSVI leverages the structure of the true MDP to build an MDP with a smaller state-action space. Monte Carlo simulations are used to estimate transitions between the states in the reduced MDP, which are used in value iteration to compute a policy for the reduced MDP. States in the true MDP are mapped to reduced states. Actions in the reduced space from the policy are then mapped to actions in the full space for execution on the true MDP. Performance of the RSVI policy improves as the state discretization becomes finer, but with increasing computational requirements, thus giving a natural trade-off between computational resources and policy suboptimality. Results of simulated persistent surveillance experiments show that our RSVI policy outperforms a baseline heuristic.",
        "primary_area": "",
        "author": "Patrick H. Washington;Mac Schwager;Patrick H. Washington;Mac Schwager",
        "authorids": "/37089196742;/37424620600;/37089196742;/37424620600",
        "aff": "Department of Aeronautics & Astronautics, Stanford University; Department of Aeronautics & Astronautics, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636160/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3250020586944156720&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Aeronautics & Astronautics",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636815",
        "title": "Refuel Scheduling for Multirobot Charging-on-Demand",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider the refuel scheduling problem for a team of ground robots deployed in \"aislelike\" environments wherein the robots are constrained to move along rows. In order to maintain a minimum service rate or throughput for the ground robots, we investigate the problem of scheduling a team of mobile charging stations deployed to replace the batteries on-board the ground robots without any interruption in their task. We propose two scheduling schemes for the mobile chargers to serve the ground robots for long-term service, and derive the parameters associated with the system required for persistent uninterrupted operation.",
        "primary_area": "",
        "author": "Tianshuang Gao;Yan Tian;Sourabh Bhattacharya;Tianshuang Gao;Yan Tian;Sourabh Bhattacharya",
        "authorids": "/37086016876;/37085433778;/37275362500;/37086016876;/37085433778;/37275362500",
        "aff": "Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Mechanical Engineering, Iowa State University, Ames, IA, USA; Department of Computer Science and Department of Mechanical Engineering, Iowa State University, Ames, IA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636815/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10136768145912867216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Iowa State University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.iastate.edu",
        "aff_unique_abbr": "ISU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ames",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635963",
        "title": "Reinforcement Learning Compensated Extended Kalman Filter for Attitude Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Inertial measurement units are widely used in different fields to estimate the attitude. Many algorithms have been proposed to improve estimation performance. However, most of them still suffer from 1) inaccurate initial estimation, 2) inaccurate initial filter gain, and 3) non-Gaussian process and/or measurement noise. This paper will leverage reinforcement learning to compensate for the classical extended Kalman filter estimation, i.e., to learn the filter gain from the sensor measurements. We also analyse the convergence of the estimate error. The effectiveness of the proposed algorithm is validated on both simulated data and real data.",
        "primary_area": "",
        "author": "Yujie Tang;Liang Hu;Qingrui Zhang;Wei Pan;Yujie Tang;Liang Hu;Qingrui Zhang;Wei Pan",
        "authorids": "/37088999709;/37086497663;/37085341265;/37088467306;/37088999709;/37086497663;/37085341265;/37088467306",
        "aff": "Department of Cognitive Robotics, Delft University of Technology, Netherlands; School of Computer Science and Electronic Engineering, University of Essex, UK; School of Aeronautics and Astronautics, Sun Yat-Sen University, China; Department of Cognitive Robotics, Delft University of Technology, Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635963/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6795931805201819277&as_sdt=5,33&sciodt=0,33&hl=en&oe=ASCII",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Delft University of Technology;University of Essex;Sun Yat-sen University",
        "aff_unique_dep": "Department of Cognitive Robotics;School of Computer Science and Electronic Engineering;School of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.tudelft.nl;https://www.essex.ac.uk;http://www.sysu.edu.cn",
        "aff_unique_abbr": "TU Delft;Essex;SYSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "Netherlands;United Kingdom;China"
    },
    {
        "id": "9636219",
        "title": "Reinforcement Learning Control of a Forestry Crane Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Forestry machines are heavy vehicles performing complex manipulation tasks in unstructured production forest environments. Together with the complex dynamics of the onboard hydraulically actuated cranes, the rough forest terrains have posed a particular challenge in forestry automation. In this study, the feasibility of applying reinforcement learning control to forestry crane manipulators is investigated in a simulated environment. Our results show that it is possible to learn successful actuator-space control policies for energy efficient log grasping by invoking a simple curriculum in a deep reinforcement learning setup. Given the pose of the selected logs, our best control policy reaches a grasping success rate of 97%. Including an energy-optimization goal in the reward function, the energy consumption is significantly reduced compared to control policies learned without incentive for energy optimization, while the increase in cycle time is marginal. The energy-optimization effects can be observed in the overall smoother motion and acceleration profiles during crane manipulation.",
        "primary_area": "",
        "author": "Jennifer Andersson;Kenneth Bodin;Daniel Lindmark;Martin Servin;Erik Wallin;Jennifer Andersson;Kenneth Bodin;Daniel Lindmark;Martin Servin;Erik Wallin",
        "authorids": "/37089195177;/37589433400;/37089196443;/37589441100;/37085416936;/37089195177;/37589433400;/37089196443;/37589441100;/37085416936",
        "aff": "Department of Physics, Ume\u00e5 University; Algoryx Simulation AB; Algoryx Simulation AB; Algoryx Simulation AB; Department of Physics, Ume\u00e5 University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636219/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14138956546695775527&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Ume\u00e5 University;Algoryx Simulation",
        "aff_unique_dep": "Department of Physics;",
        "aff_unique_url": "https://www.umu.se;https://www.algoryx.se",
        "aff_unique_abbr": "UMU;Algoryx",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9635935",
        "title": "Reinforcement Learning based Negotiation-aware Motion Planning of Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "For autonomous vehicles integrating onto road-ways with human traffic participants, it requires understanding and adapting to the participants\u2019 intention by responding in predictable ways. This paper proposes a reinforcement learning based negotiation-aware motion planning framework, which adopts RL to adjust the driving style of the planner by dynamically modifying the prediction horizon length of the motion planner in real time adaptively. The framework models the interaction between the autonomous vehicle and other traffic participants as a Markov Decision Process. A temporal sequence of occupancy grid maps are taken as inputs for RL module to embed an implicit intention reasoning. Curriculum learning is employed to enhance the training efficiency and the robustness of the algorithm. We applied our method to narrow lane navigation in both simulation and real world to demonstrate that the proposed method outperforms the common alternative due to its advantage in alleviating the social dilemma problem with proper negotiation skills.",
        "primary_area": "",
        "author": "Zhitao Wang;Yuzheng Zhuang;Qiang Gu;Dong Chen;Hongbo Zhang;Wulong Liu;Zhitao Wang;Yuzheng Zhuang;Qiang Gu;Dong Chen;Hongbo Zhang;Wulong Liu",
        "authorids": "/37086543704;/37089197880;/37086677458;/37088748688;/37859161500;/37088758367;/37086543704;/37089197880;/37086677458;/37088748688;/37859161500;/37088758367",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635935/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5925161535187152512&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12
    },
    {
        "id": "9636563",
        "title": "Reinforcement Learning for Vision-based Object Manipulation with Non-parametric Policy and Action Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "The object manipulation is a crucial ability for a service robot, but it is hard to solve with reinforcement learning due to some reasons such as sample efficiency. In this paper, to tackle this object manipulation, we propose a novel framework, AP-NPQL (Non-Parametric Q Learning with Action Primitives), that can efficiently solve the object manipulation with visual input and sparse reward, by utilizing a nonparametric policy for reinforcement learning and appropriate behavior prior for the object manipulation. We evaluate the efficiency and the performance of the proposed AP-NPQL for four object manipulation tasks on simulation (pushing plate, stacking box, flipping cup, and picking and placing plate), and it turns out that our AP-NPQL outperforms the state-of-the-art algorithms based on parametric policy and behavior prior in terms of learning time and task success rate. We also successfully transfer and validate the learned policy of the plate pick-and-place task to the real robot in a sim-to-real manner.",
        "primary_area": "",
        "author": "Dongwon Son;Myungsin Kim;Jaecheol Sim;Wonsik Shin;Dongwon Son;Myungsin Kim;Jaecheol Sim;Wonsik Shin",
        "authorids": "/37086455263;/37089196765;/37089198231;/37089195848;/37086455263;/37089196765;/37089198231;/37089195848",
        "aff": "Simulation Lab, Samsung Research, Samsung Electronics, Seoul, Republic of Korea; Simulation Lab, Samsung Research, Samsung Electronics, Seoul, Republic of Korea; Simulation Lab, Samsung Research, Samsung Electronics, Seoul, Republic of Korea; Simulation Lab, Samsung Research, Samsung Electronics, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636563/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4534161375468005218&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "Simulation Lab",
        "aff_unique_url": "https://www.samsung.com",
        "aff_unique_abbr": "Samsung",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636017",
        "title": "Relative Localization of Mobile Robots with Multiple Ultra-WideBand Ranging Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "Relative localization between autonomous robots without infrastructure is crucial to achieve their navigation, path planning, and formation in many applications, such as emergency response, where acquiring a prior knowledge of the environment is not possible. The traditional Ultra-WideBand (UWB)-based approach provides a good estimation of the distance between the robots, but obtaining the relative pose (including the displacement and orientation) remains challenging. We propose an approach to estimate the relative pose between a group of robots by equipping each robot with multiple UWB ranging nodes. We determine the pose between two robots by minimizing the residual error of the ranging measurements from all UWB nodes. To improve the localization accuracy, we propose to utilize the odometry constraints through a sliding window-based optimization. The optimized pose is then fused with the odometry in a particle filtering for pose tracking among a group of mobile robots. We have conducted extensive experiments to validate the effectiveness of the proposed approach.",
        "primary_area": "",
        "author": "Zhiqiang Cao;Ran Liu;Chau Yuen;Achala Athukorala;Benny Kai Kiat Ng;Muraleetharan Mathanraj;U-Xuan Tan;Zhiqiang Cao;Ran Liu;Chau Yuen;Achala Athukorala;Benny Kai Kiat Ng;Muraleetharan Mathanraj;U-Xuan Tan",
        "authorids": "/37090039313;/37085618269;/37273147100;/37085565872;/37088557352;/37089197575;/37085617165;/37090039313;/37085618269;/37273147100;/37085565872;/37088557352;/37089197575;/37085617165",
        "aff": "Southwest University of Science and Technology, Mianyang, Sichuan, China; Southwest University of Science and Technology, Mianyang, Sichuan, China; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; Singapore University of Technology and Design, Singapore; University of Jaffna, Jaffna, Sri Lanka; Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636017/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15587144865421047009&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;1;2;1",
        "aff_unique_norm": "Southwest University of Science and Technology;Singapore University of Technology and Design;University of Jaffna",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";https://www.sutd.edu.sg;http://www.jaffnauniversity.ac.lk",
        "aff_unique_abbr": ";SUTD;UoJ",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Mianyang;;Jaffna",
        "aff_country_unique_index": "0;0;1;1;1;2;1",
        "aff_country_unique": "China;Singapore;Sri Lanka"
    },
    {
        "id": "9636176",
        "title": "Residual Feedback Learning for Contact-Rich Manipulation Tasks with Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "While classic control theory offers state of the art solutions in many problem scenarios, it is often desired to improve beyond the structure of such solutions and surpass their limitations. To this end, residual policy learning (RPL) offers a formulation to improve existing controllers with reinforcement learning (RL) by learning an additive \"residual\" to the output of a given controller. However, the applicability of such an approach highly depends on the structure of the controller. Often, internal feedback signals of the controller limit an RL algorithm to adequately change the policy and, hence, learn the task. We propose a new formulation that addresses these limitations by also modifying the feedback signals to the controller with an RL policy and show superior performance of our approach on a contact-rich peg-insertion task under position and orientation uncertainty. In addition, we use a recent Cartesian impedance control architecture as the control framework which can be available to us as a black-box while assuming no knowledge about its input/output structure, and show the difficulties of standard RPL. Furthermore, we introduce an adaptive curriculum for the given task to gradually increase the task difficulty in terms of position and orientation uncertainty. A video showing the results can be found at https://youtu.be/SAZm_Krze7U.",
        "primary_area": "",
        "author": "Alireza Ranjbar;Ngo Anh Vien;Hanna Ziesche;Joschka Boedecker;Gerhard Neumann;Alireza Ranjbar;Ngo Anh Vien;Hanna Ziesche;Joschka Boedecker;Gerhard Neumann",
        "authorids": "/37089197578;/37838848600;/37089196852;/37888921900;/38542033100;/37089197578;/37838848600;/37089196852;/37888921900;/38542033100",
        "aff": "Bosch Center for Artificial Intelligence (BCAI); Bosch Center for Artificial Intelligence (BCAI); Bosch Center for Artificial Intelligence (BCAI); Albert-Ludwigs-Universit\u00e4t Freiburg; Karlsruhe Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636176/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12006777414160819975&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "Bosch Center for Artificial Intelligence;Albert-Ludwigs-Universit\u00e4t Freiburg;Karlsruhe Institute of Technology",
        "aff_unique_dep": "Artificial Intelligence;;",
        "aff_unique_url": "https://www.bosch-ai.com;https://www.uni-freiburg.de;https://www.kit.edu",
        "aff_unique_abbr": "BCAI;Albert-Ludwigs-Universit\u00e4t;KIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Freiburg",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9635835",
        "title": "Risk Averse Bayesian Reward Learning for Autonomous Navigation from Human Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional imitation learning provides a set of methods and algorithms to learn a reward function or policy from expert demonstrations. Learning from demonstration has been shown to be advantageous for navigation tasks as it allows for machine learning non-experts to quickly provide information needed to learn complex traversal behaviors. However, a minimal set of demonstrations is unlikely to capture all relevant information needed to achieve the desired behavior in every possible future operational environment. Due to distributional shift among environments, a robot may encounter features that were rarely or never observed during training for which the appropriate reward value is uncertain, leading to undesired outcomes. This paper proposes a Bayesian technique which quantifies uncertainty over the weights of a linear reward function given a dataset of minimal human demonstrations to operate safely in dynamic environments. This uncertainty is quantified and incorporated into a risk averse set of weights used to generate cost maps for planning. Experiments in a 3-D environment with a simulated robot show that our proposed algorithm enables a robot to avoid dangerous terrain completely in two out of three test scenarios and accumulates a lower amount of risk than related approaches in all scenarios without requiring any additional demonstrations.",
        "primary_area": "",
        "author": "Christian Ellis;Maggie Wigness;John Rogers;Craig Lennon;Lance Fiondella;Christian Ellis;Maggie Wigness;John Rogers;Craig Lennon;Lance Fiondella",
        "authorids": "/37086553463;/37085661502;/37533731800;/37085529498;/37691749200;/37086553463;/37085661502;/37533731800;/37085529498;/37691749200",
        "aff": "Department of Electrical and Computer Engineering, University of Massachusetts, Dartmouth, USA; United States Army Research Laboratory (ARL); United States Army Research Laboratory (ARL); United States Army Research Laboratory (ARL); Department of Electrical and Computer Engineering, University of Massachusetts, Dartmouth, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635835/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8714348358470449756&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of Massachusetts, Dartmouth;United States Army Research Laboratory",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.umassd.edu;https://www.arl.army.mil",
        "aff_unique_abbr": "UMass Dartmouth;ARL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Dartmouth;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636201",
        "title": "Risk Conditioned Neural Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Risk-bounded motion planning is an important yet difficult problem for safety-critical tasks. While existing mathematical programming methods offer theoretical guarantees in the context of constrained Markov decision processes, they either lack scalability in solving larger problems or produce conservative plans. Recent advances in deep reinforcement learning improve scalability by learning policy networks as function approximators. In this paper, we propose an extension of soft actor critic model to estimate the execution risk of a plan through a risk critic and produce risk-bounded policies efficiently by adding an extra risk term in the loss function of the policy network. We define the execution risk in an accurate form, as opposed to approximating it through a summation of immediate risks at each time step that leads to conservative plans. Our proposed model is conditioned on a continuous spectrum of risk bounds, allowing the user to adjust the risk-averse level of the agent on the fly. Through a set of experiments, we show the advantage of our model in terms of both computational time and plan quality, compared to a state-of-the-art mathematical programming baseline, and validate its performance in more complicated scenarios, including nonlinear dynamics and larger state space.",
        "primary_area": "",
        "author": "Xin Huang;Meng Feng;Ashkan Jasour;Guy Rosman;Brian Williams;Xin Huang;Meng Feng;Ashkan Jasour;Guy Rosman;Brian Williams",
        "authorids": "/37086595235;/37089196730;/37078643400;/37393688300;/37274902300;/37086595235;/37089196730;/37078643400;/37393688300;/37274902300",
        "aff": "Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; Toyota Research Institute, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636201/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2550938155631794660&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Toyota Research Institute",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory (CSAIL);",
        "aff_unique_url": "https://www.mit.edu;https://www.tri.global",
        "aff_unique_abbr": "MIT;TRI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636834",
        "title": "Risk-Averse RRT* Planning with Nonlinear Steering and Tracking Controllers for Nonlinear Robotic Systems Under Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a two-phase risk-averse architecture for controlling stochastic nonlinear robotic systems. We present Risk-Averse Nonlinear Steering RRT* (RANS-RRT*) as an RRT* variant that incorporates nonlinear dynamics by solving a nonlinear program (NLP) and accounts for risk by approximating the state distribution and performing a distributionally robust (DR) collision check to promote safe planning. The generated plan is used as a reference for a low-level tracking controller. We demonstrate three controllers: finite horizon linear quadratic regulator (LQR) with linearized dynamics around the reference trajectory, LQR with robustness-promoting multiplicative noise terms, and a nonlinear model predictive control law (NMPC). We demonstrate the effectiveness of our algorithm using unicycle dynamics under heavy-tailed Laplace process noise in a cluttered environment.",
        "primary_area": "",
        "author": "Sleiman Safaoui;Benjamin J. Gravell;Venkatraman Renganathan;Tyler H. Summers;Sleiman Safaoui;Benjamin J. Gravell;Venkatraman Renganathan;Tyler H. Summers",
        "authorids": "/37086937131;/37088428734;/37086291196;/38574644100;/37086937131;/37088428734;/37086291196;/38574644100",
        "aff": "Department of Electrical Engineering; Department of Mechanical Engineering, The University of Texas at Dallas, Richardson, TX, USA; Department of Mechanical Engineering, The University of Texas at Dallas, Richardson, TX, USA; Department of Mechanical Engineering, The University of Texas at Dallas, Richardson, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636834/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9752666915717707230&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Institution not specified;University of Texas at Dallas",
        "aff_unique_dep": "Department of Electrical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": ";https://www.utdallas.edu",
        "aff_unique_abbr": ";UT Dallas",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Richardson",
        "aff_country_unique_index": "1;1;1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "9635957",
        "title": "Risk-Aware Submodular Optimization for Stochastic Travelling Salesperson Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a risk-aware variant of the Traveling Salesperson Problem (TSP), where the robot tour cost and reward have to be optimized simultaneously, while being subjected to uncertainty in both. We study the case where the rewards and the costs exhibit diminishing marginal gains, i.e., are submodular. Since the costs and the rewards are stochastic, we seek to maximize a risk metric known as Conditional-Value-at-Risk (CVaR) of the submodular function. We propose a Risk-Aware Greedy Algorithm (RAGA) to find an approximate solution for this problem. The approximation algorithm runs in polynomial time and is within a constant factor of the optimal and an additive term that depends on the value of optimal solution. We use the submodular function\u2019s curvature to improve approximation results further and verify the algorithm\u2019s performance through simulations.",
        "primary_area": "",
        "author": "Rishab Balasubramanian;Lifeng Zhou;Pratap Tokekar;P. B. Sujit;Rishab Balasubramanian;Lifeng Zhou;Pratap Tokekar;P. B. Sujit",
        "authorids": "/37089196497;/37086092920;/37546532700;/37282784700;/37089196497;/37086092920;/37546532700;/37282784700",
        "aff": "IISER Bhopal, Bhopal, India; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Computer Science, University of Maryland, College Park, MD, USA; IISER Bhopal, Bhopal, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635957/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:LDy_YqL9ACgJ:scholar.google.com/&scioq=Risk-Aware+Submodular+Optimization+for+Stochastic+Travelling+Salesperson+Problem&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Indian Institute of Science Education and Research;Virginia Tech;University of Maryland",
        "aff_unique_dep": ";Department of Electrical and Computer Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.iiserbhopal.ac.in;https://www.vt.edu;https://www/umd.edu",
        "aff_unique_abbr": "IISER Bhopal;VT;UMD",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Bhopal;Blacksburg;College Park",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "9636091",
        "title": "Rm-Code: Proprioceptive Real-Time Recursive Multi-Contact Detection, Isolation and Identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Humanoid robots in unknown environments need to be able to quickly react to contacts in order to ensure safety of humans and their own hardware. For showing useful reactions to contacts, the robot needs information about possibly multiple contacts such as their respective contact locations and wrenches. In this paper, we introduce our algorithm rm-Code, a real-time multi-contact detection, isolation and identification algorithm for tree-structured floating base robots based on generalized external forces and (optional) external wrenches measured by force/torque sensors within the kinematic chain. Those entities have been deduced in the literature using proprioceptive sensing only. Furthermore, the algorithm is fast enough for online computation. To the best of our knowledge, this is the first algorithm combining all of these properties. Rm-Code is quantitatively evaluated in simulation. The results show that our solution is able to accurately solve the problem when fed with perfect input data. In a second step, possible sources of error in the presence of noisy input data are analyzed. It is concluded that purely proprioception based contact isolation and identification in the multi-contact case has certain limitations under realistic conditions. However, these limitations could be overcome easily by integrating simple link contact detection, e.g. bumpers or other similarly simple means.",
        "primary_area": "",
        "author": "Jonathan Vorndamme;Sami Haddadin;Jonathan Vorndamme;Sami Haddadin",
        "authorids": "/37085761454;/37542865300;/37085761454;/37542865300",
        "aff": "Department of Electrical and Computer Engineering, Department of Informatics, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Department of Electrical and Computer Engineering, Department of Informatics, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636091/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17515842941602231185&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636619",
        "title": "RoRD: Rotation-Robust Descriptors and Orthographic Views for Local Feature Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "The use of local detectors and descriptors in typical computer vision pipelines works well until variations in viewpoint and appearance change become extreme. Past research in this area has typically focused on one of two approaches to this challenge: the use of projections into spaces more suitable for feature matching under extreme viewpoint changes, and attempting to learn features that are inherently more robust to viewpoint change. In this paper, we present a novel framework that combines the learning of invariant descriptors through data augmentation and orthographic viewpoint projection. We propose rotation-robust local descriptors, learnt through training data augmentation based on rotation homographies, and a correspondence ensemble technique that combines vanilla feature correspondences with those obtained through rotation-robust features. Using a range of benchmark datasets as well as contributing a new bespoke dataset for this research domain, we evaluate the effectiveness of the proposed approach on key tasks including pose estimation and visual place recognition. Our system outperforms a range of baseline and state-of-the-art techniques, including enabling higher levels of place recognition precision across opposing place viewpoints, and achieves practically useful performance levels even under extreme viewpoint changes. We reduce pose estimation error by 86.72% relative to state of the art.",
        "primary_area": "",
        "author": "Udit Singh Parihar;Aniket Gujarathi;Kinal Mehta;Satyajit Tourani;Sourav Garg;Michael Milford;K. Madhava Krishna;Udit Singh Parihar;Aniket Gujarathi;Kinal Mehta;Satyajit Tourani;Sourav Garg;Michael Milford;K. Madhava Krishna",
        "authorids": "/37089195950;/37086807176;/37089198070;/37088506841;/37086209418;/37283633100;/38201465600;/37089195950;/37086807176;/37089198070;/37088506841;/37086209418;/37283633100;/38201465600",
        "aff": "Robotics Research Center, IIIT Hyderabad; Robotics Research Center, IIIT Hyderabad; Robotics Research Center, IIIT Hyderabad; Robotics Research Center, IIIT Hyderabad; QUT Centre for Robotics, Queensland University of Technology (QUT), Australia; QUT Centre for Robotics, Queensland University of Technology (QUT), Australia; Robotics Research Center, IIIT Hyderabad",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636619/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16940066951232034595&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;1;0",
        "aff_unique_norm": "IIIT Hyderabad;Queensland University of Technology",
        "aff_unique_dep": "Robotics Research Center;Centre for Robotics",
        "aff_unique_url": "https://www.iiit Hyderabad.ac.in;https://www.qut.edu.au",
        "aff_unique_abbr": "IIIT-H;QUT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hyderabad;",
        "aff_country_unique_index": "0;0;0;0;1;1;0",
        "aff_country_unique": "India;Australia"
    },
    {
        "id": "9636411",
        "title": "Road Graphical Neural Networks for Autonomous Roundabout Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel autonomous driving frame-work that leverages graph-based features of roads, such as road positions and connections. The proposed method is divided into two parts: a low-level controller which follows the trajectory calculated by a graph-based path planner, and a high-level controller which determines the speed of the vehicle to follow the traffic flow. The high-level controller uses a road graphical neural network (Road-GNN), which encodes a road graph into latent features to perceive the surrounding environment. We use a 3D driving simulator to test the performance of Road-GNN, which is implemented based on the satellite image data of 30 roundabout intersections. To show that the proposed method can be generalized to various road environments, the proposed method is tested using roundabouts which are different from the training set. In the experiment, the proposed method successfully trains the agent and drives an ego-vehicle through various roundabout environments. The results show that the graph-based method is effective for autonomous driving.",
        "primary_area": "",
        "author": "Timothy Ha;Gunmin Lee;Dohyeong Kim;Songhwai Oh;Timothy Ha;Gunmin Lee;Dohyeong Kim;Songhwai Oh",
        "authorids": "/37086455599;/37087323658;/37088687766;/37068116900;/37086455599;/37087323658;/37088687766;/37068116900",
        "aff": "Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea; Department of Electrical and Computer Engineering and ASRI, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636411/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18351955496645470224&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636581",
        "title": "Roadmap for Visibility-based Target Tracking: Iterative Construction and Motion Strategy",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of generating a fixed path for a mobile observer in a polygonal environment that can maintain a line-of-sight with an unpredictable target. In contrast to purely off-line or on-line techniques, we propose a hierarchical tracking strategy in which an off-line path generation technique based on a RRT is coupled with an online feedback-control technique to generate trajectories for the mobile observer.",
        "primary_area": "",
        "author": "Guillermo Laguna;Shashwata Mandal;Sourabh Bhattacharya;Guillermo Laguna;Shashwata Mandal;Sourabh Bhattacharya",
        "authorids": "/37086179988;/37089196313;/37275362500;/37086179988;/37089196313;/37275362500",
        "aff": "Department of Mechanical Engineering, Iowa State University, Ames; Department of Computer Science, Iowa State University, Ames; Department of Computer Science, Iowa State University, Ames",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636581/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1394315855662133664&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Iowa State University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.iastate.edu",
        "aff_unique_abbr": "ISU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ames",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635830",
        "title": "Robofleet: Open Source Communication and Management for Fleets of Autonomous Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Long-term deployment of a fleet of mobile robots requires reliable and secure two-way communication channels between individual robots and remote human operators for supervision and tasking. Existing open-source solutions to this problem degrade in performance in challenging real-world situations such as intermittent and low-bandwidth connectivity, do not provide security control options, and can be computationally expensive on hardware-constrained mobile robot platforms. In this paper, we present Robofleet, a lightweight open-source system which provides inter-robot communication, remote monitoring, and remote tasking for a heterogenous fleet of ROS-enabled service-mobile robots that is designed with the practical goals of resilience to network variance and security control in mind.Robofleet supports multi-user, multi-robot communication via a central server. This architecture deduplicates network traffic between robots, significantly reducing overall network load when compared with native ROS communication. This server also functions as a single entrypoint into the system, enabling security control and user authentication. Individual robots run the lightweight Robofleet client, which is responsible for exchanging messages with the Robofleet server. It automatically adapts to adverse network conditions through backpressure monitoring as well as topic-level priority control, ensuring that safety-critical messages are successfully transmitted. Finally, the system includes a web-based visualization tool that can be run on any internet-connected, browser-enabled device to monitor and control the fleet.We compare Robofleet to existing methods of robotic communication, and demonstrate that it provides superior resilience to network variance while maintaining performance that exceeds that of widely-used systems.",
        "primary_area": "",
        "author": "Kavan Singh Sikand;Logan Zartman;Sadegh Rabiee;Joydeep Biswas;Kavan Singh Sikand;Logan Zartman;Sadegh Rabiee;Joydeep Biswas",
        "authorids": "/37089193943;/37089195252;/37086933532;/37538259200;/37089193943;/37089195252;/37086933532;/37538259200",
        "aff": "Computer Science Department, University of Texas at Austin, USA; Computer Science Department, University of Texas at Austin, USA; Computer Science Department, University of Texas at Austin, USA; Computer Science Department, University of Texas at Austin, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635830/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4265947127806049262&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636704",
        "title": "Robot Hand based on a Spherical Parallel Mechanism for Within-Hand Rotations about a Fixed Point",
        "track": "main",
        "status": "Poster",
        "abstract": "Rotating a grasped object about all three spatial axes is challenging, because kinematically redundant robot hands require complex control schemes for within-hand rotations, and simple parallel grippers require inefficient whole arm motions. We present a novel 3-finger robot hand design inspired by a spherical parallel mechanism that achieves these rotations with just 3 actuators. The hand is designed such that at every hand-object configuration, the object pose moves along a sphere with a fixed center, which is determined by the intersection of the fingers\u2019 revolute axes and is independent of the object shape, pose, and the initial grasp configuration. We optimize the hand based on 3-RRS spherical manipulator to maximize both its rotational workspace size and manipulation motion quality. From these parameters, we implement and experimentally evaluate the hand design through grasping tests, manipulation characterization, and real-world task scenarios, which show that the hand is able to grasp a variety of object geometries and accomplish precise single and multi-DOF rotations about a fixed point. We believe this design can remarkably improve robustness and simplify control for dexterous within-hand rotations, which finds utility in augmenting the capabilities of low-DOF robot arms without an active wrist.",
        "primary_area": "",
        "author": "Vatsal V. Patel;Aaron M. Dollar;Vatsal V. Patel;Aaron M. Dollar",
        "authorids": "/37086366220;/37604732600;/37086366220;/37604732600",
        "aff": "Department of Mechanical Engineering and Materials Science, Yale University, USA; Department of Mechanical Engineering and Materials Science, Yale University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636704/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1868980828524694406&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Yale University",
        "aff_unique_dep": "Department of Mechanical Engineering and Materials Science",
        "aff_unique_url": "https://www.yale.edu",
        "aff_unique_abbr": "Yale",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636401",
        "title": "Robot-assisted Breast Ultrasound Scanning Using Geometrical Analysis of the Seroma and Image Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a robotic ultrasound imaging method that scans the breast in two separate phases to acquire high-quality ultrasound images. Our proposed system controls five Degrees of Freedom (DoFs) of the robot that hold an ultrasound probe to perform precise scanning. This system finds the desired trajectory based on geometrical analysis of the target inside the breast in a pre-scan phase and uses this information to control the probe in a post-scan phase. The proposed method updates the desired values of rotational and translational movement of the probe in the post-scan by calculating the center of mass of segmented target in each acquired frame and the average of image confidence map. The proposed method has been tested experimentally on a plastisol phantom. Given a specific trajectory, the position and orientation of the probe have been controlled at each point of the trajectory. The experiments\u2019 result shows us that our proposed visual servoing algorithm successfully controls the probe to look at target tissue and is fast enough for use in a robotic control loop.",
        "primary_area": "",
        "author": "Mojtaba Akbari;Jay Carriere;Ron Sloboda;Tyler Meyer;Nawaid Usmani;Siraj Husain;Mahdi Tavakoli;Mojtaba Akbari;Jay Carriere;Ron Sloboda;Tyler Meyer;Nawaid Usmani;Siraj Husain;Mahdi Tavakoli",
        "authorids": "/37089195415;/37085472623;/38163120900;/37086831127;/37085409253;/37086832821;/37282400400;/37089195415;/37085472623;/38163120900;/37086831127;/37085409253;/37086832821;/37282400400",
        "aff": "Department of Electrical and Computer Engineering, University of Alberta, Canada; Department of Electrical and Computer Engineering, University of Alberta, Canada; Department of Oncology, Cross Cancer Institute, Edmonton, Canada; Division of Radiation Oncology, Tom Baker Cancer Centre, Calgary; Department of Oncology, Cross Cancer Institute, Edmonton, Canada; Division of Radiation Oncology, Tom Baker Cancer Centre, Calgary; Department of Electrical and Computer Engineering, University of Alberta, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636401/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3819955668162833214&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;1;2;0",
        "aff_unique_norm": "University of Alberta;Cross Cancer Institute;Tom Baker Cancer Centre",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Oncology;Division of Radiation Oncology",
        "aff_unique_url": "https://www.ualberta.ca;https://www.crosscancerinstitute.ca;https://www.tombakercancercentre.ca",
        "aff_unique_abbr": "UAlberta;;",
        "aff_campus_unique_index": "1;2;1;2",
        "aff_campus_unique": ";Edmonton;Calgary",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636567",
        "title": "Robotic Guidance System for Visually Impaired Users Running Outdoors Using Haptic Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "For the visually impaired people, some outdoor activities like running or soccer are difficult, due to not being able to clearly see the environment. Recently, multiple researchers have contributed to help the visually impaired people run outdoors using robotic systems with different types of feedback, such as auditory feedback and haptic feedback. They discovered that using robotic systems can be an effective way to guide visually impaired people while exercising outdoors. In this paper, we propose a method to guide the visually impaired people to do sports outside using a robotic system with haptic feedback, and we evaluate the feasibility of the proposed system through experiments with blindfolded users running outdoors. In the running guidance task, the position of the runner is determined from the visual feed of a drone, and haptic feedback produced on the users\u2019 left lower leg is used to convey to the runner the directions in which to move to remain on a specific path. Additionally, we compared the performance of users under different haptic feedback modalities in the running task. The three compared modalities are: producing vibration only during the swing phase, only during stance phase or producing vibration continuously. The experimental results for a running task showed that our system enabled users to remain inside a specified track 93% of the total running time, while the ratio decreased to 79%, 77%, and 61% when receiving vibrations during only swing phase, during only stance phase, and without using any feedback respectively. We also observed users felt safer while running blindfolded by using the proposed method.",
        "primary_area": "",
        "author": "Zhenyu Liao;Jose Salazar;Yasuhisa Hirata;Zhenyu Liao;Jose Salazar;Yasuhisa Hirata",
        "authorids": "/37088448664;/37086200460;/37274134900;/37088448664;/37086200460;/37274134900",
        "aff": "Department of Robotics, Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Robotics, Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Robotics, Graduate School of Engineering, Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636567/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1284221839534526810&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sendai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636066",
        "title": "Robotic Jigsaw: A Non-Holonomic Cutting Robot and Path Planning Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "Bladed tools such as jigsaws are common tools for wood workers on job-sites and in workshops, but do not currently have sufficient autonomous hardware or path planning algorithms to enable automation. Here we present a system of an autonomous robot and a path planning algorithm for automating jigsaw operations. The robot can drill holes, insert the jigsaw, and cut plywood. Our algorithm converts complex shapes into paths for the jigsaw, drill holes, and traversal movements for the robot. The algorithm decomposes input shapes into cuttable sections and determines possible locations for drilling entry holes for inserting the blade. We cast the drill hole problem as a set coverage problem with a trade-off between number of holes and cutting distance. We characterize the algorithm on a series of shapes and determined the algorithm found valid solutions. We executed an example on the robot to demonstrate the end-to-end system.",
        "primary_area": "",
        "author": "Haisen Zhao;Yash Talwekar;Wenqing Lan;Chetan Sharma;Daniela Rus;Adriana Schulz;Jeffrey I Lipton;Haisen Zhao;Yash Talwekar;Wenqing Lan;Chetan Sharma;Daniela Rus;Adriana Schulz;Jeffrey I Lipton",
        "authorids": "/37088492036;/37089194315;/37089195256;/37086414021;/37279652300;/37086453514;/37086014107;/37088492036;/37089194315;/37089195256;/37086414021;/37279652300;/37086453514;/37086014107",
        "aff": "Computer Science And Engineering, Shandong University, Qingdao, China; Mechanical Engineering, University of Washington, Seattle, WA, USA; Computer Science And Engineering, University of Washington, Seattle, WA, USA; CSAIL MIT, Cambridge, MA, USA; CSAIL MIT, Cambridge, MA, USA; Computer Science And Engineering, University of Washington, Seattle, WA, USA; Mechanical Engineering, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636066/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7339873123562478337&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;2;2;1;1",
        "aff_unique_norm": "Shandong University;University of Washington;Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science And Engineering;Mechanical Engineering;Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "http://www.sdu.edu.cn;https://www.washington.edu;https://www.csail.mit.edu",
        "aff_unique_abbr": "SDU;UW;MIT",
        "aff_campus_unique_index": "0;1;1;2;2;1;1",
        "aff_campus_unique": "Qingdao;Seattle;Cambridge",
        "aff_country_unique_index": "0;1;1;1;1;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9636396",
        "title": "Robotic Lime Picking by Considering Leaves as Permeable Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem of robotic lime picking is challenging; lime plants have dense foliage which makes it difficult for a robotic arm to grasp a lime without coming in contact with leaves. Existing approaches either do not consider leaves, or treat them as obstacles and completely avoid them, often resulting in undesirable or infeasible plans. We focus on reaching a lime in the presence of dense foliage by considering the leaves of a plant as permeable obstacles with a collision cost. We then adapt the rapidly exploring random tree star (RRT*) algorithm for the problem of fruit harvesting by incorporating the cost of collision with leaves into the path cost. To reduce the time required for finding low-cost paths to goal, we bias the growth of the tree using an artificial potential field (APF). We compare our proposed method with prior work in a 2-D environment and a 6-DOF robot simulation. Our experiments and a real-world demonstration on a robotic lime picking task demonstrate the applicability of our approach.",
        "primary_area": "",
        "author": "Heramb Nemlekar;Ziang Liu;Suraj Kothawade;Sherdil Niyaz;Barath Raghavan;Stefanos Nikolaidis;Heramb Nemlekar;Ziang Liu;Suraj Kothawade;Sherdil Niyaz;Barath Raghavan;Stefanos Nikolaidis",
        "authorids": "/37086933305;/37088505106;/37086701351;/37085898362;/37089404579;/37643766400;/37086933305;/37088505106;/37086701351;/37085898362;/37089404579;/37643766400",
        "aff": "University of Southern California; University of Southern California; University of Southern California; University of Southern California; University of Southern California; University of Southern California",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636396/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17072728487251185263&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635947",
        "title": "Robotic Occlusion Reasoning for Efficient Object Existence Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Reasoning about potential occlusions is essential for robots to efficiently predict whether an object exists in an environment. Though existing work shows that a robot with active perception can achieve various tasks, it is still unclear if occlusion reasoning can be achieved. To answer this question, we introduce the task of robotic object existence prediction: when being asked about an object, a robot needs to move as few steps as possible around a table with randomly placed objects to predict whether the queried object exists. To address this problem, we propose a novel recurrent neural network model that can be jointly trained with supervised and reinforcement learning methods using a curriculum training strategy. Experimental results show that 1) both active perception and occlusion reasoning are necessary to successfully achieve the task; 2) the proposed model demonstrates a good occlusion reasoning ability by achieving a similar prediction accuracy to an exhaustive exploration baseline while requiring only about 10% of the baseline\u2019s number of movement steps on average; and 3) the model generalizes to novel object combinations with a moderate loss of accuracy.",
        "primary_area": "",
        "author": "Mengdi Li;Cornelius Weber;Matthias Kerzel;Jae Hee Lee;Zheni Zeng;Zhiyuan Liu;Stefan Wermter;Mengdi Li;Cornelius Weber;Matthias Kerzel;Jae Hee Lee;Zheni Zeng;Zhiyuan Liu;Stefan Wermter",
        "authorids": "/37089197422;/37549767100;/37086049282;/37088972933;/37088455772;/37875612600;/37323875400;/37089197422;/37549767100;/37086049282;/37088972933;/37088455772;/37875612600;/37323875400",
        "aff": "Department of Informatics Knowledge Technology, Knowledge Technology, University of Hamburg, Hamburg, Germany; Department of Informatics Knowledge Technology, Knowledge Technology, University of Hamburg, Hamburg, Germany; Department of Informatics Knowledge Technology, Knowledge Technology, University of Hamburg, Hamburg, Germany; Department of Informatics Knowledge Technology, Knowledge Technology, University of Hamburg, Hamburg, Germany; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Informatics Knowledge Technology, Knowledge Technology, University of Hamburg, Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635947/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=361834612363874584&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;1;0",
        "aff_unique_norm": "University of Hamburg;Tsinghua University",
        "aff_unique_dep": "Department of Informatics Knowledge Technology;Department of Computer Science and Technology",
        "aff_unique_url": "https://www.uni-hamburg.de;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": ";THU",
        "aff_campus_unique_index": "0;0;0;0;1;1;0",
        "aff_campus_unique": "Hamburg;Beijing",
        "aff_country_unique_index": "0;0;0;0;1;1;0",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "9636203",
        "title": "Robust Behavior Cloning with Adversarial Demonstration Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Imitation learning (IL) frameworks in robotics typically assume that a domain expert's demonstration always contains a correct way of doing the task. Despite its theoretical convenience, this assumption has limited practical values for an IL-powered robot in real world. There are many reasons for an expert in the real world to provide demonstrations that may contain incorrect or potentially unsafe way of doing a task. In order for IL-powered robots to work in the real world, IL frameworks need to detect such adversarial demonstrations and not learn from them. This paper proposes an IL framework that can autonomously detect and remove adversarial demonstrations, if they exist in the demonstration set, as it directly learns a task policy from the expert. The proposed framework that we term Robust Maximum Entropy behavior cloning (R-MaxEnt) learns a stochastic model that maps states to actions. In doing so, R-MaxEnt solves a minmax problem that leverages the entropy of the model to assign weights to different demonstrations while assigning poor weights to adversarial samples. Our empirical results show that R-MaxEnt outperforms the existing IL approaches in both real and simulated robotics tasks.",
        "primary_area": "",
        "author": "Mostafa Hussein;Brendan Crowe;Madison Clark-Turner;Paul Gesel;Marek Petrik;Momotaz Begum;Mostafa Hussein;Brendan Crowe;Madison Clark-Turner;Paul Gesel;Marek Petrik;Momotaz Begum",
        "authorids": "/37086129101;/37089194283;/37087237795;/37086936045;/37086734631;/37293898900;/37086129101;/37089194283;/37087237795;/37086936045;/37086734631;/37293898900",
        "aff": "Cognitive Assistive Robotics Lab, University of New Hampshire; Department of Statistics, University of New Hampshire; Cognitive Assistive Robotics Lab, University of New Hampshire; Cognitive Assistive Robotics Lab, University of New Hampshire; Department of Computer Science, University of New Hampshire; Cognitive Assistive Robotics Lab, University of New Hampshire",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636203/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17363121812512717165&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of New Hampshire",
        "aff_unique_dep": "Cognitive Assistive Robotics Lab",
        "aff_unique_url": "https://www.unh.edu",
        "aff_unique_abbr": "UNH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636553",
        "title": "Robust Event Detection based on Spatio-Temporal Latent Action Unit using Skeletal Information",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel dictionary learning approach to detect event anomalities using skeletal information extracted from RGBD video. The event action is represented as several latent action atoms and composed of latent spatial and temporal attributes. We aim to construct a network able to learn from few examples and also rules defined by the user. The skeleton frames are clustered by an initial K-means method. Each skeleton frame is assigned with a varying weight parameter and fed into our Gradual Online Dictionary Learning (GODL) algorithm. During the training process, outlier frames will be gradually filtered by reducing the weight that is inversely proportional to a cost. To strictly distinguish the event action from similar actions and robustly acquire its action units, we build a latent unit temporal structure for each sub-action.We validate the method at the example of fall event detection on NTU RGB+D dataset, because it provides a benchmark available for comparison. We present the experimental validation of the achieved accuracy, recall, and precision. Our approach achieves the best performance in precision and accuracy of human fall event detection, compared with other existing dictionary learning methods. Our method remains the highest accuracy and the lowest variance, with increasing noise ratio.",
        "primary_area": "",
        "author": "Hao Xing;Yuxuan Xue;Mingchuan Zhou;Darius Burschka;Hao Xing;Yuxuan Xue;Mingchuan Zhou;Darius Burschka",
        "authorids": "/37089197003;/37089194472;/37086332028;/37267429200;/37089197003;/37089194472;/37086332028;/37267429200",
        "aff": "Department of Computer Science, Machine Vision and Perception Group, Technical University of Munich, Munich, Germany; Department of Computer Science, Machine Vision and Perception Group, Technical University of Munich, Munich, Germany; Chair for Computer Aided Medical Procedures and Augmented Reality, Technical University of Munich; Department of Computer Science, Machine Vision and Perception Group, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636553/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14574469756916310101&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636467",
        "title": "Robust Feedback Motion Policy Design Using Reinforcement Learning on a 3D Digit Bipedal Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a hierarchical and robust framework for learning bipedal locomotion is presented and successfully implemented on the 3D biped robot Digit built by Agility Robotics. We propose a cascade-structure controller that combines the learning process with intuitive feedback regulations. This design allows the framework to realize robust and stable walking with a reduced-dimensional state and action spaces of the policy, significantly simplifying the design and increasing the sampling efficiency of the learning method. The inclusion of feedback regulation into the framework improves the robustness of the learned walking gait and ensures the success of the sim-to-real transfer of the proposed controller with minimal tuning. We specifically present a learning pipeline that considers hardware-feasible initial poses of the robot within the learning process to ensure the initial state of the learning is replicated as close as possible to the initial state of the robot in hardware experiments. Finally, we demonstrate the feasibility of our method by successfully transferring the learned policy in simulation to the Digit robot hardware, realizing sustained walking gaits under external force disturbances and challenging terrains not incurred during the training process. To the best of our knowledge, this is the first time a learning-based policy is transferred successfully to the Digit robot in hardware experiments.",
        "primary_area": "",
        "author": "Guillermo A. Castillo;Bowen Weng;Wei Zhang;Ayonga Hereid;Guillermo A. Castillo;Bowen Weng;Wei Zhang;Ayonga Hereid",
        "authorids": "/37086936437;/37086936098;/37089656248;/37077055000;/37086936437;/37086936098;/37089656248;/37077055000",
        "aff": "Electrical and Computer Engineering, Ohio State University, Columbus, OH, USA; Electrical and Computer Engineering, Ohio State University, Columbus, OH, USA; SUSTech Institute of Robotics, Southern University of Science and Technology (SUSTech), China; Mechanical and Aerospace Engineering, Ohio State University, Columbus, OH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636467/",
        "gs_citation": 88,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10739052832899517664&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Ohio State University;Southern University of Science and Technology",
        "aff_unique_dep": "Electrical and Computer Engineering;Institute of Robotics",
        "aff_unique_url": "https://www.osu.edu;https://www.sustech.edu.cn",
        "aff_unique_abbr": "OSU;SUSTech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Columbus;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9636521",
        "title": "Robust Feedback Motion Primitives for Exploration of Unknown Terrains",
        "track": "main",
        "status": "Poster",
        "abstract": "Unknown properties of a robot\u2019s environment are one of the sources of uncertainty in autonomous navigation. This uncertainty has to be accounted for when modelling robot dynamics. For ground vehicles in particular, terrain structure is one of the main environmental factors that can strongly influence the dynamics. Therefore, to ensure the ability of a robot to safely and efficiently navigate new environments, robust motion planning and control systems are needed. This paper investigates a data-driven approach to planning and control based on construction of robust motion primitives (MPs) and corresponding feedback rules that ensure a bounded error along the planned trajectory. The approach is tested in an exploration scenario in which a robot systematically inspects an area consisting of several terrain types with the aim of recognizing changes in dynamical properties, learning new dynamics models when such changes are detected and recording that information for future use. The advantage of incorporating the collected data into motion planning in multi-terrain environments is illustrated via simulation.",
        "primary_area": "",
        "author": "Charles Chernik;Pouria Tajvar;Jana Tumova;Charles Chernik;Pouria Tajvar;Jana Tumova",
        "authorids": "/37089194989;/37085507921;/38230312900;/37089194989;/37085507921;/38230312900",
        "aff": "Digital Futures; Digital Futures; Digital Futures",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636521/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7144781557121358541&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Digital Futures",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9636045",
        "title": "Robust Initialization of Multi-camera SLAM with Limited View Overlaps and Inaccurate Extrinsic Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a robust initialization method for a multi-camera visual SLAM system where cameras have only a limited common field of views and inaccurate extrinsic calibration. The limited common field of views leads to only a few common features that can be matched between cameras. Inaccurate extrinsic poses, caused by vibrations or misplacement of cameras after offline calibration, make it even harder for triangulating the seed 3D points to initialize the SLAM system successfully. Instead of taking the extrinsic parameters as constants for feature matching and 3D point triangulation as most multi-camera systems did, we propose to take the inaccurate extrinsic poses as soft constraints to accommodate the calibration errors. Our initialization method consists of two stages by matching across different cameras and between two key frames. Both stages involve optimizing the cost functions that contain the extrinsic pose priors from inaccurate calibration parameters. By incorporating those soft pose constraints, we may avoid false feature matching and triangulation caused by inaccurate extrinsic parameters, while keeping solution space limited when only a few feature correspondences exist. The results in real-world tests show that such a simple solution can improve the success rate of SLAM initialization notably, even when the pose priors from the offline calibration differ significantly from the real ones.",
        "primary_area": "",
        "author": "Ang Li;Danping Zou;Wenxian Yu;Ang Li;Danping Zou;Wenxian Yu",
        "authorids": "/37089195064;/38541939500;/37405648000;/37089195064;/38541939500;/37405648000",
        "aff": "Shanghai Key Laboratory of Navigation and Location-Based Service, Shanghai Jiao Tong University; Shanghai Key Laboratory of Navigation and Location-Based Service, Shanghai Jiao Tong University; Shanghai Key Laboratory of Navigation and Location-Based Service, Shanghai Jiao Tong University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636045/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5350119318789443237&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Shanghai Key Laboratory of Navigation and Location-Based Service",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636227",
        "title": "Robust LiDAR Localization on an HD Vector Map without a Separate Localization Layer",
        "track": "main",
        "status": "Poster",
        "abstract": "Many autonomous driving applications nowadays come along with a prebuilt vector map for routing and planning purposes. In order to localize on this map, traditional LiDAR localization methods usually require a separate localization layer to function. On one hand, the separate layer occupies large storage and is not convenient to update. On the other hand, the potential of the vector map itself has not been fully exploited by existing methods. In this paper, we present a LiDAR localization system that leverages the vector map directly as the localization layer. A semantic extraction module is developed to match the heterogeneous data between LiDAR measurements and the 3D vector elements. A local map maintenance module is introduced to keep the system function robustly when there are not enough vector matches. The system adopts an optimization-based framework and infers 6-DOF poses. Experiments show that the proposed system is able to achieve centimeter accuracy robustly in both highway and urban environments, without a separate localization layer.",
        "primary_area": "",
        "author": "Chi Zhang;Liwen Liu;Zhoupeng Xue;Kun Guo;Kuiyuan Yang;Rui Cai;Zhiwei Li;Chi Zhang;Liwen Liu;Zhoupeng Xue;Kun Guo;Kuiyuan Yang;Rui Cai;Zhiwei Li",
        "authorids": "/37086571645;/37089194476;/37089194246;/37089197149;/37089194101;/37284702100;/37404741200;/37086571645;/37089194476;/37089194246;/37089197149;/37089194101;/37284702100;/37404741200",
        "aff": "Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China; Xiaomi Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636227/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18216138384509453449&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Xiaomi Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.xiaomi.com",
        "aff_unique_abbr": "Xiaomi",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636304",
        "title": "Robust Multi-camera SLAM with Manhattan Constraint toward Automated Valet Parking",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a multi-camera simultaneous localization and mapping (SLAM) system using the Manhattan constraint to support automated valet parking. The proposed method uses multiple cameras to expand the system field of view, to improve the robustness of the SLAM system in textureless regions, where point features from different cameras are jointly optimized by a uniform cost function. To improve global map scale consistency, we utilize wheel odometer in the system initialization and the multi-camera cost function. In addition, we introduce the Manhattan world assumption, an abstraction of a man-made environment, into the proposed algorithm, to improve its estimation processes and make it suitable for the multi-camera SLAM system. The Manhattan world assumption is used to estimate the camera rotation by line features in the image and provide a global orientation constraint that increases the mapping accuracy. The proposed algorithm demonstrates stability in low-texture regions and achieves superior accuracy in experiments conducted in multistory parking lots, compared with other algorithms including monocular and multi-camera versions. Regarding efficiency, the proposed algorithm processes twice the number of measurements with 50% additional computation time while maintaining SLAM stability under a textureless environment.",
        "primary_area": "",
        "author": "Yifei Kang;Yu Song;Wuwei Ge;Tong Ling;Yifei Kang;Yu Song;Wuwei Ge;Tong Ling",
        "authorids": "/37086731622;/37293362600;/37089195462;/37089197866;/37086731622;/37293362600;/37089195462;/37089197866",
        "aff": "School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China; School of Electrical Engineering, Beijing Jiaotong University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636304/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9283946823549403348&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Beijing Jiao Tong University",
        "aff_unique_dep": "School of Electrical Engineering",
        "aff_unique_url": "http://www.bjtu.edu.cn",
        "aff_unique_abbr": "BJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636552",
        "title": "Robust Policy Search for an Agile Ground Vehicle Under Perception Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning robust policies for robotic systems operating in presence of uncertainty is a challenging task. For safe navigation, in addition to the natural stochasticity of the environment and vehicle dynamics, the perception uncertainty associated with dynamic entities, e.g. pedestrians, must be accounted for during motion planning. To this end, we construct an algorithm with built-in robustness to uncertainty by directly minimizing an upper confidence bound on the expected cost of trajectories instead of employing a standard approach based on minimizing the expected cost itself. Perception uncertainty is incorporated into the policy search framework by predicting each pedestrian\u2019s intent belief and propagating their state distribution in time using closed-loop goal-directed dynamics. We train the policy in simulation and show that it could be transferred to an agile ground vehicle for successful autonomous robot navigation in presence of pedestrians with perception uncertainty. We further show the superior performance of this policy over a policy that does not consider pedestrian intent and perception uncertainty.",
        "primary_area": "",
        "author": "Shahriar Sefati;Subhransu Mishra;Matthew Sheckells;Kapil D. Katyal;Jin Bai;Gregory D. Hager;Marin Kobilarov;Shahriar Sefati;Subhransu Mishra;Matthew Sheckells;Kapil D. Katyal;Jin Bai;Gregory D. Hager;Marin Kobilarov",
        "authorids": "/37085769362;/38236768600;/37086034388;/38228973900;/37089195535;/37276163200;/37546944400;/37085769362;/38236768600;/37086034388;/38228973900;/37089195535;/37276163200;/37546944400",
        "aff": "Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Space Exploration Technologies Corp. (SpaceX), Hawthorne, CA, USA; Applied Physics Lab, Johns Hopkins University, Laurel, MD, USA; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Malone Center for Engineering in Healthcare, Johns Hopkins University, Baltimore, MD, USA; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636552/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:3HIMBXpUJVwJ:scholar.google.com/&scioq=Robust+Policy+Search+for+an+Agile+Ground+Vehicle+Under+Perception+Uncertainty&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;0;0",
        "aff_unique_norm": "Johns Hopkins University;Space Exploration Technologies Corp.",
        "aff_unique_dep": "Laboratory for Computational Sensing and Robotics;",
        "aff_unique_url": "https://www.jhu.edu;https://www.spacex.com",
        "aff_unique_abbr": "JHU;SpaceX",
        "aff_campus_unique_index": "0;0;1;2;0;0;0",
        "aff_campus_unique": "Baltimore;Hawthorne;Laurel",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636532",
        "title": "Robust Pose Estimation Based on Normalized Information Distance",
        "track": "main",
        "status": "Poster",
        "abstract": "Dense image alignment works by minimizing the photometric error of two images since it is assumed that the illumination changes between images close in time remain the same\u2014this is what is called the brightness constancy assumption. However, this assumption does not hold with long-term maps since illumination changes continually from day to day (morning, afternoon, evening) and is dependent on certain external conditions like weather or even seasons. In this work, we present an image registration algorithm based on the Normalized Information Distance (NID) that is shown to be robust to extreme illumination changes comparing to the traditional direct methods. The pose is estimated by minimizing the NID function with the help of the nonlinear least square optimization library G2O. We share our source code 1 (CPU and GPU version) for the benefit of the community, which can be a strong basis for future tracking and mapping system based on NID.",
        "primary_area": "",
        "author": "Zhaozhong Chen;Christoffer Heckman;Zhaozhong Chen;Christoffer Heckman",
        "authorids": "/37086450966;/37086032368;/37086450966;/37086032368",
        "aff": "Autonomous Robotics and Perception Group, the University of Colorado at Boulder; Autonomous Robotics and Perception Group, the University of Colorado at Boulder",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636532/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16080904046183916782&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Colorado at Boulder",
        "aff_unique_dep": "Autonomous Robotics and Perception Group",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636443",
        "title": "Robust Rank Deficient SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous mobile robots need maps for effective, safe navigation, and SLAM in general is still an unsolved problem. Nonetheless, certain combinations of environmental characteristics and sensors admit tractable solutions. In particular, detection and tracking of linear features such as line segments (2D) or planar facets (3D) has been proven robust in many man-made environments. However, these types of features produce rank-deficient constraints, which create challenges for graph-based SLAM optimizers. We present techniques for using rank-deficient features and constraints more robustly by analyzing the approximate null-space of the constraints for each node in the factor graph representing the trajectory. We also extend auxiliary methods for correspondence calculations and map update routines, the combination of which yields state-of-the-art performance for a rank-deficient SLAM system. We present results from quantitative experiments comparing memory use, compute load, accuracy, and robustness for several ablation tests on real and simulated data.",
        "primary_area": "",
        "author": "Samer B. Nashed;Jong Jin Park;Roger Webster;Joseph W. Durham;Samer B. Nashed;Jong Jin Park;Roger Webster;Joseph W. Durham",
        "authorids": "/37086198158;/37087322796;/37089195712;/37530549200;/37086198158;/37087322796;/37089195712;/37530549200",
        "aff": "Amazon Lab126, Sunnyvale, CA, USA; Amazon Lab126, Sunnyvale, CA, USA; Amazon Lab126, Sunnyvale, CA, USA; Amazon Robotics, North Reading, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636443/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14839073606000311886&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Amazon",
        "aff_unique_dep": "Amazon Lab126",
        "aff_unique_url": "https://www.amazon.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Sunnyvale;North Reading",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636814",
        "title": "Robust SLAM Systems: Are We There Yet?",
        "track": "main",
        "status": "Poster",
        "abstract": "Progress in the last decade has brought about significant improvements in the accuracy and speed of SLAM systems, broadening their mapping capabilities. Despite these advancements, long-term operation remains a major challenge, primarily due to the wide spectrum of perturbations robotic systems may encounter.Increasing the robustness of SLAM algorithms is an ongoing effort, however it usually addresses a specific perturbation. Generalisation of robustness across a large variety of challenging scenarios is not well-studied nor understood. This paper presents a systematic evaluation of the robustness of open-source state-of-the-art SLAM algorithms with respect to challenging conditions such as fast motion, non-uniform illumination, and dynamic scenes. The experiments are performed with perturbations present both independently of each other, as well as in combination in long-term deployment settings in unconstrained environments (lifelong operation).The detailed results (approx. 20,000 experiments) along with comprehensive documentation of the benchmarking tool for integrating new datasets and evaluating SLAM algorithms not studied in this work are available at https://robustslam.github.io/evaluation.",
        "primary_area": "",
        "author": "Mihai Bujanca;Xuesong Shi;Matthew Spear;Pengpeng Zhao;Barry Lennox;Mikel Luj\u00e1n;Mihai Bujanca;Xuesong Shi;Matthew Spear;Pengpeng Zhao;Barry Lennox;Mikel Luj\u00e1n",
        "authorids": "/37086934435;/37086577986;/37089194127;/37088504382;/37299751200;/37392848800;/37086934435;/37086577986;/37089194127;/37088504382;/37299751200;/37392848800",
        "aff": "The University of Manchester, Manchester, UK; Intel Labs China, Beijing, China; The University of Manchester, Manchester, UK; Beihang University, Beijing, China; The University of Manchester, Manchester, UK; The University of Manchester, Manchester, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636814/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=393880336957226653&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;0",
        "aff_unique_norm": "University of Manchester;Intel;Beihang University",
        "aff_unique_dep": ";Intel Labs China;",
        "aff_unique_url": "https://www.manchester.ac.uk;https://www.intel.cn;http://www.buaa.edu.cn/",
        "aff_unique_abbr": "UoM;Intel China;BUAA",
        "aff_campus_unique_index": "0;1;0;1;0;0",
        "aff_campus_unique": "Manchester;Beijing",
        "aff_country_unique_index": "0;1;0;1;0;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9636273",
        "title": "Robust Sample-Based Output-Feedback Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel approach for sampling-based and control-based motion planning. We combine a representation of the environment obtained via a modified version of optimal Rapidly-exploring Random Trees (RRT*), with landmark-based output-feedback controllers obtained via Control Lyapunov Functions, Control Barrier Functions, and robust Linear Programming. Our solution inherits many benefits of RRT*-like algorithms, such as the ability to implicitly handle arbitrarily complex obstacles. Additionally, it extends planning beyond the discrete nominal paths, as feedback controllers can correct deviations from such paths, and are robust to discrepancies between the planning and real environment maps. We test our algorithms first in simulations and then in experiments, evaluating the robustness of the approach to practical conditions, such as deformations of the environment, mismatches in the dynamical model of the robot, and measurements acquired with a camera with a limited field of view.",
        "primary_area": "",
        "author": "Mahroo Bahreinian;Marc Mitjans;Roberto Tron;Mahroo Bahreinian;Marc Mitjans;Roberto Tron",
        "authorids": "/37088337008;/37088997421;/37398528900;/37088337008;/37088997421;/37398528900",
        "aff": "Division of Systems Engineering, Boston University, Boston, MA, USA; Department of Mechanical Engineering, Boston University, Boston, MA, USA; Department of Mechanical and System Engineering",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636273/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11974981455571281877&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Boston University;Mechanical and System Engineering",
        "aff_unique_dep": "Division of Systems Engineering;Department of Mechanical and System Engineering",
        "aff_unique_url": "https://www.bu.edu;",
        "aff_unique_abbr": "BU;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boston;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "9635908",
        "title": "Robust and Accurate Point Set Registration with Generalized Bayesian Coherent Point Drift",
        "track": "main",
        "status": "Poster",
        "abstract": "Point set registration (PSR) is an essential problem in surgical navigation and image-guided surgery (IGS). It can help align the pre-operative volumetric images with the intra-operative surgical space. The performances of PSR are susceptible to noise and outliers, which are the cases in real-world surgical scenarios. In this paper, we provide a novel point set registration method that utilizes the features extracted from the PSs and can guarantee the convergence of the algorithm simultaneously. More specifically, we formulate the PSR with normal vectors by generalizing the bayesian coherent point drift (BCPD) into the six-dimension scenario. Our contributions can be summarized as follows. (1) The PSR problem with normal vectors is formulated by generalizing the Bayesian coherent point drift (BCPD) approach; (2) The updated parameters during the algorithm's iterations are given in closed-forms; (3) Extensive experiments have been done to verify the proposed approach and its significant improvements over the BCPD has been validated. We have validated our proposed registration approach on both the human femur model. Results demonstrate that our proposed method outperforms the state-of-the-art registration methods and the convergence is guaranteed at the same time.",
        "primary_area": "",
        "author": "Ang Zhang;Zhe Min;Jin Pan;Max Q.-H. Meng;Ang Zhang;Zhe Min;Jin Pan;Max Q.-H. Meng",
        "authorids": "/37087246928;/37086002886;/37087244420;/37274117000;/37087246928;/37086002886;/37087244420;/37274117000",
        "aff": "Department of Electronic Engineering, The Chinese University of Hong Kong N. T., Hong Kong SAR, China; Wellcome/EPSRC Centre for Surgical and Interventional Sciences, University College London, UK; Department of Electronic Engineering, The Chinese University of Hong Kong N. T., Hong Kong SAR, China; Shenzhen Research Institute, Chinese University of Hong Kong in Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635908/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2834862942042025843&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong;University College London",
        "aff_unique_dep": "Department of Electronic Engineering;Wellcome/EPSRC Centre for Surgical and Interventional Sciences",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.ucl.ac.uk",
        "aff_unique_abbr": "CUHK;UCL",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "N. T.;;Shenzhen",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9635886",
        "title": "Robust and Long-term Monocular Teach and Repeat Navigation using a Single-experience Map",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a robust monocular visual teach-and-repeat (VT&R) navigation system for long-term operation in outdoor environments. The approach leverages deep-learned descriptors to deal with the high illumination variance of the real world. In particular, a tailored self-supervised descriptor, DarkPoint, is proposed for autonomous navigation in outdoor environments. We seamlessly integrate the localisation with control, in which proportional\u2013integral control is used to eliminate the visual error with the pitfall of the unknown depth. Consequently, our approach achieves day-to-night navigation using a single-experience map and is able to repeat complex and fast manoeuvres. To verify our approach, we performed a vast array of navigation experiments in various outdoor environments, where both navigation accuracy and robustness of the proposed system are investigated. The experimental results show that our approach is superior to the baseline method with regards to accuracy and robustness.",
        "primary_area": "",
        "author": "Li Sun;Marwan Taher;Christopher Wild;Cheng Zhao;Yu Zhang;Filip Majer;Zhi Yan;Tom\u00e1\u0161 Krajn\u00edk;Tony Prescott;Tom Duckett;Li Sun;Marwan Taher;Christopher Wild;Cheng Zhao;Yu Zhang;Filip Majer;Zhi Yan;Tom\u00e1\u0161 Krajn\u00edk;Tony Prescott;Tom Duckett",
        "authorids": "/37086401506;/37089194936;/37089197115;/37085614336;/37089266256;/37086573530;/37086432956;/38547272600;/37297987600;/37419160900;/37086401506;/37089194936;/37089197115;/37085614336;/37089266256;/37086573530;/37086432956;/38547272600;/37297987600;/37419160900",
        "aff": "Sheffield Robotics, University of Sheffield, UK; Sheffield Robotics, University of Sheffield, UK; Sheffield Robotics, University of Sheffield, UK; Department of Engineering Science, University of Oxford, UK; Harbin Institute of Technology, China; Czech Technical University in Prague, Czech Republic; CIAD UMR7533, Univ. Bourgogne Franche-Comt\u00e9, UTBM, France; Czech Technical University in Prague, Czech Republic; Sheffield Robotics, University of Sheffield, UK; L-CAS, University of Lincoln, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635886/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3777844935578119706&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;1;2;3;4;3;0;5",
        "aff_unique_norm": "University of Sheffield;University of Oxford;Harbin Institute of Technology;Czech Technical University;University Bourgogne Franche-Comt\u00e9;University of Lincoln",
        "aff_unique_dep": "Sheffield Robotics;Department of Engineering Science;;;CIAD UMR7533;L-CAS",
        "aff_unique_url": "https://www.sheffield.ac.uk;https://www.ox.ac.uk;http://www.hit.edu.cn/;https://www.ctu.cz;;https://www.lincoln.ac.uk",
        "aff_unique_abbr": "Sheffield;Oxford;HIT;CTU;;UoL",
        "aff_campus_unique_index": "0;0;0;2;2;0",
        "aff_campus_unique": "Sheffield;;Prague",
        "aff_country_unique_index": "0;0;0;0;1;2;3;2;0;0",
        "aff_country_unique": "United Kingdom;China;Czech Republic;France"
    },
    {
        "id": "9636048",
        "title": "Robust and Recursively Feasible Real-Time Trajectory Planning in Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planners for mobile robots in unknown environments face the challenge of simultaneously maintaining both robustness against unmodeled uncertainties and persistent feasibility of the trajectory-finding problem. That is, while dealing with uncertainties, a motion planner must update its trajectory, adapting to the newly revealed environment in real-time; failing to do so may involve unsafe circumstances. Many existing planning algorithms guarantee these by maintaining the clearance needed to perform an emergency brake, which is itself a robust and persistently feasible maneuver. However, such maneuvers are not applicable for systems in which braking is impossible or risky, such as fixed-wing aircraft. To that end, we propose a real-time robust planner that recursively guarantees persistent feasibility without any need of braking. The planner ensures robustness against bounded uncertainties and persistent feasibility by constructing a loop of sequentially composed funnels, starting from the receding horizon local trajectory\u2019s forward reachable set. We implement the proposed algorithm for a robotic car tracking a speed-fixed reference trajectory. The experiment results show that the proposed algorithm can be run at faster than 16 Hz, while successfully keeping the system away from entering any dead end, to maintain safety and feasibility.",
        "primary_area": "",
        "author": "Inkyu Jang;Dongjae Lee;Seungjae Lee;H. Jin Kim;Inkyu Jang;Dongjae Lee;Seungjae Lee;H. Jin Kim",
        "authorids": "/37087499137;/37086933985;/37085999205;/37599626400;/37087499137;/37086933985;/37085999205;/37599626400",
        "aff": "Department of Aerospace Engineering, Automation and Systems Research Institute (ASRI), Seoul National University, Seoul, Korea; Department of Aerospace Engineering, Automation and Systems Research Institute (ASRI), Seoul National University, Seoul, Korea; Department of Aerospace Engineering, Automation and Systems Research Institute (ASRI), Seoul National University, Seoul, Korea; Department of Aerospace Engineering, Automation and Systems Research Institute (ASRI), Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636048/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10309631440856723783&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636800",
        "title": "Robust top-down and bottom-up visual saliency for mobile robots using bio-inspired design principles",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern camera systems in robotics tend to pro-duce overwhelming amounts of visual information due to their high resolutions and high frame rates. This raises a fundamental question of how robots should focus attention on a region of the visual scene, and how they should process information in the periphery. This is particularly an issue for mobile robots, where the computational resources of low-power embedded computing boards tend to be much less than for workstations. In this paper, we look to biological design in the primate brain for inspiration on how to solve this problem. We develop a novel computational fusion of bottom-up and top-down visual saliency information. The bottom-up saliency is produced using standard colour, intensity, and motion image processing methods. The top-down saliency is produced using a deep convolutional neural network for object detection and recognition, with foveated images for computational efficiency. Regions of attention are obtained using a computational model of the basal ganglia, thought to be involved in optimal decision making. The model of the basal ganglia is based on the multi-hypothesis sequential probability ratio test (MSPRT). The visual saliency scheme is evaluated on omnidirectional video feed highlighting a proximity to human behaviour.",
        "primary_area": "",
        "author": "Uziel Jaramillo-Avila;Jonathan M. Aitken;Kevin Gurney;Sean R. Anderson;Uziel Jaramillo-Avila;Jonathan M. Aitken;Kevin Gurney;Sean R. Anderson",
        "authorids": "/37087472775;/37085714075;/37297987800;/37393515000;/37087472775;/37085714075;/37297987800;/37393515000",
        "aff": "Department of Computer Science, Center for Mathematical Research, Zacateacas, Mexico; Department of Automatic Control and Systems Engineering, University of Sheffield, Sheffield, United Kingdom; Department of Psychology, University of Sheffield, Sheffield, United Kingdom; Department of Automatic Control and Systems Engineering, University of Sheffield, Sheffield, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636800/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:pGjHGveK-i0J:scholar.google.com/&scioq=Robust+top-down+and+bottom-up+visual+saliency+for+mobile+robots+using+bio-inspired+design+principles&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Center for Mathematical Research;University of Sheffield",
        "aff_unique_dep": "Department of Computer Science;Department of Automatic Control and Systems Engineering",
        "aff_unique_url": ";https://www.sheffield.ac.uk",
        "aff_unique_abbr": ";Sheffield",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Zacatecas;Sheffield",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Mexico;United Kingdom"
    },
    {
        "id": "9636358",
        "title": "Rough Terrain Navigation for Legged Robots using Reachability Planning and Template Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigation planning for legged robots has distinct challenges compared to wheeled and tracked systems due to the ability to lift legs off the ground and step over obstacles. While most navigation planners assume a fixed traversability value for a single terrain patch, we overcome this limitation by proposing a reachability-based navigation planner for legged robots. We approximate the robot morphology by a set of reachability and body volumes, assuming that the reachability volumes need to always be in contact with the environment, while the body should be contact-free. We train a convolutional neural network to predict foothold scores which are used to restrict geometries which are considered suitable to step on. Using this representation, we propose a navigation planner based on probabilistic roadmaps. Through validation of only low-cost graph edges during graph expansion and an adaptive sampling scheme based on roadmap node density, we achieve real-time performance with fast update rates even in cluttered and narrow environments. We thoroughly validate the proposed navigation planner in simulation and demonstrate its performance in real-world experiments on the quadruped ANYmal.",
        "primary_area": "",
        "author": "Lorenz Wellhausen;Marco Hutter;Lorenz Wellhausen;Marco Hutter",
        "authorids": "/37086200470;/37545251000;/37086200470;/37545251000",
        "aff": "Robotic Systems Lab, ETH Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636358/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9639041688135627920&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636805",
        "title": "Run Like a Dog: Learning Based Whole-Body Control Framework for Quadruped Gait Style Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a learning-based whole-body loco-motion controller is proposed, which enables quadruped robots to perform running in the style of real animals. We use a low-level controller based on multi-rigid body dynamics to calculate desired torques for each joint, while the high-level neural network policy planning the expected gait and foothold. The policy is trained with reinforcement learning, so that the robot can track a variety of trajectories according to the gait patterns recorded from real-world dogs. We transfer the walking and running gait style to quadrupeds in simulation, involving pace, trot, high-speed gallop and natural transitions. The performance is evaluated by the synchronization rate of contact state between the policy result and the recorded sequence. In the experiments, the robot runs steadily at a speed of 2 m/s and showcases a notable synchronization rate of about 80%. Without prior knowledge, the policy demonstrates a realistic foothold distribution that covers the central area of the torso, which is prevalent in running animals.",
        "primary_area": "",
        "author": "Fulong Yin;Annan Tang;Liangwei Xu;Yue Cao;Yu Zheng;Zhengyou Zhang;Xiangyu Chen;Fulong Yin;Annan Tang;Liangwei Xu;Yue Cao;Yu Zheng;Zhengyou Zhang;Xiangyu Chen",
        "authorids": "/37089194180;/37089194169;/37089196233;/37089197441;/37086993722;/37088690693;/37085704184;/37089194180;/37089194169;/37089196233;/37089197441;/37086993722;/37088690693;/37085704184",
        "aff": "School of Automation, Beihang University, Beijing, China; Department of Creative-Infomatics, JSK Lab, The University of Tokyo, Tokyo, Japan; Tencent, Shenzhen, China; Fu Foundation School of Engineering and Applied Science, Columbia University, New York, NY; Tencent, Shenzhen, China; Tencent, Shenzhen, China; Tencent, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636805/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4803623551124949715&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;3;2;2;2",
        "aff_unique_norm": "Beihang University;University of Tokyo;Tencent;Columbia University",
        "aff_unique_dep": "School of Automation;Department of Creative-Infomatics;Tencent;Fu Foundation School of Engineering and Applied Science",
        "aff_unique_url": "http://www.buaa.edu.cn;https://www.u-tokyo.ac.jp;https://www.tencent.com;https://www.columbia.edu",
        "aff_unique_abbr": "BUAA;UTokyo;Tencent;Columbia",
        "aff_campus_unique_index": "0;1;2;3;2;2;2",
        "aff_campus_unique": "Beijing;Tokyo;Shenzhen;New York",
        "aff_country_unique_index": "0;1;0;2;0;0;0",
        "aff_country_unique": "China;Japan;United States"
    },
    {
        "id": "9636377",
        "title": "SENSORIMOTOR GRAPH: Action-Conditioned Graph Neural Network for Learning Robotic Soft Hand Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robotics is a thriving branch of robotics which takes inspiration from nature and uses affordable flexible materials to design adaptable non-rigid robots. However, their flexible behavior makes these robots hard to model, which is essential for a precise actuation and for optimal control. For system modelling, learning-based approaches have demonstrated good results, yet they fail to consider the physical structure underlying the system as an inductive prior. In this work, we take inspiration from sensorimotor learning, and apply a Graph Neural Network to the problem of modelling a non-rigid kinematic chain (i.e. a robotic soft hand) taking advantage of two key properties: 1) the system is compositional, that is, it is composed of simple interacting parts connected by edges, 2) it is order invariant, i.e. only the structure of the system is relevant for predicting future trajectories. We denote our model as the \"Sensorimotor Graph\" since it learns the system connectivity from observation and uses it for dynamics prediction. We validate our model in different scenarios and show that it outperforms the non-structured baselines in dynamics prediction while being more robust to configurational variations, tracking errors or node failures.",
        "primary_area": "",
        "author": "Jo\u00e3o Dami\u00e3o Almeida;Paul Schydlo;Atabak Dehban;Jos\u00e9 Santos-Victor;Jo\u00e3o Dami\u00e3o Almeida;Paul Schydlo;Atabak Dehban;Jos\u00e9 Santos-Victor",
        "authorids": "/37089195615;/37086454013;/37085794792;/38274231800;/37089195615;/37086454013;/37085794792;/38274231800",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636377/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17790363343675009231&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9636723",
        "title": "SNE-RoadSeg+: Rethinking Depth-Normal Translation and Deep Supervision for Freespace Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Freespace detection is a fundamental component of autonomous driving perception. Recently, deep convolutional neural networks (DCNNs) have achieved impressive performance for this task. In particular, SNE-RoadSeg, our previously proposed method based on a surface normal estimator (SNE) and a data-fusion DCNN (RoadSeg), has achieved impressive performance in freespace detection. However, SNE-RoadSeg is computationally intensive, and it is difficult to execute in real time. To address this problem, we introduce SNE-RoadSeg+, an upgraded version of SNE-RoadSeg. SNE-RoadSeg+ consists of 1) SNE+, a module for more accurate surface normal estimation, and 2) RoadSeg+, a data-fusion DCNN that can greatly minimize the trade-off between accuracy and efficiency with the use of deep supervision. Extensive experimental results have demonstrated the effectiveness of our SNE+ for surface normal estimation and the superior performance of our SNE-RoadSeg+ over all other freespace detection approaches. Specifically, our SNE-RoadSeg+ runs in real time, and meanwhile, achieves the state-of-the-art performance on the KITTI road benchmark. Our project page is at https://www.sne-roadseg.site/sne-roadseg-plus.",
        "primary_area": "",
        "author": "Hengli Wang;Rui Fan;Peide Cai;Ming Liu;Hengli Wang;Rui Fan;Peide Cai;Ming Liu",
        "authorids": "/37086939511;/37085892666;/37087104388;/37085398677;/37086939511;/37085892666;/37087104388;/37085398677",
        "aff": "Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, China; Shanghai Research Institute for Intelligent Autonomous Systems, Shanghai, P. R. China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636723/",
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2695723603552867108&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Shanghai Research Institute for Intelligent Autonomous Systems",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;",
        "aff_unique_url": "https://www.ust.hk;",
        "aff_unique_abbr": "HKUST;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636076",
        "title": "SPHR: A Soft Pneumatic Hybrid Robot with extreme shape changing and lifting abilities",
        "track": "main",
        "status": "Poster",
        "abstract": "Many soft robots are capable of significantly changing their shape, an ability that can offer advantages in many applications. For instance, such a robot can flatten its body to fit under small gaps and expand to move over large obstacles. Further, because these shape changes are usually driven by a pressurized fluid, if they act over a large area, they have the potential to apply large forces to the world. However, when these same shape changes are used for the locomotion of an untethered robot, they tend to result in slow forward movement. Here we present a hybrid soft-rigid elongated-sphere robot that decouples shape change from locomotion. Pairing a compliant, inflatable outer skin, which changes volume by 15x to both fit under and roll over obstacles and can lift objects up to 30 kg, with a wheeled internal carriage, we obtain relatively fast locomotion. A new two-sided controllable adhesive between the internal carriage and the skin enables the carriage to climb vertically inside the skin, allowing the robot to climb external obstacles. We present the design of the robot, simple modeling of its behavior, and experimental testing. Our work advances the area of hybrid soft-rigid robotics by demonstrating how leveraging the strengths of both soft and rigid systems can have quantifiable performance benefits.",
        "primary_area": "",
        "author": "Matthew R. Devlin;Myia M. Dickens;Charles Xiao;Elliot W. Hawkes;Matthew R. Devlin;Myia M. Dickens;Charles Xiao;Elliot W. Hawkes",
        "authorids": "/37088687226;/37089196681;/37087322201;/37681388800;/37088687226;/37089196681;/37087322201;/37681388800",
        "aff": "Department of Mechanical Engineering, University of California, Santa Barbara, CA; Department of Mechanical and Aerospace Engineering, University of California Irvine, Irvine, CA; Department of Mechanical Engineering, University of California, Santa Barbara, CA; Department of Mechanical Engineering, University of California, Santa Barbara, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636076/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14738528925919781048&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of California, Santa Barbara;University of California, Irvine",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucsb.edu;https://www.uci.edu",
        "aff_unique_abbr": "UCSB;UCI",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Santa Barbara;Irvine",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635904",
        "title": "SSC: Semantic Scan Context for Large-Scale Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Place recognition gives a SLAM system the ability to correct cumulative errors. Unlike images that contain rich texture features, point clouds are almost pure geometric information which makes place recognition based on point clouds challenging. Existing works usually encode low-level features such as coordinate, normal, reflection intensity, etc., as local or global descriptors to represent scenes. Besides, they often ignore the translation between point clouds when matching descriptors. Different from most existing methods, we explore the use of high-level features, namely semantics, to improve the descriptor\u2019s representation ability. Also, when matching descriptors, we try to correct the translation between point clouds to improve accuracy. Concretely, we propose a novel global descriptor, Semantic Scan Context, which explores semantic information to represent scenes more effectively. We also present a two-step global semantic ICP to obtain the 3D pose (x, y, yaw) used to align the point cloud to improve matching performance. Our experiments on the KITTI dataset show that our approach outperforms the state-of-the- art methods with a large margin. Our code is available at: https://github.com/lilin-hitcrt/SSC.",
        "primary_area": "",
        "author": "Lin Li;Xin Kong;Xiangrui Zhao;Tianxin Huang;Wanlong Li;Feng Wen;Hongbo Zhang;Yong Liu;Lin Li;Xin Kong;Xiangrui Zhao;Tianxin Huang;Wanlong Li;Feng Wen;Hongbo Zhang;Yong Liu",
        "authorids": "/37088997380;/37087322070;/37087122595;/37089197863;/37088687641;/37088690190;/37859161500;/37066946100;/37088997380;/37087322070;/37087122595;/37089197863;/37088687641;/37088690190;/37859161500;/37066946100",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Huawei Noah\u2019s Ark Lab, Beijing, China; Huawei Noah\u2019s Ark Lab, Beijing, China; Huawei Noah\u2019s Ark Lab, Beijing, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635904/",
        "gs_citation": 110,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11656089398444785438&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;1;1;0",
        "aff_unique_norm": "Zhejiang University;Huawei",
        "aff_unique_dep": "Institute of Cyber-Systems and Control;Huawei Noah\u2019s Ark Lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.huawei.com/en/ai/noahs-ark-lab",
        "aff_unique_abbr": "ZJU;HNA Lab",
        "aff_campus_unique_index": "0;0;0;0;1;1;1;0",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636353",
        "title": "SSTN: Self-Supervised Domain Adaptation Thermal Object Detection for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "The perception of the environment plays a decisive role in the safe and secure operation of autonomous vehicles. The perception of the surrounding is way similar to human vision. The human\u2019s brain perceives the environment by utilizing different sensory channels and develop a view-invariant representation model. In this context, different exteroceptive sensors like cameras, Lidar, are deployed on the autonomous vehicle to perceive the environment. These sensors have illustrated their benefit in the visible spectrum domain yet in the adverse weather conditions; for instance, they have limited operational capability at night, leading to fatal accidents. This work explores thermal object detection to model a view-invariant model representation by employing the self-supervised contrastive learning approach. We have proposed a deep neural network Self Supervised Thermal Network (SSTN) for learning the feature embedding to maximize the information between visible and infrared spectrum domain by contrastive learning. Later, these learned feature representations are employed for thermal object detection using a multi-scale encoder-decoder transformer network. The proposed method is extensively evaluated on the two publicly available datasets: the FLIR-ADAS dataset and the KAIST Multi-Spectral dataset. The experimental results illustrate the efficacy of the proposed method.",
        "primary_area": "",
        "author": "Farzeen Munir;Shoaib Azam;Moongu Jeon;Farzeen Munir;Shoaib Azam;Moongu Jeon",
        "authorids": "/37086487125;/37086039500;/37666359200;/37086487125;/37086039500;/37666359200",
        "aff": "School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea; School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea; School of Electrical Engineering and Computer Science, Gwangju Institute of Science and Technology, Gwangju, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636353/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10557202588871638730&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Gwangju Institute of Science and Technology",
        "aff_unique_dep": "School of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.gist.ac.kr",
        "aff_unique_abbr": "GIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Gwangju",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636255",
        "title": "STFP: Simultaneous Traffic Scene Forecasting and Planning for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles must be able to understand the surrounding traffic flows and predict the future traffic conditions for planning a safe maneuver. During prediction, the action of autonomous vehicles should be considered, as it influences the interaction between vehicles sharing the same traffic scene and thus influences the future traffic flow. From this perspective, not only should the prediction be considered for planning, but also the action of autonomous vehicles generated by planning should be considered for traffic scene prediction. Therefore, prediction and planning must work interactively at every time step, considering results of each other. In this paper, we present a novel learning-based framework that simultaneously forecasts a nearby traffic scene and plans a maneuver of autonomous vehicle at every time step. Through experiments, we demonstrated that the proposed method exhibits better planning performance than baselines in complex traffic conditions involving various surrounding vehicles.",
        "primary_area": "",
        "author": "Chan Kim;Hyung-Suk Yoon;Seung-Woo Seo;Seong-Woo Kim;Chan Kim;Hyung-Suk Yoon;Seung-Woo Seo;Seong-Woo Kim",
        "authorids": "/37089001231;/37088689634;/37271925900;/37537386000;/37089001231;/37088689634;/37271925900;/37537386000",
        "aff": "Seoul National University, Seoul, South Korea; Seoul National University, Seoul, South Korea; Seoul National University, Seoul, South Korea; Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636255/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3051774753233389918&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9635984",
        "title": "Safe Continuous Control with Constrained Model-Based Policy Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "The applicability of reinforcement learning (RL) algorithms in real-world domains often requires adherence to safety constraints, a need difficult to address given the asymptotic nature of the classic RL optimization objective. In contrast to the traditional RL objective, safe exploration considers the maximization of expected returns under safety constraints expressed in expected cost returns. We introduce a model-based safe exploration algorithm for constrained high-dimensional control to address the often prohibitively high sample complexity of model-free safe exploration algorithms. Further, we provide theoretical and empirical analyses regarding the implications of model-usage on constrained policy optimization problems and introduce a practical algorithm that accelerates policy search with model-generated data. The need for accurate estimates of a policy\u2019s constraint satisfaction is in conflict with accumulating model-errors. We address this issue by quantifying model-uncertainty as the expected Kullback-Leibler divergence between predictions of an ensemble of probabilistic dynamics models and constrain this error-measure, resulting in an adaptive resampling scheme and dynamically limited rollout horizons. We evaluate this approach on several simulated constrained robot locomotion tasks with high-dimensional action- and state-spaces. Our empirical studies find that our algorithm reaches model-free performances with a 10-20 fold reduction of training samples while maintaining approximate constraint satisfaction levels of model-free methods.",
        "primary_area": "",
        "author": "Moritz A. Zanger;Karam Daaboul;J. Marius Z\u00f6llner;Moritz A. Zanger;Karam Daaboul;J. Marius Z\u00f6llner",
        "authorids": "/37089198125;/37089013527;/37085351468;/37089198125;/37089013527;/37085351468",
        "aff": "Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635984/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5436217400115227528&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636433",
        "title": "Safe Linear Temporal Logic Motion Planning in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an online control framework for mobile robots to satisfy a complex mission given in the form of linear temporal logic (LTL) without colliding with moving obstacles in the environment. The proposed framework consists of three modules named the static planner, the local collision avoidance, and the patcher. The static planner is synthesized by solving a parity game for a finite abstraction of the robot model based on a world map with static obstacles to fulfill the LTL task. The local collision avoidance module computes a set of safe controls that guarantees a safe distance between the moving objects. Both of the modules can be rigorously computed offline only once via formal methods. The patcher is activated whenever a moving obstacle is detected and modifies the static plan online for a short horizon by using only provably safe controls. The resulting modified strategy can guarantee collision-free motion without losing the ability to satisfy the LTL task. As opposed to using assume-guarantee type of LTL tasks, the proposed framework can handle the situations where obstacle movement is unpredictable.",
        "primary_area": "",
        "author": "Yinan Li;Ebrahim Moradi Shahrivar;Jun Liu;Yinan Li;Ebrahim Moradi Shahrivar;Jun Liu",
        "authorids": "/37085899014;/37704121700;/38488376400;/37085899014;/37704121700;/38488376400",
        "aff": "Department of Applied Mathematics, University of Waterloo, Waterloo, Canada; Clearpath Robotics, Inc., Kitchener, Canada; Department of Applied Mathematics, University of Waterloo, Waterloo, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636433/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18015225457446004190&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Waterloo;Clearpath Robotics, Inc.",
        "aff_unique_dep": "Department of Applied Mathematics;",
        "aff_unique_url": "https://uwaterloo.ca;https://www.clearpathrobotics.com",
        "aff_unique_abbr": "UW;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Waterloo;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636406",
        "title": "Safe Navigation in Human Occupied Environments Using Sampling and Control Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based methods such as Rapidly-exploring Random Trees (RRTs) have been widely used for generating motion paths for autonomous mobile systems. In this work, we extend time-based RRTs with Control Barrier Functions (CBFs) to generate, safe motion plans in dynamic environments with many pedestrians. Our framework is based upon a human motion prediction model which is well suited for indoor narrow environments. We demonstrate our approach on a high-fidelity model of the Toyota Human Support Robot navigating in narrow corridors. We show in simulation results that our proposed online method can navigate safely in the presence of moving agents with unknown dynamics.",
        "primary_area": "",
        "author": "Keyvan Majd;Shakiba Yaghoubi;Tomoya Yamaguchi;Bardh Hoxha;Danil Prokhorov;Georgios Fainekos;Keyvan Majd;Shakiba Yaghoubi;Tomoya Yamaguchi;Bardh Hoxha;Danil Prokhorov;Georgios Fainekos",
        "authorids": "/37086487572;/37085394673;/37088588957;/37085547165;/37298522000;/38529834400;/37086487572;/37085394673;/37088588957;/37085547165;/37298522000;/38529834400",
        "aff": "CIDSE, Arizona State University, Tempe, AZ, USA; Toyota Research Institute of North America, Ann Arbor, MI, USA; Toyota Research Institute of North America, Ann Arbor, MI, USA; Toyota Research Institute of North America, Ann Arbor, MI, USA; Toyota Research Institute of North America, Ann Arbor, MI, USA; CIDSE, Arizona State University, Tempe, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636406/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2117228518022077163&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;0",
        "aff_unique_norm": "Arizona State University;Toyota Research Institute of North America",
        "aff_unique_dep": "CIDSE;",
        "aff_unique_url": "https://www.asu.edu;https://www.tri-na.com",
        "aff_unique_abbr": "ASU;TRI-NA",
        "aff_campus_unique_index": "0;1;1;1;1;0",
        "aff_campus_unique": "Tempe;Ann Arbor",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636175",
        "title": "Safe Reinforcement Learning using Formal Verification for Tissue Retraction in Autonomous Robotic-Assisted Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Reinforcement Learning (DRL) is a viable solution for automating repetitive surgical subtasks due to its ability to learn complex behaviours in a dynamic environment. This task automation could lead to reduced surgeon\u2019s cognitive workload, increased precision in critical aspects of the surgery, and fewer patient-related complications. However, current DRL methods do not guarantee any safety criteria as they maximise cumulative rewards without considering the risks associated with the actions performed. Due to this limitation, the application of DRL in the safety-critical paradigm of robot-assisted Minimally Invasive Surgery (MIS) has been constrained. In this work, we introduce a Safe-DRL framework that incorporates safety constraints for the automation of surgical subtasks via DRL training. We validate our approach in a virtual scene that replicates a tissue retraction task commonly occurring in multiple phases of an MIS. Furthermore, to evaluate the safe behaviour of the robotic arms, we formulate a formal verification tool for DRL methods that provides the probability of unsafe configurations. Our results indicate that a formal analysis guarantees safety with high confidence such that the robotic instruments operate within the safe workspace and avoid hazardous interaction with other anatomical structures.",
        "primary_area": "",
        "author": "Ameya Pore;Davide Corsi;Enrico Marchesini;Diego Dall\u2019Alba;Alicia Casals;Alessandro Farinelli;Paolo Fiorini;Ameya Pore;Davide Corsi;Enrico Marchesini;Diego Dall\u2019Alba;Alicia Casals;Alessandro Farinelli;Paolo Fiorini",
        "authorids": "/37088506135;/37086805416;/37086805241;/38540860700;/37277266200;/37266396700;/37279139000;/37088506135;/37086805416;/37086805241;/38540860700;/37277266200;/37266396700;/37279139000",
        "aff": "Center of Research in Biomedical Engineering, Universitat Polit\u00e8cnica de Catalunya, Barcelona, Spain; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy; Center of Research in Biomedical Engineering, Universitat Polit\u00e8cnica de Catalunya, Barcelona, Spain; Department of Computer Science, University of Verona, Verona, Italy; Department of Computer Science, University of Verona, Verona, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636175/",
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=240103179099244152&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;0;1;1",
        "aff_unique_norm": "Universitat Polit\u00e8cnica de Catalunya;University of Verona",
        "aff_unique_dep": "Center of Research in Biomedical Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.upc.edu;https://www.univr.it",
        "aff_unique_abbr": "UPC;",
        "aff_campus_unique_index": "0;1;1;1;0;1;1",
        "aff_campus_unique": "Barcelona;Verona",
        "aff_country_unique_index": "0;1;1;1;0;1;1",
        "aff_country_unique": "Spain;Italy"
    },
    {
        "id": "9636268",
        "title": "Safe and Fast Path Planner for Minimally Invasive Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Path planning of a tool in Minimally Invasive Surgery (MIS) can provide assistance to the surgeons by giving solutions for faster and safe tool movements during the surgery. However, the main challenge in this problem is to address non-uniform tool shape for planning that can change due to the tool\u2019s dexterity. A typical robotic path planning approach by describing the robot\u2019s feasible movements using C-space is applied in this work. Unlike the robotic path planning problem, the C-space description capturing the movement does not give any closed-form solution due to high degree of freedom associated with the tool moved by human hands. Hence, an interval-based approach is used for describing the C-space. The proposed interval-based approach is capable of dividing the space into feasible and non-feasible intervals of different sizes which helps to reduce the search area and cover the obstacles in a refined manner. This paper presents collision-free and fast path computation using interval arithmetic between any two points in a 2D- surgical environment cluttered with obstacles for a surgical tool robot.",
        "primary_area": "",
        "author": "Shubhangi Nema;Leena Vachhani;Shubhangi Nema;Leena Vachhani",
        "authorids": "/37089194876;/37570418900;/37089194876;/37570418900",
        "aff": "Systems and Control Engineering Group, Indian Institute of Technology Bombay, Mumbai, India; Systems and Control Engineering Group, Indian Institute of Technology Bombay, Mumbai, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636268/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14066327433480216362&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Technology Bombay",
        "aff_unique_dep": "Systems and Control Engineering Group",
        "aff_unique_url": "https://www.iitb.ac.in",
        "aff_unique_abbr": "IIT Bombay",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Mumbai",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9636691",
        "title": "Safety-Oriented Pedestrian Occupancy Forecasting",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we address an important problem in self-driving, forecasting multi-pedestrian motion and their shared scene occupancy map, which is critical for safe navigation. Our contributions are two-fold. First, we advocate for predicting both the individual motions as well as the scene occupancy map in order to effectively deal with missing detections caused by postprocessing, e.g. confidence thresholding and non-maximum suppression. Second, we propose a Scene-Actor Graph Neural Network (SA-GNN) which captures the interactions among pedestrians within the same scene, including those that have not been detected, by preserving the relative spatial information of pedestrians via 2D convolution and via message passing. We show that our scene-occupancy predictions are more accurate than those from state-of-the-art motion forecasting methods, while also matching their performance in pedestrian motion forecasting metrics on two large-scale real-world datasets, nuScenes and ATG4D.",
        "primary_area": "",
        "author": "Katie Luo;Sergio Casas;Renjie Liao;Xinchen Yan;Yuwen Xiong;Wenyuan Zeng;Raquel Urtasun;Katie Luo;Sergio Casas;Renjie Liao;Xinchen Yan;Yuwen Xiong;Wenyuan Zeng;Raquel Urtasun",
        "authorids": "/37089017407;/37086821588;/37086272063;/37089015699;/37087234073;/37087234351;/37269502900;/37089017407;/37086821588;/37086272063;/37089015699;/37087234073;/37087234351;/37269502900",
        "aff": "Cornell University; University of Toronto; Google Brain; Waymo; University of Toronto; University of Toronto; University of Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636691/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4052066052495743920&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;3;1;1;1",
        "aff_unique_norm": "Cornell University;University of Toronto;Google;Waymo",
        "aff_unique_dep": ";;Google Brain;",
        "aff_unique_url": "https://www.cornell.edu;https://www.utoronto.ca;https://brain.google.com;https://www.waymo.com",
        "aff_unique_abbr": "Cornell;U of T;Google Brain;Waymo",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;1;0;0;1;1;1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9636093",
        "title": "Safety-oriented Teleoperation Framework for Contact-rich Tasks in Hazardous Workspaces",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an admittance controller-based teleoperation system for contact-rich tasks. Based on the analysis of the motivating task (deposited iron lump removal task in the steel mill), the system concept is focused on the practical aspects of the system, and various components are combined to enhance the safety of the teleoperation of the robot. To connect the large inertia difference between the teleoperated robot and the command device, the admittance control is utilized in the teleoperation system, and the virtual spring saturation is adapted with the damping injection to ensure safe motion during the task. Lastly, the inertia and damping adaptation rule based on the contact force frequency is developed so that the system can selectively dissipate energy when the system shows oscillatory behavior. The proposed techniques have shown their effectiveness through the experiments. Although this study has started from a specific target, it suggests a practical solution for various contact-rich teleoperated tasks in the hazardous industrial workspace.",
        "primary_area": "",
        "author": "Donghyeon Lee;Wan Kyun Chung;Keehoon Kim;Donghyeon Lee;Wan Kyun Chung;Keehoon Kim",
        "authorids": "/37677365900;/37280299100;/37066398600;/37677365900;/37280299100;/37066398600",
        "aff": "Robotics Laboratory, School of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea; Robotics Laboratory, School of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea; Medical Assistant Robotics and Cognitive Haptics (MARCH) Laboratory, School of Mechanical Engineering, Pohang University of Science and Technology (POSTECH), Gyeongbuk, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636093/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15381445643222219145&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Pohang University of Science and Technology",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.postech.ac.kr",
        "aff_unique_abbr": "POSTECH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pohang",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636536",
        "title": "Sample-efficient Reinforcement Learning Representation Learning with Curiosity Contrastive Forward Dynamics Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Developing an agent in reinforcement learning (RL) that is capable of performing complex control tasks directly from high-dimensional observation such as raw pixels is a challenge as efforts still need to be made towards improving sample efficiency and generalization of RL algorithm. This paper considers a learning framework for a Curiosity Contrastive Forward Dynamics Model (CCFDM) to achieve a more sample-efficient RL based directly on raw pixels. CCFDM incorporates a forward dynamics model (FDM) and performs contrastive learning to train its deep convolutional neural network-based image encoder (IE) to extract conducive spatial and temporal information to achieve a more sample efficiency for RL. In addition, during training, CCFDM provides intrinsic rewards, produced based on FDM prediction error, and encourages the curiosity of the RL agent to improve exploration. The diverge and less-repetitive observations provided by both our exploration strategy and data augmentation available in contrastive learning improve not only the sample efficiency but also the generalization . Performance of existing model-free RL methods such as Soft Actor-Critic built on top of CCFDM outperforms prior state-of-the-art pixel-based RL methods on the DeepMind Control Suite benchmark.",
        "primary_area": "",
        "author": "Thanh Nguyen;Tung M. Luu;Thang Vu;Chang D. Yoo;Thanh Nguyen;Tung M. Luu;Thang Vu;Chang D. Yoo",
        "authorids": "/37074974200;/37088835368;/37089198044;/37415340100;/37074974200;/37088835368;/37089198044;/37415340100",
        "aff": "Faculty of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Faculty of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Faculty of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Faculty of Electrical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636536/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3537545129014442860&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9635970",
        "title": "Sampling-Based MPC for Constrained Vision Based Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual servoing control schemes, such as Image-Based (IBVS), Pose Based (PBVS) or Hybrid-Based (HBVS) have been extensively developed over the last decades making possible their uses in a large number of applications. It is well-known that the main problems to be handled concern the presence of local minima or singularities, the visibility constraint, the joint limits, etc. Recently, Model Predictive Path Integral (MPPI) control algorithm has been developed for autonomous robot navigation tasks. In this paper, we propose a MPPI-VS framework applied for the control of a 6-DoF robot with 2D point, 3D point, and Pose Based Visual Servoing techniques. We performed intensive simulations under various operating conditions to show the potential advantages of the proposed control framework compared to the classical schemes. The effectiveness, the robustness and the capability in coping easily with the system constraints of the control framework are shown.",
        "primary_area": "",
        "author": "Ihab S. Mohamed;Guillaume Allibert;Philippe Martinet;Ihab S. Mohamed;Guillaume Allibert;Philippe Martinet",
        "authorids": "/37070644500;/38530776900;/37277258700;/37070644500;/38530776900;/37277258700",
        "aff": "Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA; Cnrs, Inria, I3S, Universit\u00e9 C\u00f4te d\u2019Azur, France; Inria, Cnrs, I3S, Universit\u00e9 C\u00f4te d\u2019Azur, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635970/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7768562871834765860&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Indiana University;Universit\u00e9 C\u00f4te d\u2019Azur;INRIA",
        "aff_unique_dep": "Luddy School of Informatics, Computing, and Engineering;;",
        "aff_unique_url": "https://www.indiana.edu;https://www.univ-cotedazur.fr;https://www.inria.fr",
        "aff_unique_abbr": "IU;UCA;Inria",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Bloomington;",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "9636672",
        "title": "Sampling-based Inverse Reinforcement Learning Algorithms with Safety Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning for robotic systems is frequently formulated as an optimization problem. Instead of manually tweaking the parameters of the cost function, they can be learned from human demonstrations by Inverse Reinforcement Learning (IRL). Common IRL approaches employ a maximum entropy trajectory distribution that can be learned with soft reinforcement learning, where the reward maximization is regularized with an entropy objective. The consideration of safety constraints is of paramount importance for human-robot collaboration. For this reason, our work addresses maximum entropy IRL in constrained environments. Our contribution to this research area is threefold: (1) We propose Constrained Soft Reinforcement Learning (CSRL), an extension of soft reinforcement learning to Constrained Markov Decision Processes (CMDPs). (2) We transfer maximum entropy IRL to CMDPs based on CSRL. (3) We show that using importance sampling in maximum entropy IRL in constrained environments introduces a bias and fails to achieve feature matching. In our evaluation we consider the tactical lane change decision of an autonomous vehicle in a highway scenario modeled in the SUMO traffic simulation.",
        "primary_area": "",
        "author": "Johannes Fischer;Christoph Eyberg;Moritz Werling;Martin Lauer;Johannes Fischer;Christoph Eyberg;Moritz Werling;Martin Lauer",
        "authorids": "/37089195294;/37089194845;/37542759200;/37082886500;/37089195294;/37089194845;/37542759200;/37082886500",
        "aff": "Institute of Measurement and Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Institute of Measurement and Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; BMWGroup, Unterschleissheim, Germany; Institute of Measurement and Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636672/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8094486253927995949&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology;BMW Group",
        "aff_unique_dep": "Institute of Measurement and Control Systems;",
        "aff_unique_url": "https://www.kit.edu;https://www.bmwgroup.com",
        "aff_unique_abbr": "KIT;BMW",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Karlsruhe;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636115",
        "title": "Sampson Distance: A New Approach to Improving Visual-Inertial Odometry's Accuracy",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a new scheme based on the Sampson distance (SD) to describe visual feature residuals for visual-inertial odometry (VIO). Unlike the epipolar-constraint-based SD for visual odometry (VO), the proposed SD is formulated based on the perspective projection constraint. We proved in theory that the proposed SD retains the good properties of those earlier SD criteria in the literature of VO and it represents a visual feature residual more accurately than the prevailing transfer distance (TD) in existing VIO methods. We formulate three distance criteria, including TD, reprojection error (RE), and SD, and compared their performances by simulation. The results show that the SD is much more accurate than the TD and it is a very accurate estimate of the gold standard criteria\u2014RE. Based on the SD, we modified VINS-Mono by replacing its TD-based visual residuals with the SD-based residuals and study the SD's efficacy in pose estimation by experiments with several public datasets. The results reveal that the SD-based VINS-Mono has a substantial improvement over the original VINS-Mono in pose estimation accuracy. This indicates that the SD is a better distance criterion than the TD for representing visual feature residuals. The proposed SD may find its applications to broader areas in computer vision and robotics.",
        "primary_area": "",
        "author": "He Zhang;Cang Ye;He Zhang;Cang Ye",
        "authorids": "/37086004148;/37291591400;/37086004148;/37291591400",
        "aff": "Computer Science Department, Virginia Commonwealth University, Richmond, VA, USA; Computer Science Department, Virginia Commonwealth University, Richmond, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636115/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1486917365344013627&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Virginia Commonwealth University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.vcu.edu",
        "aff_unique_abbr": "VCU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Richmond",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636729",
        "title": "Scalable Distributed Planning for Multi-Robot, Multi-Target Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "In multi-robot multi-target tracking, robots coordinate to monitor groups of targets moving about an environment. We approach planning for such scenarios by formulating a receding-horizon, multi-robot sensing problem with a mutual information objective. Such problems are NP-Hard in general. Yet, our objective is submodular which enables certain greedy planners to guarantee constant-factor suboptimality. However, these greedy planners require robots to plan their actions in sequence, one robot at a time, so planning time is at least proportional to the number of robots. Solving these problems becomes intractable for large teams, even for distributed implementations. Our prior work proposed a distributed planner (RSP) which reduces this number of sequential steps to a constant, even for large numbers of robots, by allowing robots to plan in parallel while ignoring some of each others\u2019 decisions. Although that analysis is not applicable to target tracking, we prove a similar guarantee, that RSP planning approaches performance guarantees for fully sequential planners, by employing a novel bound which takes advantage of the independence of target motions to quantify effective redundancy between robots\u2019 observations and actions. Further, we present analysis that explicitly accounts for features of practical implementations including approximations to the objective and anytime planning. Simulation results\u2014available via open source release\u2014for target tracking with ranging sensors demonstrate that our planners consistently approach the performance of sequential planning (in terms of position uncertainty) given only 2\u20138 planning steps and for as many as 96 robots with a 24x reduction in the number of sequential steps in planning. Thus, this work makes planning for multi-robot target tracking tractable at much larger scales than before, for practical planners and general tracking problems.",
        "primary_area": "",
        "author": "Micah Corah;Nathan Michael;Micah Corah;Nathan Michael",
        "authorids": "/37085594814;/37302499000;/37085594814;/37302499000",
        "aff": "NASA Jet Propulsion Laboratory (JPL), Pasadena, CA, USA; Robotics Institute, Carnegie Mellon University (CMU), Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636729/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6231386236775030899&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "NASA Jet Propulsion Laboratory;Carnegie Mellon University",
        "aff_unique_dep": ";Robotics Institute",
        "aff_unique_url": "https://jpl.nasa.gov;https://www.cmu.edu",
        "aff_unique_abbr": "JPL;CMU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Pasadena;Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636344",
        "title": "Scalable Reinforcement Learning Policies for Multi-Agent Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We develop a Multi-Agent Reinforcement Learning (MARL) method to learn scalable control policies for target tracking. Our method can handle an arbitrary number of pursuers and targets; we show results for tasks consisting up to 1000 pursuers tracking 1000 targets. We use a decentralized, partially-observable Markov Decision Process framework to model pursuers as agents receiving partial observations (range and bearing) about targets which move using fixed, unknown policies. An attention mechanism is used to parameterize the value function of the agents; this mechanism allows us to handle an arbitrary number of targets. Entropy-regularized off-policy RL methods are used to train a stochastic policy, and we discuss how it enables a hedging behavior between pursuers that leads to a weak form of cooperation in spite of completely decentralized control execution. We further develop a masking heuristic that allows training on smaller problems with few pursuers-targets and execution on much larger problems. Thorough simulation experiments and comparisons to state of the art algorithms are performed to study the scalability of the approach and robustness of performance to varying numbers of agents and targets.",
        "primary_area": "",
        "author": "Christopher D. Hsu;Heejin Jeong;George J. Pappas;Pratik Chaudhari;Christopher D. Hsu;Heejin Jeong;George J. Pappas;Pratik Chaudhari",
        "authorids": "/37089196812;/37087322449;/37281547100;/38113795600;/37089196812;/37087322449;/37281547100;/38113795600",
        "aff": "Department of Electrical & Systems Engineering and the GRASP Laboratory, University of Pennsylvania; Department of Electrical & Systems Engineering and the GRASP Laboratory, University of Pennsylvania; Department of Electrical & Systems Engineering and the GRASP Laboratory, University of Pennsylvania; Department of Electrical & Systems Engineering and the GRASP Laboratory, University of Pennsylvania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636344/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17182491984105993141&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Department of Electrical & Systems Engineering",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636576",
        "title": "Scene Descriptor Expressing Ambiguity in Information Recovery Based on Incomplete Partial Observation",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent studies, the widespread of deep learning has made many kinds of large-scale image datasets available and it has enabled to improve the performance of image-based 3-D scene reconstruction. Several studies estimate whole 3-D scenes including occluded or unseen parts consistent with the obtained partial observations by integrating prior knowledge from training datasets with them, under no camera parameters nor image landmark correspondence are known. Although they generate \u201cdiscrete\u201d scene instances, they cannot represent and treat their \u201cambiguity\u201d at all.This paper proposes a novel deep-learning-based framework that can directly represent and treat the ambiguity of scene reconstructions. We introduce a neural network which encodes a target scene as a descriptor. The network takes partial observations as input and outputs a parametric set of the scene descriptors containing all scenes consistent with given observations. The input observations may be \u201cincomplete\u201d in the sense that they do not have enough pieces of information to uniquely determine the whole scene due to neither geometry in-formation nor landmark correspondences available (ill-defined cases). The network is trained based on the dataset of the complete 3-D scenes and possible partial observations so that it can predict the unseen parts from incomplete observations. The paper introduces the method to induce such a descriptor space into the encoder/decoder architecture by employing novel definitions of loss functions measuring \u201cvalidity\u201d, \u201cconsistency\u201d and \u201creproducibility\u201d. When the series of partial and incom-plete observations for the same 3-D scene is obtained, the reconstruction ambiguity is explicitly treated by parametrically integrating the descriptor set for each observation into one descriptor set.",
        "primary_area": "",
        "author": "Takaaki Fukui;Tadashi Matsuo;Nobutaka Shimada;Takaaki Fukui;Tadashi Matsuo;Nobutaka Shimada",
        "authorids": "/37089195453;/38187189800;/37269959300;/37089195453;/38187189800;/37269959300",
        "aff": "Digital Frontier Inc.; Ritsumeikan University; Ritsumeikan University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636576/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:5gRn2b2DbncJ:scholar.google.com/&scioq=Scene+Descriptor+Expressing+Ambiguity+in+Information+Recovery+Based+on+Incomplete+Partial+Observation&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Digital Frontier Inc.;Ritsumeikan University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.digitalfrontier.com/;https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "DFI;Ritsumeikan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636032",
        "title": "Score refinement for confidence-based 3D multi-object tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-object tracking is a critical component in autonomous navigation, as it provides valuable information for decision-making. Many researchers tackled the 3D multi-object tracking task by filtering out the frame-by-frame 3D detections; however, their focus was mainly on finding useful features or proper matching metrics. Our work focuses on a neglected part of the tracking system: score refinement and tracklet termination. We show that manipulating the scores depending on time consistency while terminating the tracklets depending on the tracklet score improves tracking results. We do this by increasing the matched tracklets\u2019 score with score update functions and decreasing the unmatched tracklets\u2019 score. Compared to count-based methods, our method consistently produces better AMOTA and MOTA scores when utilizing various detectors and filtering algorithms on different datasets. The improvements in AMOTA score went up to 1.83 and 2.96 in MOTA. We also used our method as a late-fusion ensembling method, and it performed better than voting-based ensemble methods by a solid margin. It achieved an AMOTA score of 67.6 on nuScenes test evaluation, which is comparable to other state-of-the-art trackers. Code is publicly available at: https://github.com/cogsys-tuebingen/CBMOT.",
        "primary_area": "",
        "author": "Nuri Benbarka;Jona Schr\u00f6der;Andreas Zell;Nuri Benbarka;Jona Schr\u00f6der;Andreas Zell",
        "authorids": "/37088854264;/37089194366;/37276583400;/37088854264;/37089194366;/37276583400",
        "aff": "cognitive systems group, University of T\u00fcbingen, T\u00fcbingen, Germany; cognitive systems group, University of T\u00fcbingen, T\u00fcbingen, Germany; cognitive systems group, University of T\u00fcbingen, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636032/",
        "gs_citation": 80,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11345133201766085086&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of T\u00fcbingen",
        "aff_unique_dep": "cognitive systems group",
        "aff_unique_url": "https://www.uni-tuebingen.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636387",
        "title": "Search-based Path Planning for a High Dimensional Manipulator in Cluttered Environments Using Optimization-based Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we tackle the path planning problem for a 21-dimensional snake robot-like manipulator, navigating a cluttered gas turbine for the purposes of inspection. Heuristic search based approaches are effective planning strategies for common manipulation domains. However, their performance on high dimensional systems is heavily reliant on the effectiveness of the action space and the heuristics chosen. The complex nature of our system, reachability constraints, and highly cluttered turbine environment renders naive choices of action spaces and heuristics ineffective. To this extent we have developed i) a methodology for dynamically generating actions based on online optimization that help the robot navigate narrow spaces, ii) a technique for lazily generating these computationally expensive optimization actions to effectively utilize resources, and iii) heuristics that reason about the homotopy classes induced by the blades of the turbine in the robot workspace and a Multi-Heuristic framework which guides the search along the relevant classes. The impact of our contributions is presented through an experimental study in simulation, where the 21 DOF manipulator navigates towards regions of inspection within a turbine.",
        "primary_area": "",
        "author": "Muhammad Suhail Saleem;Raghav Sood;Sho Onodera;Rohit Arora;Hiroyuki Kanazawa;Maxim Likhachev;Muhammad Suhail Saleem;Raghav Sood;Sho Onodera;Rohit Arora;Hiroyuki Kanazawa;Maxim Likhachev",
        "authorids": "/37088999044;/37088689296;/37089195344;/37089197967;/37088077482;/37309318800;/37088999044;/37088689296;/37089195344;/37089197967;/37088077482;/37309318800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Machinery Research Department, Research and Innovation Center, Mitsubishi Heavy Industries, Japan; Machinery Research Department, Research and Innovation Center, Mitsubishi Heavy Industries, Japan; Machinery Research Department, Research and Innovation Center, Mitsubishi Heavy Industries, Japan; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636387/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5386401057049639537&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Mitsubishi Heavy Industries",
        "aff_unique_dep": "Robotics Institute;Machinery Research Department",
        "aff_unique_url": "https://www.cmu.edu;https://www.mhi.com",
        "aff_unique_abbr": "CMU;MHI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;1;1;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9636405",
        "title": "Search-based Planning with Learned Behaviors for Navigation among Pedestrians",
        "track": "main",
        "status": "Poster",
        "abstract": "Agent control among pedestrians is often approached in one of the three following ways: using predefined behaviors for agent navigation, learning navigation behaviors from data, or search-based planning on a graph where each edge is a feasible action chosen from a set of predefined actions. While the first approach often produces natural looking motions and the second learns and utilizes complex interactions with pedestrians, both lack global reasoning about how to sequence these behaviors to achieve the overall goal. The third approach, namely search-based planning, does incorporate global reasoning but relies on predefined actions that do not involve any interactions with pedestrians or assume predefined interactions that cannot model complex interactions. This is a significant drawback since many situations such as going through a doorway blocked by other people require complex interactions in order to avoid highly suboptimal behaviors or not being able to get to the goal at all. To this end, we propose a search-based planning framework that constructs and searches a graph wherein each edge can be either a predefined action or a learned behavior. We further extend it to deal with the uncertainty arising from introducing learned behaviors. We present the algorithm, go over its theoretical analysis, and present experimental results.",
        "primary_area": "",
        "author": "Ishani Chatterjee;Yash Oza;Maxim Likhachev;Manuela Veloso;Ishani Chatterjee;Yash Oza;Maxim Likhachev;Manuela Veloso",
        "authorids": "/37089267445;/839624040602928;/37309318800;/37274032100;/37089267445;/839624040602928;/37309318800;/37274032100",
        "aff": "School of Computer Science, Carnegie Mellon University, USA; School of Computer Science, Carnegie Mellon University, USA; School of Computer Science, Carnegie Mellon University, USA; School of Computer Science, Carnegie Mellon University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636405/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6364162528009650107&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636440",
        "title": "Seeing All the Angles: Learning Multiview Manipulation Policies for Contact-Rich Tasks from Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "Learned visuomotor policies have shown considerable success as an alternative to traditional, hand-crafted frameworks for robotic manipulation. Surprisingly, an extension of these methods to the multiview domain is relatively unexplored. A successful multiview policy could be deployed on a mobile manipulation platform, allowing the robot to complete a task regardless of its view of the scene. In this work, we demonstrate that a multiview policy can be found through imitation learning by collecting data from a variety of viewpoints. We illustrate the general applicability of the method by learning to complete several challenging multi-stage and contact-rich tasks, from numerous viewpoints, both in a simulated environment and on a real mobile manipulation platform. Furthermore, we analyze our policies to determine the benefits of learning from multiview data compared to learning with data collected from a fixed perspective. We show that learning from multiview data results in little, if any, penalty to performance for a fixed-view task compared to learning with an equivalent amount of fixed-view data. Finally, we examine the visual features learned by the multiview and fixed-view policies. Our results indicate that multiview policies implicitly learn to identify spatially correlated features.",
        "primary_area": "",
        "author": "Trevor Ablett;Yifan Zhai;Jonathan Kelly;Trevor Ablett;Yifan Zhai;Jonathan Kelly",
        "authorids": "/37086453021;/37089195996;/37085364182;/37086453021;/37089195996;/37085364182",
        "aff": "Space & Terrestrial Autonomous Robotic Systems (STARS) Laboratory, University of Toronto Institute for Aerospace Studies (UTIAS), Toronto, Canada; Space & Terrestrial Autonomous Robotic Systems (STARS) Laboratory, University of Toronto Institute for Aerospace Studies (UTIAS), Toronto, Canada; Space & Terrestrial Autonomous Robotic Systems (STARS) Laboratory, University of Toronto Institute for Aerospace Studies (UTIAS), Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636440/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8979498887113284542&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Toronto Institute for Aerospace Studies",
        "aff_unique_dep": "Space & Terrestrial Autonomous Robotic Systems (STARS) Laboratory",
        "aff_unique_url": "https://www.ias.utoronto.ca",
        "aff_unique_abbr": "UTIAS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636310",
        "title": "Self Attention Guided Depth Completion using RGB and Sparse LiDAR Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of completing per pixel dense depth map using a single RGB image and the sparse point cloud of the scene. Depth prediction from RGB image is a hard problem and while dense point clouds obtained from LiDAR sensors can be used in addition to RGB image, the cost of such sensors is a significant barrier. Having LiDAR sensors which capture sparse point clouds is a reasonable middle ground. We propose a novel architecture which incorporates geometric primitives and self attention mechanisms, to improve the prediction. The motivation of self attention is to capture the correlations between scene and object elements, e.g. between the right and left window of car, early on in the network. While that for using geometric primitives is to have a high level clustering cue to enable the network to exploit similar correlations. In addition, we enforce complimentarity in the predictions made with RGB and sparse LiDAR respectively, this forces the two corresponding branches to focus on hard areas which are not already well predicted by the other branch. With exhaustive experiments on KITTI depth completion benchmark, NYU v2 and Matterport3D we show that the proposed method provides state-of-the-art results.",
        "primary_area": "",
        "author": "Siddharth Srivastava;Gaurav Sharma;Siddharth Srivastava;Gaurav Sharma",
        "authorids": "/37085783892;/37274173200;/37085783892;/37274173200",
        "aff": "Siddharth Srivastava is With Centre for Development of Advanced Computing, Noida, India; TensorTour Inc. and IIT Kanpur",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636310/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2841358661935468666&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Centre for Development of Advanced Computing;TensorTour Inc.",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://tensortour.com",
        "aff_unique_abbr": ";TensorTour",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "9636525",
        "title": "Self-Balancing Online Dataset for Incremental Driving Intelligence",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous driving with imitation learning is vulnerable to the quality of an expert dataset. Typical driving involves situations or online data that are biased toward specific scenarios such as lane following or stop. This property causes an imbalance in the driving dataset, and it is highly likely to deteriorate the performance of autonomous driving with imitation learning. In this paper, we propose a dataset self-balancing system with biased online data and an imbalanced dataset. By estimating the probability distribution of a dataset, we compute the probability and novelty of online data and then filter only qualified novel data. In addition, using the computed probability distribution, we determine the data that are non-informative in the current dataset and then exchange them with novel online data. At last, by retraining the driving neural network with high-entropy data batches, our method achieves incremental driving intelligence. We demonstrated the effectiveness of our method through open-loop evaluation and ablation studies in a CARLA simulator; the results show that our proposed system effectively balances the dataset with 100 scenarios and decreases test loss over time.",
        "primary_area": "",
        "author": "Hyung-Suk Yoon;Chan Kim;Seong-Woo Kim;Seung-Woo Seo;Hyung-Suk Yoon;Chan Kim;Seong-Woo Kim;Seung-Woo Seo",
        "authorids": "/37088689634;/37089001231;/37537386000;/37271925900;/37088689634;/37089001231;/37537386000;/37271925900",
        "aff": "Department of Electrical and Computer Engineering, Seoul National University, Korea; Department of Electrical and Computer Engineering, Seoul National University, Korea; Department of Electrical and Computer Engineering, Seoul National University, Korea; Department of Electrical and Computer Engineering, Seoul National University, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636525/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2491532395696394897&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636493",
        "title": "Self-Contained Kinematic Calibration of a Novel Whole-Body Artificial Skin for Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an accelerometer-based kinematic calibration algorithm to accurately estimate the pose of multiple sensor units distributed along a robot body. Our approach is self-contained, can be used on any robot provided with a Denavit-Hartenberg kinematic model, and on any skin equipped with Inertial Measurement Units (IMUs). To validate the proposed method, we first conduct extensive experimentation in simulation and demonstrate a sub-cm positional error from ground truth data\u2014an improvement of six times with respect to prior work; subsequently, we then perform a real-world evaluation on a seven degrees-of-freedom collaborative platform. For this purpose, we additionally introduce a novel design for a stand-alone artificial skin equipped with an IMU for use with the proposed algorithm and a proximity sensor for sensing distance to nearby objects. In conclusion, in this work, we demonstrate seamless integration between a novel hardware design, an accurate calibration method, and preliminary work on applications: the high positional accuracy effectively enables to locate distributed proximity data and allows for a distributed avoidance controller to safely avoid obstacles and people without the need of additional sensing.",
        "primary_area": "",
        "author": "Kandai Watanabe;Matthew Strong;Mary West;Caleb Escobedo;Ander Aramburu;Krishna Chaitanya Kodur;Alessandro Roncone;Kandai Watanabe;Matthew Strong;Mary West;Caleb Escobedo;Ander Aramburu;Krishna Chaitanya Kodur;Alessandro Roncone",
        "authorids": "/37089198237;/37088852557;/37089195452;/37089195404;/37089194905;/37085847070;/37085343755;/37089198237;/37088852557;/37089195452;/37089195404;/37089194905;/37085847070;/37085343755",
        "aff": "Computer Science Department, Human Interaction and RObotics (HIRO) Group, University of Colorado, Boulder, CO, USA; Computer Science Department, Human Interaction and RObotics (HIRO) Group, University of Colorado, Boulder, CO, USA; Computer Science Department, Human Interaction and RObotics (HIRO) Group, University of Colorado, Boulder, CO, USA; Computer Science Department, Human Interaction and RObotics (HIRO) Group, University of Colorado, Boulder, CO, USA; Computer Science Department, Human Interaction and RObotics (HIRO) Group, University of Colorado, Boulder, CO, USA; Heracleia Human-Centered Computing Lab, University of Texas at Arlington, Arlington, TX, USA; Computer Science Department, Human Interaction and RObotics (HIRO) Group, University of Colorado, Boulder, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636493/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17766863621492416781&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "University of Colorado;University of Texas at Arlington",
        "aff_unique_dep": "Computer Science Department;Heracleia Human-Centered Computing Lab",
        "aff_unique_url": "https://www.colorado.edu;https://www.uta.edu",
        "aff_unique_abbr": "CU;UTA",
        "aff_campus_unique_index": "0;0;0;0;0;1;0",
        "aff_campus_unique": "Boulder;Arlington",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635889",
        "title": "Self-Reconfiguration of Modular Robots Using Virtual Forces",
        "track": "main",
        "status": "Poster",
        "abstract": "Programmable matter is a material that can change its physical properties at will, whether it is its shape, density or conductivity. It can be implemented as an ensemble of micro-robots arranged in space to form a specific shape and having their own computing power. This technology behaves as a distributed system. Each micro-robot is called a module and the whole forms a modular robot. This paper tackles the self-reconfiguration problem by presenting a deterministic planning algorithm that can decide which positions can be filled over multiple iterations using virtual forces. The proposed algorithm implements the Hungarian method to optimize the planning by minimizing the total number of movements of the robots and preventing positions from being blocked. Each module embeds the same algorithm and coordinates with the others using neighbor-to-neighbor communications. Simulation results are conducted to show the effectiveness of the proposed approach.",
        "primary_area": "",
        "author": "Edy Hourany;Christian Stephan;Abdallah Makhoul;Benoit Piranda;Bachir Habib;Julien Bourgeois;Edy Hourany;Christian Stephan;Abdallah Makhoul;Benoit Piranda;Bachir Habib;Julien Bourgeois",
        "authorids": "/37089198162;/37089193942;/37300200900;/38340189300;/37948261200;/37545876400;/37089198162;/37089193942;/37300200900;/38340189300;/37948261200;/37545876400",
        "aff": "Univ. Bourgogne Franche-Comt\u00e9, FEMTO-ST Institute, CNRS, Montb\u00e9liard, France; Univ. Bourgogne Franche-Comt\u00e9, FEMTO-ST Institute, CNRS, Montb\u00e9liard, France; Univ. Bourgogne Franche-Comt\u00e9, FEMTO-ST Institute, CNRS, Montb\u00e9liard, France; Univ. Bourgogne Franche-Comt\u00e9, FEMTO-ST Institute, CNRS, Montb\u00e9liard, France; Department of Computer Science, Holy Spirit University of Kaslik, Jounieh, Lebanon; Univ. Bourgogne Franche-Comt\u00e9, FEMTO-ST Institute, CNRS, Montb\u00e9liard, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635889/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2003923015096621421&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Universit\u00e9 Bourgogne Franche-Comt\u00e9;Holy Spirit University of Kaslik",
        "aff_unique_dep": "FEMTO-ST Institute;Department of Computer Science",
        "aff_unique_url": "https://www.ubfc.fr;",
        "aff_unique_abbr": "UBFC;",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Montb\u00e9liard;Jounieh",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "France;Lebanon"
    },
    {
        "id": "9636363",
        "title": "Self-Supervised Disentangled Representation Learning for Third-Person Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans learn to imitate by observing others. However, robot imitation learning generally requires expert demonstrations in the first-person view (FPV). Collecting such FPV videos for every robot could be very expensive.Third-person imitation learning (TPIL) is the concept of learning action policies by observing other agents in a third-person view (TPV), similar to what humans do. This ultimately allows utilizing human and robot demonstration videos in TPV from many different data sources, for the policy learning. In this paper, we present a TPIL approach for robot tasks with egomotion. Although many robot tasks with ground/aerial mobility often involve actions with camera egomotion, study on TPIL for such tasks has been limited. Here, FPV and TPV observations are visually very different; FPV shows egomotion while the agent appearance is only observable in TPV. To enable better state learning for TPIL, we propose our disentangled representation learning method. We use a dual auto-encoder structure plus representation permutation loss and time-contrastive loss to ensure the state and viewpoint representations are well disentangled. Our experiments show the effectiveness of our approach.",
        "primary_area": "",
        "author": "Jinghuan Shang;Michael S. Ryoo;Jinghuan Shang;Michael S. Ryoo",
        "authorids": "/37089194040;/37397559800;/37089194040;/37397559800",
        "aff": "Department of Computer Science, Stony Brook University, Stony Brook, NY, USA; Department of Computer Science, Stony Brook University, Stony Brook, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636363/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14806589771971591187&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stony Brook University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.stonybrook.edu",
        "aff_unique_abbr": "SBU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stony Brook",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636020",
        "title": "Self-Supervised Online Reward Shaping in Sparse-Reward Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce Self-supervised Online Reward Shaping (SORS), which aims to improve the sample efficiency of any RL algorithm in sparse-reward environments by automatically densifying rewards. The proposed framework alternates between classification-based reward inference and policy update steps\u2014the original sparse reward provides a self-supervisory signal for reward inference by ranking trajectories that the agent observes, while the policy update is performed with the newly inferred, typically dense reward function. We introduce theory that shows that, under certain conditions, this alteration of the reward function will not change the optimal policy of the original MDP, while potentially increasing learning speed significantly. Experimental results on several sparse-reward environments demonstrate that, across multiple domains, the proposed algorithm is not only significantly more sample efficient than a standard RL baseline using sparse rewards, but, at times, also achieves similar sample efficiency compared to when hand-designed dense reward functions are used.",
        "primary_area": "",
        "author": "Farzan Memarian;Wonjoon Goo;Rudolf Lioutikov;Scott Niekum;Ufuk Topcu;Farzan Memarian;Wonjoon Goo;Rudolf Lioutikov;Scott Niekum;Ufuk Topcu",
        "authorids": "/37088650842;/37086935816;/37085362450;/37395003900;/37299604900;/37088650842;/37086935816;/37085362450;/37395003900;/37299604900",
        "aff": "Oden Institute for Computational Engineering and Sciences, University of Texas, Austin, TX, USA; Personal Autonomous Robotics Lab (PeARL), The University of Texas, Austin, TX, USA; Intuitive Robots Lab, Karlsruhe Institut of Technology, Germany; Personal Autonomous Robotics Lab (PeARL), The University of Texas, Austin, TX, USA; Department of Aerospace Engineering and Engineering Mechanics, University of Texas, Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636020/",
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16866400156917914137&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Texas at Austin;Karlsruhe Institute of Technology",
        "aff_unique_dep": "Oden Institute for Computational Engineering and Sciences;Intuitive Robots Lab",
        "aff_unique_url": "https://www.utexas.edu;https://www.kit.edu",
        "aff_unique_abbr": "UT Austin;KIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "9635975",
        "title": "Self-Supervised Optical Flow with Spiking Neural Networks and Event Based Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "Optical flow can be leveraged in robotic systems for obstacle detection where low latency solutions are critical in highly dynamic settings. While event-based cameras have changed the dominant paradigm of sending by encoding stimuli into spike trails, offering low bandwidth and latency, events are still processed with traditional convolutional networks in GPUs defeating, thus, the promise of efficient low capacity low power processing that inspired the design of event sensors. In this work, we introduce a shallow spiking neural network for the computation of optical flow consisting of Leaky Integrate and Fire neurons.Optical flow is predicted as the synthesis of motion orientation selective channels. Learning is accomplished by Back-propapagation Through Time. We present promising results on events recorded in real \"in the wild\" scenes that has the capability to use only a small fraction of the energy consumed in CNNs deployed on GPUs.",
        "primary_area": "",
        "author": "Kenneth Chaney;Artemis Panagopoulou;Chankyu Lee;Kaushik Roy;Kostas Daniilidis;Kenneth Chaney;Artemis Panagopoulou;Chankyu Lee;Kaushik Roy;Kostas Daniilidis",
        "authorids": "/37087230389;/37089197188;/37086494899;/37274519700;/37270623200;/37087230389;/37089197188;/37086494899;/37274519700;/37270623200",
        "aff": "University of Pennsylvania; University of Pennsylvania; Purdue University; Purdue University; University of Pennsylvania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635975/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4338101828999529740&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "University of Pennsylvania;Purdue University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.upenn.edu;https://www.purdue.edu",
        "aff_unique_abbr": "UPenn;Purdue",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635938",
        "title": "Self-Supervised Scale Recovery for Monocular Depth and Egomotion Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "The self-supervised loss formulation for jointly training depth and egomotion neural networks with monocular images is well studied and has demonstrated state-of-the-art accuracy. One of the main limitations of this approach, however, is that the depth and egomotion estimates are only determined up to an unknown scale. In this paper, we present a novel scale recovery loss that enforces consistency between a known camera height and the estimated camera height, generating metric (scaled) depth and egomotion predictions. We show that our proposed method is competitive with other scale recovery techniques that require more information. Further, we demonstrate that our method facilitates network retraining within new environments, whereas other scale-resolving approaches are incapable of doing so. Notably, our egomotion network is able to produce more accurate estimates than a similar method which recovers scale at test time only.",
        "primary_area": "",
        "author": "Brandon Wagstaff;Jonathan Kelly;Brandon Wagstaff;Jonathan Kelly",
        "authorids": "/37086213378;/37085364182;/37086213378;/37085364182",
        "aff": "Space & Terrestrial Autonomous Robotic Systems (STARS) Laboratory, University of Toronto Institute for Aerospace Studies (UTIAS), Toronto, Ontario, Canada; Space & Terrestrial Autonomous Robotic Systems (STARS) Laboratory, University of Toronto Institute for Aerospace Studies (UTIAS), Toronto, Ontario, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635938/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6701093635944149014&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Toronto Institute for Aerospace Studies",
        "aff_unique_dep": "Space & Terrestrial Autonomous Robotic Systems (STARS) Laboratory",
        "aff_unique_url": "https://www.ias.utoronto.ca",
        "aff_unique_abbr": "UTIAS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636505",
        "title": "Self-calibrated dense 3D sensor using multiple cross line-lasers based on light sectioning method and visual odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Among various 3D capturing systems, since the system with line lasers based on the light sectioning method is simple and accurate, it has widely attracted many developers and used for many purposes. In addition, there is no need to synchronize the camera and the laser and also the configuration of the camera and the lasers is flexible, and thus, the system can be used for extreme conditions, such as underwater. There are two open problems for the system. The first problem is a low density of the 3D shape obtained from a single image, i.e., just several curves. The second problem is the accuracy of line detection in the wild. In this paper, we propose a self-calibration method using visual odometry (VO) to bundle a large number of frames to increase the density to solve the first problem. We also propose a robust line detection algorithm using CNN to solve the second problem. Comparative experiments prove the effectiveness of our proposed method. In addition, the system was tested in the extreme condition for demonstration.",
        "primary_area": "",
        "author": "Genki Nagamatsu;Jun Takamatsu;Takafumi Iwaguchi;Diego Thomas;Hiroshi Kawasaki;Genki Nagamatsu;Jun Takamatsu;Takafumi Iwaguchi;Diego Thomas;Hiroshi Kawasaki",
        "authorids": "/37086883922;/37324010500;/37086084376;/37086122204;/37270111600;/37086883922;/37324010500;/37086084376;/37086122204;/37270111600",
        "aff": "Department of Advanced Information Technology, Kyushu University, Japan; Graduate School of Information Science, Nara Institute of Science and Technology; Department of Advanced Information Technology, Kyushu University, Japan; Department of Advanced Information Technology, Kyushu University, Japan; Department of Advanced Information Technology, Kyushu University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636505/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2395883505022234362&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Kyushu University;Nara Institute of Science and Technology",
        "aff_unique_dep": "Department of Advanced Information Technology;Graduate School of Information Science",
        "aff_unique_url": "https://www.kyushu-u.ac.jp;https://www.nist.go.jp",
        "aff_unique_abbr": "Kyushu U;NIST",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Nara",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636641",
        "title": "Self-critical Learning of Influencing Factors for Trajectory Prediction using Gated Graph Convolutional Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Forecasting future trajectories of multiple pedestrians in a crowded environment is a challenging problem due to the complex interactions among the pedestrians. The interactions can be asymmetric and their influences may vary over time. Moreover, each pedestrian can exhibit different behavior at any given time and context and thus they may have multiple future possible trajectories. In this work, we present a Gated Graph Convolutional Network (GatedGCN) based trajectory prediction model that explicitly deal with the asymmetric influences among the adjacent pedestrians through edge-wise gating mechanism. Through GatedGCN only, an overall average improvement of 16% and 18% was achieved on the two performance metrics over the state-of-the-art trajectory forecasting methods. Next, we tackle the problem of learning multi-modal distributions of each pedestrian trajectory using variational auto-encoders (VAEs). However, trajectories sampled from the learned distribution usually ignore the factors affecting the pedestrian motion such as collision avoidance and the target destination. While many of the existing approaches focus on learning such factors during the trajectory encoding process, we proposed a novel self-critical learning approach based on Actor-Critic framework to learn such factors during the trajectory generation process. We empirically show that our method creates fewer number of collisions than the existing methods on popular trajectory forecasting benchmarks.",
        "primary_area": "",
        "author": "Niraj Bhujel;Yau Wei Yun;Han Wang;Vijay Prakash Dwivedi;Niraj Bhujel;Yau Wei Yun;Han Wang;Vijay Prakash Dwivedi",
        "authorids": "/37087002903;/37086263465;/37292552600;/37088267571;/37087002903;/37086263465;/37292552600;/37088267571",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Institute for Infocomm Research, A*STAR, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636641/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4740512322975049706&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Nanyang Technological University;Institute for Infocomm Research",
        "aff_unique_dep": "School of Electrical and Electronic Engineering;",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.i2r.a-star.edu.sg",
        "aff_unique_abbr": "NTU;I2R",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9635964",
        "title": "SemAlign: Annotation-Free Camera-LiDAR Calibration with Semantic Alignment Loss",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-sensor solution has been widely adopted in real-world robotics systems (e.g., self-driving vehicles) due to its better robustness. However, its performance is highly dependent on the accurate calibration between different sensors, which is very time-consuming (i.e., hours of human efforts) to acquire. Recent learning-based solutions partially address this yet still require costly ground-truth annotations as supervision. In this paper, we introduce a novel self-supervised semantic alignment loss to quantitatively measure the quality of a given calibration. It is well correlated with conventional evaluation metrics while it does not require ground-truth calibration annotations as the reference. Based on this loss, we further propose an annotation-free optimization-based calibration algorithm (SemAlign) that first estimates a coarse calibration with loss-guided initialization and then refines it with gradient-based optimization. SemAlign reduces the calibration time from hours of human efforts to only seconds of GPU computation. It not only achieves comparable performance with existing supervised learning frameworks but also demonstrates a much better generalization capability when transferred to a different dataset.",
        "primary_area": "",
        "author": "Zhijian Liu;Haotian Tang;Sibo Zhu;Song Han;Zhijian Liu;Haotian Tang;Sibo Zhu;Song Han",
        "authorids": "/37087231394;/37089195801;/37088687809;/37086460117;/37087231394;/37089195801;/37088687809;/37086460117",
        "aff": "Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA; Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635964/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4544617886718251571&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636156",
        "title": "SemSegMap \u2013 3D Segment-based Semantic Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Localization is an essential task for mobile autonomous robotic systems that want to use pre-existing maps or create new ones in the context of SLAM. Today, many robotic platforms are equipped with high-accuracy 3D LiDAR sensors, which allow a geometric mapping, and cameras able to provide semantic cues of the environment. Segment-based mapping and localization have been applied with great success to 3D point-cloud data, while semantic understanding has been shown to improve localization performance in vision based systems. In this paper we combine both modalities in SemSegMap, extending SegMap into a segment based mapping framework able to also leverage color and semantic data from the environment to improve localization accuracy and robustness. In particular, we present new segmentation and descriptor extraction processes. The segmentation process benefits from additional distance information from color and semantic class consistency resulting in more repeatable segments and more overlap after re-visiting a place. For the descriptor, a tight fusion approach in a deep-learned descriptor extraction network is performed leading to a higher descriptiveness for landmark matching. We demonstrate the advantages of this fusion on multiple simulated and real-world datasets and compare its performance to various baselines. We show that we are able to find 50.9 % more high-accuracy prior-less global localizations compared to SegMap on challenging datasets using very compact maps while also providing accurate full 6 DoF pose estimates in real-time.",
        "primary_area": "",
        "author": "Andrei Cramariuc;Florian Tschopp;Nikhilesh Alatur;Stefan Benz;Tillmann Falck;Marius Br\u00fchlmeier;Benjamin Hahn;Juan Nieto;Roland Siegwart;Andrei Cramariuc;Florian Tschopp;Nikhilesh Alatur;Stefan Benz;Tillmann Falck;Marius Br\u00fchlmeier;Benjamin Hahn;Juan Nieto;Roland Siegwart",
        "authorids": "/37085840497;/37086688697;/37088507022;/37086943677;/37089118071;/37088689118;/37089195268;/37085778635;/37281398300;/37085840497;/37086688697;/37088507022;/37086943677;/37089118071;/37088689118;/37089195268;/37085778635;/37281398300",
        "aff": "Autonomous Systems Lab, ETH Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Switzerland; Robert Bosch GmbH, Germany; Robert Bosch GmbH, Germany; Autonomous Systems Lab, ETH Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Switzerland; Microsoft, Switzerland; Autonomous Systems Lab, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636156/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4507076285687158995&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;1;1;0;0;2;0",
        "aff_unique_norm": "ETH Zurich;Robert Bosch GmbH;Microsoft",
        "aff_unique_dep": "Autonomous Systems Lab;;Microsoft Corporation",
        "aff_unique_url": "https://www.ethz.ch;https://www.bosch.com;https://www.microsoft.com",
        "aff_unique_abbr": "ETHZ;Bosch;Microsoft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;1;0;0;0;0",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "9636517",
        "title": "Semantic Image Alignment for Vehicle Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and reliable localization is a fundamental requirement for autonomous vehicles to use map information in higher-level tasks such as navigation or planning. In this paper, we present a novel approach to vehicle localization in dense semantic maps, including vectorized high-definition maps or 3D meshes, using semantic segmentation from a monocular camera. We formulate the localization task as a direct image alignment problem on semantic images, which allows our approach to robustly track the vehicle pose in semantically labeled maps by aligning virtual camera views rendered from the map to sequences of semantically segmented camera images. In contrast to existing visual localization approaches, the system does not require additional keypoint features, handcrafted localization landmark extractors or expensive LiDAR sensors. We demonstrate the wide applicability of our method on a diverse set of semantic mesh maps generated from stereo or LiDAR as well as manually annotated HD maps and show that it achieves reliable and accurate localization in real-time.",
        "primary_area": "",
        "author": "Markus Herb;Matthias Lemberger;Marcel M. Schmitt;Alexander Kurz;Tobias Weiherer;Nassir Navab;Federico Tombari;Markus Herb;Matthias Lemberger;Marcel M. Schmitt;Alexander Kurz;Tobias Weiherer;Nassir Navab;Federico Tombari",
        "authorids": "/37086308051;/37089197356;/37089195531;/37086586040;/38492400600;/37282965500;/37593332100;/37086308051;/37089197356;/37089195531;/37086586040;/38492400600;/37282965500;/37593332100",
        "aff": "AUDI AG, Ingolstadt, Germany; Department of Informatics, Technical University of Munich, Germany; AUDI AG, Ingolstadt, Germany; AUDI AG, Ingolstadt, Germany; AUDI AG, Ingolstadt, Germany; Department of Informatics, Technical University of Munich, Germany; Google, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636517/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=93436805013851682&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;1;2",
        "aff_unique_norm": "AUDI AG;Technical University of Munich;Google",
        "aff_unique_dep": ";Department of Informatics;Google",
        "aff_unique_url": "https://www.audi.de;https://www.tum.de;https://www.google.ch",
        "aff_unique_abbr": "AUDI;TUM;Google",
        "aff_campus_unique_index": "1;1;2",
        "aff_campus_unique": ";Munich;Zurich",
        "aff_country_unique_index": "0;0;0;0;0;0;1",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "id": "9636662",
        "title": "Semantic Segmentation-assisted Scene Completion for LiDAR Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Outdoor scene completion is a challenging issue in 3D scene understanding, which plays an important role in intelligent robotics and autonomous driving. Due to the sparsity of LiDAR acquisition, it is far more complex for 3D scene completion and semantic segmentation. Since semantic features can provide constraints and semantic priors for completion tasks, the relationship between them is worth exploring. Therefore, we propose an end-to-end semantic segmentation-assisted scene completion network, including a 2D completion branch and a 3D semantic segmentation branch. Specifically, the network takes a raw point cloud as input, and merges the features from the segmentation branch into the completion branch hierarchically to provide semantic information. By adopting BEV representation and 3D sparse convolution, we can benefit from the lower operand while maintaining effective expression. Besides, the decoder of the segmentation branch is used as an auxiliary, which can be discarded in the inference stage to save computational consumption. Extensive experiments demonstrate that our method achieves competitive performance on SemanticKITTI dataset with low latency. Code and models will be released at https://github.com/jokester-zzz/SSA-SC.",
        "primary_area": "",
        "author": "Xuemeng Yang;Hao Zou;Xin Kong;Tianxin Huang;Yong Liu;Wanlong Li;Feng Wen;Hongbo Zhang;Xuemeng Yang;Hao Zou;Xin Kong;Tianxin Huang;Yong Liu;Wanlong Li;Feng Wen;Hongbo Zhang",
        "authorids": "/37088455828;/37088690615;/37087322070;/37089197863;/37066946100;/37088687641;/37088690190;/37859161500;/37088455828;/37088690615;/37087322070;/37089197863;/37066946100;/37088687641;/37088690190;/37859161500",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Huawei Noah\u2019s Ark Lab, Beijing, China; Huawei Noah\u2019s Ark Lab, Beijing, China; Huawei Noah\u2019s Ark Lab, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636662/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14933846618374876170&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;1;1",
        "aff_unique_norm": "Zhejiang University;Huawei",
        "aff_unique_dep": "Institute of Cyber-Systems and Control;Huawei Noah\u2019s Ark Lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.huawei.com/en/ai/noahs-ark-lab",
        "aff_unique_abbr": "ZJU;HNA Lab",
        "aff_campus_unique_index": "0;0;0;0;0;1;1;1",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636592",
        "title": "Semantic Tracklets: An Object-Centric Representation for Visual Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Solving complex real-world tasks, e.g., autonomous fleet control, often involves a coordinated team of multiple agents which learn strategies from visual inputs via reinforcement learning. Many existing multi-agent reinforcement learning (MARL) algorithms however don\u2019t scale to environments where agents operate on visual inputs. To address this issue, algorithmically, recent works have focused on non-stationarity and exploration. In contrast, we study whether scalability can also be achieved via a disentangled representation. For this, we explicitly construct an object-centric intermediate representation to characterize the states of an environment, which we refer to as \u2018semantic tracklets.\u2019 We evaluate \u2018semantic tracklets\u2019 on the visual multi-agent particle environment (VMPE) and on the challenging visual multi-agent GFootball environment. \u2018Semantic tracklets\u2019 consistently outperform baselines on VMPE, and achieve a +2.4 higher score difference than baselines on GFootball. Notably, this method is the first to successfully learn a strategy for five players in the GFootball environment using only visual data. For more, please see our project page: https://ioujenliu.github.io/SemanticTracklets",
        "primary_area": "",
        "author": "Iou-Jen Liu;Zhongzheng Ren;Raymond A. Yeh;Alexander G. Schwing;Iou-Jen Liu;Zhongzheng Ren;Raymond A. Yeh;Alexander G. Schwing",
        "authorids": "/37087467135;/37086165321;/37085767334;/37937546900;/37087467135;/37086165321;/37085767334;/37937546900",
        "aff": "University of Illinois at Urbana-Champaign, IL, USA; University of Illinois at Urbana-Champaign, IL, USA; University of Illinois at Urbana-Champaign, IL, USA; University of Illinois at Urbana-Champaign, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636592/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13927655722358016527&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635890",
        "title": "Semantic-Based Explainable AI: Leveraging Semantic Scene Graphs and Pairwise Ranking to Explain Robot Failures",
        "track": "main",
        "status": "Poster",
        "abstract": "When interacting in unstructured human environments, occasional robot failures are inevitable. When such failures occur, everyday people, rather than trained technicians, will be the first to respond. Existing natural language explanations hand-annotate contextual information from an environment to help everyday people understand robot failures. However, this methodology lacks generalizability and scalability. In our work, we introduce a more generalizable semantic explanation framework. Our framework autonomously captures the semantic information in a scene to produce semantically descriptive explanations for everyday users. To generate failure-focused explanations that are semantically grounded, we lever-ages both semantic scene graphs to extract spatial relations and object attributes from an environment, as well as pairwise ranking. Our results show that these semantically descriptive explanations significantly improve everyday users\u2019 ability to both identify failures and provide assistance for recovery than the existing state-of-the-art context-based explanations.",
        "primary_area": "",
        "author": "Devleena Das;Sonia Chernova;Devleena Das;Sonia Chernova",
        "authorids": "/37086608011;/37283184200;/37086608011;/37283184200",
        "aff": "Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635890/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12528977313989220713&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635893",
        "title": "Semantic-aware Active Perception for UAVs using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a semantic-aware path-planning pipeline for Unmanned Aerial Vehicles (UAVs) using deep reinforcement learning for vision-based navigation in challenging environments. Driven by the maturity of works in semantic segmentation, the proposed path-planning architecture uses reinforcement learning to distinguish the parts of the scene that are perceptually more informative using semantic cues, in effect guiding more robust, repeatable, and accurate navigation of the UAV to the predefined goal destination. Assuming that the UAV performs vision-based state estimation, such as keyframe-based visual odometry, and semantic segmentation onboard, the proposed deep policy network continuously evaluates the optimal relative perceptual informativeness of each semantic class in view. A perception-aware path planner uses these informativeness values to perform trajectory optimization in order to generate the next best action with respect to the current state and the perception quality of the surroundings, essentially guiding the UAV to avoid flying over perceptually degraded regions. Thanks to the use of semantic cues, the policy can be trained in a large number of non-photorealistic randomly-generated scenes, and results to an architecture that is generalizable to environments with the same semantic classes, independently of their visual appearance. Extensive evaluations on challenging, photorealistic simulations reveal a remarkable improvement in robustness and success rate with the proposed approach over the state of the art in active perception. Video \u2013 https://youtu.be/RaO3whUBVnc",
        "primary_area": "",
        "author": "Luca Bartolomei;Lucas Teixeira;Margarita Chli;Luca Bartolomei;Lucas Teixeira;Margarita Chli",
        "authorids": "/37087322350;/37086010655;/37546501900;/37087322350;/37086010655;/37546501900",
        "aff": "Vision For Robotics Lab, ETH Z\u00fcrich, Switzerland; Vision For Robotics Lab, ETH Z\u00fcrich, Switzerland; Vision For Robotics Lab, ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635893/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=751195411971863719&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Vision For Robotics Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636352",
        "title": "Semantically Informed Next Best View Planning for Autonomous Aerial 3D Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "To capture the geometry of an object by an autonomous system, next best view (NBV) planning can be used to determine the path a robot will take. However, current NBV planning algorithms do not distinguish between objects that need to be mapped and everything else in the environment; leading to inefficient search strategies. In this paper we present a novel approach for NBV planning that accounts for the importance of objects in the environment to inform navigation. Using weighted entropy to encode object utilities computed via semantic segmentation, we evaluate our approach over a set of virtual Gazebo environments comparable to construction scales. Our results show that using semantic information reduces the time required to capture a target object by at least 40 percent.",
        "primary_area": "",
        "author": "Sebastian A. Kay;Simon Julier;Vijay M. Pawar;Sebastian A. Kay;Simon Julier;Vijay M. Pawar",
        "authorids": "/37086800860;/37264968900;/38191148100;/37086800860;/37264968900;/38191148100",
        "aff": "Faculty of Electrical Engineering, Mathematics and Computer Science, University College London, The United Kingdom; Faculty of Electrical Engineering, Mathematics and Computer Science, University College London, The United Kingdom; Faculty of Electrical Engineering, Mathematics and Computer Science, University College London, The United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636352/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15661977467093149971&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Faculty of Electrical Engineering, Mathematics and Computer Science",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636849",
        "title": "Semi-Cooperative Control for Autonomous Emergency Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous control of an emergency vehicle will save lives through faster transport and shorter response. Towards this goal, it must overcome the challenge of inter- acting with existing human drivers on the road. We present a game-theoretic approach for semi-cooperative control of an autonomous emergency vehicle that can interact efficiently with humans on the road. We model the interactions between autonomous and human driven cars with Social Value Orientation, a metric from social psychology, that allows the controller to leverage their influence on the trajectories of neighboring human drivers. In addition, by using a modified version of iterative best response, we direct the algorithm to converge to Nash equilibria that are cooperative. We demonstrate the efficacy of our algorithm in simulations of drivers in traffic, with a variety of traffic densities and driver personalities. In simulations of prosocial human drivers, our algorithm provides an 8% improvement in distance-traveled compared to egoistic human drivers.",
        "primary_area": "",
        "author": "Noam Buckman;Wilko Schwarting;Sertac Karaman;Daniela Rus;Noam Buckman;Wilko Schwarting;Sertac Karaman;Daniela Rus",
        "authorids": "/37087324071;/37085590089;/37304113000;/37279652300;/37087324071;/37085590089;/37304113000;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory of Information and Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636849/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5372230785626276272&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636149",
        "title": "Semi-supervised Vein Segmentation of Ultrasound Images for Autonomous Venipuncture",
        "track": "main",
        "status": "Poster",
        "abstract": "Venipuncture is an indispensable procedure for both diagnosis and treatment. In this paper, unlike existing solutions that fully or partially rely on professional assistance, a compact robotic system integrating both novel hardware and software developments is introduced. The hardware consists of a set of units to facilitate the supporting, positioning, puncturing, and imaging functionalities. To achieve full automation, a novel deep learning framework \u2014 semi-ResNeXt-Unet for semi-supervised vein segmentation from ultrasound images is proposed. The depth information of vein is calculated and enables the automated navigation for the puncturing unit. The algorithm is validated on 40 volunteers, and the proposed semi-ResNeXt-Unet improves the dice similarity coefficient (DSC) by 5.36%, decreases the centroid error by 1.38 pixels and decreases the failure rate by 5.60%, compared to fully-supervised ResNeXt-Unet.",
        "primary_area": "",
        "author": "Yu Chen;Yuxuan Wang;Bolin Lai;Zijie Chen;Xu Cao;Nanyang Ye;Zhongyuan Ren;Junbo Zhao;Xiao-Yun Zhou;Peng Qi;Yu Chen;Yuxuan Wang;Bolin Lai;Zijie Chen;Xu Cao;Nanyang Ye;Zhongyuan Ren;Junbo Zhao;Xiao-Yun Zhou;Peng Qi",
        "authorids": "/37089196978;/37089229733;/37089194063;/37089195494;/37089196740;/37089017987;/37089193931;/37089194081;/37085804767;/37085342733;/37089196978;/37089229733;/37089194063;/37089195494;/37089196740;/37089017987;/37089193931;/37089194081;/37085804767;/37085342733",
        "aff": "Tongji University, Shanghai, China; Tongji University, Shanghai, China; PingAn Technology Co. Ltd., Shanghai, China; Tongji University, Shanghai, China; Tongji University, Shanghai, China; Shanghai Jiao Tong University, Shanghai, China; Soochow University Medical College, Suzhou, China; Zhejiang University, Hangzhou, China; PAII Inc., MD, USA; Tongji University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636149/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11888893275238851096&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;1;0;0;2;3;4;5;0",
        "aff_unique_norm": "Tongji University;PingAn Technology;Shanghai Jiao Tong University;Soochow University;Zhejiang University;PAII Inc.",
        "aff_unique_dep": ";;;Medical College;;",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.pingan.com;https://www.sjtu.edu.cn;https://eng.soochow.edu.cn/;http://www.zju.edu.cn;",
        "aff_unique_abbr": "Tongji;PingAn;SJTU;;ZJU;",
        "aff_campus_unique_index": "0;0;0;0;0;2;3;0",
        "aff_campus_unique": "Shanghai;;Suzhou;Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9636436",
        "title": "Sensor Fusion-based Anthropomorphic Control of Under-Actuated Bionic Hand in Dynamic Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Under-actuated bionic hands have achieved tremendous popularity in many fields because of their advantages of lightweight, budget-friendly, satisfactory flexibility, and adaptability. Except for the bionic mechanical design, various anthropomorphic control strategies have been proposed and investigated in the last decades. However, due to its under-actuated characteristic, there are still many challenges for anthropomorphic control of all the degrees of freedom (DOFs) using less input. It is challenging to map the human hand kinematic synergies on robotic hands, particularly for a dynamic environment. Therefore, it is worth studying how to control the under-actuated bionic hand effectively in a dynamic environment. In this paper, an anthropomorphic control method is proposed using sensor fusion of hand kinematic inputs to control the under-actuated bionic hand. In order to map the kinematics of human fingers to the bionic hand, a novel finger bending angle is defined to represent the posture of human fingers. Multiple Leap Motion Controllers (LMC) are fused to estimate the stable and accurate finger bending angles to avoid the occlusion problem. Finally, experiments with real-time control of the under-actuated bionic hand are implemented to demonstrate the proposed approach\u2019s effectiveness.",
        "primary_area": "",
        "author": "Hang Su;Junhao Zhang;Junling Fu;Salih Ertug Ovur;Wen Qi;Guoxin Li;Yingbai Hu;Zhijun Li;Hang Su;Junhao Zhang;Junling Fu;Salih Ertug Ovur;Wen Qi;Guoxin Li;Yingbai Hu;Zhijun Li",
        "authorids": "/37086423278;/37088967066;/37088953289;/37086877416;/37087004088;/37087004502;/37085749138;/37309823400;/37086423278;/37088967066;/37088953289;/37086877416;/37087004088;/37087004502;/37085749138;/37309823400",
        "aff": "Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Department of Electrical and Electronic Engineering, Imperial College London, United Kingdom; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Department of Automation, University of Science and Technology of China, China; Department of Informatics, Technical University of Munich, Munich, Germany; Department of Automation, University of Science and Technology of China, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636436/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4382224134761222949&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;0;2;3;2",
        "aff_unique_norm": "Politecnico di Milano;Imperial College London;University of Science and Technology of China;Technical University of Munich",
        "aff_unique_dep": "Dipartimento di Elettronica, Informazione e Bioingegneria;Department of Electrical and Electronic Engineering;Department of Automation;Department of Informatics",
        "aff_unique_url": "https://www.polimi.it;https://www.imperial.ac.uk;http://www.ustc.edu.cn;https://www.tum.de",
        "aff_unique_abbr": "Politecnico di Milano;Imperial;USTC;TUM",
        "aff_campus_unique_index": "0;0;0;1;0;3",
        "aff_campus_unique": "Milano;London;;Munich",
        "aff_country_unique_index": "0;0;0;1;0;2;3;2",
        "aff_country_unique": "Italy;United Kingdom;China;Germany"
    },
    {
        "id": "9636582",
        "title": "Sensor selection for detecting deviations from a planned itinerary",
        "track": "main",
        "status": "Poster",
        "abstract": "Suppose an agent asserts that it will move through an environment in some way. When the agent executes its motion, how does one verify the claim? The problem arises in a range of contexts including validating safety claims about robot behavior, applications in security and surveillance, and for both the conception and the (physical) design and logistics of scientific experiments. Given a set of feasible sensors to select from, we ask how to choose sensors optimally in order to ensure that the agent\u2019s execution does indeed fit its pre-disclosed itinerary. Our treatment is distinguished from prior work in sensor selection by two aspects: the form the itinerary takes (a regular language of transitions) and that families of sensor choices can be grouped as a single choice. Both are intimately tied together, permitting construction of a product automaton because the same physical sensors (i.e., the same choice) can appear multiple times. This paper establishes the hardness of sensor selection for itinerary validation within this treatment, and proposes an exact algorithm based on an integer linear programming (ILP) formulation that is capable of solving problem instances of moderate size. We demonstrate its efficacy on small-scale case studies, including one motivated by wildlife tracking.",
        "primary_area": "",
        "author": "Hazhar Rahmani;Dylan A. Shell;Jason M. O\u2019Kane;Hazhar Rahmani;Dylan A. Shell;Jason M. O\u2019Kane",
        "authorids": "/37086453006;/37269198900;/37279835400;/37086453006;/37269198900;/37279835400",
        "aff": "Dept. of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA; Dept. of Computer Science and Engineering, Texas A&M University, College Station, TX, USA; Dept. of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636582/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16617533215190393166&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of South Carolina;Texas A&M University",
        "aff_unique_dep": "Dept. of Computer Science and Engineering;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.sc.edu;https://www.tamu.edu",
        "aff_unique_abbr": "USC;TAMU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Columbia;College Station",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635885",
        "title": "Sensorimotor-inspired Tactile Feedback and Control Improve Consistency of Prosthesis Manipulation in the Absence of Direct Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "The lack of haptically aware upper-limb prostheses forces amputees to rely largely on visual cues to complete activities of daily living. In contrast, non-amputees inherently rely on conscious haptic perception and automatic tactile reflexes to govern volitional actions in situations that do not allow for constant visual attention. We therefore propose a myoelectric prosthesis system that reflects these concepts to aid manipulation performance without direct vision. To implement this design, we constructed two fabric-based tactile sensors that measure contact location along the palmar and dorsal sides of the prosthetic fingers and grasp pressure at the tip of the prosthetic thumb. Inspired by the natural sensorimotor system, we use the measurements from these sensors to provide vibrotactile feedback of contact location and implement a tactile grasp controller with reflexes that prevent over-grasping and object slip. We compare this tactile system to a standard myoelectric prosthesis in a challenging reach-to-pick-and-place task conducted without direct vision; 17 non-amputee adults took part in this single-session between-subjects study. Participants in the tactile group achieved more consistent high performance compared to participants in the standard group. These results show that adding contact-location feedback and reflex control increases the consistency with which objects can be grasped and moved without direct vision in upper-limb prosthetics.",
        "primary_area": "",
        "author": "Neha Thomas;Farimah Fazlollahi;Jeremy D. Brown;Katherine J. Kuchenbecker;Neha Thomas;Farimah Fazlollahi;Jeremy D. Brown;Katherine J. Kuchenbecker",
        "authorids": "/37088869675;/37088945444;/38556961200;/37297463900;/37088869675;/37088945444;/38556961200;/37297463900",
        "aff": "Haptic Intelligence Department, Max Planck Institute for Intelligent Systems; Haptic Intelligence Department, Max Planck Institute for Intelligent Systems; Department of Mechanical Engineering, Johns Hopkins University; Haptic Intelligence Department, Max Planck Institute for Intelligent Systems",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635885/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9154132267885828061&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;Johns Hopkins University",
        "aff_unique_dep": "Haptic Intelligence Department;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.jhu.edu",
        "aff_unique_abbr": "MPI-IS;JHU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9636250",
        "title": "Shape Estimation of Negative Obstacles for Autonomous Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Obstacle detection and avoidance plays a crucial role in autonomous navigation of unmanned ground vehicles. This becomes more challenging in off-road environments due to the higher probability of finding negative obstacles (e.g., holes, ditches, trenches, etc.) compared with on-road environments. One approach to solve this problem is to avoid the candidate path with a negative obstacle, but in off-road avoiding negative obstacles all the time is not possible. In such cases, the path planner may need to choose a candidate path with a negative obstacle that causes the least amount of damage to the vehicle. To deal better with these types of scenarios, this study introduces a novel approach to perform shape estimation of negative obstacles using LiDAR 3D point cloud data. The dimensions (width, diameter, and depth) and the location (center) of negative obstacles are calculated based on estimated shape. This approach is tested on different terrain types using the Mississippi Autonomous Vehicle Simulation (MAVS).",
        "primary_area": "",
        "author": "Viswadeep Lebakula;Bo Tang;Christopher Goodin;Cindy L. Bethel;Viswadeep Lebakula;Bo Tang;Christopher Goodin;Cindy L. Bethel",
        "authorids": "/37089195691;/37089195127;/38111378800;/38572978200;/37089195691;/37089195127;/38111378800;/38572978200",
        "aff": "Viswadeep Lebakula; Bo Tang; Christopher Goodin; Cindy L. Bethel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636250/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16263236903738076570&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9636695",
        "title": "Shape-centric Modeling for Soft Robot Inchworm Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robot modeling tends to prioritize soft robot dynamics in order to recover how they might behave. Soft robot design tends to focus on how to use compliant elements with actuation to effect certain canonical movement profiles. For soft robot locomotors, these profiles should lead to locomotion. Naturally, there is a gap between the emphasis of computational modeling and the needs of locomotion design. This paper proposes to consider modeling and computation efforts directed more toward understanding soft robot-world interactions with locomotion in mind. With a SMA-actuated inchworm as the soft robot to model and control, the framework is a combination of shape identification and geometric modeling that culminates in control equations of motion. When applied to the task of gait-based locomotion, the equations operate in a low dimensional shape-based gait space. Simulated and experimentally applied gaits for an inchworm model showed qualitatively similar outcomes, while the measured net displacement per gait cycle coincided within 9%. This result advances the idea that a shape-centric approach to soft robot modeling for control and locomotion may provide predictive locomotive models.",
        "primary_area": "",
        "author": "Alexander H. Chang;Caitlin Freeman;Arun Niddish Mahendran;Vishesh Vikas;Patricio A. Vela;Alexander H. Chang;Caitlin Freeman;Arun Niddish Mahendran;Vishesh Vikas;Patricio A. Vela",
        "authorids": "/37085540569;/37089196952;/37089195121;/37992375400;/37329553400;/37085540569;/37089196952;/37089195121;/37992375400;/37329553400",
        "aff": "Institute for Robotics and Intelligent Machines (IRIM) and School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Mechanical Engineering, University of Alabama, Tuscaloosa, AL, USA; Department of Mechanical Engineering, University of Alabama, Tuscaloosa, AL, USA; Department of Mechanical Engineering, University of Alabama, Tuscaloosa, AL, USA; Institute for Robotics and Intelligent Machines (IRIM) and School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636695/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16225541210927105807&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;University of Alabama",
        "aff_unique_dep": "School of Electrical and Computer Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.gatech.edu;https://www.ua.edu",
        "aff_unique_abbr": "Georgia Tech;UA",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Atlanta;Tuscaloosa",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636061",
        "title": "Shaping Progressive Net of Reinforcement Learning for Policy Transfer with Human Evaluative Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning has achieved significant success in many fields, but will confront sampling efficiency and safety problems when applying to robot control in the real world. Sim-to-real transfer learning was proposed to make use of samples in the simulation and overcome the gap between simulation and real world. In this paper, we focus on improving Progressive Neural Network \u2014 an effective sim-to-real learning method, by proposing Interactive Progressive Network Learning (IPNL). IPNL integrates progressive network and interactive reinforcement learning (interactive RL) which learns from evaluative feedback provided by an observing human trainer. We test our method using five RL tasks with discrete or continuous actions in OpenAI Gym and a sinusoids curve following task with AUV simulator on the Gazebo platform. Our results suggest that while Progressive Network has good performance when transferring from tasks with low-dimensional state space to those with high-dimensional one but has little effect for transferring from high-dimensional tasks to low-dimensional ones, IPNL allows an agent to learn a more stable policy with better performance faster for both cases. More importantly, our further analysis indicate that there is a synergy between Progressive Network and interactive RL for improving the agent\u2019s learning. Our results in the path following of AUV shed light on the potential of applying our method in the real world tasks.",
        "primary_area": "",
        "author": "Rongshun Juan;Jie Huang;Randy Gomez;Keisuke Nakamura;Qixin Sha;Bo He;Guangliang Li;Rongshun Juan;Jie Huang;Randy Gomez;Keisuke Nakamura;Qixin Sha;Bo He;Guangliang Li",
        "authorids": "/37089195007;/37089196244;/37979526500;/37534198900;/37393817200;/37399325300;/37086047680;/37089195007;/37089196244;/37979526500;/37534198900;/37393817200;/37399325300;/37086047680",
        "aff": "College of Information Science and Engineering, Ocean University of China, Qingdao, China; College of Information Science and Engineering, Ocean University of China, Qingdao, China; Honda Research Institute Japan Co., Ltd, Wako, Japan; Honda Research Institute Japan Co., Ltd, Wako, Japan; College of Information Science and Engineering, Ocean University of China, Qingdao, China; College of Information Science and Engineering, Ocean University of China, Qingdao, China; College of Information Science and Engineering, Ocean University of China, Qingdao, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636061/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3986877782773394961&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;0;0;0",
        "aff_unique_norm": "Ocean University of China;Honda Research Institute Japan Co., Ltd",
        "aff_unique_dep": "College of Information Science and Engineering;",
        "aff_unique_url": "http://www.ouc.edu.cn;https://www.honda-ri.jp/english/",
        "aff_unique_abbr": "OUC;HRI-JP",
        "aff_campus_unique_index": "0;0;1;1;0;0;0",
        "aff_campus_unique": "Qingdao;Wako",
        "aff_country_unique_index": "0;0;1;1;0;0;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9636275",
        "title": "Shipborne sea-ice field mapping using a LiDAR",
        "track": "main",
        "status": "Poster",
        "abstract": "The increasing interest for autonomous ships has motivated research in numerous areas. One such area is the safe navigation through ice infested waters, for which a sensor instrumentation and automated process are proposed for near-field, sea-ice 3D scanning and mapping using a ship mounted LiDAR, with attitude compensation from inertial and satellite positioning sensors. Data were collected both at the Aalto Ice Tank laboratory and on board the icebreaker S.A. Agulhas II during its voyage to the Antarctic waters. The implemented process enables automated acquisition of detailed 3D point cloud maps, containing highly valuable information for icy waters going ships currently operated by a human crew and, in the near future, supporting the development of autonomous ships. Compared to other methods using satellite, aerial or underwater data, the proposed method is a more cost-effective and easy to integrate solution into current and future icy waters going ships, thus enabling a higher level of situational awareness.",
        "primary_area": "",
        "author": "Andrei Sandru;Arto Visala;Pentti Kujala;Andrei Sandru;Arto Visala;Pentti Kujala",
        "authorids": "/37089197486;/37444691700;/37085842120;/37089197486;/37444691700;/37085842120",
        "aff": "Department of Electrical Engineering and Automation, Aalto University, Espoo, Finland; Department of Electrical Engineering and Automation, Aalto University, Espoo, Finland; Department of Mechanical Engineering, Aalto University, Espoo, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636275/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10936560713140835914&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Aalto University",
        "aff_unique_dep": "Department of Electrical Engineering and Automation",
        "aff_unique_url": "https://www.aalto.fi",
        "aff_unique_abbr": "Aalto",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Espoo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "9636614",
        "title": "ShorelineNet: An Efficient Deep Learning Approach for Shoreline Semantic Segmentation for Unmanned Surface Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a novel deep learning approach to semantic segmentation of the shoreline environments with a high frames-per-second (fps) performance, making the approach readily applicable to autonomous navigation for Unmanned Surface Vehicles (USV). The proposed ShorelineNet is an efficient deep neural network of high performance relying only on visual input. ShorelineNet uses monocular visual input to produce accurate shoreline separation and obstacle detection compared to the state-of-the-art, and achieves this with real-time performance. Experimental validation on a challenging multi-modal maritime obstacle detection dataset, the MODD2 dataset, achieves a much faster inference (25fps on an NVIDIA Tesla K80 and 6fps on a CPU) with respect to the recent state-of-the-art methods, while keeping the performance equally high (73.1% F-score). This makes ShorelineNet a robust and effective model to be used for reliable USV navigation that require real-time and high-performance semantic segmentation of maritime environments.",
        "primary_area": "",
        "author": "Linghong Yao;Dimitrios Kanoulas;Ze Ji;Yuanchang Liu;Linghong Yao;Dimitrios Kanoulas;Ze Ji;Yuanchang Liu",
        "authorids": "/37089194796;/38230575500;/37897773200;/37085677511;/37089194796;/38230575500;/37897773200;/37085677511",
        "aff": "Department of Mechanical Engineering, University College London (UCL), United Kingdom; Department of Computer Science, University College London (UCL), United Kingdom; School of Engineering, Cardiff University, Cardiff, UK; Department of Mechanical Engineering, University College London (UCL), United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636614/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16013143988340937696&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University College London;Cardiff University",
        "aff_unique_dep": "Department of Mechanical Engineering;School of Engineering",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.cardiff.ac.uk",
        "aff_unique_abbr": "UCL;Cardiff",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "London;Cardiff",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636309",
        "title": "SiamAPN++: Siamese Attentional Aggregation Network for Real-Time UAV Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, the Siamese-based method has stood out from multitudinous tracking methods owing to its state-of-the-art (SOTA) performance. Nevertheless, due to various special challenges in UAV tracking, e.g., severe occlusion and fast motion, most existing Siamese-based trackers hardly combine superior performance with high efficiency. To this concern, in this paper, a novel attentional Siamese tracker (SiamAPN++) is proposed for real-time UAV tracking. By virtue of the attention mechanism, we conduct a special attentional aggregation network (AAN) consisting of self-AAN and cross-AAN for raising the representation ability of features eventually. The former AAN aggregates and models the self-semantic interdependencies of the single feature map via spatial and channel dimensions. The latter aims to aggregate the cross-interdependencies of two different semantic features including the location information of anchors. In addition, the anchor proposal network based on dual features is proposed to raise its robustness of tracking objects with various scales. Experiments on two well-known authoritative benchmarks are conducted, where SiamAPN++ outperforms its baseline SiamAPN and other SOTA trackers. Besides, real-world tests onboard a typical embedded platform demonstrate that SiamAPN++ achieves promising tracking results with real-time speed.",
        "primary_area": "",
        "author": "Ziang Cao;Changhong Fu;Junjie Ye;Bowen Li;Yiming Li;Ziang Cao;Changhong Fu;Junjie Ye;Bowen Li;Yiming Li",
        "authorids": "/37088997696;/37086797986;/37088917418;/37089000657;/37087323806;/37088997696;/37086797986;/37088917418;/37089000657;/37087323806",
        "aff": "School of Automotive Studies, Tongji University, China; School of Mechanical Engineering, Tongji University, China; School of Mechanical Engineering, Tongji University, China; School of Mechanical Engineering, Tongji University, China; Tandon School of Engineering, New York University, New York, NY, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636309/",
        "gs_citation": 151,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1695455267678220733&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Tongji University;New York University",
        "aff_unique_dep": "School of Automotive Studies;Tandon School of Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.nyu.edu",
        "aff_unique_abbr": "Tongji;NYU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";New York",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9636259",
        "title": "Sim-to-Real Transfer for Robotic Manipulation with Tactile Sensory",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement Learning (RL) methods have been widely applied for robotic manipulations via sim-to-real transfer, typically with proprioceptive and visual information. However, the incorporation of tactile sensing into RL for contact-rich tasks lacks investigation. In this paper, we model a tactile sensor in simulation and study the effects of its feedback in RL-based robotic control via a zero-shot sim-to-real approach with domain randomization. We demonstrate that learning and controlling with feedback from tactile sensor arrays at the gripper, both in simulation and reality, can enhance grasping stability, which leads to a significant improvement in robotic manipulation performance for a door opening task. In real-world experiments, the door open angle was increased by 45% on average for transferred policies with tactile sensing over those without it.",
        "primary_area": "",
        "author": "Zihan Ding;Ya-Yen Tsai;Wang Wei Lee;Bidan Huang;Zihan Ding;Ya-Yen Tsai;Wang Wei Lee;Bidan Huang",
        "authorids": "/37088504955;/37086935862;/37085402629;/37085655047;/37088504955;/37086935862;/37085402629;/37085655047",
        "aff": "Tencent Robotics X, China; Hamlyn Centre for Robotic Surgery, Imperial College London, London, UK; Tencent Robotics X, China; Tencent Robotics X, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636259/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11999009683263838002&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Tencent;Imperial College London",
        "aff_unique_dep": "Tencent Robotics X;Hamlyn Centre for Robotic Surgery",
        "aff_unique_url": "https://robotics.tencent.com;https://www.imperial.ac.uk",
        "aff_unique_abbr": "Tencent Robotics X;ICL",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9636783",
        "title": "Sim2Sim Evaluation of a Novel Data-Efficient Differentiable Physics Engine for Tensegrity Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning policies in simulation is promising for reducing human effort when training robot controllers. This is especially true for soft robots that are more adaptive and safe but also more difficult to accurately model and control. The sim2real gap is the main barrier to successfully transfer policies from simulation to a real robot. System identification can be applied to reduce this gap but traditional identification methods require a lot of manual tuning. Data-driven alternatives can tune dynamical models directly from data but are often data hungry, which also incorporates human effort in collecting data. This work proposes a data-driven, end-to-end differentiable simulator focused on the exciting but challenging domain of tensegrity robots. To the best of the authors\u2019 knowledge, this is the first differentiable physics engine for tensegrity robots that supports cable, contact, and actuation modeling. The aim is to develop a reasonably simplified, data-driven simulation, which can learn approximate dynamics with limited ground truth data. The dynamics must be accurate enough to generate policies that can be transferred back to the ground-truth system. As a first step in this direction, the current work demonstrates sim2sim transfer, where the unknown physical model of MuJoCo acts as a ground truth system. Two different tensegrity robots are used for evaluation and learning of locomotion policies, a 6-bar and a 3-bar tensegrity. The results indicate that only 0.25% of ground truth data are needed to train a policy that works on the ground truth system when the differentiable engine is used for training against training the policy directly on the ground truth system.",
        "primary_area": "",
        "author": "Kun Wang;Mridul Aanjaneya;Kostas Bekris;Kun Wang;Mridul Aanjaneya;Kostas Bekris",
        "authorids": "/37089194334;/37546899300;/37282424700;/37089194334;/37546899300;/37282424700",
        "aff": "Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636783/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3064166766204667251&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636494",
        "title": "Similarity-Aware Fusion Network for 3D Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a similarity-aware fusion network (SAFNet) to adaptively fuse 2D images and 3D point clouds for 3D semantic segmentation. Existing fusion-based methods achieve superior performances by integrating information from multiple modalities. However, they heavily rely on the projection-based correspondence between 2D pixels and 3D points and can only perform the information fusion in a fixed manner, so that their performances cannot be easily migrated to a more realistic scenario where the collected data often lack strict pair-wise features for prediction. To address this, we employ a late fusion strategy where we first learn the geometric and contextual similarities between the input and back-projected (from 2D pixels) point clouds and utilize them to guide the fusion of two modalities to further exploit complementary information. Specifically, we employ a geometric similarity module (GSM) to directly compare the spatial coordinate distributions of pair-wise 3D neighborhoods, and a contextual similarity module (CSM) to aggregate and compare spatial contextual information of corresponding central points. The two proposed modules can effectively measure how much image features can help predictions, enabling the network to adaptively adjust the contributions of two modalities to the final prediction of each point. Experimental results on ScanNetV2 [1] benchmark demonstrate that SAFNet outperforms existing state-of-the-art fusion-based approaches across various data integrity.",
        "primary_area": "",
        "author": "Linqing Zhao;Jiwen Lu;Jie Zhou;Linqing Zhao;Jiwen Lu;Jie Zhou",
        "authorids": "/37089196948;/37404390100;/37278266700;/37089196948;/37404390100;/37278266700",
        "aff": "School of Mathematics, and the School of Electrical and Information Engineering, Tianjin University, China; Department of Automation, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636494/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16217466241327817709&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Tianjin University;Tsinghua University",
        "aff_unique_dep": "School of Mathematics;Department of Automation",
        "aff_unique_url": "http://www.tju.edu.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tianjin University;THU",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636056",
        "title": "Simulating Ocean Wave Movement in a Soft Pneumatic Surface",
        "track": "main",
        "status": "Poster",
        "abstract": "It is well understood that nature has a calming effect on us. But in a physical space remote from nature, might the robotic embodiment of a natural phenomenon have the same effect? To address this question, we have simulated the soothing movement of ocean waves in a soft robotic surface, both as a simulation and in a physical prototype. In this paper, we report on our modeling methods of this natural phenomenon, we present the application of a selected model to both a simulation of the predicted inflation pattern of the soft robot surface and to the physical soft robot surface, and we compare the behavior of the physical robot to our simulation as a means to validate our design. We observed that the prototype\u2019s frequency spectrum successfully shared the general trend and shape as our mathematical model. This research introduces a novel robot for a novel application: a soft robot to promote restoration and help regulate mental wellbeing in tight physical confines.",
        "primary_area": "",
        "author": "Alexandra W. Steelman;Elena B. Sabinson;Isha Pradhan;Aratrika Ghatak;Keith E. Green;Alexandra W. Steelman;Elena B. Sabinson;Isha Pradhan;Aratrika Ghatak;Keith E. Green",
        "authorids": "/37089197767;/37088946122;/37089195307;/37089196837;/37086537054;/37089197767;/37088946122;/37089195307;/37089196837;/37086537054",
        "aff": "School of Civil and Environmental Engineering, Cornell University, Ithaca, NY, USA; Departments of Design & Environmental Analysis, Cornell University, Ithaca, NY, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA; School of Electrical and Computer Engineering, Cornell University, Ithaca, NY, USA; Departments of Design & Environmental Analysis and the Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636056/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14792888114268880696&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "School of Civil and Environmental Engineering",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Ithaca",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635953",
        "title": "Simultaneous Actuation and Localization of Magnetic Robots Using Mobile Coils and Eye-In-Hand Hall-Effect Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Large workspace localization of magnetic robots is important for medical applications. This paper presents a novel localization strategy to achieve simultaneous localization and actuation of magnetic robots using hall-effect sensors. We integrate 25 sensors into a sensing probe and mount it on to the mobile-coil system, which realizes accurate sensing and actuation of magnetic devices within a cylindrical workspace of \u03d5500 mm\u00d7150 mm. Simulation results show the average localization error using the proposed method is 1.7 mm. A verification experiment is conducted to prove the design advantages; Another two experiments are conducted to demonstrate the simultaneous actuation and localization of a torque-driven robot and a force-driven floating robot respectively. For the force-driven floating robot, the average variation between the localization results and the desired trajectory is less than 2 mm.",
        "primary_area": "",
        "author": "Moqiu Zhang;Lidong Yang;Chong Zhang;Zhengxin Yang;Li Zhang;Moqiu Zhang;Lidong Yang;Chong Zhang;Zhengxin Yang;Li Zhang",
        "authorids": "/37088704045;/37086079463;/37089196610;/37088506149;/37085379138;/37088704045;/37086079463;/37089196610;/37088506149;/37085379138",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong, China; Department of Biomedical Engineering, The Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Shatin NT, Hong Kong, China; CUHK T Stone Robotics Institute, The Chinese University of Hong Kong, Shatin NT, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635953/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3700985800561937197&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shatin NT",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636252",
        "title": "Simultaneous Prediction of Pedestrian Trajectory and Actions based on Context Information Iterative Reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "Pedestrian trajectories and actions prediction in complex environment is challenging due to the complexity of human behavior and a variety of internal and external stimuli. Much works has gone towards predicting trajectories and actions separately without mining the coupling relationships between them, which is an important information for our humans to reason and predict. Inspired by this, we propose an end-to-end joint context information iterative reasoning network (CIR-Net). Specifically, a novel heterogeneous spatiotemporal graph module (HST-Graph) is proposed to encode and aggregate multiple types of context information of the motion pattern and the scene. And an action-trajectory hybrid guidance module is proposed to enhance the ability of long-time prediction by utilizing the internal coupling between actions and trajectory. Moreover, an iterative reasoning structure is designed to iteratively correcting the trajectory and actions prediction error. Experimental results on the ETH&UCY and VIRAT datasets demonstrate the favorable performance of the framework.",
        "primary_area": "",
        "author": "Bo Chen;Decai Li;Yuqing He;Bo Chen;Decai Li;Yuqing He",
        "authorids": "/37086939121;/37086182699;/37288326300;/37086939121;/37086182699;/37288326300",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636252/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3384361784883920878&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_unique_dep": ";Institutes for Robotics and Intelligent Manufacturing",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.cas.cn",
        "aff_unique_abbr": "UCAS;CAS",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Beijing;Shenyang",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636860",
        "title": "Simultaneous Scene Reconstruction and Whole-Body Motion Planning for Safe Operation in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work has demonstrated real-time mapping and reconstruction from dense perception, while motion planning based on distance fields has been shown to achieve fast, collision-free motion synthesis with good convergence properties. However, demonstration of a fully integrated system that can safely re-plan in unknown environments, in the presence of static and dynamic obstacles, has remained an open challenge. In this work, we first study the impact that signed and unsigned distance fields have on optimisation convergence, and the resultant error cost in trajectory optimisation problems in 2D path planning, arm manipulator motion planning, and whole-body loco-manipulation planning. We further analyse the performance of three state-of-the-art approaches to generating distance fields (Voxblox, Fiesta, and GPU-Voxels) for use in realtime environment reconstruction. Finally, we use our findings to construct a practical hybrid mapping and motion planning system which uses GPU-Voxels and GPMP2 to perform receding- horizon whole-body motion planning that can smoothly avoid moving obstacles in 3D space using live sensor data. Our results are validated in simulation and on a real-world Toyota Human Support Robot (HSR).",
        "primary_area": "",
        "author": "Mark Nicholas Finean;Wolfgang Merkt;Ioannis Havoutis;Mark Nicholas Finean;Wolfgang Merkt;Ioannis Havoutis",
        "authorids": "/37089196211;/37086118415;/37542879900;/37089196211;/37086118415;/37542879900",
        "aff": "Oxford Robotics Institute, University of Oxford; Oxford Robotics Institute, University of Oxford; Oxford Robotics Institute, University of Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636860/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17021194883741420529&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636012",
        "title": "Simultaneous Semantic and Collision Learning for 6-DoF Grasp Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping in cluttered scenes has always been a great challenge for robots, due to the requirement of the ability to well understand the scene and object information. Previous works usually assume that the geometry information of the objects is available, or utilize a step-wise, multi-stage strategy to predict the feasible 6-DoF grasp poses. In this work, we propose to formalize the 6-DoF grasp pose estimation as a simultaneous multi-task learning problem. In a unified framework, we jointly predict the feasible 6-DoF grasp poses, instance semantic segmentation, and collision information. The whole framework is jointly optimized and end-to-end differentiable. Our model is evaluated on large-scale benchmarks as well as the real robot system. On the public dataset, our method outperforms prior state-of-the-art methods by a large margin (+4.08 AP). We also demonstrate the implementation of our model on a real robotic platform and show that the robot can accurately grasp target objects in cluttered scenarios with a high success rate. Project link: https://openbyterobotics.github.io/sscl.",
        "primary_area": "",
        "author": "Yiming Li;Tao Kong;Ruihang Chu;Yifeng Li;Peng Wang;Lei Li;Yiming Li;Tao Kong;Ruihang Chu;Yifeng Li;Peng Wang;Lei Li",
        "authorids": "/37090022116;/37085802024;/37089001065;/37089195771;/37538869400;/37087235484;/37090022116;/37085802024;/37089001065;/37089195771;/37538869400;/37087235484",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Bytedance AI Lab; The Chinese University of Hong Kong; Bytedance AI Lab; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Bytedance AI Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636012/",
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6664782834820775840&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;0;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;ByteDance;Chinese University of Hong Kong",
        "aff_unique_dep": "School of Artificial Intelligence;AI Lab;",
        "aff_unique_url": "http://www.ucas.ac.cn;https://www.bytedance.com;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "UCAS;Bytedance AI Lab;CUHK",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Beijing;;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636767",
        "title": "Single-Shot is Enough: Panoramic Infrastructure Based Calibration of Multiple Cameras and 3D LiDARs",
        "track": "main",
        "status": "Poster",
        "abstract": "The integration of multiple cameras and 3D Li-DARs has become basic configuration of augmented reality devices, robotics, and autonomous vehicles. The calibration of multi-modal sensors is crucial for a system to properly function, but it remains tedious and impractical for mass production. Moreover, most devices require re-calibration after usage for certain period of time. In this paper, we propose a single-shot solution for calibrating extrinsic transformations among multiple cameras and 3D LiDARs. We establish a panoramic infrastructure, in which a camera or LiDAR can be robustly localized using data from single frame. Experiments are conducted on three devices with different camera-LiDAR configurations, showing that our approach achieved comparable calibration accuracy with the state-of-the-art approaches but with much greater efficiency.",
        "primary_area": "",
        "author": "Chuan Fang;Shuai Ding;Zilong Dong;Honghua Li;Siyu Zhu;Ping Tan;Chuan Fang;Shuai Ding;Zilong Dong;Honghua Li;Siyu Zhu;Ping Tan",
        "authorids": "/37089197665;/37089195155;/37401679600;/37089395938;/37085442921;/37085414267;/37089197665;/37089195155;/37401679600;/37089395938;/37085442921;/37085414267",
        "aff": "Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636767/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13962298653760522630&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Alibaba Group",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.alibaba.com",
        "aff_unique_abbr": "Alibaba",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636843",
        "title": "Slip Modeling and Simulation of Spiral Zipper Friction-Driven Prismatic Actuator",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, based on an analysis of experimental results, we propose a method for slip modeling of Spiral Zipper. The Spiral Zipper is a prismatic actuator that extracts a length-changeable cylindrical tube from a flexible ABS band. The band tube is driven by a friction wheel; the slip results due to the lack of synchronization between the motion of the band and that of the friction wheel. Through experiments, we verify that the flexibility of the band causes an impact force between the band and the friction wheel. Additionally, we verify that the tube extraction process causes resistance, which contributes to the increase in the relative angular velocity. Considering the factors mentioned above, we develop a slip model by employing different numbers of contact patches that express the flexibility of the band. Subsequently, we validate the model\u2019s performance through simulations. In addition, we propose a coefficients standardization method for obtaining similar results with different number of contact patches We expect that this study will be a basis for design optimization and control system development of the Spiral Zipper.",
        "primary_area": "",
        "author": "Seohyeon Lee;Sahoon Ahn;Devin Carroll;Mark Yim;TaeWon Seo;Seohyeon Lee;Sahoon Ahn;Devin Carroll;Mark Yim;TaeWon Seo",
        "authorids": "/37087325361;/37089198198;/37086283061;/37274063600;/37395768500;/37087325361;/37089198198;/37086283061;/37274063600;/37395768500",
        "aff": "Department of Mechanical Convergence Engineering, Hanyang University, Seoul, Republic of Korea; Department of Mechanical Convergence Engineering, Hanyang University, Seoul, Republic of Korea; Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, United States; Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, United States; Department of Mechanical Convergence Engineering, Hanyang University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636843/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2757219880705019990&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Hanyang University;University of Pennsylvania",
        "aff_unique_dep": "Department of Mechanical Convergence Engineering;Department of Mechanical Engineering and Applied Mechanics",
        "aff_unique_url": "http://www.hanyang.ac.kr;https://www.upenn.edu",
        "aff_unique_abbr": "HYU;UPenn",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Seoul;Philadelphia",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "9636018",
        "title": "Smart Pointers and Shared Memory Synchronisation for Efficient Inter-process Communication in ROS on an Autonomous Vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the stringent requirements of a real-time system, the reliance of the Robot Operating System (ROS) on the loopback network interface imposes a considerable overhead on the transport of high bandwidth data, while the nodelet package, which is an efficient mechanism for intra-process communication, does not address the problem of efficient local inter-process communication (IPC). To remedy this, we propose a novel integration into ROS of smart pointers and synchronisation primitives stored in shared memory. These obey the same semantics and, more importantly, exhibit the same performance as their C++ standard library counterparts, making them preferable to other local IPC mechanisms. We present a series of benchmarks for our mechanism - which we call LOT (Low Overhead Transport) - and use them to assess its performance on realistic data loads based on Five\u2019s Autonomous Vehicle (AV) system, and extend our analysis to the case where multiple ROS nodes are running in Docker containers. We find that our mechanism performs up to two orders of magnitude better than the standard IPC via local loopback. Finally, we apply industry-standard profiling techniques to explore the hotspots of code running in both user and kernel space, comparing our implementation against alternatives.",
        "primary_area": "",
        "author": "Costin Iordache;Stephen M. Fendyke;Mike J. Jones;Robert A. Buckley;Costin Iordache;Stephen M. Fendyke;Mike J. Jones;Robert A. Buckley",
        "authorids": "/37089198161;/37089196196;/37089195723;/37089194547;/37089198161;/37089196196;/37089195723;/37089194547",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636018/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16973741736705198486&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9636222",
        "title": "Smooth Mesh Estimation from Depth Data using Non-Smooth Convex Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Meshes are commonly used as 3D maps since they encode the topology of the scene while being lightweight. Unfortunately, 3D meshes are mathematically difficult to handle directly because of their combinatorial and discrete nature. Therefore, most approaches generate 3D meshes of a scene after fusing depth data using volumetric or other representations. Nevertheless, volumetric fusion remains computationally expensive both in terms of speed and memory. In this paper, we leapfrog these intermediate representations and build a 3D mesh directly from a depth map and the sparse landmarks triangulated with visual odometry. To this end, we formulate a non-smooth convex optimization problem that we solve using a primal-dual method. Our approach generates a smooth and accurate 3D mesh that substantially improves the state-of-the-art on direct mesh reconstruction while running in real-time.",
        "primary_area": "",
        "author": "Antoni Rosinol;Luca Carlone;Antoni Rosinol;Luca Carlone",
        "authorids": "/37086933297;/37545784100;/37086933297;/37545784100",
        "aff": "Laboratory for Information & Decision Systems (LIDS), Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory for Information & Decision Systems (LIDS), Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636222/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16325142931052138764&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information & Decision Systems (LIDS)",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636878",
        "title": "SnakeRaven: Teleoperation of a 3D Printed Snake-like Manipulator Integrated to the RAVEN II Surgical Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Telerobotic systems combined with miniaturised snake-like or elephant-trunk robotic arms can improve the ergonomics and accessibility in minimally invasive surgical tasks such as knee arthroscopy. Such systems, however, are usually designed in a specific and integral approach, making it expensive to adapt to various procedures or patient anatomies. 3D printed instruments with a detachable design can bring the benefits of patient-specific customisation, affordability, and adaptability to new clinical scenarios. However, the integration of such snake-like instruments to standard telerobotic systems can be challenging in terms of design and control. In this study, a teleoperation system is developed to control and steer the pose of SnakeRaven: a 3D printed, customisable snake-like end-effector attached to the RAVEN II platform for the application of fibre-optic knee arthroscopy. Algorithms for the parametric inverse kinematics and mapping between the RAVEN II joint space to the coupled tendon-driven rolling joints are developed. The controller is tested and validated on the physical prototype interfacing with the RAVEN II platform in a teleoperation experiment. A video demonstrating the main results of this paper can be found via https://youtu.be/ApJjR853kIQ",
        "primary_area": "",
        "author": "Andrew Razjigaev;Ajay K. Pandey;David Howard;Jonathan Roberts;Liao Wu;Andrew Razjigaev;Ajay K. Pandey;David Howard;Jonathan Roberts;Liao Wu",
        "authorids": "/37088744634;/37087032453;/37086143521;/37278794400;/37085418896;/37088744634;/37087032453;/37086143521;/37278794400;/37085418896",
        "aff": "School of Electrical Engineering and Robotics, Queensland University of Technology and the Australian Centre for Robotic Vision, Brisbane, Australia; School of Electrical Engineering and Robotics, Queensland University of Technology and the Australian Centre for Robotic Vision, Brisbane, Australia; Cyber Physical Systems Program, Data61, CSIRO; School of Electrical Engineering and Robotics, Queensland University of Technology and the Australian Centre for Robotic Vision, Brisbane, Australia; School of Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636878/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9402598512519474004&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "Queensland University of Technology;CSIRO;University of New South Wales",
        "aff_unique_dep": "School of Electrical Engineering and Robotics;Cyber Physical Systems Program, Data61;School of Mechanical and Manufacturing Engineering",
        "aff_unique_url": "https://www.qut.edu.au;https://www.csiro.au;https://www.unsw.edu.au",
        "aff_unique_abbr": "QUT;CSIRO;UNSW",
        "aff_campus_unique_index": "0;0;0;2",
        "aff_campus_unique": "Brisbane;;Sydney",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9636217",
        "title": "Sniffy Bug: A Fully Autonomous Swarm of Gas-Seeking Nano Quadcopters in Cluttered Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Nano quadcopters are ideal for gas source localization (GSL) as they are safe, agile and inexpensive. However, their extremely restricted sensors and computational resources make GSL a daunting challenge. We propose a novel bug algorithm named \u2018Sniffy Bug', which allows a fully autonomous swarm of gas-seeking nano quadcopters to localize a gas source in unknown, cluttered, and GPS-denied environments. The computationally efficient, mapless algorithm foresees in the avoidance of obstacles and other swarm members, while pursuing desired waypoints. The waypoints are first set for exploration, and, when a single swarm member has sensed the gas, by a particle swarm optimization-based (PSO) procedure. We evolve all the parameters of the bug (and PSO) algorithm using our novel simulation pipeline, \u2018AutoGDM'. It builds on and expands open source tools in order to enable fully automated end-to-end environment generation and gas dispersion modeling, allowing for learning in simulation. Flight tests show that Sniffy Bug with evolved parameters outperforms manually selected parameters in cluttered, real-world environments. Videos: https://bit.ly/37MmtdL",
        "primary_area": "",
        "author": "Bardienus P. Duisterhof;Shushuai Li;Javier Burgu\u00e9s;Vijay Janapa Reddi;Guido C. H. E. de Croon;Bardienus P. Duisterhof;Shushuai Li;Javier Burgu\u00e9s;Vijay Janapa Reddi;Guido C. H. E. de Croon",
        "authorids": "/37089000405;/37086938217;/38276571900;/37293801200;/37698062600;/37089000405;/37086938217;/38276571900;/37293801200;/37698062600",
        "aff": "Delft University of Technology; Delft University of Technology; University of Barcelona; Harvard University; Delft University of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636217/",
        "gs_citation": 90,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11367428217202004983&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Delft University of Technology;University of Barcelona;Harvard University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.tudelft.nl;https://www.ub.edu;https://www.harvard.edu",
        "aff_unique_abbr": "TU Delft;UB;Harvard",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;2;0",
        "aff_country_unique": "Netherlands;Spain;United States"
    },
    {
        "id": "9636059",
        "title": "SoMo: Fast and Accurate Simulations of Continuum Robots in Complex Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Engineers and scientists often rely on their intuition and experience when designing soft robotic systems. The development of performant controllers and motion plans for these systems commonly requires time-consuming iterations on hardware. We present the SoMo (Soft Motion) toolkit, a software framework that makes it easy to instantiate and control typical continuum manipulators in an accurate physics simulator. SoMo introduces a standardized and human-readable description format for continuum manipulators. It leverages this description format and the Bullet physics engine to enable fast and accurate simulations of soft and soft-rigid hybrid robots in environments with complex contact interactions. This allows users to vary design and control parameters across simulations with minimal effort. We compare the capabilities of SoMo to other physics simulators and highlight the benefits and accuracy of SoMo by demonstrating the agreement between simulation and real-world experiments on several examples; these include an in-hand manipulation task with continuum fingers, an automated exploration of how to design soft fingers for precision grasping, and a brief snake locomotion study. Overall, SoMo provides an accessible way for designers of soft robotic hardware and control systems to gain access to a simulation-accelerated workflow.",
        "primary_area": "",
        "author": "Moritz A. Graule;Clark B. Teeple;Thomas P. McCarthy;Grace R. Kim;Randall C. St. Louis;Robert J. Wood;Moritz A. Graule;Clark B. Teeple;Thomas P. McCarthy;Grace R. Kim;Randall C. St. Louis;Robert J. Wood",
        "authorids": "/37085771962;/37086131116;/37089196310;/37088996387;/37089198250;/37326227400;/37085771962;/37086131116;/37089196310;/37088996387;/37089198250;/37326227400",
        "aff": "John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636059/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12103225172120859076&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "John A. Paulson School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636539",
        "title": "SoPrA: Fabrication & Dynamical Modeling of a Scalable Soft Continuum Robotic Arm with Integrated Proprioceptive Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to their inherent compliance, soft robots are more versatile than rigid linked robots when they interact with their environment, such as object manipulation or biomimetic motion, and are considered to be the key element in introducing robots to everyday environments. Although various soft robotic actuators exist, past research has focused primarily on designing and analyzing single components. Limited effort has been made to combine each component to create an overall capable, integrated soft robot. Ideally, the behavior of such a robot can be accurately modeled, and its motion within an environment uses its proprioception, without requiring external sensors. This work presents a design and modeling process for a Soft continuum Proprioceptive Arm (SoPrA) actuated by pneumatics. The integrated design is suitable for an analytical model due to its internal capacitive flex sensor for proprioceptive measurements and its fiber-reinforced fluidic elastomer actuators. The proposed analytical dynamical model accounts for the inertial effects of the actuator\u2019s mass and the material properties, and predicts in real-time the soft robot\u2019s behavior. Our estimation method integrates the analytical model with proprioceptive sensors to calculate external forces, all without relying on an external motion capture system. SoPrA is validated in a series of experiments demonstrating the model\u2019s and sensor\u2019s accuracy in estimation. SoPrA will enable soft arm manipulation including force sensing while operating in obstructed environments that disallows exteroceptive measurements.",
        "primary_area": "",
        "author": "Yasunori Toshimitsu;Ki Wan Wong;Thomas Buchner;Robert Katzschmann;Yasunori Toshimitsu;Ki Wan Wong;Thomas Buchner;Robert Katzschmann",
        "authorids": "/37086842924;/37088686152;/37088539885;/37085423557;/37086842924;/37088686152;/37088539885;/37085423557",
        "aff": "The University of Tokyo, Japan; ETH Zurich, Switzerland; ETH Zurich, Switzerland; ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636539/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17119393281616620276&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Tokyo;ETH Zurich",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.ethz.ch",
        "aff_unique_abbr": "UTokyo;ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Japan;Switzerland"
    },
    {
        "id": "9636868",
        "title": "Soft Manipulator Fault Detection and Identification Using ANC-based LSTM",
        "track": "main",
        "status": "Poster",
        "abstract": "Timely fault detection and identification (FDI) of soft manipulators are critical in the design of surgical systems to improve reliability. However, due to the intrinsic compliance of soft manipulators, their end effectors vibrate during the dynamic control process, which introduces noise into the measured signals and makes FDI of soft manipulators challenging. This paper proposes a novel method to accomplish these tasks based on Long Short Term Memory (LSTM) recurrent neural network. Based on LSTM network, a new Attention-based Noise Compensation (ANC) module is proposed to enable the network to filter the noise merged with signals input in a self-supervision manner. Moreover, weighted cross entropy loss is introduced to balance the normal and faulty samples in the training set. Of the 9930 samples presented to the model, 9489 are correctly diagnosed in less than 1.0 second, which implies that the method can learn the spatial and temporal dependence of the signals and distinguish the healthy modes from the faulty ones. Finally, we compare the ANC-based method with the vanilla LSTM method and the state-of-art Bruin et al. method. From the comparison, we conclude that the ANC-based method proposed in this paper not only shortens the time cost of the FDI process but also suppresses the sensitivity of diagnosis results to noise. Source code, pre-trained models and dataset are available on https://github.com/IRMVLab/ANC-LSTM-fault-detection.",
        "primary_area": "",
        "author": "Haoyuan Gu;Hanjiang Hu;Hesheng Wang;Weidong Chen;Haoyuan Gu;Hanjiang Hu;Hesheng Wang;Weidong Chen",
        "authorids": "/37088906015;/37087321985;/37292567100;/37279187800;/37088906015;/37087321985;/37292567100;/37279187800",
        "aff": "Department of Automation, Insititue of Medical Robotics, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Jiao Tong University, Shanghai, China; Department of Mechanical Engineering, Carnegie Mellon University, USA; Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, China; Department of Automation, Insititue of Medical Robotics, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636868/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17158214575215764173&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Carnegie Mellon University;Beijing Institute of Technology",
        "aff_unique_dep": "Department of Automation;Department of Mechanical Engineering;Beijing Advanced Innovation Center for Intelligent Robots and Systems",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.cmu.edu;http://www.bit.edu.cn/",
        "aff_unique_abbr": "SJTU;CMU;BIT",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Shanghai;;Beijing",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9636697",
        "title": "Soft Retraction Device and Internal Camera Mount for Everting Vine Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft, tip-extending, pneumatic \"vine robots\" that grow via eversion are well suited for navigating cluttered environments. Two key mechanisms that add to the robot\u2019s functionality are a tip-mounted retraction device that allows the growth process to be reversed, and a tip-mounted camera that enables vision. However, previous designs used rigid, relatively heavy electromechanical retraction devices and external camera mounts, which reduce some advantages of these robots. These designs prevent the robot from squeezing through tight gaps, make it challenging to lift the robot tip against gravity, and require the robot to drag components against the environment. To address these limitations, we present a soft, pneumatically driven retraction device and an internal camera mount that are both lightweight and smaller than the diameter of the robot. The retraction device is composed of a soft, extending pneumatic actuator and a pair of soft clamping actuators that work together in an inch-worming motion. The camera mount sits inside the robot body and is kept at the tip of the robot by two low-friction interlocking components. We present characterizations of our retraction device and demonstrations that the robot can grow and retract through turns, tight gaps, and sticky environments while transmitting live video from the tip. Our designs advance the ability of everting vine robots to navigate difficult terrain while collecting data.",
        "primary_area": "",
        "author": "William E. Heap;Nicholas D. Naclerio;Margaret M. Coad;Sang-Goo Jeong;Elliot W. Hawkes;William E. Heap;Nicholas D. Naclerio;Margaret M. Coad;Sang-Goo Jeong;Elliot W. Hawkes",
        "authorids": "/37089194162;/37086581043;/37086124465;/37086574861;/37681388800;/37089194162;/37086581043;/37086124465;/37086574861;/37681388800",
        "aff": "College of Engineering, University of California, Santa Barbara, CA, USA; Department of Mechanical Engineering, University of California, Santa Barbara, CA, USA; Department of Aerospace and Mechanical Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Civil and Environmental Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeonsi, Republic of Korea; Department of Mechanical Engineering, University of California, Santa Barbara, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636697/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9398326680755817945&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "University of California, Santa Barbara;University of Notre Dame;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "College of Engineering;Department of Aerospace and Mechanical Engineering;Department of Civil and Environmental Engineering",
        "aff_unique_url": "https://www.ucsb.edu;https://www.nd.edu;https://www.kaist.ac.kr",
        "aff_unique_abbr": "UCSB;Notre Dame;KAIST",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Santa Barbara;Notre Dame;Daejeonsi",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "9635896",
        "title": "Soft Robot Configuration Estimation and Control Using Simultaneous Localization and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a novel approach to accomplishing soft robot configuration estimation and control using RGB-D cameras and SLAM-based methods. By placing cameras on the unactuated sections of our large-scale (approximately 2 meters long) pneumatic soft robot, we can map an environment and then estimate the orientation of the robot links using landmark-based localization. Using the orientations of each camera we can solve for the joint configurations between them. We first show that this method works for a traditional rigid robot (Baxter) where we can compare against the ground truth encoder values. For Baxter, the median joint angle error was on the order of 1-2\u25e6. We then show that the SLAM-based method provides estimates for soft robot configuration that are within 1\u25e6 when compared to our past methods of using a HTC Vive Tracker. While HTC Vive Trackers and commonly used motion capture systems require externally mounted sensors placed in the robot\u2019s environment, the SLAM-based estimation method presented here works in any visually feature-rich environment. Finally we show that this method of estimation is effective for closed-loop control of soft robots by controlling our large-scale soft robot through a series of joint configurations.",
        "primary_area": "",
        "author": "Christian Sorensen;Phillip Hyatt;Matthew Ricks;Seth Nielsen;Marc D. Killpack;Christian Sorensen;Phillip Hyatt;Matthew Ricks;Seth Nielsen;Marc D. Killpack",
        "authorids": "/37089195385;/37085627187;/37089195842;/37089194120;/37592226100;/37089195385;/37085627187;/37089195842;/37089194120;/37592226100",
        "aff": "Christian Sorensen; Phillip Hyatt; Matthew Ricks; Seth Nielsen; Marc D. Killpack",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635896/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8348338252856244117&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "1",
        "aff_unique_norm": ";Matthew Ricks",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9635921",
        "title": "Soft-CCD Algorithm for Inverse Kinematics of Soft Continuum Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "To date, soft robots have been increasingly designed and analyzed, especially, Soft Continuum Manipulators (SCMs). Due to dexterous deformability, their Inverse Kinematics (IK) is still difficult to solve. Cyclic Coordinate Descent (CCD) algorithm is one of the classical optimization algorithms to solve IK of rigid manipulators with prismatic or rotational joints. However, it cannot be directly extrapolated to SCMs with configuration space parameters such as center arc, bending angle, and torsion angle. Here, we modified the CCD algorithm from a new view and proposed several tricks to set constraints. Numerical and experimental results show that the soft-CCD algorithm can quickly and accurately generate solutions for IK of SCMs. This study provides the necessary kinematic foundation for fault tolerance, obstacle avoidance, trajectory planning, and other further explorations of SCMs.",
        "primary_area": "",
        "author": "Zhiyuan Zhang;Songtao Wang;Deshan Meng;Xueqian Wang;Bin Liang;Zhiyuan Zhang;Songtao Wang;Deshan Meng;Xueqian Wang;Bin Liang",
        "authorids": "/37086415295;/37086416327;/37085515586;/37085383477;/37270783900;/37086415295;/37086416327;/37085515586;/37085383477;/37270783900",
        "aff": "Centre of Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; Research Institute of Tsinghua University in Shenzhen, Shenzhen, China; Centre of Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; Centre of Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China; Centre of Intelligent Control and Telescience, Tsinghua Shenzhen International Graduate School, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635921/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16070776328853742957&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Tsinghua Shenzhen International Graduate School;Tsinghua University",
        "aff_unique_dep": "Centre of Intelligent Control and Telescience;Research Institute",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua SIGS;THU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635883",
        "title": "Some Research Questions for SLAM in Deformable Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "SLAM in deformable environments is a very challenging research topic. Some research works have been presented by different research groups in the past few years. However, there are still some challenging research questions remaining unanswered. This paper discusses some of these research questions focusing on the case when point features are used to describe the deformable environments. The SLAM problems are formulated as extensions of point feature based SLAM in static environments, including both optimisation based offline SLAM and filter based online SLAM. To illustrate the problems and questions more clearly, some concepts and results using simple 2D examples are presented. The MATLAB source codes of the results are made publicly available (https://github.com/cyb1212/DeformableSLAM2D.git) to help the readers understand the problems more clearly.",
        "primary_area": "",
        "author": "Shoudong Huang;Yongbo Chen;Liang Zhao;Yanhao Zhang;Mengya Xu;Shoudong Huang;Yongbo Chen;Liang Zhao;Yanhao Zhang;Mengya Xu",
        "authorids": "/37421307400;/37086455426;/37857963600;/37088452302;/37089000274;/37421307400;/37086455426;/37857963600;/37088452302;/37089000274",
        "aff": "Centre for Autonomous Systems, University of Technology, Sydney, NSW, Australia; Centre for Autonomous Systems, University of Technology, Sydney, NSW, Australia; Centre for Autonomous Systems, University of Technology, Sydney, NSW, Australia; Centre for Autonomous Systems, University of Technology, Sydney, NSW, Australia; Centre for Autonomous Systems, University of Technology, Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635883/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=354534089494944216&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "Centre for Autonomous Systems",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9636841",
        "title": "Source Seeking by Dynamic Source Location Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper focuses on the problem of multi-robot source-seeking, where a group of mobile sensors localizes and moves close to a single source using only local measurements. Drawing inspiration from the optimal sensor placement research, we develop an algorithm that estimates the source location while approaches the source following gradient descent steps on a loss function defined on the Fisher information. We show that exploiting Fisher information gives a higher chance of obtaining an accurate source location estimate and naturally leads the sensors to the source. Our numerical experiments demonstrate the advantages of our algorithm, including faster convergence to the source than other algorithms, flexibility in the choice of the loss function, and robustness to measurement modeling errors. Moreover, the performance improves as the number of sensors increases, showing the advantage of using multi-robots in our source-seeking algorithm. We also implement physical experiments to test the algorithm on small ground vehicles with light sensors, demonstrating success in seeking a moving light source.",
        "primary_area": "",
        "author": "Tianpeng Zhang;Victor Qin;Yujie Tang;Na Li;Tianpeng Zhang;Victor Qin;Yujie Tang;Na Li",
        "authorids": "/37089196638;/37089197683;/37085645216;/37085399460;/37089196638;/37089197683;/37085645216;/37085399460",
        "aff": "School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636841/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1794300178684772019&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636296",
        "title": "Sparsification for Fast Optimal Multi-Robot Path Planning in Lazy Compilation Schemes",
        "track": "main",
        "status": "Poster",
        "abstract": "Path planning for multiple robots (MRPP) represents a task of finding non-colliding paths for robots via which they can navigate from their initial positions to specified goal positions. The problem is often modeled using undirected graphs where robots move between vertices across edges while no two robots can simultaneously occupy the same vertex nor can traverse an edge in opposite directions. Contemporary optimal solving algorithms include dedicated search-based methods, that solve the problem directly, and compilation-based algorithms that reduce MRPP to a different formalism for which an efficient solver exists, such as constraint programming (CP), mixed integer linear programming (MILP), or Boolean satisfiability (SAT). In this paper, we enhance existing SAT-based algorithm for MRPP via sparsification of the set of candidate paths for each robot from which the target Boolean encoding is derived. Suggested sparsification of the set of paths led to a smaller target Boolean formulae that can be constructed and solved faster while optimality guarantees of the approach have been kept.",
        "primary_area": "",
        "author": "Pavel Surynek;Pavel Surynek",
        "authorids": "/37698202400;/37698202400",
        "aff": "Faculty of Information Technology, Czech Technical University in Prague, Czechia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636296/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=38197722189574283&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Faculty of Information Technology",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Czechia"
    },
    {
        "id": "9636813",
        "title": "Spatial Action Maps Augmented with Visit Frequency Maps for Exploration Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning has been widely applied in exploration, navigation, manipulation, and other fields. Most of the relevant techniques generate kinematic commands (e.g., move, stop, turn) for agents based on the current state information. However, recent dense action representations based research, such as spatial action maps, pointing way-points to the agent in the same domain as its observation of the state shows great promise in mobile manipulation tasks. Inspired by that, we make the first step towards using a spatial action maps based method to effectively explore novel environmental spaces. To reduce the chance of redundant exploration, the visit frequency map (VFM) and its corresponding reward function are introduced to direct the agent to actively search previously unexplored areas. In the experimental section, our work was compared to the same method without VFM and the method based on traditional steering commands with the same input data in various environments. The results show conclusively that our method is more efficient than other methods. The project page is: https://github.com/zxwang96/sam-exploration",
        "primary_area": "",
        "author": "Zixing Wang;Nikolaos Papanikolopoulos;Zixing Wang;Nikolaos Papanikolopoulos",
        "authorids": "/37088689387;/37278578300;/37088689387;/37278578300",
        "aff": "Minnesota Robotics Institute (MnRI), University of Minnesota, Minneapolis, MN, USA; Faculty of the Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636813/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10680891703624838985&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Minnesota Robotics Institute (MnRI)",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636067",
        "title": "Spatial Constraint Generation for Motion Planning in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel method to generate spatial constraints for motion planning in dynamic environments. Motion planning methods for autonomous driving and mobile robots typically need to rely on the spatial constraints imposed by a map-based global planner to generate a collision-free trajectory. These methods may fail without an offline map or where the map is invalid due to dynamic changes in the environment such as road obstruction, construction, and traffic congestion. To address this problem, triangulation-based methods can be used to obtain a spatial constraint. However, the existing methods fall short when dealing with dynamic environments and may lead the motion planner to an unrecoverable state. In this paper, we propose a new method to generate a sequence of channels across different triangulation mesh topologies to serve as the spatial constraints. This can be applied to motion planning of autonomous vehicles or robots in cluttered, unstructured environments. The proposed method is evaluated and compared with other triangulation-based methods in synthetic and complex scenarios collected from a real-world autonomous driving dataset. We have shown that the proposed method results in a more stable, long-term plan with a higher task completion rate, faster arrival time, a higher rate of successful plans, and fewer collisions compared to existing methods.",
        "primary_area": "",
        "author": "Han Hu;Peyman Yadmellat;Han Hu;Peyman Yadmellat",
        "authorids": "/37088915333;/37078570200;/37088915333;/37078570200",
        "aff": "Department of Mechanical & Industrial Engineering, University of Toronto, Toronto, Canada; Noah\u2019s Ark Lab, Huawei Technologies Canada, Markham, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636067/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6051778504701590654&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Toronto;Huawei",
        "aff_unique_dep": "Department of Mechanical & Industrial Engineering;Noah\u2019s Ark Lab",
        "aff_unique_url": "https://www.utoronto.ca;https://www.huawei.com/ca-en/",
        "aff_unique_abbr": "U of T;Huawei",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Toronto;Markham",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636550",
        "title": "Spatial Imagination With Semantic Cognition for Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The imagination of the surrounding environment based on the experience and semantic cognition has great potential to extend the limited observations to leverage the ability for mapping, collision avoidance and path planning. This paper provides a training-based algorithm for mobile robots to perform spatial imagination based on semantic cognition and evaluates the proposed method for the mapping task. We utilize a photo-realistic simulation environment, Habitat, for training and evaluation. The trained model is composed of Resent-18 as encoder and U-net as the backbone. We demonstrate that the algorithm can perform imagination for unseen parts of the object universally, by recalling the images and experience and compare our approach with traditional semantic mapping methods. It is found that our approach will improve the efficiency and accuracy of semantic mapping.",
        "primary_area": "",
        "author": "Zhengcheng Shen;Linh K\u00e4stner;Jens Lambrecht;Zhengcheng Shen;Linh K\u00e4stner;Jens Lambrecht",
        "authorids": "/37088811455;/37087466037;/37342634600;/37088811455;/37087466037;/37342634600",
        "aff": "Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering, and Computer Science, Berlin Institute of Technology, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636550/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2167969778198844546&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Berlin Institute of Technology",
        "aff_unique_dep": "Faculty of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636235",
        "title": "SpectGRASP: Robotic Grasping by Spectral Correlation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a spectral correlation-based method (SpectGRASP) for robotic grasping of arbitrarily shaped, unknown objects. Given a point cloud of an object, SpectGRASP extracts contact points on the object\u2019s surface matching the hand configuration. It neither requires offline training nor a-priori object models. We propose a novel Binary Extended Gaussian Image (BEGI), which represents the point cloud surface normals of both object and robot fingers as signals on a 2-sphere. Spherical harmonics are then used to estimate the correlation between fingers and object BEGIs. The resulting spectral correlation density function provides a similarity measure of gripper and object surface normals. This is highly efficient in that it is simultaneously evaluated at all possible finger rotations in SO(3). A set of contact points are then extracted for each finger using rotations with high correlation values. We then use our previous work, Local Contact Moment (LoCoMo) similarity metric, to sequentially rank the generated grasps such that the one with maximum likelihood is executed. We evaluate the performance of SpectGRASP by conducting experiments with a 7-axis robot fitted with a parallel-jaw gripper, in a physics simulation environment. Obtained results indicate that the method not only can grasp individual objects, but also can successfully clear randomly organized groups of objects. The SpectGRASP method also outperforms the closest state-of-the-art method in terms of grasp generation time and grasp-efficiency.",
        "primary_area": "",
        "author": "Maxime Adjigble;Cristiana de Farias;Rustam Stolkin;Naresh Marturi;Maxime Adjigble;Cristiana de Farias;Rustam Stolkin;Naresh Marturi",
        "authorids": "/37085407107;/37088812520;/37424300500;/37085558507;/37085407107;/37088812520;/37424300500;/37085558507",
        "aff": "Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, Edgbaston, UK; Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, Edgbaston, UK; Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, Edgbaston, UK; Extreme Robotics Laboratory, School of Metallurgy and Materials, University of Birmingham, Edgbaston, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636235/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3288597406257656939&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Birmingham",
        "aff_unique_dep": "School of Metallurgy and Materials",
        "aff_unique_url": "https://www.birmingham.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Edgbaston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636506",
        "title": "SpikeMS: Deep Spiking Neural Network for Motion Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Spiking Neural Networks (SNN) are the so-called third generation of neural networks which attempt to more closely match the functioning of the biological brain. They inherently encode temporal data, allowing for training with less energy usage and can be extremely energy efficient when coded on neuromorphic hardware. In addition, they are well suited for tasks involving event-based sensors, which match the event-based nature of the SNN. However, SNNs have not been as effectively applied to real-world, large-scale tasks as standard Artificial Neural Networks (ANNs) due to the algorithmic and training complexity. To exacerbate the situation further, the input representation is unconventional and requires careful analysis and deep understanding. In this paper, we propose SpikeMS, the first deep encoder-decoder SNN architecture for the real-world large-scale problem of motion segmentation using the event-based DVS camera as input. To accomplish this, we introduce a novel spatio-temporal loss formulation that includes both spike counts and classification labels in conjunction with the use of new techniques for SNN backpropagation. In addition, we show that SpikeMS is capable of incremental predictions, or predictions from smaller amounts of test data than it is trained on. This is invaluable for providing outputs even with partial input data for low-latency applications and those requiring fast predictions. We evaluated SpikeMS on challenging synthetic and real-world sequences from EV-IMO, EED and MOD datasets and achieving results on a par with a comparable ANN method, but using potentially 50 times less power.",
        "primary_area": "",
        "author": "Chethan M. Parameshwara;Simin Li;Cornelia Ferm\u00fcller;Nitin J. Sanket;Matthew S. Evanusa;Yiannis Aloimonos;Chethan M. Parameshwara;Simin Li;Cornelia Ferm\u00fcller;Nitin J. Sanket;Matthew S. Evanusa;Yiannis Aloimonos",
        "authorids": "/37086581058;/37089195829;/37269887600;/37086390746;/37088363359;/37282631400;/37086581058;/37089195829;/37269887600;/37086390746;/37088363359;/37282631400",
        "aff": "Perception and Robotics Group, University of Maryland, College Park; Perception and Robotics Group, University of Maryland, College Park; Perception and Robotics Group, University of Maryland, College Park; Perception and Robotics Group, University of Maryland, College Park; Perception and Robotics Group, University of Maryland, College Park; Perception and Robotics Group, University of Maryland, College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636506/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9165932926821442524&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "Perception and Robotics Group",
        "aff_unique_url": "https://www.umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636356",
        "title": "Stability and Robustness Analysis of Plug-Pulling using an Aerial Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, an autonomous aerial manipulation task of pulling a plug out of an electric socket is conducted, where maintaining the stability and robustness is challenging due to sudden disappearance of a large interaction force. The abrupt change in the dynamical model before and after the separation of the plug can cause destabilization or mission failure. To accomplish aerial plug-pulling, we employ the concept of hybrid automata to divide the task into three operative modes, i.e, wire-pulling, stabilizing, and free-flight. Also, a strategy for trajectory generation and a design of disturbance-observer-based controllers for each operative mode are presented. Furthermore, the theory of hybrid automata is used to prove the stability and robustness during the mode transition. We validate the proposed trajectory generation and control method by an actual wire-pulling experiment with a multirotor-based aerial manipulator.",
        "primary_area": "",
        "author": "Jeonghyun Byun;Dongjae Lee;Hoseong Seo;Inkyu Jang;Jeongjun Choi;H. Jin Kim;Jeonghyun Byun;Dongjae Lee;Hoseong Seo;Inkyu Jang;Jeongjun Choi;H. Jin Kim",
        "authorids": "/37089194964;/37086933985;/37085446499;/37087499137;/37089003541;/37599626400;/37089194964;/37086933985;/37085446499;/37087499137;/37089003541;/37599626400",
        "aff": "Department of Aerospace Engineering, Automation and System Research Institute (ASRI), Seoul National University, Seoul, South Korea; Department of Aerospace Engineering, Automation and System Research Institute (ASRI), Seoul National University, Seoul, South Korea; Department of Aerospace Engineering, Automation and System Research Institute (ASRI), Seoul National University, Seoul, South Korea; Department of Aerospace Engineering, Automation and System Research Institute (ASRI), Seoul National University, Seoul, South Korea; Department of Aerospace Engineering, Automation and System Research Institute (ASRI), Seoul National University, Seoul, South Korea; Department of Aerospace Engineering, Automation and System Research Institute (ASRI), Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636356/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3432088430831584982&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9635952",
        "title": "Stable Haptic Teleoperation of UAVs via Small L2 Gain and Control Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel haptic teleoperation approach that considers not only the safety but also the stability of a teleoperation system. Specifically, we build upon previous work on haptic shared control, which generates a reference haptic feedback that helps the human operator to safely navigate the robot but without taking away their control authority. Crucially, in this approach the force rendered to the user is not directly reflected in the motion of the robot (which is still directly controlled by the user); however, previous work in the area neglected to consider the possible instabilities in feedback loop generated by a user that over-responds to the haptic force. In this paper we introduce a differential constraint on the rendered force that makes the system finite-gain {{\\mathcal{L}}_2}{{\\mathcal{L}}_2} stable; the constraint results in a Quadratically Constrained Quadratic Program (QCQP), for which we provide a closed-form solution. Our constraint is related to, but less restrictive than, the typical passivity constraint used in previous literature. We conducted an experimental simulation in which a human operator flies a UAV near an obstacle to evaluate the proposed method.",
        "primary_area": "",
        "author": "Dawei Zhang;Roberto Tron;Dawei Zhang;Roberto Tron",
        "authorids": "/37088335718;/37398528900;/37088335718;/37398528900",
        "aff": "Department of Mechanical Engineering, Boston University, Boston, MA, USA; Department of Mechanical Engineering and the Division of Systems Engineering, Boston University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635952/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14790163024263902513&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Boston University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.bu.edu",
        "aff_unique_abbr": "BU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636116",
        "title": "State Estimation and Model-Predictive Control for Multi-Robot Handling and Tracking of AGV Motions using iGPS",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a solution for simultaneous handling of large components with industrial robots performing synchronized motions with an AGV in flexible flow assembly. For this purpose, we implement an Extended Kalman Filter with a global localization system to track an AGV and multiple manipulators. We propose a model-predictive controller for force compliance and trajectory tracking in multi-robot cooperative, decentralized, and fast manipulation tasks. In order to show the effectiveness of our system, we assemble a truck windshield using two industrial robots and an AGV in motion. In our experiments, we reliably achieve assembly tolerances of 1.5mm at AGV velocities up to 400\\frac{{{\\text{mm}}}}{{\\text{s}}}400\\frac{{{\\text{mm}}}}{{\\text{s}}}. The presented system makes flexible assembly systems with AGVs and freely reconfigurable manipulators possible. It enables the automation of high variant, low volume, large size assembly tasks such as aircraft, truck or steel beam assembly, which are mostly manual processes at present.",
        "primary_area": "",
        "author": "Christoph Storm;Henrik Hose;Robert H. Schmitt;Christoph Storm;Henrik Hose;Robert H. Schmitt",
        "authorids": "/37089194164;/37089194309;/37320386200;/37089194164;/37089194309;/37320386200",
        "aff": "Chair of Production Metrology and Quality Management at Laboratory for Machine Tools and Production Engineering (WZL), RWTH Aachen University, Germany; Chair of Production Metrology and Quality Management at Laboratory for Machine Tools and Production Engineering (WZL), RWTH Aachen University, Germany; Fraunhofer Institute for Production Technology IPT, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636116/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3156860772609138103&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "RWTH Aachen University;Fraunhofer Institute for Production Technology IPT",
        "aff_unique_dep": "Chair of Production Metrology and Quality Management;",
        "aff_unique_url": "https://www.rwth-aachen.de;https://www.ipt.fraunhofer.de/",
        "aff_unique_abbr": "RWTH;IPT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636132",
        "title": "State Estimation of a Partially Observable Multi-Link System with No Joint Encoders Incorporating External Dead-Reckoning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a technique for state estimation of a multi-link system having no joint encoders, which can only be partially observed by a camera. To fully observe the system without changing the current configuration, a gyroscope and an accelerometer are attached to each link as dead-reckoning sensors. Observations of the dead-reckoning sensors are associated with the states of the multi-link system such that the states are fully observable. The camera, which observes part of the system globally, is used as a global corrector in the framework of an extended Kalman filter to filter the dead-reckoning errors accumulated over time. Parametric studies in simulation have investigated and identified the efficacy of the proposed technique in estimating the state of the multilink system. Experimental validation using a two-link arm has demonstrated the applicability of the proposed technique to real-world multi-link systems.",
        "primary_area": "",
        "author": "Tomonari Furukawa;J. Josiah Steckenrider;Gamini Dissanayake;Tomonari Furukawa;J. Josiah Steckenrider;Gamini Dissanayake",
        "authorids": "/37280186200;/37086319773;/37279864800;/37280186200;/37086319773;/37279864800",
        "aff": "Department of Mechanical and Aerospace Engineering, University of Virginia, Charlottesville, VA, USA; Department of Civil and Mechanical Engineering, United States Military Academy, West Point, NY, USA; Center for Autonomous Systems, University of Technology, Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636132/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2195959443205521469&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Virginia;United States Military Academy;University of Technology Sydney",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering;Department of Civil and Mechanical Engineering;Center for Autonomous Systems",
        "aff_unique_url": "https://www.virginia.edu;https://www.usma.edu;https://www.uts.edu.au",
        "aff_unique_abbr": "UVA;USMA;UTS",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Charlottesville;West Point;Sydney",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "9636557",
        "title": "State-Only Imitation Learning for Dexterous Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern model-free reinforcement learning methods have recently demonstrated impressive results on a number of problems. However, complex domains like dexterous manipulation remain a challenge due to the high sample complexity. To address this, current approaches employ expert demonstrations in the form of state-action pairs, which are difficult to obtain for real-world settings such as learning from videos. In this paper, we move toward a more realistic setting and explore state-only imitation learning. To tackle this setting, we train an inverse dynamics model and use it to predict actions for state-only demonstrations. The inverse dynamics model and the policy are trained jointly. Our method performs on par with state-action approaches and considerably outperforms RL alone. By not relying on expert actions, we are able to learn from demonstrations with different dynamics, morphologies, and objects. Videos available on the {\\text{project page}}{\\text{project page}}.",
        "primary_area": "",
        "author": "Ilija Radosavovic;Xiaolong Wang;Lerrel Pinto;Jitendra Malik;Ilija Radosavovic;Xiaolong Wang;Lerrel Pinto;Jitendra Malik",
        "authorids": "/37086565491;/37085652454;/37085796211;/37282929000;/37086565491;/37085652454;/37085796211;/37282929000",
        "aff": "UC Berkeley; UC San Diego; New York University; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636557/",
        "gs_citation": 135,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5724720693621611196&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of California, Berkeley;University of California, San Diego;New York University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.ucsd.edu;https://www.nyu.edu",
        "aff_unique_abbr": "UC Berkeley;UCSD;NYU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Berkeley;San Diego;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636312",
        "title": "Stereo Hybrid Event-Frame (SHEF) Cameras for 3D Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Stereo camera systems play an important role in robotics applications to perceive the 3D world. However, conventional cameras have drawbacks such as low dynamic range, motion blur and latency due to the underlying frame- based mechanism. Event cameras address these limitations as they report the brightness changes of each pixel independently with a fine temporal resolution, but they are unable to acquire absolute intensity information directly. Although integrated hybrid event-frame sensors (e.g., DAVIS) are available, the quality of data is compromised by coupling at the pixel level in the circuit fabrication of such cameras. This paper proposes a stereo hybrid event-frame (SHEF) camera system that offers a sensor modality with separate high-quality pure event and pure frame cameras, overcoming the limitations of each separate sensor and allowing for stereo depth estimation. We provide a SHEF dataset targeted at evaluating disparity estimation algorithms and introduce a stereo disparity estimation algorithm that uses edge information extracted from the event stream correlated with the edge detected in the frame data. Our disparity estimation outperforms the state-of-the-art stereo matching algorithm on the SHEF dataset.",
        "primary_area": "",
        "author": "Ziwei Wang;Liyuan Pan;Yonhon Ng;Zheyu Zhuang;Robert Mahony;Ziwei Wang;Liyuan Pan;Yonhon Ng;Zheyu Zhuang;Robert Mahony",
        "authorids": "/37089197011;/37086239830;/37086203065;/37087324996;/37283743600;/37089197011;/37086239830;/37086203065;/37087324996;/37283743600",
        "aff": "Systems Theory and Robotics Group, College of Engineering and Computer Science, The Australian National University; A&F, Commonwealth Scientific and Industrial Research Organization (CSIRO), Canberra, Australia; Systems Theory and Robotics Group, College of Engineering and Computer Science, The Australian National University; Systems Theory and Robotics Group, College of Engineering and Computer Science, The Australian National University; Systems Theory and Robotics Group, College of Engineering and Computer Science, The Australian National University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636312/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9922734830644048211&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Australian National University;Commonwealth Scientific and Industrial Research Organization",
        "aff_unique_dep": "College of Engineering and Computer Science;",
        "aff_unique_url": "https://www.anu.edu.au;https://www.csiro.au",
        "aff_unique_abbr": "ANU;CSIRO",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Canberra",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9636616",
        "title": "Stereo Matching by Self-supervision of Multiscopic Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-supervised learning for depth estimation possesses several advantages over supervised learning. The benefits of no need for ground-truth depth, online fine-tuning, and better generalization with unlimited data attract researchers to seek self-supervised solutions. In this work, we propose a new self-supervised framework for stereo matching utilizing multiple images captured at aligned camera positions. A cross photometric loss, an uncertainty-aware mutual-supervision loss, and a new smoothness loss are introduced to optimize the network in learning disparity maps end-to-end without ground-truth depth information. To train this framework, we build a new multiscopic dataset consisting of synthetic images rendered by 3D engines and real images captured by real cameras. After being trained with only the synthetic images, our network can perform well in unseen outdoor scenes. Our experiment shows that our model obtains better disparity maps than previous unsupervised methods on the KITTI dataset and is comparable to supervised methods when generalized to unseen data. Our source code and dataset are available at https://sites.google.com/view/multiscopic.",
        "primary_area": "",
        "author": "Weihao Yuan;Yazhan Zhang;Bingkun Wu;Siyu Zhu;Ping Tan;Michael Yu Wang;Qifeng Chen;Weihao Yuan;Yazhan Zhang;Bingkun Wu;Siyu Zhu;Ping Tan;Michael Yu Wang;Qifeng Chen",
        "authorids": "/37086455209;/37086842950;/37089196117;/37085442921;/37085414267;/37280913900;/37087230927;/37086455209;/37086842950;/37089196117;/37085442921;/37085414267;/37280913900;/37087230927",
        "aff": "AI Lab, Alibaba Cloud, China; Dept. MAE and Dept. CSE, Hong Kong University of Science and Technology, China; Beihang University, China; AI Lab, Alibaba Cloud, China; AI Lab, Alibaba Cloud, China; Dept. MAE and Dept. CSE, Hong Kong University of Science and Technology, China; Dept. MAE and Dept. CSE, Hong Kong University of Science and Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636616/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3162118693286257716&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;0;1;1",
        "aff_unique_norm": "Alibaba Cloud;Hong Kong University of Science and Technology;Beihang University",
        "aff_unique_dep": "AI Lab;Dept. MAE;",
        "aff_unique_url": "https://www.alibabacloud.com;https://www.ust.hk;http://www.buaa.edu.cn/",
        "aff_unique_abbr": "Alibaba Cloud;HKUST;BUAA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636822",
        "title": "Stereo Perception in the Dark using Uncalibrated Line Laser",
        "track": "main",
        "status": "Poster",
        "abstract": "Perception using stereo requires external light. In the absence of natural light, active, structured light provides light where it is needed. In this work, we demonstrate how a free moving line striping laser can be used to perceive and model terrains. In this formulation, we do not need to know the position of the laser with respect to the stereo pair which precludes the need for calibrating the laser position. This also saves an actuator as the laser can be passively articulated using a spring. In this paper, we present the algorithms to efficiently extract the laser pixels from the stereo image pair. We also present techniques to use the structure of the light and overcome degenerate cases to build cleaner maps. This perception method benefits micro-rovers specifically those trying to operate in the extreme lighting conditions.",
        "primary_area": "",
        "author": "Srinivasan Vijayarangan;David Wettergreen;Srinivasan Vijayarangan;David Wettergreen",
        "authorids": "/37086289991;/37270533700;/37086289991;/37270533700",
        "aff": "Robotics Institute at Carnegie Mellon University, Pittsburgh, USA; Robotics Institute at Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636822/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:IBVFSsxrtfkJ:scholar.google.com/&scioq=Stereo+Perception+in+the+Dark+using+Uncalibrated+Line+Laser&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635961",
        "title": "Stereo Plane SLAM Based on Intersecting Lines",
        "track": "main",
        "status": "Poster",
        "abstract": "Plane features can be used to reduce drift errors in SLAM systems, especially in indoor environments. It is easy and efficient to extract planes from a dense point cloud, which is commonly generated from a RGB-D camera or a 3D lidar. But when using a stereo camera, it is hard to compute dense point clouds accurately or efficiently. In this paper, we propose a novel method to compute plane parameters using intersecting lines, which are extracted from stereo images. Plane features are commonly extracted from the surface of man-made objects or structures, which have regular shapes and straight edge lines. In three dimensions, two intersecting lines determine a unique plane. Therefore, we extract line segments from both left and right images of a stereo camera. By stereo matching, we compute lines\u2019 endpoints and direction vectors, and then a plane from two intersecting lines is calculated. We discard inaccurate plane features in the frame tracking. Adding such plane features in the stereo SLAM system reduces drift errors and refines the performance. Finally, we build a global map consisting of both points and planes, which can reflect real scene structures. We test our proposed system on public datasets and demonstrate its accurate estimation results, compared with state-of-the-art SLAM systems. To benefit the research of plane-based SLAM, we release our codes at https://github.com/fishmarch/Stereo-Plane-SLAM.",
        "primary_area": "",
        "author": "Xiaoyu Zhang;Wei Wang;Xianyu Qi;Ziwei Liao;Xiaoyu Zhang;Wei Wang;Xianyu Qi;Ziwei Liao",
        "authorids": "/37088703128;/37292859700;/37088699560;/37088699614;/37088703128;/37292859700;/37088699560;/37088699614",
        "aff": "Robotics Institute, Beihang University, Beijing, China; Robotics Institute, Beihang University, Beijing, China; Robotics Institute, Beihang University, Beijing, China; Robotics Institute, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635961/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5892778047334981990&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "http://www.buaa.edu.cn",
        "aff_unique_abbr": "BUAA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636807",
        "title": "Stereo Visual Inertial Odometry for Robots with Limited Computational Resources",
        "track": "main",
        "status": "Poster",
        "abstract": "Current existing stereo visual odometry algorithms are computationally too expensive for robots with restricted resources. Executing these algorithms on such robots leads to a low frame rate and unacceptable decay in accuracy. We modify S-MSCKF, one of the most computationally efficient stereo Visual Inertial Odometry (VIO) algorithm, to improve its speed and accuracy when tracking low numbers of features. Specifically, we implement the Inverse Lucas-Kanade (ILK) algorithm for feature tracking and stereo matching. An outlier detector based on the average sum square difference of the template and matching warp in the ILK ensures higher robustness, e.g., in the presence of brightness changes. We restrict stereo matching to slide the window only in the x-direction to further decrease the computational costs. Moreover, we limit detection of new features to the regions of interest that have too few features. The modified S-MSCKF uses half of the processing time while obtaining competitive accuracy. This allows the algorithm to run in real-time on the extremely limited Raspberry Pi Zero single-board computer.",
        "primary_area": "",
        "author": "Stavrow Bahnam;Sven Pfeiffer;Guido C.H.E. de Croon;Stavrow Bahnam;Sven Pfeiffer;Guido C.H.E. de Croon",
        "authorids": "/37089195844;/37089021556;/37698062600;/37089195844;/37089021556;/37698062600",
        "aff": "MAVLab, Control and Operations Department, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; MAVLab, Control and Operations Department, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands; MAVLab, Control and Operations Department, Faculty of Aerospace Engineering, Delft University of Technology, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636807/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2699085698385418378&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Control and Operations Department",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TUDelft",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9636216",
        "title": "Stereo Waterdrop Removal with Row-wise Dilated Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing vision systems for autonomous driving or robots are sensitive to waterdrops adhered to windows or camera lenses. Most recent waterdrop removal approaches take a single image as input and often fail to recover the missing content behind waterdrops faithfully. Thus, we propose a learning-based model for waterdrop removal with stereo images. To better detect and remove waterdrops from stereo images, we propose a novel row-wise dilated attention module to enlarge attention\u2019s receptive field for effective information propagation between the two stereo images. In addition, we propose an attention consistency loss between the ground-truth disparity map and attention scores to enhance the left-right consistency in stereo images. Because of related datasets\u2019 unavailability, we collect a real-world dataset that contains stereo images with and without waterdrops. Extensive experiments on our dataset suggest that our model outperforms state-of-the-art methods both quantitatively and qualitatively. Our source code and the stereo waterdrop dataset are available at https://github.com/VivianSZF/Stereo-Waterdrop-Removal.",
        "primary_area": "",
        "author": "Zifan Shi;Na Fan;Dit-Yan Yeung;Qifeng Chen;Zifan Shi;Na Fan;Dit-Yan Yeung;Qifeng Chen",
        "authorids": "/37089016455;/37089195092;/37270592100;/37087230927;/37089016455;/37089195092;/37270592100;/37087230927",
        "aff": "Department of Computer Science and Engineering, HKUST; Department of Computer Science and Engineering, HKUST; Department of Computer Science and Engineering, HKUST; Department of Computer Science and Engineering, HKUST",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636216/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9016513075771815414&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.hkust.edu.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636050",
        "title": "StereoCNC: A Stereovision-guided Robotic Laser System",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a stereovision-guided robotic laser system that can conduct laser ablation on targets selected by human operators in the color image, referred as StereoCNC. Two digital cameras are integrated into a previously developed robotic laser system to add a color sensing modality and formulate the stereovision. A calibration method is implemented to register the coordinate frames between stereo cameras and the laser system, modelled as a 3D-to-3D Least-squares problem. This problem is solved by a RANSAC-based 3D rigid transformation method and the calibration reprojection errors are used to characterize a 3D error field by Gaussian process regression. This regression error model is used to predict an error value for each data point of a stereo-reconstructed point cloud and an optimization problem is formulated to adjust the surgical site to a new position with minimum reprojection errors. Based on the calibrated system and the error model, a stereovision-guided laser-tissue removal pipeline is proposed to precisely locate, target, and ablate a surface region. The pipeline is validated by the experiments on phantoms with color texture and various geometric shapes. The overall targeting accuracy of the system achieves an average RMSE of 0.13\u00b10.02 mm and maximum error of 0.34\u00b10.06 mm, as measured by pre- and post-laser ablation images. The results show potential applications of using the developed stereovision-guided robotic system for superficial laser surgery, including dermatologic applications or removal of exposed tumorous tissue in neurosurgery.",
        "primary_area": "",
        "author": "Guangshen Ma;Weston Ross;Patrick J. Codd;Guangshen Ma;Weston Ross;Patrick J. Codd",
        "authorids": "/37086933341;/37085784524;/37688751700;/37086933341;/37085784524;/37688751700",
        "aff": "Department of Mechanical Engineering and Materials Science, Duke University; Department of Neurosurgery, Duke University Medical Center; Department of Neurosurgery, Duke University Medical Center",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636050/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8109360723374018475&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "Department of Mechanical Engineering and Materials Science",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Durham",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635987",
        "title": "Stochastic Guidance of Buoyancy Controlled Vehicles under Ice Shelves using Ocean Currents",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel technique for guidance of buoyancy-controlled vehicles in uncertain under-ice ocean flows. In-situ melt rate measurements collected at the grounding zone of Antarctic ice shelves, where the ice shelf meets the underlying bedrock, are essential to constrain models of future sea level rise. Buoyancy-controlled vehicles, which control their vertical position in the water column through internal actuation but have no means of horizontal propulsion, offer an affordable and reliable platform for such in-situ data collection. However, reaching the grounding zone requires vehicles to traverse tens of kilometers under the ice shelf, with approximate position knowledge and no means of communication, in highly variable and uncertain ocean currents. To address this challenge, we propose a partially observable MDP approach that exploits model-based knowledge of the under-ice currents and, critically, of their uncertainty, to synthesize effective guidance policies. The approach uses approximate dynamic programming to model uncertainty in the currents, and QMDP to address localization uncertainty. Numerical experiments show that the policy can deliver up to 88.8% of underwater vehicles to the grounding zone \u2013 a 33% improvement compared to state-of-the-art guidance techniques, and a 262% improvement over uncontrolled drifters. Collectively, these results show that model-based under-ice guidance is a highly promising technique for exploration of under-ice cavities, and has the potential to enable cost-effective and scalable access to these challenging and rarely observed environments.",
        "primary_area": "",
        "author": "Federico Rossi;Andrew Branch;Michael P. Schodlok;Timothy Stanton;Ian G. Fenty;Joshua Vander Hook;Evan B. Clark;Federico Rossi;Andrew Branch;Michael P. Schodlok;Timothy Stanton;Ian G. Fenty;Joshua Vander Hook;Evan B. Clark",
        "authorids": "/37085471827;/37087630521;/37089196126;/37089194757;/37087088571;/37073898100;/37088371694;/37085471827;/37087630521;/37089196126;/37089194757;/37087088571;/37073898100;/37088371694",
        "aff": "Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Moss Landing Marine Laboratories; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635987/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15260075677251459674&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;0;0",
        "aff_unique_norm": "California Institute of Technology;Moss Landing Marine Laboratories",
        "aff_unique_dep": "Jet Propulsion Laboratory;",
        "aff_unique_url": "https://www.caltech.edu;https://mlml.calstate.edu/",
        "aff_unique_abbr": "Caltech;",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pasadena;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636204",
        "title": "StyleLess layer: Improving robustness for real-world driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Neural Networks (DNNs) are a critical component for self-driving vehicles. They achieve impressive performance by reaping information from high amounts of labeled data. Yet, the full complexity of the real world cannot be encapsulated in the training data, no matter how big the dataset, and DNNs can hardly generalize to unseen conditions. Robustness to various image corruptions, caused by changing weather conditions or sensor degradation and aging, is crucial for safety when such vehicles are deployed in the real world. We address this problem through a novel type of layer, dubbed StyleLess, which enables DNNs to learn robust and informative features that can cope with varying external conditions. We propose multiple variations of this layer that can be integrated in most of the architectures and trained jointly with the main task. We validate our contribution on typical autonomous-driving tasks (detection, semantic segmentation), showing that in most cases, this approach improves predictive performance on unseen conditions (fog, rain), while preserving performance on seen conditions and objects.",
        "primary_area": "",
        "author": "Julien Rebut;Andrei Bursuc;Patrick P\u00e9rez;Julien Rebut;Andrei Bursuc;Patrick P\u00e9rez",
        "authorids": "/37063605600;/37547440400;/37276709400;/37063605600;/37547440400;/37276709400",
        "aff": "valeo.ai; valeo.ai; valeo.ai",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636204/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13667536045656801069&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Valeo",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.valeo.com",
        "aff_unique_abbr": "Valeo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636166",
        "title": "Sub-optimal and robust path tracking: a geometric approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Path tracking controllers for non-holonomic vehicles are commonly designed with primary focus on robustness to different kinds of disturbances, vehicle dynamics and other effects. Subsequently, the path tracking behavior is improved by parameter optimization or controller extensions. The possible improvement, however, is already limited by the control design itself. To overcome this drawback, this paper presents an alternative approach: In a first step, we formulate the geometrically optimal solution for a Dubins car reaching a straight target path as a globally stabilizing sliding-mode feedback law. In a second step, we introduce a single tuning parameter that achieves robustness with respect to exemplary matched disturbances. The result is a sub-optimal but robust controller. We investigate the impact of tuning this parameter towards optimality or robustness with respect to the transient and stationary tracking behavior in simulation scenarios. Following the presented approach, it is possible to adapt the control law with respect to various disturbances facing and utilizing the trade-off between optimality and robustness. This is a significant advantage in the design of path tracking controllers due to the variety of vehicle actuation and measurement systems and operational design domains.",
        "primary_area": "",
        "author": "Karin Tieber;Johannes Rumetshofer;Michael Stolz;Daniel Watzenig;Karin Tieber;Johannes Rumetshofer;Michael Stolz;Daniel Watzenig",
        "authorids": "/37088594735;/37086323359;/37682663800;/37272706100;/37088594735;/37086323359;/37682663800;/37272706100",
        "aff": "Virtual Vehicle Research GmbH, Graz, Austria; Institute of Automation and Control, Graz University of Technology, Graz, Austria; Institute of Automation and Control, Graz University of Technology, Graz, Austria; Institute of Automation and Control, Graz University of Technology, Graz, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636166/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3983963787503823291&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Virtual Vehicle Research GmbH;Graz University of Technology",
        "aff_unique_dep": ";Institute of Automation and Control",
        "aff_unique_url": ";https://www.tugraz.at",
        "aff_unique_abbr": ";TU Graz",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Graz",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9636743",
        "title": "Success Weighted by Completion Time: A Dynamics-Aware Evaluation Criteria for Embodied Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present Success weighted by Completion Time (SCT), a new metric for evaluating navigation performance for mobile robots. Several related works on navigation have used Success weighted by Path Length (SPL) as the primary method of evaluating the path an agent makes to a goal location, but SPL is limited in its ability to properly evaluate agents with complex dynamics. In contrast, SCT explicitly takes the agent\u2019s dynamics model into consideration, and aims to accurately capture how well the agent has approximated the fastest navigation behavior afforded by its dynamics. While several embodied navigation works use point-turn dynamics, we focus on unicycle-cart dynamics for our agent, which better exempli-fies the dynamics model of popular mobile robotics platforms (e.g., LoCoBot, TurtleBot, Fetch, etc.). We also present RRT*-Unicycle, an algorithm for unicycle dynamics that estimates the fastest collision-free path and completion time from a starting pose to a goal location in an environment containing obstacles. We experiment with deep reinforcement learning and reward shaping to train and compare the navigation performance of agents with different dynamics models. In evaluating these agents, we show that in contrast to SPL, SCT is able to capture the advantages in navigation speed a unicycle model has over a simpler point-turn model of dynamics. Lastly, we show that we can successfully deploy our trained models and algorithms outside of simulation in the real world. We embody our agents in a real robot to navigate an apartment, and show that they can generalize in a zero-shot manner. A video summary is available here: https://youtu.be/QOQ56XVIYVE",
        "primary_area": "",
        "author": "Naoki Yokoyama;Sehoon Ha;Dhruv Batra;Naoki Yokoyama;Sehoon Ha;Dhruv Batra",
        "authorids": "/37089657541;/37086314268;/37294512800;/37089657541;/37086314268;/37294512800",
        "aff": "College of Electrical Engineering and College of Computing, Georgia Institute of Technology, Atlanta, GA, USA; Robotics at Google; Facebook AI Research (FAIR)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636743/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6370765714283836072&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Georgia Institute of Technology;Google;Meta",
        "aff_unique_dep": "College of Electrical Engineering;Robotics;Facebook AI Research",
        "aff_unique_url": "https://www.gatech.edu;https://www.google.com;https://research.facebook.com",
        "aff_unique_abbr": "Georgia Tech;Google Robotics;FAIR",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Atlanta;Mountain View;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635862",
        "title": "Super Odometry: IMU-centric LiDAR-Visual-Inertial Estimator for Challenging Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose Super Odometry, a high-precision multi-modal sensor fusion framework, providing a simple but effective way to fuse multiple sensors such as LiDAR, camera, and IMU sensors and achieve robust state estimation in perceptually-degraded environments. Different from traditional sensor-fusion methods, Super Odometry employs an IMU-centric data processing pipeline, which combines the advantages of loosely coupled methods with tightly coupled methods and recovers motion in a coarse-to-fine manner. The proposed framework is composed of three parts: IMU odometry, Visual-inertial odometry, and LiDAR-inertial odometry. The Visual-inertial odometry and LiDAR-inertial odometry provide the pose prior to constrain the IMU bias and receive the motion prediction from IMU odometry. To ensure high performance in real-time, we apply a dynamic octree that only consumes 10% of the running time compared with a static KD-tree. The proposed system was deployed on drones and ground robots, as part of Team Explorer\u2019s effort to the DARPA Subterranean Challenge where the team won 1st and 2nd place in the Tunnel and Urban Circuits 1, respectively.",
        "primary_area": "",
        "author": "Shibo Zhao;Hengrui Zhang;Peng Wang;Lucas Nogueira;Sebastian Scherer;Shibo Zhao;Hengrui Zhang;Peng Wang;Lucas Nogueira;Sebastian Scherer",
        "authorids": "/37086444189;/37088688128;/37088689449;/37089194848;/37584159000;/37086444189;/37088688128;/37088689449;/37089194848;/37584159000",
        "aff": "Robotics Institute, Carnegie Mellon University, USA; Robotics Institute, Carnegie Mellon University, USA; Faculty of Robot Science and Engineering, Northeastern University, China; Robotics Institute, Carnegie Mellon University, USA; Robotics Institute, Carnegie Mellon University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635862/",
        "gs_citation": 203,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17612438549413518876&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Northeastern University",
        "aff_unique_dep": "Robotics Institute;Faculty of Robot Science and Engineering",
        "aff_unique_url": "https://www.cmu.edu;http://www.neu.edu.cn/",
        "aff_unique_abbr": "CMU;NEU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9636435",
        "title": "Superline: A Robust Line Segment Feature for Visual SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Along with point features, line features play an important role in achieving robust Simultaneous Localization and Mapping (SLAM) under complex environments. This paper proposes a fast and effective method, namely Superline, to simultaneously detect line segments and generate robust descriptors for matching. The entire model is composed of a convolutional backbone and two task heads, i.e., detection head and description head respectively. A line selecting mechanism and a spatial pyramid Line-of-Interest (LOI) pooling module is specially designed in the description head to aggregate multi-scale information into line feature descriptors. The entire model is implemented end-to-end and can be trained on a dataset with only line annotations and without the need of providing ground truth matching. Comparative experimental results on Wireframe and York Urban datasets as well as applying the Superline features on SLAM applications demonstrate the superior performance of our method.",
        "primary_area": "",
        "author": "Chengyu Qiao;Tingming Bai;Zhiyu Xiang;Qi Qian;Yunfeng Bi;Chengyu Qiao;Tingming Bai;Zhiyu Xiang;Qi Qian;Yunfeng Bi",
        "authorids": "/37086950749;/37089194222;/37331922100;/37086582229;/37089197221;/37086950749;/37089194222;/37331922100;/37086582229;/37089197221",
        "aff": "Dept of Information and Electronic Engineering, Zhejiang University, China; Dept of Information and Electronic Engineering, Zhejiang University, China; Dept of Information and Electronic Engineering, Zhejiang University, China; Dept of Information and Electronic Engineering, Zhejiang University, China; Dept of Information and Electronic Engineering, Zhejiang University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636435/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8032929536000827304&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "Dept of Information and Electronic Engineering",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635997",
        "title": "Supervised Autonomy for Remote Teleoperation of Hybrid Wheel-Legged Mobile Manipulator Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an improved supervised autonomy framework for remote teleoperation of a quadrupedal bimanual mobile manipulator in an unknown environment, with the usage of advanced perception technology and allowing the operator to easily assist the robot with decision making for executing tasks on the fly. First, the perception system uses lightweight deep neural network-based Single Shot Detector (SSD) MobileNet on RGB images to detect objects and highlight them to the human operator via an intuitive interactive visualization interface. After object and action selections are made by the operator, segmentation of object point cloud and 3D surfaces based on random sample consensus is performed, followed by object pose localization by using keypoint extraction. Based on the localized object, mobile manipulation motion to perform the operator-selected action is planned and executed with the help of a state estimator for the hybrid wheel-legged robot. Thanks to the autonomy of the robot in perception and manipulation, the complexity of teleoperating the robot is reduced to specifying the essential task objectives. Experimental results on the real robot, with full system integration, for 2 task scenarios, namely passage clearing and object retrieval, demonstrate a high average success rate of 92.2% over a total of 90 trials.",
        "primary_area": "",
        "author": "Samuel Cheong;Tai Pang Chen;Cihan Acar;Yangwei You;Yuda Chen;Wan Leong Sim;Keng Peng Tee;Samuel Cheong;Tai Pang Chen;Cihan Acar;Yangwei You;Yuda Chen;Wan Leong Sim;Keng Peng Tee",
        "authorids": "/37089001082;/37089195212;/37088854551;/37085753674;/37089001743;/37089193936;/37088689983;/37089001082;/37089195212;/37088854551;/37085753674;/37089001743;/37089193936;/37088689983",
        "aff": "A*STAR Institute for Infocomm Research, Singapore; A*STAR Institute for Infocomm Research, Singapore; A*STAR Institute for Infocomm Research, Singapore; A*STAR Institute for Infocomm Research, Singapore; A*STAR Institute for Infocomm Research, Singapore; A*STAR Institute for Infocomm Research, Singapore; A*STAR Institute for Infocomm Research, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635997/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6521638019953369113&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "A*STAR Institute for Infocomm Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.aistar.edu.sg",
        "aff_unique_abbr": "A*STAR I2R",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9635867",
        "title": "SurRoL: An Open-source Reinforcement Learning Centered and dVRK Compatible Platform for Surgical Robot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous surgical execution relieves tedious routines and surgeon\u2019s fatigue. Recent learning-based methods, especially reinforcement learning (RL) based methods, achieve promising performance for dexterous manipulation, which usually requires the simulation to collect data efficiently and reduce the hardware cost. The existing learning-based simulation platforms for medical robots suffer from limited scenarios and simplified physical interactions, which degrades the real-world performance of learned policies. In this work, we designed SurRoL, an RL-centered simulation platform for surgical robot learning compatible with the da Vinci Research Kit (dVRK). The designed SurRoL integrates a user-friendly RL library for algorithm development and a real-time physics engine, which is able to support more PSM/ECM scenarios and more realistic physical interactions. Ten learning-based surgical tasks are built in the platform, which are common in the real autonomous surgical execution. We evaluate SurRoL using RL algorithms in simulation, provide in-depth analysis, deploy the trained policies on the real dVRK, and show that our SurRoL achieves better transferability in the real world.",
        "primary_area": "",
        "author": "Jiaqi Xu;Bin Li;Bo Lu;Yun-Hui Liu;Qi Dou;Pheng-Ann Heng;Jiaqi Xu;Bin Li;Bo Lu;Yun-Hui Liu;Qi Dou;Pheng-Ann Heng",
        "authorids": "/37088541643;/37089266122;/37085991083;/37279412600;/37085465414;/37283077400;/37088541643;/37089266122;/37085991083;/37279412600;/37085465414;/37283077400",
        "aff": "T Stone Robotics Institute, Cuhk; Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong; T Stone Robotics Institute, Cuhk; T Stone Robotics Institute, Cuhk",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635867/",
        "gs_citation": 95,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12016815991486007742&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "T Stone Robotics Institute",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9635958",
        "title": "Surface sliding behavior analysis of space probes in simulated extraterrestrial environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This study analyzes the surface sliding behavior of space probes in simulated extraterrestrial environments. When a space probe lands on an extraterrestrial body, its landing gear (footpad, landing legs) contacts and slides along the ground surface. The influence of various parameters (i.e., footpad size, velocity, ground condition, atmospheric pressure, and gravity) on the friction behavior of footpads was experimentally evaluated herein. First, we developed an experimental system that can perform footpad sliding tests repeatedly. Subsequently, the system was used to perform tests under various conditions: 1) on ground under normal atmospheric conditions, 2) in a vacuum, and 3) in reduced gravity. The tests performed in a vacuum and in reduced gravity indicated that the friction behavior of the footpad is largely unaffected by atmospheric pressure and gravity. The findings obtained herein offer useful design and control guidelines for space probes landing on extraterrestrial bodies.",
        "primary_area": "",
        "author": "Masataku Sutoh;Yuta Sakakieda;Masatsugu Otsuki;Taizo Kobayashi;Masataku Sutoh;Yuta Sakakieda;Masatsugu Otsuki;Taizo Kobayashi",
        "authorids": "/37862037500;/37086429665;/37340705500;/37089197065;/37862037500;/37086429665;/37340705500;/37089197065",
        "aff": "Japan Aerospace Exploration Agency, Sagamihara, Kanagawa, Japan; Shinshu University, Ueda, Nagano, Japan; Japan Aerospace Exploration Agency, Sagamihara, Kanagawa, Japan; Ritsumeikan University, Kusatsu, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635958/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2125069752517732434&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Japan Aerospace Exploration Agency;Shinshu University;Ritsumeikan University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.jaxa.jp;https://www.shinshu-u.ac.jp;https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "JAXA;;Ritsumeikan",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Sagamihara;Ueda;Kusatsu",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636622",
        "title": "SymbioLCD: Ensemble-Based Loop Closure Detection using CNN-Extracted Objects and Visual Bag-of-Words",
        "track": "main",
        "status": "Poster",
        "abstract": "Loop closure detection is an essential tool of Simultaneous Localization and Mapping (SLAM) to minimize drift in its localization. Many state-of-the-art loop closure detection (LCD) algorithms use visual Bag-of-Words (vBoW), which is robust against partial occlusions in a scene but cannot perceive the semantics or spatial relationships between feature points. CNN object extraction can address those issues, by providing semantic labels and spatial relationships between objects in a scene. Previous work has mainly focused on replacing vBoW with CNN derived features. In this paper we propose SymbioLCD, a novel ensemble-based LCD that utilizes both CNN-extracted objects and vBoW features for LCD candidate prediction. When used in tandem, the added elements of object semantics and spatial-awareness creates a more robust and symbiotic loop closure detection system. The proposed SymbioLCD uses scale-invariant spatial and semantic matching, Hausdorff distance with temporal constraints, and a Random Forest that utilizes combined information from both CNN-extracted objects and vBoW features for predicting accurate loop closure candidates. Evaluation of the proposed method shows it outperforms other Machine Learning (ML) algorithms - such as SVM, Decision Tree and Neural Network, and demonstrates that there is a strong symbiosis between CNN-extracted object information and vBoW features which assists accurate LCD candidate prediction. Furthermore, it is able to perceive loop closure candidates earlier than state-of-the-art SLAM algorithms, utilizing added spatial and semantic information from CNN-extracted objects.",
        "primary_area": "",
        "author": "Jonathan J.Y. Kim;Martin Urschler;Patricia J. Riddle;J\u00f6rg S. Wicker;Jonathan J.Y. Kim;Martin Urschler;Patricia J. Riddle;J\u00f6rg S. Wicker",
        "authorids": "/37089195032;/37392041500;/37565812900;/37087404551;/37089195032;/37392041500;/37565812900;/37087404551",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636622/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6856672200420955076&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9635860",
        "title": "Synergetic Gait Prediction for Stroke Rehabilitation with Varying Walking Speeds",
        "track": "main",
        "status": "Poster",
        "abstract": "Lower Limb Exoskeletons (LLEs) are promising in gait rehabilitation for stroke survivors. In gait training of post-stroke patients with LLEs, one of the main challenges is how to generate appropriate gait patterns from the sound leg to the paretic leg for different patients with varying walking speeds. In this paper, we proposed a Synergetic Gait Prediction (SGP) model for rehabilitation LLEs with post-stroke patients, which can generate adaptive synergetic gait patterns for different patients with varying walking speeds. The proposed SGP model is based on Sequence-to-Sequence (Seq2Seq) neural networks with temporal attention mechanisms. In the training procedure of the proposed SGP model, a gait database with collected gait patterns from healthy subjects is employed to learn the parameters of SGP model. The SGP model takes current joint angles from the sound leg and a segment of observed history joint angles from both legs as input and predicts the future joint angles for the paretic leg. We compared the effectiveness of the SGP model with the Long Short Term Memory (LSTM) model, experimental results indicate that SGP model can generate synergetic gait patterns for different subjects via varying walking speeds with less prediction error.",
        "primary_area": "",
        "author": "Chaobin Zou;Rui Huang;Zhinan Peng;Jing Qiu;Hong Cheng;Chaobin Zou;Rui Huang;Zhinan Peng;Jing Qiu;Hong Cheng",
        "authorids": "/37086267498;/37085625169;/37086471879;/37086356733;/37280209600;/37086267498;/37085625169;/37086471879;/37086356733;/37280209600",
        "aff": "Center for Robotics, School of Automation and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation and Engineering, University of Electronic Science and Technology of China, Chengdu, China; School of Mechanical and Electrical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation and Engineering, University of Electronic Science and Technology of China, Chengdu, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635860/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10029888920689472733&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Electronic Science and Technology of China",
        "aff_unique_dep": "School of Automation and Engineering",
        "aff_unique_url": "https://www.uestc.edu.cn",
        "aff_unique_abbr": "UESTC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Chengdu",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636728",
        "title": "TUM-VIE: The TUM Stereo Visual-Inertial Event Dataset",
        "track": "main",
        "status": "Poster",
        "abstract": "Event cameras are bio-inspired vision sensors which measure per pixel brightness changes. They offer numerous benefits over traditional, frame-based cameras, including low latency, high dynamic range, high temporal resolution and low power consumption. Thus, these sensors are suited for robotics and virtual reality applications. To foster the development of 3D perception and navigation algorithms with event cameras, we present the TUM-VIE dataset. It consists of a large variety of handheld and head-mounted sequences in indoor and outdoor environments, including rapid motion during sports and high dynamic range scenarios. The dataset contains stereo event data, stereo grayscale frames at 20Hz as well as IMU data at 200Hz. Timestamps between all sensors are synchronized in hardware. The event cameras contain a large sensor of 1280x720 pixels, which is significantly larger than the sensors used in existing stereo event datasets (at least by a factor of ten). We provide ground truth poses from a motion capture system at 120Hz during the beginning and end of each sequence, which can be used for trajectory evaluation. TUM-VIE includes challenging sequences where state-of-the art visual SLAM algorithms either fail or result in large drift. Hence, our dataset can help to push the boundary of future research on event-based visual-inertial perception algorithms.",
        "primary_area": "",
        "author": "Simon Klenk;Jason Chui;Nikolaus Demmel;Daniel Cremers;Simon Klenk;Jason Chui;Nikolaus Demmel;Daniel Cremers",
        "authorids": "/37089194566;/37089195870;/37595100200;/37282875300;/37089194566;/37089195870;/37595100200;/37282875300",
        "aff": "Department of Informatics, Computer Vision Group, Technical University of Munich, Germany; Department of Informatics, Computer Vision Group, Technical University of Munich, Germany; Department of Informatics, Computer Vision Group, Technical University of Munich, Germany; Department of Informatics, Computer Vision Group, Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636728/",
        "gs_citation": 73,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3797020956621245049&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Informatics",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636599",
        "title": "TUPPer-Map: Temporal and Unified Panoptic Perception for 3D Metric-Semantic Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose TUPPer-Map, a metric-semantic mapping framework based on the unified panoptic segmentation and temporal data association. In contrast to the previous mapping method, our framework integrates the data association stage into the holistic pixel-level segmentation stage in an end-to-end fashion, taking advantage of both intra-frame and inter-frame spatial and temporal knowledge. Firstly, we unify two-branch instance segmentation network and semantic segmentation network into a single network by sharing the backbone net, maximizing the 2D panoptic segmentation performance. Next, we leverage geometric segmentation to refine the segments predicted via deep learning. Then, we design a novel deep learning based data association module to track the object instances across different frames. Optical flow of consecutive frames and alignment of ROI (Region of Interest) candidates are learned to predict the frame-consistent instance label. At last, 2D semantics are integrated into 3D volume by TSDF raycasting to build the final map. We evaluated the performance of our framework extensively over the SceneNN, ScanNet v2 and Cityscapes-VPS datasets. Our experimental results demonstrate the superiority of TUPPer-Map over existing semantic mapping methods. Overall, our work illustrates that using learning based data association strategy can enable a more unified perception network for 3D mapping.",
        "primary_area": "",
        "author": "Zhiliu Yang;Chen Liu;Zhiliu Yang;Chen Liu",
        "authorids": "/37086430886;/37599996300;/37086430886;/37599996300",
        "aff": "Department of Electrical and Computer Engineering, Clarkson University, Potsdam, NY, USA; Department of Electrical and Computer Engineering, Clarkson University, Potsdam, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636599/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17365817145943415680&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Clarkson University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.clarkson.edu",
        "aff_unique_abbr": "Clarkson",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Potsdam",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636196",
        "title": "Tachyon: Design and Control of High Payload, Robust, and Dynamic Quadruped Robot with Series-Parallel Elastic Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a quadruped robot, Tachyon, which aims to achieve high payload, robust, and dynamic locomotion on the various terrain with high energy efficiency. Thanks to a novel compact series-parallel elastic actuator (SPEA) on the upper link and a four-bar linkage design in the knee joint for constant vertical foot force, the 41-kg robot can carry more than 20 kg of payloads with dynamic walking. The combination of a robust horizontal CoM stabilizer and SPEA joint torque controller provides low impedance force controllability of the whole-body even when only the knee joint can accurately detect its joint torque. The major performance of Tachyon is demonstrated by carrying a 20-kg rice bag\u2014half of its body weight\u2014and climbing stairs with dynamic locomotion. When the robot climbs the stairs, the SPEA parallel spring improves energy efficiency by 16% and is also effective for various other gaits. The robustness of the robot is also shown by its high flexibility and fall avoidance capability when an unknown disturbance of 400 N or more is applied.",
        "primary_area": "",
        "author": "Yasuhisa Kamikawa;Masaya Kinoshita;Noriaki Takasugi;Katsufumi Sugimoto;Toshimitsu Kai;Takashi Kito;Atsushi Sakamoto;Kenichiro Nagasaka;Yasunori Kawanami;Yasuhisa Kamikawa;Masaya Kinoshita;Noriaki Takasugi;Katsufumi Sugimoto;Toshimitsu Kai;Takashi Kito;Atsushi Sakamoto;Kenichiro Nagasaka;Yasunori Kawanami",
        "authorids": "/37866918500;/37089194945;/37086204564;/37089195931;/37089197187;/37089136787;/37087605460;/37281333500;/37528845500;/37866918500;/37089194945;/37086204564;/37089195931;/37089197187;/37089136787;/37087605460;/37281333500;/37528845500",
        "aff": "Sony Group Corporation, Minato-ku, Tokyo, Japan; Sony Group Corporation, Minato-ku, Tokyo, Japan; Sony Group Corporation, Minato-ku, Tokyo, Japan; Sony Group Corporation, Minato-ku, Tokyo, Japan; Sony Group Corporation, Minato-ku, Tokyo, Japan; Sony Group Corporation, Minato-ku, Tokyo, Japan; Sony Group Corporation, Minato-ku, Tokyo, Japan; Sony Group Corporation, Minato-ku, Tokyo, Japan; Sony Group Corporation, Minato-ku, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636196/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14247564336711752343&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Sony Group Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sony.com",
        "aff_unique_abbr": "Sony",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636602",
        "title": "Tactile Slip Detection in the Wild Leveraging Distributed Sensing of both Normal and Shear Forces",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to detect that a grasped object is slipping from the robot gripper is a crucial skill for autonomous robotic manipulation. However, current solutions for automatic slip detection do not perform well in real-world unstructured settings, in which a wide variety of gripper-object interactions could occur. Tactile and force sensing are the most suitable sensory modalities to detect such events, and the recent technological advances in the field are generating novel interesting opportunities. In this work, we propose a data-driven method for automatic slip detection that leverages a novel sensor, which combines the advantages of tactile and force sensing, i.e. distributed measurements of normal and shear contact forces. Interestingly, our model is trained (and tested) uniquely with data obtained during routine robot operations (i.e. in the wild) rather than during a controlled data collection procedure. We compare different sets of tactile/force features to highlight the advantages provided by the different sensory modalities, and we report results that show good detection performances on our in-the-wild dataset, which we make publicly available.",
        "primary_area": "",
        "author": "Rodrigo Zenha;Brice Denoun;Claudio Coppola;Lorenzo Jamone;Rodrigo Zenha;Brice Denoun;Claudio Coppola;Lorenzo Jamone",
        "authorids": "/37086886337;/37088532553;/37086087991;/37295474600;/37086886337;/37088532553;/37086087991;/37295474600",
        "aff": "ARQ (Advanced Robotics at Queen Mary), School of Electronic Engineering and Computer Science, Queen Mary University of London, UK; ARQ (Advanced Robotics at Queen Mary), School of Electronic Engineering and Computer Science, Queen Mary University of London, UK; ARQ (Advanced Robotics at Queen Mary), School of Electronic Engineering and Computer Science, Queen Mary University of London, UK; ARQ (Advanced Robotics at Queen Mary), School of Electronic Engineering and Computer Science, Queen Mary University of London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636602/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4327457177955733117&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Queen Mary University of London",
        "aff_unique_dep": "School of Electronic Engineering and Computer Science",
        "aff_unique_url": "https://www.qmul.ac.uk",
        "aff_unique_abbr": "QMUL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636548",
        "title": "Talk the talk and walk the walk: Dialogue-driven navigation in unknown indoor environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Prior work in natural-language-driven navigation demonstrates success in systems deployed in synthetic environments or applied to large datasets, both real and synthetic. However, there is an absence of such frameworks being deployed and rigorously tested in real environments, unknown a priori. In this paper, we present a novel framework that uses spoken dialogue with a real person to interpret a set of navigational instructions into a plan and subsequently execute that plan in a novel, unknown, indoor environment. This framework is implemented on a real robot and its performance is evaluated in 39 trials across 3 novel test-building environments. We also demonstrate that our approach outperforms three prior vision-and-language navigation methods in this same environment.",
        "primary_area": "",
        "author": "Thomas Victor Ilyevsky;Jared Sigurd Johansen;Jeffrey Mark Siskind;Thomas Victor Ilyevsky;Jared Sigurd Johansen;Jeffrey Mark Siskind",
        "authorids": "/37089194024;/37089196803;/37089194914;/37089194024;/37089196803;/37089194914",
        "aff": "School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636548/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10324654828685348489&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636446",
        "title": "Target-visible Polynomial Trajectory Generation within an MAV Team",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous aerial videography is a challenging task, which involves collision avoidance against obstacles and visibility guaranteed target tracking in unstructured environments. In this paper, we organize a two micro aerial vehicle (MAV) team, which consists of a target agent responsible for a specific mission and a camera agent for filming the target agent. Especially, this paper focuses on trajectory planning of the camera agent to chase without occlusion of target agent. Our trajectory planner module includes two phases of guaranteeing target visibility. In the first phase, we generate homotopic safe flight corridor (SFC) to attain target-visible regions. In the subsequent phase, we generate a safe and smooth trajectory with the continuous visibility constraint based on the SFC, using quadratic programming (QP). Regardless of complexity of map, our planner converts an overall problem to a single QP and generates a steady flight trajectory without undesirable fluctuating motion, while guaranteeing all-time visibility. We validate our approach in Gazebo simulations and a real-world experiment.",
        "primary_area": "",
        "author": "Yunwoo Lee;Jungwon Park;Boseong Jeon;H. Jin Kim;Yunwoo Lee;Jungwon Park;Boseong Jeon;H. Jin Kim",
        "authorids": "/37088504927;/37087323909;/37087323064;/37599626400;/37088504927;/37087323909;/37087323064;/37599626400",
        "aff": "Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636446/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5510994674469602972&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636812",
        "title": "Task Driven Skill Learning in a Soft-Robotic Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we introduce a novel technique that aims to dynamically control a two-module bio-inspired soft-robotic arm in order to qualitatively reproduce a path defined by sparse way-points. The main idea behind this work is based on the assumption that a complex trajectory may be derived as a combination of a discrete set of parameterizable simple movements, as suggested by Movement Primitive (MP) theory. Capitalising on recent advances in this field, the proposed controller uses a Probabilistic MP (ProMP) model which initially creates an abstract mapping in the primitive-level between the task and the actuation space, and subsequently guides the movement\u2019s composition by exploiting its unique properties - conditioning and blending. At the same time, a learning-based adaptive controller updates the composition parameters by estimating the inverse kinematics of the robot, while an auxiliary process through replanning ensures that the trajectory complies with the new estimation. The learning architecture is evaluated on both a simulation model, and a real soft-robotic arm. The research findings show that the proposed methodology constitutes a novel approach that successfully manages to simplify the trajectory control task for robots of complex dynamics when high-precision is not required.",
        "primary_area": "",
        "author": "Paris Oikonomou;Athanasios Dometios;Mehdi Khamassi;Costas S. Tzafestas;Paris Oikonomou;Athanasios Dometios;Mehdi Khamassi;Costas S. Tzafestas",
        "authorids": "/37088507451;/37085837403;/37085730247;/37296005200;/37088507451;/37085837403;/37085730247;/37296005200",
        "aff": "School of Electrical and Computer Engineering, National Technical University of Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Greece; Sorbonne Universit\u00e9, CNRS, Institute of Intelligent Systems and Robotics, Paris, France; School of Electrical and Computer Engineering, National Technical University of Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636812/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18147617065390270933&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 23,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "National Technical University of Athens;Sorbonne Universit\u00e9",
        "aff_unique_dep": "School of Electrical and Computer Engineering;Institute of Intelligent Systems and Robotics",
        "aff_unique_url": "https://www.ntua.gr;https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "NTUA;Sorbonne U",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Paris",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Greece;France"
    },
    {
        "id": "9636209",
        "title": "Task geometry aware assistance for kinesthetic teaching of redundant robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Kinesthetic teaching allows the direct skill transfer from the human to the robot through physical human-robot interaction. However, it is heavily affected by the robot\u2019s dynamics and the control scheme utilized for the physical interaction. In this work, we aim at assisting the human-teacher by reducing her/his physical and cognitive load. To this aim, we propose a controller with virtual fixtures and inertia optimization for assisting kinesthetic teaching, exploiting knowledge of the task geometry and the robot redundancy. Experimental results utilizing a KUKA LWR4+ robot for the teaching of a brush painting motion on a curved surface validate the method and demonstrate its performance in comparison with a gravity compensation scheme and the utilization of virtual fixtures alone. The system is proved to be passive under the exertion of a human force.",
        "primary_area": "",
        "author": "Dimitrios Papageorgiou;Sotiris Stavridis;Christos Papakonstantinou;Zoe Doulgeri;Dimitrios Papageorgiou;Sotiris Stavridis;Christos Papakonstantinou;Zoe Doulgeri",
        "authorids": "/37449072200;/37086186963;/37089197971;/37274011500;/37449072200;/37086186963;/37089197971;/37274011500",
        "aff": "Dept. of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Greece; Dept. of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Greece; Dept. of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Greece; Dept. of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636209/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5186639331826085802&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki",
        "aff_unique_dep": "Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.auth.gr",
        "aff_unique_abbr": "AUTH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Thessaloniki",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9635916",
        "title": "Task-Consistent Path Planning for Mobile 3D Printing",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we explore the problem of task-consistent path planning for printing-in-motion via Mobile Manipulators (MM). MM offer a potentially unlimited planar workspace and flexibility for print operations. However, most existing methods have only mobility to relocate an arm which then prints while stationary. In this paper we present a new fully autonomous path planning approach for mobile material deposition. We use a modified version of Rapidly-exploring Random Tree Star (RRT*) algorithm, which is informed by a constrained Inverse Reachability Map (IRM) to ensure task consistency. Collision avoidance and end-effector reachability are respected in our approach. Our method also detects when a print path cannot be completed in a single execution. In this case it will decompose the path into several segments and reposition the base accordingly.",
        "primary_area": "",
        "author": "Julius Sustarevas;Dimitrios Kanoulas;Simon Julier;Julius Sustarevas;Dimitrios Kanoulas;Simon Julier",
        "authorids": "/37086578524;/38230575500;/37264968900;/37086578524;/38230575500;/37264968900",
        "aff": "Department of Computer Science, University College London, UK; Department of Computer Science, University College London, UK; Department of Computer Science, University College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635916/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=543080086454402867&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636288",
        "title": "Team Orienteering Coverage Planning with Uncertain Reward",
        "track": "main",
        "status": "Poster",
        "abstract": "Many municipalities and large organizations have fleets of vehicles that need to be coordinated for tasks such as garbage collection or infrastructure inspection. Motivated by this need, this paper focuses on the common subproblem in which a team of vehicles needs to plan coordinated routes to patrol an area over iterations while minimizing temporally and spatially dependent costs. In particular, at a specific location (e.g., a vertex on a graph), we assume the cost accumulates over time and its growth rate is a random variable with a fixed but unknown mean, and the cost is reset to zero whenever any vehicle visits the vertex (representing the robot \"servicing\" the vertex). We formulate this problem in graph terminology and call it Team Orienteering Coverage Planning with Uncertain Reward (TOCPUR). We propose to solve TOCPUR by simultaneously estimating the accumulated cost at every vertex on the graph and solving a novel variant of the Team Orienteering Problem (TOP) iteratively, which we call the Team Orienteering Coverage Problem (TOCP). We provide the first mixed integer programming formulation for the TOCP, as a significant adaptation of the original TOP. We introduce a new benchmark consisting of hundreds of randomly generated graphs for comparing different methods. We show the proposed solution outperforms both the exact TOP solution and a greedy algorithm. In addition, we provide a demo of our method on a team of three physical robots in a real-world environment. The code is publicly available at https://github.com/Cranial-XIX/TOCPUR.git.",
        "primary_area": "",
        "author": "Bo Liu;Xuesu Xiao;Peter Stone;Bo Liu;Xuesu Xiao;Peter Stone",
        "authorids": "/37088429909;/37086258082;/37269574900;/37088429909;/37086258082;/37269574900",
        "aff": "Department of Computer Science, University of Texas at Austin, Austin, TX; Department of Computer Science, University of Texas at Austin, Austin, TX; Sony AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636288/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3680255049216681027&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Texas at Austin;Sony",
        "aff_unique_dep": "Department of Computer Science;Sony AI",
        "aff_unique_url": "https://www.utexas.edu;https://www.sony.com",
        "aff_unique_abbr": "UT Austin;Sony AI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9636005",
        "title": "Telemanipulation via Virtual Reality Interfaces with Enhanced Environment Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Extreme environments, such as search and rescue missions, defusing bombs, or exploring extraterrestrial planets, are unsafe environments for humans to be in. Robots enable humans to explore and interact in these environments through remote presence and teleoperation and virtual reality provides a medium to create immersive and easy-to-use teleoperation interfaces. However, current virtual reality interfaces are still very limited in their capabilities. In this work, we aim to advance robot teleoperation virtual reality interfaces by developing an environment reconstruction methodology capable of recognizing objects in a robot\u2019s environment and rendering high fidelity models inside a virtual reality headset. We compare our proposed environment reconstruction method against traditional point cloud streaming by having operators plan waypoint trajectories to accomplish a pick-and-place task. Overall, our results show that users find our environment reconstruction method more usable and less cognitive work compared to raw point cloud streaming.",
        "primary_area": "",
        "author": "Murphy Wonsick;Tar\u0131k Kele\u0219temur;Stephen Alt;Ta\u0219k\u0131n Pad\u0131r;Murphy Wonsick;Tar\u0131k Kele\u0219temur;Stephen Alt;Ta\u0219k\u0131n Pad\u0131r",
        "authorids": "/37086001974;/37086935384;/37089195748;/38496444600;/37086001974;/37086935384;/37089195748;/38496444600",
        "aff": "Institute for Experiential Robotics, Northeastern University, Boston, MA, USA; Institute for Experiential Robotics, Northeastern University, Boston, MA, USA; Institute for Experiential Robotics, Northeastern University, Boston, MA, USA; Institute for Experiential Robotics, Northeastern University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636005/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8943594785795339753&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Institute for Experiential Robotics",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636223",
        "title": "Temporal Force Synergies in Human Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans can intuitively grasp objects of different shape and weight. Throughout the grasp execution they control and coordinate the grasp forces at all contact points between the hand and the object to achieve a stable grasp. Dexterous grasping with humanoid hands relies on the perfect coordination between grasp posture and force balance at the contact points in a high dimensional space and remains a challenge. In this paper, we present temporal force synergies describing the change in human grasp forces during the grasp execution in a low-dimensional space based on two new grasp synergy models: 1) static force synergies that are derived by a Principal Component Analysis and represent temporal grasp forces as a sequence of time-independent synergy configurations and 2) dynamic force synergies that are learned by a recurrent neural network and encode the temporal change of grasp forces throughout grasp execution in a latent synergy space clustered by grasp types. We show that both synergy spaces encode human grasp forces with an error of less than 2% and allow the generation of human-like grasp force patterns. Grasp forces for stable grasps described by the dynamic force synergies achieve a grasp quality comparable to demonstrated human grasps in simulation.",
        "primary_area": "",
        "author": "Julia Starke;Marco Keller;Amim Asfour;Julia Starke;Marco Keller;Amim Asfour",
        "authorids": "/37086278005;/37089197504;/37089196223;/37086278005;/37089197504;/37089196223",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636223/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4354693862224205374&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636583",
        "title": "TemporalFusion: Temporal Motion Reasoning with Multi-Frame Fusion for 6D Object Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "6D object pose estimation is an essential task in vision-based robotic grasping and manipulation. Prior works extract spatial features by fusing the RGB image and depth without considering the temporal motion information, limiting their performance in heavy occlusion robotic grasping scenarios. In this paper, we present an end-to-end model named TemporalFusion, which integrates the temporal motion information from RGB-D images for 6D object pose estimation. The core of proposed TemporalFusion model is to embed and fuse the temporal motion information from multi-frame RGB-D sequences, which could handle heavy occlusion in robotic grasping tasks. Furthermore, the proposed deep model can also obtain stable pose sequences, which is essential for real-time robotic grasping tasks. We evaluated the proposed method in the YCB-Video dataset, and experimental results show our model outperforms state-of-the-art approaches. Our code is available at https://github.com/mufengjun260/TemporalFusion21.",
        "primary_area": "",
        "author": "Fengjun Mu;Rui Huang;Ao Luo;Xin Li;Jing Qiu;Hong Cheng;Fengjun Mu;Rui Huang;Ao Luo;Xin Li;Jing Qiu;Hong Cheng",
        "authorids": "/37089186306;/37085625169;/37089014361;/37086259866;/37086356733;/37280209600;/37089186306;/37085625169;/37089014361;/37086259866;/37086356733;/37280209600",
        "aff": "School of Mechanical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China; Inception Institute of Artificial Intelligence, Dubai, The United Arab Emirates; School of Mechanical Engineering, University of Electronic Science and Technology of China, Chengdu, China; Center for Robotics, School of Automation Engineering, University of Electronic Science and Technology of China, Chengdu, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636583/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8021517970719970145&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "University of Electronic Science and Technology of China;Inception Institute of Artificial Intelligence",
        "aff_unique_dep": "School of Mechanical Engineering;",
        "aff_unique_url": "http://www.uestc.edu.cn;",
        "aff_unique_abbr": "UESTC;",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Chengdu;Dubai",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "China;United Arab Emirates"
    },
    {
        "id": "9636751",
        "title": "Temporally-Continuous Probabilistic Prediction using Polynomial Trajectory Parameterization",
        "track": "main",
        "status": "Poster",
        "abstract": "A commonly-used representation for motion prediction of actors is a sequence of waypoints (comprising positions and orientations) for each actor at discrete future time-points. While regressing waypoints is simple and flexible, it can exhibit unrealistic higher-order derivatives (such as acceleration) and approximation errors at intermediate time steps. To address this issue we propose a general representation for temporally-continuous probabilistic trajectory prediction that regresses polynomial parameterization coefficients. We evaluate the proposed representation on supervised trajectory prediction tasks using two large self-driving data sets. The results show realistic higher-order derivatives and better accuracy at interpolated time-points, as well as the benefits of the inferred noise distributions over the trajectories. Extensive experimental studies based on existing state-of-the-art models demonstrate the effectiveness of the proposed approach relative to other representations in predicting the future motions of vehicle, bicyclist, and pedestrian traffic actors.",
        "primary_area": "",
        "author": "Zhaoen Su;Chao Wang;Henggang Cui;Nemanja Djuric;Carlos Vallespi-Gonzalez;David Bradley;Zhaoen Su;Chao Wang;Henggang Cui;Nemanja Djuric;Carlos Vallespi-Gonzalez;David Bradley",
        "authorids": "/37089016510;/37089197672;/37086936263;/37085410883;/37087231633;/37088504519;/37089016510;/37089197672;/37086936263;/37085410883;/37087231633;/37088504519",
        "aff": "Aurora Innovation Inc., Pittsburgh, PA; Aurora Innovation Inc., Pittsburgh, PA; Aurora Innovation Inc., Pittsburgh, PA; Aurora Innovation Inc., Pittsburgh, PA; Aurora Innovation Inc., Pittsburgh, PA; Aurora Innovation Inc., Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636751/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6958702291396191114&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Aurora Innovation Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://aurora.tech",
        "aff_unique_abbr": "Aurora",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636519",
        "title": "Terrain-Aware Risk-Assessment-Network-Aided Deep Reinforcement Learning for Quadrupedal Locomotion in Tough Terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "When it comes to the control system of quadruped robots, deep reinforcement learning (DRL) is considered to be a promising solution. Despite years of development in this field, difficulties remain in guaranteeing the action stability of DRL-based quadruped robots\u2019 locomotion, especially in tough terrain. In this paper, a terrain-aware teacher-student controller integrating a risk assessment network (RAN) is proposed to alleviate this problem. During the training phase, the RAN can evaluate the risk level of historical observation or current state and further guide the update of the policy, thereby assisting the policy in selecting better actions and avoid risky ones. Furthermore, the real-time elevation map is transmitted to the controller as visual information, so that it can perceive the terrain to produce higher performance locomotion. With the aforementioned configuration, we enable a robot to traverse various challenging terrain in simulation and bound or trot stably in the real environment.",
        "primary_area": "",
        "author": "Hongyin Zhang;Jilong Wang;Zhengqing Wu;Yinuo Wang;Donglin Wang;Hongyin Zhang;Jilong Wang;Zhengqing Wu;Yinuo Wang;Donglin Wang",
        "authorids": "/37088595146;/37089194886;/37089194362;/37089195393;/37405353300;/37088595146;/37089194886;/37089194362;/37089195393;/37405353300",
        "aff": "MiLAB, Westlake University; MiLAB, Westlake University; MiLAB, Westlake University; MiLAB, Westlake University; MiLAB, Westlake University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636519/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14646457717225666029&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Westlake University",
        "aff_unique_dep": "MiLAB",
        "aff_unique_url": "https://www.westlake.edu.cn/",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636793",
        "title": "Text-based robot emotion and human-like emotional transition",
        "track": "main",
        "status": "Poster",
        "abstract": "Studies on the production of emotions have been conducted to create robotic facial expressions. The reported methodologies for generating emotions for a robot have focused on recognizing a user\u2019s emotions using devices, such as cameras and microphones, and then generating the reactive emotions of a robot according to the user\u2019s emotions. However, these methodologies may have some limitations in delivering emotions in the robot that match the robot\u2019s utterances to users. In this paper, we propose a methodology for producing robotic emotions suitable for a robot\u2019s utterances based on texts so that it can be applied to various fields such as robotic dialogue and reading services. To produce human-like emotions in a robot, our methodology applied patterns of human emotional changes as well as the resilience theory that humans have an ability to recover their emotional states considering their own personality over time. We measured the performance of the model for analyzing texts and observed that there is a linear correlation between the predicted emotions and the annotated ones from humans. Furthermore, when we carried out the experiments based on scenarios, our methodology could produce human-like patterns of emotional changes and the robot could recover its emotional state on its own.",
        "primary_area": "",
        "author": "Yu-Jung Chae;Tae-Hee Jeon;ChangHwan Kim;Sung-Kee Park;Yu-Jung Chae;Tae-Hee Jeon;ChangHwan Kim;Sung-Kee Park",
        "authorids": "/37085350131;/37089194484;/37292328800;/37280895200;/37085350131;/37089194484;/37292328800;/37280895200",
        "aff": "HCI & Robotics Division of Nano & Information Technology, KIST School, Korea University of Science and Technology, Seoul, Republic of Korea; Korean Language and Literature, College of Liberal Arts, Korea University, Seoul, Republic of Korea; Center for Robotics Research, Korea Institute of Science and Technology, Seoul, Republic of Korea; Center for Robotics Research, Korea Institute of Science and Technology, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636793/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13692847394002335608&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;2",
        "aff_unique_norm": "Korea University of Science and Technology;Korea University;Korea Institute of Science and Technology",
        "aff_unique_dep": "HCI & Robotics Division of Nano & Information Technology, KIST School;College of Liberal Arts;Center for Robotics Research",
        "aff_unique_url": "http://www.kust.ac.kr;http://www.korea.ac.kr;https://www.kist.re.kr",
        "aff_unique_abbr": "KUST;KU;KIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9635992",
        "title": "Textile Taxonomy and Classification Using Pulling and Twisting",
        "track": "main",
        "status": "Poster",
        "abstract": "Identification of textile properties is an important milestone toward advanced robotic manipulation tasks that consider interaction with clothing items such as assisted dressing, laundry folding, automated sewing, textile recycling and reusing. Despite the abundance of work considering this class of deformable objects, many open problems remain. These relate to the choice and modelling of the sensory feedback as well as the control and planning of the interaction and manipulation strategies. Most importantly, there is no structured approach for studying and assessing different approaches that may bridge the gap between the robotics community and textile production industry. To this end, we outline a textile taxonomy considering fiber types and production methods, commonly used in textile industry. We devise datasets according to the taxonomy, and study how robotic actions, such as pulling and twisting of the textile samples, can be used for the classification. We also provide important insights from the perspective of visualization and interpretability of the gathered data.",
        "primary_area": "",
        "author": "Alberta Longhini;Michael C. Welle;Ioanna Mitsioni;Danica Kragic;Alberta Longhini;Michael C. Welle;Ioanna Mitsioni;Danica Kragic",
        "authorids": "/37088920995;/38202265300;/37086293438;/37281296000;/37088920995;/38202265300;/37086293438;/37281296000",
        "aff": "Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Robotics, Perception and Learning Lab, EECS, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635992/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=934503491115634708&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "EECS",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9636604",
        "title": "The ARoA Platform: An Autonomous Robotic Assistant with a Reconfigurable Torso System and Dexterous Manipulation Capabilities",
        "track": "main",
        "status": "Poster",
        "abstract": "The ongoing global healthcare crisis has amplified the need for automation of manual tasks in several industries and service sectors. Simple household tasks such as tidying and cleaning are in high demand, with only a few robotic platforms capable of performing them due to the mobility, workspace, and dexterity requirements. This work presents ARoA, an autonomous robotic assistant that can execute complex tasks in industrial, service, and home environments. It is equipped with two lightweight, compliant, 7 degree of freedom arms and a pair of adaptive end-effectors that enable efficient execution of a wide range of tasks. Due to the linear rail based torso system that supports the arms, the ARoA offers exceptional flexibility in terms of reachable workspace. A framework for vision-based execution of tidying and cleaning tasks is also proposed and integrated in the platform. The efficiency of the ARoA platform was experimentally validated through two everyday life applications: i) picking up and tidying randomly scattered household objects and ii) cleaning of common surfaces.",
        "primary_area": "",
        "author": "Gal Gorjup;Che-Ming Chang;Geng Gao;Lucas Gerez;Anany Dwivedi;Ruobing Yu;Patrick Jarvis;Minas Liarokapis;Gal Gorjup;Che-Ming Chang;Geng Gao;Lucas Gerez;Anany Dwivedi;Ruobing Yu;Patrick Jarvis;Minas Liarokapis",
        "authorids": "/37087237844;/37087236127;/37087027460;/37086448935;/37086133073;/37088456480;/37088456883;/38558084100;/37087237844;/37087236127;/37087027460;/37086448935;/37086133073;/37088456480;/37088456883;/38558084100",
        "aff": "Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Humanoid Artificial Intelligence, Lake Mary, FL, USA; Humanoid Artificial Intelligence, Lake Mary, FL, USA; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636604/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3328493310414552264&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;1;0",
        "aff_unique_norm": "University of Auckland;Humanoid Artificial Intelligence",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.auckland.ac.nz;",
        "aff_unique_abbr": "UoA;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Lake Mary",
        "aff_country_unique_index": "0;0;0;0;0;1;1;0",
        "aff_country_unique": "New Zealand;United States"
    },
    {
        "id": "9635995",
        "title": "The New Dexterity Omnirotor Platform: Design, Modeling, and Control of a Modular, Versatile, All-Terrain Vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "Micro Aerial Vehicles (MAV) with Vertical Takeoff and Landing (VTOL) capabilities, such as quadrotors, have offered significant value to many research fields and markets. However, only recently, MAV began to be explored as systems capable of interacting with the environment, performing manipulation tasks, and participating in more versatility-demanding operations. Pursuing the goal of turning flying machines into more versatile instruments, many researchers have resorted to using tilting rotor mechanisms to create new aerial vehicle concepts. Nevertheless, most such new concepts are bulky and lack the required versatility, and are restricted to particular applications. In this work, we address these issues by proposing a novel coaxial, versatile, modular tilt-rotor UAV concept. The Omnirotor platform can apply its full thrust in any direction, regardless of the frame\u2019s orientation where it is mounted. The platform does not have any limitations regarding rotation\u2019s range. It can change its thrust direction continuously without needing to unwind back to a specific configuration. With the addition of control surfaces between the coaxial rotors, the Omnirotor is turned into a functional VTOL MAV with hovering capabilities that can be used as a ground vehicle, a UAV, and an all-terrain vehicle.",
        "primary_area": "",
        "author": "Joao Buzzatto;Pedro H. Mendes;Navin Perera;Karl Stol;Minas Liarokapis;Joao Buzzatto;Pedro H. Mendes;Navin Perera;Karl Stol;Minas Liarokapis",
        "authorids": "/37088599578;/37089194213;/37089195923;/37543648400;/38558084100;/37088599578;/37089194213;/37089195923;/37543648400;/38558084100",
        "aff": "Department of Mechanical Engineering, The University of Auckland, New Zealand; Department of Mechanical Engineering, The University of Auckland, New Zealand; Department of Mechanical Engineering, The University of Auckland, New Zealand; Department of Mechanical Engineering, The University of Auckland, New Zealand; Department of Mechanical Engineering, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635995/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3147705065056825944&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Auckland",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "UoA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9636731",
        "title": "The Pursuit and Evasion of Drones Attacking an Automated Turret",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates the pursuit-evasion problem of a defensive gun turret and one or more attacking drones. The turret must \"visit\" each attacking drone once, as quickly as possible, to defeat the threat. This constitutes a Shortest Hamiltonian Path (SHP) through the drones. The investigation considers situations with increasing fidelity, starting with a 2D kinematic model and progressing to a 3D dynamic model. In 2D we determine the region from which one or more drones can always reach a turret, or the region close enough to it where they can evade the turret. This provides optimal starting angles for n drones around a turret and the maximum starting radius for one and two drones.We show that safety regions also exist in 3D and provide a controller so that a drone in this region can evade the pan-tilt turret. Through simulations we explore the maximum range n drones can start and still have at least one reach the turret, and analyze the effect of turret behavior and the drones\u2019 number, starting configuration, and behaviors.",
        "primary_area": "",
        "author": "Daniel Biediger;Luben Popov;Aaron T. Becker;Daniel Biediger;Luben Popov;Aaron T. Becker",
        "authorids": "/37086325072;/37089196498;/37588897100;/37086325072;/37089196498;/37588897100",
        "aff": "Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Bloomberg, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636731/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1048666727580886983&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Houston;Bloomberg",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.uh.edu;https://www.bloomberg.com",
        "aff_unique_abbr": "UH;Bloomberg",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Houston;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636338",
        "title": "The Radar Ghost Dataset \u2013 An Evaluation of Ghost Objects in Automotive Radar Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Radar sensors have a long tradition in advanced driver assistance systems (ADAS) and also play a major role in current concepts for autonomous vehicles. Their importance is reasoned by their high robustness against meteorological effects, such as rain, snow, or fog, and the radar\u2019s ability to measure relative radial velocity differences via the Doppler effect. The cause for these advantages, namely the large wavelength, is also one of the drawbacks of radar sensors. Compared to camera or lidar sensor, a lot more surfaces in a typical traffic scenario appear flat relative to the radar\u2019s emitted signal. This results in multi-path reflections or so called ghost detections in the radar signal. Ghost objects pose a major source for potential false positive detections in a vehicle\u2019s perception pipeline. Therefore, it is important to be able to segregate multipath reflections from direct ones. In this article, we present a dataset with detailed manual annotations for different kinds of ghost detections. Moreover, two different approaches for identifying these kinds of objects are evaluated. We hope that our dataset encourages more researchers to engage in the fields of multi-path object suppression or exploitation.",
        "primary_area": "",
        "author": "Florian Kraus;Nicolas Scheiner;Werner Ritter;Klaus Dietmayer;Florian Kraus;Nicolas Scheiner;Werner Ritter;Klaus Dietmayer",
        "authorids": "/37087107264;/37086488971;/37283474100;/37283417900;/37087107264;/37086488971;/37283474100;/37283417900",
        "aff": "Institute of Measurement, Control and Microtechnology, Ulm University, Ulm, Germany; Mercedes-Benz AG, Stuttgart, Germany; Mercedes-Benz AG, Stuttgart, Germany; Institute of Measurement, Control and Microtechnology, Ulm University, Ulm, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636338/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4115867121896127755&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Ulm University;Mercedes-Benz AG",
        "aff_unique_dep": "Institute of Measurement, Control and Microtechnology;",
        "aff_unique_url": "https://www.uni-ulm.de;https://www.mercedes-benz.com",
        "aff_unique_abbr": "Ulm U;MB AG",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Ulm;Stuttgart",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9635960",
        "title": "The Reasonable Crowd: Towards evidence-based and interpretable models of driving behavior",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles must balance a complex set of objectives. There is no consensus on how they should do so, nor on a model for specifying a desired driving behavior. We created a dataset to help address some of these questions in a limited operating domain. The data consists of 92 traffic scenarios, with multiple ways of traversing each scenario. Multiple annotators expressed their preference between pairs of scenario traversals. We used the data to compare an instance of a rulebook [1], carefully hand-crafted independently of the dataset, with several interpretable machine learning models such as Bayesian networks, decision trees, and logistic regression trained on the dataset. To compare driving behavior, these models use scores indicating by how much different scenario traversals violate each of 14 driving rules. The rules are interpretable and designed by subject-matter experts. First, we found that these rules were enough for these models to achieve a high classification accuracy on the dataset. Second, we found that the rulebook provides high interpretability without excessively sacrificing performance. Third, the data pointed to possible improvements in the rulebook and the rules, and to potential new rules. Fourth, we explored the interpretability vs performance trade-off by also training non-interpretable models such as a random forest. Finally, we make the dataset publicly available to encourage a discussion from the wider community on behavior specification for AVs. Please find it at github.com/bassam-motional/Reasonable-Crowd.",
        "primary_area": "",
        "author": "Bassam Helou;Aditya Dusi;Anne Collin;Noushin Mehdipour;Zhiliang Chen;Cristhian Lizarazo;Calin Belta;Tichakorn Wongpiromsarn;Radboud Duintjer Tebbens;Oscar Beijbom;Bassam Helou;Aditya Dusi;Anne Collin;Noushin Mehdipour;Zhiliang Chen;Cristhian Lizarazo;Calin Belta;Tichakorn Wongpiromsarn;Radboud Duintjer Tebbens;Oscar Beijbom",
        "authorids": "/37088457839;/37086337791;/37088754744;/37086595770;/37089195416;/37089194020;/37276061600;/37547924000;/37088748319;/38467234500;/37088457839;/37086337791;/37088754744;/37086595770;/37089195416;/37089194020;/37276061600;/37547924000;/37088748319;/38467234500",
        "aff": "Motional, Boston, MA; Motional, Boston, MA; Motional, Boston, MA; Motional, Boston, MA; Motional, Boston, MA; Motional, Boston, MA; Boston University, Boston, MA; Iowa State University, IA; Motional, Boston, MA; Motional, Boston, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635960/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2468665149311665670&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;0;0;1;2;0;0",
        "aff_unique_norm": "Motional;Boston University;Iowa State University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.motional.com;https://www.bu.edu;https://www.iastate.edu",
        "aff_unique_abbr": ";BU;ISU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;1;0;0",
        "aff_campus_unique": "Boston;Ames",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636188",
        "title": "The Role of Digit Arrangement in Soft Robotic In-Hand Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "The need for robotic hands capable of gentle in-hand manipulation is growing rapidly as robots enter the real world. In this work, we show that the arrangement of digits in a soft robotic hand has a strong effect on in-hand manipulation capabilities. Introducing task-based performance metrics which quantify the range of motion, repeatability, and accuracy of in-hand manipulation tasks, we investigate hand designs with finger arrangements ranging from axisymmetric-circular to anthropomorphic. Using an open-source soft robot simulator, the effect of object size and aspect ratio on the in-hand manipulation performance is studied for a variety of finger arrangements, and findings are validated using a physical hardware platform. We found that the ideal finger arrangement is task-dependent; anthropomorphic arrangements excel at lateral translations, and axisymmetric arrangements are best suited for rotations. The aspect ratio of the object also has a strong effect on in-hand manipulation, with anthropomorphic designs performing best on objects of high aspect ratio, and axisymmetric arrangements doing well on objects of low aspect ratio. These findings are further confirmed in a real-world task with delicate pastries, where gentle in-hand manipulation is critical. Overall, our results suggest that active control of digit arrangement is necessary for soft robotic hands to maximize in-hand manipulation capabilities with arbitrary objects.",
        "primary_area": "",
        "author": "Clark B. Teeple;Randall C. St. Louis;Moritz A. Graule;Robert J. Wood;Clark B. Teeple;Randall C. St. Louis;Moritz A. Graule;Robert J. Wood",
        "authorids": "/37086131116;/37089198250;/37085771962;/37326227400;/37086131116;/37089198250;/37085771962;/37326227400",
        "aff": "School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636188/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17473036645835601351&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636062",
        "title": "The Usage of Kinematic Singularities to Produce Periodic High-Powered Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged robots primarily energize their center of mass through external contact during stance phase. This links their range of possible motions to actuator power limits applied during usually short periods of time. Enabling limb actuators to pump energy into the system during non-contact phases can greatly extend the energetic profile of possible motions. However, funneling this extra energy into useful dynamics is a problem of its own. In this paper, we propose designing limb mechanisms that purposefully integrate kinematic singularities into their configuration space to enable airborne energization and enhance gait periodicity before sensors and feedback control are incorporated. The result produces a mechanical reflex that unloads spring energy stored during flight phase into a useful push-off motion as triggered by the onset of stance phase. The implementation generates an \"S\" shaped curve into a specific slice of the configuration space, motivating the name S-curve. We compare our proposed approach to more conventional strategies and survey the design parameters that can be used to shape an S-curve. Ranges of useful S-curves are determined through a simulation study and a linkage mechanism capable of producing an S-curve is displayed.",
        "primary_area": "",
        "author": "Chang Liu;Mark Plecnik;Chang Liu;Mark Plecnik",
        "authorids": "/37089194305;/37085786438;/37089194305;/37085786438",
        "aff": "Department of Aerospace & Mechanical Engineering, University of Notre Dame; Department of Aerospace & Mechanical Engineering, University of Notre Dame",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636062/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4100734610198930865&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Aerospace & Mechanical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636366",
        "title": "Through the Looking Glass: Diminishing Occlusions in Robot Vision Systems with Mirror Reflections",
        "track": "main",
        "status": "Poster",
        "abstract": "The quality of robot vision greatly affects the performance of automation systems, where occlusions stand as one of the biggest challenges. If the target is occluded from the sensor, detecting and grasping such objects become very challenging. For example, when multiple robot arms cooperate in a single workplace, occlusions will be created under the robot arm itself and hide objects underneath. While occlusions can be greatly reduced by installing multiple sensors, the increase in sensor costs cannot be ignored. Moreover, the sensor placements must be rearranged every time the robot operation routine and layout change.To diminish occlusions, we propose the first robot vision system with tilt-type mirror reflection sensing. By instantly tilting the sensor itself, we obtain two sensing results with different views: conventional direct line-of-sight sensing and non-line-of-sight sensing via mirror reflections. Our proposed system removes occlusions adaptively by detecting the occlusions in the scene and dynamically configuring the sensor tilt angle to sense the detected occluded area. Thus, sensor rearrangements are not required even after changes in robot operation or layout. Since the required hardware is the tilt-unit and a commercially available mirror, the cost increase is marginal. Through experiments, we show that our system can achieve a similar detection accuracy as systems with multiple sensors, regardless of the single-sensor implementation.",
        "primary_area": "",
        "author": "Kentaro Yoshioka;Hidenori Okuni;Tuan Thanh Ta;Akihide Sai;Kentaro Yoshioka;Hidenori Okuni;Tuan Thanh Ta;Akihide Sai",
        "authorids": "/38496594300;/37870892400;/37862641600;/37653699000;/38496594300;/37870892400;/37862641600;/37653699000",
        "aff": "Now with Keio University, Yokohama, Japan; Wireless System Laboratory, Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Wireless System Laboratory, Research and Development Center, Toshiba Corporation, Kawasaki, Japan; Wireless System Laboratory, Research and Development Center, Toshiba Corporation, Kawasaki, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636366/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1366446625503211294&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Keio University;Toshiba Corporation",
        "aff_unique_dep": ";Wireless System Laboratory",
        "aff_unique_url": "https://www.keio.ac.jp;https://www.toshiba.co.jp",
        "aff_unique_abbr": "Keio;Toshiba",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Yokohama;Kawasaki",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636778",
        "title": "Thrust Direction Control of an Underactuated Oscillating Swimming Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "The Modboat is an autonomous surface robot that turns the oscillation of a single motor into a controlled paddling motion through passive flippers. Inertial control methods developed in prior work can successfully drive the Modboat along trajectories and enable docking to neighboring modules, but have a non-constant cycle time and cannot react to dynamic environments. In this work we present a thrust direction control method for the Modboat that significantly improves the time-response of the system and increases the accuracy with which it can be controlled. We experimentally demonstrate that this method can be used to perform more compact maneuvers than prior methods or comparable robots can. We also present an extension to the controller that solves the reaction wheel problem of unbounded actuator velocity, and show that it further improves performance.",
        "primary_area": "",
        "author": "Gedaliah Knizhnik;Mark Yim;Gedaliah Knizhnik;Mark Yim",
        "authorids": "/37086285239;/37274063600;/37086285239;/37274063600",
        "aff": "GRASP Laboratory, University of Pensylvannia, Philadelphia, PA; GRASP Laboratory, University of Pensylvannia, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636778/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6342255332018373543&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636469",
        "title": "Topology-Guided Path Planning for Reliable Visual Navigation of MAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual navigation has been widely used for state estimation of micro aerial vehicles (MAVs). For stable visual navigation, MAVs should generate perception-aware paths which guarantee enough visible landmarks. Many previous works on perception-aware path planning focused on sampling-based planners. However, they may suffer from sample inefficiency, which leads to computational burden for finding a global optimal path. To address this issue, we suggest a perception-aware path planner which utilizes topological information of environments. Since the topological class of a path and visible landmarks during traveling the path are closely related, the proposed algorithm checks distinctive topological classes to choose the class with abundant visual information. Topological graph is extracted from the generalized Voronoi diagram of the environment and initial paths with different topological classes are found. To evaluate the perception quality of the classes, we divide the initial path into discrete segments where the points in each segment share similar visual information. The optimal class with high perception quality is selected, and a graph-based planner is utilized to generate path within the class. With simulations and real-world experiments, we confirmed that the proposed method could guarantee accurate visual navigation compared with the perception-agnostic method while showing improved computational efficiency than the sampling-based perception-aware planner.",
        "primary_area": "",
        "author": "Dabin Kim;Gyeong Chan Kim;Youngseok Jang;H. Jin Kim;Dabin Kim;Gyeong Chan Kim;Youngseok Jang;H. Jin Kim",
        "authorids": "/37087409258;/37086927682;/37087502351;/37599626400;/37087409258;/37086927682;/37087502351;/37599626400",
        "aff": "Mechanical and Aerospace Engineering Department, Seoul National University, Seoul, South Korea; Aerospace Engineering Department, Seoul National University, Seoul, South Korea; Mechanical and Aerospace Engineering Department, Seoul National University, Seoul, South Korea; Aerospace Engineering Department, Seoul National University, Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636469/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11080665496405607779&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Mechanical and Aerospace Engineering Department",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9636138",
        "title": "Toward State-Unsaturation Guaranteed Fault Detection Method in Visual Servoing of Soft Robot Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper puts forward a novel sensor-less fault detection method with only task errors feedback and applies it to visual servoing tasks of soft robot manipulators. The method is developed by introducing a suitably designed endogenous accessory signal (EAS). On the one hand, EAS transforms the change of jacobian matrix led by faults into the change of task errors, which enables the fault to be directly measured and detected; on the other hand, EAS adjusts the state trajectories according to the distance between states and their boundaries, so that state saturation is avoided. To enhance the robustness of the method, we introduce an artificial potential field that keeps the states from the undesired hyperplanes that lead to the loss of effectiveness of the method. Due to the uncalibrated feature point, its coordinates used in control laws and artificial potential filed are unknown. An adaptive algorithm is developed to guarantee the stability of the system and the convergence of the image errors. Experiments are conducted to validate the performance of the proposed method in both healthy and faulty systems.",
        "primary_area": "",
        "author": "Haoyuan Gu;Hesheng Wang;Weidong Chen;Haoyuan Gu;Hesheng Wang;Weidong Chen",
        "authorids": "/37088906015;/37292567100;/37279187800;/37088906015;/37292567100;/37279187800",
        "aff": "Department of Automation, Insititue of Medical Robotics, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, China and Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, China; Department of Automation, Insititue of Medical Robotics, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636138/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10324360946364878323&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Harbin Institute of Technology",
        "aff_unique_dep": "Department of Automation;State Key Laboratory of Robotics and System",
        "aff_unique_url": "https://www.sjtu.edu.cn;http://www.hit.edu.cn/",
        "aff_unique_abbr": "SJTU;HIT",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Shanghai;Harbin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636087",
        "title": "Toward battery-free flight: Duty cycled recharging of small drones",
        "track": "main",
        "status": "Poster",
        "abstract": "Constrained battery life on current Unmanned Aerial Vehicles (drones) limits the time they can operate and distance they can travel. We address this challenge by harvesting solar power to enable duty-cycled operation on a palm-sized drone. We present a scaling analysis that suggests that more solar power can be collected per unit mass of the drone as scale reduces, favoring small drones. By charging from the sun, the drone can operate for more than a single charging cycle, enabling extended mission time, and long-distance travel. To realize this, we design a high efficiency charging circuit and introduce two innovations. The first is a photovoltaic array that passively folds down while in flight to reduce air drag and automatically opens during landing due to the ground effect. The second is a sensor system and controller that autonomously finds suitable charging sites that are flat and well-lit. The drone can be fully charged in 3 hrs using the solar array and charging circuit with an average efficiency of 90.84%. Each charge enables a 4.7 min flight, allowing the drone to travel up to 1.2 km in a day. We also discuss how this platform could be used to take periodic measurements for smart agriculture or wildlife tracking, rapidly deploy wireless networks, or deploy microrobots in the future.",
        "primary_area": "",
        "author": "Nishant Elkunchwar;Suvesha Chandrasekaran;Vikram Iyer;Sawyer B. Fuller;Nishant Elkunchwar;Suvesha Chandrasekaran;Vikram Iyer;Sawyer B. Fuller",
        "authorids": "/37089198167;/37089194376;/37086452962;/37408404900;/37089198167;/37089194376;/37086452962;/37408404900",
        "aff": "Department of Mechanical Engineering, University of Washington, Seattle, WA, USA; Department of Mechanical Engineering, University of Washington, Seattle, WA, USA; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; Department of Mechanical Engineering, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636087/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13710195358263744492&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636106",
        "title": "Towards Autonomous Parking using Vision-only Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing autonomous parking solutions usually require special signs, pre-built maps or accurate ranging sensors to achieve reliable perception of the parking environment, but these methods are difficult to popularize because they either require preconditions or are expensive for production cars. In this paper, we propose a vision-only autonomous parking solution based on only six cameras. Through the appropriate depth estimation algorithms, our method obtains the pixel level depth of the image, and constructs a dense point cloud, so as to realize the fine perception of the parking environment. An improved Radon transform based parking space detection method are applied for better parking space detection method. Our proposed method achieves processing speed of above 5 Hz on a intermediate level computing platform. Furthermore, we demonstrate the practicability of the proposed system in real-world parking lots.",
        "primary_area": "",
        "author": "Yi Yang;Miaoxin Pan;Sitan Jiang;Jianhang Wang;Wei Wang;Junbo Wang;Meiling Wang;Yi Yang;Miaoxin Pan;Sitan Jiang;Jianhang Wang;Wei Wang;Junbo Wang;Meiling Wang",
        "authorids": "/37899921700;/37089002530;/37087053901;/37087052331;/37086920960;/37087080305;/37406965500;/37899921700;/37089002530;/37087053901;/37087052331;/37086920960;/37087080305;/37406965500",
        "aff": "State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Institute of Technology, Beijing, China; State Key Laboratory of Intelligent Control and Decision of Complex System, Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636106/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2265633823907323636&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Beijing Institute of Technology",
        "aff_unique_dep": "State Key Laboratory of Intelligent Control and Decision of Complex System",
        "aff_unique_url": "http://www.bit.edu.cn/",
        "aff_unique_abbr": "BIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636097",
        "title": "Towards Coordinated Robot Motions: End-to-End Learning of Motion Policies on Transform Trees",
        "track": "main",
        "status": "Poster",
        "abstract": "Generating robot motion that fulfills multiple tasks simultaneously is challenging due to the geometric constraints imposed on the robot. In this paper, we propose to solve multi-task problems through learning structured policies from human demonstrations. Our structured policy is inspired by RMPflow, a framework for combining subtask policies on different spaces. The policy structure provides the user an interface to 1) specifying the spaces that are directly relevant to the completion of the tasks, and 2) designing policies for certain tasks that do not need to be learned. We derive an end-to-end learning objective that is suitable for the multi-task problem, emphasizing the distance between generated motions and demonstrations measured on task spaces. Furthermore, the motion generated from the learned policy class is guaranteed to be stable. We validate the effectiveness of our proposed learning framework through qualitative and quantitative evaluations on three robotic tasks on a 7-DOF Rethink Sawyer robot.",
        "primary_area": "",
        "author": "M. Asif Rana;Anqi Li;Dieter Fox;Sonia Chernova;Byron Boots;Nathan Ratliff;M. Asif Rana;Anqi Li;Dieter Fox;Sonia Chernova;Byron Boots;Nathan Ratliff",
        "authorids": "/37086935482;/37086580906;/37284329000;/37283184200;/37085459219;/37579950900;/37086935482;/37086580906;/37284329000;/37283184200;/37085459219;/37579950900",
        "aff": "NVIDIA Research; NVIDIA Research; NVIDIA Research; Georgia Institute of Technology; NVIDIA Research; NVIDIA Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636097/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16494064937790473098&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "NVIDIA;Georgia Institute of Technology",
        "aff_unique_dep": "NVIDIA Research;",
        "aff_unique_url": "https://www.nvidia.com/research;https://www.gatech.edu",
        "aff_unique_abbr": "NVIDIA;Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636755",
        "title": "Towards Efficient Learning-Based Model Predictive Control via Feedback Linearization and Gaussian Process Regression",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a learning-based Model Predictive Control (MPC) methodology incorporating nonlinear predictions with robotics applications in mind. In particular, MPC is combined with feedback linearization for computational efficiency and Gaussian Process Regression (GPR) is used to model unknown system dynamics and nonlinearities. In this method, MPC predicts future states by leveraging a GPR model and optimizes a sequence of inputs over feedback linearized states. The controller was tested in simulation by using a two-link planar robot in the presence of model uncertainty. With respect to trajectory-tracking error, the proposed controller outperformed a conventional Proportional-Derivative Inverse Dynamics controller and a GPR-augmented version. Although a fully nonlinear MPC formulation achieved slightly better performance, the proposed controller had an average control calculation time that was 82\u00d7 faster.",
        "primary_area": "",
        "author": "Jack Caldwell;Joshua A. Marshall;Jack Caldwell;Joshua A. Marshall",
        "authorids": "/37089194441;/37269656200;/37089194441;/37269656200",
        "aff": "Department of Electrical & Computer Engineering and the Ingenuity Labs Research Institute, Queen\u2019s University, Kingston, Canada; Department of Electrical & Computer Engineering and the Ingenuity Labs Research Institute, Queen\u2019s University, Kingston, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636755/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4036463067911688771&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Queen\u2019s University",
        "aff_unique_dep": "Department of Electrical & Computer Engineering",
        "aff_unique_url": "https://www.queensu.ca",
        "aff_unique_abbr": "Queen's U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kingston",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636015",
        "title": "Towards Human Haptic Gesture Interpretation for Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Physical human-robot interactions (pHRI) are less efficient and communicative than human-human interactions, and a key reason is a lack of informative sense of touch in robotic systems. Interpreting human touch gestures is a nuanced, challenging task with extreme gaps between human and robot capability. Among prior works that demonstrate human touch recognition capability, differences in sensors, gesture classes, feature sets, and classification algorithms yield a conglomerate of non-transferable results and a glaring lack of a standard. To address this gap, this work presents 1) four proposed touch gesture classes that cover an important subset of the gesture characteristics identified in the literature, 2) the collection of an extensive force dataset on a common pHRI robotic arm with only its internal wrist force-torque sensor, and 3) an exhaustive performance comparison of combinations of feature sets and classification algorithms on this dataset. We demonstrate high classification accuracies among our proposed gesture definitions on a test set, emphasizing that neural network classifiers on the raw data outperform other combinations of feature sets and algorithms. Accompanying video is here.1",
        "primary_area": "",
        "author": "Bibit Bianchini;Prateek Verma;J. Kenneth Salisbury;Bibit Bianchini;Prateek Verma;J. Kenneth Salisbury",
        "authorids": "/37089197669;/37085759643;/37355483800;/37089197669;/37085759643;/37355483800",
        "aff": "Department of Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA; Artificial Intelligence Laboratory at the Department of Computer Science, Stanford University, Stanford, CA; Departments of Computer Science and Surgery, Stanford University, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636015/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9566431550314063695&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Pennsylvania;Stanford University",
        "aff_unique_dep": "Department of Mechanical Engineering and Applied Mechanics;Department of Computer Science",
        "aff_unique_url": "https://www.upenn.edu;https://www.stanford.edu",
        "aff_unique_abbr": "UPenn;Stanford",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Philadelphia;Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636341",
        "title": "Towards Intelligent Fruit Picking with In-hand Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Studies have shown that picking techniques play an important role in determining fruit quality at harvest (e.g. bruising, stem retention, etc). When picking fruit such as apples and pears, professional pickers use active perception, incorporating both visual and tactile input about fruit orientation, stem location, and the fruit\u2019s immediate surroundings. This combination of tactile, visual, and force feedback is what enables human workers to execute dynamic movements that quickly and efficiently remove fruit from the tree without damage. However, much of the prior work on robotic fruit picking has formulated the harvesting problem as a position-control problem, using visual feedback for closed-loop end-effector placement while disregarding feedback on physical contact. As a first step towards more intelligent fruit picking \u2014 combining proprioception, localized sensing, and observed forces \u2014 we have developed a custom end-effector with multiple in-hand sensors, including tactile sensors on the fingertips. This paper presents the mechatronic design of the device as well as results from multiple outdoor picking trials with a Honeycrisp apple tree. Preliminary results show that, with multi-modal sensing, fruit slip, fruit separation from the tree, and fruit release from the hand can be detected.",
        "primary_area": "",
        "author": "Lisa M. Dischinger;Miranda Cravetz;Jacob Dawes;Callen Votzke;Chelse VanAtter;Matthew L. Johnston;Cindy M. Grimm;Joseph R. Davidson;Lisa M. Dischinger;Miranda Cravetz;Jacob Dawes;Callen Votzke;Chelse VanAtter;Matthew L. Johnston;Cindy M. Grimm;Joseph R. Davidson",
        "authorids": "/37089196784;/37089197002;/37085768811;/37086561398;/37089195081;/37085767167;/37085798146;/37075739400;/37089196784;/37089197002;/37085768811;/37086561398;/37089195081;/37085767167;/37085798146;/37075739400",
        "aff": "Collaborative Robotics and Intelligent Systems Institute (CoRIS), Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute (CoRIS), Oregon State University, Corvallis, OR, USA; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA; Department of Bioengineering, Clemson University, Clemson, SC, USA; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute (CoRIS), Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems Institute (CoRIS), Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636341/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=925874708023437469&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;0;0;0",
        "aff_unique_norm": "Oregon State University;Clemson University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems Institute (CoRIS);Department of Bioengineering",
        "aff_unique_url": "https://oregonstate.edu;https://www.clemson.edu",
        "aff_unique_abbr": "OSU;Clemson",
        "aff_campus_unique_index": "0;0;0;0;1;0;0;0",
        "aff_campus_unique": "Corvallis;Clemson",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636831",
        "title": "Towards Robust Human Trajectory Prediction in Raw Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "Human trajectory prediction has received increased attention lately due to its importance in applications such as autonomous vehicles and indoor robots. However, most existing methods make predictions based on human-labeled trajectories and ignore the errors and noises in detection and tracking. In this paper, we study the problem of human trajectory forecasting in raw videos, and show that the prediction accuracy can be severely affected by various types of tracking errors. Accordingly, we propose a simple yet effective strategy to correct the tracking failures by enforcing prediction consistency over time. The proposed \"re-tracking\" algorithm can be applied to any existing tracking and prediction pipelines. Experiments on public benchmark datasets demonstrate that the proposed method can improve both tracking and prediction performance in challenging real-world scenarios. The code and data are available at https://git.io/retracking-prediction.",
        "primary_area": "",
        "author": "Rui Yu;Zihan Zhou;Rui Yu;Zihan Zhou",
        "authorids": "/37088689897;/37085991262;/37088689897;/37085991262",
        "aff": "College of Information Sciences and Technology, Pennsylvania State University, PA, USA; College of Information Sciences and Technology, Pennsylvania State University, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636831/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2738634116212579609&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Pennsylvania State University",
        "aff_unique_dep": "College of Information Sciences and Technology",
        "aff_unique_url": "https://www.psu.edu",
        "aff_unique_abbr": "PSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "University Park",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636844",
        "title": "Towards Robust Monocular Visual Odometry for Flying Robots on Planetary Missions",
        "track": "main",
        "status": "Poster",
        "abstract": "In the future, extraterrestrial expeditions will not only be conducted by rovers but also by flying robots. The technical demonstration drone Ingenuity, that just landed on Mars, will mark the beginning of a new era of exploration unhindered by terrain traversability. Robust self-localization is crucial for that. Cameras that are lightweight, cheap and information-rich sensors are already used to estimate the ego-motion of vehicles. However, methods proven to work in man-made environments cannot simply be deployed on other planets. The highly repetitive textures present in the wastelands of Mars pose a huge challenge to descriptor matching based approaches.In this paper, we present an advanced robust monocular odometry algorithm that uses efficient optical flow tracking to obtain feature correspondences between images and a refined keyframe selection criterion. In contrast to most other approaches, our framework can also handle rotation-only motions that are particularly challenging for monocular odometry systems. Furthermore, we present a novel approach to estimate the current risk of scale drift based on a principal component analysis of the relative translation information matrix. This way we obtain an implicit measure of uncertainty. We evaluate the validity of our approach on all sequences of a challenging real-world dataset captured in a Mars-like environment and show that it outperforms state-of-the-art approaches. The source code is publicly available at: https://github.com/DLR-RM/granit.",
        "primary_area": "",
        "author": "M. Wudenka;M. G. M\u00fcller;N. Demmel;A. Wedler;R. Triebel;D. Cremers;W. St\u00fcrzl;M. Wudenka;M. G. M\u00fcller;N. Demmel;A. Wedler;R. Triebel;D. Cremers;W. St\u00fcrzl",
        "authorids": "/37089194913;/37088444744;/37595100200;/37946067800;/37542908700;/37282875300;/37598170500;/37089194913;/37088444744;/37595100200;/37946067800;/37542908700;/37282875300;/37598170500",
        "aff": "Department of Informatics, Computer Vision Group, Technical University of Munich, Germany; Autonomous Systems Lab, ETH Zurich, Switzerland; Department of Informatics, Computer Vision Group, Technical University of Munich, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR); Department of Informatics, Computer Vision Group, Technical University of Munich, Germany; Department of Informatics, Computer Vision Group, Technical University of Munich, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636844/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15782063114508136463&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;0;0;2",
        "aff_unique_norm": "Technical University of Munich;ETH Zurich;German Aerospace Center",
        "aff_unique_dep": "Department of Informatics;Autonomous Systems Lab;Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.tum.de;https://www.ethz.ch;https://www.dlr.de",
        "aff_unique_abbr": "TUM;ETHZ;DLR",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0;1;0;0;0;0;0",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "id": "9636099",
        "title": "Towards Robust Visual Diver Detection Onboard Autonomous Underwater Robots: Assessing the Effects of Models and Data1",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep neural networks are the leading solution to the object detection problem. However, challenges arise when applying these networks to the kind of real-time, first-person video data that a robotic platform must process: specifically, detections may not be consistent from frame to frame, and objects may frequently appear at viewpoints that are particularly challenging for the model, resulting in inaccurate detections. In this paper, we present our approach for addressing these challenges for our particular vision problem: diver detection onboard autonomous underwater vehicles (AUVs). We begin by producing and releasing a dataset of approximately 105,000 annotated images of divers sourced from videos in order to address the challenge of learning a wide variety of object rotations and translations. This is one of the largest and most varied diver detection datasets ever created, and we compare models trained and tested on both our dataset and a previous dataset to demonstrate that our dataset improves the state-of-the-art in diver detection. Then, in order to choose an object detection model that produces detections that are consistent from frame to frame, we evaluate several state-of-the-art object detection models on the temporal stability of their detections in addition to the typical accuracy and efficiency metrics, mean average precision (mAP) and frames per second. Importantly, our results showed that models with the highest mAP do not also have the highest temporal stability.",
        "primary_area": "",
        "author": "Karin de Langis;Michael Fulton;Junaed Sattar;Karin de Langis;Michael Fulton;Junaed Sattar",
        "authorids": "/37089196197;/37086541498;/37546394500;/37089196197;/37086541498;/37546394500",
        "aff": "Department of Computer Science and Engineering and the Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering and the Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering and the Minnesota Robotics Institute, University of Minnesota Twin Cities, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636099/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11848715807180976876&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota Twin Cities",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636220",
        "title": "Towards Safe In Situ Needle Manipulation for Robot Assisted Lumbar Injection in Interventional MRI",
        "track": "main",
        "status": "Poster",
        "abstract": "Lumbar injection is an image-guided procedure performed manually for diagnosis and treatment of lower back pain and leg pain. Previously, we have developed and verified an MR-Conditional robotic solution to assisting the needle insertion process. Drawing on our clinical experiences, a virtual remote center of motion (RCM) constraint is implemented to enable our robot to mimic a clinician\u2019s hand motion to adjust the needle tip position in situ. Force and image data are collected to study the needle behavior in gel phantoms during this motion, and a mechanics-based needle-tissue interaction model is proposed and evaluated to further examine the underlying physics. This work extends the commonly-adopted notion of an RCM for flexible needles, and introduces new motion parameters to describe the needle behavior. The model parameters can be tuned to match the experimental result to sub-millimeter accuracy, and this proposed needle manipulation method presents a safer alternative to laterally translating the needle during in situ needle adjustments.",
        "primary_area": "",
        "author": "Yanzhou Wang;Gang Li;Ka-Wai Kwok;Kevin Cleary;Russell H. Taylor;Iulian Iordachita;Yanzhou Wang;Gang Li;Ka-Wai Kwok;Kevin Cleary;Russell H. Taylor;Iulian Iordachita",
        "authorids": "/37086019302;/37085576110;/37085400834;/37267443600;/37277162900;/37330620500;/37086019302;/37085576110;/37085400834;/37267443600;/37277162900;/37330620500",
        "aff": "Department of Mechanical Engineering and Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, Maryland, USA; Department of Mechanical Engineering and Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, Maryland, USA; Department of Mechanical Engineering, The University of Hong Kong, Hong Kong; Sheikh Zayed Institute for Pediatric Surgical Innovation, Children\u2019s National Hospital, Washington, DC, USA; Department of Computer Science and Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, Maryland, USA; Department of Mechanical Engineering and Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, Maryland, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636220/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9049486250479034165&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;0;0",
        "aff_unique_norm": "Johns Hopkins University;University of Hong Kong;Children\u2019s National Hospital",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering;Sheikh Zayed Institute for Pediatric Surgical Innovation",
        "aff_unique_url": "https://www.jhu.edu;https://www.hku.hk;https://childrensnational.org",
        "aff_unique_abbr": "JHU;HKU;",
        "aff_campus_unique_index": "0;0;1;2;0;0",
        "aff_campus_unique": "Baltimore;Hong Kong SAR;Washington, DC",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9636102",
        "title": "Towards Safe Navigation Through Crowded Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel neural network-based control policy to enable a mobile robot to navigate safety through environments filled with both static obstacles, such as tables and chairs, and dense crowds of pedestrians. The network architecture uses early fusion to combine a short history of lidar data with kinematic data about nearby pedestrians. This kinematic data is key to enable safe robot navigation in these uncontrolled, human-filled environments. The network is trained in a supervised setting, using expert demonstrations to learn safe navigation behaviors. A series of experiments in detailed simulated environments demonstrate the efficacy of this policy, which is able to achieve a higher success rate than either standard model-based planners or state-of-the-art neural network control policies that use only raw sensor data.",
        "primary_area": "",
        "author": "Zhanteng Xie;Pujie Xin;Philip Dames;Zhanteng Xie;Pujie Xin;Philip Dames",
        "authorids": "/37089197059;/37089196308;/38547257300;/37089197059;/37089196308;/38547257300",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636102/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6319660489602150081&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "9636740",
        "title": "Towards a Compact Vision-based Auto-Focusing System for Endoscopic Laser Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Endoscopic laser tools have been recently proposed in order to overcome the limitations of state-of-the-art laser tools, by integrating fiber-coupled lasers into flexible endoscopic systems. One of the main challenges in designing such endoscopic tools consists in the focusing of the laser, that requires to be frequently adjusted reducing the reliability of the system and increasing surgeons\u2019 mental workload. To avoid these problems, compact auto-focusing tools have been recently developed, taking advantage of MEMS varifocal mirrors (VM) to allow integration with endoscopic tools. In this paper, we integrate such VM-based tool with a distance sensing algorithm based on 3D surface reconstruction to achieve a complete autofocusing system. We evaluate the performance of the proposed integrated system by ablating lines on plaster block targets at variable distance and comparing the obtained ablation depth and width with that of a fixed focus system. Preliminary results show that the proposed system is able to keep the laser in focus resulting in uniform ablation lines for distance ranges from 14mm to 22mm.",
        "primary_area": "",
        "author": "Andre Geraldes;Veronica Penza;Leonardo S. Mattos;Andre Geraldes;Veronica Penza;Leonardo S. Mattos",
        "authorids": "/37086450593;/37085895473;/37283193500;/37086450593;/37085895473;/37283193500",
        "aff": "Department of Advanced Robotics, Biomedical Robotics Lab, Istituto Italiano di Tecnologia, Genoa, Italy; Department of Advanced Robotics, Biomedical Robotics Lab, Istituto Italiano di Tecnologia, Genoa, Italy; Department of Advanced Robotics, Biomedical Robotics Lab, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636740/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15142999727245091924&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Advanced Robotics",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9636865",
        "title": "Towards a Manipulator System for Disposal of Waste from Patients Undergoing Chemotherapy",
        "track": "main",
        "status": "Poster",
        "abstract": "There has been an increasing demand to automate the non-patient care matters so that the clinical staff can focus on delivering patient care. For example, out-patients undergoing chemotherapy increases their toilet usage frequency due to the treatment. As they are undergoing chemotherapy, their output waste contains a level of chemical. This task is compulsory yet troublesome and time-consuming so it is often desired to be removed from the nursing staff for them to focus on patient care. Hence, in this paper, we propose a manipulator system to automatically dispose the bedpan used by patients undergoing chemotherapy. The main technical challenge lies in the removal of the bedpan from the commode as the interaction of the grasping is highly dynamic, along with the different conditions of the bedpans. To address this manipulation issue, a Residual Reinforcement Learning (RRL) method that leverages vision-based commode pose estimation and the reinforcement learning (RL)-based uncertainty compensation for improvement of the grasping accuracy is proposed to increase the robustness of the disposal. The experiments conducted show that the manipulator can dispose the bedpan without human intervention and the proposed method achieves a 100 % success rate while the traditional method without RL is only 50 %.",
        "primary_area": "",
        "author": "Hsieh-Yu Li;Lay Siong Ho;Achala Athukorala;Wan Yun Lu;Audelia Dharmawan;Jane Li Feng Guo;Mabel May Leng Tan;Kok Cheong Wong;Nuri Syahida Ng;Maxim Mei Xin Tan;Hong Choon Oh;Daniel Tiang;Wei Wei Hong;Franklin Tan;Gek Kheng Png;Ivan Khoo;Chau Yuen;Pon Poh Hsu;Chen Ee Lee;U-Xuan Tan;Hsieh-Yu Li;Lay Siong Ho;Achala Athukorala;Wan Yun Lu;Audelia Dharmawan;Jane Li Feng Guo;Mabel May Leng Tan;Kok Cheong Wong;Nuri Syahida Ng;Maxim Mei Xin Tan;Hong Choon Oh;Daniel Tiang;Wei Wei Hong;Franklin Tan;Gek Kheng Png;Ivan Khoo;Chau Yuen;Pon Poh Hsu;Chen Ee Lee;U-Xuan Tan",
        "authorids": "/37085839428;/37089197848;/37085565872;/37089194580;/37085595490;/37089196584;/37089197666;/37089195298;/37089194391;/37089197667;/37089196301;/37089195763;/37089196759;/37089197033;/37089197836;/37089197753;/37273147100;/37089196054;/37089197646;/37085617165;/37085839428;/37089197848;/37085565872;/37089194580;/37085595490;/37089196584;/37089197666;/37089195298;/37089194391;/37089197667;/37089196301;/37089195763;/37089196759;/37089197033;/37089197836;/37089197753;/37273147100;/37089196054;/37089197646;/37085617165",
        "aff": "Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; National Cancer Centre Singapore, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; National Cancer Centre Singapore, Singapore; National Cancer Centre Singapore, Singapore; Changi General Hospital, Singapore; Changi General Hospital, Singapore; Changi General Hospital, Singapore; Changi General Hospital, Singapore; Singapore Health Services, Singapore; Singapore Health Services, Singapore; Singapore Health Services, Singapore; Changi General Hospital, Singapore; SIIX-AGT Medtech Pte. Ltd, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; Singapore Health Services, Singapore; Singapore Health Services, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636865/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2148587300780282110&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 40,
        "aff_unique_index": "0;1;0;0;0;1;1;2;2;2;2;3;3;3;2;4;0;3;3;0",
        "aff_unique_norm": "Singapore University of Technology and Design;National Cancer Centre Singapore;Changi General Hospital;Singapore Health Services;SIIX-AGT Medtech Pte. Ltd",
        "aff_unique_dep": "Pillar of Engineering Product Development;;;;",
        "aff_unique_url": "https://www.sutd.edu.sg;https://www.nccs.com.sg;https://www.changihospital.sg;https://www.shs.com.sg;",
        "aff_unique_abbr": "SUTD;NCCS;;SHS;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9636329",
        "title": "Towards a Reference Framework for Tactile Robot Performance and Safety Benchmarking",
        "track": "main",
        "status": "Poster",
        "abstract": "Improving robot systems via newly-developed sensing devices, control algorithms, or state estimators in order to obtain safe and efficient human-robot interaction as well as tactile manipulation skills requires standardized performance measurement protocols for objective comparison. Common protocols to evaluate robot motion performance are currently defined in EN ISO 9283:1998. For tactile and safety performance, however, no common metrics were agreed on nor standardized yet. In this paper, we propose a set of quantifiable performance criteria for robot performance analysis, objectifying robot force sensing, force control, and collision detection/reaction performance. We introduce the corresponding measurement setups and protocols, demonstrate and experimentally validate each with a Universal Robot UR10e and UR5e as well as a Franka Emika Panda robot arm. The proposed performance criteria, metrics, and experimental setups constitute the basis of a fully tactile performance and safety benchmarking framework that allows to objectively evaluate tactile robot performance via reproducible reference tests.",
        "primary_area": "",
        "author": "Robin Jeanne Kirschner;Alexander Kurdas;K\u00fcbra Karacan;Philipp Junge;Seyed Ali Baradaran Birjandi;Nico Mansfeld;Saeed Abdolshah;Sami Haddadin;Robin Jeanne Kirschner;Alexander Kurdas;K\u00fcbra Karacan;Philipp Junge;Seyed Ali Baradaran Birjandi;Nico Mansfeld;Saeed Abdolshah;Sami Haddadin",
        "authorids": "/37088861072;/37088861524;/37088532694;/37089197611;/37089196783;/38541896600;/37086148547;/37542865300;/37088861072;/37088861524;/37088532694;/37089197611;/37089196783;/38541896600;/37086148547;/37542865300",
        "aff": "Institute for Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Institute for Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Institute for Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Institute for Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Institute for Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Institute for Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Institute for Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Institute for Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636329/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1208154702131539000&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Institute for Robotics and Systems Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636200",
        "title": "Towards a User Adaptive Assistive Robot: Learning from Demonstration Using Navigation Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Elderly and mobility impaired people need special attention during bathing activities, since these tasks are demanding in body flexibility. Our aim is to build an assistive robotic bathing system, in order to increase the independence and safety of this procedure. Towards this end, the expertise of professional carers for bathing sequences and appropriate motions have to be adopted, in order to achieve natural, physical human - robot interaction. In this paper a Navigation Function (NF) approach is proposed in order to reproduce the way an expert clinical carer executes the bathing activities by means of construction repulsive potential fields (\"virtual obstacles\") for an assistive bath robot. The produced vector field, constructed based on the demonstration procedure, is used for real-time motion behavior planning tasks, which exploits the visual information from Depth sensors and the advantages of the NF approach, to estimate the reference pose for the end- effector of the assistive robotic system. The proposed method guarantees globally asymptotic convergence to the learned from demonstration washing motion, within the deformable and moving body-part limits, while in addition, restricted areas on the body surface are avoided. The proposed method is evaluated using real experimental data, obtained from human subjects during pouring water task demonstration.",
        "primary_area": "",
        "author": "Xanthi S. Papageorgiou;Athanasios C. Dometios;Costas S. Tzafestas;Xanthi S. Papageorgiou;Athanasios C. Dometios;Costas S. Tzafestas",
        "authorids": "/37296495800;/37085837403;/37296005200;/37296495800;/37085837403;/37296005200",
        "aff": "Embodied Interaction and Robotics Group, ILSP, ATHENA RC, Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Greece; School of Electrical and Computer Engineering, National Technical University of Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636200/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:mT3xJm-L8cMJ:scholar.google.com/&scioq=Towards+a+User+Adaptive+Assistive+Robot:+Learning+from+Demonstration+Using+Navigation+Functions&hl=en&as_sdt=0,33",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Athena Research Center;National Technical University of Athens",
        "aff_unique_dep": "Embodied Interaction and Robotics Group;School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.athena rc.gr;https://www.ntua.gr",
        "aff_unique_abbr": "ATHENA RC;NTUA",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Athens;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9636278",
        "title": "Towards an Online Framework for Changing-Contact Robot Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "We describe a framework for changing-contact robot manipulation tasks, which require the robot to make and break contacts with objects and surfaces. The discontinuous interaction dynamics of such tasks make it difficult to construct and use a single dynamics model or control strategy for such tasks. For any target motion trajectory, our framework incrementally improves its prediction of when contacts will occur. This prediction and a model relating approach velocity to impact force modify the velocity profile of the motion sequence such that it is C\u221e smooth, and help achieve a desired force on impact. We implement this framework by building on our hybrid force-motion variable impedance controller for continuous-contact tasks. We evaluate our framework in the illustrative context of a robot manipulator performing sliding tasks involving multiple contact changes with surfaces of different properties.",
        "primary_area": "",
        "author": "Saif Sidhik;Mohan Sridharan;Dirk Ruiken;Saif Sidhik;Mohan Sridharan;Dirk Ruiken",
        "authorids": "/37088342241;/37269573500;/37990697500;/37088342241;/37269573500;/37990697500",
        "aff": "Intelligent Robotics Lab, School of Computer Science, University of Birmingham, UK; Intelligent Robotics Lab, School of Computer Science, University of Birmingham, UK; Offenbach am Main, Honda Research Institute Europe GmbH, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636278/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17702096933120583584&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Birmingham;Honda Research Institute Europe GmbH",
        "aff_unique_dep": "School of Computer Science;",
        "aff_unique_url": "https://www.birmingham.ac.uk;https://www.honda-ri.de",
        "aff_unique_abbr": "UoB;HRI-Europe",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Birmingham;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "id": "9636316",
        "title": "Towards autonomous area inspection with a bio-inspired underwater legged robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, a new category of bio-inspired legged robots moving directly on the seabed have been proposed to complement the abilities of traditional underwater vehicles and to enhance manipulation and sampling tasks. So far, only tele-operated use of underwater legged robots has been reported and in this paper we attempt to fill such gap by presenting the first step towards autonomous area inspection. First, we present a 3 dimensional single-legged model for underwater hopping locomotion and derive a path following control strategy. Later, we adapt such control strategy to an underwater hexapod robot SILVER2 on the robotic simulator Webots. Finally, we simulate a full autonomous mission consisting in the inspection of an area over a pre-defined path, target recognition, transition to a safer gait and target approach. Our results show the feasibility of the approach and encourage the implementation of the presented control strategy on the robot SILVER2.",
        "primary_area": "",
        "author": "Giacomo Picardi;Rossana Lovecchio;Marcello Calisti;Giacomo Picardi;Rossana Lovecchio;Marcello Calisti",
        "authorids": "/37086415837;/37089194626;/37601977800;/37086415837;/37089194626;/37601977800",
        "aff": "BioRobotics Institute, Scuola Superiore Sant\u2019Anna, Pisa (PI), Italy; BioRobotics Institute, Scuola Superiore Sant\u2019Anna, Pisa (PI), Italy; Lincoln Insitute for Agri-food Technology, University of Lincoln, Lincoln, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636316/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=959007329344291670&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Scuola Superiore Sant\u2019Anna;University of Lincoln",
        "aff_unique_dep": "BioRobotics Institute;Lincoln Institute for Agri-food Technology",
        "aff_unique_url": "https://www.sssup.it;https://www.lincoln.ac.uk",
        "aff_unique_abbr": "SSSA;",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Pisa;Lincoln",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Italy;United Kingdom"
    },
    {
        "id": "9636346",
        "title": "TrajectoTree: Trajectory Optimization Meets Tree Search for Planning Multi-contact Dexterous Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Dexterous manipulation tasks often require contact switching, where fingers make and break contact with the object. We propose a method that plans trajectories for dexterous manipulation tasks involving contact switching using contact-implicit trajectory optimization (CITO) augmented with a high-level discrete contact sequence planner. We first use the high-level planner to find a sequence of finger contact switches given a desired object trajectory. With this contact sequence plan, we impose additional constraints in the CITO problem. We show that our method finds trajectories approximately 7 times faster than a general CITO baseline for a four-finger planar manipulation scenario. Furthermore, when executing the planned trajectories in a full dynamics simulator, we are able to more closely track the object pose trajectories planned by our method than those planned by the baselines.",
        "primary_area": "",
        "author": "Claire Chen;Preston Culbertson;Marion Lepert;Mac Schwager;Jeannette Bohg;Claire Chen;Preston Culbertson;Marion Lepert;Mac Schwager;Jeannette Bohg",
        "authorids": "/37089198158;/37086321694;/37089194121;/37424620600;/37591153900;/37089198158;/37086321694;/37089194121;/37424620600;/37591153900",
        "aff": "Departments of Computer Science, Stanford University; Departments of Mechanical Engineering, Stanford University; Departments of Mechanical Engineering, Stanford University; Departments of Aeronautics and Astronautics, Stanford University; Departments of Computer Science, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636346/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11064824986029098608&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636231",
        "title": "Trajectory Generation in New Environments from Past Experiences",
        "track": "main",
        "status": "Poster",
        "abstract": "Being able to safely operate for extended periods of time in dynamic environments is a critical capability for autonomous systems. This generally involves the prediction and understanding of motion patterns of dynamic entities, such as vehicles and people, in the surroundings. Many motion prediction methods in the literature implicitly account for environmental factors by learning on observed motion in a fixed environment, and are designed to make predictions in the same environment. In this paper, we address the problem of generating likely motion trajectories for novel environments, represented as occupancy grid maps, where motion has not been observed. We introduce the Occupancy-Conditional Trajectory Network (OTNet) framework, capable of transferring the previously observed motion patterns in known environments to new environments. OTNet provides a functional representation for motion trajectories and utilises neural networks to learn occupancy-conditional distributions over the function parameters. We empirically demonstrate our method\u2019s ability to generate complex multi-modal trajectory patterns in both simulated and real-world environments.",
        "primary_area": "",
        "author": "Weiming Zhi;Tin Lai;Lionel Ott;Fabio Ramos;Weiming Zhi;Tin Lai;Lionel Ott;Fabio Ramos",
        "authorids": "/37086936558;/37086935412;/38251784400;/37285364500;/37086936558;/37086935412;/38251784400;/37285364500",
        "aff": "School of Computer Science, the University of Sydney, Australia; School of Computer Science, the University of Sydney, Australia; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; NVIDIA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636231/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6029426989099731681&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "University of Sydney;ETH Zurich;NVIDIA",
        "aff_unique_dep": "School of Computer Science;Autonomous Systems Lab;NVIDIA",
        "aff_unique_url": "https://www.sydney.edu.au;https://www.ethz.ch;https://www.nvidia.com",
        "aff_unique_abbr": "USYD;ETHZ;NV",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Sydney;Zurich;",
        "aff_country_unique_index": "0;0;1;2",
        "aff_country_unique": "Australia;Switzerland;United States"
    },
    {
        "id": "9636535",
        "title": "Trajectory Optimization For Rendezvous Planning Using Quadratic B\u00e9zier Curves",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider a trajectory planning problem where an autonomous vehicle aims to rendezvous with another cooperating vehicle in minimum time. The first vehicle has kinematic constraints, consequently feasible trajectories must have a maximum curvature less than a specified limit. Rendezvous is said to occur at the instant that the two vehicles are collocated with the same heading. We propose a technique to construct a trajectory, composed of piecewise quadratic B\u00e9zier curves, that satisfies the vehicle motion constraints and achieves rendezvous in minimum time. The methodology begins by finding safe flight corridors, which are constructed from sequences of triangles using constrained Delaunay triangulation of the feasible space; the triangles define the bounds of B\u00e9zier curves. We formulate the necessary constraints for continuity and feasibility as functions of the control points that define the B\u00e9zier curves, and the resulting optimization problem is solved using a nonlinear programming solver. The techniques developed were tested using simulated scenarios, and we present the results which highlight the efficacy of the proposed solution approach. Furthermore, the algorithm was implemented and tested in a field test and those results are presented.",
        "primary_area": "",
        "author": "Satyanarayana G. Manyam;David W. Casbeer;Isaac E. Weintraub;Colin Taylor;Satyanarayana G. Manyam;David W. Casbeer;Isaac E. Weintraub;Colin Taylor",
        "authorids": "/38096429300;/37273056100;/37086423160;/37089194915;/38096429300;/37273056100;/37086423160;/37089194915",
        "aff": "Infoscitex Corporation, a DCS Company, Dayton, OH, USA; Controls Center of Excellence, Air Force Research Laboratory, WPAFB, OH, USA; Controls Center of Excellence, Air Force Research Laboratory, WPAFB, OH, USA; Parallax Advanced Research, Dayton, OH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636535/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18050953530778678226&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Infoscitex Corporation;Air Force Research Laboratory;Parallax Advanced Research",
        "aff_unique_dep": ";Controls Center of Excellence;",
        "aff_unique_url": ";https://www.afrl.af.mil/;",
        "aff_unique_abbr": ";AFRL;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";WPAFB",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636364",
        "title": "Trajectory Selection for Power-over-Tether Atmospheric Sensing UAS",
        "track": "main",
        "status": "Poster",
        "abstract": "Power-over-tether aircraft is an effective tool for persistent spatiotemporal monitoring of environmental phenomena. This paper presents the design and evaluation of flight trajectories for the tethered aircraft unmanned system (TAUS) sensing a dynamic temperature field. TAUS is a novel power-over-tether-based unmanned aerial system (UAS) configured for long-term, high throughput atmospheric monitoring. It is unique in that it provides position control while measuring atmospheric properties on-board the aircraft and with sensors along the tether. We validated the robotic system by conducting outdoor experiments to characterize the sensor performance against a meteorological tower. We found minimal sensing error at the corresponding altitude relative to the ground truth installation. We then used the experimental data to simulate four trajectories (Lawn-mower, Spiral, Star, and Flower) on power-tethered and untethered system models to evaluate performance factors related to trajectory selection. The analysis of the simulated data indicated that the power-tethered Star trajectory performed well concerning key performance factors when measuring changing atmospheric fields.",
        "primary_area": "",
        "author": "Daniel A. Rico;Francisco Mu\u00f1oz-Arriola;Carrick Detweiler;Daniel A. Rico;Francisco Mu\u00f1oz-Arriola;Carrick Detweiler",
        "authorids": "/37089196854;/37089194961;/38535355300;/37089196854;/37089194961;/38535355300",
        "aff": "Department of Computer Science and Engineering, NIMBUS Lab; School of Natural Resources, University of Nebraska-Lincoln, Nebraska, USA; Department of Computer Science and Engineering, NIMBUS Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636364/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5535341541533413190&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "NIMBUS Lab;University of Nebraska-Lincoln",
        "aff_unique_dep": "Department of Computer Science and Engineering;School of Natural Resources",
        "aff_unique_url": ";https://www.unl.edu",
        "aff_unique_abbr": ";UNL",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Lincoln",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "9636846",
        "title": "Trajectory Splitting: A Distributed Formulation for Collision Avoiding Trajectory Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Efficient trajectory optimization is essential for avoiding collisions in unstructured environments, but it remains challenging to have both speed and quality in the solutions. One reason is that second-order optimality requires calculating Hessian matrices that can grow with O(N2) with the number of waypoints. Decreasing the waypoints can quadratically decrease computation time. Unfortunately, fewer waypoints result in lower quality trajectories that may not avoid the collision. To have both, dense waypoints and reduced computation time, we took inspiration from recent studies on consensus optimization and propose a distributed formulation of collocated trajectory optimization. It breaks a long trajectory into several segments, where each segment becomes a subproblem of a few waypoints. These subproblems are solved classically, but in parallel, and the solutions are fused into a single trajectory with a consensus constraint that enforces continuity of the segments through a consensus update. With this scheme, the quadratic complexity is distributed to each segment and enables solving for higher-quality trajectories with denser waypoints. Furthermore, the proposed formulation is amenable to using any existing trajectory optimizer for solving the subproblems. We compare the performance of our implementation of trajectory splitting against leading motion planning algorithms and demonstrate the improved computational efficiency of our method.",
        "primary_area": "",
        "author": "Changhao Wang;Jeffrey Bingham;Masayoshi Tomizuka;Changhao Wang;Jeffrey Bingham;Masayoshi Tomizuka",
        "authorids": "/37086426211;/37089194143;/37281933000;/37086426211;/37089194143;/37281933000",
        "aff": "Dept. of Mechanical Engineering, University of California, Berkeley, CA, USA; X, the Moonshot Factory, Mountain View, CA, USA; Dept. of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636846/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16062418238352108977&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Berkeley;X Development LLC",
        "aff_unique_dep": "Dept. of Mechanical Engineering;",
        "aff_unique_url": "https://www.berkeley.edu;https://xdevllc.com",
        "aff_unique_abbr": "UC Berkeley;X",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Berkeley;Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636422",
        "title": "Trajectory-Constrained Deep Latent Visual Attention for Improved Local Planning in Presence of Heterogeneous Terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a reward-predictive, model-based learning method featuring trajectory-constrained visual attention for use in mapless, local visual navigation tasks. Our method learns to place visual attention at locations in latent image space which follow trajectories caused by vehicle control actions to later enhance predictive accuracy during planning. Our attention model is jointly optimized by the task-specific loss and additional trajectory-constraint loss, allowing adaptability yet encouraging a regularized structure for improved generalization and reliability. Importantly, visual attention is applied in latent feature map space instead of raw image space to promote efficient planning. We validated our model in visual navigation tasks of planning low turbulence, collision-free trajectories in off-road settings and hill climbing with locking differentials in the presence of slippery terrain. Experiments involved randomized procedural generated simulation and real-world environments. We found our method improved generalization and learning efficiency when compared to no-attention and self-attention alternatives.",
        "primary_area": "",
        "author": "Stefan Wapnick;Travis Manderson;David Meger;Gregory Dudek;Stefan Wapnick;Travis Manderson;David Meger;Gregory Dudek",
        "authorids": "/37088503946;/38491501400;/37542891800;/37274057100;/37088503946;/38491501400;/37542891800;/37274057100",
        "aff": "Mobile Robotics Laboratory, School of Computer Science, McGill University, Montreal, Canada; Mobile Robotics Laboratory, School of Computer Science, McGill University, Montreal, Canada; Mobile Robotics Laboratory, School of Computer Science, McGill University, Montreal, Canada; Mobile Robotics Laboratory, School of Computer Science, McGill University, Montreal, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636422/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3457816264462645690&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "McGill University",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.mcgill.ca",
        "aff_unique_abbr": "McGill",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636842",
        "title": "Trajectory-based Split Hindsight Reverse Curriculum Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping is one of the most fundamental problems in robotic manipulation. In recent years, with the development of data-driven methods, reinforcement learning has been used in solving robotic grasping problems. However, grasping is a long-horizon and sparse reward task, whose natural reward only appears when the task is successfully achieved. Therefore, it brings great challenges to the deployment of reinforcement learning methods. To tackle this difficulty, we propose a new method called Trajectory-based Split Hindsight Reverse Curriculum Learning. This method of reverse learning from the goal can greatly improve the learning efficiency and the final performance of the tasks. Specifically, based on referred trajectories, the agent starts to learn in a small state space near the goal and then gradually in larger state spaces until covering the entire state space. Through split hindsight experience replay, the sampled trajectory is divided into segments that match the current subspace's size; then, they are modified to successful trajectories to enable more efficient learning. In both simulation and real-world experiments, our method surpasses the existing methods and achieves the goal-oriented grasping tasks with higher success rates and better data efficiencies. The detailed experimental results can be viewed at https://youtu.be/7uNRzmRZhDk.",
        "primary_area": "",
        "author": "Jiaxi Wu;Dianmin Zhang;Shanlin Zhong;Hong Qiao;Jiaxi Wu;Dianmin Zhang;Shanlin Zhong;Hong Qiao",
        "authorids": "/37088964822;/37088966183;/37086387702;/37338715300;/37088964822;/37088966183;/37086387702;/37338715300",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Center for Excellence in Brain Science and Intelligence Technology, Institute of Neuroscience, Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636842/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9501411413469572112&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_unique_dep": "School of Artificial Intelligence;Institute of Neuroscience",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.cas.cn",
        "aff_unique_abbr": "UCAS;CAS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636301",
        "title": "Transformer-based deep imitation learning for dual-arm robot manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep imitation learning is promising for solving dexterous manipulation tasks because it does not require an environment model and pre-programmed robot behavior. However, its application to dual-arm manipulation tasks remains challenging. In a dual-arm manipulation setup, the increased number of state dimensions caused by the additional robot manipulators causes distractions and results in poor performance of the neural networks. We address this issue using a self-attention mechanism that computes dependencies between elements in a sequential input and focuses on important elements. A Transformer, a variant of self-attention architecture, is applied to deep imitation learning to solve dual-arm manipulation tasks in the real world. The proposed method has been tested on dual-arm manipulation tasks using a real robot. The experimental results demonstrated that the Transformer-based deep imitation learning architecture can attend to the important features among the sensory inputs, therefore reducing distractions and improving manipulation performance when compared with the baseline architecture without the self-attention mechanisms.",
        "primary_area": "",
        "author": "Heecheol Kim;Yoshiyuki Ohmura;Yasuo Kuniyoshi;Heecheol Kim;Yoshiyuki Ohmura;Yasuo Kuniyoshi",
        "authorids": "/37088419106;/37581602900;/37299294900;/37088419106;/37581602900;/37299294900",
        "aff": "Laboratory for Intelligent Systems and Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Laboratory for Intelligent Systems and Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Laboratory for Intelligent Systems and Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636301/",
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2870359898886552298&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636342",
        "title": "Translating Natural Language Instructions to Computer Programs for Robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "It is highly desirable for robots that work alongside humans to be able to understand instructions in natural language. Existing language conditioned imitation learning models directly predict the actuator commands from the image observation and the instruction text. Rather than directly predicting actuator commands, we propose translating the natural language instruction to a Python function which queries the scene by accessing the output of the object detector and controls the robot to perform the specified task. This enables the use of non-differentiable modules such as a constraint solver when computing commands to the robot. Moreover, the labels in this setup are significantly more informative computer programs that capture the intent of the expert rather than teleoperated demonstrations. We show that the proposed method performs better than training a neural network to directly predict the robot actions.",
        "primary_area": "",
        "author": "Sagar Gubbi Venkatesh;Raviteja Upadrashta;Bharadwaj Amrutur;Sagar Gubbi Venkatesh;Raviteja Upadrashta;Bharadwaj Amrutur",
        "authorids": "/37087323447;/37085368187;/37370284100;/37087323447;/37085368187;/37370284100",
        "aff": "Robert Bosch Center for Cyber Physical Systems, Indian Institute of Science, Bangalore, India; Robert Bosch Center for Cyber Physical Systems, Indian Institute of Science, Bangalore, India; Robert Bosch Center for Cyber Physical Systems, Indian Institute of Science, Bangalore, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636342/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7776233867798087262&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Indian Institute of Science",
        "aff_unique_dep": "Robert Bosch Center for Cyber Physical Systems",
        "aff_unique_url": "https://www.iisc.ac.in",
        "aff_unique_abbr": "IISc",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bangalore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9635891",
        "title": "Traversability-based Trajectory Planning with Quasi-Dynamic Vehicle Model in Loose Soil",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a framework for trajectory planning that explicitly considers robotic traversability based on a quasi-dynamic vehicle model of a mobile robot in loose soil. The quasi-dynamic model estimates the slip effect due to wheel-terrain interaction forces regardless of solving complicated multibody dynamics. Therefore, our proposed model is computationally efficient for quantifying how the robot safely traverses each trajectory segment generated by a planning algorithm. The trajectory planning in our framework exploits a sampling-based incremental search algorithm, i.e., Closed-Loop Rapidly-Exploring Random Trees (CL-RRT). In the tree extension process of the CL-RRT, the traversability assessment based on the quasi-dynamic vehicle model excludes the trajectory segment associated with a hazardous wheel slip ratio. As a result, a trajectory generated from the proposed framework is safely traversable for the robot even in high slip terrain. Simulation results show that the proposed vehicle model can run 57K times faster than the dynamic model and predict the robot motion 3 times more accurately than the kinematic model. Multiple trials of the trajectory planning simulation show that our proposed framework incorporated with the quasi-dynamic model reduces a wheel slip ratio by about 40 % as compared with the kinematic model.",
        "primary_area": "",
        "author": "Reiya Takemura;Genya Ishigami;Reiya Takemura;Genya Ishigami",
        "authorids": "/37089194658;/37546428100;/37089194658;/37546428100",
        "aff": "Graduate School of Integrated Design Engineering, Keio University, Japan; Graduate School of Integrated Design Engineering, Keio University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635891/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9898712798827670405&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Keio University",
        "aff_unique_dep": "Graduate School of Integrated Design Engineering",
        "aff_unique_url": "https://www.keio.ac.jp",
        "aff_unique_abbr": "Keio",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636006",
        "title": "Trotting and Pacing Locomotion of a Position-Controlled Quadruped Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Compared with torque-control techniques, a position-controlled quadruped robot is lower cost, easier to build, and more direct to drive. However, the stiff actuation of position-controlled actuators makes it difficult for the quadruped to achieve dynamically stable locomotion. This paper presents an implementation of joint velocity programming technique to regulate the body\u2019s moving speed and orientation for a position-controlled quadruped robot that performs trotting or pacing locomotion. The robot model is mapped to a new coordinate space in order to decouple the control of its body. In one plane of the new coordinate space, the robot is simplified to an inverted pendulum model to generate attitude and velocity tracking actions. In the other planes, body regulating problems are formulated in velocity forms and solved by designing support leg motions. The controllers in these planes are integrated to produce joint velocities that enable robust trotting and pacing locomotion at a variety of speeds and directions, despite lacking force control or feedback techniques. Physical test results as well as simulating results demonstrate control of the quadruped robot SmarQ to perform omni-directional locomotion, impact recovery, and adaptability to uneven terrains.",
        "primary_area": "",
        "author": "Guoteng Zhang;Yibin Li;Shugen Ma;Guoteng Zhang;Yibin Li;Shugen Ma",
        "authorids": "/37085406403;/37279897500;/37280187400;/37085406403;/37279897500;/37280187400",
        "aff": "School of Control Science and Engineering, Shandong University, Jinan, China; School of Control Science and Engineering, Shandong University, Jinan, China; Department of Robotics, Ritsumeikan University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636006/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2266860475531494981&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Shandong University;Ritsumeikan University",
        "aff_unique_dep": "School of Control Science and Engineering;Department of Robotics",
        "aff_unique_url": "http://www.sdu.edu.cn;https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "SDU;Ritsumeikan",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Jinan;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9636485",
        "title": "Trust your supervisor: quadrotor obstacle avoidance using controlled invariant sets",
        "track": "main",
        "status": "Poster",
        "abstract": "Supervision of a nominal controller, to enforce safety, is concerned with appropriately modifying the generated control inputs, if needed, in order to keep a control system within a set of safe states. An integral component in supervision is a controlled invariant set contained in the set of safe states. In this paper, we build on recent results on the computation of polytopic controlled invariant sets to present a supervision framework that computes the corrected inputs analytically and, hence, suitable for real-time control. The framework is validated on the task of quadrotor obstacle avoidance by forcing the vehicle to navigate within controlled invariant sets of the obstacle-free space. The results are experimentally demonstrated on a Crazyflie 2.0 quadrotor.",
        "primary_area": "",
        "author": "Luigi Pannocchi;Tzanis Anevlavis;Paulo Tabuada;Luigi Pannocchi;Tzanis Anevlavis;Paulo Tabuada",
        "authorids": "/37086116670;/37086592184;/37300854400;/37086116670;/37086592184;/37300854400",
        "aff": "Department of Electrical and Computer Engineering, University of California, Los Angeles; Department of Electrical and Computer Engineering, University of California, Los Angeles; Department of Electrical and Computer Engineering, University of California, Los Angeles",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636485/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11515227676493417010&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636596",
        "title": "Turning an Articulated 3-PPSR Manipulator into a Parallel Continuum Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Parallel Continuum Robots (PCR) have received a lot of attention in recent years. This paper presents a new 6-degrees-of-freedom PCR derived from the conventional 3-PPSR parallel manipulator. This robot is driven by three limbs consisting of two flexible rods each and replacing the spherical and revolute joints of the original version. Each limb is mounted onto two linear axes arranged in series. To allow a direct comparison between the articulated and the continuum version, the parallel mechanism of an industrial manipulator has been replaced by an elastic structure of the same size. The simulations and the experiments show that the flexible counterpart of the manipulator is able to achieve a larger workspace, increasing the range of motion by 150% for rotations and by 157% in elevation. Moreover, the position repeatability is improved by 47% (reaching 3.4 \u00b5m) and the orientation repeatability by 57% (reaching 14.3 \u00b5rad). This can be explained by the removal of the spherical and revolute joints but also by the constant stress in the structure that acts as an anti backlash system on leadscrew actuators.",
        "primary_area": "",
        "author": "Oscar F. Gallardo;Benjamin Mauz\u00e9;Redwan Dahmouche;Christian Duriez;Guillaume J. Laurent;Oscar F. Gallardo;Benjamin Mauz\u00e9;Redwan Dahmouche;Christian Duriez;Guillaume J. Laurent",
        "authorids": "/37089197077;/37088371255;/37546446600;/37428704500;/37553268000;/37089197077;/37088371255;/37546446600;/37428704500;/37553268000",
        "aff": "FEMTO-ST Institute, Univ. Bourgogne Franche-Comt\u00e9, UMR CNRS 6174, Besan\u00e7on, France; FEMTO-ST Institute, Univ. Bourgogne Franche-Comt\u00e9, UMR CNRS 6174, Besan\u00e7on, France; FEMTO-ST Institute, Univ. Bourgogne Franche-Comt\u00e9, UMR CNRS 6174, Besan\u00e7on, France; DEFROST Team at INRIA Lille-Nord-Europe, Universit\u00e9 de Lille, France; FEMTO-ST Institute, Univ. Bourgogne Franche-Comt\u00e9, UMR CNRS 6174, Besan\u00e7on, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636596/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16868862425997578331&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "FEMTO-ST Institute;INRIA Lille-Nord-Europe",
        "aff_unique_dep": "UMR CNRS 6174;DEFROST Team",
        "aff_unique_url": ";https://www.inria.fr/en/centre/lille-nord-europe",
        "aff_unique_abbr": ";INRIA",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Besan\u00e7on;Lille",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636251",
        "title": "Two-Stage Optimization of a Reconfigurable Asymmetric 6-DOF Haptic Robot for Task-Specific Workspace",
        "track": "main",
        "status": "Poster",
        "abstract": "Parallel mechanisms (PMs) are commonly used for developing haptic devices due to low inertia, high rigidity and precision. However, limited workspace impedes their application for task-oriented robotic therapy which generally requires large motion ranges. To solve this problem, first, a PM- based reconfigurable asymmetric 6-DOF haptic interface was presented, and then a two-stage optimization method was proposed to make the robot implement two kinds of task-specific workspaces including gross motor tasks (GMTs) and fine motor tasks (FMTs). Optimization of this robot was conducted to pursue a compact size and high accuracy. The global conditioning index (GCI) and the occupied area of the robot were selected as the evaluation indices, where the GCI was derived using a dimensionally homogeneous Jacobian matrix. A multi-objective optimization method based on the genetic algorithm (GA) was utilized. The actual design parameters were finally defined from solutions of the Pareto front. The proposed two-stage optimization method provides a feasible solution for determining task-specific robotic workspace of the reconfigurable mechanism.",
        "primary_area": "",
        "author": "Changqi Zhang;Congzhe Wang;Qing Miao;Mingming Zhang;Changqi Zhang;Congzhe Wang;Qing Miao;Mingming Zhang",
        "authorids": "/37089196581;/37088393580;/37088951602;/37085459780;/37089196581;/37088393580;/37088951602;/37085459780",
        "aff": "Department of Biomedical Engineering, Shenzhen Key Laboratory of Smart Healthcare Engineering, College of Engineering, Southern University of Science and Technology, Shenzhen, China; School of Advanced Manufacturing Engineering, Chongqing University of Posts and Telecommunications, Chongqing, China; Department of Biomedical Engineering, Shenzhen Key Laboratory of Smart Healthcare Engineering, College of Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Biomedical Engineering, Shenzhen Key Laboratory of Smart Healthcare Engineering, College of Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636251/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10977972220250892335&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Southern University of Science and Technology;Chongqing University of Posts and Telecommunications",
        "aff_unique_dep": "Department of Biomedical Engineering;School of Advanced Manufacturing Engineering",
        "aff_unique_url": "https://www.sustech.edu.cn;",
        "aff_unique_abbr": "SUSTech;",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Shenzhen;Chongqing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636523",
        "title": "Understanding and Segmenting Human Demonstrations into Reusable Compliant Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "Hard coded robotic manipulation skills work well in known, predictable and repeatable situations. Human environments, however, are better described as dynamic, chaotic, uncertain or unstructured. Therefore, plans relying on preprogrammed trajectories are bound to fail in these settings. In order to increase robustness to uncertainty and avoid coding new skills from scratch, we can make flexible plans that execute existing autonomous primitives based on the sensed state of the environment. A key challenge of this approach is finding the sequence of primitives required to perform the desired task. This work uses a variation of a Hidden Markov Model (HMM) with an augmented particle filter to find the primitive sequence using only a reduced number of human demonstrations. The algorithm was tested on 40 demonstrations of two different manipulation tasks involving six primitives. It was seeded with a single manually labelled demonstration of each task and was able to automatically label the other 38 demonstration sequences with an average success of 81.5%. The results show improved convergence and a 9% increase in accuracy over other versions of the algorithm.",
        "primary_area": "",
        "author": "Elena Galbally Herrero;Jonathan Ho;Oussama Khatib;Elena Galbally Herrero;Jonathan Ho;Oussama Khatib",
        "authorids": "/37086935096;/37089194665;/37283150000;/37086935096;/37089194665;/37283150000",
        "aff": "Department of Aeronautics & Astronautics, Stanford University; Department of Aeronautics & Astronautics, Stanford University; Department of Aeronautics & Astronautics, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636523/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13964560559049350166&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Aeronautics & Astronautics",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636258",
        "title": "Underwater Visual Acoustic SLAM with Extrinsic Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "Underwater scenarios are challenging for visual Simultaneous Localization and Mapping (SLAM) due to limited visibility and intermittently losing structures in image views. In this paper, we propose a visual acoustic bundle adjustment system which fuses a camera and a Doppler Velocity Log (DVL) in a graph SLAM framework for reliable underwater localization and mapping. In order to fuse the vision with the acoustic measurements, an calibration algorithm is also designed to estimate extrinsic parameters between a camera and a DVL using features detected in scenes. Experimental results in a tank and an offshore wind farm show the proposed method can achieve better robustness and localization accuracy than pure visual SLAM, especially in visually challenging scenarios, and the extrinsic calibration parameters can be accurately estimated, even when initialized with a random guess.",
        "primary_area": "",
        "author": "Shida Xu;Tomasz Luczynski;Jonatan Scharff Willners;Ziyang Hong;Kaicheng Zhang;Yvan R. Petillot;Sen Wang;Shida Xu;Tomasz Luczynski;Jonatan Scharff Willners;Ziyang Hong;Kaicheng Zhang;Yvan R. Petillot;Sen Wang",
        "authorids": "/37089197042;/37085646043;/37086222444;/37088217691;/37089195030;/37282015500;/37086278300;/37089197042;/37085646043;/37086222444;/37088217691;/37089195030;/37282015500;/37086278300",
        "aff": "School of Engineering and Physical Sciences, Heriot-Watt University, UK; School of Engineering and Physical Sciences, Heriot-Watt University, UK; School of Engineering and Physical Sciences, Heriot-Watt University, UK; School of Engineering and Physical Sciences, Heriot-Watt University, UK; School of Engineering and Physical Sciences, Heriot-Watt University, UK; School of Engineering and Physical Sciences, Heriot-Watt University, UK; School of Engineering and Physical Sciences, Heriot-Watt University, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636258/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16659786612728772493&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Heriot-Watt University",
        "aff_unique_dep": "School of Engineering and Physical Sciences",
        "aff_unique_url": "https://www.hw.ac.uk",
        "aff_unique_abbr": "HWU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636281",
        "title": "Unknown Object Segmentation from Stereo Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Although instance-aware perception is a key prerequisite for many autonomous robotic applications, most of the methods only partially solve the problem by focusing solely on known object categories. However, for robots interacting in dynamic and cluttered environments, this is not realistic and severely limits the range of potential applications. Therefore, we propose a novel object instance segmentation approach that does not require any semantic or geometric information of the objects beforehand. In contrast to existing works, we do not explicitly use depth data as input, but rely on the insight that slight viewpoint changes, which for example are provided by stereo image pairs, are often sufficient to determine object boundaries and thus to segment objects. Focusing on the versatility of stereo sensors, we employ a transformer-based architecture that maps directly from the pair of input images to the object instances. This has the major advantage that instead of a noisy, and potentially incomplete depth map as an input, on which the segmentation is computed, we use the original image pair to infer the object instances and a dense depth map. In experiments in several different application domains, we show that our Instance Stereo Transformer (INSTR) algorithm outperforms current state-of-the-art methods that are based on depth maps. Training code and pretrained models are available at https://github.com/DLR-RM/instr.",
        "primary_area": "",
        "author": "Maximilian Durner;Wout Boerdijk;Martin Sundermeyer;Werner Friedl;Zolt\u00e1n-Csaba M\u00e1rton;Rudolph Triebel;Maximilian Durner;Wout Boerdijk;Martin Sundermeyer;Werner Friedl;Zolt\u00e1n-Csaba M\u00e1rton;Rudolph Triebel",
        "authorids": "/37086116487;/37089000280;/37089406746;/37295467000;/37583288500;/37542908700;/37086116487;/37089000280;/37089406746;/37295467000;/37583288500;/37542908700",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Agile Robots AG, Munich, Germany; Department of Computer Science, Technical University of Munich (TUM), Garching, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636281/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9805471248521086294&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;2",
        "aff_unique_norm": "German Aerospace Center;Agile Robots AG;Technical University of Munich",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;;Department of Computer Science",
        "aff_unique_url": "https://www.dlr.de;https://www.agilerobots.com;https://www.tum.de",
        "aff_unique_abbr": "DLR;;TUM",
        "aff_campus_unique_index": "0;0;0;0;1;2",
        "aff_campus_unique": "Wessling;Munich;Garching",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636555",
        "title": "Unsupervised Deep Persistent Monocular Visual Odometry and Depth Estimation in Extreme Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, unsupervised deep learning approaches have received significant attention to estimating the depth and visual odometry (VO) from unlabelled monocular image sequences. However, their performance is limited in challenging environments due to perceptual degradation, occlusions, and rapid motions. Moreover, the existing unsupervised methods suffer from the lack of scale-consistency constraints across frames, which causes that the VO estimators fail to provide persistent trajectories over long sequences. In this study, we propose an unsupervised monocular deep VO framework that predicts a six-degrees-of-freedom pose camera motion and depth map of the scene from unlabelled RGB image sequences. We provide detailed quantitative and qualitative evaluations of the proposed framework on a) a challenging dataset collected during the DARPA Subterranean challenge 1; and b) the benchmark KITTI and Cityscapes datasets. The proposed approach significantly outperforms state-of-the-art unsupervised deep VO and depth prediction methods under perceptually degraded conditions providing better results for both pose estimation and depth recovery. Furthermore, it achieves state-of-the-art results in most of the VO and depth metrics on benchmark datasets. The presented approach is part of the solution used by the COSTAR team participating in the DARPA Subterranean Challenge.",
        "primary_area": "",
        "author": "Yasin Almalioglu;Angel Santamaria-Navarro;Benjamin Morrell;Ali-Akbar Agha-Mohammadi;Yasin Almalioglu;Angel Santamaria-Navarro;Benjamin Morrell;Ali-Akbar Agha-Mohammadi",
        "authorids": "/37086453755;/37077359600;/37086454259;/38274170800;/37086453755;/37077359600;/37086454259;/38274170800",
        "aff": "NASA - Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, US; NASA - Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, US; NASA - Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, US; NASA - Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, US",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636555/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17269158736640137971&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636570",
        "title": "Unsupervised Learning of Depth Estimation and Visual Odometry for Sparse Light Field Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "While an exciting diversity of new imaging devices is emerging that could dramatically improve robotic perception, the challenges of calibrating and interpreting these cameras have limited their uptake in the robotics community. In this work we generalise techniques from unsupervised learning to allow a robot to autonomously interpret new kinds of cameras. We consider emerging sparse light field (LF) cameras, which capture a subset of the 4D LF function describing the set of light rays passing through a plane. We introduce a generalised encoding of sparse LFs that allows unsupervised learning of odometry and depth. We demonstrate the proposed approach outperforming monocular, stereo and conventional techniques for dealing with 4D imagery, yielding more accurate odometry and depth maps and delivering these with metric scale. We anticipate our technique to generalise to a broad class of LF and sparse LF cameras, and to enable unsupervised recalibration for coping with shifts in camera behaviour over the lifetime of a robot. This work represents a first step toward streamlining the integration of new kinds of imaging devices in robotics applications.",
        "primary_area": "",
        "author": "S. Tejaswi Digumarti;Joseph Daniel;Ahalya Ravendran;Ryan Griffiths;Donald G. Dansereau;S. Tejaswi Digumarti;Joseph Daniel;Ahalya Ravendran;Ryan Griffiths;Donald G. Dansereau",
        "authorids": "/37085517244;/37089195709;/37085654540;/37085652497;/37270808500;/37085517244;/37089195709;/37085654540;/37085652497;/37270808500",
        "aff": "Sydney Institute for Robotics and Intelligent Systems, NSW, Australia; School of Aerospace, Mechanical and Mechatronic Engineering, The University of Sydney, NSW, Australia; Sydney Institute for Robotics and Intelligent Systems, NSW, Australia; Sydney Institute for Robotics and Intelligent Systems, NSW, Australia; Sydney Institute for Robotics and Intelligent Systems, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636570/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10506819710018174578&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Sydney",
        "aff_unique_dep": "Sydney Institute for Robotics and Intelligent Systems",
        "aff_unique_url": "https://www.sydney.edu.au",
        "aff_unique_abbr": "USYD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9636030",
        "title": "Unsupervised Monocular Depth Learning with Integrated Intrinsics and Spatio-Temporal Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular depth inference has gained tremendous attention from researchers in recent years and remains as a promising replacement for expensive time-of-flight sensors, but issues with scale acquisition and implementation overhead still plague these systems. To this end, this work presents an unsupervised learning framework that is able to predict at-scale depth maps and egomotion, in addition to camera intrinsics, from a sequence of monocular images via a single network. Our method incorporates both spatial and temporal geometric constraints to resolve depth and pose scale factors, which are enforced within the supervisory reconstruction loss functions at training time. Only unlabeled stereo sequences are required for training the weights of our single-network architecture, which reduces overall implementation overhead as compared to previous methods. Our results demonstrate strong performance when compared to the current state-of-the-art on multiple sequences of the KITTI driving dataset and can provide faster training times with its reduced network complexity.",
        "primary_area": "",
        "author": "Kenny Chen;Alexandra Pogue;Brett T. Lopez;Ali-Akbar Agha-Mohammadi;Ankur Mehta;Kenny Chen;Alexandra Pogue;Brett T. Lopez;Ali-Akbar Agha-Mohammadi;Ankur Mehta",
        "authorids": "/37088689284;/37085443001;/37085654767;/38274170800;/37086302574;/37088689284;/37085443001;/37085654767;/38274170800;/37086302574",
        "aff": "Department of Electrical and Computer Engineering, University of California Los Angeles, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California Los Angeles, Los Angeles, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; NASA Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA, USA; Department of Electrical and Computer Engineering, University of California Los Angeles, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636030/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7817073292887455365&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "University of California, Los Angeles;California Institute of Technology",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;NASA Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.ucla.edu;https://www.caltech.edu",
        "aff_unique_abbr": "UCLA;Caltech",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Los Angeles;Pasadena",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636818",
        "title": "Unsupervised Path Regression Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We demonstrate that challenging shortest path problems can be solved via direct spline regression from a neural network, trained in an unsupervised manner (i.e. without requiring ground truth optimal paths for training). To achieve this, we derive a geometry-dependent optimal cost function whose minima guarantees collision-free solutions. Our method beats state-of-the-art supervised learning baselines for shortest path planning, with a much more scalable training pipeline, and a significant speedup in inference time.",
        "primary_area": "",
        "author": "Michal P\u00e1ndy;Daniel Lenton;Ronald Clark;Michal P\u00e1ndy;Daniel Lenton;Ronald Clark",
        "authorids": "/37089194109;/37088459308;/37086184882;/37089194109;/37088459308;/37086184882",
        "aff": "Department of Computer Science and Technology, University of Cambridge; Department of Computing, Imperial College London; Department of Computing, Imperial College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636818/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1700134450298843853&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Cambridge;Imperial College London",
        "aff_unique_dep": "Department of Computer Science and Technology;Department of Computing",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.imperial.ac.uk",
        "aff_unique_abbr": "Cambridge;Imperial",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Cambridge;London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9636688",
        "title": "Unsupervised Temporal Segmentation Using Models That Discriminate Between Demonstrations and Unintentional Actions",
        "track": "main",
        "status": "Poster",
        "abstract": "Segmentation of a compound task with multiple subtasks is crucial for imitation learning. Conventional unsupervised segmentation methods focused on only reproducibility of demonstrations and did not use the property that goal-directed actions rarely occur without intention. In this paper, we propose a novel method to segment demonstrations into goal-directed actions by self-supervised learning. We use the discriminator between demonstrations and self-generated unintentional actions performed by the same body in behavioral cloning paradigm because goal-directed actions rarely occur without intention, and thus can be separated from unintentional actions. And we consider the states that cannot be reached by unintentional actions as subtask changepoints. We evaluated our method on manipulation tasks with multiple subtasks. The results indicate that our method can detect subtask changepoints more accurately than an existing unsupervised segmentation method.",
        "primary_area": "",
        "author": "Takayuki Komatsu;Yoshiyuki Ohmura;Yasuo Kuniyoshi;Takayuki Komatsu;Yoshiyuki Ohmura;Yasuo Kuniyoshi",
        "authorids": "/37089197390;/37581602900;/37299294900;/37089197390;/37581602900;/37299294900",
        "aff": "Laboratory for Intelligent Systems and Informatics Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Laboratory for Intelligent Systems and Informatics Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Laboratory for Intelligent Systems and Informatics Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636688/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9035680616734099143&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Graduate School of Information Science and Technology",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9636318",
        "title": "Unsupervised Traffic Scene Generation with Synthetic 3D Scene Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Image synthesis driven by computer graphics achieved recently a remarkable realism, yet synthetic image data generated this way reveals a significant domain gap with respect to real-world data. This is especially true in autonomous driving scenarios, which represent a critical aspect for over-coming utilizing synthetic data for training neural networks. We propose a method based on domain-invariant scene representation to directly synthesize traffic scene imagery without rendering. Specifically, we rely on synthetic scene graphs as our internal representation and introduce an unsupervised neural network architecture for realistic traffic scene synthesis. We enhance synthetic scene graphs with spatial information about the scene and demonstrate the effectiveness of our approach through scene manipulation.",
        "primary_area": "",
        "author": "Artem Savkin;Rachid Ellouze;Nassir Navab;Federico Tombari;Artem Savkin;Rachid Ellouze;Nassir Navab;Federico Tombari",
        "authorids": "/37086960994;/37089195161;/37282965500;/37593332100;/37086960994;/37089195161;/37282965500;/37593332100",
        "aff": "BMW AG, Munich, Germany; BMW AG, Munich, Germany; JHU, Baltimore, MD, United States; Google, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636318/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12284270731233562335&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "BMW AG;Johns Hopkins University;Google",
        "aff_unique_dep": ";;Google",
        "aff_unique_url": "https://www.bmw.com;https://www.jhu.edu;https://www.google.ch",
        "aff_unique_abbr": "BMW;JHU;Google",
        "aff_campus_unique_index": "0;0;1;2",
        "aff_campus_unique": "Munich;Baltimore;Zurich",
        "aff_country_unique_index": "0;0;1;2",
        "aff_country_unique": "Germany;United States;Switzerland"
    },
    {
        "id": "9636545",
        "title": "Unsupervised Vehicle Re-Identification via Self-supervised Metric Learning using Feature Dictionary",
        "track": "main",
        "status": "Poster",
        "abstract": "The key challenge of unsupervised vehicle re-identification (Re-ID) is learning discriminative features from unlabelled vehicle images. Numerous methods using domain adaptation have achieved outstanding performance, but those methods still need a labelled dataset as a source domain. This paper addresses an unsupervised vehicle Re-ID method, which no need any types of a labelled dataset, through a Self-supervised Metric Learning (SSML) based on a feature dictionary. Our method initially extracts features from vehicle images and stores them in a dictionary. Thereafter, based on the dictionary, the proposed method conducts dictionary-based positive label mining (DPLM) to search for positive labels. Pair-wise similarity, relative-rank consistency, and adjacent feature distribution similarity are jointly considered to find images that may belong to the same vehicle of a given probe image. The results of DPLM are applied to dictionary-based triplet loss (DTL) to improve the discriminativeness of learnt features and to refine the quality of the results of DPLM progressively. The iterative process with DPLM and DTL boosts the performance of unsupervised vehicle Re-ID. Experimental results demonstrate the effectiveness of the proposed method by producing promising vehicle Re-ID performance without a pre-labelled dataset. The source code for this paper is publicly available on https://github.com/andreYoo/VeRI_SSML_FD.git.",
        "primary_area": "",
        "author": "Jongmin Yu;Hyeontaek Oh;Jongmin Yu;Hyeontaek Oh",
        "authorids": "/37089731854;/38063839000;/37089731854;/38063839000",
        "aff": "Institute for IT Convergence, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Institute for IT Convergence, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636545/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14560263565803845592&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Institute for IT Convergence",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9635888",
        "title": "Up-to-Down Network: Fusing Multi-Scale Context for 3D Semantic Scene Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "An efficient 3D scene perception algorithm is a vital component for autonomous driving and robotics systems. In this paper, we focus on semantic scene completion, which is a task of jointly estimating the volumetric occupancy and semantic labels of objects. Since the real-world data is sparse and occluded, this is an extremely challenging task. We propose a novel framework, named Up-to-Down network (UDNet), to achieve the large-scale semantic scene completion with an encoder-decoder architecture for voxel grids. The novel up-to-down block can effectively aggregate multi-scale context information to improve labeling coherence, and the atrous spatial pyramid pooling module is leveraged to expand the receptive field while preserving detailed geometric information. Besides, the proposed multi-scale fusion mechanism efficiently aggregates global background information and improves the semantic completion accuracy. Moreover, to further satisfy the needs of different tasks, our UDNet can accomplish the multi-resolution semantic completion, achieving faster but coarser completion. Detailed experiments in the semantic scene completion benchmark of SemanticKITTI illustrate that our proposed framework surpasses the state-of-the-art methods with remarkable margins and a real-time inference speed by using only voxel grids as input.",
        "primary_area": "",
        "author": "Hao Zou;Xuemeng Yang;Tianxin Huang;Chujuan Zhang;Yong Liu;Wanlong Li;Feng Wen;Hongbo Zhang;Hao Zou;Xuemeng Yang;Tianxin Huang;Chujuan Zhang;Yong Liu;Wanlong Li;Feng Wen;Hongbo Zhang",
        "authorids": "/37088690615;/37088455828;/37089197863;/37088689834;/37066946100;/37088687641;/37088690190;/37859161500;/37088690615;/37088455828;/37089197863;/37088689834;/37066946100;/37088687641;/37088690190;/37859161500",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Huawei Noah\u2019s Ark lab.; Huawei Noah\u2019s Ark lab.; Huawei Noah\u2019s Ark lab.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635888/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5823430657912171507&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;1;1",
        "aff_unique_norm": "Zhejiang University;Huawei",
        "aff_unique_dep": "Institute of Cyber-Systems and Control;Noah\u2019s Ark lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.huawei.com",
        "aff_unique_abbr": "ZJU;Huawei",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hangzhou;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636264",
        "title": "User Controlled Interface for Tuning Robotic Knee Prosthesis",
        "track": "main",
        "status": "Poster",
        "abstract": "The tuning process for a robotic prosthesis is a challenging and time-consuming task both for users and clinicians. An automatic tuning approach using reinforcement learning (RL) has been developed for a knee prosthesis to address the challenges of manual tuning methods. The algorithm tunes the optimal control parameters based on the provided knee joint profile that the prosthesis is expected to replicate during gait safely. This paper presents an intuitive interface designed for the prosthesis users and clinicians to choose the preferred knee joint profile during gait and use the autotuner to replicate in the prosthesis. The interface-based approach is validated by observing the ability of the tuning algorithm to successfully converge to various alternate knee profiles by testing on two able-bodied subjects walking with a robotic knee prosthesis. The algorithm was found to converge successfully in an average duration of 1.15 min for the first subject and 2.31 min for the second subject. Further, the subjects displayed different preferences for optimal profiles reinforcing the need to tune alternate profiles. The implications of the results in the tuning of robotic prosthetic devices are discussed.",
        "primary_area": "",
        "author": "Abbas Alili;Varun Nalam;Minhan Li;Ming Liu;Jennie Si;He Helen Huang;Abbas Alili;Varun Nalam;Minhan Li;Ming Liu;Jennie Si;He Helen Huang",
        "authorids": "/37086054009;/37086046980;/37086936924;/38237723700;/37308391800;/37401091200;/37086054009;/37086046980;/37086936924;/38237723700;/37308391800;/37401091200",
        "aff": "Department of Electrical and Computer Engineering, NC State University, Raleigh, NC, USA; University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ, USA; University of North Carolina at Chapel Hill, Chapel Hill, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636264/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8455198799379455987&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;2;1",
        "aff_unique_norm": "NC State University;University of North Carolina at Chapel Hill;Arizona State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;;Department of Electrical, Computer, and Energy Engineering",
        "aff_unique_url": "https://www.ncsu.edu;https://www.unc.edu;https://www.asu.edu",
        "aff_unique_abbr": "NC State;UNC Chapel Hill;ASU",
        "aff_campus_unique_index": "0;1;1;1;2;1",
        "aff_campus_unique": "Raleigh;Chapel Hill;Tempe",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9635982",
        "title": "Using Bayesian Optimization to Identify Optimal Exoskeleton Parameters Targeting Propulsion Mechanics: A Simulation Study",
        "track": "main",
        "status": "Poster",
        "abstract": "The long-term goal of this research is to develop methods for training propulsion during walking using robotic exoskeletons that customize their intervention based on the response of an individual.In this study, we first determined the feasibility of modeling the relationship between propulsion mechanics and parameters of a robotic intervention applied at the hip and knee joints as a Gaussian process. Specifically, we used data obtained in a previous experiment that used pulses of torque applied at the hip and knee joint, at early and late stance, to establish the relationship between a 4D control parameter space and the resulting changes in hip extension and propulsive impulse at multiple strides following intervention. We estimated Gaussian models both at the group level and for each subject. Moreover, we used the estimated subject-specific models to simulate virtual human-in-the-loop optimization (HIL) experiments based on Bayesian optimization to establish the optimal settings of acquisition function and seed point selection methods.The estimated subject-specific optimal conditions have large between-subject variability in the kinetic component of propulsion mechanics (propulsive impulse), with only 31% of subjects featuring a subject-specific optimal point in the surroundings (within a sphere of radius 20% of each dimension\u2019s range) of the group-level optimal point. Instead, variability of the effects on the kinematic component of propulsion (leg extension) were smaller (75% of the subjects within the surroundings of the group-optimal point). Virtual HIL experiments indicate that expected improvement is the most effective acquisition method, while no significant effect of seed point selection method was observed. Our study suggests that individualized training may be necessary for inducing desired effects in propulsive force generation during walking.",
        "primary_area": "",
        "author": "GilHwan Kim;Fabrizio Sergi;GilHwan Kim;Fabrizio Sergi",
        "authorids": "/37089197818;/37546074300;/37089197818;/37546074300",
        "aff": "Department of Mechanical Engineering, University of Delaware, Newark, DE, USA; Department of Biomedical Engineering, University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635982/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15308400086748854319&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636077",
        "title": "Using Depth Vision for Terrain Detection during Active Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision-based systems for terrain detection are ubiquitous in mobile robotics, while such systems recently emerged for locomotion assistance of disabled people. For instance, wearable devices embedding vision sensors can assist people in navigation; or guide lower-limb prosthesis or exoskeleton controller to retrieve gait patterns being adapted to the executed task (overground walking, stairs, slopes, etc.). In this research, we present a vision-based algorithm achieving the detection of flat ground, steps, and ramps, using a depth camera. The raw point cloud data obtained from the depth camera passes through multiple processing steps to extract environmental features, and then achieves terrain detection by feeding these features into a classification tree. The camera was mounted on a custom-made wearable tool that can be placed on the chest of human users. This contribution reports a pilot validation study with 6 healthy subjects moving in an indoor environment containing a rich set of different types of terrains. Our method can predict the locomotion modes up to three steps in front of the user. Moreover, it is able to perform terrain detection even if the path is partially occluded by another walker. The method accuracy with a cleared path was found to be above 90% for all locomotion modes.",
        "primary_area": "",
        "author": "Ali H. A. Al-dabbagh;Renaud Ronsse;Ali H. A. Al-dabbagh;Renaud Ronsse",
        "authorids": "/37089196527;/37299789300;/37089196527;/37299789300",
        "aff": "Institute of Mechanics, Materials, and Civil Engineering; Institute of Neuroscience; and Louvain Bionics, Universit\u00e9 catholique de Louvain, Louvainla-Neuve, Belgium; Institute of Mechanics, Materials, and Civil Engineering; Institute of Neuroscience; and Louvain Bionics, Universit\u00e9 catholique de Louvain, Louvainla-Neuve, Belgium",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636077/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13000347585534310389&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1;2;0;1;2",
        "aff_unique_norm": "Institute of Mechanics, Materials, and Civil Engineering;Institute of Neuroscience;Universit\u00e9 catholique de Louvain",
        "aff_unique_dep": "Mechanics, Materials, and Civil Engineering;;Louvain Bionics",
        "aff_unique_url": ";;https://www.uclouvain.be",
        "aff_unique_abbr": ";;UCLouvain",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Louvainla-Neuve",
        "aff_country_unique_index": "1;1",
        "aff_country_unique": ";Belgium"
    },
    {
        "id": "9636236",
        "title": "Using Experience to Improve Constrained Planning on Foliations for Multi-Modal Problems",
        "track": "main",
        "status": "Poster",
        "abstract": "Many robotic manipulation problems are multi-modal\u2014they consist of a discrete set of mode families (e.g., whether an object is grasped or placed) each with a continuum of parameters (e.g., where exactly an object is grasped). Core to these problems is solving single-mode motion plans, i.e., given a mode from a mode family (e.g., a specific grasp), find a feasible motion to transition to the next desired mode. Many planners for such problems have been proposed, but complex manipulation plans may require prohibitively long computation times due to the difficulty of solving these underlying single-mode problems. It has been shown that using experience from similar planning queries can significantly improve the efficiency of motion planning. However, even though modes from the same family are similar, they impose different constraints on the planning problem, and thus experience gained in one mode cannot be directly applied to another. We present a new experience-based framework, ALEF, for such multi-modal planning problems. ALEF learns using paths from single-mode problems from a mode family, and applies this experience to novel modes from the same family. We evaluate ALEF on a variety of challenging problems and show a significant improvement in the efficiency of sampling-based planners both in isolation and within a multi-modal manipulation planner.",
        "primary_area": "",
        "author": "Zachary Kingston;Constantinos Chamzas;Lydia E. Kavraki;Zachary Kingston;Constantinos Chamzas;Lydia E. Kavraki",
        "authorids": "/37085542480;/37086933748;/37279015600;/37085542480;/37086933748;/37279015600",
        "aff": "Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636236/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6313022384643138411&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636133",
        "title": "Using Visual Anomaly Detection for Task Execution Monitoring",
        "track": "main",
        "status": "Poster",
        "abstract": "Execution monitoring is essential for robots to detect and respond to failures. Since it is impossible to enumerate all failures for a given task, we learn from successful executions of the task to detect visual anomalies during runtime. Our method learns to predict the motions that occur during the nominal execution of a task, including camera and robot body motion. A probabilistic U-Net architecture is used to learn to predict optical flow, and the robot\u2019s kinematics and 3D model are used to model camera and body motion. The errors between the observed and predicted motion are used to calculate an anomaly score. We evaluate our method on a dataset of a robot placing a book on a shelf, which includes anomalies such as falling books, camera occlusions, and robot disturbances. We find that modeling camera and body motion, in addition to the learning-based optical flow prediction, results in an improvement of the area under the receiver operating characteristic curve from 0.752 to 0.804, and the area under the precision-recall curve from 0.467 to 0.549.",
        "primary_area": "",
        "author": "Santosh Thoduka;Juergen Gall;Paul G. Pl\u00f6ger;Santosh Thoduka;Juergen Gall;Paul G. Pl\u00f6ger",
        "authorids": "/37086060004;/37393846400;/37344552000;/37086060004;/37393846400;/37344552000",
        "aff": "Computer Science Department, Hochschule Bonn-Rhein-Sieg, Sankt Augustin, Germany; Computer Vision Department, University of Bonn, Bonn, Germany; Computer Science Department, Hochschule Bonn-Rhein-Sieg, Sankt Augustin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636133/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17598627416021734433&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Hochschule Bonn-Rhein-Sieg;University of Bonn",
        "aff_unique_dep": "Computer Science Department;Computer Vision Department",
        "aff_unique_url": "https://www.h-brs.de;https://www.uni-bonn.de",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Sankt Augustin;Bonn",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636618",
        "title": "V-RVO: Decentralized Multi-Agent Collision Avoidance using Voronoi Diagrams and Reciprocal Velocity Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a decentralized collision avoidance method for dense environments based on buffered Voronoi cells (BVC) and reciprocal velocity obstacles (RVO). Our approach is designed for scenarios with a large number of agents in close proximity and provides passive-friendly collision avoidance guarantees. The Voronoi cells are superimposed with RVO cones to compute a suitable direction for each agent, and we use that direction to compute a local collision-free path. Our approach can also satisfy double-integrator dynamics, and we use the properties of the BVC to formulate a simple, decentralized deadlock resolution strategy. We demonstrate the benefits of V-RVO in complex scenarios with tens of agents in close proximity. In practice, V-RVO\u2019s performance is comparable to prior velocity-obstacle methods, and the collision avoidance behavior is significantly less conservative than ORCA.",
        "primary_area": "",
        "author": "Senthil Hariharan Arul;Dinesh Manocha;Senthil Hariharan Arul;Dinesh Manocha",
        "authorids": "/37086929465;/37267825600;/37086929465;/37267825600",
        "aff": "Department of Electrical and Computer Engineering, University of Maryland, College Park, MD, USA; Department of Computer Science, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636618/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9532499059598012196&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Maryland, College Park;University of Maryland",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.umd.edu;https://www/umd.edu",
        "aff_unique_abbr": "UMD;UMD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636283",
        "title": "VIPose: Real-time Visual-Inertial 6D Object Pose Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating the 6D pose of objects is beneficial for robotics tasks such as transportation, autonomous navigation, manipulation as well as in scenarios beyond robotics like virtual and augmented reality. With respect to single image pose estimation, pose tracking takes into account the temporal information across multiple frames to overcome possible detection inconsistencies and to improve the pose estimation efficiency. In this work, we introduce a novel Deep Neural Network (DNN) called VIPose, that combines inertial and camera data to address the object pose tracking problem in real-time. The key contribution is the design of a novel DNN architecture which fuses visual and inertial features to predict the objects\u2019 relative 6D pose between consecutive image frames. The overall 6D pose is then estimated by consecutively combining relative poses. Our approach shows remarkable pose estimation results for heavily occluded objects that are well known to be very challenging to handle by existing state-of-the-art solutions. The effectiveness of the proposed approach is validated on a new dataset called VIYCB with RGB image, IMU data, and accurate 6D pose annotations created by employing an automated labeling technique. The approach presents accuracy performances comparable to state-of-the-art techniques, but with the additional benefit of being real-time.",
        "primary_area": "",
        "author": "Rundong Ge;Giuseppe Loianno;Rundong Ge;Giuseppe Loianno",
        "authorids": "/37088600577;/37085496544;/37088600577;/37085496544",
        "aff": "Tandon School of Engineering, New York University, Brooklyn, NY, USA; Tandon School of Engineering, New York University, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636283/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12522624321738083092&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "Tandon School of Engineering",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Brooklyn",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636656",
        "title": "Variable Stiffness Folding Joints for Haptic Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Origami robots composed of rigid parts with flexible joints have inherent compliance that enables deployment and reconfiguration for various shape adaptations. The major drawback of such mechanical compliance is its intrinsic softness and lack of controllability of this stiffness. In this work, we propose a design of variable stiffness origami joints to be integrated into large scale origami systems with an inner controllable joint stiffness. This novel way of controlling compliance in origami structures demonstrates that the embedded variable stiffness joint in the prototype can provide rich haptic feedback to the user through its compact, collapsible interactive platform.",
        "primary_area": "",
        "author": "Fabio Zuliani;Jamie Paik;Fabio Zuliani;Jamie Paik",
        "authorids": "/37086298689;/37085372758;/37086298689;/37085372758",
        "aff": "Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland; Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636656/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10022643758980145052&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636762",
        "title": "Variable-Speed Traveling Salesman Problem for Vehicles with Curvature Constrained Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel approach to the multigoal trajectory planning for vehicles with curvature-constrained trajectories such as fixed-wing aircraft. In the existing formulation called the Dubins Traveling Salesman Problem (DTSP), the vehicle speed is assumed to be constant over the whole trajectory, and that does not allow adaptation of the turning radius of the trajectory between the target locations. It does not support optimization of the overall flight time of the multi-goal trajectory by exploiting higher speeds for longer turning radii. Therefore, we propose a novel problem formulation called the Variable-Speed Traveling Salesman Problem (VS-TSP) that employs time-efficient trajectories with variable speed based on a generalization of the Dubins vehicle model, allowing multiple turning radii and change of the forward speed of the vehicle. The VS-TSP allows the vehicle to slow down if high maneuverability is necessary and speed up if high-speed turns with a large radius are beneficial to the overall tour cost. Based on the evaluation results for Cessna 172 aircraft model, the proposed VNS-based algorithm with variable speed provides up to about 20 % faster trajectories than a solution of the DTSP with a single turning radius.",
        "primary_area": "",
        "author": "Krist\u00fdna Ku\u010derov\u00e1;Petr V\u00e1\u0148a;Jan Faigl;Krist\u00fdna Ku\u010derov\u00e1;Petr V\u00e1\u0148a;Jan Faigl",
        "authorids": "/37089197106;/37085751648;/37540566100;/37089197106;/37085751648;/37540566100",
        "aff": "Faculty of Electrical Engineering, Czech Technical University, Prague, Czech Republic; Faculty of Electrical Engineering, Czech Technical University, Prague, Czech Republic; Faculty of Electrical Engineering, Czech Technical University, Prague, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636762/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11232980774525084405&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Czech Technical University",
        "aff_unique_dep": "Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "9636499",
        "title": "Vehicle Dispatch in On-Demand Ride-Sharing with Stochastic Travel Times",
        "track": "main",
        "status": "Poster",
        "abstract": "On-demand ride-sharing is a promising way to improve mobility efficiency and reliability. The quality of passenger experience and the profit achieved by these platforms are strongly affected by the vehicle dispatch policy. However, existing ride-sharing research seldom considers travel time uncertainty, which leads to inaccurate dispatch allocations. This paper proposes a framework for dynamic vehicle dispatch that leverages stochastic travel time models to improve the performance of a fleet of shared vehicles. The novelty of this work includes: (1) a stochastic on-demand ride-sharing scheme to maximize the service rate (percentage of requests served) and reliability (probability of on-time arrival); (2) a technique based on approximate stochastic shortest path algorithms to compute the reliability for a ride-sharing trip; (3) a method to maximize the profit when a penalty for late arrivals is introduced. Based on New York City taxi data, it is shown that by considering travel time uncertainty, ride-sharing service achieves higher service rate, reliability and profit.",
        "primary_area": "",
        "author": "Cheng Li;David Parker;Qi Hao;Cheng Li;David Parker;Qi Hao",
        "authorids": "/37089000323;/37271264600;/37403530000;/37089000323;/37271264600;/37403530000",
        "aff": "Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; School of Computer Science, University of Birmingham, Birmingham, UK; Research Institute of Trustworthy Autonomous System, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636499/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11568851296945929058&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Southern University of Science and Technology;University of Birmingham",
        "aff_unique_dep": "Department of Computer Science and Engineering;School of Computer Science",
        "aff_unique_url": "https://www.sustech.edu.cn;https://www.birmingham.ac.uk",
        "aff_unique_abbr": "SUSTech;UoB",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Shenzhen;Birmingham",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9636537",
        "title": "Verifying Safe Transitions between Dynamic Motion Primitives on Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Functional autonomous systems often realize complex tasks by utilizing state machines comprised of discrete primitive behaviors and transitions between these behaviors. This architecture has been widely studied in the context of quasi-static and dynamics-independent systems. However, applications of this concept to dynamical systems are relatively sparse, despite extensive research on individual dynamic primitive behaviors, which we refer to as \"motion primitives.\" This paper formalizes a process to determine dynamic-state aware conditions for transitions between motion primitives in the context of safety. The result is framed as a \"motion primitive graph\" that can be traversed by standard graph search and planning algorithms to realize functional autonomy. To demonstrate this framework, dynamic motion primitives\u2014 including standing up, walking, and jumping\u2014and the transitions between these behaviors are experimentally realized on a quadrupedal robot.",
        "primary_area": "",
        "author": "Wyatt Ubellacker;Noel Csomay-Shanklin;Tamas G. Molnar;Aaron D. Ames;Wyatt Ubellacker;Noel Csomay-Shanklin;Tamas G. Molnar;Aaron D. Ames",
        "authorids": "/37077831700;/37086862522;/38152008100;/37300877900;/37077831700;/37086862522;/38152008100;/37300877900",
        "aff": "Department of Control and Dynamical Systems and the Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Control and Dynamical Systems and the Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Control and Dynamical Systems and the Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Control and Dynamical Systems and the Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636537/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3402193005210106390&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Control and Dynamical Systems",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636161",
        "title": "Vessel Classification Using A Regression Neural Network Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Marine vessels are subject to high wear and tear due to the conditions they operate in. To reduce risk of failure during operation, vessels are inspected periodically every five years. These inspections are prone to high subjectiveness that makes them hard to reproduce for the shipping owners. The purpose of this paper is to present a regressor to a Faster R-CNN network that can help alleviate some of the subjective assessment currently performed by human surveyors by estimating the severity of a corroded area, autonomously using drones. A feature pyramid backbone is shared between the Faster R-CNN and the added regression head. The goal of the regressor is to introduce a more objective assessment of the vessel that gives a consistent output for a consistent input. The system is evaluated on a real dataset, acquired in ballast tanks and the experimental results indicate that our deep learning approach can be used to detect and quantify corroded areas during the inspection process of marine vessels.",
        "primary_area": "",
        "author": "Rasmus Eckholdt Andersen;Lazaros Nalpantidis;Evangelos Boukas;Rasmus Eckholdt Andersen;Lazaros Nalpantidis;Evangelos Boukas",
        "authorids": "/37088602086;/37304022500;/38232071900;/37088602086;/37304022500;/38232071900",
        "aff": "Automation and Control, Department of Electrical Engineering, Technical University of Denmark, Kongens Lyngby, Denmark; Automation and Control, Department of Electrical Engineering, Technical University of Denmark, Kongens Lyngby, Denmark; Automation and Control, Department of Electrical Engineering, Technical University of Denmark, Kongens Lyngby, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636161/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13625889777526335205&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Denmark",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.tek.dk",
        "aff_unique_abbr": "DTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kongens Lyngby",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9635989",
        "title": "ViNet: Pushing the limits of Visual Modality for Audio-Visual Saliency Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose the ViNet architecture for audio-visual saliency prediction. ViNet is a fully convolutional encoder-decoder architecture. The encoder uses visual features from a network trained for action recognition, and the decoder infers a saliency map via trilinear interpolation and 3D convolutions, combining features from multiple hierarchies. The overall architecture of ViNet is conceptually simple; it is causal and runs in real-time (60 fps). ViNet does not use audio as input and still outperforms the state-of-the-art audio-visual saliency prediction models on nine different datasets (three visual-only and six audio-visual datasets). ViNet also surpasses human performance on the CC, SIM and AUC metrics for the AVE dataset, and to our knowledge, it is the first model to do so. We also explore a variation of ViNet architecture by augmenting audio features into the decoder. To our surprise, upon sufficient training, the network becomes agnostic to the input audio and provides the same output irrespective of the input. Interestingly, we also observe similar behaviour in the previous state-of-the-art models [1] for audio-visual saliency prediction. Our findings contrast with previous works on deep learning-based audio-visual saliency prediction, suggesting a clear avenue for future explorations incorporating audio in a more effective manner. The code and pre-trained models are available at https://github.com/samyak0210/ViNet.",
        "primary_area": "",
        "author": "Samyak Jain;Pradeep Yarlagadda;Shreyank Jyoti;Shyamgopal Karthik;Ramanathan Subramanian;Vineet Gandhi;Samyak Jain;Pradeep Yarlagadda;Shreyank Jyoti;Shyamgopal Karthik;Ramanathan Subramanian;Vineet Gandhi",
        "authorids": "/37088688004;/37088687853;/37086388731;/37089653652;/38489889400;/37075471000;/37088688004;/37088687853;/37086388731;/37089653652;/38489889400;/37075471000",
        "aff": "CVIT, KCIS, International Institute for Information Technology, Hyderabad; CVIT, KCIS, International Institute for Information Technology, Hyderabad; CVIT, KCIS, International Institute for Information Technology, Hyderabad; CVIT, KCIS, International Institute for Information Technology, Hyderabad; University of Canberra; CVIT, KCIS, International Institute for Information Technology, Hyderabad",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635989/",
        "gs_citation": 100,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14249912354424146452&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "International Institute for Information Technology;University of Canberra",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.iiit Hyderabad.ac.in;https://www.canberra.edu.au",
        "aff_unique_abbr": "IIIT Hyderabad;UC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hyderabad;",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "India;Australia"
    },
    {
        "id": "9636701",
        "title": "Viewpoint Planning for Fruit Size and Position Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern agricultural applications require knowledge about the position and size of fruits on plants. However, occlusions from leaves typically make obtaining this information difficult. We present a novel viewpoint planning approach that builds up an octree of plants with labeled regions of interest (ROIs), i.e., fruits. Our method uses this octree to sample viewpoint candidates that increase the information around the fruit regions and evaluates them using a heuristic utility function that takes into account the expected information gain. Our system automatically switches between ROI targeted sampling and exploration sampling, which considers general frontier voxels, depending on the estimated utility. When the plants have been sufficiently covered with the RGB-D sensor, our system clusters the ROI voxels and estimates the position and size of the detected fruits. We evaluated our approach in simulated scenarios and compared the resulting fruit estimations with the ground truth. The results demonstrate that our combined approach outperforms a sampling method that does not explicitly consider the ROIs to generate viewpoints in terms of the number of discovered ROI cells. Furthermore, we show the real-world applicability by testing our framework on a robotic arm equipped with an RGB-D camera installed on an automated pipe-rail trolley in a capsicum glasshouse.",
        "primary_area": "",
        "author": "Tobias Zaenker;Claus Smitt;Chris McCool;Maren Bennewitz;Tobias Zaenker;Claus Smitt;Chris McCool;Maren Bennewitz",
        "authorids": "/37088540533;/37088999928;/38274733400;/37324765000;/37088540533;/37088999928;/38274733400;/37324765000",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636701/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11539902026810558857&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9636753",
        "title": "Visibility-aware Trajectory Optimization with Application to Aerial Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "The visibility of targets determines performance and even success rate of various applications, such as active slam, exploration, and target tracking. Therefore, it is crucial to take the visibility of targets into explicit account in trajectory planning. In this paper, we propose a general metric for target visibility, considering observation distance and angle as well as occlusion effect. We formulate this metric into a differentiable visibility cost function, with which spatial trajectory and yaw can be jointly optimized. Furthermore, this visibility-aware trajectory optimization handles dynamic feasibility of position and yaw simultaneously. To validate that our method is practical and generic, we integrate it into a customized quadrotor tracking system. The experimental results show that our visibility-aware planner performs more robustly and observes targets better. In order to benefit related researches, we release our code to the public.",
        "primary_area": "",
        "author": "Qianhao Wang;Yuman Gao;Jialin Ji;Chao Xu;Fei Gao;Qianhao Wang;Yuman Gao;Jialin Ji;Chao Xu;Fei Gao",
        "authorids": "/37089197978;/37089194623;/37088999913;/37404060100;/37086045143;/37089197978;/37089194623;/37088999913;/37404060100;/37086045143",
        "aff": "Huzhou Institute of Zhejiang University, HuZhou, China; Huzhou Institute of Zhejiang University, HuZhou, China; Huzhou Institute of Zhejiang University, HuZhou, China; Huzhou Institute of Zhejiang University, HuZhou, China; Huzhou Institute of Zhejiang University, HuZhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636753/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=341915288712091&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Huzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636648",
        "title": "Vision-Based Control of an Unknown Suspended Payload with a Multirotor",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a vision-based control strategy for a rotary-wing unmanned aerial vehicle (RUAV) transporting an unknown suspended payload. The suspended payload parameters, which include its mass and cable length, are unknown and direct measurements of its states are not available. A feedforward-feedback adaptive control strategy, that consists of a notch filter and linear quadratic Gaussian (LQG) controller, is proposed to simultaneously avoid the excitation and actively damp the payload swing oscillations. The unknown payload mass is estimated using recursive least squares and the unknown cable length is estimated using a dedicated sine wave estimator. The payload parameter estimates are then used to adapt the control strategy for the specific suspended payload. A vision-based state estimator is implemented to provide payload state estimates for the optimal full-state feedback controller. Simulation results show that the control strategy successfully adapts for different suspended payloads and effectively damps the unwanted payload swing oscillations.",
        "primary_area": "",
        "author": "J. F. Slabber;H. W. Jordaan;J. F. Slabber;H. W. Jordaan",
        "authorids": "/37089195575;/37088344638;/37089195575;/37088344638",
        "aff": "Electrical and Electronic Engineering Department, Stellenbosch University, Stellenbosch, South Africa; Electrical and Electronic Engineering Department, Stellenbosch University, Stellenbosch, South Africa",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636648/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2315573005349669384&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stellenbosch University",
        "aff_unique_dep": "Electrical and Electronic Engineering Department",
        "aff_unique_url": "https://www.sun.ac.za",
        "aff_unique_abbr": "SU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stellenbosch",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Africa"
    },
    {
        "id": "9636466",
        "title": "Vision-encoder-based Payload State Estimation for Autonomous MAV With a Suspended Payload",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous delivery of suspended payloads with MAVs has many applications in rescue and logistics transportation. Robust and online estimation of the payload status is important but challenging especially in outdoor environments. The paper develops a novel real-time system for estimating the payload position; the system consists of a monocular fisheye camera and a novel encoder-based device. A Gaussian fusion-based estimation algorithm is developed to obtain the payload state estimation. Based on the robust payload position estimation, a payload controller is presented to ensure the re-liable tracking performance on aggressive trajectories. Several experiments are performed to validate the high performance of the proposed method.",
        "primary_area": "",
        "author": "Yunfan Ren;Jianheng Liu;Haoyao Chen;Yunhui Liu;Yunfan Ren;Jianheng Liu;Haoyao Chen;Yunhui Liu",
        "authorids": "/37087243712;/37089197631;/37600762500;/37279412600;/37087243712;/37089197631;/37600762500;/37279412600",
        "aff": "School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, P.R. China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, P.R. China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, P.R. China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636466/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=632912468931938208&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Harbin Institute of Technology;Chinese University of Hong Kong",
        "aff_unique_dep": "School of Mechanical Engineering and Automation;Department of Mechanical and Automation Engineering",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "HIT;CUHK",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Shenzhen;Hong Kong",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636054",
        "title": "Visual Identification of Articulated Object Parts",
        "track": "main",
        "status": "Poster",
        "abstract": "As autonomous robots interact and navigate around real-world environments such as homes, it is useful to reliably identify and manipulate articulated objects, such as doors and cabinets. Many prior works in object articulation identification require manipulation of the object, either by the robot or a human. While recent works have addressed predicting articulation types from visual observations alone, they often assume prior knowledge of category-level kinematic motion models or sequence of observations where the articulated parts are moving according to their kinematic constraints. In this work, we propose FormNet, a neural network that identifies the articulation mechanisms between pairs of object parts from a single frame of an RGB-D image and segmentation masks. The network is trained on 100k synthetic images of 149 articulated objects from 6 categories. Synthetic images are rendered via a photorealistic simulator with domain randomization. Our proposed model predicts motion residual flows of object parts, and these flows are used to determine the articulation type and parameters. The network achieves an articulation type classification accuracy of 82.5% on novel object instances in trained categories. Experiments also show how this method enables generalization to novel categories and can be applied to real-world images without fine-tuning.",
        "primary_area": "",
        "author": "Vicky Zeng;Tabitha Edith Lee;Jacky Liang;Oliver Kroemer;Vicky Zeng;Tabitha Edith Lee;Jacky Liang;Oliver Kroemer",
        "authorids": "/37089195693;/37089274027;/37088504798;/37593222300;/37089195693;/37089274027;/37088504798;/37593222300",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA; Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636054/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14004183488615082430&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636649",
        "title": "Visual Place Recognition using LiDAR Intensity Information",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots and autonomous systems need to know where they are within a map to navigate effectively. Thus, simultaneous localization and mapping or SLAM is a common building block of robot navigation systems. When building a map via a SLAM system, robots need to re-recognize places to find loop closure and reduce the odometry drift. Image-based place recognition received a lot of attention in computer vision, and in this work, we investigate how such approaches can be used for 3D LiDAR data. Recent LiDAR sensors produce high-resolution 3D scans in combination with comparably stable intensity measurements. Through a cylindrical projection, we can turn this information into a 360\u00b0 panoramic range image. As a result, we can apply techniques from visual place recognition to LiDAR intensity data. The question of how well this approach works in practice has only partially been investigated. This paper provides an analysis of how such visual techniques can be with LiDAR data, and we provide an evaluation on different datasets. Our results suggest that this form of place recognition is possible and an effective means for determining loop closures.",
        "primary_area": "",
        "author": "Luca Di Giammarino;Irvin Aloise;Cyrill Stachniss;Giorgio Grisetti;Luca Di Giammarino;Irvin Aloise;Cyrill Stachniss;Giorgio Grisetti",
        "authorids": "/37089196483;/37086847602;/37329668600;/37324134600;/37089196483;/37086847602;/37329668600;/37324134600",
        "aff": "Department of Computer, Control, and Management Engineering \"Antonio Ruberti\", Sapienza University of Rome, Italy; Department of Computer, Control, and Management Engineering \"Antonio Ruberti\", Sapienza University of Rome, Italy; University of Bonn, Germany; Department of Computer, Control, and Management Engineering \"Antonio Ruberti\", Sapienza University of Rome, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636649/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=231345084023846449&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Sapienza University of Rome;University of Bonn",
        "aff_unique_dep": "Department of Computer, Control, and Management Engineering \"Antonio Ruberti\";",
        "aff_unique_url": "https://www.uniroma1.it;https://www.uni-bonn.de",
        "aff_unique_abbr": "Sapienza;UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Italy;Germany"
    },
    {
        "id": "9636150",
        "title": "Visual-Tactile Fusion for 3D Objects Reconstruction from a Single Depth View and a Single Gripper Touch for Robotics Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "The planning of robotic manipulation and grasping tasks depends on the reconstruction of the 3D object\u2019s shape. Most of the existing 3D object reconstruction methods are based on visual sensing that are limited due to the lack of the object\u2019s occluded side information. The goal of this paper is to overcome these limitations and improve the 3D objects\u2019 reconstruction by adding the tactile sensing to the visual data. In this paper, a novel multi-modal (visual and tactile) semi-supervised generative model is presented to reconstruct the complete 3D object\u2019s shape using a single arbitrary depth-view and a single dexterous-hand\u2019s touch. The presented approach takes the strength of the autoencoder and generative networks to provide an end-to-end trainable model with high generalization ability. The 3D voxel grids of the depth and tactile data are the only requirements of the proposed model to predict a high resolution voxel grids of 643 for the incomplete shape. This research generates its tactile dataset based on the kinematic model of the shadow dexterous hand. The developed dataset has aligned depth, tactile and ground truth voxel grids of different resolutions (403, 643 and 1283) from different camera views. Experimental results show that the proposed multi-modal model outperforms other state-of-the-art methods.",
        "primary_area": "",
        "author": "Mohamed Tahoun;Omar Tahri;Juan Antonio Corrales Ram\u00f3n;Youcef Mezouar;Mohamed Tahoun;Omar Tahri;Juan Antonio Corrales Ram\u00f3n;Youcef Mezouar",
        "authorids": "/37087246272;/37281585400;/37086353284;/37299713100;/37087246272;/37281585400;/37086353284;/37299713100",
        "aff": "Universit\u00e9 Clermont Auvergne, CNRS, Clermont Auvergne INP, Institut Pascal, Clermont\u2013Ferrand, France; VIBOT EMR CNRS 6000, ImViA, Universit\u00e9 Bourgogne Franche-Comt\u00e9 (UBFC); Centro Singular de Investigaci\u00f3n en Tecnolox\u00edas Intelixentes (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain; Universit\u00e9 Clermont Auvergne, CNRS, Clermont Auvergne INP, Institut Pascal, Clermont\u2013Ferrand, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636150/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17510425903580190774&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Universit\u00e9 Clermont Auvergne;Universit\u00e9 Bourgogne Franche-Comt\u00e9;Universidade de Santiago de Compostela",
        "aff_unique_dep": ";ImViA;Centro Singular de Investigaci\u00f3n en Tecnolox\u00edas Intelixentes (CiTIUS)",
        "aff_unique_url": "https://www.uca.fr;https://www.ubfc.fr;https://www.usc.es",
        "aff_unique_abbr": "UCA;UBFC;USC",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Clermont\u2013Ferrand;;Santiago de Compostela",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "France;Spain"
    },
    {
        "id": "9636725",
        "title": "VoluMon: Weakly-Supervised Volumetric Monocular Estimation with Ellipsoid Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning approaches to estimating 3D object pose and geometry present an attractive alternative to online estimation techniques, which can suffer from significant estimation latency. However, a practical hurdle to training state-of-the-art deep 3D bounding box estimators is collecting a sufficiently large dataset of 3D bounding box labels. In this work, we present a novel framework for weakly supervised volumetric monocular estimation (VoluMon) that requires annotations in the image space only, i.e., associated object bounding box detections and instance segmentation. By approximating object geometry as ellipsoids, we can exploit the dual form of the ellipsoid to optimize with respect to bounding box annotations and the primal form of the ellipsoid to optimize with respect to a segmented pointcloud. For a simulated dataset with access to ground-truth, we show monocular object estimation performance similar to a naive online depth based estimation approach and after online refinement when depth images are available, we also approach the performance of a learned deep 6D pose estimator, which is supervised with projected 3D bounding box keypoints and assumes known model dimensions. Finally, we show promising qualitative results generated from a real-world dataset collected using a stereo pair.",
        "primary_area": "",
        "author": "Katherine Liu;Kyel Ok;Nicholas Roy;Katherine Liu;Kyel Ok;Nicholas Roy",
        "authorids": "/37086454373;/38469784900;/37274058700;/37086454373;/38469784900;/37274058700",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology in Cambridge, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology in Cambridge, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology in Cambridge, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636725/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17819758065093416600&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636739",
        "title": "Vulnerability of Connected Autonomous Vehicles Networks to Periodic Time-Varying Communication Delays of Certain Frequency",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider periodic communication delays within the connected autonomous vehicles platoon. Periodic signals are fundamentally simple to create, and in this study we analyze whether certain amplitude or frequencies can cause instability. This is important as we discover in this study, the classical method of replacing time-varying delays with constant delays does not capture the complex stability boundary of periodic time delays which could be exploited by attackers to cause instability in the vehicle platoon. We use the semi-discretization method to obtain plant stability. Then, we take the average value of the time delay functions to characterize the maximal admissible delay region such that the time-delayed system remains stable and provide string stability analysis. Through numerical simulations, we verify the analytical results. We construct stability charts in different parameter spaces to explore the effects of the model parameters on the system stability. A specific range of frequencies was found that could destabilize the connected autonomous vehicle platoon.",
        "primary_area": "",
        "author": "Isam Al-Darabsah;Kuei-Fang Hsueh;Mohammad Al Janaideh;Sue Ann Campbell;Deepa Kundur;Isam Al-Darabsah;Kuei-Fang Hsueh;Mohammad Al Janaideh;Sue Ann Campbell;Deepa Kundur",
        "authorids": "/37086064930;/37089197342;/37542671600;/37087979155;/37269460100;/37086064930;/37089197342;/37542671600;/37087979155;/37269460100",
        "aff": "Department of Applied Mathematics, University of Waterloo, Waterloo, Canada; Edward S. Rogers Sr. Department of Electrical & Computer Engineering, University of Toronto, Toronto, Canada; Department of Mechanical Engineering, Memorial University, St. John\u2019s, NL, Canada; Department of Applied Mathematics, University of Waterloo, Waterloo, Canada; Edward S. Rogers Sr. Department of Electrical & Computer Engineering, University of Toronto, Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636739/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18365909058390181572&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;1",
        "aff_unique_norm": "University of Waterloo;University of Toronto;Memorial University",
        "aff_unique_dep": "Department of Applied Mathematics;Edward S. Rogers Sr. Department of Electrical & Computer Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://uwaterloo.ca;https://www.utoronto.ca;https://www.mun.ca",
        "aff_unique_abbr": "UW;U of T;MUN",
        "aff_campus_unique_index": "0;1;2;0;1",
        "aff_campus_unique": "Waterloo;Toronto;St. John\u2019s",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9636357",
        "title": "Wasserstein-Splitting Gaussian Process Regression for Heterogeneous Online Bayesian Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "Gaussian processes (GPs) are a well-known nonparametric Bayesian inference technique, but they suffer from scalability problems for large sample sizes, and their performance can degrade for non-stationary or spatially heterogeneous data. In this work, we seek to overcome these issues through (i) employing variational free energy approximations of GPs operating in tandem with online expectation propagation steps; and (ii) introducing a local splitting step which instantiates a new GP whenever the posterior distribution changes significantly as quantified by the Wasserstein metric over posterior distributions. Over time, then, this yields an ensemble of sparse GPs which may be updated incrementally, and adapts to locality, heterogeneity, and non-stationarity in training data. We provide a 1-dimensional example to illustrate the motivation behind our approach, and compare the performance of our approach to other Gaussian process methods across various data sets, which often achieves competitive, if not superior predictive performance, relative to other locality-based GP regression methods in which hyperparameters are learned in an online manner.",
        "primary_area": "",
        "author": "Michael E. Kepler;Alec Koppel;Amrit Singh Bedi;Daniel J. Stilwell;Michael E. Kepler;Alec Koppel;Amrit Singh Bedi;Daniel J. Stilwell",
        "authorids": "/37086590146;/37085457697;/37088665735;/37283170000;/37086590146;/37085457697;/37088665735;/37283170000",
        "aff": "Bradley Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; Computational and Information Sciences Directorate, U.S. Army Research Laboratory, Adelphi, MD, USA; Computational and Information Sciences Directorate, U.S. Army Research Laboratory, Adelphi, MD, USA; Bradley Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636357/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18046316241350795630&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Virginia Polytechnic Institute and State University;U.S. Army Research Laboratory",
        "aff_unique_dep": "Bradley Department of Electrical and Computer Engineering;Computational and Information Sciences Directorate",
        "aff_unique_url": "https://www.vt.edu;https://www.arl.army.mil",
        "aff_unique_abbr": "VT;ARL",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Blacksburg;Adelphi",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636182",
        "title": "Water Surface Stability Prediction of Amphibious Bio-Inspired Undulatory Fin Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "To solve the interference problems of wind and wave action and load movement when switching under water surface conditions in the marine environment, a study on the water surface stability prediction of the bio-inspired undulatory fin robot is carried out. Based on the fin motion equation and fluid drag theory, a water surface stability calculation model of the robot is established. The study compares the effects of different loads and heel angles on the stability of the robot's water surface under different calculation methods and verifies the validity of the model through computational fluid dynamics methods. The simulation results show that the water surface stability of the robot exhibits sinusoidal-like changes over time, which is equal to the undulatory fin period. The stability decreases with the increase of the drainage volume. When the drainage volume is constant, the stability first increases and then decreases with the increase in heel angle. The theoretical calculation results are consistent with the numerical results, which verify the effectiveness of the water surface stability prediction model proposed in this paper. It can provide a theoretical basis for the optimization design of water surface stability of the undulatory fin robot.",
        "primary_area": "",
        "author": "Zhenhan Chen;Qiao Hu;Yingliang Chen;Chang Wei;Shenglin Yin;Zhenhan Chen;Qiao Hu;Yingliang Chen;Chang Wei;Shenglin Yin",
        "authorids": "/37088953898;/37551334000;/37089197035;/37088953465;/37088954245;/37088953898;/37551334000;/37089197035;/37088953465;/37088954245",
        "aff": "Shaanxi Key Laboratory of Intelligent Robots, Xi\u2019an Jiaotong University, Xi'an, P.R. China; Shaanxi Key Laboratory of Intelligent Robots, Xi\u2019an Jiaotong University, Xi'an, P.R. China; Kunming Precision Machinery Research Institute, Kunming, P.R. China; Shaanxi Key Laboratory of Intelligent Robots, Xi\u2019an Jiaotong University, Xi'an, P.R. China; Shaanxi Key Laboratory of Intelligent Robots, Xi\u2019an Jiaotong University, Xi'an, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636182/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=60229096875722415&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Xi'an Jiao Tong University;Kunming Precision Machinery Research Institute",
        "aff_unique_dep": "Shaanxi Key Laboratory of Intelligent Robots;",
        "aff_unique_url": "http://www.xjtu.edu.cn;",
        "aff_unique_abbr": "XJTU;",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Xi'an;Kunming",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636194",
        "title": "Wearable Tactile Sensor Suit for Natural Body Dynamics Extraction: Case Study on Posture Prediction Based on Physical Reservoir Computing",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a wearable tactile sensor suit, which can be regarded as tactile sensor networks, for monitoring natural body dynamics to be exploited as a computational resource for estimating the posture of a human or robot that wears it. We emulated the periodic motions of a wearer (a human and an android robot) using a novel sensor suit with a 9-channel fabric tactile sensor on the left arm. The emulation was conducted by using a linear regression (LR) model of sensor states as readout modules that predict the next wearer's movement using the current sensor data. Our result shows that the LR performance is comparable with other recurrent neural network approaches, suggesting that a fabric tactile sensor network can monitor the natural body motions, and further, this natural body dynamics itself can be used as an effective computational resource.",
        "primary_area": "",
        "author": "Hidenobu Sumioka;Kohei Nakajima;Kurima Sakai;Takashi Minato;Masahiro Shiomi;Hidenobu Sumioka;Kohei Nakajima;Kurima Sakai;Takashi Minato;Masahiro Shiomi",
        "authorids": "/37397310900;/38238899500;/37076169800;/37302023700;/37296827100;/37397310900;/38238899500;/37076169800;/37302023700;/37296827100",
        "aff": "Advanced Telecommunications Research Institute International, Kyoto, Japan; Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Advanced Telecommunications Research Institute International, Kyoto, Japan; RIKEN Guardian Robot Project, Kyoto, Japan; Advanced Telecommunications Research Institute International, Kyoto, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636194/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4620236528834213450&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "Advanced Telecommunications Research Institute International;University of Tokyo;RIKEN",
        "aff_unique_dep": ";Graduate School of Information Science and Technology;Guardian Robot Project",
        "aff_unique_url": "https://www.atr.jp;https://www.u-tokyo.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "ATR;UTokyo;RIKEN",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Kyoto;Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9635999",
        "title": "What Information Should a Robot Convey?",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic technologies are becoming pervasive within industrial and domestic settings, resulting in more frequent interactions between humans and robots. To ensure these interactions are effective, Human-Robot Interaction (HRI) researchers have argued that robots and humans must establish a shared common ground by communicating fundamental pieces of information to each other, such as their intentions, goals, plans, status, etc. Although a large body of work has explored how robots might signal individual aspects of such information to users, we still know relatively little regarding the importance of such information overall (e.g., is communicating robot status more important than communicating robot goals?). Such information is necessary for robots acting in the wild to create prioritized lists of communicative goals as, at any given time, it is unlikely that a robot will be able to convey all possibly relevant or important aspects of information to users. Prioritizing information for users is a complex problem as many factors might influence information priority, including task context, user expertise, and robot capability. In this work, we first address the current state-of-the-art signaling methods for non-humanoid robots. Second, we take an initial step towards understanding prioritization by exploring what types of information users request, and how the rankings of informational importance that users assign change, in a prototypical shared-environment interaction with three different types of robots. Our results, collected from 150 participants on Amazon\u2019s Mechanical Turk, generally show that users value information related to the robot\u2019s battery, capabilities, task, safety, navigation, communication, and privacy, with user priorities of these items varying across a small ground robot, a large ground robot, and an aerial robot.",
        "primary_area": "",
        "author": "Hooman Hedayati;Mark D. Gross;Daniel Szafir;Hooman Hedayati;Mark D. Gross;Daniel Szafir",
        "authorids": "/37086804419;/37289829600;/37086231248;/37086804419;/37289829600;/37086231248",
        "aff": "Department of Computer Science, University of Colorado Boulder; Department of Computer Science and ATLAS Institute, University of Colorado Boulder; Department of Computer Science, University of North Carolina\u2014Chapel Hill",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9635999/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13182014952889168755&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Colorado Boulder;University of North Carolina\u2014Chapel Hill",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu;https://www.unc.edu",
        "aff_unique_abbr": "CU Boulder;UNC Chapel Hill",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Boulder;Chapel Hill",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636424",
        "title": "What\u2019s Best for My Mesh? Convex or Non-Convex Regularisation for Mesh Optimisation",
        "track": "main",
        "status": "Poster",
        "abstract": "A 3D mesh offers a rich yet lightweight representation of geometry and topology for the metric and semantic understanding of a robot\u2019s scene. Noisy features are often used to generate the mesh which furthers the need for accurate regularisation. Current approaches tightly couple front-end optimisation with regularisation making it difficult to evaluate the choice of discretisation and regularisation on mesh accuracy. In this work, we aim to explicitly query the performance of a set of well-known convex and non-convex regularisers on the mesh optimisation problem. We then apply these norms to dense depth estimation from a mesh representation and evaluate their performance in indoor and outdoor environments.While we show that the use of exotic, non-convex regularisers such as logTV and logTGV can result in more faithful structural reconstruction under noise, this comes at the cost of stronger outlier persistence that limits their performance when compared to their convex equivalents. This represents a significant departure from results achieved when the same regularisers are applied in denser \"every-pixel\" scenarios and suggests that current discretisation techniques adopted for this problem are more sensitive to triangulation. This sensitivity is often obscured in many practical robotic applications by a rigorous front-end that removes artefacts from the mesh to be optimised. By decoupling the front and back-ends we therefore show that further consideration must be taken to align current mesh discretisations with the classical definitions of variational regularisers to allow the full benefit of their well-documented properties to be realised.",
        "primary_area": "",
        "author": "Jason Pilbrough;Paul Amayo;Jason Pilbrough;Paul Amayo",
        "authorids": "/37089194207;/37085789648;/37089194207;/37085789648",
        "aff": "Dept. Electrical Engineering, African Robotics Unit, University of Cape Town, South Africa; Dept. Electrical Engineering, African Robotics Unit, University of Cape Town, South Africa",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636424/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10929447783369248039&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Cape Town",
        "aff_unique_dep": "Dept. Electrical Engineering, African Robotics Unit",
        "aff_unique_url": "https://www.uct.ac.za",
        "aff_unique_abbr": "UCT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Africa"
    },
    {
        "id": "9636348",
        "title": "What\u2019s in My LiDAR Odometry Toolbox?",
        "track": "main",
        "status": "Poster",
        "abstract": "With the democratization of 3D LiDAR sensors, precise LiDAR odometries and SLAM are in high demand. New methods regularly appear, proposing solutions ranging from small variations in classical algorithms to radically new paradigms based on deep learning. Yet it is often difficult to compare these methods, notably due to the few datasets on which the methods can be evaluated and compared. Furthermore, their weaknesses are rarely examined, often letting the user discover the hard way whether a method would be appropriate for a use case.In this paper, we review and organize the main 3D LiDAR odometries into distinct categories. We implemented several approaches (geometric based, deep learning based, and hybrid methods) to conduct an in-depth analysis of their strengths and weaknesses on multiple datasets, guiding the reader through the different LiDAR odometries available. Implementation of the methods has been made publicly available at: https://github.com/Kitware/pyLiDAR-SLAM.",
        "primary_area": "",
        "author": "Pierre Dellenbach;Jean-Emmanuel Deschaud;Bastien Jacquet;Fran\u00e7ois Goulette;Pierre Dellenbach;Jean-Emmanuel Deschaud;Bastien Jacquet;Fran\u00e7ois Goulette",
        "authorids": "/37089197985;/38519215400;/37076103600;/37402879500;/37089197985;/38519215400;/37076103600;/37402879500",
        "aff": "Computer Vision Team, Kitware, Villeurbanne, France; Centre for Robotics, MINES ParisTech, PSL University, Paris, France; Computer Vision Team, Kitware, Villeurbanne, France; Centre for Robotics, MINES ParisTech, PSL University, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636348/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2312927893276894288&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Kitware;MINES ParisTech",
        "aff_unique_dep": "Computer Vision Team;Centre for Robotics",
        "aff_unique_url": "https://www.kitware.com;https://www.minesparistech.fr",
        "aff_unique_abbr": ";MINES ParisTech",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Villeurbanne;Paris",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9636371",
        "title": "Whole-Body MPC and Online Gait Sequence Generation for Wheeled-Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Our paper proposes a model predictive controller as a single-task formulation that simultaneously optimizes wheel and torso motions. This online joint velocity and ground reaction force optimization integrates a kinodynamic model of a wheeled quadrupedal robot. It defines the single rigid body dynamics along with the robot\u2019s kinematics while treating the wheels as moving ground contacts. With this approach, we can accurately capture the robot\u2019s rolling constraint and dynamics, enabling automatic discovery of hybrid maneuvers without needless motion heuristics. The formulation\u2019s generality through the simultaneous optimization over the robot\u2019s whole-body variables allows for a single set of parameters and makes online gait sequence adaptation possible. Aperiodic gait sequences are automatically found through kinematic leg utilities without the need for predefined contact and lift-off timings, reducing the cost of transport by up to 85 %. Our experiments demonstrate dynamic motions on a quadrupedal robot with non-steerable wheels in challenging indoor and outdoor environments. The paper\u2019s findings contribute to evaluating a decomposed, i.e., sequential optimization of wheel and torso motion, and single-task motion planner with a novel quantity, the prediction error, which describes how well a receding horizon planner can predict the robot\u2019s future state. To this end, we report an improvement of up to 71 % using our proposed single-task approach, making fast locomotion feasible and revealing wheeled-legged robots\u2019 full potential.",
        "primary_area": "",
        "author": "Marko Bjelonic;Ruben Grandia;Oliver Harley;Cla Galliard;Samuel Zimmermann;Marco Hutter;Marko Bjelonic;Ruben Grandia;Oliver Harley;Cla Galliard;Samuel Zimmermann;Marco Hutter",
        "authorids": "/37085993346;/37086355336;/37089195295;/37089196494;/37086117772;/37545251000;/37085993346;/37086355336;/37089195295;/37089196494;/37086117772;/37545251000",
        "aff": "ETH Z\u00fcrich, Robotic Systems Lab, Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Robotic Systems Lab, Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Robotic Systems Lab, Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Robotic Systems Lab, Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Robotic Systems Lab, Z\u00fcrich, Switzerland; ETH Z\u00fcrich, Robotic Systems Lab, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636371/",
        "gs_citation": 112,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1380176375075482332&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9636315",
        "title": "Why fly blind? Event-based visual guidance for ornithopter robot flight",
        "track": "main",
        "status": "Poster",
        "abstract": "The development of perception and control methods that allow bird-scale flapping-wing robots (a.k.a. ornithopters) to perform autonomously is an under-researched area. This paper presents a fully onboard event-based method for ornithopter robot visual guidance. The method uses event cameras to exploit their fast response and robustness against motion blur in order to feed the ornithopter control loop at high rates (100 Hz). The proposed scheme visually guides the robot using line features extracted in the event image plane and controls the flight by actuating over the horizontal and vertical tail deflections. It has been validated on board a real ornithopter robot with real-time computation in low-cost hardware. The experimental evaluation includes sets of experiments with different maneuvers indoors and outdoors.",
        "primary_area": "",
        "author": "A. G\u00f3mez Egu\u00edluz;J.P. Rodr\u00edguez-G\u00f3mez;R. Tapia;F.J. Maldonado;J.\u00c1. Acosta;J.R. Mart\u00ednez-de Dios;A. Ollero;A. G\u00f3mez Egu\u00edluz;J.P. Rodr\u00edguez-G\u00f3mez;R. Tapia;F.J. Maldonado;J.\u00c1. Acosta;J.R. Mart\u00ednez-de Dios;A. Ollero",
        "authorids": "/37085472327;/37087994966;/37088598615;/37088688490;/37399220800;/38303554600;/37265412000;/37085472327;/37087994966;/37088598615;/37088688490;/37399220800;/38303554600;/37265412000",
        "aff": "GRVC Robotics Lab Sevilla, Universidad de Sevilla, Seville, Spain; GRVC Robotics Lab Sevilla, Universidad de Sevilla, Seville, Spain; GRVC Robotics Lab Sevilla, Universidad de Sevilla, Seville, Spain; GRVC Robotics Lab Sevilla, Universidad de Sevilla, Seville, Spain; GRVC Robotics Lab Sevilla, Universidad de Sevilla, Seville, Spain; GRVC Robotics Lab Sevilla, Universidad de Sevilla, Seville, Spain; GRVC Robotics Lab Sevilla, Universidad de Sevilla, Seville, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636315/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5854098422693099747&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Universidad de Sevilla",
        "aff_unique_dep": "GRVC Robotics Lab",
        "aff_unique_url": "https://www.us.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Seville",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9636735",
        "title": "Wing Fold and Twist Greatly Improves Flight Efficiency for Bat-Scale Flapping Wing Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Inspired by bat flight performance, we explore the advantages of wing twist and fold for flapping wing robots. For this purpose, we develop a dynamical model that incorporates these two degrees of freedom to the wing. The twist is assumed to be linearly-increasing along the wing, while the wing fold is modeled as a relative rotation of the handwing with respect to the armwing. An optimization scheme parameterizes the wing kinematics for 2, 5 and 8 m/s forward flight velocities. The intricate interplay between wing orientation, effective angle of attack and the ensuing lift and thrust generation are discussed. The results show that wing twist and fold alleviate negative lift and thrust in the upstroke, and in some cases producing persistent positive thrust throughout cycle for handwing. As a result, power consumption drops precipitously compared to the base case of a rigid flat plate. Another crucial realization is the relative importance of wing twist and fold in achieving efficient flight strongly depends on speeds. At slow flight, twist is significantly more effective in minimizing the power, but becomes energetically inefficient for fast speeds. The results also show that a 45\u00b0 wing fold during upstroke is energetically beneficial for all speeds. The synergy of wing twist and fold are most prominent at slow flight. These findings provides useful guidelines for designing flapping wing robots.",
        "primary_area": "",
        "author": "Xiaozhou Fan;Kenneth Breuer;Hamid Vejdani;Xiaozhou Fan;Kenneth Breuer;Hamid Vejdani",
        "authorids": "/37089196891;/37282604600;/37077203200;/37089196891;/37282604600;/37077203200",
        "aff": "School of Engineering, Center for Fluid Mechanics, Brown University, Providence, RI, USA; School of Engineering, Center for Fluid Mechanics, Brown University, Providence, RI, USA; Mechanical, Robotics, and Industrial Engineering Department, Lawrence Technological University, Southfield, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636735/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3295910444200223968&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Brown University;Lawrence Technological University",
        "aff_unique_dep": "School of Engineering, Center for Fluid Mechanics;Mechanical, Robotics, and Industrial Engineering Department",
        "aff_unique_url": "https://www.brown.edu;https://www.ltu.edu",
        "aff_unique_abbr": "Brown;LTU",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Providence;Southfield",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636759",
        "title": "XAI-N: Sensor-based Robot Navigation using Expert Policies and Decision Trees",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel sensor-based learning navigation algorithm to compute a collision-free trajectory for a robot in dense and dynamic environments with moving obstacles or targets. Our approach uses deep reinforcement learning-based expert policy that is trained using a sim2real paradigm. In order to increase the reliability and handle the failure cases of the expert policy, we combine with a policy extraction technique to transform the resulting policy into a decision tree format. We use properties of decision trees to analyze and modify the policy and improve performance of navigation algorithm including smoothness, frequency of oscillation, frequency of immobilization, and obstruction of target. Overall, we are able to modify the policy to design an improved learning algorithm without retraining. We highlight the benefits of our approach in simulated environments and navigating a Clearpath Jackal robot among moving pedestrians. (Videos at this url: https://gamma.umd.edu/researchdirections/xrl/navviper)",
        "primary_area": "",
        "author": "Aaron M. Roth;Jing Liang;Dinesh Manocha;Aaron M. Roth;Jing Liang;Dinesh Manocha",
        "authorids": "/37087235704;/37088504802;/37267825600;/37087235704;/37088504802;/37267825600",
        "aff": "Department of Computer Science, University of Maryland, College Park, Maryland, USA; Department of Computer Science, University of Maryland, College Park, Maryland, USA; Department of Computer Science, University of Maryland, College Park, Maryland, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636759/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7615666855948513869&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Maryland, College Park",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636858",
        "title": "You Only Group Once: Efficient Point-Cloud Processing with Token Representation and Relation Inference Module",
        "track": "main",
        "status": "Poster",
        "abstract": "3D perception on point-cloud is a challenging and crucial computer vision task. A point-cloud consists of a sparse, unstructured, and unordered set of points. To understand a point-cloud, previous point-based methods, such as PointNet++, extract visual features through the hierarchical aggregation of local features. However, such methods have several critical limitations: 1) They require considerable sampling and grouping operations, which leads to low inference speed. 2) Despite redundancy among adjacent points, they treat all points alike with an equal amount of computation. 3) They aggregate local features together through downsampling, which causes information loss and hurts perception capability. To overcome these challenges, we propose a novel, simple, and elegant deep learning model called YOGO (You Only Group Once). YOGO divides a point-cloud into a small number of parts and extracts a high-dimensional token to represent points within each sub-region. Next, we use self-attention to capture token-to-token relations, and project the token features back to the point features. We formulate such a series of operations as a relation inference module (RIM). Compared with previous methods, YOGO is very efficient because it only needs to sample and group a point-cloud once. Instead of operating on points, YOGO operates on a small number of tokens, each of which summarizes the point features in a sub-region. This allows us to avoid redundant computation and thus boosts efficiency. Moreover, YOGO preserves pointwise features by projecting token features to point features although the RIM computes on tokens. This avoids information loss and enhances point-wise perception capability. We conduct thorough experiments to demonstrate that YOGO achieves at least 3.0x speedup over point-based baselines while delivering competitive classification and segmentation performance on a classification dataset and a segmentation dataset based on 3D Wharehouse, and S3DIS datasets. The c... Show More",
        "primary_area": "",
        "author": "Chenfeng Xu;Bohan Zhai;Bichen Wu;Tian Li;Wei Zhan;Peter Vajda;Kurt Keutzer;Masayoshi Tomizuka;Chenfeng Xu;Bohan Zhai;Bichen Wu;Tian Li;Wei Zhan;Peter Vajda;Kurt Keutzer;Masayoshi Tomizuka",
        "authorids": "/37089197139;/37089194014;/37086085163;/37089196237;/37067099600;/37321610000;/37267034900;/37281933000;/37089197139;/37089194014;/37086085163;/37089196237;/37067099600;/37321610000;/37267034900;/37281933000",
        "aff": "University of California, Berkeley; University of California, Berkeley; Facebook Reality Labs; Peking University; University of California, Berkeley; Facebook Reality Labs; University of California, Berkeley; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636858/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14633778535457923476&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;2;0;1;0;0",
        "aff_unique_norm": "University of California, Berkeley;Meta;Peking University",
        "aff_unique_dep": ";Facebook Reality Labs;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.facebook.com/realitylabs;http://www.pku.edu.cn",
        "aff_unique_abbr": "UC Berkeley;FRL;Peking U",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;1;0;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9636152",
        "title": "da\u00df: Distributable And Scalable Simulation of Robotic Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Simulation is an essential tool for developing robotic systems; however it is computationally intensive and does not scale well, especially for multi-robot scenarios. In this paper we introduce da\u00df \u2013 a system that facilitates distributable and scalable simulations of robotic applications. It overcomes many of the performance and quality limitations involved in common multi-robot simulation scenarios through horizontal scaling. Through extensive evaluation, we show that da\u00df significantly outperforms the widely used Gazebo robotics simulator, and easily scales well beyond the current limitations with no significant loss in performance and simulation fidelity.",
        "primary_area": "",
        "author": "Hans C. Woithe;Itai Segall;Hans C. Woithe;Itai Segall",
        "authorids": "/37594194600;/37572047200;/37594194600;/37572047200",
        "aff": "Bell Labs, Murray Hill, NJ, USA; Bell Labs, Murray Hill, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636152/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:LE8haZq8qWkJ:scholar.google.com/&scioq=da%C3%9F:+Distributable+And+Scalable+Simulation+of+Robotic+Applications&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Bell Labs",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.bell-labs.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Murray Hill",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636667",
        "title": "iGibson 1.0: A Simulation Environment for Interactive Tasks in Large Realistic Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "We present iGibson 1.0, a novel simulation environment to develop robotic solutions for interactive tasks in large-scale realistic scenes. Our environment contains 15 fully interactive home-sized scenes with 108 rooms populated with rigid and articulated objects. The scenes are replicas of real-world homes, with distribution and the layout of objects aligned to those of the real world. iGibson 1.0 integrates several key features to facilitate the study of interactive tasks: i) generation of high-quality virtual sensor signals (RGB, depth, segmentation, LiDAR, flow and so on), ii) domain randomization to change the materials of the objects (both visual and physical) and/or their shapes, iii) integrated sampling-based motion planners to generate collision-free trajectories for robot bases and arms, and iv) intuitive human-iGibson interface that enables efficient collection of human demonstrations. Through experiments, we show that the full interactivity of the scenes enables agents to learn useful visual representations that accelerate the training of downstream manipulation tasks. We also show that iGibson features enable the generalization of navigation agents, and that the human-iGibson interface and integrated motion planners facilitate efficient imitation learning of human demonstrated (mobile) manipulation behaviors. iGibson 1.0 is open-source, equipped with comprehensive examples and documentation. For more information, visit our project website: http://svl.stanford.edu/igibson/.",
        "primary_area": "",
        "author": "Bokui Shen;Fei Xia;Chengshu Li;Roberto Mart\u00edn-Mart\u00edn;Linxi Fan;Guanzhi Wang;Claudia P\u00e9rez-D\u2019Arpino;Shyamal Buch;Sanjana Srivastava;Lyne Tchapmi;Micael Tchapmi;Kent Vainio;Josiah Wong;Li Fei-Fei;Silvio Savarese;Bokui Shen;Fei Xia;Chengshu Li;Roberto Mart\u00edn-Mart\u00edn;Linxi Fan;Guanzhi Wang;Claudia P\u00e9rez-D\u2019Arpino;Shyamal Buch;Sanjana Srivastava;Lyne Tchapmi;Micael Tchapmi;Kent Vainio;Josiah Wong;Li Fei-Fei;Silvio Savarese",
        "authorids": "/37089197242;/37086564490;/37087318952;/37085788640;/37089196100;/37089088123;/38270722900;/37086225600;/37089197124;/37086391554;/37087320580;/37089195179;/37088968066;/38273560700;/37298502600;/37089197242;/37086564490;/37087318952;/37085788640;/37089196100;/37089088123;/38270722900;/37086225600;/37089197124;/37086391554;/37087320580;/37089195179;/37088968066;/38273560700;/37298502600",
        "aff": "Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University; Stanford Vision & Learning Laboratory, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636667/",
        "gs_citation": 193,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9210824955042543925&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 30,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Stanford Vision & Learning Laboratory",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636708",
        "title": "iNeRF: Inverting Neural Radiance Fields for Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present iNeRF, a framework that performs mesh-free pose estimation by \"inverting\" a Neural Radiance Field (NeRF). NeRFs have been shown to be remarkably effective for the task of view synthesis \u2014 synthesizing photorealistic novel views of real-world scenes or objects. In this work, we investigate whether we can apply analysis-by-synthesis via NeRF for mesh-free, RGB-only 6DoF pose estimation \u2013 given an image, find the translation and rotation of a camera relative to a 3D object or scene. Our method assumes that no object mesh models are available during either training or test time. Starting from an initial pose estimate, we use gradient descent to minimize the residual between pixels rendered from a NeRF and pixels in an observed image. In our experiments, we first study 1) how to sample rays during pose refinement for iNeRF to collect informative gradients and 2) how different batch sizes of rays affect iNeRF on a synthetic dataset. We then show that for complex real-world scenes from the LLFF dataset [21], iNeRF can improve NeRF by estimating the camera poses of novel images and using these images as additional training data for NeRF. Finally, we show iNeRF can perform categorylevel object pose estimation, including object instances not seen during training, with RGB images by inverting a NeRF model inferred from a single view.",
        "primary_area": "",
        "author": "Lin Yen-Chen;Pete Florence;Jonathan T. Barron;Alberto Rodriguez;Phillip Isola;Tsung-Yi Lin;Lin Yen-Chen;Pete Florence;Jonathan T. Barron;Alberto Rodriguez;Phillip Isola;Tsung-Yi Lin",
        "authorids": "/37088505485;/37085786926;/37953015500;/38194796600;/37945396900;/37089937636;/37088505485;/37085786926;/37953015500;/38194796600;/37945396900;/37089937636",
        "aff": "Massachusetts Institute of Technology; Google Research; Google Research; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Google Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636708/",
        "gs_citation": 494,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13575743072399988193&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://web.mit.edu;https://research.google",
        "aff_unique_abbr": "MIT;Google Research",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9636460",
        "title": "micROS.BT: An Event-Driven Behavior Tree Framework for Swarm Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose micROS.BT, an event-driven behavior tree (BT) framework aiming at supporting swarm-robot coordination. Compared with other BT frame-works, micROS.BT implements the event-driven way under the multi-thread mode, which can effectively save computing resources. Moreover, in order to ensure swarm-robot coordination, we optimize the implementation of the traditional blackboard and propose the multi-mode blackboard, which supports inner-tree, inter-tree, and inter-robot data sharing. Furthermore, considering the limited modularity of a single tree, micROS.BT realizes a mechanism called hierarchical tree management which involves inter-tree notifying and waiting functionalities, while ensuring that each tree is independent and self-scheduled. The effectiveness of micROS.BT is verified by simulation and real-robot experiments for different system settings, showing that a substantial improvement is achieved in comparison with the traditional BT implementations.",
        "primary_area": "",
        "author": "Yunlong Wu;Jinghua Li;Huadong Dai;Xiaodong Yi;Yanzhen Wang;Xuejun Yang;Yunlong Wu;Jinghua Li;Huadong Dai;Xiaodong Yi;Yanzhen Wang;Xuejun Yang",
        "authorids": "/37086091212;/37089198307;/37598013900;/37085630673;/37085616944;/37401424700;/37086091212;/37089198307;/37598013900;/37085630673;/37085616944;/37401424700",
        "aff": "Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China; Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China; Artificial Intelligence Research Center (AIRC), National Innovation Institute of Defense Technology (NIIDT), Beijing, China; Artificial Intelligence Research Center (AIRC), National Innovation Institute of Defense Technology (NIIDT), Beijing, China; Tianjin Artificial Intelligence Innovation Center (TAIIC), Tianjin, China; Artificial Intelligence Research Center (AIRC), National Innovation Institute of Defense Technology (NIIDT), Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636460/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10257271050160544989&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;1",
        "aff_unique_norm": "Tianjin Artificial Intelligence Innovation Center;National Innovation Institute of Defense Technology",
        "aff_unique_dep": ";Artificial Intelligence Research Center",
        "aff_unique_url": ";",
        "aff_unique_abbr": "TAIIC;NIIDT",
        "aff_campus_unique_index": "0;0;1;1;0;1",
        "aff_campus_unique": "Tianjin;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9636044",
        "title": "roboSLAM: Dense RGB-D SLAM for Humanoid Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In the current paper we investigate the challenges of localizing walking humanoid robots using Visual SLAM (VSLAM). We propose a novel dense RGB-D SLAM framework that seamlessly integrates with the dynamic state of a humanoid, to provide real-time localization and dense mapping of its surroundings. Following the path of recent research in humanoid localization, in the current work we explore the integration between a VSLAM system and the humanoid state, by considering the gait cycle and the feet contacts. We analyze how these effects undermine the quality of data acquisition and association for VSLAM, by capturing the unilateral ground forces at the robot\u2019s feet, and design a system that mitigates their impact.We evaluate our framework on both open and closed-loop bipedal gaits, using a low-cost humanoid platform, and demonstrate that it outperforms kinematic odometry and state-of-the-art dense RGB-D VSLAM methods, by continuously localizing the robot, even in the face of highly irregular and unstable motions.",
        "primary_area": "",
        "author": "Emmanouil Hourdakis;Stylianos Piperakis;Panos Trahanias;Emmanouil Hourdakis;Stylianos Piperakis;Panos Trahanias",
        "authorids": "/37313506700;/37085813142;/37329551300;/37313506700;/37085813142;/37329551300",
        "aff": "Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH), Heraklion, Greece; Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH), Heraklion, Greece; Institute of Computer Science, Foundation for Research and Technology - Hellas (FORTH), Heraklion, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9636044/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3194544294278943183&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Foundation for Research and Technology - Hellas",
        "aff_unique_dep": "Institute of Computer Science",
        "aff_unique_url": "https://www.forth.gr",
        "aff_unique_abbr": "FORTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Heraklion",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Greece"
    }
]