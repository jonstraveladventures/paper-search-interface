[
    {
        "id": "596b56d1b0",
        "title": "$\\ell_\u221e$-Bounds of the MLE in the BTL Model under General Comparison Graphs",
        "site": "https://proceedings.mlr.press/v180/li22g.html",
        "author": "Wanshan Li; Shamindra Shrotriya; Alessandro Rinaldo",
        "abstract": "The Bradley-Terry-Luce (BTL) model is a popular statistical approach for estimating the global ranking of a collection of items using pairwise comparisons. To ensure accurate ranking, it is essential to obtain precise estimates of the model parameters in the $\\ell_{\\infty}$-loss. The difficulty of this task depends crucially on the topology of the pairwise comparison graph over the given items. However, beyond very few well-studied cases, such as the complete and Erd{\u00f6}s-R{\u00e9}nyi comparison graphs, little is known about the performance of the maximum likelihood estimator (MLE) of the BTL model parameters in the $\\ell_{\\infty}$-loss under more general graph topologies. In this paper, we derive novel, general upper bounds on the $\\ell_{\\infty}$ estimation error of the BTL MLE that depend explicitly on the algebraic connectivity of the comparison graph, the maximal performance gap across items and the sample complexity. We demonstrate that the derived bounds perform well and in some cases are sharper compared to known results obtained using different loss functions and more restricted assumptions and graph topologies. We carefully compare our results to Yan et al. (2012), which is closest in spirit to our work. We further provide minimax lower bounds under $\\ell_{\\infty}$-error that nearly match the upper bounds over a class of sufficiently regular graph topologies. Finally, we study the implications of our $\\ell_{\\infty}$-bounds for efficient (offline) tournament design. We illustrate and discuss our findings through various examples and simulations.",
        "bibtex": "@InProceedings{pmlr-v180-li22g,\n  title = \t {$\\ell_{\u221e}$-Bounds of the MLE in the BTL Model under General Comparison Graphs},\n  author =       {Li, Wanshan and Shrotriya, Shamindra and Rinaldo, Alessandro},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1178--1187},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/li22g/li22g.pdf},\n  url = \t {https://proceedings.mlr.press/v180/li22g.html},\n  abstract = \t {The Bradley-Terry-Luce (BTL) model is a popular statistical approach for estimating the global ranking of a collection of items using pairwise comparisons. To ensure accurate ranking, it is essential to obtain precise estimates of the model parameters in the $\\ell_{\\infty}$-loss. The difficulty of this task depends crucially on the topology of the pairwise comparison graph over the given items. However, beyond very few well-studied cases, such as the complete and Erd{\u00f6}s-R{\u00e9}nyi comparison graphs, little is known about the performance of the maximum likelihood estimator (MLE) of the BTL model parameters in the $\\ell_{\\infty}$-loss under more general graph topologies. In this paper, we derive novel, general upper bounds on the $\\ell_{\\infty}$ estimation error of the BTL MLE that depend explicitly on the algebraic connectivity of the comparison graph, the maximal performance gap across items and the sample complexity. We demonstrate that the derived bounds perform well and in some cases are sharper compared to known results obtained using different loss functions and more restricted assumptions and graph topologies. We carefully compare our results to Yan et al. (2012), which is closest in spirit to our work. We further provide minimax lower bounds under $\\ell_{\\infty}$-error that nearly match the upper bounds over a class of sufficiently regular graph topologies. Finally, we study the implications of our $\\ell_{\\infty}$-bounds for efficient (offline) tournament design. We illustrate and discuss our findings through various examples and simulations.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/li22g/li22g.pdf",
        "supp": "",
        "pdf_size": 374328,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18033646649668310290&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "82259d6ed8",
        "title": "A causal bandit approach to learning good atomic interventions in presence of unobserved confounders",
        "site": "https://proceedings.mlr.press/v180/maiti22a.html",
        "author": "Aurghya Maiti; Vineet Nair; Gaurav Sinha",
        "abstract": "We study the problem of determining the best atomic intervention in a Causal Bayesian Network (CBN) specified only by its causal graph. We model this as a stochastic multi-armed bandit (MAB) problem with side-information, where interventions on CBN correspond to arms of the bandit instance. First, we propose a simple regret minimization algorithm that takes as input a causal graph with observable and unobservable nodes and in $T$ exploration rounds achieves $\\tilde{O}(\\sqrt{m(\\mathcal{C})/T})$ expected simple regret. Here $m(\\mathcal{C})$ is a parameter dependent on the input CBN $\\mathcal{C}$ and could be much smaller than the number of arms. We also show that this is almost optimal for CBNs whose causal graphs have an $n$-ary tree structure.  Next, we propose a cumulative regret minimization algorithm that takes as input a causal graph with observable nodes and performs better than the optimal MAB algorithms that do not use causal side-information. We experimentally compare both our algorithms with the best known algorithms in the literature.",
        "bibtex": "@InProceedings{pmlr-v180-maiti22a,\n  title = \t {A causal bandit approach to learning good atomic interventions in presence of unobserved confounders},\n  author =       {Maiti, Aurghya and Nair, Vineet and Sinha, Gaurav},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1328--1338},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/maiti22a/maiti22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/maiti22a.html},\n  abstract = \t {We study the problem of determining the best atomic intervention in a Causal Bayesian Network (CBN) specified only by its causal graph. We model this as a stochastic multi-armed bandit (MAB) problem with side-information, where interventions on CBN correspond to arms of the bandit instance. First, we propose a simple regret minimization algorithm that takes as input a causal graph with observable and unobservable nodes and in $T$ exploration rounds achieves $\\tilde{O}(\\sqrt{m(\\mathcal{C})/T})$ expected simple regret. Here $m(\\mathcal{C})$ is a parameter dependent on the input CBN $\\mathcal{C}$ and could be much smaller than the number of arms. We also show that this is almost optimal for CBNs whose causal graphs have an $n$-ary tree structure.  Next, we propose a cumulative regret minimization algorithm that takes as input a causal graph with observable nodes and performs better than the optimal MAB algorithms that do not use causal side-information. We experimentally compare both our algorithms with the best known algorithms in the literature.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/maiti22a/maiti22a.pdf",
        "supp": "",
        "pdf_size": 623684,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6928369697558156725&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "917c7dc0e9",
        "title": "A competitive analysis of online failure-aware assignment",
        "site": "https://proceedings.mlr.press/v180/chen22a.html",
        "author": "Mengjing Chen; Pingzhong Tang; Zihe Wang; Shenke Xiao; Xiwang Yang",
        "abstract": "Motivated by a new generation of Internet advertising that has emerged in the live streaming e-commerce markets (e.g., Tiktok) over the past five years, we study a variant of online bipartite matching problem: advertisers send ad requests to influencers (aka, key opinion leaders) on a social media platform. Each influencer has a maximum number of ad requests she can accommodate. We assign a fixed number of influencers to an advertiser when she enters the platform. The advertiser then matches with each of the assigned influencers with a probability, which can be thought of as a set of negotiations between the advertiser and the set of assigned influencers. Unlike the standard online assignment problems, the outcome of any of these matches is not revealed throughout the session (negotiations take time). Our goal is to maximize the expected number of matches between advertisers and influencers. We put forward a new deterministic algorithm with a competitive ratio of $1/2$ and prove that no deterministic algorithm can achieve a better competitive ratio. We also show that the competitive ratio can be improved when randomness is allowed. We then study a setting where a match is successful with either probability 0 or a fixed $p$. We present an optimal randomized algorithm that achieves a competitive ratio of $1-1/e$ in this setting.",
        "bibtex": "@InProceedings{pmlr-v180-chen22a,\n  title = \t {A competitive analysis of online failure-aware assignment},\n  author =       {Chen, Mengjing and Tang, Pingzhong and Wang, Zihe and Xiao, Shenke and Yang, Xiwang},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {317--325},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/chen22a/chen22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/chen22a.html},\n  abstract = \t {Motivated by a new generation of Internet advertising that has emerged in the live streaming e-commerce markets (e.g., Tiktok) over the past five years, we study a variant of online bipartite matching problem: advertisers send ad requests to influencers (aka, key opinion leaders) on a social media platform. Each influencer has a maximum number of ad requests she can accommodate. We assign a fixed number of influencers to an advertiser when she enters the platform. The advertiser then matches with each of the assigned influencers with a probability, which can be thought of as a set of negotiations between the advertiser and the set of assigned influencers. Unlike the standard online assignment problems, the outcome of any of these matches is not revealed throughout the session (negotiations take time). Our goal is to maximize the expected number of matches between advertisers and influencers. We put forward a new deterministic algorithm with a competitive ratio of $1/2$ and prove that no deterministic algorithm can achieve a better competitive ratio. We also show that the competitive ratio can be improved when randomness is allowed. We then study a setting where a match is successful with either probability 0 or a fixed $p$. We present an optimal randomized algorithm that achieves a competitive ratio of $1-1/e$ in this setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/chen22a/chen22a.pdf",
        "supp": "",
        "pdf_size": 262725,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10397808949598639594&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "394b316fcc",
        "title": "A free lunch from the noise: Provable and practical exploration for representation learning",
        "site": "https://proceedings.mlr.press/v180/ren22a.html",
        "author": "Tongzheng Ren; Tianjun Zhang; Csaba Szepesv\u00e1ri; Bo Dai",
        "abstract": "Representation learning lies at the heart of the empirical success of deep learning for dealing with the curse of dimensionality. However, the power of representation learning has not been fully exploited yet in reinforcement learning (RL), due to i), the trade-off between expressiveness and tractability; and ii), the coupling between exploration and representation learning. In this paper, we first reveal the fact that under some noise assumption in the stochastic control model, we can obtain the linear spectral feature of its corresponding Markov transition operator in closed-form for free. Based on this observation, we propose Spectral Dynamics Embedding (SPEDE), which breaks the tradeoff and completes optimistic exploration for representation learning by exploiting the structure of the noise. We provide rigorous theoretical analysis of SPEDE, and demonstrate the practical superior performance over the existing state-of-the-art empirical algorithms on several benchmarks.",
        "bibtex": "@InProceedings{pmlr-v180-ren22a,\n  title = \t {A free lunch from the noise: Provable and practical exploration for representation learning},\n  author =       {Ren, Tongzheng and Zhang, Tianjun and Szepesv\\'{a}ri, Csaba and Dai, Bo},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1686--1696},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ren22a/ren22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ren22a.html},\n  abstract = \t {Representation learning lies at the heart of the empirical success of deep learning for dealing with the curse of dimensionality. However, the power of representation learning has not been fully exploited yet in reinforcement learning (RL), due to i), the trade-off between expressiveness and tractability; and ii), the coupling between exploration and representation learning. In this paper, we first reveal the fact that under some noise assumption in the stochastic control model, we can obtain the linear spectral feature of its corresponding Markov transition operator in closed-form for free. Based on this observation, we propose Spectral Dynamics Embedding (SPEDE), which breaks the tradeoff and completes optimistic exploration for representation learning by exploiting the structure of the noise. We provide rigorous theoretical analysis of SPEDE, and demonstrate the practical superior performance over the existing state-of-the-art empirical algorithms on several benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/ren22a/ren22a.pdf",
        "supp": "",
        "pdf_size": 398705,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7632946949412805126&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, UT Austin + Google Research, Brain Team; Department of EECS, UC Berkeley; DeepMind + Department of Computer Science, University of Alberta; Google Research, Brain Team",
        "aff_domain": "utexas.edu;berkeley.edu;deepmind.com;google.com",
        "email": "utexas.edu;berkeley.edu;deepmind.com;google.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2;3+4;1",
        "aff_unique_norm": "University of Texas at Austin;Google;University of California, Berkeley;DeepMind;University of Alberta",
        "aff_unique_dep": "Department of Computer Science;Google Research;Department of Electrical Engineering and Computer Sciences;;Department of Computer Science",
        "aff_unique_url": "https://www.utexas.edu;https://research.google;https://www.berkeley.edu;https://deepmind.com;https://www.ualberta.ca",
        "aff_unique_abbr": "UT Austin;Google;UC Berkeley;DeepMind;UAlberta",
        "aff_campus_unique_index": "0+1;2;;1",
        "aff_campus_unique": "Austin;Mountain View;Berkeley;",
        "aff_country_unique_index": "0+0;0;1+2;0",
        "aff_country_unique": "United States;United Kingdom;Canada"
    },
    {
        "id": "a17de98404",
        "title": "A geometric method for improved uncertainty estimation in real-time",
        "site": "https://proceedings.mlr.press/v180/chouraqui22a.html",
        "author": "Gabriella Chouraqui; Liron Cohen; Gil Einziger; Liel Leman",
        "abstract": "Machine learning classifiers are probabilistic in nature, and thus inevitably involve uncertainty. Predicting the probability of a specific input to be correct is called uncertainty (or confidence) estimation and is crucial for risk management.Post-hoc model calibrations can improve models\u2019 uncertainty estimations without the need for retraining, and without changing the model.Our work puts forward a geometric-based approach for uncertainty estimation. Roughly speaking, we use the geometric distance of the current input from the existing training inputs as a signal for estimating uncertainty and then calibrate that signal (instead of the model\u2019s estimation) using standard post-hoc calibration techniques.  We show that our method yields better uncertainty estimations than recently proposed approaches by extensively evaluating multiple datasets and models. In addition, we also demonstrate the possibility of performing our approach in near real-time applications. Our code is available at our Github: https://github.com/NoSleepDeveloper/Geometric-Calibrator",
        "bibtex": "@InProceedings{pmlr-v180-chouraqui22a,\n  title = \t {A geometric method for improved uncertainty estimation in real-time},\n  author =       {Chouraqui, Gabriella and Cohen, Liron and Einziger, Gil and Leman, Liel},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {422--432},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/chouraqui22a/chouraqui22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/chouraqui22a.html},\n  abstract = \t {Machine learning classifiers are probabilistic in nature, and thus inevitably involve uncertainty. Predicting the probability of a specific input to be correct is called uncertainty (or confidence) estimation and is crucial for risk management.Post-hoc model calibrations can improve models\u2019 uncertainty estimations without the need for retraining, and without changing the model.Our work puts forward a geometric-based approach for uncertainty estimation. Roughly speaking, we use the geometric distance of the current input from the existing training inputs as a signal for estimating uncertainty and then calibrate that signal (instead of the model\u2019s estimation) using standard post-hoc calibration techniques.  We show that our method yields better uncertainty estimations than recently proposed approaches by extensively evaluating multiple datasets and models. In addition, we also demonstrate the possibility of performing our approach in near real-time applications. Our code is available at our Github: https://github.com/NoSleepDeveloper/Geometric-Calibrator }\n}",
        "pdf": "https://proceedings.mlr.press/v180/chouraqui22a/chouraqui22a.pdf",
        "supp": "",
        "pdf_size": 387940,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16656390452949667386&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "990075d7ce",
        "title": "A label efficient two-sample test",
        "site": "https://proceedings.mlr.press/v180/li22f.html",
        "author": "Weizhi Li; Gautam Dasarathy; Karthikeyan Natesan Ramamurthy; Visar Berisha",
        "abstract": "Two-sample tests evaluate whether two samples are realizations of the same distribution (the null hypothesis) or two different distributions (the alternative hypothesis). We consider a new setting for this problem where sample features are easily measured whereas sample labels are unknown and costly to obtain. Accordingly, we devise a three-stage framework in service of performing an effective two-sample test with only a small number of sample label queries: first, a classifier is trained with samples uniformly labeled to model the posterior probabilities of the labels; second, a novel query scheme dubbed bimodal query is used to query labels of samples from both classes, and last, the classical Friedman-Rafsky (FR) two-sample test is performed on the queried samples. Theoretical analysis and extensive experiments performed on several datasets demonstrate that the proposed test controls the Type I error and has decreased Type II error relative to uniform querying and certainty-based querying. Source code for our algorithms and experimental results is available at https://github.com/wayne0908/Label-Efficient-Two-Sample.",
        "bibtex": "@InProceedings{pmlr-v180-li22f,\n  title = \t {A label efficient two-sample test},\n  author =       {Li, Weizhi and Dasarathy, Gautam and Ramamurthy, Karthikeyan Natesan and Berisha, Visar},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1168--1177},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/li22f/li22f.pdf},\n  url = \t {https://proceedings.mlr.press/v180/li22f.html},\n  abstract = \t {Two-sample tests evaluate whether two samples are realizations of the same distribution (the null hypothesis) or two different distributions (the alternative hypothesis). We consider a new setting for this problem where sample features are easily measured whereas sample labels are unknown and costly to obtain. Accordingly, we devise a three-stage framework in service of performing an effective two-sample test with only a small number of sample label queries: first, a classifier is trained with samples uniformly labeled to model the posterior probabilities of the labels; second, a novel query scheme dubbed bimodal query is used to query labels of samples from both classes, and last, the classical Friedman-Rafsky (FR) two-sample test is performed on the queried samples. Theoretical analysis and extensive experiments performed on several datasets demonstrate that the proposed test controls the Type I error and has decreased Type II error relative to uniform querying and certainty-based querying. Source code for our algorithms and experimental results is available at https://github.com/wayne0908/Label-Efficient-Two-Sample.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/li22f/li22f.pdf",
        "supp": "",
        "pdf_size": 532563,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4102943909260462490&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 11,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6408997038",
        "title": "A mutually exciting latent space Hawkes process model for continuous-time networks",
        "site": "https://proceedings.mlr.press/v180/huang22b.html",
        "author": "Zhipeng Huang; Hadeel Soliman; Subhadeep Paul; Kevin S. Xu",
        "abstract": "Networks and temporal point processes serve as fundamental building blocks for modeling complex dynamic relational data in various domains. We propose the latent space Hawkes (LSH) model, a novel generative model for continuous-time networks of relational events, using a latent space representation for nodes. We model relational events between nodes using mutually exciting Hawkes processes with baseline intensities dependent upon the distances between the nodes in the latent space and sender and receiver specific effects. We demonstrate that our proposed LSH model can replicate many features observed in real temporal networks including reciprocity and transitivity, while also achieving superior prediction accuracy and providing more interpretable fits than existing models.",
        "bibtex": "@InProceedings{pmlr-v180-huang22b,\n  title = \t {A mutually exciting latent space {Hawkes} process model for continuous-time networks},\n  author =       {Huang, Zhipeng and Soliman, Hadeel and Paul, Subhadeep and Xu, Kevin S.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {863--873},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/huang22b/huang22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/huang22b.html},\n  abstract = \t {Networks and temporal point processes serve as fundamental building blocks for modeling complex dynamic relational data in various domains. We propose the latent space Hawkes (LSH) model, a novel generative model for continuous-time networks of relational events, using a latent space representation for nodes. We model relational events between nodes using mutually exciting Hawkes processes with baseline intensities dependent upon the distances between the nodes in the latent space and sender and receiver specific effects. We demonstrate that our proposed LSH model can replicate many features observed in real temporal networks including reciprocity and transitivity, while also achieving superior prediction accuracy and providing more interpretable fits than existing models.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/huang22b/huang22b.pdf",
        "supp": "",
        "pdf_size": 339228,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3367233236551104342&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "03fa7183d1",
        "title": "A new constructive criterion for Markov equivalence of MAGs",
        "site": "https://proceedings.mlr.press/v180/wienobst22a.html",
        "author": "Marcel Wien\u00f6bst; Max Bannach; Maciej Li\u015bkiewicz",
        "abstract": "Ancestral graphs are an important tool for encoding causal knowledge as they represent uncertainty about the presence of latent confounding and selection bias, and they can be inferred from data. As for other graphical models, several maximal ancestral graphs (MAGs) may encode the same statistical information in the form of conditional independencies.  Such MAGs are said to be Markov equivalent. This work concerns graphical characterizations and computational aspects of Markov equivalence between MAGs. These issues have been studied in past years leading to several criteria and methods to test Markov equivalence. The state-of-the-art algorithm, provided by Hu and Evans [UAI 2020], runs in time $O(n^5)$ for instances with $n$ vertices. We propose a new constructive graphical criterion for the Markov equivalence of MAGs, which allows us to develop a practically effective equivalence test with worst-case runtime $O(n^3)$. Additionally, our criterion is expressed in terms of natural graphical concepts, which is of independent value.",
        "bibtex": "@InProceedings{pmlr-v180-wienobst22a,\n  title = \t {A new constructive criterion for {Markov} equivalence of {MAGs}},\n  author =       {Wien{\\\"o}bst, Marcel and Bannach, Max and Li{\\'s}kiewicz, Maciej},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2107--2116},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/wienobst22a/wienobst22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/wienobst22a.html},\n  abstract = \t {Ancestral graphs are an important tool for encoding causal knowledge as they represent uncertainty about the presence of latent confounding and selection bias, and they can be inferred from data. As for other graphical models, several maximal ancestral graphs (MAGs) may encode the same statistical information in the form of conditional independencies.  Such MAGs are said to be Markov equivalent. This work concerns graphical characterizations and computational aspects of Markov equivalence between MAGs. These issues have been studied in past years leading to several criteria and methods to test Markov equivalence. The state-of-the-art algorithm, provided by Hu and Evans [UAI 2020], runs in time $O(n^5)$ for instances with $n$ vertices. We propose a new constructive graphical criterion for the Markov equivalence of MAGs, which allows us to develop a practically effective equivalence test with worst-case runtime $O(n^3)$. Additionally, our criterion is expressed in terms of natural graphical concepts, which is of independent value.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/wienobst22a/wienobst22a.pdf",
        "supp": "",
        "pdf_size": 282208,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14642972969533595067&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "db0d577c32",
        "title": "A robustness test for estimating total effects with covariate adjustment",
        "site": "https://proceedings.mlr.press/v180/su22a.html",
        "author": "Zehao Su; Leonard Henckel",
        "abstract": "Suppose we want to estimate a total effect with covariate adjustment in a linear structural equation model. We have a causal graph to decide what covariates to adjust for, but are uncertain about the graph. Here, we propose a testing procedure, that exploits the fact that there are multiple valid adjustment sets for the target total effect in the causal graph, to perform a robustness check on the graph. If the test rejects, it is a strong indication that we should not rely on the graph. We discuss what mistakes in the graph our testing procedure can detect and which ones it cannot and develop two strategies on how to select a list of valid adjustment sets for the procedure. We also connect our result to the related econometrics literature on coefficient stability tests.",
        "bibtex": "@InProceedings{pmlr-v180-su22a,\n  title = \t {A robustness test for estimating total effects with covariate adjustment},\n  author =       {Su, Zehao and Henckel, Leonard},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1886--1895},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/su22a/su22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/su22a.html},\n  abstract = \t {Suppose we want to estimate a total effect with covariate adjustment in a linear structural equation model. We have a causal graph to decide what covariates to adjust for, but are uncertain about the graph. Here, we propose a testing procedure, that exploits the fact that there are multiple valid adjustment sets for the target total effect in the causal graph, to perform a robustness check on the graph. If the test rejects, it is a strong indication that we should not rely on the graph. We discuss what mistakes in the graph our testing procedure can detect and which ones it cannot and develop two strategies on how to select a list of valid adjustment sets for the procedure. We also connect our result to the related econometrics literature on coefficient stability tests.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/su22a/su22a.pdf",
        "supp": "",
        "pdf_size": 546664,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=131743796063235871&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Section of Biostatistics, Department of Public Health, University of Copenhagen; Department of Mathematical Sciences, University of Copenhagen",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Copenhagen",
        "aff_unique_dep": "Section of Biostatistics, Department of Public Health",
        "aff_unique_url": "https://www.sund.ku.dk/",
        "aff_unique_abbr": "UCPH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "073a40a59c",
        "title": "AND/OR branch-and-bound for computational protein design optimizing K*",
        "site": "https://proceedings.mlr.press/v180/pezeshki22a.html",
        "author": "Bobak Pezeshki; Radu Marinescu; Alexander Ihler; Rina Dechter",
        "abstract": "The importance of designing proteins, such as high affinity antibodies, has become ever more apparent.  Computational Protein Design can cast such design problems as optimization tasks with the objective of maximizing K*, an approximation of binding affinity.  Here we lay out a graphical model framework for K* optimization that enables use of compact AND/OR search algorithms. We designed an AND/OR branch-and-bound algorithm, AOBB-K*, for optimizing K* that is guided by a new K* heuristic and can incorporate specialized performance improvements with theoretical guarantees. As AOBB-K* is inspired by algorithms from the well studied task of Marginal MAP, this work provides a foundation for harnessing advancements in state-of-the-art mixed inference schemes and adapting them to protein design.",
        "bibtex": "@InProceedings{pmlr-v180-pezeshki22a,\n  title = \t {{AND/OR} branch-and-bound for computational protein design optimizing {K*}},\n  author =       {Pezeshki, Bobak and Marinescu, Radu and Ihler, Alexander and Dechter, Rina},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1602--1612},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/pezeshki22a/pezeshki22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/pezeshki22a.html},\n  abstract = \t {The importance of designing proteins, such as high affinity antibodies, has become ever more apparent.  Computational Protein Design can cast such design problems as optimization tasks with the objective of maximizing K*, an approximation of binding affinity.  Here we lay out a graphical model framework for K* optimization that enables use of compact AND/OR search algorithms. We designed an AND/OR branch-and-bound algorithm, AOBB-K*, for optimizing K* that is guided by a new K* heuristic and can incorporate specialized performance improvements with theoretical guarantees. As AOBB-K* is inspired by algorithms from the well studied task of Marginal MAP, this work provides a foundation for harnessing advancements in state-of-the-art mixed inference schemes and adapting them to protein design.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/pezeshki22a/pezeshki22a.pdf",
        "supp": "",
        "pdf_size": 3044996,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11928063842351816956&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6c070fdad3",
        "title": "AUTM flow: atomic unrestricted time machine for monotonic normalizing flows",
        "site": "https://proceedings.mlr.press/v180/cai22a.html",
        "author": "Difeng Cai; Yuliang Ji; Huan He; Qiang Ye; Yuanzhe Xi",
        "abstract": "Nonlinear monotone transformations are used extensively in normalizing flows to construct invertible triangular mappings from simple distributions to complex ones. In existing literature, monotonicity is usually enforced by restricting function classes or model parameters and the inverse transformation is often approximated by root-finding algorithms as a closed-form inverse is unavailable. In this paper, we introduce a new integral-based approach termed: Atomic Unrestricted Time Machine (AUTM), equipped with unrestricted integrands and easy-to-compute explicit inverse. AUTM offers a versatile and efficient way to the design of normalizing flows with explicit inverse and unrestricted function classes or parameters. Theoretically, we present a constructive proof that AUTM is universal: all monotonic normalizing flows can be viewed as limits of AUTM flows. We provide a concrete example to show how to approximate any given monotonic normalizing flow using AUTM flows with guaranteed convergence. The result implies that AUTM can be used to transform an existing flow into a new one equipped with explicit inverse and unrestricted parameters. The performance of the new approach is evaluated on high dimensional density estimation, variational inference and image generation. Experiments demonstrate superior speed and memory efficiency of AUTM.",
        "bibtex": "@InProceedings{pmlr-v180-cai22a,\n  title = \t {AUTM flow: atomic unrestricted time machine for monotonic normalizing flows},\n  author =       {Cai, Difeng and Ji, Yuliang and He, Huan and Ye, Qiang and Xi, Yuanzhe},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {266--274},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/cai22a/cai22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/cai22a.html},\n  abstract = \t {Nonlinear monotone transformations are used extensively in normalizing flows to construct invertible triangular mappings from simple distributions to complex ones. In existing literature, monotonicity is usually enforced by restricting function classes or model parameters and the inverse transformation is often approximated by root-finding algorithms as a closed-form inverse is unavailable. In this paper, we introduce a new integral-based approach termed: Atomic Unrestricted Time Machine (AUTM), equipped with unrestricted integrands and easy-to-compute explicit inverse. AUTM offers a versatile and efficient way to the design of normalizing flows with explicit inverse and unrestricted function classes or parameters. Theoretically, we present a constructive proof that AUTM is universal: all monotonic normalizing flows can be viewed as limits of AUTM flows. We provide a concrete example to show how to approximate any given monotonic normalizing flow using AUTM flows with guaranteed convergence. The result implies that AUTM can be used to transform an existing flow into a new one equipped with explicit inverse and unrestricted parameters. The performance of the new approach is evaluated on high dimensional density estimation, variational inference and image generation. Experiments demonstrate superior speed and memory efficiency of AUTM.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/cai22a/cai22a.pdf",
        "supp": "",
        "pdf_size": 941938,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18101351997843808859&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Mathematics, Emory University, Atlanta, GA, USA; Department of Mathematics, Emory University, Atlanta, GA, USA; Department of Computer Science, Emory University, Atlanta, GA, USA; Department of Mathematics, University of Kentucky, Lexington, KY, USA; Department of Mathematics, Emory University, Atlanta, GA, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Emory University;University of Kentucky",
        "aff_unique_dep": "Department of Mathematics;Department of Mathematics",
        "aff_unique_url": "https://www.emory.edu;https://www.uky.edu",
        "aff_unique_abbr": "Emory;UK",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Atlanta;Lexington",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f24fb32a2d",
        "title": "Accelerating training of batch normalization: A manifold perspective",
        "site": "https://proceedings.mlr.press/v180/yi22a.html",
        "author": "Mingyang Yi",
        "abstract": "Batch normalization (BN) has become a critical component across diverse deep neural networks. The network with BN is invariant to positively linear re-scale transformation, which makes there exist infinite functionally equivalent networks with different scales of weights. However, optimizing these equivalent networks with the first-order method such as stochastic gradient descent will obtain a series of iterates converging to different local optima owing to their different gradients across training. To obviate this, we propose a quotient manifold PSI manifold, in which all the equivalent weights of the network with BN are regarded as the same element. Next, we construct gradient descent and stochastic gradient descent on the proposed PSI manifold to train the network with BN. The two algorithms guarantee that every group of equivalent weights (caused by positively re-scaling) converge to the equivalent optima. Besides that, we give convergence rates of the proposed algorithms on the PSI manifold. The results show that our methods accelerate training compared with the algorithms on the Euclidean weight space. Finally, empirical results verify that our algorithms consistently improve the existing methods in both convergence rate and generalization ability under various experimental settings.",
        "bibtex": "@InProceedings{pmlr-v180-yi22a,\n  title = \t {Accelerating training of batch normalization: A manifold perspective},\n  author =       {Yi, Mingyang},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1128--1137},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yi22a/yi22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yi22a.html},\n  abstract = \t {Batch normalization (BN) has become a critical component across diverse deep neural networks. The network with BN is invariant to positively linear re-scale transformation, which makes there exist infinite functionally equivalent networks with different scales of weights. However, optimizing these equivalent networks with the first-order method such as stochastic gradient descent will obtain a series of iterates converging to different local optima owing to their different gradients across training. To obviate this, we propose a quotient manifold PSI manifold, in which all the equivalent weights of the network with BN are regarded as the same element. Next, we construct gradient descent and stochastic gradient descent on the proposed PSI manifold to train the network with BN. The two algorithms guarantee that every group of equivalent weights (caused by positively re-scaling) converge to the equivalent optima. Besides that, we give convergence rates of the proposed algorithms on the PSI manifold. The results show that our methods accelerate training compared with the algorithms on the Euclidean weight space. Finally, empirical results verify that our algorithms consistently improve the existing methods in both convergence rate and generalization ability under various experimental settings.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yi22a/yi22a.pdf",
        "supp": "",
        "pdf_size": 730938,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12524728974224201045&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "University of Chinese Academy of Sciences+Academy of Mathematics and Systems Science, Chinese Academy of Sciences",
        "aff_domain": "mails.ucas.edu.cn",
        "email": "mails.ucas.edu.cn",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_unique_dep": ";Academy of Mathematics and Systems Science",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.amss.cas.cn",
        "aff_unique_abbr": "UCAS;AMSS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "a40790d718",
        "title": "Active approximately metric-fair learning",
        "site": "https://proceedings.mlr.press/v180/cao22a.html",
        "author": "Yiting Cao; Chao Lan",
        "abstract": "Existing studies on individual fairness focus on the passive setting and typically require $O(\\frac{1}{\\varepsilon^2})$ labeled instances to achieve an $\\varepsilon$ bias budget. In this paper, we build on the elegant Approximately Metric-Fair (AMF) learning framework and propose an active AMF learner that can provably achieve the same budget with only $O(\\log \\frac{1}{\\varepsilon})$ labeled instances. To our knowledge, this is a first and substantial improvement of the existing sample complexity for achieving individual fairness. Through experiments on three data sets, we show the proposed active AMF learner improves fairness on linear and non-linear models more efficiently than its passive counterpart as well as state-of-the-art active learners, while maintaining a comparable accuracy. To facilitate algorithm design and analysis, we also design a provably equivalent form of the approximate metric fairness based on uniform continuity instead of the existing almost Lipschitz continuity.",
        "bibtex": "@InProceedings{pmlr-v180-cao22a,\n  title = \t {Active approximately metric-fair learning},\n  author =       {Cao, Yiting and Lan, Chao},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {275--285},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/cao22a/cao22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/cao22a.html},\n  abstract = \t {Existing studies on individual fairness focus on the passive setting and typically require $O(\\frac{1}{\\varepsilon^2})$ labeled instances to achieve an $\\varepsilon$ bias budget. In this paper, we build on the elegant Approximately Metric-Fair (AMF) learning framework and propose an active AMF learner that can provably achieve the same budget with only $O(\\log \\frac{1}{\\varepsilon})$ labeled instances. To our knowledge, this is a first and substantial improvement of the existing sample complexity for achieving individual fairness. Through experiments on three data sets, we show the proposed active AMF learner improves fairness on linear and non-linear models more efficiently than its passive counterpart as well as state-of-the-art active learners, while maintaining a comparable accuracy. To facilitate algorithm design and analysis, we also design a provably equivalent form of the approximate metric fairness based on uniform continuity instead of the existing almost Lipschitz continuity. }\n}",
        "pdf": "https://proceedings.mlr.press/v180/cao22a/cao22a.pdf",
        "supp": "",
        "pdf_size": 610557,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=468719444086750134&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "School of Computer Science, University of Oklahoma, Norman, Oklahoma, USA; School of Computer Science, University of Oklahoma, Norman, Oklahoma, USA",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Oklahoma",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.ou.edu",
        "aff_unique_abbr": "OU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Norman",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "86b6076011",
        "title": "Active learning with label comparisons",
        "site": "https://proceedings.mlr.press/v180/yona22a.html",
        "author": "Gal Yona; Shay Moran; Gal Elidan; Amir Globerson",
        "abstract": "Supervised learning typically relies on manual annotation of the true labels. When there are many potential classes, searching for the best one can be prohibitive for a human annotator. On the other hand, comparing two candidate labels is often much easier. We focus on this type of pairwise supervision and ask how it can be used effectively in learning, and in particular in active learning. We obtain several insightful results in this context. In principle, finding the best of k labels can be done with k-1 active queries. We show that there is a natural class where this approach is sub-optimal, and that there is a more comparison-efficient active learning scheme. A key element in our analysis is the \u201clabel neighborhood graph\u201d of the true distribution, which has an edge between two classes if they share a decision boundary. We also show that in the PAC setting, pairwise comparisons cannot provide improved sample complexity in the worst case. We complement our theoretical results with experiments, clearly demonstrating the effect of the neighborhood graph on sample complexity.",
        "bibtex": "@InProceedings{pmlr-v180-yona22a,\n  title = \t {Active learning with label comparisons},\n  author =       {Yona, Gal and Moran, Shay and Elidan, Gal and Globerson, Amir},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2289--2298},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yona22a/yona22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yona22a.html},\n  abstract = \t {Supervised learning typically relies on manual annotation of the true labels. When there are many potential classes, searching for the best one can be prohibitive for a human annotator. On the other hand, comparing two candidate labels is often much easier. We focus on this type of pairwise supervision and ask how it can be used effectively in learning, and in particular in active learning. We obtain several insightful results in this context. In principle, finding the best of k labels can be done with k-1 active queries. We show that there is a natural class where this approach is sub-optimal, and that there is a more comparison-efficient active learning scheme. A key element in our analysis is the \u201clabel neighborhood graph\u201d of the true distribution, which has an edge between two classes if they share a decision boundary. We also show that in the PAC setting, pairwise comparisons cannot provide improved sample complexity in the worst case. We complement our theoretical results with experiments, clearly demonstrating the effect of the neighborhood graph on sample complexity.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yona22a/yona22a.pdf",
        "supp": "",
        "pdf_size": 1041802,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2151713555430938349&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cd2669874d",
        "title": "AdaCat: Adaptive categorical discretization for autoregressive models",
        "site": "https://proceedings.mlr.press/v180/li22h.html",
        "author": "Qiyang Li; Ajay Jain; Pieter Abbeel",
        "abstract": "Autoregressive generative models can estimate complex continuous data distributions, like trajectory rollouts in an RL environment, image intensities, and audio. Most state-of-the-art models discretize continuous data into several bins and use categorical distributions over the bins to approximate the continuous data distribution. The advantage is that the categorical distribution can easily express multiple modes and are straightforward to optimize. However, such approximation cannot express sharp changes in density without using significantly more bins, which makes it parameter inefficient. We propose an efficient, expressive, multimodal parameterization called Adaptive Categorical Discretization (AdaCat). AdaCat discretizes each dimension of an autoregressive model adaptively, which allows the model to allocate density to fine intervals of interest, improving parameter efficiency. AdaCat generalizes both categoricals and quantile-based regression. AdaCat is a simple add-on to any discretization-based distribution estimator. In experiments, AdaCat improves density estimation for real-world tabular data, images, audio, and trajectories, and improves planning in model-based offline RL.",
        "bibtex": "@InProceedings{pmlr-v180-li22h,\n  title = \t {AdaCat: Adaptive categorical discretization for autoregressive models},\n  author =       {Li, Qiyang and Jain, Ajay and Abbeel, Pieter},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1188--1198},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/li22h/li22h.pdf},\n  url = \t {https://proceedings.mlr.press/v180/li22h.html},\n  abstract = \t {Autoregressive generative models can estimate complex continuous data distributions, like trajectory rollouts in an RL environment, image intensities, and audio. Most state-of-the-art models discretize continuous data into several bins and use categorical distributions over the bins to approximate the continuous data distribution. The advantage is that the categorical distribution can easily express multiple modes and are straightforward to optimize. However, such approximation cannot express sharp changes in density without using significantly more bins, which makes it parameter inefficient. We propose an efficient, expressive, multimodal parameterization called Adaptive Categorical Discretization (AdaCat). AdaCat discretizes each dimension of an autoregressive model adaptively, which allows the model to allocate density to fine intervals of interest, improving parameter efficiency. AdaCat generalizes both categoricals and quantile-based regression. AdaCat is a simple add-on to any discretization-based distribution estimator. In experiments, AdaCat improves density estimation for real-world tabular data, images, audio, and trajectories, and improves planning in model-based offline RL.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/li22h/li22h.pdf",
        "supp": "",
        "pdf_size": 578526,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8964244332292732746&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1d2da9c694",
        "title": "Addressing token uniformity in transformers via singular value transformation",
        "site": "https://proceedings.mlr.press/v180/yan22b.html",
        "author": "Hanqi Yan; Lin Gui; Wenjie Li; Yulan He",
        "abstract": "Token uniformity is commonly observed in transformer-based models, in which different tokens share a large proportion of similar information after going through stacked multiple self-attention layers in a transformer. In this paper, we propose to use the distribution of singular values of outputs of each transformer layer to characterise the phenomenon of token uniformity and empirically illustrate that a less skewed singular value distribution can alleviate the token uniformity problem. Base on our observations, we define several desirable properties of singular value distributions and propose a novel transformation function for updating the singular values. We show that apart from alleviating token uniformity, the transformation function should preserve the local neighbourhood structure in the original embedding space. Our proposed singular value transformation function is applied to a range of transformer-based language models such as BERT, ALBERT, RoBERTa and DistilBERT, and improved performance is observed in semantic textual similarity evaluation and a range of GLUE tasks.",
        "bibtex": "@InProceedings{pmlr-v180-yan22b,\n  title = \t {Addressing token uniformity in transformers via singular value transformation},\n  author =       {Yan, Hanqi and Gui, Lin and Li, Wenjie and He, Yulan},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2181--2191},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yan22b/yan22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yan22b.html},\n  abstract = \t {Token uniformity is commonly observed in transformer-based models, in which different tokens share a large proportion of similar information after going through stacked multiple self-attention layers in a transformer. In this paper, we propose to use the distribution of singular values of outputs of each transformer layer to characterise the phenomenon of token uniformity and empirically illustrate that a less skewed singular value distribution can alleviate the token uniformity problem. Base on our observations, we define several desirable properties of singular value distributions and propose a novel transformation function for updating the singular values. We show that apart from alleviating token uniformity, the transformation function should preserve the local neighbourhood structure in the original embedding space. Our proposed singular value transformation function is applied to a range of transformer-based language models such as BERT, ALBERT, RoBERTa and DistilBERT, and improved performance is observed in semantic textual similarity evaluation and a range of GLUE tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yan22b/yan22b.pdf",
        "supp": "",
        "pdf_size": 1084455,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=159385836257547496&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "62c8f4982a",
        "title": "An explore-then-commit algorithm for submodular maximization under full-bandit feedback",
        "site": "https://proceedings.mlr.press/v180/nie22a.html",
        "author": "Guanyu Nie; Mridul Agarwal; Abhishek Kumar Umrawal; Vaneet Aggarwal; Christopher John Quinn",
        "abstract": "We investigate the problem of combinatorial multi-armed bandits with stochastic submodular (in expectation) rewards and full-bandit feedback, where no extra information other than the reward of selected action at each time step $t$ is observed. We propose a simple algorithm, Explore-Then-Commit Greedy (ETCG) and prove that it achieves a $(1-1/e)$-regret upper bound of $\\mathcal{O}(n^\\frac{1}{3}k^\\frac{4}{3}T^\\frac{2}{3}\\log(T)^\\frac{1}{2})$ for a horizon $T$, number of base elements $n$, and cardinality constraint $k$. We also show in experiments with synthetic and real-world data that the ETCG empirically outperforms other full-bandit methods.",
        "bibtex": "@InProceedings{pmlr-v180-nie22a,\n  title = \t {An explore-then-commit algorithm for submodular maximization under full-bandit feedback},\n  author =       {Nie, Guanyu and Agarwal, Mridul and Umrawal, Abhishek Kumar and Aggarwal, Vaneet and John Quinn, Christopher},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1541--1551},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/nie22a/nie22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/nie22a.html},\n  abstract = \t {We investigate the problem of combinatorial multi-armed bandits with stochastic submodular (in expectation) rewards and full-bandit feedback, where no extra information other than the reward of selected action at each time step $t$ is observed. We propose a simple algorithm, Explore-Then-Commit Greedy (ETCG) and prove that it achieves a $(1-1/e)$-regret upper bound of $\\mathcal{O}(n^\\frac{1}{3}k^\\frac{4}{3}T^\\frac{2}{3}\\log(T)^\\frac{1}{2})$ for a horizon $T$, number of base elements $n$, and cardinality constraint $k$. We also show in experiments with synthetic and real-world data that the ETCG empirically outperforms other full-bandit methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/nie22a/nie22a.pdf",
        "supp": "",
        "pdf_size": 5539748,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14566317465762150517&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Computer Science Department, Iowa State University, Ames, Iowa, USA; Purdue University, West Lafayette, Indiana, USA; Purdue University, West Lafayette, Indiana, USA; Purdue University, West Lafayette, Indiana, USA; Computer Science Department, Iowa State University, Ames, Iowa, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Iowa State University;Purdue University",
        "aff_unique_dep": "Computer Science Department;",
        "aff_unique_url": "https://www.iastate.edu;https://www.purdue.edu",
        "aff_unique_abbr": "ISU;Purdue",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Ames;West Lafayette",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8e321a08f6",
        "title": "Asymmetric DQN for partially observable reinforcement learning",
        "site": "https://proceedings.mlr.press/v180/baisero22a.html",
        "author": "Andrea Baisero; Brett Daley; Christopher Amato",
        "abstract": "Offline training in simulated partially observable environments allows reinforcement learning methods to exploit privileged state information through a mechanism known as asymmetry. Such privileged information has the potential to greatly improve the optimal convergence properties, if used appropriately. However, current research in asymmetric reinforcement learning is often heuristic in nature, with few connections to underlying theory or theoretical guarantees, and is primarily tested through empirical evaluation. In this work, we develop the theory of Asymmetric Policy Iteration, an exact model-based dynamic programming solution method, and then apply relaxations which eventually result in Asymmetric DQN, a model-free deep reinforcement learning algorithm. Our theoretical findings are complemented and validated by empirical experimentation performed in environments which exhibit significant amounts of partial observability, and require both information gathering strategies and memorization.",
        "bibtex": "@InProceedings{pmlr-v180-baisero22a,\n  title = \t {Asymmetric {DQN} for partially observable reinforcement learning},\n  author =       {Baisero, Andrea and Daley, Brett and Amato, Christopher},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {107--117},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/baisero22a/baisero22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/baisero22a.html},\n  abstract = \t {Offline training in simulated partially observable environments allows reinforcement learning methods to exploit privileged state information through a mechanism known as asymmetry. Such privileged information has the potential to greatly improve the optimal convergence properties, if used appropriately. However, current research in asymmetric reinforcement learning is often heuristic in nature, with few connections to underlying theory or theoretical guarantees, and is primarily tested through empirical evaluation. In this work, we develop the theory of Asymmetric Policy Iteration, an exact model-based dynamic programming solution method, and then apply relaxations which eventually result in Asymmetric DQN, a model-free deep reinforcement learning algorithm. Our theoretical findings are complemented and validated by empirical experimentation performed in environments which exhibit significant amounts of partial observability, and require both information gathering strategies and memorization.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/baisero22a/baisero22a.pdf",
        "supp": "",
        "pdf_size": 365006,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11482084963467485888&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fa1db2190a",
        "title": "Asymptotic optimality for active learning processes",
        "site": "https://proceedings.mlr.press/v180/zhan22a.html",
        "author": "Xueying Zhan; Yaowei Wang; Antoni B. Chan",
        "abstract": "Active Learning (AL) aims to optimize basic learned model(s) iteratively by selecting and annotating unlabeled data samples that are deemed to best maximise the model performance with minimal required data. However, the learned model is easy to overfit due to the biased distribution (sampling bias and dataset shift) formed by non-uniform sampling used in AL. Considering AL as an iterative sequential optimization process, we first provide a perspective on AL in terms of statistical properties, i.e., asymptotic unbiasedness, consistency and asymptotic efficiency, with respect to basic estimators when the sample size (size of labeled set) becomes large, and in the limit as sample size tends to infinity. We then discuss how biases affect AL. Finally, we proposed a flexible AL framework that aims to mitigate the impact of bias in AL by minimizing generalization error and importance-weighted training loss simultaneously.",
        "bibtex": "@InProceedings{pmlr-v180-zhan22a,\n  title = \t {Asymptotic optimality for active learning processes},\n  author =       {Zhan, Xueying and Wang, Yaowei and Chan, Antoni~B.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2342--2352},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/zhan22a/zhan22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/zhan22a.html},\n  abstract = \t {Active Learning (AL) aims to optimize basic learned model(s) iteratively by selecting and annotating unlabeled data samples that are deemed to best maximise the model performance with minimal required data. However, the learned model is easy to overfit due to the biased distribution (sampling bias and dataset shift) formed by non-uniform sampling used in AL. Considering AL as an iterative sequential optimization process, we first provide a perspective on AL in terms of statistical properties, i.e., asymptotic unbiasedness, consistency and asymptotic efficiency, with respect to basic estimators when the sample size (size of labeled set) becomes large, and in the limit as sample size tends to infinity. We then discuss how biases affect AL. Finally, we proposed a flexible AL framework that aims to mitigate the impact of bias in AL by minimizing generalization error and importance-weighted training loss simultaneously.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/zhan22a/zhan22a.pdf",
        "supp": "",
        "pdf_size": 581701,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2773719375767463332&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, City University of Hong Kong, Hong Kong SAR, China + Department of Computing, The Hong Kong Polytechnic University, Hong Kong SAR, China; Department of Computing, The Hong Kong Polytechnic University, Hong Kong SAR, China; Department of Computer Science, City University of Hong Kong, Hong Kong SAR, China",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1;0",
        "aff_unique_norm": "City University of Hong Kong;Hong Kong Polytechnic University",
        "aff_unique_dep": "Department of Computer Science;Department of Computing",
        "aff_unique_url": "https://www.cityu.edu.hk;https://www.polyu.edu.hk",
        "aff_unique_abbr": "CityU;PolyU",
        "aff_campus_unique_index": "0+0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "87e9fc9e34",
        "title": "Attribution of predictive uncertainties in classification models",
        "site": "https://proceedings.mlr.press/v180/perez22a.html",
        "author": "Iker Perez; Piotr Skalski; Alec Barns-Graham; Jason Wong; David Sutton",
        "abstract": "Predictive uncertainties in classification tasks are often a consequence of model inadequacy or insufficient training data. In popular applications, such as image processing, we are often required to scrutinise these uncertainties by meaningfully attributing them to input features. This helps to improve interpretability assessments. However, there exist few effective frameworks for this purpose. Vanilla forms of popular methods for the provision of saliency masks, such as SHAP or integrated gradients, adapt poorly to target measures of uncertainty. Thus, state-of-the-art tools instead proceed by creating counterfactual or adversarial feature vectors, and assign attributions by direct comparison to original images. In this paper, we present a novel framework that combines path integrals, counterfactual explanations and generative models, in order to procure attributions that contain few observable artefacts or noise. We evidence that this outperforms existing alternatives through quantitative evaluations with popular benchmarking methods and data sets of varying complexity.",
        "bibtex": "@InProceedings{pmlr-v180-perez22a,\n  title = \t {Attribution of predictive uncertainties in classification models},\n  author =       {Perez, Iker and Skalski, Piotr and Barns-Graham, Alec and Wong, Jason and Sutton, David},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1582--1591},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/perez22a/perez22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/perez22a.html},\n  abstract = \t {Predictive uncertainties in classification tasks are often a consequence of model inadequacy or insufficient training data. In popular applications, such as image processing, we are often required to scrutinise these uncertainties by meaningfully attributing them to input features. This helps to improve interpretability assessments. However, there exist few effective frameworks for this purpose. Vanilla forms of popular methods for the provision of saliency masks, such as SHAP or integrated gradients, adapt poorly to target measures of uncertainty. Thus, state-of-the-art tools instead proceed by creating counterfactual or adversarial feature vectors, and assign attributions by direct comparison to original images. In this paper, we present a novel framework that combines path integrals, counterfactual explanations and generative models, in order to procure attributions that contain few observable artefacts or noise. We evidence that this outperforms existing alternatives through quantitative evaluations with popular benchmarking methods and data sets of varying complexity.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/perez22a/perez22a.pdf",
        "supp": "",
        "pdf_size": 4034107,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12755747435839513195&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Featurespace Research, Cambridge, United Kingdom; Featurespace Research, Cambridge, United Kingdom; Featurespace Research, Cambridge, United Kingdom; Featurespace Research, Cambridge, United Kingdom; Featurespace Research, Cambridge, United Kingdom",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Featurespace Research",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "fd39e8f24e",
        "title": "Balancing adaptability and non-exploitability in repeated games",
        "site": "https://proceedings.mlr.press/v180/digiovanni22a.html",
        "author": "Anthony DiGiovanni; Ambuj Tewari",
        "abstract": "We study the problem of adaptability in repeated games: simultaneously guaranteeing low regret for several classes of opponents. We add the constraint that our algorithm is non-exploitable, in that the opponent lacks an incentive to use an algorithm against which we cannot achieve rewards exceeding some \u201cfair\u201d value. Our solution is an expert algorithm (LAFF), which searches within a set of sub-algorithms that are optimal for each opponent class, and punishes evidence of exploitation by switching to a policy that enforces a fair solution. With benchmarks that depend on the opponent class, we first show that LAFF has sublinear regret uniformly over  these classes. Second, we show that LAFF discourages exploitation,  because exploitative opponents have linear regret.  To our knowledge, this work is the first to provide guarantees for both regret and non-exploitability in multi-agent learning.",
        "bibtex": "@InProceedings{pmlr-v180-digiovanni22a,\n  title = \t {Balancing adaptability and non-exploitability in repeated games},\n  author =       {DiGiovanni, Anthony and Tewari, Ambuj},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {559--568},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/digiovanni22a/digiovanni22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/digiovanni22a.html},\n  abstract = \t {We study the problem of adaptability in repeated games: simultaneously guaranteeing low regret for several classes of opponents. We add the constraint that our algorithm is non-exploitable, in that the opponent lacks an incentive to use an algorithm against which we cannot achieve rewards exceeding some \u201cfair\u201d value. Our solution is an expert algorithm (LAFF), which searches within a set of sub-algorithms that are optimal for each opponent class, and punishes evidence of exploitation by switching to a policy that enforces a fair solution. With benchmarks that depend on the opponent class, we first show that LAFF has sublinear regret uniformly over  these classes. Second, we show that LAFF discourages exploitation,  because exploitative opponents have linear regret.  To our knowledge, this work is the first to provide guarantees for both regret and non-exploitability in multi-agent learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/digiovanni22a/digiovanni22a.pdf",
        "supp": "",
        "pdf_size": 428675,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3846796433280906159&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Statistics, University of Michigan, Ann Arbor, MI, USA; Department of Statistics, University of Michigan, Ann Arbor, MI, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "658d66554a",
        "title": "Balancing utility and scalability in metric differential privacy",
        "site": "https://proceedings.mlr.press/v180/imola22a.html",
        "author": "Jacob Imola; Shiva Kasiviswanathan; Stephen White; Abhinav Aggarwal; Nathanael Teissier",
        "abstract": "Metric differential privacy (mDP) is a modification of differential privacy that is more suitable when records can be represented in a general metric space, such as text data represented as word embed- dings or geographical coordinates on a map. We consider the task of releasing elements of the metric space under metric differential privacy where utility is measured as the distance of the released element to the original element. Linear programming (LP) can be used to construct a mechanism that achieves the optimal utility for a particular mDP constraint. However, these LPs suffer from a polynomial explosion of variables and constraints that render them impractical for solving real-world problems. An important question is how to design rigorous mDP mechanisms that balance the utility- scalability tradeoff. Our main contribution is a new method for reducing the LP size used to generate mDP mechanisms by constraining the search space such that certain input and output pairs have transition probabilities derived from the exponential mechanism. Our method produces mDP mechanisms whose LPs are smaller that all prior work in this area. We also provide a lower bound on the best possible mechanism utility. Our experiments on real-world metric spaces highlight the superior utility-scalability tradeoff of our mechanism.",
        "bibtex": "@InProceedings{pmlr-v180-imola22a,\n  title = \t {Balancing utility and scalability in metric differential privacy},\n  author =       {Imola, Jacob and Kasiviswanathan, Shiva and White, Stephen and Aggarwal, Abhinav and Teissier, Nathanael},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {885--894},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/imola22a/imola22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/imola22a.html},\n  abstract = \t {Metric differential privacy (mDP) is a modification of differential privacy that is more suitable when records can be represented in a general metric space, such as text data represented as word embed- dings or geographical coordinates on a map. We consider the task of releasing elements of the metric space under metric differential privacy where utility is measured as the distance of the released element to the original element. Linear programming (LP) can be used to construct a mechanism that achieves the optimal utility for a particular mDP constraint. However, these LPs suffer from a polynomial explosion of variables and constraints that render them impractical for solving real-world problems. An important question is how to design rigorous mDP mechanisms that balance the utility- scalability tradeoff. Our main contribution is a new method for reducing the LP size used to generate mDP mechanisms by constraining the search space such that certain input and output pairs have transition probabilities derived from the exponential mechanism. Our method produces mDP mechanisms whose LPs are smaller that all prior work in this area. We also provide a lower bound on the best possible mechanism utility. Our experiments on real-world metric spaces highlight the superior utility-scalability tradeoff of our mechanism.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/imola22a/imola22a.pdf",
        "supp": "",
        "pdf_size": 537897,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2328230629491130487&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "UC San Diego, La Jolla, CA; Amazon, USA; Amazon, USA; Amazon, USA; Amazon, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "University of California, San Diego;Amazon",
        "aff_unique_dep": ";Amazon.com, Inc.",
        "aff_unique_url": "https://ucsd.edu;https://www.amazon.com",
        "aff_unique_abbr": "UCSD;Amazon",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "La Jolla;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "29f2da6705",
        "title": "Bayesian federated estimation of causal effects from observational data",
        "site": "https://proceedings.mlr.press/v180/vo22a.html",
        "author": "Thanh Vinh Vo; Young Lee; Trong Nghia Hoang; Tze-Yun Leong",
        "abstract": "We propose a Bayesian framework for estimating causal effects from federated observational data sources. Bayesian causal inference is an important approach to learning the distribution of the causal estimands and understanding the uncertainty of causal effects. Our framework estimates the posterior distributions of the causal effects to compute the higher-order statistics that capture the uncertainty. We integrate local causal effects from different data sources without centralizing them. We then estimate the treatment effects from observational data using a non-parametric reformulation of the classical potential outcomes framework. We model the potential outcomes as a random function distributed by Gaussian processes, with defining parameters that can be efficiently learned from multiple data sources. Our method avoids exchanging raw data among the sources, thus contributing towards privacy-preserving causal learning. The promise of our approach is demonstrated through a set of simulated and real-world examples.",
        "bibtex": "@InProceedings{pmlr-v180-vo22a,\n  title = \t {Bayesian federated estimation of causal effects from observational data},\n  author =       {Vo, Thanh Vinh and Lee, Young and Hoang, Trong Nghia and Leong, Tze-Yun},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2024--2034},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/vo22a/vo22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/vo22a.html},\n  abstract = \t {We propose a Bayesian framework for estimating causal effects from federated observational data sources. Bayesian causal inference is an important approach to learning the distribution of the causal estimands and understanding the uncertainty of causal effects. Our framework estimates the posterior distributions of the causal effects to compute the higher-order statistics that capture the uncertainty. We integrate local causal effects from different data sources without centralizing them. We then estimate the treatment effects from observational data using a non-parametric reformulation of the classical potential outcomes framework. We model the potential outcomes as a random function distributed by Gaussian processes, with defining parameters that can be efficiently learned from multiple data sources. Our method avoids exchanging raw data among the sources, thus contributing towards privacy-preserving causal learning. The promise of our approach is demonstrated through a set of simulated and real-world examples.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/vo22a/vo22a.pdf",
        "supp": "",
        "pdf_size": 498879,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3436139480554660777&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ba6215ebfa",
        "title": "Bayesian quantile and expectile optimisation",
        "site": "https://proceedings.mlr.press/v180/picheny22a.html",
        "author": "Victor Picheny; Henry Moss; L\u00e9onard Torossian; Nicolas Durrande",
        "abstract": "Bayesian optimisation (BO) is widely used  to optimise stochastic black box functions. While most BO approaches focus on optimising conditional expectations, many applications require risk-averse strategies and alternative criteria accounting for the distribution tails need to be considered. In this paper, we propose new variational models for Bayesian quantile and expectile regression that are well-suited for heteroscedastic noise settings. Our models consist of two latent Gaussian processes accounting respectively for the conditional quantile (or expectile) and the scale parameter of an asymmetric likelihood functions. Furthermore, we propose two BO strategies based on max-value entropy search and Thompson sampling, that are tailored to such models and that can accommodate large batches of points. Contrary to existing BO approaches for risk-averse optimisation, our strategies can directly optimise for the quantile and expectile, without requiring replicating observations or assuming a parametric form for the noise. As illustrated in the experimental section, the proposed approach clearly outperforms the state of the art in the heteroscedastic, non-Gaussian case.",
        "bibtex": "@InProceedings{pmlr-v180-picheny22a,\n  title = \t {Bayesian quantile and expectile optimisation},\n  author =       {Picheny, Victor and Moss, Henry and Torossian, L\\'eonard and Durrande, Nicolas},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1623--1633},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/picheny22a/picheny22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/picheny22a.html},\n  abstract = \t {Bayesian optimisation (BO) is widely used  to optimise stochastic black box functions. While most BO approaches focus on optimising conditional expectations, many applications require risk-averse strategies and alternative criteria accounting for the distribution tails need to be considered. In this paper, we propose new variational models for Bayesian quantile and expectile regression that are well-suited for heteroscedastic noise settings. Our models consist of two latent Gaussian processes accounting respectively for the conditional quantile (or expectile) and the scale parameter of an asymmetric likelihood functions. Furthermore, we propose two BO strategies based on max-value entropy search and Thompson sampling, that are tailored to such models and that can accommodate large batches of points. Contrary to existing BO approaches for risk-averse optimisation, our strategies can directly optimise for the quantile and expectile, without requiring replicating observations or assuming a parametric form for the noise. As illustrated in the experimental section, the proposed approach clearly outperforms the state of the art in the heteroscedastic, non-Gaussian case.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/picheny22a/picheny22a.pdf",
        "supp": "",
        "pdf_size": 867108,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7811674352463024665&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c7415ab3b0",
        "title": "Bayesian spillover graphs for dynamic networks",
        "site": "https://proceedings.mlr.press/v180/deng22a.html",
        "author": "Grace Deng; David S. Matteson",
        "abstract": "We present Bayesian Spillover Graphs (BSG), a novel method for learning temporal relationships, identifying critical nodes, and quantifying uncertainty for multi-horizon spillover effects in a dynamic system. BSG leverages both an interpretable framework via forecast error variance decompositions (FEVD) and comprehensive uncertainty quantification via Bayesian time series models to contextualize temporal relationships in terms of systemic risk and prediction variability. Forecast horizon hyperparameter h allows for learning both short-term and equilibrium state network behaviors. Experiments for identifying source and sink nodes under various graph and error specifications show significant performance gains against state-of-the-art Bayesian Networks and deep-learning baselines. Applications to real-world systems also showcase BSG as an exploratory analysis tool for uncovering indirect spillovers and quantifying systemic risk.",
        "bibtex": "@InProceedings{pmlr-v180-deng22a,\n  title = \t {Bayesian spillover graphs for dynamic networks},\n  author =       {Deng, Grace and Matteson, David S.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {529--538},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/deng22a/deng22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/deng22a.html},\n  abstract = \t {We present Bayesian Spillover Graphs (BSG), a novel method for learning temporal relationships, identifying critical nodes, and quantifying uncertainty for multi-horizon spillover effects in a dynamic system. BSG leverages both an interpretable framework via forecast error variance decompositions (FEVD) and comprehensive uncertainty quantification via Bayesian time series models to contextualize temporal relationships in terms of systemic risk and prediction variability. Forecast horizon hyperparameter h allows for learning both short-term and equilibrium state network behaviors. Experiments for identifying source and sink nodes under various graph and error specifications show significant performance gains against state-of-the-art Bayesian Networks and deep-learning baselines. Applications to real-world systems also showcase BSG as an exploratory analysis tool for uncovering indirect spillovers and quantifying systemic risk.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/deng22a/deng22a.pdf",
        "supp": "",
        "pdf_size": 578094,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1742772968148432572&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Statistics & Data Science, Cornell University, Ithaca, NY, USA; Department of Statistics & Data Science, Cornell University, Ithaca, NY, USA",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "Department of Statistics & Data Science",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ithaca",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0d80af439f",
        "title": "Bayesian structure learning with generative flow networks",
        "site": "https://proceedings.mlr.press/v180/deleu22a.html",
        "author": "Tristan Deleu; Ant\u00f3nio G\u00f3is; Chris Emezue; Mansi Rankawat; Simon Lacoste-Julien; Stefan Bauer; Yoshua Bengio",
        "abstract": "In Bayesian structure learning, we are interested in inferring a distribution over the directed acyclic graph (DAG) structure of Bayesian networks, from data. Defining such a distribution is very challenging, due to the combinatorially large sample space, and approximations based on MCMC are often required. Recently, a novel class of probabilistic models, called Generative Flow Networks (GFlowNets), have been introduced as a general framework for generative modeling of discrete and composite objects, such as graphs. In this work, we propose to use a GFlowNet as an alternative to MCMC for approximating the posterior distribution over the structure of Bayesian networks, given a dataset of observations. Generating a sample DAG from this approximate distribution is viewed as a sequential decision problem, where the graph is constructed one edge at a time, based on learned transition probabilities. Through evaluation on both simulated and real data, we show that our approach, called DAG-GFlowNet, provides an accurate approximation of the posterior over DAGs, and it compares favorably against other methods based on MCMC or variational inference.",
        "bibtex": "@InProceedings{pmlr-v180-deleu22a,\n  title = \t {Bayesian structure learning with generative flow networks},\n  author =       {Deleu, Tristan and G\\'{o}is, Ant\\'{o}nio and Emezue, Chris and Rankawat, Mansi and Lacoste-Julien, Simon and Bauer, Stefan and Bengio, Yoshua},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {518--528},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/deleu22a/deleu22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/deleu22a.html},\n  abstract = \t {In Bayesian structure learning, we are interested in inferring a distribution over the directed acyclic graph (DAG) structure of Bayesian networks, from data. Defining such a distribution is very challenging, due to the combinatorially large sample space, and approximations based on MCMC are often required. Recently, a novel class of probabilistic models, called Generative Flow Networks (GFlowNets), have been introduced as a general framework for generative modeling of discrete and composite objects, such as graphs. In this work, we propose to use a GFlowNet as an alternative to MCMC for approximating the posterior distribution over the structure of Bayesian networks, given a dataset of observations. Generating a sample DAG from this approximate distribution is viewed as a sequential decision problem, where the graph is constructed one edge at a time, based on learned transition probabilities. Through evaluation on both simulated and real data, we show that our approach, called DAG-GFlowNet, provides an accurate approximation of the posterior over DAGs, and it compares favorably against other methods based on MCMC or variational inference.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/deleu22a/deleu22a.pdf",
        "supp": "",
        "pdf_size": 567176,
        "gs_citation": 169,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2612870162252151595&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Mila, Universit\u00e9 de Montr\u00e9al; Mila, Universit\u00e9 de Montr\u00e9al; Technical University of Munich; Mila, Universit\u00e9 de Montr\u00e9al; Mila, Universit\u00e9 de Montr\u00e9al+CIFAR AI Chair; KTH Stockholm+CIFAR Azrieli Global Scholar; Mila, Universit\u00e9 de Montr\u00e9al+CIFAR Senior Fellow",
        "aff_domain": "mila.quebec; ; ; ; ; ; ",
        "email": "mila.quebec; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0+2;3+2;0+2",
        "aff_unique_norm": "Universit\u00e9 de Montr\u00e9al;Technical University of Munich;CIFAR;KTH Royal Institute of Technology",
        "aff_unique_dep": "Mila;;AI Chair;",
        "aff_unique_url": "https://umontreal.ca;https://www.tum.de;https://www.cifar.ca;https://www.kth.se",
        "aff_unique_abbr": "UdeM;TUM;CIFAR;KTH",
        "aff_campus_unique_index": "0;0;0;0;2;0",
        "aff_campus_unique": "Montr\u00e9al;;Stockholm",
        "aff_country_unique_index": "0;0;1;0;0+0;2+0;0+0",
        "aff_country_unique": "Canada;Germany;Sweden"
    },
    {
        "id": "337db22b3b",
        "title": "Bias aware probabilistic Boolean matrix factorization",
        "site": "https://proceedings.mlr.press/v180/wan22a.html",
        "author": "Changlin Wan; Pengtao Dang; Tong Zhao; Yong Zang; Chi Zhang; Sha Cao",
        "abstract": "Boolean matrix factorization (BMF) is a combinatorial problem arising from a wide range of applications including recommendation system, collaborative filtering, and dimensionality reduction. Currently, the noise model of existing BMF methods is often assumed to be homoscedastic; however, in real world data scenarios, the deviations of observed data from their true values are almost surely diverse due to stochastic noises, making  each data point not equally suitable for fitting a model. In this case, it is not ideal to treat all data points as equally distributed. Motivated by such observations, we introduce a probabilistic BMF model that recognizes the object- and feature-wise bias distribution respectively, called bias aware BMF (BABF). To the best of our knowledge, BABF is the first approach for Boolean decomposition with consideration of the feature-wise and object-wise bias in binary data. We conducted experiments on datasets with different levels of background noise, bias level, and sizes of the signal patterns, to test the effectiveness of our method in various scenarios. We demonstrated that our model outperforms the state-of-the-art factorization methods in both accuracy and efficiency in recovering the original datasets, and the inferred bias level is highly  significantly correlated with true existing bias in both simulated and real world datasets.",
        "bibtex": "@InProceedings{pmlr-v180-wan22a,\n  title = \t {Bias aware probabilistic Boolean matrix factorization},\n  author =       {Wan, Changlin and Dang, Pengtao and Zhao, Tong and Zang, Yong and Zhang, Chi and Cao, Sha},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2035--2044},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/wan22a/wan22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/wan22a.html},\n  abstract = \t {Boolean matrix factorization (BMF) is a combinatorial problem arising from a wide range of applications including recommendation system, collaborative filtering, and dimensionality reduction. Currently, the noise model of existing BMF methods is often assumed to be homoscedastic; however, in real world data scenarios, the deviations of observed data from their true values are almost surely diverse due to stochastic noises, making  each data point not equally suitable for fitting a model. In this case, it is not ideal to treat all data points as equally distributed. Motivated by such observations, we introduce a probabilistic BMF model that recognizes the object- and feature-wise bias distribution respectively, called bias aware BMF (BABF). To the best of our knowledge, BABF is the first approach for Boolean decomposition with consideration of the feature-wise and object-wise bias in binary data. We conducted experiments on datasets with different levels of background noise, bias level, and sizes of the signal patterns, to test the effectiveness of our method in various scenarios. We demonstrated that our model outperforms the state-of-the-art factorization methods in both accuracy and efficiency in recovering the original datasets, and the inferred bias level is highly  significantly correlated with true existing bias in both simulated and real world datasets. }\n}",
        "pdf": "https://proceedings.mlr.press/v180/wan22a/wan22a.pdf",
        "supp": "",
        "pdf_size": 889958,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15226520435340181885&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f582ee2d34",
        "title": "Binary independent component analysis: a non-stationarity-based approach",
        "site": "https://proceedings.mlr.press/v180/hyttinen22a.html",
        "author": "Antti Hyttinen; Vit\u00f3ria Barin Pacela; Aapo Hyv\u00e4rinen",
        "abstract": "We consider independent component analysis of binary data. While fundamental in practice, this case has been much less developed than ICA for continuous data. We start by assuming a linear mixing model in a continuous-valued latent space, followed by a binary observation model. Importantly, we assume that the sources are non-stationary; this is necessary since any non-Gaussianity would essentially be destroyed by the binarization. Interestingly, the model allows for closed-form likelihood by employing the cumulative distribution function of the multivariate Gaussian distribution. In stark contrast to the continuous-valued case, we prove non-identifiability of the model with few observed variables; our empirical results imply identifiability when the number of observed variables is higher. We present a practical method for binary ICA that uses only pairwise marginals, which are faster to compute than the full multivariate likelihood. Experiments give insight into the requirements for the number of observed variables, segments, and latent sources that allow the model to be estimated.",
        "bibtex": "@InProceedings{pmlr-v180-hyttinen22a,\n  title = \t {Binary independent component analysis: a non-stationarity-based approach},\n  author =       {Hyttinen, Antti and Barin Pacela, Vit{\\'o}ria and Hyv{\\\"a}rinen, Aapo},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {874--884},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/hyttinen22a/hyttinen22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/hyttinen22a.html},\n  abstract = \t {We consider independent component analysis of binary data. While fundamental in practice, this case has been much less developed than ICA for continuous data. We start by assuming a linear mixing model in a continuous-valued latent space, followed by a binary observation model. Importantly, we assume that the sources are non-stationary; this is necessary since any non-Gaussianity would essentially be destroyed by the binarization. Interestingly, the model allows for closed-form likelihood by employing the cumulative distribution function of the multivariate Gaussian distribution. In stark contrast to the continuous-valued case, we prove non-identifiability of the model with few observed variables; our empirical results imply identifiability when the number of observed variables is higher. We present a practical method for binary ICA that uses only pairwise marginals, which are faster to compute than the full multivariate likelihood. Experiments give insight into the requirements for the number of observed variables, segments, and latent sources that allow the model to be estimated.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/hyttinen22a/hyttinen22a.pdf",
        "supp": "",
        "pdf_size": 508494,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8072570856787658263&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ef52e23a39",
        "title": "Byzantine-tolerant distributed multiclass sparse linear discriminant analysis",
        "site": "https://proceedings.mlr.press/v180/bao22b.html",
        "author": "Yajie Bao; Weidong Liu; Xiaojun Mao; Weijia Xiong",
        "abstract": "Communication cost and security issues are both important in large-scale distributed machine learning. In this paper, we investigate a multiclass sparse classification problem under two distributed systems. We propose two distributed multiclass sparse discriminant analysis algorithms based on mean-aggregation and median-aggregation under the normal distributed system or Byzantine failure system. Both of them are computation and communication efficient. Several theoretical results, including estimation error bounds, and support recovery, are established. With moderate initial estimators, our iterative estimators achieve a (near-)optimal rate and exact support recovery after a constant number of rounds. Experiments on both synthetic and real datasets are provided to demonstrate the effectiveness of our proposed methods.",
        "bibtex": "@InProceedings{pmlr-v180-bao22b,\n  title = \t {Byzantine-tolerant distributed multiclass sparse linear discriminant analysis},\n  author =       {Bao, Yajie and Liu, Weidong and Mao, Xiaojun and Xiong, Weijia},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {129--138},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/bao22b/bao22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/bao22b.html},\n  abstract = \t {Communication cost and security issues are both important in large-scale distributed machine learning. In this paper, we investigate a multiclass sparse classification problem under two distributed systems. We propose two distributed multiclass sparse discriminant analysis algorithms based on mean-aggregation and median-aggregation under the normal distributed system or Byzantine failure system. Both of them are computation and communication efficient. Several theoretical results, including estimation error bounds, and support recovery, are established. With moderate initial estimators, our iterative estimators achieve a (near-)optimal rate and exact support recovery after a constant number of rounds. Experiments on both synthetic and real datasets are provided to demonstrate the effectiveness of our proposed methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/bao22b/bao22b.pdf",
        "supp": "",
        "pdf_size": 403223,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3262336482811894080&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "School of Mathematical Sciences, Shanghai Jiao Tong University, Shanghai, China + MoE Key Lab of Arti\ufb01cial Intelligence, Shanghai Jiao Tong University, Shanghai, China; School of Mathematical Sciences, Shanghai Jiao Tong University, Shanghai, China + MoE Key Lab of Arti\ufb01cial Intelligence, Shanghai Jiao Tong University, Shanghai, China; School of Mathematical Sciences, Shanghai Jiao Tong University, Shanghai, China; School of Public Health, The University of Hong Kong, Hong Kong, China",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0+0;0;1",
        "aff_unique_norm": "Shanghai Jiao Tong University;University of Hong Kong",
        "aff_unique_dep": "School of Mathematical Sciences;School of Public Health",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.hku.hk",
        "aff_unique_abbr": "SJTU;HKU",
        "aff_campus_unique_index": "0+0;0+0;0;1",
        "aff_campus_unique": "Shanghai;Hong Kong",
        "aff_country_unique_index": "0+0;0+0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "cf444799f6",
        "title": "CIGMO: Categorical invariant representations in a deep generative framework",
        "site": "https://proceedings.mlr.press/v180/hosoya22a.html",
        "author": "Haruo Hosoya",
        "abstract": "Data of general object images have two most common structures: (1) each object of a given shape can be rendered in multiple different views, and (2) shapes of objects can be categorized in such a way that the diversity of shapes is much larger across categories than within a category.  Existing deep generative models can typically capture either structure, but not both.  In this work, we introduce a novel deep generative model, called CIGMO, that can learn to represent category, shape, and view factors from image data.  The model is comprised of multiple modules of shape representations that are each specialized to a particular category and disentangled from view representation, and can be learned using a group-based weakly supervised learning method.  By empirical investigation, we show that our model can effectively discover categories of object shapes despite large view variation and quantitatively supersede various previous methods including the state-of-the-art invariant clustering algorithm.  Further, we show that our approach using category-specialization can enhance the learned shape representation to better perform down-stream tasks such as one-shot object identification as well as shape-view disentanglement.",
        "bibtex": "@InProceedings{pmlr-v180-hosoya22a,\n  title = \t {CIGMO: Categorical invariant representations in a deep generative framework},\n  author =       {Hosoya, Haruo},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {833--843},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/hosoya22a/hosoya22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/hosoya22a.html},\n  abstract = \t {Data of general object images have two most common structures: (1) each object of a given shape can be rendered in multiple different views, and (2) shapes of objects can be categorized in such a way that the diversity of shapes is much larger across categories than within a category.  Existing deep generative models can typically capture either structure, but not both.  In this work, we introduce a novel deep generative model, called CIGMO, that can learn to represent category, shape, and view factors from image data.  The model is comprised of multiple modules of shape representations that are each specialized to a particular category and disentangled from view representation, and can be learned using a group-based weakly supervised learning method.  By empirical investigation, we show that our model can effectively discover categories of object shapes despite large view variation and quantitatively supersede various previous methods including the state-of-the-art invariant clustering algorithm.  Further, we show that our approach using category-specialization can enhance the learned shape representation to better perform down-stream tasks such as one-shot object identification as well as shape-view disentanglement.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/hosoya22a/hosoya22a.pdf",
        "supp": "",
        "pdf_size": 1324930,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Sum5j3XAM3wJ:scholar.google.com/&scioq=CIGMO:+Categorical+invariant+representations+in+a+deep+generative+framework&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": "Brain Labs., ATR International, Kyoto, Japan",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "ATR International",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Kyoto",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "85be16287e",
        "title": "Calibrated ensembles can mitigate accuracy tradeoffs under distribution shift",
        "site": "https://proceedings.mlr.press/v180/kumar22a.html",
        "author": "Ananya Kumar; Tengyu Ma; Percy Liang; Aditi Raghunathan",
        "abstract": "We often see undesirable tradeoffs in robust machine learning where out-of-distribution (OOD) accuracy is at odds with in-distribution (ID) accuracy. A robust classifier obtained via specialized techniques such as removing spurious features often has better OOD but worse ID accuracy compared to a standard classifier trained via vanilla ERM. In this paper, we find that a simple approach of ensembling the standard and robust models, after calibrating on only ID data, outperforms prior state-of-the-art both ID and OOD. On ten natural distribution shift datasets, ID-calibrated ensembles get the best of both worlds: strong ID accuracy of the standard model and OOD accuracy of the robust model. We analyze this method in stylized settings, and identify two important conditions for ensembles to perform well on both ID and OOD: (1) standard and robust models should be calibrated (on ID data, because OOD data is unavailable), (2) OOD has no anticorrelated spurious features.",
        "bibtex": "@InProceedings{pmlr-v180-kumar22a,\n  title = \t {Calibrated ensembles can mitigate accuracy tradeoffs under distribution shift},\n  author =       {Kumar, Ananya and Ma, Tengyu and Liang, Percy and Raghunathan, Aditi},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1041--1051},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/kumar22a/kumar22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/kumar22a.html},\n  abstract = \t {We often see undesirable tradeoffs in robust machine learning where out-of-distribution (OOD) accuracy is at odds with in-distribution (ID) accuracy. A robust classifier obtained via specialized techniques such as removing spurious features often has better OOD but worse ID accuracy compared to a standard classifier trained via vanilla ERM. In this paper, we find that a simple approach of ensembling the standard and robust models, after calibrating on only ID data, outperforms prior state-of-the-art both ID and OOD. On ten natural distribution shift datasets, ID-calibrated ensembles get the best of both worlds: strong ID accuracy of the standard model and OOD accuracy of the robust model. We analyze this method in stylized settings, and identify two important conditions for ensembles to perform well on both ID and OOD: (1) standard and robust models should be calibrated (on ID data, because OOD data is unavailable), (2) OOD has no anticorrelated spurious features.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/kumar22a/kumar22a.pdf",
        "supp": "",
        "pdf_size": 603284,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6541144457777683346&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1f0f29711e",
        "title": "Can mean field control (mfc) approximate cooperative multi agent reinforcement learning (marl) with non-uniform interaction?",
        "site": "https://proceedings.mlr.press/v180/mondal22a.html",
        "author": "Washim Uddin Mondal; Vaneet Aggarwal; Satish V. Ukkusuri",
        "abstract": "Mean-Field Control (MFC) is a powerful tool to solve Multi-Agent Reinforcement Learning (MARL) problems. Recent studies have shown that MFC can well-approximate MARL when the population size is large and the agents are exchangeable. Unfortunately, the presumption of exchangeability implies that all agents uniformly interact with one another which is not true in many practical scenarios. In this article, we relax the assumption of exchangeability and model the interaction between agents via an arbitrary doubly stochastic matrix. As a result, in our framework, the mean-field \u2018seen\u2019 by different agents are different. We prove that, if the reward of each agent is an affine function of the mean-field seen by that agent, then one can approximate such a non-uniform MARL problem via its associated MFC problem within an error of $e=\\mathcal{O}(\\frac{1}{\\sqrt{N}}[\\sqrt{|\\mathcal{X}|} + \\sqrt{|\\mathcal{U}|}])$ where $N$ is the population size and $|\\mathcal{X}|$, $|\\mathcal{U}|$ are the sizes of state and action spaces respectively. Finally, we develop a Natural Policy Gradient (NPG) algorithm that can provide a solution to the non-uniform MARL with an error $\\mathcal{O}(\\max\\{e,\\epsilon\\})$ and a sample complexity of $\\mathcal{O}(\\epsilon^{-3})$ for any $\\epsilon >0$.",
        "bibtex": "@InProceedings{pmlr-v180-mondal22a,\n  title = \t {Can mean field control (mfc) approximate cooperative multi agent reinforcement learning (marl) with non-uniform interaction?},\n  author =       {Mondal, Washim Uddin and Aggarwal, Vaneet and Ukkusuri, Satish V.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1371--1380},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/mondal22a/mondal22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/mondal22a.html},\n  abstract = \t {Mean-Field Control (MFC) is a powerful tool to solve Multi-Agent Reinforcement Learning (MARL) problems. Recent studies have shown that MFC can well-approximate MARL when the population size is large and the agents are exchangeable. Unfortunately, the presumption of exchangeability implies that all agents uniformly interact with one another which is not true in many practical scenarios. In this article, we relax the assumption of exchangeability and model the interaction between agents via an arbitrary doubly stochastic matrix. As a result, in our framework, the mean-field \u2018seen\u2019 by different agents are different. We prove that, if the reward of each agent is an affine function of the mean-field seen by that agent, then one can approximate such a non-uniform MARL problem via its associated MFC problem within an error of $e=\\mathcal{O}(\\frac{1}{\\sqrt{N}}[\\sqrt{|\\mathcal{X}|} + \\sqrt{|\\mathcal{U}|}])$ where $N$ is the population size and $|\\mathcal{X}|$, $|\\mathcal{U}|$ are the sizes of state and action spaces respectively. Finally, we develop a Natural Policy Gradient (NPG) algorithm that can provide a solution to the non-uniform MARL with an error $\\mathcal{O}(\\max\\{e,\\epsilon\\})$ and a sample complexity of $\\mathcal{O}(\\epsilon^{-3})$ for any $\\epsilon >0$.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/mondal22a/mondal22a.pdf",
        "supp": "",
        "pdf_size": 347590,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12753088133830251583&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e7f13aa330",
        "title": "Capturing actionable dynamics with structured latent ordinary differential equations",
        "site": "https://proceedings.mlr.press/v180/chapfuwa22a.html",
        "author": "Paidamoyo Chapfuwa; Sherri Rose; Lawrence Carin; Edward Meeds; Ricardo Henao",
        "abstract": "End-to-end learning of dynamical systems with black-box models, such as neural ordinary differential equations (ODEs), provides a flexible framework for learning dynamics from data without prescribing a mathematical model for the dynamics. Unfortunately, this flexibility comes at the cost of understanding the dynamical system, for which ODEs are used ubiquitously. Further, experimental data are collected under various conditions (inputs), such as treatments, or grouped in some way, such as part of sub-populations. Understanding the effects of these system inputs on system outputs is crucial to have any meaningful model of a dynamical system. To that end, we propose a structured latent ODE model that explicitly captures system input variations within its latent representation. Building on a static latent variable specification, our model learns (independent) stochastic factors of variation for each input to the system, thus separating the effects of the system inputs in the latent space. This approach provides actionable modeling through the controlled generation of time-series data for novel input combinations (or perturbations). Additionally, we propose a flexible approach for quantifying uncertainties, leveraging a quantile regression formulation. Results on challenging biological datasets show consistent improvements over competitive baselines in the controlled generation of observational data and inference of biologically meaningful system inputs.",
        "bibtex": "@InProceedings{pmlr-v180-chapfuwa22a,\n  title = \t {Capturing actionable dynamics with structured latent ordinary differential equations},\n  author =       {Chapfuwa, Paidamoyo and Rose, Sherri and Carin, Lawrence and Meeds, Edward and Henao, Ricardo},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {286--295},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/chapfuwa22a/chapfuwa22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/chapfuwa22a.html},\n  abstract = \t {End-to-end learning of dynamical systems with black-box models, such as neural ordinary differential equations (ODEs), provides a flexible framework for learning dynamics from data without prescribing a mathematical model for the dynamics. Unfortunately, this flexibility comes at the cost of understanding the dynamical system, for which ODEs are used ubiquitously. Further, experimental data are collected under various conditions (inputs), such as treatments, or grouped in some way, such as part of sub-populations. Understanding the effects of these system inputs on system outputs is crucial to have any meaningful model of a dynamical system. To that end, we propose a structured latent ODE model that explicitly captures system input variations within its latent representation. Building on a static latent variable specification, our model learns (independent) stochastic factors of variation for each input to the system, thus separating the effects of the system inputs in the latent space. This approach provides actionable modeling through the controlled generation of time-series data for novel input combinations (or perturbations). Additionally, we propose a flexible approach for quantifying uncertainties, leveraging a quantile regression formulation. Results on challenging biological datasets show consistent improvements over competitive baselines in the controlled generation of observational data and inference of biologically meaningful system inputs.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/chapfuwa22a/chapfuwa22a.pdf",
        "supp": "",
        "pdf_size": 587105,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:KlKsCRplN_sJ:scholar.google.com/&scioq=Capturing+actionable+dynamics+with+structured+latent+ordinary+differential+equations&hl=en&as_sdt=0,33",
        "gs_version_total": 9,
        "aff": "Stanford University, USA; Stanford University, USA; KAUST, Saudi Arabia; Microsoft Research, Cambridge, UK; Duke University, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;3",
        "aff_unique_norm": "Stanford University;King Abdullah University of Science and Technology;Microsoft;Duke University",
        "aff_unique_dep": ";;Microsoft Research;",
        "aff_unique_url": "https://www.stanford.edu;https://www.kaust.edu.sa;https://www.microsoft.com/en-us/research;https://www.duke.edu",
        "aff_unique_abbr": "Stanford;KAUST;MSR;Duke",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Stanford;;Cambridge",
        "aff_country_unique_index": "0;0;1;2;0",
        "aff_country_unique": "United States;Saudi Arabia;United Kingdom"
    },
    {
        "id": "db9766681e",
        "title": "Case-based off-policy evaluation using prototype learning",
        "site": "https://proceedings.mlr.press/v180/matsson22a.html",
        "author": "Anton Matsson; Fredrik D. Johansson",
        "abstract": "Importance sampling (IS) is often used to perform off-policy evaluation but it is prone to several issues\u2014especially when the behavior policy is unknown and must be estimated from data. Significant differences between target and behavior policies can result in uncertain value estimates due to, for example, high variance. Standard practices such as inspecting IS weights may be insufficient to diagnose such problems and determine for which type of inputs the policies differ in suggested actions and resulting values. To address this, we propose estimating the behavior policy for IS using prototype learning. The learned prototypes provide a condensed summary of the input-action space, which allows for describing differences between policies and assessing the support for evaluating a certain target policy. In addition, we can describe a value estimate in terms of prototypes to understand which parts of the target policy have the most impact on the estimate. We find that this provides new insights in the examination of a learned policy for sepsis management. Moreover, we study the bias resulting from restricting models to use prototypes, how bias propagates to IS weights and estimated values and how this varies with history length.",
        "bibtex": "@InProceedings{pmlr-v180-matsson22a,\n  title = \t {Case-based off-policy evaluation using prototype learning},\n  author =       {Matsson, Anton and Johansson, Fredrik D.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1339--1349},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/matsson22a/matsson22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/matsson22a.html},\n  abstract = \t {Importance sampling (IS) is often used to perform off-policy evaluation but it is prone to several issues\u2014especially when the behavior policy is unknown and must be estimated from data. Significant differences between target and behavior policies can result in uncertain value estimates due to, for example, high variance. Standard practices such as inspecting IS weights may be insufficient to diagnose such problems and determine for which type of inputs the policies differ in suggested actions and resulting values. To address this, we propose estimating the behavior policy for IS using prototype learning. The learned prototypes provide a condensed summary of the input-action space, which allows for describing differences between policies and assessing the support for evaluating a certain target policy. In addition, we can describe a value estimate in terms of prototypes to understand which parts of the target policy have the most impact on the estimate. We find that this provides new insights in the examination of a learned policy for sepsis management. Moreover, we study the bias resulting from restricting models to use prototypes, how bias propagates to IS weights and estimated values and how this varies with history length.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/matsson22a/matsson22a.pdf",
        "supp": "",
        "pdf_size": 773283,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=643633692834226757&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Chalmers University of Technology; Chalmers University of Technology",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Chalmers University of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.chalmers.se",
        "aff_unique_abbr": "Chalmers",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "965bf581cb",
        "title": "Causal discovery under a confounder blanket",
        "site": "https://proceedings.mlr.press/v180/watson22a.html",
        "author": "David S. Watson; Ricardo Silva",
        "abstract": "Inferring causal relationships from observational data is rarely straightforward, but the problem is especially difficult in high dimensions. For these applications, causal discovery algorithms typically require parametric restrictions or extreme sparsity constraints. We relax these assumptions and focus on an important but more specialized problem, namely recovering the causal order among a subgraph of variables known to descend from some (possibly large) set of confounding covariates, i.e. a $\\textit{confounder blanket}$. This is useful in many settings, for example when studying a dynamic biomolecular subsystem with genetic data providing background information. Under a structural assumption called the $\\textit{confounder blanket principle}$, which we argue is essential for tractable causal discovery in high dimensions, our method accommodates graphs of low or high sparsity while maintaining polynomial time complexity. We present a structure learning algorithm that is provably sound and complete with respect to a so-called $\\textit{lazy oracle}$. We design inference procedures with finite sample error control for linear and nonlinear systems, and demonstrate our approach on a range of simulated and real-world datasets. An accompanying $\\texttt{R}$ package, $\\texttt{cbl}$, is available from $\\texttt{CRAN}$.",
        "bibtex": "@InProceedings{pmlr-v180-watson22a,\n  title = \t {Causal discovery under a confounder blanket},\n  author =       {Watson, David S. and Silva, Ricardo},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2096--2106},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/watson22a/watson22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/watson22a.html},\n  abstract = \t {Inferring causal relationships from observational data is rarely straightforward, but the problem is especially difficult in high dimensions. For these applications, causal discovery algorithms typically require parametric restrictions or extreme sparsity constraints. We relax these assumptions and focus on an important but more specialized problem, namely recovering the causal order among a subgraph of variables known to descend from some (possibly large) set of confounding covariates, i.e. a $\\textit{confounder blanket}$. This is useful in many settings, for example when studying a dynamic biomolecular subsystem with genetic data providing background information. Under a structural assumption called the $\\textit{confounder blanket principle}$, which we argue is essential for tractable causal discovery in high dimensions, our method accommodates graphs of low or high sparsity while maintaining polynomial time complexity. We present a structure learning algorithm that is provably sound and complete with respect to a so-called $\\textit{lazy oracle}$. We design inference procedures with finite sample error control for linear and nonlinear systems, and demonstrate our approach on a range of simulated and real-world datasets. An accompanying $\\texttt{R}$ package, $\\texttt{cbl}$, is available from $\\texttt{CRAN}$.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/watson22a/watson22a.pdf",
        "supp": "",
        "pdf_size": 574685,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4887138072580474687&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Statistical Science, University College London, London, UK; Department of Statistical Science, University College London, London, UK",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "https://cran.r-project.org/package=cbl",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Department of Statistical Science",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "a0176ac9b5",
        "title": "Causal discovery with heterogeneous observational data",
        "site": "https://proceedings.mlr.press/v180/zhou22a.html",
        "author": "Fangting Zhou; Kejun He; Yang Ni",
        "abstract": "We consider the problem of causal discovery (structure learning) from heterogeneous observational data. Most existing methods assume homogeneous sampling scheme and causal mechanism, which may lead to misleading conclusions when violated. We propose a novel approach that exploits data heterogeneity to infer possibly cyclic causal structures from causally insufficient systems. The core idea is to model the direct causal effects as functions of exogenous covariates that help explain sampling and causal heterogeneity. We investigate the structure identifiability properties of the proposed model. Structure learning is carried out in a fully Bayesian fashion, which provides natural uncertainty quantification. We demonstrate its utility through extensive simulations and two real-world applications.",
        "bibtex": "@InProceedings{pmlr-v180-zhou22a,\n  title = \t {Causal discovery with heterogeneous observational data},\n  author =       {Zhou, Fangting and He, Kejun and Ni, Yang},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2383--2393},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/zhou22a/zhou22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/zhou22a.html},\n  abstract = \t {We consider the problem of causal discovery (structure learning) from heterogeneous observational data. Most existing methods assume homogeneous sampling scheme and causal mechanism, which may lead to misleading conclusions when violated. We propose a novel approach that exploits data heterogeneity to infer possibly cyclic causal structures from causally insufficient systems. The core idea is to model the direct causal effects as functions of exogenous covariates that help explain sampling and causal heterogeneity. We investigate the structure identifiability properties of the proposed model. Structure learning is carried out in a fully Bayesian fashion, which provides natural uncertainty quantification. We demonstrate its utility through extensive simulations and two real-world applications.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/zhou22a/zhou22a.pdf",
        "supp": "",
        "pdf_size": 1324447,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4748723169259848535&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a1a8dd249e",
        "title": "Causal forecasting: generalization bounds for autoregressive models",
        "site": "https://proceedings.mlr.press/v180/vankadara22a.html",
        "author": "Leena Chennuru Vankadara; Philipp Michael Faller; Michaela Hardt; Lenon Minorics; Debarghya Ghoshdastidar; Dominik Janzing",
        "abstract": "Despite the increasing relevance of forecasting methods, causal implications of these algorithms remain largely unexplored. This is concerning considering that, even under simplifying assumptions such as causal sufficiency, the statistical risk of a model can differ significantly from its causal risk. Here, we study the problem of causal generalization\u2014generalizing from the observational to interventional distributions\u2014in forecasting. Our goal is to find answers to the question: How does the efficacy of an autoregressive (VAR) model in predicting statistical associations compare with its ability to predict under interventions? To this end, we introduce the framework of causal learning theory for forecasting. Using this framework, we obtain a characterization of the difference between statistical and causal risks, which helps identify sources of divergence between them. Under causal sufficiency, the problem of causal generalization amounts to learning under covariate shifts albeit with additional structure (restriction to interventional distributions under the VAR model). This structure allows us to obtain uniform convergence bounds on causal generalizability for the class of VAR models. To the best of our knowledge, this is the first work that provides theoretical guarantees for causal generalization in the time-series setting.",
        "bibtex": "@InProceedings{pmlr-v180-vankadara22a,\n  title = \t {Causal forecasting: generalization bounds for autoregressive models},\n  author =       {Vankadara, Leena Chennuru and Faller, Philipp Michael and Hardt, Michaela and Minorics, Lenon and Ghoshdastidar, Debarghya and Janzing, Dominik},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2002--2012},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/vankadara22a/vankadara22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/vankadara22a.html},\n  abstract = \t {Despite the increasing relevance of forecasting methods, causal implications of these algorithms remain largely unexplored. This is concerning considering that, even under simplifying assumptions such as causal sufficiency, the statistical risk of a model can differ significantly from its causal risk. Here, we study the problem of causal generalization\u2014generalizing from the observational to interventional distributions\u2014in forecasting. Our goal is to find answers to the question: How does the efficacy of an autoregressive (VAR) model in predicting statistical associations compare with its ability to predict under interventions? To this end, we introduce the framework of causal learning theory for forecasting. Using this framework, we obtain a characterization of the difference between statistical and causal risks, which helps identify sources of divergence between them. Under causal sufficiency, the problem of causal generalization amounts to learning under covariate shifts albeit with additional structure (restriction to interventional distributions under the VAR model). This structure allows us to obtain uniform convergence bounds on causal generalizability for the class of VAR models. To the best of our knowledge, this is the first work that provides theoretical guarantees for causal generalization in the time-series setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/vankadara22a/vankadara22a.pdf",
        "supp": "",
        "pdf_size": 586525,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2453693723778584390&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of T\u00fcbingen; Amazon Research; Amazon Research; Amazon Research; Technical University of Munich, Munich Data Science Institute; Amazon Research",
        "aff_domain": "uni-tuebingen.de;amazon.com;amazon.com;amazon.com;tum.de;amazon.com",
        "email": "uni-tuebingen.de;amazon.com;amazon.com;amazon.com;tum.de;amazon.com",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;2;1",
        "aff_unique_norm": "University of T\u00fcbingen;Amazon;Technical University of Munich",
        "aff_unique_dep": ";Amazon Research;Munich Data Science Institute",
        "aff_unique_url": "https://www.uni-tuebingen.de/;https://www.amazon.science;https://www.tum.de",
        "aff_unique_abbr": "Uni T\u00fcbingen;Amazon;TUM",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Munich",
        "aff_country_unique_index": "0;1;1;1;0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "982759faf9",
        "title": "Causal inference with treatment measurement error: a nonparametric instrumental variable approach",
        "site": "https://proceedings.mlr.press/v180/zhu22a.html",
        "author": "Yuchen Zhu; Limor Gultchin; Arthur Gretton; Matt J. Kusner; Ricardo Silva",
        "abstract": "We propose a kernel-based nonparametric estimator for the causal effect when the cause is corrupted by error. We do so by generalizing estimation in the instrumental variable setting. Despite significant work on regression with measurement error, additionally handling unobserved confounding in the continuous setting is non-trivial: we have seen little prior work. As a by-product of our investigation, we clarify a connection between mean embeddings and characteristic functions, and how learning one simultaneously allows one to learn the other. This opens the way for kernel method research to leverage existing results in characteristic function estimation. Finally, we empirically show that our proposed method, MEKIV, improves over baselines and is robust under changes in the strength of measurement error and to the type of error distributions.",
        "bibtex": "@InProceedings{pmlr-v180-zhu22a,\n  title = \t {Causal inference with treatment measurement error: a nonparametric instrumental variable approach},\n  author =       {Zhu, Yuchen and Gultchin, Limor and Gretton, Arthur and Kusner, Matt J. and Silva, Ricardo},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2414--2424},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/zhu22a/zhu22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/zhu22a.html},\n  abstract = \t {We propose a kernel-based nonparametric estimator for the causal effect when the cause is corrupted by error. We do so by generalizing estimation in the instrumental variable setting. Despite significant work on regression with measurement error, additionally handling unobserved confounding in the continuous setting is non-trivial: we have seen little prior work. As a by-product of our investigation, we clarify a connection between mean embeddings and characteristic functions, and how learning one simultaneously allows one to learn the other. This opens the way for kernel method research to leverage existing results in characteristic function estimation. Finally, we empirically show that our proposed method, MEKIV, improves over baselines and is robust under changes in the strength of measurement error and to the type of error distributions.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/zhu22a/zhu22a.pdf",
        "supp": "",
        "pdf_size": 606951,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7455172804667830489&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, University College London, UK; Department of Computer Science, University of Oxford, UK + The Alan Turing Institute, London, UK; Department of Computer Science, University College London, UK; Department of Computer Science, University College London, UK; Department of Computer Science, University College London, UK",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;0;0;0",
        "aff_unique_norm": "University College London;University of Oxford;Alan Turing Institute",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science;",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.ox.ac.uk;https://www.turing.ac.uk",
        "aff_unique_abbr": "UCL;Oxford;ATI",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";London",
        "aff_country_unique_index": "0;0+0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "3b435a2ef6",
        "title": "Clustering a union of linear subspaces via matrix factorization and innovation search",
        "site": "https://proceedings.mlr.press/v180/rahmani22a.html",
        "author": "Mostafa Rahmani",
        "abstract": "This paper focuses on the Matrix Factorization based Clustering (MFC) method  which is one of the few closed-form algorithms for the subspace clustering algorithm. Despite being simple, closed-form, and computation-efficient, MFC can outperform the other sophisticated subspace clustering methods in many challenging scenarios. We reveal the connection between MFC and the Innovation Pursuit (iPursuit) algorithm which was shown to be able to outperform the other spectral clustering based methods with a notable margin especially when the span of clusters are close. A novel theoretical study is presented which sheds light on the key performance factors of both algorithms (MFC/iPursuit) and  it is shown that both algorithms can be robust to notable intersections between the span of  clusters. Importantly, in contrast to the theoretical guarantees of other algorithms which emphasized on the distance between the subspaces as the key performance factor and without making the innovation assumption, it is shown that the performance of MFC/iPursuit mainly depends on the distance between the innovative components of the clusters.",
        "bibtex": "@InProceedings{pmlr-v180-rahmani22a,\n  title = \t {Clustering a union of linear subspaces via matrix factorization and innovation search},\n  author =       {Rahmani, Mostafa},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1654--1664},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/rahmani22a/rahmani22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/rahmani22a.html},\n  abstract = \t {This paper focuses on the Matrix Factorization based Clustering (MFC) method  which is one of the few closed-form algorithms for the subspace clustering algorithm. Despite being simple, closed-form, and computation-efficient, MFC can outperform the other sophisticated subspace clustering methods in many challenging scenarios. We reveal the connection between MFC and the Innovation Pursuit (iPursuit) algorithm which was shown to be able to outperform the other spectral clustering based methods with a notable margin especially when the span of clusters are close. A novel theoretical study is presented which sheds light on the key performance factors of both algorithms (MFC/iPursuit) and  it is shown that both algorithms can be robust to notable intersections between the span of  clusters. Importantly, in contrast to the theoretical guarantees of other algorithms which emphasized on the distance between the subspaces as the key performance factor and without making the innovation assumption, it is shown that the performance of MFC/iPursuit mainly depends on the distance between the innovative components of the clusters.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/rahmani22a/rahmani22a.pdf",
        "supp": "",
        "pdf_size": 673104,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:oIjeTJOJgnIJ:scholar.google.com/&scioq=Clustering+a+union+of+linear+subspaces+via+matrix+factorization+and+innovation+search&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "aff": "Amazon Prime Video, Seattle WA",
        "aff_domain": "amazon.com",
        "email": "amazon.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Amazon",
        "aff_unique_dep": "Amazon Prime Video",
        "aff_unique_url": "https://www.primevideo.com",
        "aff_unique_abbr": "APV",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "712a3afee6",
        "title": "CoSPA: An improved masked language model with copy mechanism for Chinese spelling correction",
        "site": "https://proceedings.mlr.press/v180/yang22d.html",
        "author": "Shoujian Yang; Lian Yu",
        "abstract": "Existing BERT-based models for Chinese spelling correction (CSC) have three issues. 1) Bert tends to rectify a correct low-frequency collocation into a high-frequency one and leads to over-correcting. 2) It fails to completely detect phonic or morphological errors by the current learned similarity knowledge between Chinese characters, and the recall rate still has room to improve. 3) Two-dimensional glyph information of Chinese characters is overlooked and some morphological misused characters may be difficult to detect. This paper proposes a hybrid approach, CoSPA, to address these issues. 1) This paper proposes an alterable copy mechanism to alleviate over-correcting by jointly learning to copy a correct character from input sentence, or generate a character from BERT. No method has used copy mechanism in BERT for CSC. 2) The attention mechanism is further applied on the phonic and shape representation of each character at the output layer. 3) Shape representation is enhanced by mining character glyph with ResNet, and fused with stroke representation via an adaptive gating unit. The experimental results show that CoSPA outperforms the previous state-of-the-art methods on SIGHAN2015 datasets.",
        "bibtex": "@InProceedings{pmlr-v180-yang22d,\n  title = \t {CoSPA: An improved masked language model with copy mechanism for Chinese spelling correction},\n  author =       {Yang, Shoujian and Yu, Lian},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2225--2234},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yang22d/yang22d.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yang22d.html},\n  abstract = \t {Existing BERT-based models for Chinese spelling correction (CSC) have three issues. 1) Bert tends to rectify a correct low-frequency collocation into a high-frequency one and leads to over-correcting. 2) It fails to completely detect phonic or morphological errors by the current learned similarity knowledge between Chinese characters, and the recall rate still has room to improve. 3) Two-dimensional glyph information of Chinese characters is overlooked and some morphological misused characters may be difficult to detect. This paper proposes a hybrid approach, CoSPA, to address these issues. 1) This paper proposes an alterable copy mechanism to alleviate over-correcting by jointly learning to copy a correct character from input sentence, or generate a character from BERT. No method has used copy mechanism in BERT for CSC. 2) The attention mechanism is further applied on the phonic and shape representation of each character at the output layer. 3) Shape representation is enhanced by mining character glyph with ResNet, and fused with stroke representation via an adaptive gating unit. The experimental results show that CoSPA outperforms the previous state-of-the-art methods on SIGHAN2015 datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yang22d/yang22d.pdf",
        "supp": "",
        "pdf_size": 777918,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5828797861714999649&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": "School of Software & Microelectronics, Peking University, China; School of Software & Microelectronics, Peking University, China",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Peking University",
        "aff_unique_dep": "School of Software & Microelectronics",
        "aff_unique_url": "http://www.pku.edu.cn",
        "aff_unique_abbr": "PKU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "a3b7c41aeb",
        "title": "Combating the instability of mutual information-based losses via regularization",
        "site": "https://proceedings.mlr.press/v180/choi22a.html",
        "author": "Kwanghee Choi; Siyeong Lee",
        "abstract": "Notable progress has been made in numerous fields of machine learning based on neural network-driven mutual information (MI) bounds. However, utilizing the conventional MI-based losses is often challenging due to their practical and mathematical limitations. In this work, we first identify the symptoms behind their instability: (1) the neural network not converging even after the loss seemed to converge, and (2) saturating neural network outputs causing the loss to diverge. We mitigate both issues by adding a novel regularization term to the existing losses. We theoretically and experimentally demonstrate that added regularization stabilizes training. Finally, we present a novel benchmark that evaluates MI-based losses on both the MI estimation power and its capability on the downstream tasks, closely following the pre-existing supervised and contrastive learning settings. We evaluate six different MI-based losses and their regularized counterparts on multiple benchmarks to show that our approach is simple yet effective.",
        "bibtex": "@InProceedings{pmlr-v180-choi22a,\n  title = \t {Combating the instability of mutual information-based losses via regularization},\n  author =       {Choi, Kwanghee and Lee, Siyeong},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {411--421},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/choi22a/choi22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/choi22a.html},\n  abstract = \t {Notable progress has been made in numerous fields of machine learning based on neural network-driven mutual information (MI) bounds. However, utilizing the conventional MI-based losses is often challenging due to their practical and mathematical limitations. In this work, we first identify the symptoms behind their instability: (1) the neural network not converging even after the loss seemed to converge, and (2) saturating neural network outputs causing the loss to diverge. We mitigate both issues by adding a novel regularization term to the existing losses. We theoretically and experimentally demonstrate that added regularization stabilizes training. Finally, we present a novel benchmark that evaluates MI-based losses on both the MI estimation power and its capability on the downstream tasks, closely following the pre-existing supervised and contrastive learning settings. We evaluate six different MI-based losses and their regularized counterparts on multiple benchmarks to show that our approach is simple yet effective.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/choi22a/choi22a.pdf",
        "supp": "",
        "pdf_size": 1966946,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2482329108429626304&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Sogang University; NA VER LABS",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Sogang University;NAVER LABS",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.sogang.ac.kr;https://www.naverlabs.com",
        "aff_unique_abbr": "Sogang;NAVER Labs",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "30cfd11eb6",
        "title": "Combinatorial Bayesian optimization with random mapping functions to convex polytopes",
        "site": "https://proceedings.mlr.press/v180/kim22a.html",
        "author": "Jungtaek Kim; Seungjin Choi; Minsu Cho",
        "abstract": "Bayesian optimization is a popular method for solving the problem of global optimization of an expensive-to-evaluate black-box function. It relies on a probabilistic surrogate model of the objective function, upon which an acquisition function is built to determine where next to evaluate the objective function. In general, Bayesian optimization with Gaussian process regression operates on a continuous space. When input variables are categorical or discrete, an extra care is needed. A common approach is to use one-hot encoded or Boolean representation for categorical variables which might yield a combinatorial explosion problem. In this paper we present a method for Bayesian optimization in a combinatorial space, which can operate well in a large combinatorial space. The main idea is to use a random mapping which embeds the combinatorial space into a convex polytope in a continuous space, on which all essential process is performed to determine a solution to the black-box optimization in the combinatorial space. We describe our combinatorial Bayesian optimization algorithm and present its regret analysis. Numerical experiments demonstrate that our method shows satisfactory performance compared to existing methods.",
        "bibtex": "@InProceedings{pmlr-v180-kim22a,\n  title = \t {Combinatorial Bayesian optimization with random mapping functions to convex polytopes},\n  author =       {Kim, Jungtaek and Choi, Seungjin and Cho, Minsu},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1001--1011},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/kim22a/kim22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/kim22a.html},\n  abstract = \t {Bayesian optimization is a popular method for solving the problem of global optimization of an expensive-to-evaluate black-box function. It relies on a probabilistic surrogate model of the objective function, upon which an acquisition function is built to determine where next to evaluate the objective function. In general, Bayesian optimization with Gaussian process regression operates on a continuous space. When input variables are categorical or discrete, an extra care is needed. A common approach is to use one-hot encoded or Boolean representation for categorical variables which might yield a combinatorial explosion problem. In this paper we present a method for Bayesian optimization in a combinatorial space, which can operate well in a large combinatorial space. The main idea is to use a random mapping which embeds the combinatorial space into a convex polytope in a continuous space, on which all essential process is performed to determine a solution to the black-box optimization in the combinatorial space. We describe our combinatorial Bayesian optimization algorithm and present its regret analysis. Numerical experiments demonstrate that our method shows satisfactory performance compared to existing methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/kim22a/kim22a.pdf",
        "supp": "",
        "pdf_size": 534711,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1564812840991340480&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "651ce78a6f",
        "title": "Conditional simulation using diffusion Schr\u00f6dinger bridges",
        "site": "https://proceedings.mlr.press/v180/shi22a.html",
        "author": "Yuyang Shi; Valentin De Bortoli; George Deligiannidis; Arnaud Doucet",
        "abstract": "Denoising diffusion models have recently emerged as a powerful class of generative models. They provide state-of-the-art results, not only for unconditional simulation, but also when used to solve conditional simulation problems arising in a wide range of inverse problems. A limitation of these models is that they are computationally intensive at generation time as they require simulating a diffusion process over a long time horizon. When performing unconditional simulation, a Schr{\u00f6}dinger bridge formulation of generative modeling leads to a theoretically grounded algorithm shortening generation time which is complementary to other proposed acceleration techniques. We extend the Schr\u00f6dinger bridge framework to conditional simulation. We demonstrate this novel methodology on various applications including image super-resolution, optimal filtering for state-space models and the refinement of pre-trained networks. Our code can be found at https://github.com/vdeborto/cdsb.",
        "bibtex": "@InProceedings{pmlr-v180-shi22a,\n  title = \t {Conditional simulation using diffusion {S}chr{\u00f6}dinger bridges},\n  author =       {Shi, Yuyang and De Bortoli, Valentin and Deligiannidis, George and Doucet, Arnaud},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1792--1802},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/shi22a/shi22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/shi22a.html},\n  abstract = \t {Denoising diffusion models have recently emerged as a powerful class of generative models. They provide state-of-the-art results, not only for unconditional simulation, but also when used to solve conditional simulation problems arising in a wide range of inverse problems. A limitation of these models is that they are computationally intensive at generation time as they require simulating a diffusion process over a long time horizon. When performing unconditional simulation, a Schr{\u00f6}dinger bridge formulation of generative modeling leads to a theoretically grounded algorithm shortening generation time which is complementary to other proposed acceleration techniques. We extend the Schr\u00f6dinger bridge framework to conditional simulation. We demonstrate this novel methodology on various applications including image super-resolution, optimal filtering for state-space models and the refinement of pre-trained networks. Our code can be found at https://github.com/vdeborto/cdsb.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/shi22a/shi22a.pdf",
        "supp": "",
        "pdf_size": 2712005,
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4475022718090888453&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Statistics, University of Oxford, UK; ENS, PSL University, Paris, France; Department of Statistics, University of Oxford, UK; Department of Statistics, University of Oxford, UK",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "https://github.com/vdeborto/cdsb",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Oxford;\u00c9cole Normale Sup\u00e9rieure",
        "aff_unique_dep": "Department of Statistics;",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.ens.psl.eu",
        "aff_unique_abbr": "Oxford;ENS",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Oxford;Paris",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United Kingdom;France"
    },
    {
        "id": "6bddb03368",
        "title": "Contrastive latent variable models for neural text generation",
        "site": "https://proceedings.mlr.press/v180/teng22a.html",
        "author": "Zhiyang Teng; Chenhua Chen; Yan Zhang; Yue Zhang",
        "abstract": "Deep latent variable models such as variational autoencoders and energy-based models are widely used for neural text generation. Most of them focus on matching the prior distribution with the posterior distribution of the latent variable for text reconstruction. In addition to instance-level reconstruction, this paper aims to integrate contrastive learning in the latent space, forcing the latent variables to learn high-level semantics by exploring inter-instance relationships. Experiments on various text generation benchmarks show the effectiveness of our proposed method. We also empirically show that our method can mitigate the posterior collapse issue for latent variable based text generation models.",
        "bibtex": "@InProceedings{pmlr-v180-teng22a,\n  title = \t {Contrastive latent variable models for neural text generation},\n  author =       {Teng, Zhiyang and Chen, Chenhua and Zhang, Yan and Zhang, Yue},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1928--1938},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/teng22a/teng22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/teng22a.html},\n  abstract = \t {Deep latent variable models such as variational autoencoders and energy-based models are widely used for neural text generation. Most of them focus on matching the prior distribution with the posterior distribution of the latent variable for text reconstruction. In addition to instance-level reconstruction, this paper aims to integrate contrastive learning in the latent space, forcing the latent variables to learn high-level semantics by exploring inter-instance relationships. Experiments on various text generation benchmarks show the effectiveness of our proposed method. We also empirically show that our method can mitigate the posterior collapse issue for latent variable based text generation models. }\n}",
        "pdf": "https://proceedings.mlr.press/v180/teng22a/teng22a.pdf",
        "supp": "",
        "pdf_size": 3150718,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12002456938297413237&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1914a907d4",
        "title": "Convergence Analysis of Linear Coupling with Inexact Proximal Operator",
        "site": "https://proceedings.mlr.press/v180/zhou22b.html",
        "author": "Qiang Zhou; Sinno Jialin Pan",
        "abstract": "Linear coupling is recently proposed to accelerate first-order algorithms by linking gradient descent and mirror descent together, which is able to achieve the accelerated convergence rate for first-order algorithms. This work focuses on the convergence analysis of linear coupling for convex composite minimization when the proximal operator cannot be exactly computed. It is of particular interest to study the convergence of linear coupling because it not only achieves the accelerated convergence rate for first-order algorithm but also works for generic norms. We present convergence analysis of linear coupling by allowing the proximal operator to be computed up to a certain precision. Our analysis illustrates that the accelerated convergence rate of linear coupling with inexact proximal operator can be preserved if the error sequence of inexact proximal operator decreases in a sufficiently fast rate. More importantly, our analysis leads to better bounds than existing works on inexact proximal operator. Experiment results on several real-world datasets verify our theoretical results.",
        "bibtex": "@InProceedings{pmlr-v180-zhou22b,\n  title = \t {Convergence Analysis of Linear Coupling with Inexact Proximal Operator},\n  author =       {Zhou, Qiang and Jialin Pan, Sinno},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2394--2403},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/zhou22b/zhou22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/zhou22b.html},\n  abstract = \t {Linear coupling is recently proposed to accelerate first-order algorithms by linking gradient descent and mirror descent together, which is able to achieve the accelerated convergence rate for first-order algorithms. This work focuses on the convergence analysis of linear coupling for convex composite minimization when the proximal operator cannot be exactly computed. It is of particular interest to study the convergence of linear coupling because it not only achieves the accelerated convergence rate for first-order algorithm but also works for generic norms. We present convergence analysis of linear coupling by allowing the proximal operator to be computed up to a certain precision. Our analysis illustrates that the accelerated convergence rate of linear coupling with inexact proximal operator can be preserved if the error sequence of inexact proximal operator decreases in a sufficiently fast rate. More importantly, our analysis leads to better bounds than existing works on inexact proximal operator. Experiment results on several real-world datasets verify our theoretical results.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/zhou22b/zhou22b.pdf",
        "supp": "",
        "pdf_size": 417536,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13403031908022785049&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1fb3a48dd0",
        "title": "CounteRGAN: Generating counterfactuals for real-time recourse and interpretability using residual GANs",
        "site": "https://proceedings.mlr.press/v180/nemirovsky22a.html",
        "author": "Daniel Nemirovsky; Nicolas Thiebaut; Ye Xu; Abhishek Gupta",
        "abstract": "Model interpretability, fairness, and recourse for end users have increased as machine learning models have become increasingly popular in areas including criminal justice, finance, healthcare, and job marketplaces. This work presents a novel method of addressing these issues by producing meaningful counterfactuals that are aimed at providing recourse to users and highlighting potential model biases. A meaningful counterfactual is a reasonable alternative scenario that illustrates how input data perturbations can influence the model\u2019s output. The CounteRGAN method generates meaningful counterfactuals for a target classifier by utilizing a novel Residual Generative Adversarial Network (RGAN). We compare our method against leading state-of-the-art approaches on image and tabular datasets over a variety of performance metrics. The results indicate a significant improvement over existing techniques in combined metric performance, with a latency reduction of 2 to 7 orders of magnitude which enables providing real-time recourse to users. The code for reproducibility can be found here: https://github.com/gan-counterfactuals/countergan.",
        "bibtex": "@InProceedings{pmlr-v180-nemirovsky22a,\n  title = \t {CounteRGAN: Generating counterfactuals for real-time recourse and interpretability using residual GANs},\n  author =       {Nemirovsky, Daniel and Thiebaut, Nicolas and Xu, Ye and Gupta, Abhishek},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1488--1497},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/nemirovsky22a/nemirovsky22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/nemirovsky22a.html},\n  abstract = \t {Model interpretability, fairness, and recourse for end users have increased as machine learning models have become increasingly popular in areas including criminal justice, finance, healthcare, and job marketplaces. This work presents a novel method of addressing these issues by producing meaningful counterfactuals that are aimed at providing recourse to users and highlighting potential model biases. A meaningful counterfactual is a reasonable alternative scenario that illustrates how input data perturbations can influence the model\u2019s output. The CounteRGAN method generates meaningful counterfactuals for a target classifier by utilizing a novel Residual Generative Adversarial Network (RGAN). We compare our method against leading state-of-the-art approaches on image and tabular datasets over a variety of performance metrics. The results indicate a significant improvement over existing techniques in combined metric performance, with a latency reduction of 2 to 7 orders of magnitude which enables providing real-time recourse to users. The code for reproducibility can be found here: https://github.com/gan-counterfactuals/countergan.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/nemirovsky22a/nemirovsky22a.pdf",
        "supp": "",
        "pdf_size": 711008,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3235633025264838811&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Amazon, Seattle, WA, U.S.A.; Hired, New York, NY, U.S.A.; Meta, Menlo Park, CA, U.S.A. + Hired, New York, NY, U.S.A.; Meta, Menlo Park, CA, U.S.A.",
        "aff_domain": "amazon.com;hired.com;fb.com;fb.com",
        "email": "amazon.com;hired.com;fb.com;fb.com",
        "github": "https://github.com/gan-counterfactuals/countergan",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+1;2",
        "aff_unique_norm": "Amazon;Hired;Meta",
        "aff_unique_dep": "Amazon;;Meta Platforms, Inc.",
        "aff_unique_url": "https://www.amazon.com;https://www.hired.com;https://www.meta.com",
        "aff_unique_abbr": "Amazon;;Meta",
        "aff_campus_unique_index": "0;2;2",
        "aff_campus_unique": "Seattle;;Menlo Park",
        "aff_country_unique_index": "0;0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c12608b498",
        "title": "Counterfactual inference of second Opinions",
        "site": "https://proceedings.mlr.press/v180/corvelo-benz22a.html",
        "author": "Nina L. Corvelo Benz; Manuel Gomez Rodriguez",
        "abstract": "Automated decision support systems that are able to infer second opinions from experts can potentially facilitate a more efficient allocation of resources\u2014they can help decide when and from whom to seek a second opinion. In this paper, we look at the design of this type of support systems from the perspective of counterfactual inference. We focus on a multiclass classification setting and first show that, if experts make predictions on their own, the underlying causal mechanism generating their predictions needs to satisfy a desirable set invariant property. Further, we show that, for any causal mechanism satisfying this property, there exists an equivalent mechanism where the predictions by each expert are generated by independent sub-mechanisms governed by a common noise. This motivates the design of a set invariant Gumbel-Max structural causal model where the structure of the noise governing the sub-mechanisms underpinning the model depends on an intuitive notion of similarity between experts which can be estimated from data. Experiments on both synthetic and real data show that our model can be used to infer second opinions more accurately than its non-causal counterpart.",
        "bibtex": "@InProceedings{pmlr-v180-corvelo-benz22a,\n  title = \t {Counterfactual inference of second Opinions},\n  author =       {Corvelo Benz, Nina L. and Gomez Rodriguez, Manuel},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {453--463},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/corvelo-benz22a/corvelo-benz22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/corvelo-benz22a.html},\n  abstract = \t {Automated decision support systems that are able to infer second opinions from experts can potentially facilitate a more efficient allocation of resources\u2014they can help decide when and from whom to seek a second opinion. In this paper, we look at the design of this type of support systems from the perspective of counterfactual inference. We focus on a multiclass classification setting and first show that, if experts make predictions on their own, the underlying causal mechanism generating their predictions needs to satisfy a desirable set invariant property. Further, we show that, for any causal mechanism satisfying this property, there exists an equivalent mechanism where the predictions by each expert are generated by independent sub-mechanisms governed by a common noise. This motivates the design of a set invariant Gumbel-Max structural causal model where the structure of the noise governing the sub-mechanisms underpinning the model depends on an intuitive notion of similarity between experts which can be estimated from data. Experiments on both synthetic and real data show that our model can be used to infer second opinions more accurately than its non-causal counterpart.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/corvelo-benz22a/corvelo-benz22a.pdf",
        "supp": "",
        "pdf_size": 1174890,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3489777536118770054&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Max Planck Institute for Software Systems, Kaiserslautern, Germany+Department of Biosystems Science and Engineering, ETH Zurich, Zurich, Switzerland; Max Planck Institute for Software Systems, Kaiserslautern, Germany",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0",
        "aff_unique_norm": "Max Planck Institute for Software Systems;ETH Zurich",
        "aff_unique_dep": ";Department of Biosystems Science and Engineering",
        "aff_unique_url": "https://www.mpi-sws.org;https://www.ethz.ch",
        "aff_unique_abbr": "MPI-SWS;ETHZ",
        "aff_campus_unique_index": "0+1;0",
        "aff_campus_unique": "Kaiserslautern;Zurich",
        "aff_country_unique_index": "0+1;0",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "id": "36161572a5",
        "title": "Cross-domain adaptive transfer reinforcement learning based on state-action correspondence",
        "site": "https://proceedings.mlr.press/v180/you22a.html",
        "author": "Heng You; Tianpei Yang; Yan Zheng; Jianye Hao; E. Taylor Matthew",
        "abstract": "Despite the impressive success achieved in various domains, deep reinforcement learning (DRL) is still faced with the sample inefficiency problem.  Transfer learning (TL), which leverages prior knowledge from different but related tasks to accelerate the target task learning, has emerged as a promising direction to improve RL efficiency.  The majority of prior work considers TL across tasks with the same state-action spaces, while transferring across domains with different state-action spaces is relatively unexplored.  Furthermore, such existing cross-domain transfer approaches only enable transfer from a single source policy, leaving open the important question of how to best transfer from multiple source policies. This paper proposes a novel framework called Cross-domain Adaptive Transfer (CAT) to accelerate DRL. CAT learns the state-action correspondence from each source task to the target task and adaptively transfers knowledge from multiple source task policies to the target policy. CAT can be easily combined with existing DRL algorithms and experimental results show that CAT significantly accelerates learning and outperforms other cross-domain transfer methods on multiple continuous action control tasks.",
        "bibtex": "@InProceedings{pmlr-v180-you22a,\n  title = \t {Cross-domain adaptive transfer reinforcement \\\\{learning} based on state-action correspondence},\n  author =       {You, Heng and Yang, Tianpei and Zheng, Yan and Hao, Jianye and Taylor, Matthew, E.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2299--2309},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/you22a/you22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/you22a.html},\n  abstract = \t {Despite the impressive success achieved in various domains, deep reinforcement learning (DRL) is still faced with the sample inefficiency problem.  Transfer learning (TL), which leverages prior knowledge from different but related tasks to accelerate the target task learning, has emerged as a promising direction to improve RL efficiency.  The majority of prior work considers TL across tasks with the same state-action spaces, while transferring across domains with different state-action spaces is relatively unexplored.  Furthermore, such existing cross-domain transfer approaches only enable transfer from a single source policy, leaving open the important question of how to best transfer from multiple source policies. This paper proposes a novel framework called Cross-domain Adaptive Transfer (CAT) to accelerate DRL. CAT learns the state-action correspondence from each source task to the target task and adaptively transfers knowledge from multiple source task policies to the target policy. CAT can be easily combined with existing DRL algorithms and experimental results show that CAT significantly accelerates learning and outperforms other cross-domain transfer methods on multiple continuous action control tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/you22a/you22a.pdf",
        "supp": "",
        "pdf_size": 3384660,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1841316864161542326&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "College of Intelligence and Computing, Tianjin University, China; College of Intelligence and Computing, Tianjin University, China + Department of Computing Science, University of Alberta and Alberta Machine Intelligence Institute, Canada; College of Intelligence and Computing, Tianjin University, China; College of Intelligence and Computing, Tianjin University, China; Department of Computing Science, University of Alberta and Alberta Machine Intelligence Institute, Canada",
        "aff_domain": "tju.edu.cn;tju.edu.cn;tju.edu.cn;tju.edu.cn;ualberta.ca",
        "email": "tju.edu.cn;tju.edu.cn;tju.edu.cn;tju.edu.cn;ualberta.ca",
        "github": "https://github.com/TJU-DRL-LAB/transfer-and-multi-task-reinforcement-learning",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;0;0;1",
        "aff_unique_norm": "Tianjin University;University of Alberta",
        "aff_unique_dep": "College of Intelligence and Computing;Department of Computing Science",
        "aff_unique_url": "http://www.tju.edu.cn;https://www.ualberta.ca",
        "aff_unique_abbr": "Tianjin University;UAlberta",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+1;0;0;1",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "46016f16c5",
        "title": "Cycle class consistency with distributional optimal transport and knowledge distillation for unsupervised domain adaptation",
        "site": "https://proceedings.mlr.press/v180/nguyen22c.html",
        "author": "Tuan Nguyen; Van Nguyen; Trung Le; He Zhao; Quan Hung Tran; Dinh Phung",
        "abstract": "Unsupervised domain adaptation (UDA) aims to transfer knowledge from a model trained on a labeled source domain to an unlabeled target domain. To this end, we propose in this paper a novel cycle class-consistent model based on optimal transport (OT) and knowledge distillation. The model consists of two agents, a teacher and a student cooperatively working in a cycle process under the guidance of the distributional optimal transport and distillation manner. The OT distance is designed to bridge the gap between the distribution of the target data and a distribution over the source class-conditional distributions. The optimal probability matrix then provides pseudo labels to learn a teacher that achieves a good classification performance on the target domain. Knowledge distillation is performed in the next step in which the teacher distills and transfers its knowledge to the student. And finally, the student produces its prediction for the optimal transport step. This process forms a closed cycle in which the teacher and student networks are simultaneously trained to conduct transfer learning from the source to the target domain. Extensive experiments show that our proposed method outperforms existing methods, especially the class-aware and OT-based ones on benchmark datasets including Office-31, Office-Home, and ImageCLEF-DA.",
        "bibtex": "@InProceedings{pmlr-v180-nguyen22c,\n  title = \t {Cycle class consistency with distributional optimal transport and knowledge distillation for unsupervised domain adaptation},\n  author =       {Nguyen, Tuan and Nguyen, Van and Le, Trung and Zhao, He and Tran, Quan Hung and Phung, Dinh},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1519--1529},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/nguyen22c/nguyen22c.pdf},\n  url = \t {https://proceedings.mlr.press/v180/nguyen22c.html},\n  abstract = \t {Unsupervised domain adaptation (UDA) aims to transfer knowledge from a model trained on a labeled source domain to an unlabeled target domain. To this end, we propose in this paper a novel cycle class-consistent model based on optimal transport (OT) and knowledge distillation. The model consists of two agents, a teacher and a student cooperatively working in a cycle process under the guidance of the distributional optimal transport and distillation manner. The OT distance is designed to bridge the gap between the distribution of the target data and a distribution over the source class-conditional distributions. The optimal probability matrix then provides pseudo labels to learn a teacher that achieves a good classification performance on the target domain. Knowledge distillation is performed in the next step in which the teacher distills and transfers its knowledge to the student. And finally, the student produces its prediction for the optimal transport step. This process forms a closed cycle in which the teacher and student networks are simultaneously trained to conduct transfer learning from the source to the target domain. Extensive experiments show that our proposed method outperforms existing methods, especially the class-aware and OT-based ones on benchmark datasets including Office-31, Office-Home, and ImageCLEF-DA.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/nguyen22c/nguyen22c.pdf",
        "supp": "",
        "pdf_size": 2499948,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9503562334702447849&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9fc1dd010c",
        "title": "Cyclic test time augmentation with entropy weight method",
        "site": "https://proceedings.mlr.press/v180/chun22a.html",
        "author": "Sewhan Chun; Jae Young Lee; Junmo Kim",
        "abstract": "In the recent studies of data augmentation of neural networks, the application of test time augmentation has been studied to extract optimal transformation policies to enhance performance with minimum cost. The policy search method with the best level of input data dependency involves training a loss predictor network to estimate suitable transformations for each of the given input image in independent manner, resulting in instance-level transformation extraction. In this work, we propose a method to utilize and modify the loss prediction pipeline to further improve the performance with the cyclic search for suitable transformations and the use of the entropy weight method. The cyclic usage of the loss predictor allows refining each input image with multiple transformations with a more flexible transformation magnitude. For cases where multiple augmentations are generated, we implement the entropy weight method to reflect the data uncertainty of each augmentation to force the final result to focus on augmentations with low uncertainty. The experimental results show convincing qualitative outcomes and robust performance for the corrupted conditions of data.",
        "bibtex": "@InProceedings{pmlr-v180-chun22a,\n  title = \t {Cyclic test time augmentation with entropy weight method},\n  author =       {Chun, Sewhan and Lee, Jae Young and Kim, Junmo},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {433--442},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/chun22a/chun22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/chun22a.html},\n  abstract = \t {In the recent studies of data augmentation of neural networks, the application of test time augmentation has been studied to extract optimal transformation policies to enhance performance with minimum cost. The policy search method with the best level of input data dependency involves training a loss predictor network to estimate suitable transformations for each of the given input image in independent manner, resulting in instance-level transformation extraction. In this work, we propose a method to utilize and modify the loss prediction pipeline to further improve the performance with the cyclic search for suitable transformations and the use of the entropy weight method. The cyclic usage of the loss predictor allows refining each input image with multiple transformations with a more flexible transformation magnitude. For cases where multiple augmentations are generated, we implement the entropy weight method to reflect the data uncertainty of each augmentation to force the final result to focus on augmentations with low uncertainty. The experimental results show convincing qualitative outcomes and robust performance for the corrupted conditions of data.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/chun22a/chun22a.pdf",
        "supp": "",
        "pdf_size": 487651,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1725783248374401360&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "eb3d78c152",
        "title": "Data augmentation in Bayesian neural networks and the cold posterior effect",
        "site": "https://proceedings.mlr.press/v180/nabarro22a.html",
        "author": "Seth Nabarro; Stoil Ganev; Adri\u00e0 Garriga-Alonso; Vincent Fortuin; Mark van der Wilk; Laurence Aitchison",
        "abstract": "Bayesian neural networks that incorporate data augmentation implicitly use a \u201crandomly perturbed log-likelihood [which] does not have a clean interpretation as a valid likelihood function\u201d (Izmailov et al. 2021). Here, we provide several approaches to developing principled Bayesian neural networks incorporating data augmentation. We introduce a \u201cfinite orbit\u201d setting which allows valid likelihoods to be computed exactly, and for the more usual \u201cfull orbit\u201d setting we derive multi-sample bounds tighter than those used previously. These models cast light on the origin of the cold posterior effect. In particular, we find that the cold posterior effect persists even in these principled models incorporating data augmentation. This suggests that the cold posterior effect cannot be dismissed as an artifact of data augmentation using incorrect likelihoods.",
        "bibtex": "@InProceedings{pmlr-v180-nabarro22a,\n  title = \t {Data augmentation in Bayesian neural networks and the cold posterior effect},\n  author =       {Nabarro, Seth and Ganev, Stoil and Garriga-Alonso, Adri\\`a and Fortuin, Vincent and van der Wilk, Mark and Aitchison, Laurence},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1434--1444},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/nabarro22a/nabarro22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/nabarro22a.html},\n  abstract = \t {Bayesian neural networks that incorporate data augmentation implicitly use a \u201crandomly perturbed log-likelihood [which] does not have a clean interpretation as a valid likelihood function\u201d (Izmailov et al. 2021). Here, we provide several approaches to developing principled Bayesian neural networks incorporating data augmentation. We introduce a \u201cfinite orbit\u201d setting which allows valid likelihoods to be computed exactly, and for the more usual \u201cfull orbit\u201d setting we derive multi-sample bounds tighter than those used previously. These models cast light on the origin of the cold posterior effect. In particular, we find that the cold posterior effect persists even in these principled models incorporating data augmentation. This suggests that the cold posterior effect cannot be dismissed as an artifact of data augmentation using incorrect likelihoods.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/nabarro22a/nabarro22a.pdf",
        "supp": "",
        "pdf_size": 633481,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10875054050802472360&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "82f1b6f586",
        "title": "Data dependent randomized smoothing",
        "site": "https://proceedings.mlr.press/v180/alfarra22a.html",
        "author": "Motasem Alfarra; Adel Bibi; Philip H. S. Torr; Bernard Ghanem",
        "abstract": "Randomized smoothing is a recent technique that achieves state-of-art performance in training certifiably robust deep neural networks. While the smoothing family of distributions is often connected to the choice of the norm used for certification, the parameters of these distributions are always set as global hyper parameters independent from the input data on which a network is certified. In this work, we revisit Gaussian randomized smoothing and show that the variance of the Gaussian distribution can be optimized at each input so as to maximize the certification radius for the construction of the smooth classifier. Since the data dependent classifier does not directly enjoy sound certification with existing approaches, we propose a memory-enhanced data dependent smooth classifier that is certifiable by construction. This new approach is generic, parameter-free, and easy to implement. In fact, we show that our data dependent framework can be seamlessly incorporated into 3 randomized smoothing approaches, leading to consistent improved certified accuracy. When this framework is used in the training routine of these approaches followed by a data dependent certification, we achieve 9% and 6% improvement over the certified accuracy of the strongest baseline for a radius of 0.5 on CIFAR10 and ImageNet.",
        "bibtex": "@InProceedings{pmlr-v180-alfarra22a,\n  title = \t {Data dependent randomized smoothing},\n  author =       {Alfarra, Motasem and Bibi, Adel and Torr, Philip H. S. and Ghanem, Bernard},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {64--74},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/alfarra22a/alfarra22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/alfarra22a.html},\n  abstract = \t {Randomized smoothing is a recent technique that achieves state-of-art performance in training certifiably robust deep neural networks. While the smoothing family of distributions is often connected to the choice of the norm used for certification, the parameters of these distributions are always set as global hyper parameters independent from the input data on which a network is certified. In this work, we revisit Gaussian randomized smoothing and show that the variance of the Gaussian distribution can be optimized at each input so as to maximize the certification radius for the construction of the smooth classifier. Since the data dependent classifier does not directly enjoy sound certification with existing approaches, we propose a memory-enhanced data dependent smooth classifier that is certifiable by construction. This new approach is generic, parameter-free, and easy to implement. In fact, we show that our data dependent framework can be seamlessly incorporated into 3 randomized smoothing approaches, leading to consistent improved certified accuracy. When this framework is used in the training routine of these approaches followed by a data dependent certification, we achieve 9% and 6% improvement over the certified accuracy of the strongest baseline for a radius of 0.5 on CIFAR10 and ImageNet.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/alfarra22a/alfarra22a.pdf",
        "supp": "",
        "pdf_size": 2729168,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15497611913511940623&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "King Abdullah University of Science and Technology (KAUST), Saudi Arabia; University of Oxford, United Kingdom; University of Oxford, United Kingdom; King Abdullah University of Science and Technology (KAUST), Saudi Arabia",
        "aff_domain": "kaust.edu.sa;eng.ox.ac.uk; ; ",
        "email": "kaust.edu.sa;eng.ox.ac.uk; ; ",
        "github": "https://github.com/MotasemAlfarra/DDRS",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "King Abdullah University of Science and Technology;University of Oxford",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.kaust.edu.sa;https://www.ox.ac.uk",
        "aff_unique_abbr": "KAUST;Oxford",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Saudi Arabia;United Kingdom"
    },
    {
        "id": "d9d83c6d1f",
        "title": "Data poisoning attacks on off-policy policy evaluation methods",
        "site": "https://proceedings.mlr.press/v180/lobo22a.html",
        "author": "Elita Lobo; Harvineet Singh; Marek Petrik; Cynthia Rudin; Himabindu Lakkaraju",
        "abstract": "Off-policy Evaluation (OPE) methods are a crucial tool for evaluating policies in high-stakes domains such as healthcare, where exploration is often infeasible, unethical, or expensive. However, the extent to which such methods can be trusted under adversarial threats to data quality is largely unexplored. In this work, we make the first attempt at investigating the sensitivity of OPE methods to marginal adversarial perturbations to the data. We design a generic data poisoning attack framework leveraging influence functions from robust statistics to carefully construct perturbations that maximize error in the policy value estimates. We carry out extensive experimentation with multiple healthcare and control datasets. Our results demonstrate that many existing OPE methods are highly prone to generating value estimates with large errors when subject to data poisoning attacks, even for small adversarial perturbations. These findings question the reliability of policy values derived using OPE methods and motivate the need for developing OPE methods that are statistically robust to train-time data poisoning attacks.",
        "bibtex": "@InProceedings{pmlr-v180-lobo22a,\n  title = \t {Data poisoning attacks on off-policy policy evaluation methods},\n  author =       {Lobo, Elita and Singh, Harvineet and Petrik, Marek and Rudin, Cynthia and Lakkaraju, Himabindu},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1264--1274},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/lobo22a/lobo22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/lobo22a.html},\n  abstract = \t {Off-policy Evaluation (OPE) methods are a crucial tool for evaluating policies in high-stakes domains such as healthcare, where exploration is often infeasible, unethical, or expensive. However, the extent to which such methods can be trusted under adversarial threats to data quality is largely unexplored. In this work, we make the first attempt at investigating the sensitivity of OPE methods to marginal adversarial perturbations to the data. We design a generic data poisoning attack framework leveraging influence functions from robust statistics to carefully construct perturbations that maximize error in the policy value estimates. We carry out extensive experimentation with multiple healthcare and control datasets. Our results demonstrate that many existing OPE methods are highly prone to generating value estimates with large errors when subject to data poisoning attacks, even for small adversarial perturbations. These findings question the reliability of policy values derived using OPE methods and motivate the need for developing OPE methods that are statistically robust to train-time data poisoning attacks.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/lobo22a/lobo22a.pdf",
        "supp": "",
        "pdf_size": 1057811,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2096365551542151531&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of New Hampshire, Durham, NH, USA; New York University, New York, NY, USA; University of New Hampshire, Durham, NH, USA; Duke University, Durham, NC, USA; Harvard University, Boston, MA, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2;3",
        "aff_unique_norm": "University of New Hampshire;New York University;Duke University;Harvard University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.unh.edu;https://www.nyu.edu;https://www.duke.edu;https://www.harvard.edu",
        "aff_unique_abbr": "UNH;NYU;Duke;Harvard",
        "aff_campus_unique_index": "0;1;0;0;2",
        "aff_campus_unique": "Durham;New York;Boston",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a52d903446",
        "title": "Data sampling affects the complexity of online SGD over dependent data",
        "site": "https://proceedings.mlr.press/v180/ma22a.html",
        "author": "Shaocong Ma; Ziyi Chen; Yi Zhou; Kaiyi Ji; Yingbin Liang",
        "abstract": "Conventional machine learning applications typically assume that data samples are independently and identically distributed (i.i.d.). However, practical scenarios often involve a data-generating process that produces highly dependent data samples, which are known to heavily bias the stochastic optimization process and slow down the convergence of learning. In this paper, we conduct a fundamental study on how different stochastic data sampling schemes affect the sample complexity of online stochastic gradient descent (SGD) over highly dependent data. Specifically, with a $\\phi$-mixing process of data, we show that online SGD with proper periodic data-subsampling achieves an improved sample complexity over the standard online SGD in the full spectrum of the data dependence level. Interestingly, even subsampling a subset of data samples can accelerate the convergence of online SGD over highly dependent data.  Moreover, we show that online SGD with mini-batch sampling can further substantially improve the sample complexity over online SGD with periodic data-subsampling over highly dependent data. Numerical experiments validate our theoretical results.",
        "bibtex": "@InProceedings{pmlr-v180-ma22a,\n  title = \t {Data sampling affects the complexity of online SGD over dependent data},\n  author =       {Ma, Shaocong and Chen, Ziyi and Zhou, Yi and Ji, Kaiyi and Liang, Yingbin},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1296--1305},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ma22a/ma22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ma22a.html},\n  abstract = \t {Conventional machine learning applications typically assume that data samples are independently and identically distributed (i.i.d.). However, practical scenarios often involve a data-generating process that produces highly dependent data samples, which are known to heavily bias the stochastic optimization process and slow down the convergence of learning. In this paper, we conduct a fundamental study on how different stochastic data sampling schemes affect the sample complexity of online stochastic gradient descent (SGD) over highly dependent data. Specifically, with a $\\phi$-mixing process of data, we show that online SGD with proper periodic data-subsampling achieves an improved sample complexity over the standard online SGD in the full spectrum of the data dependence level. Interestingly, even subsampling a subset of data samples can accelerate the convergence of online SGD over highly dependent data.  Moreover, we show that online SGD with mini-batch sampling can further substantially improve the sample complexity over online SGD with periodic data-subsampling over highly dependent data. Numerical experiments validate our theoretical results.  }\n}",
        "pdf": "https://proceedings.mlr.press/v180/ma22a/ma22a.pdf",
        "supp": "",
        "pdf_size": 1668015,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10529263309754617068&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Electrical and Computer Engineering, University of Utah; Department of Electrical and Computer Engineering, University of Utah; Department of Electrical and Computer Engineering, University of Utah; Electrical Engineering and Computer Science Department, University of Michigan, Ann Arbor; Department of Electrical and Computer Engineering, The Ohio State University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "University of Utah;University of Michigan;Ohio State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Electrical Engineering and Computer Science Department;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.utah.edu;https://www.umich.edu;https://www.osu.edu",
        "aff_unique_abbr": "Utah;UM;OSU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Ann Arbor",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f1572fc666",
        "title": "Decision-theoretic planning with communication in open multiagent systems",
        "site": "https://proceedings.mlr.press/v180/kakarlapudi22a.html",
        "author": "Anirudh Kakarlapudi; Gayathri Anil; Adam Eck; Prashant Doshi; Leen-Kiat Soh",
        "abstract": "In open multiagent systems, the set of agents operating in the environment changes over time and in ways that are nontrivial to predict. For example, if collaborative robots were tasked with fighting wildfires, they may run out of suppressants and be temporarily unavailable to assist their peers. Because an agent\u2019s optimal action depends on the actions of others, each agent must not only predict the actions of its peers, but, before that, reason whether they are even present to perform an action.  Addressing openness thus requires agents to model each other\u2019s presence, which can be enhanced through agents communicating about their presence in the environment.  At the same time, communicative acts can also incur costs (e.g., consuming limited bandwidth), and thus an agent must tradeoff the benefits of enhanced coordination with the costs of communication.  We present a new principled, decision-theoretic method in the context provided by the recent communicative interactive POMDP framework for planning in open agent settings that balances this tradeoff. Simulations of multiagent wildfire suppression problems demonstrate how communication can improve planning in open agent environments, as well as how agents tradeoff the benefits and costs of communication under different scenarios.",
        "bibtex": "@InProceedings{pmlr-v180-kakarlapudi22a,\n  title = \t {Decision-theoretic planning with communication in open multiagent systems},\n  author =       {Kakarlapudi, Anirudh and Anil, Gayathri and Eck, Adam and Doshi, Prashant and Soh, Leen-Kiat},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {938--948},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/kakarlapudi22a/kakarlapudi22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/kakarlapudi22a.html},\n  abstract = \t {In open multiagent systems, the set of agents operating in the environment changes over time and in ways that are nontrivial to predict. For example, if collaborative robots were tasked with fighting wildfires, they may run out of suppressants and be temporarily unavailable to assist their peers. Because an agent\u2019s optimal action depends on the actions of others, each agent must not only predict the actions of its peers, but, before that, reason whether they are even present to perform an action.  Addressing openness thus requires agents to model each other\u2019s presence, which can be enhanced through agents communicating about their presence in the environment.  At the same time, communicative acts can also incur costs (e.g., consuming limited bandwidth), and thus an agent must tradeoff the benefits of enhanced coordination with the costs of communication.  We present a new principled, decision-theoretic method in the context provided by the recent communicative interactive POMDP framework for planning in open agent settings that balances this tradeoff. Simulations of multiagent wildfire suppression problems demonstrate how communication can improve planning in open agent environments, as well as how agents tradeoff the benefits and costs of communication under different scenarios.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/kakarlapudi22a/kakarlapudi22a.pdf",
        "supp": "",
        "pdf_size": 1361098,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18128247390308382270&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Computer Science Department, University of Georgia, Athens, Georgia, USA; Computer Science Department, University of Georgia, Athens, Georgia, USA; Computer Science Department, Oberlin College, Oberlin, Ohio, USA; Computer Science Department, University of Georgia, Athens, Georgia, USA; School of Computing, University of Nebraska, Lincoln, Nebraska, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "University of Georgia;Oberlin College;University of Nebraska",
        "aff_unique_dep": "Computer Science Department;Computer Science Department;School of Computing",
        "aff_unique_url": "https://www.uga.edu;https://www.oberlin.edu;https://www.unl.edu",
        "aff_unique_abbr": "UGA;Oberlin;UNL",
        "aff_campus_unique_index": "0;0;1;0;2",
        "aff_campus_unique": "Athens;Oberlin;Lincoln",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "556d5aa032",
        "title": "Deep Dirichlet process mixture models",
        "site": "https://proceedings.mlr.press/v180/li22c.html",
        "author": "Naiqi Li; Wenjie Li; Yong Jiang; Shu-Tao Xia",
        "abstract": "In this paper we propose the deep Dirichlet process mixture (DDPM) model, which is an unsupervised method that simultaneously performs clustering and feature learning. The traditional Dirichlet process mixture model can infer the number of mixture components, but its flexibility is restricted since the clustering is performed in the raw feature space. Our method alleviates this limitation by using the flow-based deep neural network to learn more expressive features. DDPM unifies Dirichlet processes and the flow-based model with Monte Carlo expectation-maximization, and uses Gibbs sampling to sample from the posterior. This combination allows our method to exploit the mutually beneficial relation between clustering and feature learning. The effectiveness of DDPM is demonstrated by thorough experiments in various synthetic and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v180-li22c,\n  title = \t {Deep Dirichlet process mixture models},\n  author =       {Li, Naiqi and Li, Wenjie and Jiang, Yong and Xia, Shu-Tao},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1138--1147},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/li22c/li22c.pdf},\n  url = \t {https://proceedings.mlr.press/v180/li22c.html},\n  abstract = \t {In this paper we propose the deep Dirichlet process mixture (DDPM) model, which is an unsupervised method that simultaneously performs clustering and feature learning. The traditional Dirichlet process mixture model can infer the number of mixture components, but its flexibility is restricted since the clustering is performed in the raw feature space. Our method alleviates this limitation by using the flow-based deep neural network to learn more expressive features. DDPM unifies Dirichlet processes and the flow-based model with Monte Carlo expectation-maximization, and uses Gibbs sampling to sample from the posterior. This combination allows our method to exploit the mutually beneficial relation between clustering and feature learning. The effectiveness of DDPM is demonstrated by thorough experiments in various synthetic and real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/li22c/li22c.pdf",
        "supp": "",
        "pdf_size": 924545,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17936712230563689136&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3a794af196",
        "title": "Detecting textual adversarial examples through randomized substitution and vote",
        "site": "https://proceedings.mlr.press/v180/wang22b.html",
        "author": "Xiaosen Wang; Xiong Yifeng; Kun He",
        "abstract": "A line of work has shown that natural text processing models are vulnerable to adversarial examples. Correspondingly, various defense methods are proposed to mitigate the threat of textual adversarial examples, \\textit{e.g.} adversarial training, input transformations, detection, \\textit{etc}. In this work, we treat the optimization process for synonym substitution based textual adversarial attacks as a specific sequence of word replacement, in which each word mutually influences other words. We identify that we could destroy such mutual interaction and eliminate the adversarial perturbation by randomly substituting a word with its synonyms. Based on this observation, we propose a novel textual adversarial example detection method, termed \\textit{Randomized Substitution and Vote} (RS&V), which votes the prediction label by accumulating the logits of $k$ samples generated by randomly substituting the words in the input text with synonyms. The proposed RS&V is generally applicable to any existing neural networks without modification on the architecture or extra training, and it is orthogonal to prior work on making the classification network itself more robust. Empirical evaluations on three benchmark datasets demonstrate that our RS&V could detect the textual adversarial examples more successfully than the existing detection methods while maintaining the high classification accuracy on benign samples.",
        "bibtex": "@InProceedings{pmlr-v180-wang22b,\n  title = \t {Detecting textual adversarial examples through randomized substitution and vote},\n  author =       {Wang, Xiaosen and Yifeng, Xiong and He, Kun},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2056--2065},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/wang22b/wang22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/wang22b.html},\n  abstract = \t {A line of work has shown that natural text processing models are vulnerable to adversarial examples. Correspondingly, various defense methods are proposed to mitigate the threat of textual adversarial examples, \\textit{e.g.} adversarial training, input transformations, detection, \\textit{etc}. In this work, we treat the optimization process for synonym substitution based textual adversarial attacks as a specific sequence of word replacement, in which each word mutually influences other words. We identify that we could destroy such mutual interaction and eliminate the adversarial perturbation by randomly substituting a word with its synonyms. Based on this observation, we propose a novel textual adversarial example detection method, termed \\textit{Randomized Substitution and Vote} (RS&V), which votes the prediction label by accumulating the logits of $k$ samples generated by randomly substituting the words in the input text with synonyms. The proposed RS&V is generally applicable to any existing neural networks without modification on the architecture or extra training, and it is orthogonal to prior work on making the classification network itself more robust. Empirical evaluations on three benchmark datasets demonstrate that our RS&V could detect the textual adversarial examples more successfully than the existing detection methods while maintaining the high classification accuracy on benign samples.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/wang22b/wang22b.pdf",
        "supp": "",
        "pdf_size": 534321,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14455227801794045518&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China",
        "aff_domain": "hust.edu.cn;hust.edu.cn;hust.edu.cn",
        "email": "hust.edu.cn;hust.edu.cn;hust.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Huazhong University of Science and Technology",
        "aff_unique_dep": "School of Computer Science and Technology",
        "aff_unique_url": "http://www.hust.edu.cn",
        "aff_unique_abbr": "HUST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Wuhan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "190769d793",
        "title": "Deterministic policy gradient: Convergence analysis",
        "site": "https://proceedings.mlr.press/v180/xiong22a.html",
        "author": "Huaqing. Xiong; Tengyu Xu; Lin Zhao; Yingbin Liang; Wei Zhang",
        "abstract": "The deterministic policy gradient (DPG) method proposed in Silver et al. [2014] has been demonstrated to exhibit superior performance particularly for applications with multi-dimensional and continuous action spaces. However, it remains unclear whether DPG converges, and if so, how fast it converges and whether it converges as efficiently as other PG methods. In this paper, we provide a theoretical analysis of DPG to answer those questions. We study the single timescale DPG (often the case in practice) in both on-policy and off-policy settings, and show that both algorithms attain an $\\epsilon$-accurate stationary policy with a sample complexity of $\\mathcal{O}(\\epsilon^{-2})$. Moreover, we establish the convergence rate for DPG under Gaussian noise exploration, which is widely adopted in practice to improve the performance of DPG. To our best knowledge, this is the first non-asymptotic convergence characterization for DPG methods.",
        "bibtex": "@InProceedings{pmlr-v180-xiong22a,\n  title = \t {Deterministic policy gradient: Convergence analysis},\n  author =       {Xiong, Huaqing. and Xu, Tengyu and Zhao, Lin and Liang, Yingbin and Zhang, Wei},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2159--2169},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/xiong22a/xiong22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/xiong22a.html},\n  abstract = \t {The deterministic policy gradient (DPG) method proposed in Silver et al. [2014] has been demonstrated to exhibit superior performance particularly for applications with multi-dimensional and continuous action spaces. However, it remains unclear whether DPG converges, and if so, how fast it converges and whether it converges as efficiently as other PG methods. In this paper, we provide a theoretical analysis of DPG to answer those questions. We study the single timescale DPG (often the case in practice) in both on-policy and off-policy settings, and show that both algorithms attain an $\\epsilon$-accurate stationary policy with a sample complexity of $\\mathcal{O}(\\epsilon^{-2})$. Moreover, we establish the convergence rate for DPG under Gaussian noise exploration, which is widely adopted in practice to improve the performance of DPG. To our best knowledge, this is the first non-asymptotic convergence characterization for DPG methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/xiong22a/xiong22a.pdf",
        "supp": "",
        "pdf_size": 249991,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5965373080016714733&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Electrical and Computer Engineering, The Ohio State University, Columbus, Ohio, USA; Department of Electrical and Computer Engineering, The Ohio State University, Columbus, Ohio, USA; Department of Electrical and Computer Engineering, National University of Singapore, Singapore, Republic of Singapore; Department of Electrical and Computer Engineering, The Ohio State University, Columbus, Ohio, USA; Department of Mechanical and Energy Engineering, Southern University of Science and Technology (SUSTech), Shenzhen, Guangdong, China",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "Ohio State University;National University of Singapore;Southern University of Science and Technology",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Electrical and Computer Engineering;Department of Mechanical and Energy Engineering",
        "aff_unique_url": "https://www.osu.edu;https://www.nus.edu.sg;https://www.sustech.edu.cn",
        "aff_unique_abbr": "OSU;NUS;SUSTech",
        "aff_campus_unique_index": "0;0;1;0;2",
        "aff_campus_unique": "Columbus;Singapore;Shenzhen",
        "aff_country_unique_index": "0;0;1;0;2",
        "aff_country_unique": "United States;Singapore;China"
    },
    {
        "id": "10375c7b5a",
        "title": "Differentially private SGDA for minimax problems",
        "site": "https://proceedings.mlr.press/v180/yang22a.html",
        "author": "Zhenhuan Yang; Shu Hu; Yunwen Lei; Kush R Vashney; Siwei Lyu; Yiming Ying",
        "abstract": "Stochastic gradient descent ascent (SGDA) and its variants have been the workhorse for solving minimax problems. However,  in contrast to the well-studied stochastic gradient descent (SGD) with differential privacy (DP) constraints,  there is  little work on understanding the generalization (utility)  of SGDA with DP constraints. In this paper, we use the algorithmic stability approach to establish the generalization (utility) of DP-SGDA in different settings. In particular, for the convex-concave setting, we prove that the DP-SGDA can achieve  an optimal utility rate in terms of the weak primal-dual population risk in both smooth and non-smooth cases. To our best knowledge, this is the first-ever-known result for DP-SGDA in the non-smooth case.  We further provide its  utility  analysis in   the nonconvex-strongly-concave setting which is  the  first-ever-known result in terms of the primal population risk.  The convergence and generalization results for this nonconvex setting  are new even in the non-private setting.  Finally,  numerical experiments are conducted to  demonstrate the effectiveness of DP-SGDA  for both convex and nonconvex cases.",
        "bibtex": "@InProceedings{pmlr-v180-yang22a,\n  title = \t {Differentially private SGDA for minimax problems},\n  author =       {Yang, Zhenhuan and Hu, Shu and Lei, Yunwen and Vashney, Kush R and Lyu, Siwei and Ying, Yiming},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2192--2202},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yang22a/yang22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yang22a.html},\n  abstract = \t {Stochastic gradient descent ascent (SGDA) and its variants have been the workhorse for solving minimax problems. However,  in contrast to the well-studied stochastic gradient descent (SGD) with differential privacy (DP) constraints,  there is  little work on understanding the generalization (utility)  of SGDA with DP constraints. In this paper, we use the algorithmic stability approach to establish the generalization (utility) of DP-SGDA in different settings. In particular, for the convex-concave setting, we prove that the DP-SGDA can achieve  an optimal utility rate in terms of the weak primal-dual population risk in both smooth and non-smooth cases. To our best knowledge, this is the first-ever-known result for DP-SGDA in the non-smooth case.  We further provide its  utility  analysis in   the nonconvex-strongly-concave setting which is  the  first-ever-known result in terms of the primal population risk.  The convergence and generalization results for this nonconvex setting  are new even in the non-private setting.  Finally,  numerical experiments are conducted to  demonstrate the effectiveness of DP-SGDA  for both convex and nonconvex cases.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yang22a/yang22a.pdf",
        "supp": "",
        "pdf_size": 356958,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7088896679029486802&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e87a559e1f",
        "title": "Differentially private multi-party data release for linear regression",
        "site": "https://proceedings.mlr.press/v180/wu22b.html",
        "author": "Ruihan Wu; Xin Yang; Yuanshun Yao; Jiankai Sun; Tianyi Liu; Q. Kilian Weinberger; Chong Wang",
        "abstract": "Differentially Private (DP) data release is a promising technique to disseminate data without compromising the privacy of data subjects. However the majority of prior work has focused on scenarios where a single party owns all the data. In this paper we focus on the multi-party setting, where different stakeholders own disjoint sets of attributes belonging to the same group of data subjects. Within the context of linear regression that allow all parties to train models on the complete data without the ability to infer private attributes or identities of individuals, we start with directly applying Gaussian mechanism and show it has the small eigenvalue problem. We further propose our novel method and prove it asymptotically converges to the optimal (non-private) solutions with increasing dataset size. We substantiate the theoretical results through experiments on both artificial and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v180-wu22b,\n  title = \t {Differentially private multi-party data release for linear regression},\n  author =       {Wu, Ruihan and Yang, Xin and Yao, Yuanshun and Sun, Jiankai and Liu, Tianyi and Weinberger, Q. Kilian and Wang, Chong},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2128--2137},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/wu22b/wu22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/wu22b.html},\n  abstract = \t {Differentially Private (DP) data release is a promising technique to disseminate data without compromising the privacy of data subjects. However the majority of prior work has focused on scenarios where a single party owns all the data. In this paper we focus on the multi-party setting, where different stakeholders own disjoint sets of attributes belonging to the same group of data subjects. Within the context of linear regression that allow all parties to train models on the complete data without the ability to infer private attributes or identities of individuals, we start with directly applying Gaussian mechanism and show it has the small eigenvalue problem. We further propose our novel method and prove it asymptotically converges to the optimal (non-private) solutions with increasing dataset size. We substantiate the theoretical results through experiments on both artificial and real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/wu22b/wu22b.pdf",
        "supp": "",
        "pdf_size": 17095528,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7110609049745001953&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Cornell University, USA; ByteDance Inc., USA; ByteDance Inc., USA; ByteDance Inc., USA; ByteDance Inc., USA; Cornell University, USA; ByteDance Inc., USA",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;1;0;1",
        "aff_unique_norm": "Cornell University;Bytedance Inc.",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cornell.edu;https://www.bytedance.com",
        "aff_unique_abbr": "Cornell;ByteDance",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7555151f3f",
        "title": "Dimension reduction for high-dimensional small counts with KL divergence",
        "site": "https://proceedings.mlr.press/v180/ling22a.html",
        "author": "Yurong Ling; Jing-Hao Xue",
        "abstract": "Dimension reduction for high-dimensional count data with a large proportion of zeros is an important task in various applications. As a large number of dimension reduction methods rely on the proximity measure, we develop a dissimilarity measure that is well-suited for small counts based on the Kullback-Leibler divergence. We compare the proposed measure with other widely used dissimilarity measures and show that the proposed one has superior discriminative ability when applied to high-dimensional count data having an excess of zeros. Extensive empirical results, on both simulated and publicly-available real-world datasets that contain many zeros, demonstrate that the proposed dissimilarity measure can improve a wide range of dimension reduction methods.",
        "bibtex": "@InProceedings{pmlr-v180-ling22a,\n  title = \t {Dimension reduction for high-dimensional small counts with KL divergence},\n  author =       {Ling, Yurong and Xue, Jing-Hao},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1210--1220},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ling22a/ling22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ling22a.html},\n  abstract = \t {Dimension reduction for high-dimensional count data with a large proportion of zeros is an important task in various applications. As a large number of dimension reduction methods rely on the proximity measure, we develop a dissimilarity measure that is well-suited for small counts based on the Kullback-Leibler divergence. We compare the proposed measure with other widely used dissimilarity measures and show that the proposed one has superior discriminative ability when applied to high-dimensional count data having an excess of zeros. Extensive empirical results, on both simulated and publicly-available real-world datasets that contain many zeros, demonstrate that the proposed dissimilarity measure can improve a wide range of dimension reduction methods. }\n}",
        "pdf": "https://proceedings.mlr.press/v180/ling22a/ling22a.pdf",
        "supp": "",
        "pdf_size": 787160,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16516536595746315228&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Statistical Science, University College London, London, UK; Department of Statistical Science, University College London, London, UK",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Department of Statistical Science",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "27265878c4",
        "title": "Discovery of extended summary graphs in time series",
        "site": "https://proceedings.mlr.press/v180/assaad22a.html",
        "author": "Charles K. Assaad; Emilie Devijver; Eric Gaussier",
        "abstract": "This study addresses the problem of learning an extended summary causal graph from time series. The algorithms we propose fit within the well-known constraint-based framework for causal discovery and make use of information-theoretic measures to determine (in)dependencies between time series. We first introduce generalizations of the causation entropy measure to any lagged or instantaneous relations, prior to using this measure to construct extended summary causal graphs by adapting two well-known algorithms, namely PC and FCI. The behaviour of our method is illustrated through several experiments.",
        "bibtex": "@InProceedings{pmlr-v180-assaad22a,\n  title = \t {Discovery of extended summary graphs in time series},\n  author =       {Assaad, Charles K. and Devijver, Emilie and Gaussier, Eric},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {96--106},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/assaad22a/assaad22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/assaad22a.html},\n  abstract = \t {This study addresses the problem of learning an extended summary causal graph from time series. The algorithms we propose fit within the well-known constraint-based framework for causal discovery and make use of information-theoretic measures to determine (in)dependencies between time series. We first introduce generalizations of the causation entropy measure to any lagged or instantaneous relations, prior to using this measure to construct extended summary causal graphs by adapting two well-known algorithms, namely PC and FCI. The behaviour of our method is illustrated through several experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/assaad22a/assaad22a.pdf",
        "supp": "",
        "pdf_size": 352823,
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9448214709318415313&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "EasyVista, 38000, Grenoble, France+Univ. Grenoble Alpes, CNRS, Grenoble INP, LIG, 38000 Grenoble, France; Univ. Grenoble Alpes, CNRS, Grenoble INP, LIG, 38000 Grenoble, France; Univ. Grenoble Alpes, CNRS, Grenoble INP, LIG, 38000 Grenoble, France",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1;1",
        "aff_unique_norm": "EasyVista;Universite Grenoble Alpes",
        "aff_unique_dep": ";Laboratoire d'Informatique de Grenoble (LIG)",
        "aff_unique_url": ";https://www.univ-grenoble-alpes.fr",
        "aff_unique_abbr": ";UGA",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Grenoble",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "d65fb3fcbb",
        "title": "Distributed adversarial training to robustify deep neural networks at scale",
        "site": "https://proceedings.mlr.press/v180/zhang22a.html",
        "author": "Gaoyuan Zhang; Songtao Lu; Yihua Zhang; Xiangyi Chen; Pin-Yu Chen; Quanfu Fan; Lee Martie; Lior Horesh; Mingyi Hong; Sijia Liu",
        "abstract": "Current deep neural networks (DNNs) are vulnerable to adversarial attacks, where adversarial perturbations to the inputs can change or manipulate classification. To defend against such attacks, an effective and popular approach, known as adversarial training (AT), has been shown to mitigate the negative impact of adversarial attacks by virtue of a min-max robust training method. While effective, it remains unclear whether it can successfully be adapted to the distributed learning context. The power of distributed optimization over multiple machines enables us to scale up robust training over large models and datasets. Spurred by that, we propose distributed adversarial training (DAT), a large-batch adversarial training framework implemented over multiple machines. We show that DAT is general, which supports training over labeled and unlabeled data, multiple types of attack generation methods, and gradient compression operations favored for distributed optimization. Theoretically, we provide, under standard conditions in the optimization theory, the convergence rate of DAT to the first-order stationary points in general non-convex settings. Empirically, we demonstrate that DAT either matches or outperforms state-of-the-art robust accuracies and achieves a graceful training speedup (e.g., on ResNet-50 under ImageNet). Codes are available at https://github.com/dat-2022/dat.",
        "bibtex": "@InProceedings{pmlr-v180-zhang22a,\n  title = \t {Distributed adversarial training to robustify deep neural networks at scale},\n  author =       {Zhang, Gaoyuan and Lu, Songtao and Zhang, Yihua and Chen, Xiangyi and Chen, Pin-Yu and Fan, Quanfu and Martie, Lee and Horesh, Lior and Hong, Mingyi and Liu, Sijia},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2353--2363},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/zhang22a/zhang22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/zhang22a.html},\n  abstract = \t {Current deep neural networks (DNNs) are vulnerable to adversarial attacks, where adversarial perturbations to the inputs can change or manipulate classification. To defend against such attacks, an effective and popular approach, known as adversarial training (AT), has been shown to mitigate the negative impact of adversarial attacks by virtue of a min-max robust training method. While effective, it remains unclear whether it can successfully be adapted to the distributed learning context. The power of distributed optimization over multiple machines enables us to scale up robust training over large models and datasets. Spurred by that, we propose distributed adversarial training (DAT), a large-batch adversarial training framework implemented over multiple machines. We show that DAT is general, which supports training over labeled and unlabeled data, multiple types of attack generation methods, and gradient compression operations favored for distributed optimization. Theoretically, we provide, under standard conditions in the optimization theory, the convergence rate of DAT to the first-order stationary points in general non-convex settings. Empirically, we demonstrate that DAT either matches or outperforms state-of-the-art robust accuracies and achieves a graceful training speedup (e.g., on ResNet-50 under ImageNet). Codes are available at https://github.com/dat-2022/dat.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/zhang22a/zhang22a.pdf",
        "supp": "",
        "pdf_size": 358946,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17955922536544917562&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;;;;;;;",
        "aff_domain": ";;;;;;;;;",
        "email": ";;;;;;;;;",
        "github": "",
        "project": "",
        "author_num": 10,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1ea00113af",
        "title": "Do Bayesian variational autoencoders know what they don\u2019t know?",
        "site": "https://proceedings.mlr.press/v180/glazunov22a.html",
        "author": "Misha Glazunov; Apostolis Zarras",
        "abstract": "The problem of detecting the Out-of-Distribution (OoD) inputs is of paramount importance for Deep Neural Networks. It has been previously shown that even Deep Generative Models that allow estimating the density of the inputs may not be reliable and often tend to make over-confident predictions for OoDs, assigning to them a higher density than to the in-distribution data. This over-confidence in a single model can be potentially mitigated with Bayesian inference over the model parameters that take into account epistemic uncertainty. This paper investigates three approaches to Bayesian inference: stochastic gradient Markov chain Monte Carlo, Bayes by Backpropagation, and Stochastic Weight Averaging-Gaussian. The inference is implemented over the weights of the deep neural networks that parameterize the likelihood of the Variational Autoencoder. We empirically evaluate the approaches against several benchmarks that are often used for OoD detection: estimation of the marginal likelihood utilizing sampled model ensemble, typicality test, disagreement score, and Watanabe-Akaike Information Criterion. Finally, we introduce two simple scores that demonstrate the state-of-the-art performance.",
        "bibtex": "@InProceedings{pmlr-v180-glazunov22a,\n  title = \t {Do Bayesian variational autoencoders know what they don\u2019t know?},\n  author =       {Glazunov, Misha and Zarras, Apostolis},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {718--727},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/glazunov22a/glazunov22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/glazunov22a.html},\n  abstract = \t {The problem of detecting the Out-of-Distribution (OoD) inputs is of paramount importance for Deep Neural Networks. It has been previously shown that even Deep Generative Models that allow estimating the density of the inputs may not be reliable and often tend to make over-confident predictions for OoDs, assigning to them a higher density than to the in-distribution data. This over-confidence in a single model can be potentially mitigated with Bayesian inference over the model parameters that take into account epistemic uncertainty. This paper investigates three approaches to Bayesian inference: stochastic gradient Markov chain Monte Carlo, Bayes by Backpropagation, and Stochastic Weight Averaging-Gaussian. The inference is implemented over the weights of the deep neural networks that parameterize the likelihood of the Variational Autoencoder. We empirically evaluate the approaches against several benchmarks that are often used for OoD detection: estimation of the marginal likelihood utilizing sampled model ensemble, typicality test, disagreement score, and Watanabe-Akaike Information Criterion. Finally, we introduce two simple scores that demonstrate the state-of-the-art performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/glazunov22a/glazunov22a.pdf",
        "supp": "",
        "pdf_size": 460261,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=971266465418965547&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Delft University of Technology, the Netherlands; Delft University of Technology, the Netherlands",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TUDelft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "4d2410f9bc",
        "title": "Dynamic relocation in ridesharing via fixpoint construction",
        "site": "https://proceedings.mlr.press/v180/kash22a.html",
        "author": "Ian A. Kash; Zhongkai Wen; Lenore D. Zuck",
        "abstract": "To address spatial imbalances in the supply and demand of drivers, ridesharing platforms can make use of policies to direct driver relocation.  We study a simple model of this problem, which allows us to give a constructive characterization of the unique fixpoint of system dynamics.  Using this construction, we design a dynamic policy that provides stronger, than previous work,  guarantees about its rate of convergence to the fixpoint.  Simulations demonstrate the benefits of our approach.",
        "bibtex": "@InProceedings{pmlr-v180-kash22a,\n  title = \t {Dynamic relocation in ridesharing via fixpoint construction },\n  author =       {Kash, Ian A. and Wen, Zhongkai and Zuck, Lenore D.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {980--989},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/kash22a/kash22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/kash22a.html},\n  abstract = \t {To address spatial imbalances in the supply and demand of drivers, ridesharing platforms can make use of policies to direct driver relocation.  We study a simple model of this problem, which allows us to give a constructive characterization of the unique fixpoint of system dynamics.  Using this construction, we design a dynamic policy that provides stronger, than previous work,  guarantees about its rate of convergence to the fixpoint.  Simulations demonstrate the benefits of our approach.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/kash22a/kash22a.pdf",
        "supp": "",
        "pdf_size": 313258,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5727833294805258169&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5e17cf67ff",
        "title": "Efficient and accurate top-k recovery from choice data",
        "site": "https://proceedings.mlr.press/v180/nguyen22b.html",
        "author": "Duc Nguyen",
        "abstract": "The intersection of learning to rank and choice modeling is an active area of research with applications in e-commerce, information retrieval and the social sciences. In some applications such as recommendation systems, the statistician is primarily interested in recovering the set of the top ranked items from a large pool of items as efficiently as possible using passively collected discrete choice data, i.e., the user picks one item from a set of multiple items. Motivated by this practical consideration, we propose the choice-based Borda count algorithm as a fast and accurate ranking algorithm for top $K$-recovery i.e., correctly identifying all of the top $K$ items. We show that the choice-based Borda count algorithm has optimal sample complexity for top-$K$ recovery under a broad class of random utility models. We prove that in the limit, the choice-based Borda count algorithm produces the same top-$K$ estimate as the commonly used Maximum Likelihood Estimate method but the former\u2019s speed and simplicity brings considerable advantages in practice. Experiments on both synthetic and real datasets show that the counting algorithm is competitive with commonly used ranking algorithms in terms of accuracy while being several orders of magnitude faster.",
        "bibtex": "@InProceedings{pmlr-v180-nguyen22b,\n  title = \t {Efficient and accurate top-k recovery from choice data},\n  author =       {Nguyen, Duc},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1509--1518},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/nguyen22b/nguyen22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/nguyen22b.html},\n  abstract = \t {The intersection of learning to rank and choice modeling is an active area of research with applications in e-commerce, information retrieval and the social sciences. In some applications such as recommendation systems, the statistician is primarily interested in recovering the set of the top ranked items from a large pool of items as efficiently as possible using passively collected discrete choice data, i.e., the user picks one item from a set of multiple items. Motivated by this practical consideration, we propose the choice-based Borda count algorithm as a fast and accurate ranking algorithm for top $K$-recovery i.e., correctly identifying all of the top $K$ items. We show that the choice-based Borda count algorithm has optimal sample complexity for top-$K$ recovery under a broad class of random utility models. We prove that in the limit, the choice-based Borda count algorithm produces the same top-$K$ estimate as the commonly used Maximum Likelihood Estimate method but the former\u2019s speed and simplicity brings considerable advantages in practice. Experiments on both synthetic and real datasets show that the counting algorithm is competitive with commonly used ranking algorithms in terms of accuracy while being several orders of magnitude faster.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/nguyen22b/nguyen22b.pdf",
        "supp": "",
        "pdf_size": 429273,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Hq5OvW595zYJ:scholar.google.com/&scioq=Efficient+and+accurate+top-k+recovery+from+choice+data&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "aff": "Department of Computer and Information Science, University of Pennsylvania",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Department of Computer and Information Science",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f2098cb4ef",
        "title": "Efficient and transferable adversarial examples from bayesian neural networks",
        "site": "https://proceedings.mlr.press/v180/gubri22a.html",
        "author": "Martin Gubri; Maxime Cordy; Mike Papadakis; Yves Le Traon; Koushik Sen",
        "abstract": "An established way to improve the transferability of black-box evasion attacks is to craft the adversarial examples on an ensemble-based surrogate to increase diversity. We argue that transferability is fundamentally related to uncertainty. Based on a state-of-the-art Bayesian Deep Learning technique, we propose a new method to efficiently build a surrogate by sampling approximately from the posterior distribution of neural network weights, which represents the belief about the value of each parameter. Our extensive experiments on ImageNet, CIFAR-10 and MNIST show that our approach improves the success rates of four state-of-the-art attacks significantly (up to 83.2 percentage points), in both intra-architecture and inter-architecture transferability. On ImageNet, our approach can reach 94% of success rate while reducing training computations from 11.6 to 2.4 exaflops, compared to an ensemble of independently trained DNNs. Our vanilla surrogate achieves 87.5% of the time higher transferability than three test-time techniques designed for this purpose. Our work demonstrates that the way to train a surrogate has been overlooked, although it is an important element of transfer-based attacks. We are, therefore, the first to review the effectiveness of several training methods in increasing transferability. We provide new directions to better understand the transferability phenomenon and offer a simple but strong baseline for future work.",
        "bibtex": "@InProceedings{pmlr-v180-gubri22a,\n  title = \t {Efficient and transferable adversarial examples from bayesian neural networks},\n  author =       {Gubri, Martin and Cordy, Maxime and Papadakis, Mike and Le Traon, Yves and Sen, Koushik},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {738--748},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/gubri22a/gubri22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/gubri22a.html},\n  abstract = \t {An established way to improve the transferability of black-box evasion attacks is to craft the adversarial examples on an ensemble-based surrogate to increase diversity. We argue that transferability is fundamentally related to uncertainty. Based on a state-of-the-art Bayesian Deep Learning technique, we propose a new method to efficiently build a surrogate by sampling approximately from the posterior distribution of neural network weights, which represents the belief about the value of each parameter. Our extensive experiments on ImageNet, CIFAR-10 and MNIST show that our approach improves the success rates of four state-of-the-art attacks significantly (up to 83.2 percentage points), in both intra-architecture and inter-architecture transferability. On ImageNet, our approach can reach 94% of success rate while reducing training computations from 11.6 to 2.4 exaflops, compared to an ensemble of independently trained DNNs. Our vanilla surrogate achieves 87.5% of the time higher transferability than three test-time techniques designed for this purpose. Our work demonstrates that the way to train a surrogate has been overlooked, although it is an important element of transfer-based attacks. We are, therefore, the first to review the effectiveness of several training methods in increasing transferability. We provide new directions to better understand the transferability phenomenon and offer a simple but strong baseline for future work.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/gubri22a/gubri22a.pdf",
        "supp": "",
        "pdf_size": 492789,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2945454159737611926&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "University of Luxembourg; University of Luxembourg; University of Luxembourg; University of Luxembourg; University of California, Berkeley",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of Luxembourg;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://wwwen.uniluxembourg.lu;https://www.berkeley.edu",
        "aff_unique_abbr": "Uni Lu;UC Berkeley",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Luxembourg;United States"
    },
    {
        "id": "841975cd46",
        "title": "Efficient inference for dynamic topic modeling with large vocabularies",
        "site": "https://proceedings.mlr.press/v180/tomasi22a.html",
        "author": "Federico Tomasi; Mounia Lalmas; Zhenwen Dai",
        "abstract": "Dynamic topic modeling is a well established tool for capturing the temporal dynamics of the topics of a corpus. In this work, we develop a scalable dynamic topic model by utilizing the correlation among the words in the vocabulary. By correlating previously independent temporal processes for words, our new model allows us to reliably estimate the topic representations containing less frequent words. We develop an amortised variational inference method with self-normalised importance sampling approximation to the word distribution that dramatically reduces the computational complexity and the number of variational parameters in order to handle large vocabularies. With extensive experiments on text datasets, we show that our method significantly outperforms the previous works by modeling word correlations, and it is able to handle real world data with a large vocabulary which could not be processed by previous continuous dynamic topic models.",
        "bibtex": "@InProceedings{pmlr-v180-tomasi22a,\n  title = \t {Efficient inference for dynamic topic modeling with large vocabularies},\n  author =       {Tomasi, Federico and Lalmas, Mounia and Dai, Zhenwen},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1950--1959},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/tomasi22a/tomasi22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/tomasi22a.html},\n  abstract = \t {Dynamic topic modeling is a well established tool for capturing the temporal dynamics of the topics of a corpus. In this work, we develop a scalable dynamic topic model by utilizing the correlation among the words in the vocabulary. By correlating previously independent temporal processes for words, our new model allows us to reliably estimate the topic representations containing less frequent words. We develop an amortised variational inference method with self-normalised importance sampling approximation to the word distribution that dramatically reduces the computational complexity and the number of variational parameters in order to handle large vocabularies. With extensive experiments on text datasets, we show that our method significantly outperforms the previous works by modeling word correlations, and it is able to handle real world data with a large vocabulary which could not be processed by previous continuous dynamic topic models.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/tomasi22a/tomasi22a.pdf",
        "supp": "",
        "pdf_size": 1884391,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18154550463397315340&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "499f91056a",
        "title": "Efficient learning of sparse and decomposable PDEs using random projection",
        "site": "https://proceedings.mlr.press/v180/nasim22a.html",
        "author": "Md Nasim; Xinghang Zhang; Anter El-Azab; Yexiang Xue",
        "abstract": "Learning physics models in the form of Partial Differential Equations (PDEs) is carried out through back-propagation to match the simulations of the physics model with experimental observations. Nevertheless, such matching involves computation over billions of elements, presenting a significant computational overhead. We notice many PDEs in real world problems are sparse and decomposable, where the temporal updates and the spatial features are sparsely concentrated on small interface regions. We propose RAPID-PDE, an algorithm to expedite the learning of sparse and decomposable PDEs. Our RAPID-PDE first uses random projection to compress the high dimensional sparse updates and features into low dimensional representations and then use these compressed signals during learning. Crucially, such a conversion is only carried out once prior to learning and the entire learning process is conducted in the compressed space. Theoretically, we derive a constant factor approximation between the projected loss function and the original one with logarithmic number of projected dimensions. Empirically, we demonstrate RAPID-PDE with data compressed to 0.05% of its original size learns similar models compared with uncompressed algorithms in learning a set of phase-field models which govern the spatial-temporal dynamics of nano-scale structures in metallic materials.",
        "bibtex": "@InProceedings{pmlr-v180-nasim22a,\n  title = \t {Efficient learning of sparse and decomposable PDEs using random projection},\n  author =       {Nasim, Md and Zhang, Xinghang and El-Azab, Anter and Xue, Yexiang},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1466--1476},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/nasim22a/nasim22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/nasim22a.html},\n  abstract = \t {Learning physics models in the form of Partial Differential Equations (PDEs) is carried out through back-propagation to match the simulations of the physics model with experimental observations. Nevertheless, such matching involves computation over billions of elements, presenting a significant computational overhead. We notice many PDEs in real world problems are sparse and decomposable, where the temporal updates and the spatial features are sparsely concentrated on small interface regions. We propose RAPID-PDE, an algorithm to expedite the learning of sparse and decomposable PDEs. Our RAPID-PDE first uses random projection to compress the high dimensional sparse updates and features into low dimensional representations and then use these compressed signals during learning. Crucially, such a conversion is only carried out once prior to learning and the entire learning process is conducted in the compressed space. Theoretically, we derive a constant factor approximation between the projected loss function and the original one with logarithmic number of projected dimensions. Empirically, we demonstrate RAPID-PDE with data compressed to 0.05% of its original size learns similar models compared with uncompressed algorithms in learning a set of phase-field models which govern the spatial-temporal dynamics of nano-scale structures in metallic materials.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/nasim22a/nasim22a.pdf",
        "supp": "",
        "pdf_size": 1406159,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3051333847024840878&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b5945d0036",
        "title": "Efficient resource allocation with fairness constraints in restless multi-armed bandits",
        "site": "https://proceedings.mlr.press/v180/li22e.html",
        "author": "Dexun. Li; Pradeep Varakantham",
        "abstract": "Restless Multi-Armed Bandits (RMAB) is an apt model to represent decision-making problems in public health interventions (e.g., tuberculosis, maternal, and child care), anti-poaching planning, sensor monitoring, personalized recommendations and many more. Existing research in RMAB has contributed mechanisms and theoretical results to a wide variety of settings, where the focus is on maximizing expected value. In this paper, we are interested in ensuring that RMAB decision making is also fair to different arms while maximizing expected value. In the context of public health settings, this would ensure that different people and/or communities are fairly represented while making public health intervention decisions. To achieve this goal, we formally define the fairness constraints in RMAB and provide planning and learning methods to solve RMAB in a fair manner. We demonstrate key theoretical properties of fair RMAB and experimentally demonstrate that our proposed methods handle fairness constraints without sacrificing significantly on solution quality.",
        "bibtex": "@InProceedings{pmlr-v180-li22e,\n  title = \t {Efficient resource allocation with fairness constraints in restless multi-armed bandits},\n  author =       {Li, Dexun. and Varakantham, Pradeep},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1158--1167},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/li22e/li22e.pdf},\n  url = \t {https://proceedings.mlr.press/v180/li22e.html},\n  abstract = \t {Restless Multi-Armed Bandits (RMAB) is an apt model to represent decision-making problems in public health interventions (e.g., tuberculosis, maternal, and child care), anti-poaching planning, sensor monitoring, personalized recommendations and many more. Existing research in RMAB has contributed mechanisms and theoretical results to a wide variety of settings, where the focus is on maximizing expected value. In this paper, we are interested in ensuring that RMAB decision making is also fair to different arms while maximizing expected value. In the context of public health settings, this would ensure that different people and/or communities are fairly represented while making public health intervention decisions. To achieve this goal, we formally define the fairness constraints in RMAB and provide planning and learning methods to solve RMAB in a fair manner. We demonstrate key theoretical properties of fair RMAB and experimentally demonstrate that our proposed methods handle fairness constraints without sacrificing significantly on solution quality.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/li22e/li22e.pdf",
        "supp": "",
        "pdf_size": 415522,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5611012090563531009&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "School of Computing and Information Systems, Singapore Management University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Singapore Management University",
        "aff_unique_dep": "School of Computing and Information Systems",
        "aff_unique_url": "https://www.smu.edu.sg",
        "aff_unique_abbr": "SMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "7349aa4e3f",
        "title": "Empirical bayes approach to truth discovery problems",
        "site": "https://proceedings.mlr.press/v180/ben-shabat22a.html",
        "author": "Tsviel Ben Shabat; Reshef Meir; David Azriel",
        "abstract": "When aggregating information from conflicting sources, one\u2019s goal is to find the truth. Most real-value truth discovery (TD) algorithms try to achieve this goal by estimating the competence of each source and then aggregating the conflicting information by weighing each source\u2019s answer proportionally to her competence. However, each of those algorithms requires more than a single source for such estimation and usually does not consider different estimation methods other than a weighted mean. Therefore, in this work we formulate, prove, and empirically test the conditions for an Empirical Bayes Estimator (EBE) to dominate the weighted mean aggregation. Our main result demonstrates that EBE, under mild conditions, can be used as a second step of any TD algorithm in order to reduce the expected error.",
        "bibtex": "@InProceedings{pmlr-v180-ben-shabat22a,\n  title = \t {Empirical bayes approach to truth discovery problems},\n  author =       {Ben Shabat, Tsviel and Meir, Reshef and Azriel, David},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {150--158},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ben-shabat22a/ben-shabat22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ben-shabat22a.html},\n  abstract = \t {When aggregating information from conflicting sources, one\u2019s goal is to find the truth. Most real-value truth discovery (TD) algorithms try to achieve this goal by estimating the competence of each source and then aggregating the conflicting information by weighing each source\u2019s answer proportionally to her competence. However, each of those algorithms requires more than a single source for such estimation and usually does not consider different estimation methods other than a weighted mean. Therefore, in this work we formulate, prove, and empirically test the conditions for an Empirical Bayes Estimator (EBE) to dominate the weighted mean aggregation. Our main result demonstrates that EBE, under mild conditions, can be used as a second step of any TD algorithm in order to reduce the expected error.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/ben-shabat22a/ben-shabat22a.pdf",
        "supp": "",
        "pdf_size": 928295,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17366469704778918607&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9702e1ea7e",
        "title": "Enhanced adaptive optics control with image to image translation",
        "site": "https://proceedings.mlr.press/v180/smith22a.html",
        "author": "Jeffrey Smith; Jesse Cranney; Charles Gretton; Damien Gratadour",
        "abstract": "We aim to significantly enhance the science return of astronomical observatories, and in particular giant terrestrial optical telescopes. Observatories employ Adaptive Optics (AO) systems in order to acquire high sensitivity diffraction limited images of the sky. The incumbent \u201cworkhorse\u201d for control of AO systems employs a linear real-time controller in a closed loop, with sensing of state performed via a (Shack-Hartmann) wavefront sensor (WFS). The actuators of a deformable mirror (DM) are driven, with the action performed in each iteration having a continuous representation as an array of DC voltages. The typical control regime is practical and scalable, nonetheless, there remains a residual uncompensated turbulence that leads to optical aberrations limiting the class of scientific assets that can be acquired. We have developed and trained a translational GAN model that accurately estimates residual perturbations from WFS images. Model inference occurs in 0.34 milliseconds using off-the-shelf GPU hardware, and is applicable for use in AO control where the control loop might be running at 500Hz. We develop an AO control regime with a second controller stage actuating a second DM controlled in an open loop according to the estimated residual turbulence. Using the open-source COMPASS tool for simulation, we are able to significantly improve the performance using our new regime.",
        "bibtex": "@InProceedings{pmlr-v180-smith22a,\n  title = \t {Enhanced adaptive optics control with image to image translation},\n  author =       {Smith, Jeffrey and Cranney, Jesse and Gretton, Charles and Gratadour, Damien},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1846--1856},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/smith22a/smith22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/smith22a.html},\n  abstract = \t {We aim to significantly enhance the science return of astronomical observatories, and in particular giant terrestrial optical telescopes. Observatories employ Adaptive Optics (AO) systems in order to acquire high sensitivity diffraction limited images of the sky. The incumbent \u201cworkhorse\u201d for control of AO systems employs a linear real-time controller in a closed loop, with sensing of state performed via a (Shack-Hartmann) wavefront sensor (WFS). The actuators of a deformable mirror (DM) are driven, with the action performed in each iteration having a continuous representation as an array of DC voltages. The typical control regime is practical and scalable, nonetheless, there remains a residual uncompensated turbulence that leads to optical aberrations limiting the class of scientific assets that can be acquired. We have developed and trained a translational GAN model that accurately estimates residual perturbations from WFS images. Model inference occurs in 0.34 milliseconds using off-the-shelf GPU hardware, and is applicable for use in AO control where the control loop might be running at 500Hz. We develop an AO control regime with a second controller stage actuating a second DM controlled in an open loop according to the estimated residual turbulence. Using the open-source COMPASS tool for simulation, we are able to significantly improve the performance using our new regime.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/smith22a/smith22a.pdf",
        "supp": "",
        "pdf_size": 1120929,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9833904748957656119&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cdc9563301",
        "title": "Equilibrium aggregation: encoding sets via optimization",
        "site": "https://proceedings.mlr.press/v180/bartunov22a.html",
        "author": "Sergey Bartunov; Fabian B. Fuchs; Timothy P. Lillicrap",
        "abstract": "Processing sets or other unordered, potentially variable-sized inputs in neural networks is usually handled by aggregating a number of input tensors into a single representation. While a number of aggregation methods already exist from simple sum pooling to multi-head attention, they are limited in their representational power both from theoretical and empirical perspectives. On the search of a principally more powerful aggregation strategy, we propose an optimization-based method called Equilibrium Aggregation. We show that many existing aggregation methods can be recovered as special cases of Equilibrium Aggregation and that it is provably more efficient in some important cases. Equilibrium Aggregation can be used as a drop-in replacement in many existing architectures and applications. We validate its efficiency on three different tasks: median estimation, class counting, and molecular property prediction. In all experiments, Equilibrium Aggregation achieves higher performance than the other aggregation techniques we test.",
        "bibtex": "@InProceedings{pmlr-v180-bartunov22a,\n  title = \t {Equilibrium aggregation: encoding sets via optimization},\n  author =       {Bartunov, Sergey and Fuchs, Fabian B. and Lillicrap, Timothy P.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {139--149},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/bartunov22a/bartunov22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/bartunov22a.html},\n  abstract = \t {Processing sets or other unordered, potentially variable-sized inputs in neural networks is usually handled by aggregating a number of input tensors into a single representation. While a number of aggregation methods already exist from simple sum pooling to multi-head attention, they are limited in their representational power both from theoretical and empirical perspectives. On the search of a principally more powerful aggregation strategy, we propose an optimization-based method called Equilibrium Aggregation. We show that many existing aggregation methods can be recovered as special cases of Equilibrium Aggregation and that it is provably more efficient in some important cases. Equilibrium Aggregation can be used as a drop-in replacement in many existing architectures and applications. We validate its efficiency on three different tasks: median estimation, class counting, and molecular property prediction. In all experiments, Equilibrium Aggregation achieves higher performance than the other aggregation techniques we test.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/bartunov22a/bartunov22a.pdf",
        "supp": "",
        "pdf_size": 986777,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14949321278073413353&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "728c4c41c7",
        "title": "Estimating transfer entropy under long ranged dependencies",
        "site": "https://proceedings.mlr.press/v180/garg22a.html",
        "author": "Sahil Garg; Umang Gupta; Yu Chen; Syamantak Datta Gupta; Yeshaya Adler; Anderson Schneider; Yuriy Nevmyvaka",
        "abstract": "Estimating Transfer Entropy (TE) between time series is a highly impactful  problem in fields such as finance and neuroscience. The well-known nearest neighbor estimator of TE potentially fails if temporal dependencies are noisy and long ranged, primarily because it estimates TE indirectly relying on the estimation of joint entropy terms in high dimensions, which is a hard problem in itself. Other estimators, such as those based on Copula entropy or conditional mutual information have similar limitations. Leveraging the successes of modern discriminative models that operate in high dimensional (noisy) feature spaces, we express TE as a difference of two conditional entropy terms, which we directly estimate from conditional likelihoods computed in-sample from any discriminator (timeseries forecaster) trained per maximum likelihood principle. To ensure that the in-sample log likelihood estimates are not overfit to the data, we propose a novel perturbation model based on locality sensitive hash (LSH) functions, which regularizes a discriminative model to have smooth functional outputs within local neighborhoods of the input space. Our estimator is consistent, and its variance reduces linearly in sample size. We also demonstrate its superiority w.r.t. state-of-the-art estimators through empirical evaluations on a synthetic as well as real world datasets from the neuroscience and finance domains.",
        "bibtex": "@InProceedings{pmlr-v180-garg22a,\n  title = \t {Estimating transfer entropy under long ranged dependencies},\n  author =       {Garg, Sahil and Gupta, Umang and Chen, Yu and Gupta, Syamantak Datta and Adler, Yeshaya and Schneider, Anderson and Nevmyvaka, Yuriy},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {685--695},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/garg22a/garg22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/garg22a.html},\n  abstract = \t {Estimating Transfer Entropy (TE) between time series is a highly impactful  problem in fields such as finance and neuroscience. The well-known nearest neighbor estimator of TE potentially fails if temporal dependencies are noisy and long ranged, primarily because it estimates TE indirectly relying on the estimation of joint entropy terms in high dimensions, which is a hard problem in itself. Other estimators, such as those based on Copula entropy or conditional mutual information have similar limitations. Leveraging the successes of modern discriminative models that operate in high dimensional (noisy) feature spaces, we express TE as a difference of two conditional entropy terms, which we directly estimate from conditional likelihoods computed in-sample from any discriminator (timeseries forecaster) trained per maximum likelihood principle. To ensure that the in-sample log likelihood estimates are not overfit to the data, we propose a novel perturbation model based on locality sensitive hash (LSH) functions, which regularizes a discriminative model to have smooth functional outputs within local neighborhoods of the input space. Our estimator is consistent, and its variance reduces linearly in sample size. We also demonstrate its superiority w.r.t. state-of-the-art estimators through empirical evaluations on a synthetic as well as real world datasets from the neuroscience and finance domains.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/garg22a/garg22a.pdf",
        "supp": "",
        "pdf_size": 3880228,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6577872381959158922&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Department of Machine Learning Research, Morgan Stanley, New York, NY, USA + Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Machine Learning Research, Morgan Stanley, New York, NY, USA; Department of Machine Learning Research, Morgan Stanley, New York, NY, USA; Department of Machine Learning Research, Morgan Stanley, New York, NY, USA; Department of Machine Learning Research, Morgan Stanley, New York, NY, USA; Department of Machine Learning Research, Morgan Stanley, New York, NY, USA",
        "aff_domain": "gmail.com;morganstanley.com; ; ; ; ; ",
        "email": "gmail.com;morganstanley.com; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1;0;0;0;0;0",
        "aff_unique_norm": "Morgan Stanley;University of Southern California",
        "aff_unique_dep": "Department of Machine Learning Research;Department of Computer Science",
        "aff_unique_url": "https://www.morganstanley.com;https://www.usc.edu",
        "aff_unique_abbr": "MS;USC",
        "aff_campus_unique_index": "0+1;1;0;0;0;0;0",
        "aff_campus_unique": "New York;Los Angeles",
        "aff_country_unique_index": "0+0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d2bab10483",
        "title": "Evaluating high-order predictive distributions in deep learning",
        "site": "https://proceedings.mlr.press/v180/osband22a.html",
        "author": "Ian Osband; Zheng Wen; Seyed Mohammad Asghari; Vikranth Dwaracherla; Xiuyuan Lu; Benjamin Van Roy",
        "abstract": "Most work on supervised learning research has focused on marginal predictions. In decision problems, joint predictive distributions are essential for good performance. Previous work has developed methods for assessing low-order predictive distributions with inputs sampled i.i.d. from the testing distribution. With low-dimensional inputs, these methods distinguish agents that effectively estimate uncertainty from those that do not. We establish that the predictive distribution order required for such differentiation increases greatly with input dimension, rendering these methods impractical. To accommodate high-dimensional inputs, we introduce dyadic sampling, which focuses on predictive distributions associated with random pairs of inputs. We demonstrate that this approach efficiently distinguishes agents in high-dimensional examples involving simple logistic regression as well as complex synthetic and empirical data.",
        "bibtex": "@InProceedings{pmlr-v180-osband22a,\n  title = \t {Evaluating high-order predictive distributions in deep learning},\n  author =       {Osband, Ian and Wen, Zheng and Asghari, Seyed Mohammad and Dwaracherla, Vikranth and Lu, Xiuyuan and Van Roy, Benjamin},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1552--1560},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/osband22a/osband22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/osband22a.html},\n  abstract = \t {Most work on supervised learning research has focused on marginal predictions. In decision problems, joint predictive distributions are essential for good performance. Previous work has developed methods for assessing low-order predictive distributions with inputs sampled i.i.d. from the testing distribution. With low-dimensional inputs, these methods distinguish agents that effectively estimate uncertainty from those that do not. We establish that the predictive distribution order required for such differentiation increases greatly with input dimension, rendering these methods impractical. To accommodate high-dimensional inputs, we introduce dyadic sampling, which focuses on predictive distributions associated with random pairs of inputs. We demonstrate that this approach efficiently distinguishes agents in high-dimensional examples involving simple logistic regression as well as complex synthetic and empirical data.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/osband22a/osband22a.pdf",
        "supp": "",
        "pdf_size": 392585,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10159554942845999252&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fd37ed1a64",
        "title": "Expectation programming: Adapting probabilistic programming systems to estimate expectations efficiently",
        "site": "https://proceedings.mlr.press/v180/reichelt22a.html",
        "author": "Tim Reichelt; Adam Goli\u0144ski; Luke Ong; Tom Rainforth",
        "abstract": "We show that the standard computational pipeline of probabilistic programming systems (PPSs) can be inefficient for estimating expectations and introduce the concept of expectation programming to address this. In expectation programming, the aim of the backend inference engine is to directly estimate expected return values of programs, as opposed to approximating their conditional distributions. This distinction, while subtle, allows us to achieve substantial performance improvements over the standard PPS computational pipeline by tailoring computation to the expectation we care about. We realize a particular instance of our expectation programming concept, Expectation Programming in Turing (EPT), by extending the PPS Turing to allow so-called target-aware inference to be run automatically. We then verify the statistical soundness of EPT theoretically, and show that it provides substantial empirical gains in practice.",
        "bibtex": "@InProceedings{pmlr-v180-reichelt22a,\n  title = \t {Expectation programming: Adapting probabilistic programming systems to estimate expectations efficiently},\n  author =       {Reichelt, Tim and Goli{\\'n}ski, Adam and Ong, Luke and Rainforth, Tom},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1676--1685},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/reichelt22a/reichelt22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/reichelt22a.html},\n  abstract = \t {We show that the standard computational pipeline of probabilistic programming systems (PPSs) can be inefficient for estimating expectations and introduce the concept of expectation programming to address this. In expectation programming, the aim of the backend inference engine is to directly estimate expected return values of programs, as opposed to approximating their conditional distributions. This distinction, while subtle, allows us to achieve substantial performance improvements over the standard PPS computational pipeline by tailoring computation to the expectation we care about. We realize a particular instance of our expectation programming concept, Expectation Programming in Turing (EPT), by extending the PPS Turing to allow so-called target-aware inference to be run automatically. We then verify the statistical soundness of EPT theoretically, and show that it provides substantial empirical gains in practice.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/reichelt22a/reichelt22a.pdf",
        "supp": "",
        "pdf_size": 412939,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3739369250921717169&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "74f6a8898f",
        "title": "Fast inference and transfer of compositional task structures for few-shot task generalization",
        "site": "https://proceedings.mlr.press/v180/sohn22a.html",
        "author": "Sungryull Sohn; Hyunjae Woo; Jongwook Choi; Lyubing Qiang; Izzeddin Gur; Aleksandra Faust; Honglak Lee",
        "abstract": "We tackle real-world problems with complex structures beyond the pixel-based game or simulator. We formulate it as a few-shot reinforcement learning problem where a task is characterized by a subtask graph that defines a set of subtasks and their dependencies that are unknown to the agent. Different from the previous meta-RL methods trying to directly infer the unstructured task embedding, our multi-task subtask graph inferencer (MTSGI) first infers the common high-level task structure in terms of the subtask graph from the training tasks, and use it as a prior to improve the task inference in testing. Our experiment results on 2D grid-world and complex web navigation domains show that the proposed method can learn and leverage the common underlying structure of the tasks for faster adaptation to the unseen tasks than various existing algorithms such as meta reinforcement learning, hierarchical reinforcement learning, and other heuristic agents.",
        "bibtex": "@InProceedings{pmlr-v180-sohn22a,\n  title = \t {Fast inference and transfer of compositional task structures for few-shot task generalization},\n  author =       {Sohn, Sungryull and Woo, Hyunjae and Choi, Jongwook and Qiang, Lyubing and Gur, Izzeddin and Faust, Aleksandra and Lee, Honglak},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1857--1865},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/sohn22a/sohn22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/sohn22a.html},\n  abstract = \t {We tackle real-world problems with complex structures beyond the pixel-based game or simulator. We formulate it as a few-shot reinforcement learning problem where a task is characterized by a subtask graph that defines a set of subtasks and their dependencies that are unknown to the agent. Different from the previous meta-RL methods trying to directly infer the unstructured task embedding, our multi-task subtask graph inferencer (MTSGI) first infers the common high-level task structure in terms of the subtask graph from the training tasks, and use it as a prior to improve the task inference in testing. Our experiment results on 2D grid-world and complex web navigation domains show that the proposed method can learn and leverage the common underlying structure of the tasks for faster adaptation to the unseen tasks than various existing algorithms such as meta reinforcement learning, hierarchical reinforcement learning, and other heuristic agents.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/sohn22a/sohn22a.pdf",
        "supp": "",
        "pdf_size": 2997674,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "University of Michigan; University of Michigan; University of Michigan; University of Michigan; Google Research; Google Research; University of Michigan+LG AI Research Center Ann Arbor",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;1;1;0+2",
        "aff_unique_norm": "University of Michigan;Google;LG",
        "aff_unique_dep": ";Google Research;LG AI Research Center",
        "aff_unique_url": "https://www.umich.edu;https://research.google;https://www.lg.com/global/ai-research-center",
        "aff_unique_abbr": "UM;Google Research;LG AI",
        "aff_campus_unique_index": "1;1;2",
        "aff_campus_unique": ";Mountain View;Ann Arbor",
        "aff_country_unique_index": "0;0;0;0;0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e777bae2ee",
        "title": "Fast predictive uncertainty for classification with Bayesian deep networks",
        "site": "https://proceedings.mlr.press/v180/hobbhahn22a.html",
        "author": "Marius Hobbhahn; Agustinus Kristiadi; Philipp Hennig",
        "abstract": "In Bayesian Deep Learning, distributions over the output of classification neural networks are often approximated by first constructing a Gaussian distribution over the weights, then sampling from it to receive a distribution over the softmax outputs. This is costly. We reconsider old work (Laplace Bridge) to construct a Dirichlet approximation of this softmax output distribution, which yields an analytic map between Gaussian distributions in logit space and Dirichlet distributions (the conjugate prior to the Categorical distribution) in the output space.  Importantly, the vanilla Laplace Bridge comes with certain limitations. We analyze those and suggest a simple solution that compares favorably to other commonly used estimates of the softmax-Gaussian integral. We demonstrate that the resulting Dirichlet distribution has multiple advantages, in particular, more efficient computation of the uncertainty estimate and scaling to large datasets and networks like ImageNet and DenseNet.  We further demonstrate the usefulness of this Dirichlet approximation by using it to construct a lightweight uncertainty-aware output ranking for ImageNet.",
        "bibtex": "@InProceedings{pmlr-v180-hobbhahn22a,\n  title = \t {Fast predictive uncertainty for classification with Bayesian deep networks},\n  author =       {Hobbhahn, Marius and Kristiadi, Agustinus and Hennig, Philipp},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {822--832},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/hobbhahn22a/hobbhahn22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/hobbhahn22a.html},\n  abstract = \t {In Bayesian Deep Learning, distributions over the output of classification neural networks are often approximated by first constructing a Gaussian distribution over the weights, then sampling from it to receive a distribution over the softmax outputs. This is costly. We reconsider old work (Laplace Bridge) to construct a Dirichlet approximation of this softmax output distribution, which yields an analytic map between Gaussian distributions in logit space and Dirichlet distributions (the conjugate prior to the Categorical distribution) in the output space.  Importantly, the vanilla Laplace Bridge comes with certain limitations. We analyze those and suggest a simple solution that compares favorably to other commonly used estimates of the softmax-Gaussian integral. We demonstrate that the resulting Dirichlet distribution has multiple advantages, in particular, more efficient computation of the uncertainty estimate and scaling to large datasets and networks like ImageNet and DenseNet.  We further demonstrate the usefulness of this Dirichlet approximation by using it to construct a lightweight uncertainty-aware output ranking for ImageNet. }\n}",
        "pdf": "https://proceedings.mlr.press/v180/hobbhahn22a/hobbhahn22a.pdf",
        "supp": "",
        "pdf_size": 2457765,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8925183995102430081&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of T\u00fcbingen; University of T\u00fcbingen; University of T\u00fcbingen + Max-Planck Institute for Intelligent Systems",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "University of T\u00fcbingen;Max-Planck Institute for Intelligent Systems",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-tuebingen.de/;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "Uni T\u00fcbingen;MPI-IS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "ec9297a989",
        "title": "Faster non-convex federated learning via global and local momentum",
        "site": "https://proceedings.mlr.press/v180/das22b.html",
        "author": "Rudrajit Das; Anish Acharya; Abolfazl Hashemi; Sujay Sanghavi; Inderjit S. Dhillon; Ufuk Topcu",
        "abstract": "We propose \\texttt{FedGLOMO}, a novel federated learning (FL) algorithm with an iteration complexity of $\\mathcal{O}(\\epsilon^{-1.5})$ to converge to an $\\epsilon$-stationary point (i.e., $\\mathbb{E}[\\|\\nabla f(x)\\|^2] \\leq \\epsilon$) for smooth non-convex functions \u2013 under arbitrary client heterogeneity and compressed communication \u2013 compared to the $\\mathcal{O}(\\epsilon^{-2})$ complexity of most prior works. Our key algorithmic idea that enables achieving this improved complexity is based on the observation that the convergence in FL is hampered by two sources of high variance: (i) the global server aggregation step with multiple local updates, exacerbated by client heterogeneity, and (ii) the noise of the local client-level stochastic gradients. The first issue is particularly detrimental to FL algorithms that perform plain averaging at the server. By modeling the server aggregation step as a generalized gradient-type update, we propose a variance-reducing momentum-based global update at the server, which when applied in conjunction with variance-reduced local updates at the clients, enables \\texttt{FedGLOMO} to enjoy an improved convergence rate. Our experiments illustrate the intrinsic variance reduction effect of \\texttt{FedGLOMO}, which implicitly suppresses client-drift in heterogeneous data distribution settings and promotes communication efficiency.",
        "bibtex": "@InProceedings{pmlr-v180-das22b,\n  title = \t {Faster non-convex federated learning via global and local momentum},\n  author =       {Das, Rudrajit and Acharya, Anish and Hashemi, Abolfazl and Sanghavi, Sujay and Dhillon, Inderjit S. and Topcu, Ufuk},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {496--506},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/das22b/das22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/das22b.html},\n  abstract = \t {We propose \\texttt{FedGLOMO}, a novel federated learning (FL) algorithm with an iteration complexity of $\\mathcal{O}(\\epsilon^{-1.5})$ to converge to an $\\epsilon$-stationary point (i.e., $\\mathbb{E}[\\|\\nabla f(x)\\|^2] \\leq \\epsilon$) for smooth non-convex functions \u2013 under arbitrary client heterogeneity and compressed communication \u2013 compared to the $\\mathcal{O}(\\epsilon^{-2})$ complexity of most prior works. Our key algorithmic idea that enables achieving this improved complexity is based on the observation that the convergence in FL is hampered by two sources of high variance: (i) the global server aggregation step with multiple local updates, exacerbated by client heterogeneity, and (ii) the noise of the local client-level stochastic gradients. The first issue is particularly detrimental to FL algorithms that perform plain averaging at the server. By modeling the server aggregation step as a generalized gradient-type update, we propose a variance-reducing momentum-based global update at the server, which when applied in conjunction with variance-reduced local updates at the clients, enables \\texttt{FedGLOMO} to enjoy an improved convergence rate. Our experiments illustrate the intrinsic variance reduction effect of \\texttt{FedGLOMO}, which implicitly suppresses client-drift in heterogeneous data distribution settings and promotes communication efficiency.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/das22b/das22b.pdf",
        "supp": "",
        "pdf_size": 788526,
        "gs_citation": 106,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2676810505267272889&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Texas at Austin, USA; University of Texas at Austin, USA; Purdue University, West Lafayette, Indiana, USA; University of Texas at Austin, USA; University of Texas at Austin, USA; University of Texas at Austin, USA",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "University of Texas at Austin;Purdue University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utexas.edu;https://www.purdue.edu",
        "aff_unique_abbr": "UT Austin;Purdue",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Austin;West Lafayette",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5a372f27ce",
        "title": "Feature learning and random features in standard finite-width convolutional neural networks: An empirical study",
        "site": "https://proceedings.mlr.press/v180/samarin22a.html",
        "author": "Maxim Samarin; Volker Roth; David Belius",
        "abstract": "The Neural Tangent Kernel is an important milestone in the ongoing effort to build a theory for deep learning. Its prediction that sufficiently wide neural networks behave as kernel methods, or equivalently as random feature models arising from linearized networks, has been confirmed empirically for certain wide architectures. In this paper, we compare the performance of two common finite-width convolutional neural networks, LeNet and AlexNet, to their linearizations on common benchmark datasets like MNIST and modified versions of it, CIFAR-10 and an ImageNet subset. We demonstrate empirically that finite-width neural networks, generally, greatly outperform the finite-width linearization of these architectures. When increasing the problem difficulty of the classification task, we observe a larger gap which is in line with common intuition that finite-width neural networks perform feature learning which finite-width linearizations cannot. At the same time, finite-width linearizations improve dramatically with width, approaching the behavior of the wider standard networks which in turn perform slightly better than their standard width counterparts. Therefore, it appears that feature learning for non-wide standard networks is important but becomes less significant with increasing width. We furthermore identify cases where both standard and linearized networks match in performance, in agreement with NTK theory, and a case where a wide linearization outperforms its standard width counterpart.",
        "bibtex": "@InProceedings{pmlr-v180-samarin22a,\n  title = \t {Feature learning and random features in standard finite-width convolutional neural networks: An empirical study},\n  author =       {Samarin, Maxim and Roth, Volker and Belius, David},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1718--1727},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/samarin22a/samarin22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/samarin22a.html},\n  abstract = \t {The Neural Tangent Kernel is an important milestone in the ongoing effort to build a theory for deep learning. Its prediction that sufficiently wide neural networks behave as kernel methods, or equivalently as random feature models arising from linearized networks, has been confirmed empirically for certain wide architectures. In this paper, we compare the performance of two common finite-width convolutional neural networks, LeNet and AlexNet, to their linearizations on common benchmark datasets like MNIST and modified versions of it, CIFAR-10 and an ImageNet subset. We demonstrate empirically that finite-width neural networks, generally, greatly outperform the finite-width linearization of these architectures. When increasing the problem difficulty of the classification task, we observe a larger gap which is in line with common intuition that finite-width neural networks perform feature learning which finite-width linearizations cannot. At the same time, finite-width linearizations improve dramatically with width, approaching the behavior of the wider standard networks which in turn perform slightly better than their standard width counterparts. Therefore, it appears that feature learning for non-wide standard networks is important but becomes less significant with increasing width. We furthermore identify cases where both standard and linearized networks match in performance, in agreement with NTK theory, and a case where a wide linearization outperforms its standard width counterpart.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/samarin22a/samarin22a.pdf",
        "supp": "",
        "pdf_size": 377351,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17405296153120769043&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e02676a921",
        "title": "Feature selection for discovering distributional treatment effect modifiers",
        "site": "https://proceedings.mlr.press/v180/chikahara22a.html",
        "author": "Yoichi Chikahara; Makoto Yamada; Hisashi Kashima",
        "abstract": "Finding the features relevant to the difference in treatment effects is essential to unveil the underlying causal mechanisms. Existing methods seek such features by measuring how greatly the feature attributes affect the degree of the {\\it conditional average treatment effect} (CATE). However, these methods may overlook important features because CATE, a measure of the average treatment effect, cannot detect differences in distribution parameters other than the mean (e.g., variance). To resolve this weakness of existing methods, we propose a feature selection framework for discovering {\\it distributional treatment effect modifiers}. We first formulate a feature importance measure that quantifies how strongly the feature attributes influence the discrepancy between potential outcome distributions. Then we derive its computationally efficient estimator and develop a feature selection algorithm that can control the type I error rate to the desired level. Experimental results show that our framework successfully discovers important features and outperforms the existing mean-based method.",
        "bibtex": "@InProceedings{pmlr-v180-chikahara22a,\n  title = \t {Feature selection for discovering distributional treatment effect modifiers},\n  author =       {Chikahara, Yoichi and Yamada, Makoto and Kashima, Hisashi},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {400--410},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/chikahara22a/chikahara22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/chikahara22a.html},\n  abstract = \t { Finding the features relevant to the difference in treatment effects is essential to unveil the underlying causal mechanisms. Existing methods seek such features by measuring how greatly the feature attributes affect the degree of the {\\it conditional average treatment effect} (CATE). However, these methods may overlook important features because CATE, a measure of the average treatment effect, cannot detect differences in distribution parameters other than the mean (e.g., variance). To resolve this weakness of existing methods, we propose a feature selection framework for discovering {\\it distributional treatment effect modifiers}. We first formulate a feature importance measure that quantifies how strongly the feature attributes influence the discrepancy between potential outcome distributions. Then we derive its computationally efficient estimator and develop a feature selection algorithm that can control the type I error rate to the desired level. Experimental results show that our framework successfully discovers important features and outperforms the existing mean-based method.     }\n}",
        "pdf": "https://proceedings.mlr.press/v180/chikahara22a/chikahara22a.pdf",
        "supp": "",
        "pdf_size": 473679,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7634804754479151516&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "de6e2aecf7",
        "title": "Federated online clustering of bandits",
        "site": "https://proceedings.mlr.press/v180/liu22a.html",
        "author": "Xutong Liu; Haoru Zhao; Tong Yu; Shuai Li; John C.S. Lui",
        "abstract": "Contextual multi-armed bandit (MAB) is an important sequential decision-making problem in recommendation systems. A line of works, called the clustering of bandits (CLUB), utilize the collaborative effect over users and dramatically improve the recommendation quality. Owing to the increasing application scale and public concerns about privacy, there is a growing demand to keep user data decentralized and push bandit learning to the local server side. Existing CLUB algorithms, however, are designed under the centralized setting where data are available at a central server. We focus on studying the federated online clustering of bandit (FCLUB) problem, which aims to minimize the total regret while satisfying privacy and communication considerations. We design a new phase-based scheme for cluster detection and a novel asynchronous communication protocol for cooperative bandit learning for this problem. To protect users\u2019 privacy, previous differential privacy (DP) definitions are not very suitable, and we propose a new DP notion that acts on the user cluster level. We provide rigorous proofs to show that our algorithm simultaneously achieves (clustered) DP, sublinear communication complexity and sublinear regret. Finally, experimental evaluations show our superior performance compared with benchmark algorithms.",
        "bibtex": "@InProceedings{pmlr-v180-liu22a,\n  title = \t {Federated online clustering of bandits},\n  author =       {Liu, Xutong and Zhao, Haoru and Yu, Tong and Li, Shuai and Lui, John C.S.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1221--1231},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/liu22a/liu22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/liu22a.html},\n  abstract = \t {Contextual multi-armed bandit (MAB) is an important sequential decision-making problem in recommendation systems. A line of works, called the clustering of bandits (CLUB), utilize the collaborative effect over users and dramatically improve the recommendation quality. Owing to the increasing application scale and public concerns about privacy, there is a growing demand to keep user data decentralized and push bandit learning to the local server side. Existing CLUB algorithms, however, are designed under the centralized setting where data are available at a central server. We focus on studying the federated online clustering of bandit (FCLUB) problem, which aims to minimize the total regret while satisfying privacy and communication considerations. We design a new phase-based scheme for cluster detection and a novel asynchronous communication protocol for cooperative bandit learning for this problem. To protect users\u2019 privacy, previous differential privacy (DP) definitions are not very suitable, and we propose a new DP notion that acts on the user cluster level. We provide rigorous proofs to show that our algorithm simultaneously achieves (clustered) DP, sublinear communication complexity and sublinear regret. Finally, experimental evaluations show our superior performance compared with benchmark algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/liu22a/liu22a.pdf",
        "supp": "",
        "pdf_size": 1291449,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11551265857768092796&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "The Chinese University of Hong Kong, Hong Kong SAR, China; Shanghai Jiao Tong University, Shanghai, China; Adobe Research, San Jose, CA, USA; Shanghai Jiao Tong University, Shanghai, China; The Chinese University of Hong Kong, Hong Kong SAR, China",
        "aff_domain": "link.cuhk.edu.hk;sjtu.edu.cn;adobe.com;sjtu.edu.cn;cse.cuhk.edu.hk",
        "email": "link.cuhk.edu.hk;sjtu.edu.cn;adobe.com;sjtu.edu.cn;cse.cuhk.edu.hk",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Shanghai Jiao Tong University;Adobe",
        "aff_unique_dep": ";;Adobe Research",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.sjtu.edu.cn;https://research.adobe.com",
        "aff_unique_abbr": "CUHK;SJTU;Adobe",
        "aff_campus_unique_index": "0;1;2;1;0",
        "aff_campus_unique": "Hong Kong SAR;Shanghai;San Jose",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "80376341c1",
        "title": "Fedvarp: Tackling the variance due to partial client participation in federated learning",
        "site": "https://proceedings.mlr.press/v180/jhunjhunwala22a.html",
        "author": "Divyansh Jhunjhunwala; Pranay Sharma; Aushim Nagarkatti; Gauri Joshi",
        "abstract": "Data-heterogeneous federated learning (FL) systems suffer from two significant sources of convergence error: 1) client drift error caused by performing multiple local optimization steps at clients, and 2) partial client participation error caused by the fact that only a small subset of the edge clients participate in every training round. We find that among these, only the former has received significant attention in the literature. To remedy this, we propose FedVARP, a novel variance reduction algorithm applied at the server that eliminates error due to partial client participation. To do so, the server simply maintains in memory the most recent update for each client and uses these as surrogate updates for the non-participating clients in every round. Further, to alleviate the memory requirement at the server, we propose a novel clustering-based variance reduction algorithm ClusterFedVARP. Unlike previously proposed methods, both FedVARP and ClusterFedVARP do not require additional computation at clients or communication of additional optimization parameters. Through extensive experiments, we show that FedVARP outperforms state-of-the-art methods, and ClusterFedVARP achieves performance comparable to FedVARP with much less memory requirements.",
        "bibtex": "@InProceedings{pmlr-v180-jhunjhunwala22a,\n  title = \t {Fedvarp: Tackling the variance due to partial client participation in federated learning},\n  author =       {Jhunjhunwala, Divyansh and Sharma, Pranay and Nagarkatti, Aushim and Joshi, Gauri},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {906--916},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/jhunjhunwala22a/jhunjhunwala22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/jhunjhunwala22a.html},\n  abstract = \t {Data-heterogeneous federated learning (FL) systems suffer from two significant sources of convergence error: 1) client drift error caused by performing multiple local optimization steps at clients, and 2) partial client participation error caused by the fact that only a small subset of the edge clients participate in every training round. We find that among these, only the former has received significant attention in the literature. To remedy this, we propose FedVARP, a novel variance reduction algorithm applied at the server that eliminates error due to partial client participation. To do so, the server simply maintains in memory the most recent update for each client and uses these as surrogate updates for the non-participating clients in every round. Further, to alleviate the memory requirement at the server, we propose a novel clustering-based variance reduction algorithm ClusterFedVARP. Unlike previously proposed methods, both FedVARP and ClusterFedVARP do not require additional computation at clients or communication of additional optimization parameters. Through extensive experiments, we show that FedVARP outperforms state-of-the-art methods, and ClusterFedVARP achieves performance comparable to FedVARP with much less memory requirements.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/jhunjhunwala22a/jhunjhunwala22a.pdf",
        "supp": "",
        "pdf_size": 457758,
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1027327804286965708&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "be6c0381dc",
        "title": "Fine-Grained matching with multi-perspective similarity modeling for cross-modal retrieval",
        "site": "https://proceedings.mlr.press/v180/xie22a.html",
        "author": "Xiumin Xie; Chuanwen Hou; Zhixin Li",
        "abstract": "Cross-modal retrieval relies on learning inter-modal correspondences. Most existing approaches focus on learning global or local correspondence and fail to explore fine-grained multi-level alignments. Moreover, it remains to be investigated how to infer more accurate similarity scores. In this paper, we propose a novel fine-grained matching with Multi-Perspective Similarity Modeling (MPSM) Network for cross-modal retrieval. Specifically, the Knowledge Graph Iterative Dissemination (KGID) module is designed to iteratively broadcast global semantic knowledge, enabling domain information to be integrated and relevant nodes to be associated, resulting in fine-grained modality representations. Subsequently, vector-based similarity representations are learned from multiple perspectives to model multi-level alignments comprehensively. The Relation Graph Reconstruction (SRGR) module is further developed to enhance cross-modal correspondence by constructing similarity relation graphs and adaptively reconstructing them. Extensive experiments on the Flickr30K and MSCOCO datasets validate that our model significantly outperforms several state-of-the-art baselines.",
        "bibtex": "@InProceedings{pmlr-v180-xie22a,\n  title = \t {Fine-Grained matching with multi-perspective similarity modeling for cross-modal retrieval},\n  author =       {Xie, Xiumin and Hou, Chuanwen and Li, Zhixin},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2148--2158},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/xie22a/xie22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/xie22a.html},\n  abstract = \t {Cross-modal retrieval relies on learning inter-modal correspondences. Most existing approaches focus on learning global or local correspondence and fail to explore fine-grained multi-level alignments. Moreover, it remains to be investigated how to infer more accurate similarity scores. In this paper, we propose a novel fine-grained matching with Multi-Perspective Similarity Modeling (MPSM) Network for cross-modal retrieval. Specifically, the Knowledge Graph Iterative Dissemination (KGID) module is designed to iteratively broadcast global semantic knowledge, enabling domain information to be integrated and relevant nodes to be associated, resulting in fine-grained modality representations. Subsequently, vector-based similarity representations are learned from multiple perspectives to model multi-level alignments comprehensively. The Relation Graph Reconstruction (SRGR) module is further developed to enhance cross-modal correspondence by constructing similarity relation graphs and adaptively reconstructing them. Extensive experiments on the Flickr30K and MSCOCO datasets validate that our model significantly outperforms several state-of-the-art baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/xie22a/xie22a.pdf",
        "supp": "",
        "pdf_size": 706679,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12801423947605785970&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 2,
        "aff": "Guangxi Key Lab of Multi-source Information Mining and Security, Guangxi Normal University; Guangxi Key Lab of Multi-source Information Mining and Security, Guangxi Normal University; Guangxi Key Lab of Multi-source Information Mining and Security, Guangxi Normal University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Guangxi Normal University",
        "aff_unique_dep": "Guangxi Key Lab of Multi-source Information Mining and Security",
        "aff_unique_url": "http://www.gxnu.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "09b1f5f496",
        "title": "Finite-horizon equilibria for neuro-symbolic concurrent stochastic games",
        "site": "https://proceedings.mlr.press/v180/yan22a.html",
        "author": "Rui Yan; Gabriel Santos; Xiaoming Duan; David Parker; Marta Kwiatkowska",
        "abstract": "We present novel techniques for neuro-symbolic concurrent stochastic games, a recently proposed modelling formalism to represent a set of probabilistic agents operating in a continuous-space environment using a combination of neural network based perception mechanisms and traditional symbolic methods. To date, only zero-sum variants of the model were studied, which is too restrictive when agents have distinct objectives. We formalise notions of equilibria for these models and present algorithms to synthesise them. Focusing on the finite-horizon setting, and (global) social welfare subgame-perfect optimality, we consider two distinct types: Nash equilibria and correlated equilibria. We first show that an exact solution based on backward induction may yield arbitrarily bad equilibria. We then propose an approximation algorithm called frozen subgame improvement, which proceeds through iterative solution of nonlinear programs. We develop a prototype implementation and demonstrate the benefits of our approach on two case studies: an automated car-parking system and an aircraft collision avoidance system.",
        "bibtex": "@InProceedings{pmlr-v180-yan22a,\n  title = \t {Finite-horizon equilibria for neuro-symbolic concurrent stochastic games},\n  author =       {Yan, Rui and Santos, Gabriel and Duan, Xiaoming and Parker, David and Kwiatkowska, Marta},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2170--2180},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yan22a/yan22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yan22a.html},\n  abstract = \t {We present novel techniques for neuro-symbolic concurrent stochastic games, a recently proposed modelling formalism to represent a set of probabilistic agents operating in a continuous-space environment using a combination of neural network based perception mechanisms and traditional symbolic methods. To date, only zero-sum variants of the model were studied, which is too restrictive when agents have distinct objectives. We formalise notions of equilibria for these models and present algorithms to synthesise them. Focusing on the finite-horizon setting, and (global) social welfare subgame-perfect optimality, we consider two distinct types: Nash equilibria and correlated equilibria. We first show that an exact solution based on backward induction may yield arbitrarily bad equilibria. We then propose an approximation algorithm called frozen subgame improvement, which proceeds through iterative solution of nonlinear programs. We develop a prototype implementation and demonstrate the benefits of our approach on two case studies: an automated car-parking system and an aircraft collision avoidance system.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yan22a/yan22a.pdf",
        "supp": "",
        "pdf_size": 321814,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3094193166166892270&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "Department of Computer Science, University of Oxford, Oxford, UK; Department of Computer Science, University of Oxford, Oxford, UK; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; School of Computer Science, University of Birmingham, Birmingham, UK; Department of Computer Science, University of Oxford, Oxford, UK",
        "aff_domain": "; ; ; ; ",
        "email": "; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "University of Oxford;Shanghai Jiao Tong University;University of Birmingham",
        "aff_unique_dep": "Department of Computer Science;Department of Automation;School of Computer Science",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.sjtu.edu.cn;https://www.birmingham.ac.uk",
        "aff_unique_abbr": "Oxford;SJTU;UoB",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Oxford;Shanghai;Birmingham",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "54ca8461d7",
        "title": "Fixing the Bethe approximation: How structural modifications in a graph improve belief propagation",
        "site": "https://proceedings.mlr.press/v180/leisenberger22a.html",
        "author": "Harald Leisenberger; Franz Pernkopf; Christian Knoll",
        "abstract": "Belief propagation is an iterative method for inference in probabilistic graphical models. Its well-known relationship to a classical concept from statistical physics, the Bethe free energy, puts it on a solid theoretical foundation. If belief propagation fails to approximate the marginals, then this is often due to a failure of the Bethe approximation. In this work, we show how modifications in a graphical model can be a great remedy for fixing the Bethe approximation. Specifically, we analyze how the removal of edges influences and improves belief propagation, and demonstrate that this positive effect is particularly distinct for dense graphs.",
        "bibtex": "@InProceedings{pmlr-v180-leisenberger22a,\n  title = \t {Fixing the Bethe approximation: How structural modifications in a graph improve belief propagation},\n  author =       {Leisenberger, Harald and Pernkopf, Franz and Knoll, Christian},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1085--1095},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/leisenberger22a/leisenberger22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/leisenberger22a.html},\n  abstract = \t {Belief propagation is an iterative method for inference in probabilistic graphical models. Its well-known relationship to a classical concept from statistical physics, the Bethe free energy, puts it on a solid theoretical foundation. If belief propagation fails to approximate the marginals, then this is often due to a failure of the Bethe approximation. In this work, we show how modifications in a graphical model can be a great remedy for fixing the Bethe approximation. Specifically, we analyze how the removal of edges influences and improves belief propagation, and demonstrate that this positive effect is particularly distinct for dense graphs.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/leisenberger22a/leisenberger22a.pdf",
        "supp": "",
        "pdf_size": 792413,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1372023836898877654&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8ba0b1d292",
        "title": "Forget-me-not! Contrastive critics for mitigating posterior collapse",
        "site": "https://proceedings.mlr.press/v180/menon22a.html",
        "author": "Sachit Menon; David Blei; Carl Vondrick",
        "abstract": "Variational autoencoders (VAEs) suffer from posterior collapse, where the powerful neural networks used for modeling and inference optimize the objective without meaningfully using the latent representation. We introduce inference critics that detect and incentivize against posterior collapse by requiring correspondence between latent variables and the observations. By connecting the critic\u2019s objective to the literature in self-supervised contrastive representation learning, we show both theoretically and empirically that optimizing inference critics increases the mutual information between observations and latents, mitigating posterior collapse. This approach is straightforward to implement and requires significantly less training time than prior methods, yet obtains competitive results on three established datasets. Overall, the approach lays the foundation to bridge the previously disconnected frameworks of contrastive learning and probabilistic modeling with variational autoencoders, underscoring the benefits both communities may find at their intersection.",
        "bibtex": "@InProceedings{pmlr-v180-menon22a,\n  title = \t {Forget-me-not! Contrastive critics for mitigating posterior collapse},\n  author =       {Menon, Sachit and Blei, David and Vondrick, Carl},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1360--1370},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/menon22a/menon22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/menon22a.html},\n  abstract = \t {Variational autoencoders (VAEs) suffer from posterior collapse, where the powerful neural networks used for modeling and inference optimize the objective without meaningfully using the latent representation. We introduce inference critics that detect and incentivize against posterior collapse by requiring correspondence between latent variables and the observations. By connecting the critic\u2019s objective to the literature in self-supervised contrastive representation learning, we show both theoretically and empirically that optimizing inference critics increases the mutual information between observations and latents, mitigating posterior collapse. This approach is straightforward to implement and requires significantly less training time than prior methods, yet obtains competitive results on three established datasets. Overall, the approach lays the foundation to bridge the previously disconnected frameworks of contrastive learning and probabilistic modeling with variational autoencoders, underscoring the benefits both communities may find at their intersection.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/menon22a/menon22a.pdf",
        "supp": "",
        "pdf_size": 345370,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1158568069356569096&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "71b48b4818",
        "title": "Future gradient descent for adapting the temporal shifting data distribution in online recommendation systems",
        "site": "https://proceedings.mlr.press/v180/ye22b.html",
        "author": "Mao Ye; Ruichen Jiang; Haoxiang Wang; Dhruv Choudhary; Xiaocong Du; Bhargav Bhushanam; Aryan Mokhtari; Arun Kejariwal; Qiang Liu",
        "abstract": "One of the key challenges of learning an online recommendation model is the temporal domain shift, which causes the mismatch between the training and testing data distribution and hence domain generalization error. To overcome, we propose to learn a meta future gradient generator that forecasts the gradient information of the future data distribution for training so that the recommendation model can be trained as if we were able to look ahead at the future of its deployment. Compared with Batch Update, a widely used paradigm, our theory suggests that the proposed algorithm achieves smaller temporal domain generalization error measured by a gradient variation term in a local regret. We demonstrate the empirical advantage by comparing with various representative baselines.",
        "bibtex": "@InProceedings{pmlr-v180-ye22b,\n  title = \t {Future gradient descent for adapting the temporal shifting data distribution in online recommendation systems},\n  author =       {Ye, Mao and Jiang, Ruichen and Wang, Haoxiang and Choudhary, Dhruv and Du, Xiaocong and Bhushanam, Bhargav and Mokhtari, Aryan and Kejariwal, Arun and Liu, Qiang},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2256--2266},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ye22b/ye22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ye22b.html},\n  abstract = \t {One of the key challenges of learning an online recommendation model is the temporal domain shift, which causes the mismatch between the training and testing data distribution and hence domain generalization error. To overcome, we propose to learn a meta future gradient generator that forecasts the gradient information of the future data distribution for training so that the recommendation model can be trained as if we were able to look ahead at the future of its deployment. Compared with Batch Update, a widely used paradigm, our theory suggests that the proposed algorithm achieves smaller temporal domain generalization error measured by a gradient variation term in a local regret. We demonstrate the empirical advantage by comparing with various representative baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/ye22b/ye22b.pdf",
        "supp": "",
        "pdf_size": 1696061,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15072035240564801990&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "The University of Texas at Austin; The University of Texas at Austin; The University of Illinois at Urbana-Champaign; Meta; Meta; Meta; The University of Texas at Austin; Meta; The University of Texas at Austin",
        "aff_domain": ";;;;;;;;",
        "email": ";;;;;;;;",
        "github": "",
        "project": "",
        "author_num": 9,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;2;2;0;2;0",
        "aff_unique_norm": "University of Texas at Austin;University of Illinois Urbana-Champaign;Meta",
        "aff_unique_dep": ";;Meta Platforms, Inc.",
        "aff_unique_url": "https://www.utexas.edu;https://illinois.edu;https://meta.com",
        "aff_unique_abbr": "UT Austin;UIUC;Meta",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Austin;Urbana-Champaign;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d00ea8bba2",
        "title": "GNN2GNN: Graph neural networks to generate neural networks",
        "site": "https://proceedings.mlr.press/v180/agiollo22a.html",
        "author": "Andrea Agiollo; Andrea Omicini",
        "abstract": "The success of neural networks (NNs) is tightly linked with their architectural design\u2014a complex problem by itself. We here introduce a novel framework leveraging Graph Neural Networks to Generate Neural Networks (GNN2GNN) where powerful NN architectures can be learned out of a set of available architecture-performance pairs. GNN2GNN relies on a three-way adversarial training of GNN, to optimise a generator model capable of producing predictions about powerful NN architectures. Unlike Neural Architecture Search (NAS) techniques proposing efficient searching algorithms over a set of NN architec- tures, GNN2GNN relies on learning NN architectural design criteria. GNN2GNN learns to propose NN architectures in a single step \u2013 i.e., training of the generator \u2013, overcoming the recursive approach characterising NAS. Therefore, GNN2GNN avoids the expensive and inflexible search of efficient structures typical of NAS approaches. Extensive experiments over two state-of-the-art datasets prove the strength of our framework, showing that it can generate powerful architectures with high probability. Moreover, GNN2GNN outperforms possible counterparts for generating NN architectures, and shows flexibility against dataset quality degradation. Finally, GNN2GNN paves the way towards generalisation between datasets.",
        "bibtex": "@InProceedings{pmlr-v180-agiollo22a,\n  title = \t {{GNN2GNN}: Graph neural networks to generate neural networks},\n  author =       {Agiollo, Andrea and Omicini, Andrea},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {32--42},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/agiollo22a/agiollo22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/agiollo22a.html},\n  abstract = \t {The success of neural networks (NNs) is tightly linked with their architectural design\u2014a complex problem by itself. We here introduce a novel framework leveraging Graph Neural Networks to Generate Neural Networks (GNN2GNN) where powerful NN architectures can be learned out of a set of available architecture-performance pairs. GNN2GNN relies on a three-way adversarial training of GNN, to optimise a generator model capable of producing predictions about powerful NN architectures. Unlike Neural Architecture Search (NAS) techniques proposing efficient searching algorithms over a set of NN architec- tures, GNN2GNN relies on learning NN architectural design criteria. GNN2GNN learns to propose NN architectures in a single step \u2013 i.e., training of the generator \u2013, overcoming the recursive approach characterising NAS. Therefore, GNN2GNN avoids the expensive and inflexible search of efficient structures typical of NAS approaches. Extensive experiments over two state-of-the-art datasets prove the strength of our framework, showing that it can generate powerful architectures with high probability. Moreover, GNN2GNN outperforms possible counterparts for generating NN architectures, and shows flexibility against dataset quality degradation. Finally, GNN2GNN paves the way towards generalisation between datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/agiollo22a/agiollo22a.pdf",
        "supp": "",
        "pdf_size": 340616,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3643983533846865361&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science and Engineering (DISI), A LMA MATER STUDIORUM \u2014University of Bologna, Italy+The Research Hub by Electrolux Professional S.p.A., Pordenone, Italy; Department of Computer Science and Engineering (DISI), A LMA MATER STUDIORUM \u2014University of Bologna, Italy",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0",
        "aff_unique_norm": "University of Bologna;Electrolux Professional S.p.A.",
        "aff_unique_dep": "Department of Computer Science and Engineering (DISI);The Research Hub",
        "aff_unique_url": "https://www.unibo.it;https://www.electrolux.com/professional/",
        "aff_unique_abbr": "UNIBO;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "613ff95e25",
        "title": "Generalized Bayesian quadrature with spectral kernels",
        "site": "https://proceedings.mlr.press/v180/warren22a.html",
        "author": "Houston Warren; Rafael Oliveira; Fabio Ramos",
        "abstract": "Bayesian probabilistic integration, or Bayesian quadrature (BQ), has arisen as a popular means of numerical integral estimation with quantified uncertainty for problems where computational cost limits data availability. BQ leverages flexible Gaussian processes (GPs) to model an integrand which can be subsequently analytically integrated through properties of Gaussian distributions. However, BQ is inherently limited by the fact that the method relies on the use of a strict set of kernels for use in the GP model of the integrand, reducing the flexibility of the method in modeling varied integrand types. In this paper, we present spectral Bayesian quadrature, a form of Bayesian quadrature that allows for the use of any shift-invariant kernel in the integrand GP model while still maintaining the analytical tractability of the integral posterior, increasing the flexibility of BQ methods to address varied problem settings. Additionally our method enables integration with respect to a uniform expectation, effectively computing definite integrals of challenging integrands. We derive the theory and error bounds for this model, as well as demonstrate GBQ\u2019s improved accuracy, flexibility, and data efficiency, compared to traditional BQ and other numerical integration methods, on a variety of quadrature problems.",
        "bibtex": "@InProceedings{pmlr-v180-warren22a,\n  title = \t {Generalized Bayesian quadrature with spectral kernels},\n  author =       {Warren, Houston and Oliveira, Rafael and Ramos, Fabio},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2085--2095},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/warren22a/warren22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/warren22a.html},\n  abstract = \t {Bayesian probabilistic integration, or Bayesian quadrature (BQ), has arisen as a popular means of numerical integral estimation with quantified uncertainty for problems where computational cost limits data availability. BQ leverages flexible Gaussian processes (GPs) to model an integrand which can be subsequently analytically integrated through properties of Gaussian distributions. However, BQ is inherently limited by the fact that the method relies on the use of a strict set of kernels for use in the GP model of the integrand, reducing the flexibility of the method in modeling varied integrand types. In this paper, we present spectral Bayesian quadrature, a form of Bayesian quadrature that allows for the use of any shift-invariant kernel in the integrand GP model while still maintaining the analytical tractability of the integral posterior, increasing the flexibility of BQ methods to address varied problem settings. Additionally our method enables integration with respect to a uniform expectation, effectively computing definite integrals of challenging integrands. We derive the theory and error bounds for this model, as well as demonstrate GBQ\u2019s improved accuracy, flexibility, and data efficiency, compared to traditional BQ and other numerical integration methods, on a variety of quadrature problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/warren22a/warren22a.pdf",
        "supp": "",
        "pdf_size": 759950,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4333218380061609349&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "School of Computer Science, The University of Sydney, Sydney, Australia; Brain and Mind Centre, The University of Sydney, Sydney, Australia; School of Computer Science, The University of Sydney, Sydney, Australia + NVIDIA, USA",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "University of Sydney;NVIDIA",
        "aff_unique_dep": "School of Computer Science;NVIDIA",
        "aff_unique_url": "https://www.sydney.edu.au;https://www.nvidia.com",
        "aff_unique_abbr": "USYD;NV",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0;0;0+1",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "d86104b2e6",
        "title": "Generalizing off-policy learning under sample selection bias",
        "site": "https://proceedings.mlr.press/v180/hatt22a.html",
        "author": "Tobias Hatt; Daniel Tschernutter; Stefan Feuerriegel",
        "abstract": "Learning personalized decision policies that generalize to the target population is of great relevance. Since training data is often not representative of the target population, standard policy learning methods may yield policies that do not generalize target population. To address this challenge, we propose a novel framework for learning policies that generalize to the target population. For this, we characterize the difference between the training data and the target population as a sample selection bias using a selection variable. Over an uncertainty set around this selection variable, we optimize the minimax value of a policy to achieve the best worst-case policy value on the target population. In order to solve the minimax problem, we derive an efficient algorithm based on a convex-concave procedure and prove convergence for parametrized spaces of policies such as logistic policies. We prove that, if the uncertainty set is well-specified, our policies generalize to the target population as they can not do worse than on the training data. Using simulated data and a clinical trial, we demonstrate that, compared to standard policy learning methods, our framework improves the generalizability of policies substantially.",
        "bibtex": "@InProceedings{pmlr-v180-hatt22a,\n  title = \t {Generalizing off-policy learning under sample selection bias},\n  author =       {Hatt, Tobias and Tschernutter, Daniel and Feuerriegel, Stefan},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {769--779},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/hatt22a/hatt22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/hatt22a.html},\n  abstract = \t {Learning personalized decision policies that generalize to the target population is of great relevance. Since training data is often not representative of the target population, standard policy learning methods may yield policies that do not generalize target population. To address this challenge, we propose a novel framework for learning policies that generalize to the target population. For this, we characterize the difference between the training data and the target population as a sample selection bias using a selection variable. Over an uncertainty set around this selection variable, we optimize the minimax value of a policy to achieve the best worst-case policy value on the target population. In order to solve the minimax problem, we derive an efficient algorithm based on a convex-concave procedure and prove convergence for parametrized spaces of policies such as logistic policies. We prove that, if the uncertainty set is well-specified, our policies generalize to the target population as they can not do worse than on the training data. Using simulated data and a clinical trial, we demonstrate that, compared to standard policy learning methods, our framework improves the generalizability of policies substantially.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/hatt22a/hatt22a.pdf",
        "supp": "",
        "pdf_size": 423334,
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15230884756011039692&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "ETH Zurich, Switzerland; ETH Zurich, Switzerland; ETH Zurich, Switzerland+LMU Munich, Germany",
        "aff_domain": ";;",
        "email": ";;",
        "github": "github.com/tobhatt/GeneralOPL",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "ETH Zurich;Ludwig Maximilian University of Munich",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ethz.ch;https://www.lmu.de",
        "aff_unique_abbr": "ETHZ;LMU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Munich",
        "aff_country_unique_index": "0;0;0+1",
        "aff_country_unique": "Switzerland;Germany"
    },
    {
        "id": "b2658ba6c3",
        "title": "Greedy equivalence search in the presence of latent confounders",
        "site": "https://proceedings.mlr.press/v180/claassen22a.html",
        "author": "Tom Claassen; Ioan G. Bucur",
        "abstract": "We investigate Greedy PAG Search (GPS) for score-based causal discovery  over equivalence classes, similar to the famous Greedy Equivalence Search algorithm, except now in the presence of latent confounders. It is based on a novel characterization of Markov equivalence classes for MAGs, that not only improves state-of-the-art identification of Markov equivalence between MAGs to linear time complexity for sparse graphs, but also allows for efficient traversal over equivalence classes in the space of all MAGs. The resulting GPS algorithm is evaluated against several existing alternatives and found to show promising performance, both in terms of speed and accuracy.",
        "bibtex": "@InProceedings{pmlr-v180-claassen22a,\n  title = \t {Greedy equivalence search in the presence of latent confounders},\n  author =       {Claassen, Tom and Bucur, Ioan G.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {443--452},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/claassen22a/claassen22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/claassen22a.html},\n  abstract = \t {We investigate Greedy PAG Search (GPS) for score-based causal discovery  over equivalence classes, similar to the famous Greedy Equivalence Search algorithm, except now in the presence of latent confounders. It is based on a novel characterization of Markov equivalence classes for MAGs, that not only improves state-of-the-art identification of Markov equivalence between MAGs to linear time complexity for sparse graphs, but also allows for efficient traversal over equivalence classes in the space of all MAGs. The resulting GPS algorithm is evaluated against several existing alternatives and found to show promising performance, both in terms of speed and accuracy.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/claassen22a/claassen22a.pdf",
        "supp": "",
        "pdf_size": 418727,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4871626211932796233&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Institute for Computing and Information Sciences, Radboud University, Nijmegen, (The) Netherlands; Institute for Computing and Information Sciences, Radboud University, Nijmegen, (The) Netherlands",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Radboud University",
        "aff_unique_dep": "Institute for Computing and Information Sciences",
        "aff_unique_url": "https://www.ru.nl",
        "aff_unique_abbr": "RU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nijmegen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "72d8691762",
        "title": "Greedy modality selection via approximate submodular maximization",
        "site": "https://proceedings.mlr.press/v180/cheng22a.html",
        "author": "Runxiang Cheng; Gargi Balasubramaniam; Yifei He; Yao-Hung Hubert Tsai; Han Zhao",
        "abstract": "Multimodal learning considers learning from multi-modality data, aiming to fuse heterogeneous sources of information. However, it is not always feasible to leverage all available modalities due to memory constraints. Further, training on all the modalities may be inefficient when redundant information exists within data, such as different subsets of modalities providing similar performance. In light of these challenges, we study modality selection, intending to efficiently select the most informative and complementary modalities under certain computational constraints. We formulate a theoretical framework for optimizing modality selection in multimodal learning and introduce a utility measure to quantify the benefit of selecting a modality. For this optimization problem, we present efficient algorithms when the utility measure exhibits monotonicity and approximate submodularity. We also connect the utility measure with existing Shapley-value-based feature importance scores. Last, we demonstrate the efficacy of our algorithm on synthetic (Patch-MNIST) and real-world (PEMS-SF, CMU-MOSI) datasets.",
        "bibtex": "@InProceedings{pmlr-v180-cheng22a,\n  title = \t {Greedy modality selection via approximate submodular maximization},\n  author =       {Cheng, Runxiang and Balasubramaniam, Gargi and He, Yifei and Tsai, Yao-Hung Hubert and Zhao, Han},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {389--399},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/cheng22a/cheng22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/cheng22a.html},\n  abstract = \t {Multimodal learning considers learning from multi-modality data, aiming to fuse heterogeneous sources of information. However, it is not always feasible to leverage all available modalities due to memory constraints. Further, training on all the modalities may be inefficient when redundant information exists within data, such as different subsets of modalities providing similar performance. In light of these challenges, we study modality selection, intending to efficiently select the most informative and complementary modalities under certain computational constraints. We formulate a theoretical framework for optimizing modality selection in multimodal learning and introduce a utility measure to quantify the benefit of selecting a modality. For this optimization problem, we present efficient algorithms when the utility measure exhibits monotonicity and approximate submodularity. We also connect the utility measure with existing Shapley-value-based feature importance scores. Last, we demonstrate the efficacy of our algorithm on synthetic (Patch-MNIST) and real-world (PEMS-SF, CMU-MOSI) datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/cheng22a/cheng22a.pdf",
        "supp": "",
        "pdf_size": 294166,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16805285787858976286&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of Illinois Urbana-Champaign, Illinois, USA; University of Illinois Urbana-Champaign, Illinois, USA; University of Illinois Urbana-Champaign, Illinois, USA; Carnegie Mellon University, Pennsylvania, USA; University of Illinois Urbana-Champaign, Illinois, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Carnegie Mellon University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://illinois.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UIUC;CMU",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Urbana-Champaign;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a0bbb655fc",
        "title": "Greedy relaxations of the sparsest permutation algorithm",
        "site": "https://proceedings.mlr.press/v180/lam22a.html",
        "author": "Wai-Yin Lam; Bryan Andrews; Joseph Ramsey",
        "abstract": "There has been an increasing interest in methods that exploit permutation reasoning to search for directed acyclic causal models, including the \u201cOrdering Search\u2019\u2019 of Teyssier and Kohler and GSP of Solus, Wang and Uhler. We extend the methods of the latter by a permutation-based operation tuck, and develop a class of algorithms, namely GRaSP, that are computationally efficient and pointwise consistent under increasingly weaker assumptions than faithfulness. The most relaxed form of GRaSP outperforms many state-of-the-art causal search algorithms in simulation, allowing efficient and accurate search even for dense graphs and graphs with more than 100 variables.",
        "bibtex": "@InProceedings{pmlr-v180-lam22a,\n  title = \t {Greedy relaxations of the sparsest permutation algorithm},\n  author =       {Lam, Wai-Yin and Andrews, Bryan and Ramsey, Joseph},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1052--1062},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/lam22a/lam22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/lam22a.html},\n  abstract = \t {There has been an increasing interest in methods that exploit permutation reasoning to search for directed acyclic causal models, including the \u201cOrdering Search\u2019\u2019 of Teyssier and Kohler and GSP of Solus, Wang and Uhler. We extend the methods of the latter by a permutation-based operation tuck, and develop a class of algorithms, namely GRaSP, that are computationally efficient and pointwise consistent under increasingly weaker assumptions than faithfulness. The most relaxed form of GRaSP outperforms many state-of-the-art causal search algorithms in simulation, allowing efficient and accurate search even for dense graphs and graphs with more than 100 variables.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/lam22a/lam22a.pdf",
        "supp": "",
        "pdf_size": 396439,
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10933152077362717855&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5dc9bef217",
        "title": "High-probability bounds for robust stochastic Frank-Wolfe algorithm",
        "site": "https://proceedings.mlr.press/v180/tang22a.html",
        "author": "Tongyi Tang; Krishna Balasubramanian; Thomas Chun Man Lee",
        "abstract": "We develop and analyze robust Stochastic Frank-Wolfe type algorithms for projection-free stochastic convex optimization problems with heavy-tailed stochastic gradients. Existing works on the oracle complexity of such algorithms require a uniformly bounded variance assumption, and hold only in expectation. We develop tight high-probability bounds for robust versions of Stochastic Frank-Wolfe type algorithm under heavy-tailed assumptions, including infinite variance, on the stochastic gradient. Our methodological construction of the robust Stochastic Frank-Wolfe type algorithms leverage techniques from the robust statistic literature. Our theoretical analysis highlights the need to utilize robust versions of Stochastic Frank-Wolfe type algorithm for dealing with heavy-tailed data arising in practice.",
        "bibtex": "@InProceedings{pmlr-v180-tang22a,\n  title = \t {High-probability bounds for robust stochastic Frank-Wolfe algorithm},\n  author =       {Tang, Tongyi and Balasubramanian, Krishna and Chun Man Lee, Thomas},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1917--1927},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/tang22a/tang22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/tang22a.html},\n  abstract = \t {We develop and analyze robust Stochastic Frank-Wolfe type algorithms for projection-free stochastic convex optimization problems with heavy-tailed stochastic gradients. Existing works on the oracle complexity of such algorithms require a uniformly bounded variance assumption, and hold only in expectation. We develop tight high-probability bounds for robust versions of Stochastic Frank-Wolfe type algorithm under heavy-tailed assumptions, including infinite variance, on the stochastic gradient. Our methodological construction of the robust Stochastic Frank-Wolfe type algorithms leverage techniques from the robust statistic literature. Our theoretical analysis highlights the need to utilize robust versions of Stochastic Frank-Wolfe type algorithm for dealing with heavy-tailed data arising in practice.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/tang22a/tang22a.pdf",
        "supp": "",
        "pdf_size": 588300,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1391215286666480131&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7ed2852024",
        "title": "Hitting times for continuous-time imprecise-Markov chains",
        "site": "https://proceedings.mlr.press/v180/krak22a.html",
        "author": "Thomas Krak",
        "abstract": "We study the problem of characterizing the expected hitting times for a robust generalization of continuous-time Markov chains. This generalization is based on the theory of imprecise probabilities, and the models with which we work essentially constitute sets of stochastic processes. Their inferences are tight lower- and upper bounds with respect to variation within these sets.  We consider three distinct types of these models, corresponding to different levels of generality and structural independence assumptions on the constituent processes.  Our main results are twofold; first, we demonstrate that the hitting times for all three types are equivalent. Moreover, we show that these inferences are described by a straightforward generalization of a well-known linear system of equations that characterizes expected hitting times for traditional time-homogeneous continuous-time Markov chains.",
        "bibtex": "@InProceedings{pmlr-v180-krak22a,\n  title = \t {Hitting times for continuous-time imprecise-{M}arkov chains},\n  author =       {Krak, Thomas},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1031--1040},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/krak22a/krak22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/krak22a.html},\n  abstract = \t {We study the problem of characterizing the expected hitting times for a robust generalization of continuous-time Markov chains. This generalization is based on the theory of imprecise probabilities, and the models with which we work essentially constitute sets of stochastic processes. Their inferences are tight lower- and upper bounds with respect to variation within these sets.  We consider three distinct types of these models, corresponding to different levels of generality and structural independence assumptions on the constituent processes.  Our main results are twofold; first, we demonstrate that the hitting times for all three types are equivalent. Moreover, we show that these inferences are described by a straightforward generalization of a well-known linear system of equations that characterizes expected hitting times for traditional time-homogeneous continuous-time Markov chains.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/krak22a/krak22a.pdf",
        "supp": "",
        "pdf_size": 303161,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15487206722785458603&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Mathematics and Computer Science, Eindhoven University of Technology, Eindhoven, The Netherlands",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Eindhoven University of Technology",
        "aff_unique_dep": "Department of Mathematics and Computer Science",
        "aff_unique_url": "https://www.tue.nl",
        "aff_unique_abbr": "TU/e",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Eindhoven",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "a75c5b3a12",
        "title": "How unfair is private learning?",
        "site": "https://proceedings.mlr.press/v180/sanyal22a.html",
        "author": "Amartya Sanyal; Yaxi Hu; Fanny Yang",
        "abstract": "As machine learning algorithms are deployed on sensitive data in critical decision making processes, it is becoming increasingly important that they are also private and fair. In this paper, we show that, when the data has a long-tailed structure, it is not possible to build accurate learning algorithms that are both private and results in higher accuracy on minority subpopulations. We further show that relaxing overall accuracy can lead to good fairness even with strict privacy requirements. To corroborate our theoretical results in practice, we provide an extensive set of experimental results using a variety of synthetic, vision (CIFAR-10 and CelebA), and tabular (Law School) datasets and learning algorithms.",
        "bibtex": "@InProceedings{pmlr-v180-sanyal22a,\n  title = \t {How unfair is private learning?},\n  author =       {Sanyal, Amartya and Hu, Yaxi and Yang, Fanny},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1738--1748},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/sanyal22a/sanyal22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/sanyal22a.html},\n  abstract = \t {As machine learning algorithms are deployed on sensitive data in critical decision making processes, it is becoming increasingly important that they are also private and fair. In this paper, we show that, when the data has a long-tailed structure, it is not possible to build accurate learning algorithms that are both private and results in higher accuracy on minority subpopulations. We further show that relaxing overall accuracy can lead to good fairness even with strict privacy requirements. To corroborate our theoretical results in practice, we provide an extensive set of experimental results using a variety of synthetic, vision (CIFAR-10 and CelebA), and tabular (Law School) datasets and learning algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/sanyal22a/sanyal22a.pdf",
        "supp": "",
        "pdf_size": 966004,
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3803164501088654359&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "ETH AI Center, ETH Z\u00fcrich, Z\u00fcrich, Switzerland + Department of Computer Science, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Department of Mathematics, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Department of Computer Science, ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "ETH AI Center",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0+0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0+0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "72941ca8f1",
        "title": "Identifiability of sparse causal effects using instrumental variables",
        "site": "https://proceedings.mlr.press/v180/pfister22a.html",
        "author": "Niklas Pfister; Jonas Peters",
        "abstract": "Exogenous heterogeneity, for example, in the form of instrumental variables can help us learn a system\u2019s underlying causal structure and predict the outcome of unseen intervention experiments. In this paper, we consider linear models in which the causal effect from covariates X on a response Y is sparse. We provide conditions under which the causal coefficient becomes identifiable from the observed distribution. These conditions can be satisfied even if the number of instruments is as small as the number of causal parents. We also develop graphical criteria under which identifiability holds with probability one if the edge coefficients are sampled randomly from a distribution that is absolutely continuous with respect to Lebesgue measure and $Y$ is childless.  As an estimator, we propose spaceIV and prove that it consistently estimates the causal effect if the model is identifiable and evaluate its performance on simulated data. If identifiability does not hold, we show that it may still be possible to recover a subset of the causal parents.",
        "bibtex": "@InProceedings{pmlr-v180-pfister22a,\n  title = \t {Identifiability of sparse causal effects using instrumental variables},\n  author =       {Pfister, Niklas and Peters, Jonas},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1613--1622},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/pfister22a/pfister22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/pfister22a.html},\n  abstract = \t {Exogenous heterogeneity, for example, in the form of instrumental variables can help us learn a system\u2019s underlying causal structure and predict the outcome of unseen intervention experiments. In this paper, we consider linear models in which the causal effect from covariates X on a response Y is sparse. We provide conditions under which the causal coefficient becomes identifiable from the observed distribution. These conditions can be satisfied even if the number of instruments is as small as the number of causal parents. We also develop graphical criteria under which identifiability holds with probability one if the edge coefficients are sampled randomly from a distribution that is absolutely continuous with respect to Lebesgue measure and $Y$ is childless.  As an estimator, we propose spaceIV and prove that it consistently estimates the causal effect if the model is identifiable and evaluate its performance on simulated data. If identifiability does not hold, we show that it may still be possible to recover a subset of the causal parents.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/pfister22a/pfister22a.pdf",
        "supp": "",
        "pdf_size": 530422,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2499619703534508567&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Mathematical Sciences, University of Copenhagen, Denmark; Department of Mathematical Sciences, University of Copenhagen, Denmark",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Copenhagen",
        "aff_unique_dep": "Department of Mathematical Sciences",
        "aff_unique_url": "https://www.ku.dk",
        "aff_unique_abbr": "UCPH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "3cfe056384",
        "title": "Identifying near-optimal decisions in linear-in-parameter  bandit models with continuous decision sets",
        "site": "https://proceedings.mlr.press/v180/bhat22a.html",
        "author": "Sanjay P. Bhat; Chaitanya Amballa",
        "abstract": "We consider an online optimization problem in a bandit  setting in which a learner chooses decisions from a continuous decision  set at discrete decision epochs, and receives noisy rewards from the  environment in response. While the noise samples are assumed to be  independent and sub-Gaussian, the mean reward at each epoch is a fixed but  unknown linear function of a feature vector, which depends on the decision  through a known (and possibly nonlinear)  feature map. We study the  problem within the framework of best-arm identification with fixed  confidence, and provide a template algorithm for approximately learning  the optimal decision in a probably approximately correct (PAC) setting.  More precisely, the template algorithm samples the decision space till a  stopping condition is met,  and returns a subset of decisions such that,  with the required confidence, every element of the subset is approximately  optimal for the unknown mean reward function.  We provide a sample  complexity bound for the template algorithm and then specialize it to the  case where the mean-reward function is a univariate polynomial of a single  decision variable. We provide an implementable algorithm for this case by  explicitly instantiating all the steps in the template algorithm. Finally,  we provide experimental results to demonstrate the efficacy of our  algorithms.",
        "bibtex": "@InProceedings{pmlr-v180-bhat22a,\n  title = \t {Identifying near-optimal decisions in linear-in-parameter  bandit models with continuous decision sets},\n  author =       {Bhat, Sanjay P. and Amballa, Chaitanya},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {181--190},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/bhat22a/bhat22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/bhat22a.html},\n  abstract = \t {We consider an online optimization problem in a bandit  setting in which a learner chooses decisions from a continuous decision  set at discrete decision epochs, and receives noisy rewards from the  environment in response. While the noise samples are assumed to be  independent and sub-Gaussian, the mean reward at each epoch is a fixed but  unknown linear function of a feature vector, which depends on the decision  through a known (and possibly nonlinear)  feature map. We study the  problem within the framework of best-arm identification with fixed  confidence, and provide a template algorithm for approximately learning  the optimal decision in a probably approximately correct (PAC) setting.  More precisely, the template algorithm samples the decision space till a  stopping condition is met,  and returns a subset of decisions such that,  with the required confidence, every element of the subset is approximately  optimal for the unknown mean reward function.  We provide a sample  complexity bound for the template algorithm and then specialize it to the  case where the mean-reward function is a univariate polynomial of a single  decision variable. We provide an implementable algorithm for this case by  explicitly instantiating all the steps in the template algorithm. Finally,  we provide experimental results to demonstrate the efficacy of our  algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/bhat22a/bhat22a.pdf",
        "supp": "",
        "pdf_size": 316094,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16335726059537578941&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "TCS Research, Hyderabad, India; TCS Research, Hyderabad, India",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tata Consultancy Services",
        "aff_unique_dep": "Research",
        "aff_unique_url": "https://www.tcs.com",
        "aff_unique_abbr": "TCS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hyderabad",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "c2e19d13ed",
        "title": "If you\u2019ve trained one you\u2019ve trained them all: inter-architecture similarity increases with robustness",
        "site": "https://proceedings.mlr.press/v180/jones22a.html",
        "author": "Haydn T. Jones; Jacob M. Springer; Garrett T. Kenyon; Juston S. Moore",
        "abstract": "Previous work has shown that commonly-used metrics for comparing representations between neural networks overestimate similarity due to correlations between data points. We show that intra-example feature correlations also causes significant overestimation of network similarity and propose an image inversion technique to analyze only the features used by a network. With this technique, we find that similarity across architectures is significantly lower than commonly understood, but we surprisingly find that similarity between models with different architectures increases as the adversarial robustness of the models increase. Our findings indicate that robust networks tend toward a universal set of representations, regardless of architecture, and that the robust training criterion is a strong prior constraint on the functions that can be learned by diverse modern architectures. We also find that the representations learned by a robust network of any architecture have an asymmetric overlap with non-robust networks of many architectures, indicating that the representations used by robust neural networks are highly entangled with the representations used by non-robust networks.",
        "bibtex": "@InProceedings{pmlr-v180-jones22a,\n  title = \t {If you\u2019ve trained one you\u2019ve trained them all: inter-architecture similarity increases with robustness},\n  author =       {Jones, Haydn T. and Springer, Jacob M. and Kenyon, Garrett T. and Moore, Juston S.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {928--937},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/jones22a/jones22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/jones22a.html},\n  abstract = \t {Previous work has shown that commonly-used metrics for comparing representations between neural networks overestimate similarity due to correlations between data points. We show that intra-example feature correlations also causes significant overestimation of network similarity and propose an image inversion technique to analyze only the features used by a network. With this technique, we find that similarity across architectures is significantly lower than commonly understood, but we surprisingly find that similarity between models with different architectures increases as the adversarial robustness of the models increase. Our findings indicate that robust networks tend toward a universal set of representations, regardless of architecture, and that the robust training criterion is a strong prior constraint on the functions that can be learned by diverse modern architectures. We also find that the representations learned by a robust network of any architecture have an asymmetric overlap with non-robust networks of many architectures, indicating that the representations used by robust neural networks are highly entangled with the representations used by non-robust networks.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/jones22a/jones22a.pdf",
        "supp": "",
        "pdf_size": 1174885,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2847578652044377164&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Los Alamos National Laboratory; Los Alamos National Laboratory; Los Alamos National Laboratory; Los Alamos National Laboratory",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/haydn-jones",
        "project": "haydn-jones.github.io/posts/a-better-index-of-similarity",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Los Alamos National Laboratory",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.lanl.gov",
        "aff_unique_abbr": "LANL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ba42bc95cb",
        "title": "Implicit kernel meta-learning using kernel integral forms",
        "site": "https://proceedings.mlr.press/v180/falk22a.html",
        "author": "John Isak Texas Falk; Carlo Cilibert; Massimiliano Pontil",
        "abstract": "Meta-learning algorithms have made significant progress in the context of meta-learning for image classification but less attention has been given to the regression setting. In this paper we propose to learn the probability distribution representing a random feature kernel that we wish to use within kernel ridge regression (KRR). We introduce two instances of this meta-learning framework, learning a neural network pushforward for a translation-invariant kernel and an affine pushforward for a neural network random feature kernel, both mapping from a Gaussian latent distribution. We learn the parameters of the pushforward by minimizing a meta-loss associated to the KRR objective. Since the resulting kernel does not admit an analytical form, we adopt a random feature sampling approach to approximate it. We call the resulting method Implicit Kernel Meta-Learning (IKML). We derive a meta-learning bound for IKML, which shows the role played by the number of tasks $T$, the task sample size $n$, and the number of random features $M$. In particular the bound implies that $M$ can be the chosen independently of $T$ and only mildly dependent on $n$. We introduce one synthetic and two real-world meta-learning regression benchmark datasets. Experiments on these datasets show that IKML",
        "bibtex": "@InProceedings{pmlr-v180-falk22a,\n  title = \t {Implicit kernel meta-learning using kernel integral forms},\n  author =       {Falk, John Isak Texas and Cilibert, Carlo and Pontil, Massimiliano},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {652--662},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/falk22a/falk22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/falk22a.html},\n  abstract = \t {Meta-learning algorithms have made significant progress in the context of meta-learning for image classification but less attention has been given to the regression setting. In this paper we propose to learn the probability distribution representing a random feature kernel that we wish to use within kernel ridge regression (KRR). We introduce two instances of this meta-learning framework, learning a neural network pushforward for a translation-invariant kernel and an affine pushforward for a neural network random feature kernel, both mapping from a Gaussian latent distribution. We learn the parameters of the pushforward by minimizing a meta-loss associated to the KRR objective. Since the resulting kernel does not admit an analytical form, we adopt a random feature sampling approach to approximate it. We call the resulting method Implicit Kernel Meta-Learning (IKML). We derive a meta-learning bound for IKML, which shows the role played by the number of tasks $T$, the task sample size $n$, and the number of random features $M$. In particular the bound implies that $M$ can be the chosen independently of $T$ and only mildly dependent on $n$. We introduce one synthetic and two real-world meta-learning regression benchmark datasets. Experiments on these datasets show that IKML}\n}",
        "pdf": "https://proceedings.mlr.press/v180/falk22a/falk22a.pdf",
        "supp": "",
        "pdf_size": 412698,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10383649648007972157&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f9205267c2",
        "title": "Improved feature importance computation for tree models based on the Banzhaf value",
        "site": "https://proceedings.mlr.press/v180/karczmarz22a.html",
        "author": "Adam Karczmarz; Tomasz Michalak; Anish Mukherjee; Piotr Sankowski; Piotr Wygocki",
        "abstract": "The Shapley value \u2013 a fundamental game-theoretic solution concept \u2013 has recently become one of the main tools used to explain predictions of tree ensemble models. Another well-known game-theoretic solution concept is the Banzhaf value. Although the Banzhaf value is closely related to the Shapley value, its properties w.r.t. feature attribution have not been understood equally well. This paper shows that, for tree ensemble models, the Banzhaf value offers some crucial advantages over the Shapley value while providing similar feature attributions. In particular, we first give an optimal O(TL + n) time algorithm for computing the Banzhaf value-based attribution of a tree ensemble model\u2019s output. Here, T is the number of trees, L is the maximum number of leaves in a tree, and n is the number of features. In comparison, the state-of-the-art Shapley value-based algorithm runs in O(TLD^2 + n) time, where D denotes the maximum depth of a tree in the ensemble. Next, we experimentally compare the Banzhaf and Shapley values for tree ensemble models. Both methods deliver essentially the same average importance scores for the studied datasets using two different tree ensemble models (the sklearn implementation of Decision Trees or xgboost implementation of Gradient Boosting Decision Trees). However, our results indicate that, on top of being computable faster, the Banzhaf is more numerically robust than the Shapley value.",
        "bibtex": "@InProceedings{pmlr-v180-karczmarz22a,\n  title = \t {Improved feature importance computation for tree models based on the Banzhaf value},\n  author =       {Karczmarz, Adam and Michalak, Tomasz and Mukherjee, Anish and Sankowski, Piotr and Wygocki, Piotr},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {969--979},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/karczmarz22a/karczmarz22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/karczmarz22a.html},\n  abstract = \t {The Shapley value \u2013 a fundamental game-theoretic solution concept \u2013 has recently become one of the main tools used to explain predictions of tree ensemble models. Another well-known game-theoretic solution concept is the Banzhaf value. Although the Banzhaf value is closely related to the Shapley value, its properties w.r.t. feature attribution have not been understood equally well. This paper shows that, for tree ensemble models, the Banzhaf value offers some crucial advantages over the Shapley value while providing similar feature attributions. In particular, we first give an optimal O(TL + n) time algorithm for computing the Banzhaf value-based attribution of a tree ensemble model\u2019s output. Here, T is the number of trees, L is the maximum number of leaves in a tree, and n is the number of features. In comparison, the state-of-the-art Shapley value-based algorithm runs in O(TLD^2 + n) time, where D denotes the maximum depth of a tree in the ensemble. Next, we experimentally compare the Banzhaf and Shapley values for tree ensemble models. Both methods deliver essentially the same average importance scores for the studied datasets using two different tree ensemble models (the sklearn implementation of Decision Trees or xgboost implementation of Gradient Boosting Decision Trees). However, our results indicate that, on top of being computable faster, the Banzhaf is more numerically robust than the Shapley value.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/karczmarz22a/karczmarz22a.pdf",
        "supp": "",
        "pdf_size": 295220,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5490294364125889862&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Institute of Informatics, University of Warsaw, Poland+IDEAS NCBR, Warsaw, Poland; Institute of Informatics, University of Warsaw, Poland+IDEAS NCBR, Warsaw, Poland; Institute of Informatics, University of Warsaw, Poland+IDEAS NCBR, Warsaw, Poland; Institute of Informatics, University of Warsaw, Poland+IDEAS NCBR, Warsaw, Poland+MIM Solutions, Warsaw, Poland; Institute of Informatics, University of Warsaw, Poland+MIM Solutions, Warsaw, Poland",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0+1;0+1+2;0+2",
        "aff_unique_norm": "University of Warsaw;IDEAS National Centre for Biotechnology;MIM Solutions",
        "aff_unique_dep": "Institute of Informatics;;",
        "aff_unique_url": "https://www.uw.edu.pl;;",
        "aff_unique_abbr": "UW;IDEAS NCBR;",
        "aff_campus_unique_index": ";;;;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0+0;0+0",
        "aff_country_unique": "Poland"
    },
    {
        "id": "1e1babbf1e",
        "title": "Improving sign-random-projection via count sketch",
        "site": "https://proceedings.mlr.press/v180/dubey22a.html",
        "author": "Punit Pankaj Dubey; Bhisham Dev Verma; Rameshwar Pratap; Keegan Kang",
        "abstract": "Computing the angular similarity between pairs of vectors is a core part of various machine learning algorithms. The seminal work of Charikar (a.k.a. Sign-Random-Projection (SRP) or SimHash) provides an unbiased estimate for the same. However, SRP suffers from the following limitations: (i) large variance in the similarity estimation, (ii) and high running time while computing the sketch. There are improved variants that address these limitations. However, they are known to improve on only one aspect in their proposal, for e.g. Yu et al. suggest a faster algorithm, Ji et al., Kang and Wong, provide estimates with a smaller variance. In this work, we propose a sketching algorithm that addresses both aspects in one algorithm \u2013 a faster algorithm along with a smaller variance in the similarity estimation. Moreover, our algorithm is space-efficient as well. We present a rigorous theoretical analysis of our proposal and complement it via experiments on synthetic and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v180-dubey22a,\n  title = \t {Improving sign-random-projection via count sketch},\n  author =       {Dubey, Punit Pankaj and Verma, Bhisham Dev and Pratap, Rameshwar and Kang, Keegan},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {599--609},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/dubey22a/dubey22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/dubey22a.html},\n  abstract = \t {Computing the angular similarity between pairs of vectors is a core part of various machine learning algorithms. The seminal work of Charikar (a.k.a. Sign-Random-Projection (SRP) or SimHash) provides an unbiased estimate for the same. However, SRP suffers from the following limitations: (i) large variance in the similarity estimation, (ii) and high running time while computing the sketch. There are improved variants that address these limitations. However, they are known to improve on only one aspect in their proposal, for e.g. Yu et al. suggest a faster algorithm, Ji et al., Kang and Wong, provide estimates with a smaller variance. In this work, we propose a sketching algorithm that addresses both aspects in one algorithm \u2013 a faster algorithm along with a smaller variance in the similarity estimation. Moreover, our algorithm is space-efficient as well. We present a rigorous theoretical analysis of our proposal and complement it via experiments on synthetic and real-world datasets. }\n}",
        "pdf": "https://proceedings.mlr.press/v180/dubey22a/dubey22a.pdf",
        "supp": "",
        "pdf_size": 466553,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5842339817602636347&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f1f46dbcb4",
        "title": "Individual fairness in feature-based pricing for monopoly markets",
        "site": "https://proceedings.mlr.press/v180/das22a.html",
        "author": "Shantanu Das; Swapnil Dhamal; Ganesh Ghalme; Shweta Jain; Sujit Gujar",
        "abstract": "We study fairness in the context of feature-based price discrimination in monopoly markets. We propose a new notion of individual fairness, namely, \\alpha-fairness, which guarantees that individuals with similar features face similar prices. First, we study discrete valuation space and give an analytical solution for optimal fair feature-based pricing.  We show that the cost of fair pricing is defined as the ratio of expected revenue in an optimal feature-based pricing to the expected revenue in an optimal fair feature-based pricing  (CoF) can be arbitrarily large in general. When the revenue function is continuous and concave with respect to the prices, we show that one can achieve CoF strictly less than 2, irrespective of the model parameters. Finally, we provide an algorithm to compute fair feature-based pricing strategy that achieves this CoF.",
        "bibtex": "@InProceedings{pmlr-v180-das22a,\n  title = \t {Individual fairness in feature-based pricing for monopoly markets},\n  author =       {Das, Shantanu and Dhamal, Swapnil and Ghalme, Ganesh and Jain, Shweta and Gujar, Sujit},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {486--495},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/das22a/das22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/das22a.html},\n  abstract = \t {We study fairness in the context of feature-based price discrimination in monopoly markets. We propose a new notion of individual fairness, namely, \\alpha-fairness, which guarantees that individuals with similar features face similar prices. First, we study discrete valuation space and give an analytical solution for optimal fair feature-based pricing.  We show that the cost of fair pricing is defined as the ratio of expected revenue in an optimal feature-based pricing to the expected revenue in an optimal fair feature-based pricing  (CoF) can be arbitrarily large in general. When the revenue function is continuous and concave with respect to the prices, we show that one can achieve CoF strictly less than 2, irrespective of the model parameters. Finally, we provide an algorithm to compute fair feature-based pricing strategy that achieves this CoF.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/das22a/das22a.pdf",
        "supp": "",
        "pdf_size": 573364,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11649916803980949791&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Machine Learning Lab, International Institute of Information Technology, Hyderabad, India; T\u00e9l\u00e9com SudParis, Institut Polytechnique de Paris, \u00c9vry, France; Indian Institute of Technology, Hyderabad, India; Indian Institute of Technology, Ropar, India; Machine Learning Lab, International Institute of Information Technology, Hyderabad, India",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "International Institute of Information Technology;T\u00e9l\u00e9com SudParis;Indian Institute of Technology Hyderabad;Indian Institute of Technology Ropar",
        "aff_unique_dep": "Machine Learning Lab;;;",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;https://www.telecom-sudparis.eu;https://www.iith.ac.in;https://iitrpr.ac.in",
        "aff_unique_abbr": "IIIT Hyderabad;TSP;IIT Hyderabad;IIT Ropar",
        "aff_campus_unique_index": "0;1;0;2;0",
        "aff_campus_unique": "Hyderabad;\u00c9vry;Ropar",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "India;France"
    },
    {
        "id": "090cbfc468",
        "title": "Inductive synthesis of finite-state controllers for POMDPs",
        "site": "https://proceedings.mlr.press/v180/andriushchenko22a.html",
        "author": "Roman Andriushchenko; Milan \u010ce\u0161ka; Sebastian Junges; Joost-Pieter Katoen",
        "abstract": "We present a novel learning framework to obtain finite-state controllers (FSCs) for partially observable Markov decision processes and illustrate its applicability for indefinite-horizon specifications. Our framework builds on oracle-guided inductive synthesis to explore a design space compactly representing available FSCs. The inductive synthesis approach consists of two stages: The outer stage determines the design space, i.e., the set of FSC candidates, while the inner stage efficiently explores the design space. This framework is easily generalisable and shows promising results when compared to existing approaches. Experiments indicate that our technique is (i) competitive to state-of-the-art belief-based approaches for indefinite-horizon properties, (ii) yields smaller FSCs than existing methods for several POMDP models, and (iii) naturally treats multi-objective specifications.",
        "bibtex": "@InProceedings{pmlr-v180-andriushchenko22a,\n  title = \t {Inductive synthesis of finite-state controllers for POMDPs},\n  author =       {Andriushchenko, Roman and \\v{C}e\\v{s}ka, Milan and Junges, Sebastian and Katoen, Joost-Pieter},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {85--95},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/andriushchenko22a/andriushchenko22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/andriushchenko22a.html},\n  abstract = \t {We present a novel learning framework to obtain finite-state controllers (FSCs) for partially observable Markov decision processes and illustrate its applicability for indefinite-horizon specifications. Our framework builds on oracle-guided inductive synthesis to explore a design space compactly representing available FSCs. The inductive synthesis approach consists of two stages: The outer stage determines the design space, i.e., the set of FSC candidates, while the inner stage efficiently explores the design space. This framework is easily generalisable and shows promising results when compared to existing approaches. Experiments indicate that our technique is (i) competitive to state-of-the-art belief-based approaches for indefinite-horizon properties, (ii) yields smaller FSCs than existing methods for several POMDP models, and (iii) naturally treats multi-objective specifications.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/andriushchenko22a/andriushchenko22a.pdf",
        "supp": "",
        "pdf_size": 391088,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11136528745538285519&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1be7ac1d49",
        "title": "Information design for multiple independent and self-interested defenders: Work less, pay off more",
        "site": "https://proceedings.mlr.press/v180/zhou22c.html",
        "author": "Chenghan Zhou; Andrew Spivey; Haifeng Xu; Thanh Hong Nguyen",
        "abstract": "This paper studies the problem of information design in a general security game setting in which multiple independent self-interested defenders attempt to provide protection simultaneously on the same set of important targets against an unknown attacker. A principal, who can be one of the defenders, has access to certain private information (i.e., attacker type) whereas other defenders do not. We investigate the  question of how that principal, with additional private information, can influence the decisions of the defenders by partially and strategically revealing her information. We focus on the algorithmic study of information design for private signaling in this game setting. In particular, we develop a polynomial-time ellipsoid algorithm to compute an optimal private signaling scheme. Our key finding is that the separation oracle in the ellipsoid approach can be carefully reduced to bipartite matching. Furthermore, we introduce a compact representation of any ex-ante persuasive signaling schemes by exploiting intrinsic security resource allocation structures, enabling us to compute an optimal scheme significantly faster. Our experiment results show that by strategically revealing private information, the principal can significantly enhance the protection effectiveness on the targets.",
        "bibtex": "@InProceedings{pmlr-v180-zhou22c,\n  title = \t {Information design for multiple independent and self-interested defenders: Work less, pay off more},\n  author =       {Zhou, Chenghan and Spivey, Andrew and Xu, Haifeng and Hong Nguyen, Thanh},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2404--2413},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/zhou22c/zhou22c.pdf},\n  url = \t {https://proceedings.mlr.press/v180/zhou22c.html},\n  abstract = \t {This paper studies the problem of information design in a general security game setting in which multiple independent self-interested defenders attempt to provide protection simultaneously on the same set of important targets against an unknown attacker. A principal, who can be one of the defenders, has access to certain private information (i.e., attacker type) whereas other defenders do not. We investigate the  question of how that principal, with additional private information, can influence the decisions of the defenders by partially and strategically revealing her information. We focus on the algorithmic study of information design for private signaling in this game setting. In particular, we develop a polynomial-time ellipsoid algorithm to compute an optimal private signaling scheme. Our key finding is that the separation oracle in the ellipsoid approach can be carefully reduced to bipartite matching. Furthermore, we introduce a compact representation of any ex-ante persuasive signaling schemes by exploiting intrinsic security resource allocation structures, enabling us to compute an optimal scheme significantly faster. Our experiment results show that by strategically revealing private information, the principal can significantly enhance the protection effectiveness on the targets.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/zhou22c/zhou22c.pdf",
        "supp": "",
        "pdf_size": 648040,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:cgosYTXpHMkJ:scholar.google.com/&scioq=Information+design+for+multiple+independent+and+self-interested+defenders:+Work+less,+pay+off+more&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a90490d815",
        "title": "Information theoretic approach to detect collusion in multi-agent games",
        "site": "https://proceedings.mlr.press/v180/bonjour22a.html",
        "author": "Trevor Bonjour; Vaneet Aggarwal; Bharat Bhargava",
        "abstract": "Collusion in a competitive multi-agent game occurs when two or more agents co-operate covertly to the disadvantage of others. Most competitive multi-agent games do not allow players to share information and explicitly prohibit collusion. In this paper, we present a novel way of detecting collusion using a domain-independent information-theoretic approach. Specifically, we show that the use of mutual information between actions of the agents provides a good indication of collusive behavior. Our experiments show that our method can detect varying levels of collusion in repeated simultaneous games like iterated Rock Paper Scissors. We further extend the detection to partially observable sequential games like poker and show the effectiveness of our methodology.",
        "bibtex": "@InProceedings{pmlr-v180-bonjour22a,\n  title = \t {Information theoretic approach to detect collusion in multi-agent games},\n  author =       {Bonjour, Trevor and Aggarwal, Vaneet and Bhargava, Bharat},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {223--232},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/bonjour22a/bonjour22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/bonjour22a.html},\n  abstract = \t {Collusion in a competitive multi-agent game occurs when two or more agents co-operate covertly to the disadvantage of others. Most competitive multi-agent games do not allow players to share information and explicitly prohibit collusion. In this paper, we present a novel way of detecting collusion using a domain-independent information-theoretic approach. Specifically, we show that the use of mutual information between actions of the agents provides a good indication of collusive behavior. Our experiments show that our method can detect varying levels of collusion in repeated simultaneous games like iterated Rock Paper Scissors. We further extend the detection to partially observable sequential games like poker and show the effectiveness of our methodology.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/bonjour22a/bonjour22a.pdf",
        "supp": "",
        "pdf_size": 834322,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3705315277973356781&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Computer Science, Purdue University, West Lafayette, Indiana, USA; School of Industrial Engineering, Purdue University, West Lafayette, Indiana, USA; Department of Computer Science, Purdue University, West Lafayette, Indiana, USA",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "500caf3e81",
        "title": "Interpolating between sampling and variational inference with infinite stochastic mixtures",
        "site": "https://proceedings.mlr.press/v180/lange22a.html",
        "author": "Richard D. Lange; Ari S. Benjamin; Ralf M. Haefner; Xaq Pitkow",
        "abstract": "Sampling and Variational Inference (VI) are two large families of methods for approximate inference that have complementary strengths. Sampling methods excel at approximating arbitrary probability distributions, but can be inefficient. VI methods are efficient, but may misrepresent the true distribution. Here, we develop a general framework where approximations are stochastic mixtures of simple component distributions. Both sampling and VI can be seen as special cases: in sampling, each mixture component is a delta-function and is chosen stochastically, while in standard VI a single component is chosen to minimize divergence. We derive a practical method that interpolates between sampling and VI by analytically solving an optimization problem over a mixing distribution. Intermediate inference methods then arise by varying a single parameter. Our method provably improves on sampling (reducing variance) and on VI (reducing bias+variance despite increasing variance). We demonstrate our method\u2019s bias/variance trade-off in practice on reference problems, and we compare outcomes to commonly used sampling and VI methods. This work takes a step towards a highly flexible yet simple family of inference methods that combines the complementary strengths of sampling and VI.",
        "bibtex": "@InProceedings{pmlr-v180-lange22a,\n  title = \t {Interpolating between sampling and variational inference with infinite stochastic mixtures},\n  author =       {Lange, Richard D. and Benjamin, Ari S. and Haefner, Ralf M. and Pitkow, Xaq},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1063--1073},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/lange22a/lange22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/lange22a.html},\n  abstract = \t {Sampling and Variational Inference (VI) are two large families of methods for approximate inference that have complementary strengths. Sampling methods excel at approximating arbitrary probability distributions, but can be inefficient. VI methods are efficient, but may misrepresent the true distribution. Here, we develop a general framework where approximations are stochastic mixtures of simple component distributions. Both sampling and VI can be seen as special cases: in sampling, each mixture component is a delta-function and is chosen stochastically, while in standard VI a single component is chosen to minimize divergence. We derive a practical method that interpolates between sampling and VI by analytically solving an optimization problem over a mixing distribution. Intermediate inference methods then arise by varying a single parameter. Our method provably improves on sampling (reducing variance) and on VI (reducing bias+variance despite increasing variance). We demonstrate our method\u2019s bias/variance trade-off in practice on reference problems, and we compare outcomes to commonly used sampling and VI methods. This work takes a step towards a highly flexible yet simple family of inference methods that combines the complementary strengths of sampling and VI.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/lange22a/lange22a.pdf",
        "supp": "",
        "pdf_size": 1833077,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3238316500001724719&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "af4db2782a",
        "title": "Intervention target estimation in the presence of latent variables",
        "site": "https://proceedings.mlr.press/v180/varici22a.html",
        "author": "Burak Varici; Karthikeyan Shanmugam; Prasanna Sattigeri; Ali Tajer",
        "abstract": "This paper considers the problem of estimating unknown intervention targets in causal directed acyclic graphs from observational and interventional data in the presence of latent variables. The focus is on linear structural equation models with soft interventions. The existing approaches to this problem involve performing extensive conditional independence tests, and they estimate the unknown intervention targets alongside learning the structure of the causal model in its entirety. This joint learning approach results in algorithms that are not scalable as graph sizes grow. This paper proposes an approach that does not necessitate learning the entire causal model and focuses on learning only the intervention targets. The key idea of this approach is leveraging the property that interventions impose sparse changes in the precision matrix of a linear model. The proposed framework consists of a sequence of precision difference estimation steps. Furthermore, the necessary knowledge to refine an observational Markov equivalence class (MEC) to an interventional MEC is inferred. Simulation results are provided to illustrate the scalability of the proposed algorithm and compare it with those of the existing approaches.",
        "bibtex": "@InProceedings{pmlr-v180-varici22a,\n  title = \t {Intervention target estimation in the presence of latent variables},\n  author =       {Varici, Burak and Shanmugam, Karthikeyan and Sattigeri, Prasanna and Tajer, Ali},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2013--2023},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/varici22a/varici22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/varici22a.html},\n  abstract = \t {This paper considers the problem of estimating unknown intervention targets in causal directed acyclic graphs from observational and interventional data in the presence of latent variables. The focus is on linear structural equation models with soft interventions. The existing approaches to this problem involve performing extensive conditional independence tests, and they estimate the unknown intervention targets alongside learning the structure of the causal model in its entirety. This joint learning approach results in algorithms that are not scalable as graph sizes grow. This paper proposes an approach that does not necessitate learning the entire causal model and focuses on learning only the intervention targets. The key idea of this approach is leveraging the property that interventions impose sparse changes in the precision matrix of a linear model. The proposed framework consists of a sequence of precision difference estimation steps. Furthermore, the necessary knowledge to refine an observational Markov equivalence class (MEC) to an interventional MEC is inferred. Simulation results are provided to illustrate the scalability of the proposed algorithm and compare it with those of the existing approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/varici22a/varici22a.pdf",
        "supp": "",
        "pdf_size": 291296,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3986761000084586165&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "316fe24b47",
        "title": "Knowledge representation combining quaternion path integration and depth-wise atrous circular convolution",
        "site": "https://proceedings.mlr.press/v180/chen22c.html",
        "author": "Xinyuan Chen; Zhongmei Zhou; Meichun Gao; Daya Shi; Mohd N. Husen",
        "abstract": "Knowledge models endeavor to improve representation and feature extraction capabilities while keeping low computational cost. Firstly, existing embedding models in hypercomplex spaces of non-Abelian group are optimized. Then a method for fast quaternion multiplication is proposed with proof, with which path semantics are computed and further integrated with the attention mechanism based on the idea semantic extraction of relation sequences could be regarded as a multiple rotational blending problem. A depth-wise atrous circular convolution framework is set up for better feature extraction. Experiments including Link Prediction and Path Query are conducted on benchmark datasets verifying our model holds advantages over state-of-the-art models like Rotate3D. Moreover, the model is tested on a biomedical dataset simulating real-world applications. An ablation study is also performed to explore the effectiveness of different components.",
        "bibtex": "@InProceedings{pmlr-v180-chen22c,\n  title = \t {Knowledge representation combining quaternion path integration and depth-wise atrous circular convolution},\n  author =       {Chen, Xinyuan and Zhou, Zhongmei and Gao, Meichun and Shi, Daya and Husen, Mohd N.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {336--345},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/chen22c/chen22c.pdf},\n  url = \t {https://proceedings.mlr.press/v180/chen22c.html},\n  abstract = \t {Knowledge models endeavor to improve representation and feature extraction capabilities while keeping low computational cost. Firstly, existing embedding models in hypercomplex spaces of non-Abelian group are optimized. Then a method for fast quaternion multiplication is proposed with proof, with which path semantics are computed and further integrated with the attention mechanism based on the idea semantic extraction of relation sequences could be regarded as a multiple rotational blending problem. A depth-wise atrous circular convolution framework is set up for better feature extraction. Experiments including Link Prediction and Path Query are conducted on benchmark datasets verifying our model holds advantages over state-of-the-art models like Rotate3D. Moreover, the model is tested on a biomedical dataset simulating real-world applications. An ablation study is also performed to explore the effectiveness of different components. }\n}",
        "pdf": "https://proceedings.mlr.press/v180/chen22c/chen22c.pdf",
        "supp": "",
        "pdf_size": 1667049,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7262684186842425962&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "School of Technology, Fuzhou Technology and Business University, Fuzhou, Fujian, China+Malaysian Institute of Information Technology, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia; School of Technology, Fuzhou Technology and Business University, Fuzhou, Fujian, China; School of Technology, Fuzhou Technology and Business University, Fuzhou, Fujian, China; School of Technology, Fuzhou Technology and Business University, Fuzhou, Fujian, China; Malaysian Institute of Information Technology, Universiti Kuala Lumpur, Kuala Lumpur, Malaysia",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0;0;1",
        "aff_unique_norm": "Fuzhou Technology and Business University;Universiti Kuala Lumpur",
        "aff_unique_dep": "School of Technology;Malaysian Institute of Information Technology",
        "aff_unique_url": ";https://www.unikl.edu.my",
        "aff_unique_abbr": ";UniKL",
        "aff_campus_unique_index": "0+1;0;0;0;1",
        "aff_campus_unique": "Fuzhou;Kuala Lumpur",
        "aff_country_unique_index": "0+1;0;0;0;1",
        "aff_country_unique": "China;Malaysia"
    },
    {
        "id": "29024d296c",
        "title": "Laplace approximated Gaussian process state-space models",
        "site": "https://proceedings.mlr.press/v180/lindinger22a.html",
        "author": "Jakob Lindinger; Barbara Rakitsch; Christoph Lippert",
        "abstract": "Gaussian process state-space models describe time series data in a probabilistic and non-parametric manner using a Gaussian process transition function. As inference is intractable, recent methods use variational inference and either rely on simplifying independence assumptions on the approximate posterior or learn the temporal states iteratively. The latter hampers optimization since the posterior over the presence can only be learned once the posterior governing the past has converged. We present a novel inference scheme that applies stochastic variational inference for the Gaussian process posterior and the Laplace approximation on the temporal states. This approach respects the conditional dependencies in the model and, through the Laplace approximation, treats the temporal states jointly, thereby avoiding their sequential learning. Our method is computationally efficient and  leads to better calibrated predictions compared to state-of-the art alternatives on synthetic data and on a range of benchmark datasets.",
        "bibtex": "@InProceedings{pmlr-v180-lindinger22a,\n  title = \t {Laplace approximated Gaussian process state-space models},\n  author =       {Lindinger, Jakob and Rakitsch, Barbara and Lippert, Christoph},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1199--1209},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/lindinger22a/lindinger22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/lindinger22a.html},\n  abstract = \t {Gaussian process state-space models describe time series data in a probabilistic and non-parametric manner using a Gaussian process transition function. As inference is intractable, recent methods use variational inference and either rely on simplifying independence assumptions on the approximate posterior or learn the temporal states iteratively. The latter hampers optimization since the posterior over the presence can only be learned once the posterior governing the past has converged. We present a novel inference scheme that applies stochastic variational inference for the Gaussian process posterior and the Laplace approximation on the temporal states. This approach respects the conditional dependencies in the model and, through the Laplace approximation, treats the temporal states jointly, thereby avoiding their sequential learning. Our method is computationally efficient and  leads to better calibrated predictions compared to state-of-the art alternatives on synthetic data and on a range of benchmark datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/lindinger22a/lindinger22a.pdf",
        "supp": "",
        "pdf_size": 364848,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6654806942153181350&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7ad0fbc6c4",
        "title": "Learning a neural Pareto manifold extractor with constraints",
        "site": "https://proceedings.mlr.press/v180/gupta22a.html",
        "author": "Soumyajit Gupta; Gurpreet Singh; Raghu Bollapragada; \\Matthew Lease",
        "abstract": "Multi-objective optimization (MOO) problems require balancing competing objectives, often under constraints. The Pareto optimal solution set defines all possible optimal trade-offs over such objectives. In this work, we present a novel method for Pareto-front learning: inducing the full Pareto manifold at train-time so users can pick any desired optimal trade-off point at run-time. Our key insight is to exploit Fritz-John Conditions for a novel guided double gradient descent strategy. Evaluation on synthetic benchmark problems allows us to vary MOO problem difficulty in controlled fashion and measure accuracy \\vs known analytic solutions. We further test scalability and generalization in learning optimal neural model parameterizations for Multi-Task Learning (MTL) on image classification. Results show consistent improvement in  accuracy and efficiency over prior MTL methods as well as techniques from operations research.",
        "bibtex": "@InProceedings{pmlr-v180-gupta22a,\n  title = \t {Learning a neural Pareto manifold extractor with constraints},\n  author =       {Gupta, Soumyajit and Singh, Gurpreet and Bollapragada, Raghu and Lease, \\Matthew},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {749--758},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/gupta22a/gupta22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/gupta22a.html},\n  abstract = \t {Multi-objective optimization (MOO) problems require balancing competing objectives, often under constraints. The Pareto optimal solution set defines all possible optimal trade-offs over such objectives. In this work, we present a novel method for Pareto-front learning: inducing the full Pareto manifold at train-time so users can pick any desired optimal trade-off point at run-time. Our key insight is to exploit Fritz-John Conditions for a novel guided double gradient descent strategy. Evaluation on synthetic benchmark problems allows us to vary MOO problem difficulty in controlled fashion and measure accuracy \\vs known analytic solutions. We further test scalability and generalization in learning optimal neural model parameterizations for Multi-Task Learning (MTL) on image classification. Results show consistent improvement in  accuracy and efficiency over prior MTL methods as well as techniques from operations research.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/gupta22a/gupta22a.pdf",
        "supp": "",
        "pdf_size": 443188,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17751684618029669076&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "491904fcce",
        "title": "Learning binary multi-scale games on networks",
        "site": "https://proceedings.mlr.press/v180/yu22a.html",
        "author": "Sixie Yu; P. Jeffrey Brantingham; Matthew Valasik; Yevgeniy Vorobeychik",
        "abstract": "Network games are a natural modeling framework for strategic interactions of agents whose actions have local impact on others. Recently, a multi-scale network game model has been proposed to capture local effects at multiple network scales, such as among both individuals and groups. We propose a framework to learn the utility functions of binary multi-scale games from agents\u2019 behavioral data. Departing from much prior work in this area, we model agent behavior as following logit-response dynamics, rather than acting according to a Nash equilibrium. This defines a generative time-series model  of joint behavior of both agents and groups, which enables us to naturally cast the learning problem as maximum likelihood estimation (MLE). We show that in the important special case of multi-scale linear-quadratic games, this MLE problem is convex. Extensive experiments using both synthetic and real data demonstrate that our proposed modeling and learning approach is effective in both game parameter estimation as well as prediction of future behavior, even when we learn the game from only a single behavior time series. Furthermore, we show how to use our framework to develop a statistical test for the existence of multi-scale structure in the game, and use it to demonstrate that real time-series data indeed exhibits such structure.",
        "bibtex": "@InProceedings{pmlr-v180-yu22a,\n  title = \t {Learning binary multi-scale games on networks},\n  author =       {Yu, Sixie and Brantingham, P. Jeffrey and Valasik, Matthew and Vorobeychik, Yevgeniy},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2310--2319},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yu22a/yu22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yu22a.html},\n  abstract = \t {Network games are a natural modeling framework for strategic interactions of agents whose actions have local impact on others. Recently, a multi-scale network game model has been proposed to capture local effects at multiple network scales, such as among both individuals and groups. We propose a framework to learn the utility functions of binary multi-scale games from agents\u2019 behavioral data. Departing from much prior work in this area, we model agent behavior as following logit-response dynamics, rather than acting according to a Nash equilibrium. This defines a generative time-series model  of joint behavior of both agents and groups, which enables us to naturally cast the learning problem as maximum likelihood estimation (MLE). We show that in the important special case of multi-scale linear-quadratic games, this MLE problem is convex. Extensive experiments using both synthetic and real data demonstrate that our proposed modeling and learning approach is effective in both game parameter estimation as well as prediction of future behavior, even when we learn the game from only a single behavior time series. Furthermore, we show how to use our framework to develop a statistical test for the existence of multi-scale structure in the game, and use it to demonstrate that real time-series data indeed exhibits such structure.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yu22a/yu22a.pdf",
        "supp": "",
        "pdf_size": 374620,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16106719132730483419&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Washington University in St. Louis; University of California, Los Angeles; Louisiana State University; Washington University in St. Louis",
        "aff_domain": "wustl.edu;ucla.edu;lsu.edu;wustl.edu",
        "email": "wustl.edu;ucla.edu;lsu.edu;wustl.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Washington University in St. Louis;University of California, Los Angeles;Louisiana State University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://wustl.edu;https://www.ucla.edu;https://www.lsu.edu",
        "aff_unique_abbr": "WashU;UCLA;LSU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "St. Louis;Los Angeles;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fe052fa72c",
        "title": "Learning explainable templated graphical models",
        "site": "https://proceedings.mlr.press/v180/embar22a.html",
        "author": "Varun Embar; Sriram Srinivasa; Lise Getoor",
        "abstract": "Templated graphical models (TGMs) encode model structure using rules that capture recurring relationships between multiple random variables. While the rules in TGMs are interpretable, it is not clear how they can be used to generate explanations for the individual predictions of the model. Further, learning these rules from data comes with high computational costs: it typically requires an expensive combinatorial search over the space of rules and repeated optimization over rule weights. In this work, we propose a new structure learning algorithm, Explainable Structured Model Search (ESMS), that learns a templated graphical model and an explanation framework for its predictions. ESMS uses a novel search procedure to efficiently search the space of models and discover models that trade-off predictive accuracy and explainability. We introduce the notion of relational stability and prove that our proposed explanation framework is stable. Further, our proposed piecewise pseudolikelihood (PPLL) objective does not require re-optimizing the rule weights across models during each iteration of the search. In our empirical evaluation on three realworld datasets, we show that our proposed approach not only discovers models that are explainable, but also significantly outperforms existing state-out-the-art structure learning approaches.",
        "bibtex": "@InProceedings{pmlr-v180-embar22a,\n  title = \t {Learning explainable templated graphical models},\n  author =       {Embar, Varun and Srinivasa, Sriram and Getoor, Lise},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {621--630},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/embar22a/embar22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/embar22a.html},\n  abstract = \t {Templated graphical models (TGMs) encode model structure using rules that capture recurring relationships between multiple random variables. While the rules in TGMs are interpretable, it is not clear how they can be used to generate explanations for the individual predictions of the model. Further, learning these rules from data comes with high computational costs: it typically requires an expensive combinatorial search over the space of rules and repeated optimization over rule weights. In this work, we propose a new structure learning algorithm, Explainable Structured Model Search (ESMS), that learns a templated graphical model and an explanation framework for its predictions. ESMS uses a novel search procedure to efficiently search the space of models and discover models that trade-off predictive accuracy and explainability. We introduce the notion of relational stability and prove that our proposed explanation framework is stable. Further, our proposed piecewise pseudolikelihood (PPLL) objective does not require re-optimizing the rule weights across models during each iteration of the search. In our empirical evaluation on three realworld datasets, we show that our proposed approach not only discovers models that are explainable, but also significantly outperforms existing state-out-the-art structure learning approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/embar22a/embar22a.pdf",
        "supp": "",
        "pdf_size": 309208,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:HCJ7Fp1A3IMJ:scholar.google.com/&scioq=Learning+explainable+templated+graphical+models&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "aff": "Dept. of Computer Science and Engineering, University of California, Santa Cruz, USA; Dept. of Computer Science and Engineering, University of California, Santa Cruz, USA; Dept. of Computer Science and Engineering, University of California, Santa Cruz, USA",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Santa Cruz",
        "aff_unique_dep": "Dept. of Computer Science and Engineering",
        "aff_unique_url": "https://www.ucsc.edu",
        "aff_unique_abbr": "UCSC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Santa Cruz",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "42dbea66bc",
        "title": "Learning functions on multiple sets using multi-set transformers",
        "site": "https://proceedings.mlr.press/v180/selby22a.html",
        "author": "Kira A. Selby; Ahmad Rashid; Ivan Kobyzev; Mehdi Rezagholizadeh; Pascal Poupart",
        "abstract": "We propose a general deep architecture for learning functions on multiple permutation-invariant sets.  We also show how to generalize this architecture to sets of elements of any dimension by dimension equivariance. We demonstrate that our architecture is a universal approximator of these functions, and show superior results to existing methods on a variety of tasks including counting tasks, alignment tasks, distinguishability tasks and statistical distance measurements. This last task is quite important in Machine Learning.  Although our approach is quite general, we demonstrate that it can generate approximate estimates of KL divergence and mutual information that are more accurate than previous techniques that are specifically designed to approximate those statistical distances.",
        "bibtex": "@InProceedings{pmlr-v180-selby22a,\n  title = \t {Learning functions on multiple sets using multi-set transformers},\n  author =       {Selby, Kira A. and Rashid, Ahmad and Kobyzev, Ivan and Rezagholizadeh, Mehdi and Poupart, Pascal},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1760--1770},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/selby22a/selby22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/selby22a.html},\n  abstract = \t {We propose a general deep architecture for learning functions on multiple permutation-invariant sets.  We also show how to generalize this architecture to sets of elements of any dimension by dimension equivariance. We demonstrate that our architecture is a universal approximator of these functions, and show superior results to existing methods on a variety of tasks including counting tasks, alignment tasks, distinguishability tasks and statistical distance measurements. This last task is quite important in Machine Learning.  Although our approach is quite general, we demonstrate that it can generate approximate estimates of KL divergence and mutual information that are more accurate than previous techniques that are specifically designed to approximate those statistical distances.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/selby22a/selby22a.pdf",
        "supp": "",
        "pdf_size": 390400,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3536574617572946660&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada+Vector Institute, Toronto, Ontario, Canada; Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada+Vector Institute, Toronto, Ontario, Canada+Huawei Noah\u2019s Ark Lab, Montreal, Quebec, Canada; Huawei Noah\u2019s Ark Lab, Montreal, Quebec, Canada; Huawei Noah\u2019s Ark Lab, Montreal, Quebec, Canada; Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario, Canada+Vector Institute, Toronto, Ontario, Canada",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/krylea/partial-invariance",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1+2;2;2;0+1",
        "aff_unique_norm": "University of Waterloo;Vector Institute;Huawei",
        "aff_unique_dep": "Cheriton School of Computer Science;;Huawei Noah\u2019s Ark Lab",
        "aff_unique_url": "https://uwaterloo.ca;https://vectorinstitute.ai;https://www.huawei.com/en/ai/noahs-ark-lab",
        "aff_unique_abbr": "UW;Vector Institute;HNAL",
        "aff_campus_unique_index": "0+1;0+1+2;2;2;0+1",
        "aff_campus_unique": "Waterloo;Toronto;Montreal",
        "aff_country_unique_index": "0+0;0+0+0;0;0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "166d63dc4a",
        "title": "Learning in Markov games: Can we exploit a general-sum opponent?",
        "site": "https://proceedings.mlr.press/v180/ramponi22a.html",
        "author": "Giorgia Ramponi; Marcello Restelli",
        "abstract": "In this paper, we study the learning problem in two-player general-sum Markov Games. We consider the online setting where we control a single player, playing against an arbitrary opponent to minimize the regret. Previous works only consider the zero-sum Markov Games setting, in which the two agents are completely adversarial. However, in some cases, the two agents may have different reward functions without having conflicting objectives. This involves a stronger notion of regret than the one used in previous works. This class of games, called general-sum Markov Games is far to be well understood and studied. We show that the new regret minimization problem is significantly harder than in standard Markov Decision Processes and zero-sum Markov Games. To do this, we derive a lower bound on the expected regret of any \u201cgood\u201d learning strategy which shows the constant dependencies with the number of deterministic policies, which is not present in zerosum Markov Games and Markov Decision Processes. Then we propose a novel optimistic algorithm that nearly matches the proposed lower bound. Proving these results requires overcoming several new challenges that are not present in Markov Decision Processes or zero-sum Markov Games.",
        "bibtex": "@InProceedings{pmlr-v180-ramponi22a,\n  title = \t {Learning in Markov games: Can we exploit a general-sum opponent?},\n  author =       {Ramponi, Giorgia and Restelli, Marcello},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1665--1675},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ramponi22a/ramponi22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ramponi22a.html},\n  abstract = \t {In this paper, we study the learning problem in two-player general-sum Markov Games. We consider the online setting where we control a single player, playing against an arbitrary opponent to minimize the regret. Previous works only consider the zero-sum Markov Games setting, in which the two agents are completely adversarial. However, in some cases, the two agents may have different reward functions without having conflicting objectives. This involves a stronger notion of regret than the one used in previous works. This class of games, called general-sum Markov Games is far to be well understood and studied. We show that the new regret minimization problem is significantly harder than in standard Markov Decision Processes and zero-sum Markov Games. To do this, we derive a lower bound on the expected regret of any \u201cgood\u201d learning strategy which shows the constant dependencies with the number of deterministic policies, which is not present in zerosum Markov Games and Markov Decision Processes. Then we propose a novel optimistic algorithm that nearly matches the proposed lower bound. Proving these results requires overcoming several new challenges that are not present in Markov Decision Processes or zero-sum Markov Games.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/ramponi22a/ramponi22a.pdf",
        "supp": "",
        "pdf_size": 338895,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11820506300723853207&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Computer Science Department, ETH AI Center, Zurich, Switzerland; Computer Science Department, Politecnico di Milano, Milan, Italy",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "ETH Zurich;Politecnico di Milano",
        "aff_unique_dep": "Computer Science Department;Computer Science Department",
        "aff_unique_url": "https://www.ethz.ch;https://www.polimi.it",
        "aff_unique_abbr": "ETHZ;Politecnico di Milano",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Zurich;Milan",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Switzerland;Italy"
    },
    {
        "id": "60320012e1",
        "title": "Learning invariant weights in neural networks",
        "site": "https://proceedings.mlr.press/v180/ouderaa22a.html",
        "author": "Tycho F.A. van der Ouderaa; Mark van der Wilk",
        "abstract": "Assumptions about invariances or symmetries in data can significantly increase the predictive power of statistical models. Many commonly used machine learning models are constraint to respect certain symmetries, such as translation equivariance in convolutional neural networks, and incorporating other symmetry types is actively being studied. Yet, learning invariances from the data itself remains an open research problem. It has been shown that the marginal likelihood offers a principled way to learn invariances in Gaussian Processes. We propose a weight-space equivalent to this approach, by minimizing a lower bound on the marginal likelihood to learn invariances in neural networks, resulting in naturally higher performing models.",
        "bibtex": "@InProceedings{pmlr-v180-ouderaa22a,\n  title = \t {Learning invariant weights in neural networks},\n  author =       {van der Ouderaa, Tycho F.A. and van der Wilk, Mark},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1992--2001},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ouderaa22a/ouderaa22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ouderaa22a.html},\n  abstract = \t {Assumptions about invariances or symmetries in data can significantly increase the predictive power of statistical models. Many commonly used machine learning models are constraint to respect certain symmetries, such as translation equivariance in convolutional neural networks, and incorporating other symmetry types is actively being studied. Yet, learning invariances from the data itself remains an open research problem. It has been shown that the marginal likelihood offers a principled way to learn invariances in Gaussian Processes. We propose a weight-space equivalent to this approach, by minimizing a lower bound on the marginal likelihood to learn invariances in neural networks, resulting in naturally higher performing models.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/ouderaa22a/ouderaa22a.pdf",
        "supp": "",
        "pdf_size": 1281009,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17052493408300234492&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Imperial College London, UK; Imperial College London, UK",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "6387812c64",
        "title": "Learning large Bayesian networks with expert constraints",
        "site": "https://proceedings.mlr.press/v180/peruvemba-ramaswamy22a.html",
        "author": "Vaidyanathan Peruvemba Ramaswamy; Stefan Szeider",
        "abstract": "We propose a new score-based algorithm for learning the structure of a Bayesian Network (BN). It is the first algorithm that simultaneously supports the requirements of (i) learning a BN of bounded treewidth, (ii) satisfying expert constraints, including positive and negative ancestry properties between nodes, and (iii) scaling up to BNs with several thousand nodes. The algorithm operates in two phases. In Phase 1, we utilize a modified version of an existing BN structure learning algorithm, modified to generate an initial Directed Acyclic Graph (DAG) that supports a portion of the given constraints. In Phase 2, we follow the BN-SLIM framework, introduced by Peruvemba Ramaswamy and Szeider (AAAI 2021). We improve the initial DAG by repeatedly running a MaxSAT solver on selected local parts. The MaxSAT encoding entails local versions of the expert constraints as hard constraints. We evaluate a prototype implementation of our algorithm on several standard benchmark sets. The encouraging results demonstrate the power and flexibility of the BN-SLIM framework. It boosts the score while increasing the number of satisfied expert constraints.",
        "bibtex": "@InProceedings{pmlr-v180-peruvemba-ramaswamy22a,\n  title = \t {Learning large {Bayesian} networks with expert constraints},\n  author =       {Peruvemba Ramaswamy, Vaidyanathan and Szeider, Stefan},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1592--1601},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/peruvemba-ramaswamy22a/peruvemba-ramaswamy22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/peruvemba-ramaswamy22a.html},\n  abstract = \t {We propose a new score-based algorithm for learning the structure of a Bayesian Network (BN). It is the first algorithm that simultaneously supports the requirements of (i) learning a BN of bounded treewidth, (ii) satisfying expert constraints, including positive and negative ancestry properties between nodes, and (iii) scaling up to BNs with several thousand nodes. The algorithm operates in two phases. In Phase 1, we utilize a modified version of an existing BN structure learning algorithm, modified to generate an initial Directed Acyclic Graph (DAG) that supports a portion of the given constraints. In Phase 2, we follow the BN-SLIM framework, introduced by Peruvemba Ramaswamy and Szeider (AAAI 2021). We improve the initial DAG by repeatedly running a MaxSAT solver on selected local parts. The MaxSAT encoding entails local versions of the expert constraints as hard constraints. We evaluate a prototype implementation of our algorithm on several standard benchmark sets. The encouraging results demonstrate the power and flexibility of the BN-SLIM framework. It boosts the score while increasing the number of satisfied expert constraints.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/peruvemba-ramaswamy22a/peruvemba-ramaswamy22a.pdf",
        "supp": "",
        "pdf_size": 989676,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9540370253060368944&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Algorithms and Complexity Group, TU Wien, Vienna, Austria; Algorithms and Complexity Group, TU Wien, Vienna, Austria",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "TU Wien",
        "aff_unique_dep": "Algorithms and Complexity Group",
        "aff_unique_url": "https://www.tuwien.ac.at",
        "aff_unique_abbr": "TU Wien",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Vienna",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "85dfce20e0",
        "title": "Learning linear non-Gaussian polytree models",
        "site": "https://proceedings.mlr.press/v180/tramontano22a.html",
        "author": "Daniele Tramontano; Anthea Monod; Mathias Drton",
        "abstract": "In the context of graphical causal discovery, we adapt the versatile framework of linear non-Gaussian acyclic models (LiNGAMs) to propose new algorithms to efficiently learn graphs that are polytrees.  Our approach combines the Chow\u2013Liu algorithm, which first learns the undirected tree structure, with novel schemes to orient the edges.  The orientation schemes assess algebraic relations among moments of the data-generating distribution and are computationally inexpensive. We establish high-dimensional consistency results for our approach and compare different algorithmic versions in numerical experiments.",
        "bibtex": "@InProceedings{pmlr-v180-tramontano22a,\n  title = \t {Learning linear non-{G}aussian polytree models},\n  author =       {Tramontano, Daniele and Monod, Anthea and Drton, Mathias},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1960--1969},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/tramontano22a/tramontano22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/tramontano22a.html},\n  abstract = \t { In the context of graphical causal discovery, we adapt the versatile framework of linear non-Gaussian acyclic models (LiNGAMs) to propose new algorithms to efficiently learn graphs that are polytrees.  Our approach combines the Chow\u2013Liu algorithm, which first learns the undirected tree structure, with novel schemes to orient the edges.  The orientation schemes assess algebraic relations among moments of the data-generating distribution and are computationally inexpensive. We establish high-dimensional consistency results for our approach and compare different algorithmic versions in numerical experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/tramontano22a/tramontano22a.pdf",
        "supp": "",
        "pdf_size": 865946,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4863644256956260856&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Mathematics and Munich Data Science Institute, Technical University of Munich, Germany; Department of Mathematics, Imperial College London, UK; Department of Mathematics and Munich Data Science Institute, Technical University of Munich, Germany",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Technical University of Munich;Imperial College London",
        "aff_unique_dep": "Department of Mathematics;Department of Mathematics",
        "aff_unique_url": "https://www.tum.de;https://www.imperial.ac.uk",
        "aff_unique_abbr": "TUM;Imperial",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Munich;London",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "1e22d03408",
        "title": "Learning soft interventions in complex equilibrium systems",
        "site": "https://proceedings.mlr.press/v180/besserve22a.html",
        "author": "Michel Besserve; Bernhard Sch\u00f6lkopf",
        "abstract": "Complex systems often contain feedback loops that can be described as cyclic causal models. Intervening in such systems may lead to counterintuitive effects, which cannot be inferred directly from the graph structure. After establishing a framework for differentiable soft interventions based on Lie groups, we take advantage of modern automatic differentiation techniques and their application to implicit functions in order to optimize interventions in cyclic causal models. We illustrate the use of this framework by investigating scenarios of transition to sustainable economies.",
        "bibtex": "@InProceedings{pmlr-v180-besserve22a,\n  title = \t {Learning soft interventions in complex equilibrium systems},\n  author =       {Besserve, Michel and Sch{\\\"o}lkopf, Bernhard},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {170--180},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/besserve22a/besserve22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/besserve22a.html},\n  abstract = \t {Complex systems often contain feedback loops that can be described as cyclic causal models. Intervening in such systems may lead to counterintuitive effects, which cannot be inferred directly from the graph structure. After establishing a framework for differentiable soft interventions based on Lie groups, we take advantage of modern automatic differentiation techniques and their application to implicit functions in order to optimize interventions in cyclic causal models. We illustrate the use of this framework by investigating scenarios of transition to sustainable economies.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/besserve22a/besserve22a.pdf",
        "supp": "",
        "pdf_size": 890306,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8559540078669651097&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Empirical Inference, Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Department of Empirical Inference, Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/mbesserve/lie-inter",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Department of Empirical Inference",
        "aff_unique_url": "https://www.mpituebingen.mpg.de",
        "aff_unique_abbr": "MPI-IS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "e29588968d",
        "title": "Learning sparse representations of preferences within Choquet expected utility theory",
        "site": "https://proceedings.mlr.press/v180/herin22a.html",
        "author": "Margot Herin; Patrice Perny; Nataliya Sokolovska",
        "abstract": "This paper deals with preference elicitation within Choquet Expected Utility (CEU) theory for decision making under uncertainty. We consider the Savage\u2019s framework with a finite set of states and assume that preferences of the Decision Maker over acts are observable. The CEU model involves two parameters that must be tuned to the value system of the decision maker: a set function (capacity) modeling weights attached to events, of size exponential in the number of states, and a utility function defined on the space of outcomes.  Our aim is to learn a sparse representation of the CEU model from preference data.  We propose and test a preference learning approach based on a spline representation of utilities and the sparse learning of capacities to obtain CEU models achieving a good tradeoff between the aim of sparsity and the expressivity required by preference data.",
        "bibtex": "@InProceedings{pmlr-v180-herin22a,\n  title = \t {Learning sparse representations of preferences within {C}hoquet expected utility theory},\n  author =       {Herin, Margot and Perny, Patrice and Sokolovska, Nataliya},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {800--810},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/herin22a/herin22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/herin22a.html},\n  abstract = \t {This paper deals with preference elicitation within Choquet Expected Utility (CEU) theory for decision making under uncertainty. We consider the Savage\u2019s framework with a finite set of states and assume that preferences of the Decision Maker over acts are observable. The CEU model involves two parameters that must be tuned to the value system of the decision maker: a set function (capacity) modeling weights attached to events, of size exponential in the number of states, and a utility function defined on the space of outcomes.  Our aim is to learn a sparse representation of the CEU model from preference data.  We propose and test a preference learning approach based on a spline representation of utilities and the sparse learning of capacities to obtain CEU models achieving a good tradeoff between the aim of sparsity and the expressivity required by preference data.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/herin22a/herin22a.pdf",
        "supp": "",
        "pdf_size": 497302,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7272980678057312430&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0d434e48a7",
        "title": "Lifting in multi-agent systems under uncertainty",
        "site": "https://proceedings.mlr.press/v180/braun22a.html",
        "author": "Tanya Braun; Marcel Gehrke; Florian Lau; Ralf M\u00f6ller",
        "abstract": "A decentralised partially observable Markov decision problem (DecPOMDP) formalises collaborative multi-agent decision making. A solution to a DecPOMDP is a joint policy for the agents, fulfilling an optimality criterion such as maximum expected utility. A crux is that the problem is intractable regarding the number of agents. Inspired by lifted inference, this paper examines symmetries within the agent set for a potential tractability. Specifically, this paper contributes (i) specifications of counting and isomorphic symmetries, (ii) a compact encoding of symmetric DecPOMDPs as partitioned DecPOMDPs, and (iii) a formal analysis of complexity and tractability. This works allows tractability in terms of agent numbers and a new query type for isomorphic DecPOMDPs.",
        "bibtex": "@InProceedings{pmlr-v180-braun22a,\n  title = \t {Lifting in multi-agent systems under uncertainty},\n  author =       {Braun, Tanya and Gehrke, Marcel and Lau, Florian and M\\\"oller, Ralf},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {233--243},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/braun22a/braun22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/braun22a.html},\n  abstract = \t { A decentralised partially observable Markov decision problem (DecPOMDP) formalises collaborative multi-agent decision making. A solution to a DecPOMDP is a joint policy for the agents, fulfilling an optimality criterion such as maximum expected utility. A crux is that the problem is intractable regarding the number of agents. Inspired by lifted inference, this paper examines symmetries within the agent set for a potential tractability. Specifically, this paper contributes (i) specifications of counting and isomorphic symmetries, (ii) a compact encoding of symmetric DecPOMDPs as partitioned DecPOMDPs, and (iii) a formal analysis of complexity and tractability. This works allows tractability in terms of agent numbers and a new query type for isomorphic DecPOMDPs. }\n}",
        "pdf": "https://proceedings.mlr.press/v180/braun22a/braun22a.pdf",
        "supp": "",
        "pdf_size": 319380,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6843419763646463567&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "861c76d2fe",
        "title": "Linearizing contextual bandits with latent state dynamics",
        "site": "https://proceedings.mlr.press/v180/nelson22a.html",
        "author": "Elliot Nelson; Debarun Bhattacharjya; Tian Gao; Miao Liu; Djallel Bouneffouf; Pascal Poupart",
        "abstract": "In many real-world applications of multi-armed bandit problems, both rewards and contexts are often influenced by confounding latent variables which evolve stochastically over time. While the observed contexts and rewards are nonlinearly related, we show that prior knowledge of latent causal structure can be used to reduce the problem to the linear bandit setting. We develop two algorithms, Latent Linear Thompson Sampling (L2TS) and Latent Linear UCB (L2UCB), which use online EM algorithms for hidden Markov models to learn the latent transition model and maintain a posterior belief over the latent state, and then use the resulting posteriors as context features in a linear bandit problem. We upper bound the error in reward estimation in the presence of a dynamical latent state, and derive a novel problem-dependent regret bound for linear Thompson sampling with non-stationarity and unconstrained reward distributions, which we apply to L2TS under certain conditions. Finally, we demonstrate the superiority of our algorithms over related bandit algorithms through experiments.",
        "bibtex": "@InProceedings{pmlr-v180-nelson22a,\n  title = \t {Linearizing contextual bandits with latent state dynamics},\n  author =       {Nelson, Elliot and Bhattacharjya, Debarun and Gao, Tian and Liu, Miao and Bouneffouf, Djallel and Poupart, Pascal},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1477--1487},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/nelson22a/nelson22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/nelson22a.html},\n  abstract = \t {In many real-world applications of multi-armed bandit problems, both rewards and contexts are often influenced by confounding latent variables which evolve stochastically over time. While the observed contexts and rewards are nonlinearly related, we show that prior knowledge of latent causal structure can be used to reduce the problem to the linear bandit setting. We develop two algorithms, Latent Linear Thompson Sampling (L2TS) and Latent Linear UCB (L2UCB), which use online EM algorithms for hidden Markov models to learn the latent transition model and maintain a posterior belief over the latent state, and then use the resulting posteriors as context features in a linear bandit problem. We upper bound the error in reward estimation in the presence of a dynamical latent state, and derive a novel problem-dependent regret bound for linear Thompson sampling with non-stationarity and unconstrained reward distributions, which we apply to L2TS under certain conditions. Finally, we demonstrate the superiority of our algorithms over related bandit algorithms through experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/nelson22a/nelson22a.pdf",
        "supp": "",
        "pdf_size": 579273,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7270469670699717782&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; IBM T. J. Watson Research Center, Yorktown Heights, NY, USA; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "IBM;University of Waterloo",
        "aff_unique_dep": "IBM T. J. Watson Research Center;David R. Cheriton School of Computer Science",
        "aff_unique_url": "https://www.ibm.com/research/watson;https://uwaterloo.ca",
        "aff_unique_abbr": "IBM Watson;UWaterloo",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Yorktown Heights;Waterloo",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "632b5a60a0",
        "title": "Local calibration: metrics and recalibration",
        "site": "https://proceedings.mlr.press/v180/luo22a.html",
        "author": "Rachel Luo; Aadyot Bhatnagar; Yu Bai; Shengjia Zhao; Huan Wang; Caiming Xiong; Silvio Savarese; Stefano Ermon; Edward Schmerling; Marco Pavone",
        "abstract": "Probabilistic classifiers output confidence scores along with their predictions, and these confidence scores should be calibrated, i.e., they should reflect the reliability of the prediction. Confidence scores that minimize standard metrics such as the expected calibration error (ECE) accurately measure the reliability \\textit{on average} across the entire population. However, it is in general impossible to measure the reliability of an \\textit{individual} prediction. In this work, we propose the local calibration error (LCE) to span the gap between average and individual reliability. For each individual prediction, the LCE measures the average reliability of a set of similar predictions, where similarity is quantified by a kernel function on a pretrained feature space and by a binning scheme over predicted model confidences. We show theoretically that the LCE can be estimated sample-efficiently from data, and empirically find that it reveals miscalibration modes that are more fine-grained than the ECE can detect. Our key result is a novel {\\textbf{lo}cal \\textbf{re}calibration} method \\method{}, to improve confidence scores for individual predictions and decrease the LCE. Experimentally, we show that our recalibration method produces more accurate confidence scores, which improves downstream fairness and decision making on classification tasks with both image and tabular data.",
        "bibtex": "@InProceedings{pmlr-v180-luo22a,\n  title = \t {Local calibration: metrics and recalibration},\n  author =       {Luo, Rachel and Bhatnagar, Aadyot and Bai, Yu and Zhao, Shengjia and Wang, Huan and Xiong, Caiming and Savarese, Silvio and Ermon, Stefano and Schmerling, Edward and Pavone, Marco},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1286--1295},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/luo22a/luo22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/luo22a.html},\n  abstract = \t {Probabilistic classifiers output confidence scores along with their predictions, and these confidence scores should be calibrated, i.e., they should reflect the reliability of the prediction. Confidence scores that minimize standard metrics such as the expected calibration error (ECE) accurately measure the reliability \\textit{on average} across the entire population. However, it is in general impossible to measure the reliability of an \\textit{individual} prediction. In this work, we propose the local calibration error (LCE) to span the gap between average and individual reliability. For each individual prediction, the LCE measures the average reliability of a set of similar predictions, where similarity is quantified by a kernel function on a pretrained feature space and by a binning scheme over predicted model confidences. We show theoretically that the LCE can be estimated sample-efficiently from data, and empirically find that it reveals miscalibration modes that are more fine-grained than the ECE can detect. Our key result is a novel {\\textbf{lo}cal \\textbf{re}calibration} method \\method{}, to improve confidence scores for individual predictions and decrease the LCE. Experimentally, we show that our recalibration method produces more accurate confidence scores, which improves downstream fairness and decision making on classification tasks with both image and tabular data.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/luo22a/luo22a.pdf",
        "supp": "",
        "pdf_size": 679462,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17343114239658011497&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;;;;;",
        "aff_domain": ";;;;;;;;;",
        "email": ";;;;;;;;;",
        "github": "",
        "project": "",
        "author_num": 10,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7c62b12050",
        "title": "Low-precision arithmetic for fast Gaussian processes",
        "site": "https://proceedings.mlr.press/v180/maddox22a.html",
        "author": "Wesley J. Maddox; Andres Potapcynski; Andrew Gordon Wilson",
        "abstract": "Low precision arithmetic has had a transformative effect on the training of neural networks, reducing computation, memory and energy requirements. However, despite their promise, low precision operations have received little attention for Gaussian process (GP) training, largely because GPs require sophisticated linear algebra routines that are unstable in low precision. We study the different failure modes that can occur when training GPs in half-precision. To circumvent these failure modes, we propose a multi-faceted approach involving conjugate gradients with re-orthogonalization, mixed precision, compact kernels, and preconditioners. Our approach significantly improves the numerical stability and practical performance of conjugate gradients in low precision over a wide range of settings, and reduces the runtime of 1.8 million data points to 10 hours on a single GPU, without requiring any sparse approximations.",
        "bibtex": "@InProceedings{pmlr-v180-maddox22a,\n  title = \t {Low-precision arithmetic for fast Gaussian processes},\n  author =       {Maddox, Wesley J. and Potapcynski, Andres and Wilson, Andrew Gordon},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1306--1316},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/maddox22a/maddox22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/maddox22a.html},\n  abstract = \t {Low precision arithmetic has had a transformative effect on the training of neural networks, reducing computation, memory and energy requirements. However, despite their promise, low precision operations have received little attention for Gaussian process (GP) training, largely because GPs require sophisticated linear algebra routines that are unstable in low precision. We study the different failure modes that can occur when training GPs in half-precision. To circumvent these failure modes, we propose a multi-faceted approach involving conjugate gradients with re-orthogonalization, mixed precision, compact kernels, and preconditioners. Our approach significantly improves the numerical stability and practical performance of conjugate gradients in low precision over a wide range of settings, and reduces the runtime of 1.8 million data points to 10 hours on a single GPU, without requiring any sparse approximations.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/maddox22a/maddox22a.pdf",
        "supp": "",
        "pdf_size": 452394,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15551161953416051801&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Center for Data Science, New York University; Center for Data Science, New York University; Center for Data Science, New York University",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "Center for Data Science",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "06e9e5a5eb",
        "title": "Marginal MAP estimation for inverse RL under occlusion with observer noise",
        "site": "https://proceedings.mlr.press/v180/suresh22a.html",
        "author": "Prasanth Sengadu Suresh; Prashant Doshi",
        "abstract": "We consider the problem of learning the behavioral preferences of an expert engaged in a task from noisy and partially-observable demonstrations. This is motivated by real-world applications such as a line robot learning from observing a human worker, where some observations are occluded by environmental elements. Furthermore, robotic perception tends to be imperfect and noisy. Previous techniques for inverse reinforcement learning (IRL) take the approach of either omitting the missing portions or inferring it as part of expectation-maximization, which tends to be slow and prone to local optima. We present a new method that generalizes the well-known Bayesian maximum-a-posteriori (MAP) IRL method by marginalizing the occluded portions of the trajectory. This is then extended with an observation model to account for perception noise. This novel application of marginal MAP (MMAP) to IRL significantly improves on the previous IRL technique under occlusion in both formative evaluations on a toy problem and in a summative evaluation on a produce sorting line task by a physical robot.",
        "bibtex": "@InProceedings{pmlr-v180-suresh22a,\n  title = \t {Marginal {MAP} estimation for inverse {RL} under occlusion with observer noise},\n  author =       {Suresh, Prasanth Sengadu and Doshi, Prashant},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1907--1916},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/suresh22a/suresh22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/suresh22a.html},\n  abstract = \t {We consider the problem of learning the behavioral preferences of an expert engaged in a task from noisy and partially-observable demonstrations. This is motivated by real-world applications such as a line robot learning from observing a human worker, where some observations are occluded by environmental elements. Furthermore, robotic perception tends to be imperfect and noisy. Previous techniques for inverse reinforcement learning (IRL) take the approach of either omitting the missing portions or inferring it as part of expectation-maximization, which tends to be slow and prone to local optima. We present a new method that generalizes the well-known Bayesian maximum-a-posteriori (MAP) IRL method by marginalizing the occluded portions of the trajectory. This is then extended with an observation model to account for perception noise. This novel application of marginal MAP (MMAP) to IRL significantly improves on the previous IRL technique under occlusion in both formative evaluations on a toy problem and in a summative evaluation on a produce sorting line task by a physical robot.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/suresh22a/suresh22a.pdf",
        "supp": "",
        "pdf_size": 1912223,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5172356797305679100&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "THINC Lab, Department of Computer Science, University of Georgia, Athens, GA 30606, USA; THINC Lab, Department of Computer Science, University of Georgia, Athens, GA 30606, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Georgia",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uga.edu",
        "aff_unique_abbr": "UGA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Athens",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6519f59a20",
        "title": "Meta-learning without data via Wasserstein distributionally-robust model fusion",
        "site": "https://proceedings.mlr.press/v180/wang22a.html",
        "author": "Zhenyi Wang; Xiaoyang Wang; Li Shen; Qiuling Suo; Kaiqiang Song; Dong Yu; Yan Shen; Mingchen Gao",
        "abstract": "Existing meta-learning works assume that each task has available training and testing data. However, there are many available pre-trained models without accessing their training data in practice. We often need a single model to solve different tasks simultaneously as this is much more convenient to deploy the models.  Our work aims to meta-learn a model initialization from these pre-trained models without using corresponding training data. We name this challenging problem setting as Data-Free Learning To Learn (DFL2L). We propose a distributionally robust optimization (DRO) framework to learn a black-box model to fuse and compress all the pre-trained models into a single network to address this problem. To encourage good generalization to the unseen new tasks, the proposed DRO framework diversifies the learned task embedding associated with each pre-trained model to cover the diversity in the underlying training task distributions. A model initialization is sampled from the black-box network during meta-testing as the meta learned initialization. Extensive experiments on offline and online DFL2L settings and several real image datasets demonstrate the effectiveness of the proposed methods.",
        "bibtex": "@InProceedings{pmlr-v180-wang22a,\n  title = \t {Meta-learning without data via Wasserstein distributionally-robust model fusion},\n  author =       {Wang, Zhenyi and Wang, Xiaoyang and Shen, Li and Suo, Qiuling and Song, Kaiqiang and Yu, Dong and Shen, Yan and Gao, Mingchen},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2045--2055},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/wang22a/wang22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/wang22a.html},\n  abstract = \t {Existing meta-learning works assume that each task has available training and testing data. However, there are many available pre-trained models without accessing their training data in practice. We often need a single model to solve different tasks simultaneously as this is much more convenient to deploy the models.  Our work aims to meta-learn a model initialization from these pre-trained models without using corresponding training data. We name this challenging problem setting as Data-Free Learning To Learn (DFL2L). We propose a distributionally robust optimization (DRO) framework to learn a black-box model to fuse and compress all the pre-trained models into a single network to address this problem. To encourage good generalization to the unseen new tasks, the proposed DRO framework diversifies the learned task embedding associated with each pre-trained model to cover the diversity in the underlying training task distributions. A model initialization is sampled from the black-box network during meta-testing as the meta learned initialization. Extensive experiments on offline and online DFL2L settings and several real image datasets demonstrate the effectiveness of the proposed methods. }\n}",
        "pdf": "https://proceedings.mlr.press/v180/wang22a/wang22a.pdf",
        "supp": "",
        "pdf_size": 599650,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=492336180945534894&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fe23f94af1",
        "title": "Mitigating statistical bias within differentially private synthetic data",
        "site": "https://proceedings.mlr.press/v180/ghalebikesabi22a.html",
        "author": "Sahra Ghalebikesabi; Harry Wilde; Jack Jewson; Arnaud Doucet; Sebastian Vollmer; Chris Holmes",
        "abstract": "Increasing interest in privacy-preserving machine learning has led to new and evolved approaches for generating private synthetic data from undisclosed real data. However, mechanisms of privacy preservation can significantly reduce the utility of synthetic data, which in turn impacts downstream tasks such as learning predictive models or inference. We propose several re-weighting strategies using privatised likelihood ratios that not only mitigate statistical bias of downstream estimators but also have general applicability to differentially private generative models. Through large-scale empirical evaluation, we show that private importance weighting provides simple and effective privacy-compliant augmentation for general applications of synthetic data.",
        "bibtex": "@InProceedings{pmlr-v180-ghalebikesabi22a,\n  title = \t {Mitigating statistical bias within differentially private synthetic data},\n  author =       {Ghalebikesabi, Sahra and Wilde, Harry and Jewson, Jack and Doucet, Arnaud and Vollmer, Sebastian and Holmes, Chris},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {696--705},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ghalebikesabi22a/ghalebikesabi22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ghalebikesabi22a.html},\n  abstract = \t {Increasing interest in privacy-preserving machine learning has led to new and evolved approaches for generating private synthetic data from undisclosed real data. However, mechanisms of privacy preservation can significantly reduce the utility of synthetic data, which in turn impacts downstream tasks such as learning predictive models or inference. We propose several re-weighting strategies using privatised likelihood ratios that not only mitigate statistical bias of downstream estimators but also have general applicability to differentially private generative models. Through large-scale empirical evaluation, we show that private importance weighting provides simple and effective privacy-compliant augmentation for general applications of synthetic data.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/ghalebikesabi22a/ghalebikesabi22a.pdf",
        "supp": "",
        "pdf_size": 878925,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13877902667596542921&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "University of Oxford; University of Warwick; Universitat Pompeu Fabra; University of Oxford; University of Kaiserslautern, German Research Centre for Artificial Intelligence (DFKI); University of Oxford",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0;3;0",
        "aff_unique_norm": "University of Oxford;University of Warwick;Universitat Pompeu Fabra;University of Kaiserslautern",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.warwick.ac.uk;https://www.upf.edu/;https://www.uni-kl.de",
        "aff_unique_abbr": "Oxford;Warwick;UPF;Uni KL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;2;0",
        "aff_country_unique": "United Kingdom;Spain;Germany"
    },
    {
        "id": "5495e6fc78",
        "title": "Modeling extremes with $d$-max-decreasing neural networks",
        "site": "https://proceedings.mlr.press/v180/hasan22a.html",
        "author": "Ali Hasan; Khalil Elkhalil; Yuting Ng; Jo\u00e3o M. Pereira; Sina Farsiu; Jose Blanchet; Vahid Tarokh",
        "abstract": "We propose a neural network architecture that enables non-parametric calibration and generation of multivariate extreme value distributions (MEVs).  MEVs arise from Extreme Value Theory (EVT) as the necessary class of models when extrapolating a distributional fit over large spatial and temporal scales based on data observed in intermediate scales.  In turn, EVT dictates that $d$-max-decreasing, a stronger form of convexity, is an essential shape constraint in the characterization of MEVs.  As far as we know, our proposed architecture provides the first class of non-parametric estimators for MEVs that preserve these essential shape constraints.  We show that the architecture approximates the dependence structure encoded by MEVs at parametric rate.  Moreover, we present a new method for sampling high-dimensional MEVs using a generative model.  We demonstrate our methodology on a wide range of experimental settings, ranging from environmental sciences to financial mathematics and verify that the structural properties of MEVs are retained compared to existing methods.",
        "bibtex": "@InProceedings{pmlr-v180-hasan22a,\n  title = \t {Modeling extremes with $d$-max-decreasing neural networks},\n  author =       {Hasan, Ali and Elkhalil, Khalil and Ng, Yuting and Pereira, Jo\\~ao M. and Farsiu, Sina and Blanchet, Jose and Tarokh, Vahid},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {759--768},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/hasan22a/hasan22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/hasan22a.html},\n  abstract = \t {We propose a neural network architecture that enables non-parametric calibration and generation of multivariate extreme value distributions (MEVs).  MEVs arise from Extreme Value Theory (EVT) as the necessary class of models when extrapolating a distributional fit over large spatial and temporal scales based on data observed in intermediate scales.  In turn, EVT dictates that $d$-max-decreasing, a stronger form of convexity, is an essential shape constraint in the characterization of MEVs.  As far as we know, our proposed architecture provides the first class of non-parametric estimators for MEVs that preserve these essential shape constraints.  We show that the architecture approximates the dependence structure encoded by MEVs at parametric rate.  Moreover, we present a new method for sampling high-dimensional MEVs using a generative model.  We demonstrate our methodology on a wide range of experimental settings, ranging from environmental sciences to financial mathematics and verify that the structural properties of MEVs are retained compared to existing methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/hasan22a/hasan22a.pdf",
        "supp": "",
        "pdf_size": 1077988,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=756590993617880583&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "dd456c8a92",
        "title": "Monotonicity regularization: Improved penalties and novel applications to disentangled representation learning and robust classification",
        "site": "https://proceedings.mlr.press/v180/monteiro22a.html",
        "author": "Jo\u00e3o Monteiro; Mohamed Osama Ahmed; Hoseein Hajimirsadeghi; Greg Mori",
        "abstract": "We study settings where gradient penalties are used alongside risk minimization with the goal of obtaining predictors satisfying different notions of monotonicity. Specifically, we present two sets of contributions. In the first part of the paper, we show that different choices of penalties define the regions of the input space where the property is observed. As such, previous methods result in models that are monotonic only in a small volume of the input space. We thus propose an approach that uses mixtures of training instances and random points to populate the space and enforce the penalty in a much larger region. As a second set of contributions, we introduce regularization strategies that enforce other notions of monotonicity in different settings. In this case, we consider applications, such as image classification and generative modeling, where monotonicity is not a hard constraint but can help improve some aspects of the model. Namely, we show that inducing monotonicity can be beneficial in applications such as: (1) allowing for controllable data generation, (2) defining strategies to detect anomalous data, and (3) generating explanations for predictions. Our proposed approaches do not introduce relevant computational overhead while leading to efficient procedures that provide extra benefits over baseline models.",
        "bibtex": "@InProceedings{pmlr-v180-monteiro22a,\n  title = \t {Monotonicity regularization: Improved penalties and novel applications to disentangled representation learning and robust classification},\n  author =       {Monteiro, Jo\\~ao and Ahmed, Mohamed Osama and Hajimirsadeghi, Hoseein and Mori, Greg},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1381--1391},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/monteiro22a/monteiro22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/monteiro22a.html},\n  abstract = \t {We study settings where gradient penalties are used alongside risk minimization with the goal of obtaining predictors satisfying different notions of monotonicity. Specifically, we present two sets of contributions. In the first part of the paper, we show that different choices of penalties define the regions of the input space where the property is observed. As such, previous methods result in models that are monotonic only in a small volume of the input space. We thus propose an approach that uses mixtures of training instances and random points to populate the space and enforce the penalty in a much larger region. As a second set of contributions, we introduce regularization strategies that enforce other notions of monotonicity in different settings. In this case, we consider applications, such as image classification and generative modeling, where monotonicity is not a hard constraint but can help improve some aspects of the model. Namely, we show that inducing monotonicity can be beneficial in applications such as: (1) allowing for controllable data generation, (2) defining strategies to detect anomalous data, and (3) generating explanations for predictions. Our proposed approaches do not introduce relevant computational overhead while leading to efficient procedures that provide extra benefits over baseline models.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/monteiro22a/monteiro22a.pdf",
        "supp": "",
        "pdf_size": 1036896,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7379813541857313933&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Borealis AI; Borealis AI; Borealis AI; Borealis AI+Simon Fraser University",
        "aff_domain": "borealisai.com;borealisai.com;borealisai.com;borealisai.com+greg.mori",
        "email": "borealisai.com;borealisai.com;borealisai.com;borealisai.com+greg.mori",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0+1",
        "aff_unique_norm": "Borealis AI;Simon Fraser University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.borealisai.com;https://www.sfu.ca",
        "aff_unique_abbr": "Borealis AI;SFU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "34c0191db9",
        "title": "Multi-objective Bayesian optimization over high-dimensional search spaces",
        "site": "https://proceedings.mlr.press/v180/daulton22a.html",
        "author": "Samuel Daulton; David Eriksson; Maximilian Balandat; Eytan Bakshy",
        "abstract": "Many real world scientific and industrial applications require optimizing multiple competing black-box objectives. When the objectives are expensive-to-evaluate, multi-objective Bayesian optimization (BO) is a popular approach because of its high sample efficiency. However, even with recent methodological advances, most existing multi-objective BO methods perform poorly on search spaces with more than a few dozen parameters and rely on global surrogate models that scale cubically with the number of observations. In this work we propose MORBO, a scalable method for multi-objective BO over high-dimensional search spaces. MORBO identifies diverse globally optimal solutions by performing BO in multiple local regions of the design space in parallel using a coordinated strategy. We show that MORBO significantly advances the state-of-the-art in sample efficiency for several high-dimensional synthetic problems and real world applications, including an optical display design problem and a vehicle design problem with 146 and 222 parameters, respectively. On these problems, where existing BO algorithms fail to scale and perform well, MORBO provides practitioners with order-of-magnitude improvements in sample efficiency over the current approach.",
        "bibtex": "@InProceedings{pmlr-v180-daulton22a,\n  title = \t {Multi-objective Bayesian optimization over high-dimensional search spaces},\n  author =       {Daulton, Samuel and Eriksson, David and Balandat, Maximilian and Bakshy, Eytan},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {507--517},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/daulton22a/daulton22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/daulton22a.html},\n  abstract = \t {Many real world scientific and industrial applications require optimizing multiple competing black-box objectives. When the objectives are expensive-to-evaluate, multi-objective Bayesian optimization (BO) is a popular approach because of its high sample efficiency. However, even with recent methodological advances, most existing multi-objective BO methods perform poorly on search spaces with more than a few dozen parameters and rely on global surrogate models that scale cubically with the number of observations. In this work we propose MORBO, a scalable method for multi-objective BO over high-dimensional search spaces. MORBO identifies diverse globally optimal solutions by performing BO in multiple local regions of the design space in parallel using a coordinated strategy. We show that MORBO significantly advances the state-of-the-art in sample efficiency for several high-dimensional synthetic problems and real world applications, including an optical display design problem and a vehicle design problem with 146 and 222 parameters, respectively. On these problems, where existing BO algorithms fail to scale and perform well, MORBO provides practitioners with order-of-magnitude improvements in sample efficiency over the current approach.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/daulton22a/daulton22a.pdf",
        "supp": "",
        "pdf_size": 532464,
        "gs_citation": 141,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5724070517088849972&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of Oxford+Meta; Meta; Meta; Meta",
        "aff_domain": "ox.ac.uk;meta.com;meta.com;meta.com",
        "email": "ox.ac.uk;meta.com;meta.com;meta.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1;1;1",
        "aff_unique_norm": "University of Oxford;Meta",
        "aff_unique_dep": ";Meta Platforms, Inc.",
        "aff_unique_url": "https://www.ox.ac.uk;https://meta.com",
        "aff_unique_abbr": "Oxford;Meta",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+1;1;1;1",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "50d1346839",
        "title": "Multi-source domain adaptation via weighted joint distributions optimal transport",
        "site": "https://proceedings.mlr.press/v180/turrisi22a.html",
        "author": "Rosanna Turrisi; R\u00e9mi Flamary; Alain Rakotomamonjy; Massimiliano Pontil",
        "abstract": "This work addresses the problem of domain adaptation on an unlabeled target dataset using knowledge from multiple labelled source datasets. Most current approaches tackle this problem by searching for an embedding that is invariant across source and target domains, which corresponds to searching for a universal classifier that works well on all domains. In this paper, we address this problem from a new perspective: instead of crushing diversity of the source distributions, we exploit it to adapt better to the target distribution. Our method, named Multi-Source Domain Adaptation via Weighted Joint Distribution Optimal Transport (MSDA-WJDOT), aims at finding simultaneously an Optimal Transport-based alignment between the source and target distributions and a re-weighting of the sources distributions. We discuss the theoret- ical aspects of the method and propose a conceptually simple algorithm. Numerical experiments indicate that the proposed method achieves state-of- the-art performance on simulated and real datasets.",
        "bibtex": "@InProceedings{pmlr-v180-turrisi22a,\n  title = \t {Multi-source domain adaptation via weighted joint distributions optimal transport},\n  author =       {Turrisi, Rosanna and Flamary, R\\'emi and Rakotomamonjy, Alain and Pontil, Massimiliano},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1970--1980},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/turrisi22a/turrisi22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/turrisi22a.html},\n  abstract = \t {This work addresses the problem of domain adaptation on an unlabeled target dataset using knowledge from multiple labelled source datasets. Most current approaches tackle this problem by searching for an embedding that is invariant across source and target domains, which corresponds to searching for a universal classifier that works well on all domains. In this paper, we address this problem from a new perspective: instead of crushing diversity of the source distributions, we exploit it to adapt better to the target distribution. Our method, named Multi-Source Domain Adaptation via Weighted Joint Distribution Optimal Transport (MSDA-WJDOT), aims at finding simultaneously an Optimal Transport-based alignment between the source and target distributions and a re-weighting of the sources distributions. We discuss the theoret- ical aspects of the method and propose a conceptually simple algorithm. Numerical experiments indicate that the proposed method achieves state-of- the-art performance on simulated and real datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/turrisi22a/turrisi22a.pdf",
        "supp": "",
        "pdf_size": 3578843,
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9971338660820197627&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "63b1f83abb",
        "title": "Multi-winner approval voting goes epistemic",
        "site": "https://proceedings.mlr.press/v180/allouche22a.html",
        "author": "Tahar Allouche; J\u00e9r\u00f4me Lang; Florian Yger",
        "abstract": "Epistemic voting interprets votes as noisy signals about a ground truth. We consider contexts where the truth consists of a set of objective winners, knowing a lower and upper bound on its cardinality. A prototypical problem for this setting is the aggregation of multi-label annotations with prior knowledge on the size of the ground truth. We posit noise models, for which we define rules that output an optimal set of winners. We report on experiments on multi-label annotations (which we collected).",
        "bibtex": "@InProceedings{pmlr-v180-allouche22a,\n  title = \t {Multi-winner approval voting goes epistemic},\n  author =       {Allouche, Tahar and Lang, J{\\'e}r{\\^o}me and Yger, Florian},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {75--84},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/allouche22a/allouche22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/allouche22a.html},\n  abstract = \t {Epistemic voting interprets votes as noisy signals about a ground truth. We consider contexts where the truth consists of a set of objective winners, knowing a lower and upper bound on its cardinality. A prototypical problem for this setting is the aggregation of multi-label annotations with prior knowledge on the size of the ground truth. We posit noise models, for which we define rules that output an optimal set of winners. We report on experiments on multi-label annotations (which we collected).}\n}",
        "pdf": "https://proceedings.mlr.press/v180/allouche22a/allouche22a.pdf",
        "supp": "",
        "pdf_size": 601070,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5616794258264698349&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7a52d10ba3",
        "title": "Multiclass classification for Hawkes processes",
        "site": "https://proceedings.mlr.press/v180/denis22a.html",
        "author": "Christophe Denis; Charlotte Dion-Blanc; Laure Sansonnet",
        "abstract": "We investigate the multiclass classification prob- lem where the features are event sequences. More precisely, the data are assumed to be generated by a mixture of simple linear Hawkes processes. In this new setting, the classes are discriminated by various triggering kernels. A challenge is then to build an efficient classification procedure. We de- rive the optimal Bayes rule and provide a two-step estimation procedure of the Bayes classifier. In the first step, the weights of the mixture are estimated; in the second step, an empirical risk minimization procedure is performed to estimate the parameters of the Hawkes processes. We establish the consis- tency of the resulting procedure and derive rates of convergence. Finally, the numerical properties of the data-driven algorithm are illustrated through a simulation study where the triggering kernels are assumed to belong to the popular parametric expo- nential family. It highlights the accuracy and the robustness of the proposed algorithm. In particular, even if the underlying kernels are misspecified, the procedure exhibits good performance.",
        "bibtex": "@InProceedings{pmlr-v180-denis22a,\n  title = \t {Multiclass classification for Hawkes processes},\n  author =       {Denis, Christophe and Dion-Blanc, Charlotte and Sansonnet, Laure},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {539--547},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/denis22a/denis22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/denis22a.html},\n  abstract = \t {We investigate the multiclass classification prob- lem where the features are event sequences. More precisely, the data are assumed to be generated by a mixture of simple linear Hawkes processes. In this new setting, the classes are discriminated by various triggering kernels. A challenge is then to build an efficient classification procedure. We de- rive the optimal Bayes rule and provide a two-step estimation procedure of the Bayes classifier. In the first step, the weights of the mixture are estimated; in the second step, an empirical risk minimization procedure is performed to estimate the parameters of the Hawkes processes. We establish the consis- tency of the resulting procedure and derive rates of convergence. Finally, the numerical properties of the data-driven algorithm are illustrated through a simulation study where the triggering kernels are assumed to belong to the popular parametric expo- nential family. It highlights the accuracy and the robustness of the proposed algorithm. In particular, even if the underlying kernels are misspecified, the procedure exhibits good performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/denis22a/denis22a.pdf",
        "supp": "",
        "pdf_size": 327058,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15272600463643315088&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "64d812ab42",
        "title": "Multistate analysis with infinite mixtures of Markov chains",
        "site": "https://proceedings.mlr.press/v180/maystre22a.html",
        "author": "Lucas Maystre; Tiffany Wu; Roberto Sanchis-Ojeda; Tony Jebara",
        "abstract": "Driven by applications in clinical medicine and business, we address the problem of modeling trajectories over multiple states. We build on well-known methods from survival analysis and introduce a family of sequence models based on localized Bayesian Markov chains. We develop inference and prediction algorithms, and we apply the model to real-world data, demonstrating favorable empirical results. Our approach provides a practical and effective alternative to plain Markov chains and to existing (finite) mixture models; It retains the simplicity and computational benefits of the former while matching or exceeding the predictive performance of the latter.",
        "bibtex": "@InProceedings{pmlr-v180-maystre22a,\n  title = \t {Multistate analysis with infinite mixtures of {Markov} chains},\n  author =       {Maystre, Lucas and Wu, Tiffany and Sanchis-Ojeda, Roberto and Jebara, Tony},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1350--1359},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/maystre22a/maystre22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/maystre22a.html},\n  abstract = \t {Driven by applications in clinical medicine and business, we address the problem of modeling trajectories over multiple states. We build on well-known methods from survival analysis and introduce a family of sequence models based on localized Bayesian Markov chains. We develop inference and prediction algorithms, and we apply the model to real-world data, demonstrating favorable empirical results. Our approach provides a practical and effective alternative to plain Markov chains and to existing (finite) mixture models; It retains the simplicity and computational benefits of the former while matching or exceeding the predictive performance of the latter.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/maystre22a/maystre22a.pdf",
        "supp": "",
        "pdf_size": 351897,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:7RpH-1axZQgJ:scholar.google.com/&scioq=Multistate+analysis+with+infinite+mixtures+of+Markov+chains&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8b6d01171a",
        "title": "Mutation-driven follow the regularized leader for last-iterate convergence in zero-sum games",
        "site": "https://proceedings.mlr.press/v180/abe22a.html",
        "author": "Kenshi Abe; Mitsuki Sakamoto; Atsushi Iwasaki",
        "abstract": "In this study, we consider a variant of the Follow the Regularized Leader (FTRL) dynamics in two-player zero-sum games. FTRL is guaranteed to converge to a Nash equilibrium when time-averaging the strategies, while a lot of variants suffer from the issue of limit cycling behavior, i.e., lack the last-iterate convergence guarantee. To this end, we propose mutant FTRL (M-FTRL), an algorithm that introduces mutation for the perturbation of action probabilities. We then investigate the continuous-time dynamics of M-FTRL and provide the strong convergence guarantees toward stationary points that approximate Nash equilibria under full-information feedback. Furthermore, our simulation demonstrates that M-FTRL can enjoy faster convergence rates than FTRL and optimistic FTRL under full-information feedback and surprisingly exhibits clear convergence under bandit feedback.",
        "bibtex": "@InProceedings{pmlr-v180-abe22a,\n  title = \t {Mutation-driven follow the regularized leader for last-iterate convergence in zero-sum games},\n  author =       {Abe, Kenshi and Sakamoto, Mitsuki and Iwasaki, Atsushi},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1--10},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/abe22a/abe22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/abe22a.html},\n  abstract = \t {In this study, we consider a variant of the Follow the Regularized Leader (FTRL) dynamics in two-player zero-sum games. FTRL is guaranteed to converge to a Nash equilibrium when time-averaging the strategies, while a lot of variants suffer from the issue of limit cycling behavior, i.e., lack the last-iterate convergence guarantee. To this end, we propose mutant FTRL (M-FTRL), an algorithm that introduces mutation for the perturbation of action probabilities. We then investigate the continuous-time dynamics of M-FTRL and provide the strong convergence guarantees toward stationary points that approximate Nash equilibria under full-information feedback. Furthermore, our simulation demonstrates that M-FTRL can enjoy faster convergence rates than FTRL and optimistic FTRL under full-information feedback and surprisingly exhibits clear convergence under bandit feedback.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/abe22a/abe22a.pdf",
        "supp": "",
        "pdf_size": 5943254,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15297866724381319851&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "20084ed428",
        "title": "Mutual information based Bayesian graph neural network for few-shot learning",
        "site": "https://proceedings.mlr.press/v180/song22a.html",
        "author": "Kaiyu Song; Kun Yue; Liang Duan; Mingze Yang; Angsheng Li",
        "abstract": "In the deep neural network based few-shot learning, the limited training data may make the neural network extract ineffective features, which leads to inaccurate results. By Bayesian graph neural network (BGNN), the probability distributions on hidden layers imply useful features, and the few-shot learning could improved by establishing the correlation among features. Thus, in this paper, we incorporate mutual information (MI) into BGNN to describe the correlation, and propose an innovative framework by adopting the Bayesian network with continuous variables (BNCV) for effective calculation of MI. First, we build the BNCV simultaneously when calculating the probability distributions of features from the Dropout in hidden layers of BGNN. Then, we approximate the MI values efficiently by probabilistic inferences over BNCV. Finally, we give the correlation based loss function and training algorithm of our BGNN model. Experimental results show that our MI based BGNN framework is effective for few-shot learning and outperforms some state-of-the-art competitors by large margins on accuracy.",
        "bibtex": "@InProceedings{pmlr-v180-song22a,\n  title = \t {Mutual information based Bayesian graph neural network for few-shot learning},\n  author =       {Song, Kaiyu and Yue, Kun and Duan, Liang and Yang, Mingze and Li, Angsheng},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1866--1875},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/song22a/song22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/song22a.html},\n  abstract = \t {In the deep neural network based few-shot learning, the limited training data may make the neural network extract ineffective features, which leads to inaccurate results. By Bayesian graph neural network (BGNN), the probability distributions on hidden layers imply useful features, and the few-shot learning could improved by establishing the correlation among features. Thus, in this paper, we incorporate mutual information (MI) into BGNN to describe the correlation, and propose an innovative framework by adopting the Bayesian network with continuous variables (BNCV) for effective calculation of MI. First, we build the BNCV simultaneously when calculating the probability distributions of features from the Dropout in hidden layers of BGNN. Then, we approximate the MI values efficiently by probabilistic inferences over BNCV. Finally, we give the correlation based loss function and training algorithm of our BGNN model. Experimental results show that our MI based BGNN framework is effective for few-shot learning and outperforms some state-of-the-art competitors by large margins on accuracy.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/song22a/song22a.pdf",
        "supp": "",
        "pdf_size": 386095,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10765892885074322881&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fbfbe689f7",
        "title": "Near-optimal Thompson sampling-based algorithms for differentially private stochastic bandits",
        "site": "https://proceedings.mlr.press/v180/hu22a.html",
        "author": "Bingshan Hu; Nidhi Hegde",
        "abstract": "We address differentially private stochastic bandits. We present two (near)-optimal  Thompson Sampling-based learning algorithms: DP-TS and Lazy-DP-TS. The core idea in achieving optimality  is  the principle of optimism in the face of uncertainty. We reshape the posterior distribution in an optimistic way as compared to the  non-private Thompson Sampling. Our DP-TS achieves a $\\sum\\limits_{j \\in \\mathcal{A}: \\Delta_j > 0} O \\left(\\frac{\\log(T)}{\\min \\left\\{\\epsilon, \\Delta_j \\right\\} )} \\log \\left(\\frac{\\log(T)}{\\epsilon \\cdot \\Delta_j} \\right) \\right)$ regret bound, where $\\mathcal{A}$ is the arm set, $\\Delta_j$ is the sub-optimality gap of a sub-optimal arm $j$, and $\\epsilon$ is the  privacy parameter.  Our Lazy-DP-TS gets rid of the extra $\\log$ factor by using the idea of dropping observations. The regret of Lazy-DP-TS  is  $ \\sum\\limits_{j \\in \\mathcal{A}: \\Delta_j > 0} O \\left(\\frac{\\log(T)}{\\min \\left\\{\\epsilon, \\Delta_j \\right\\}} \\right)$, which matches the  regret lower bound. Additionally, we conduct experiments to compare the empirical performance of our proposed  algorithms with the existing optimal  algorithms for differentially private stochastic bandits.",
        "bibtex": "@InProceedings{pmlr-v180-hu22a,\n  title = \t {Near-optimal Thompson sampling-based algorithms for differentially private stochastic bandits},\n  author =       {Hu, Bingshan and Hegde, Nidhi},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {844--852},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/hu22a/hu22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/hu22a.html},\n  abstract = \t {We address differentially private stochastic bandits. We present two (near)-optimal  Thompson Sampling-based learning algorithms: DP-TS and Lazy-DP-TS. The core idea in achieving optimality  is  the principle of optimism in the face of uncertainty. We reshape the posterior distribution in an optimistic way as compared to the  non-private Thompson Sampling. Our DP-TS achieves a $\\sum\\limits_{j \\in \\mathcal{A}: \\Delta_j > 0} O \\left(\\frac{\\log(T)}{\\min \\left\\{\\epsilon, \\Delta_j \\right\\} )} \\log \\left(\\frac{\\log(T)}{\\epsilon \\cdot \\Delta_j} \\right) \\right)$ regret bound, where $\\mathcal{A}$ is the arm set, $\\Delta_j$ is the sub-optimality gap of a sub-optimal arm $j$, and $\\epsilon$ is the  privacy parameter.  Our Lazy-DP-TS gets rid of the extra $\\log$ factor by using the idea of dropping observations. The regret of Lazy-DP-TS  is  $ \\sum\\limits_{j \\in \\mathcal{A}: \\Delta_j > 0} O \\left(\\frac{\\log(T)}{\\min \\left\\{\\epsilon, \\Delta_j \\right\\}} \\right)$, which matches the  regret lower bound. Additionally, we conduct experiments to compare the empirical performance of our proposed  algorithms with the existing optimal  algorithms for differentially private stochastic bandits.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/hu22a/hu22a.pdf",
        "supp": "",
        "pdf_size": 306302,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2557827236794729363&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Computing Science, University of Alberta, Edmonton, Alberta, Canada+Amii (Alberta Machine Intelligence Institute); Department of Computing Science, University of Alberta, Edmonton, Alberta, Canada+Amii (Alberta Machine Intelligence Institute)",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "University of Alberta;Alberta Machine Intelligence Institute",
        "aff_unique_dep": "Department of Computing Science;",
        "aff_unique_url": "https://www.ualberta.ca;https://amiilabs.ca",
        "aff_unique_abbr": "UAlberta;Amii",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Edmonton;",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "346dd47ca6",
        "title": "Neural ensemble search via Bayesian sampling",
        "site": "https://proceedings.mlr.press/v180/shu22a.html",
        "author": "Yao Shu; Yizhou Chen; Zhongxiang Dai; Bryan Kian Hsiang Low",
        "abstract": "Recently, neural architecture search (NAS) has been applied to automate the design of neural networks in real-world applications. A large number of algorithms have been developed to improve the search cost or the performance of the final selected architectures in NAS. Unfortunately, these NAS algorithms aim to select only one single well-performing architecture from their search spaces and thus have overlooked the capability of neural network ensemble (i.e., an ensemble of neural networks with diverse architectures) in achieving improved performance over a single final selected architecture. To this end, we introduce a novel neural ensemble search algorithm, called neural ensemble search via Bayesian sampling (NESBS), to effectively and efficiently select well-performing neural network ensembles from a NAS search space. In our extensive experiments, NESBS algorithm is shown to be able to achieve improved performance over state-of-the-art NAS algorithms while incurring a comparable search cost, thus indicating the superior performance of our NESBS algorithm over these NAS algorithms in practice.",
        "bibtex": "@InProceedings{pmlr-v180-shu22a,\n  title = \t {Neural ensemble search via Bayesian sampling},\n  author =       {Shu, Yao and Chen, Yizhou and Dai, Zhongxiang and Low, Bryan Kian Hsiang},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1803--1812},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/shu22a/shu22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/shu22a.html},\n  abstract = \t {Recently, neural architecture search (NAS) has been applied to automate the design of neural networks in real-world applications. A large number of algorithms have been developed to improve the search cost or the performance of the final selected architectures in NAS. Unfortunately, these NAS algorithms aim to select only one single well-performing architecture from their search spaces and thus have overlooked the capability of neural network ensemble (i.e., an ensemble of neural networks with diverse architectures) in achieving improved performance over a single final selected architecture. To this end, we introduce a novel neural ensemble search algorithm, called neural ensemble search via Bayesian sampling (NESBS), to effectively and efficiently select well-performing neural network ensembles from a NAS search space. In our extensive experiments, NESBS algorithm is shown to be able to achieve improved performance over state-of-the-art NAS algorithms while incurring a comparable search cost, thus indicating the superior performance of our NESBS algorithm over these NAS algorithms in practice.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/shu22a/shu22a.pdf",
        "supp": "",
        "pdf_size": 3760017,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6113136881091841593&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "524f758320",
        "title": "Neural-progressive hedging: Enforcing constraints in reinforcement learning with stochastic programming",
        "site": "https://proceedings.mlr.press/v180/ghosh22a.html",
        "author": "Supriyo Ghosh; Laura Wynter; Shiau Hong Lim; Duc Thien Nguyen",
        "abstract": "We propose a framework, called neural-progressive hedging (NP), that leverages stochastic programming during the online phase of executing a reinforcement learning (RL) policy. The goal is to ensure feasibility with respect to constraints  and risk-based objectives such as conditional value-at-risk (CVaR) during the execution of the policy, using probabilistic models of the state transitions to guide policy adjustments. The framework is particularly amenable to the class of sequential resource allocation problems since feasibility with respect to typical resource constraints cannot be enforced in a scalable manner. The NP framework provides an alternative that adds modest overhead during the online phase. Experimental results demonstrate the efficacy of the NP framework on two continuous real-world tasks: (i) the portfolio optimization problem with liquidity constraints for financial planning, characterized by non-stationary state distributions; and (ii) the dynamic repositioning problem in bike sharing systems, that embodies the class of supply-demand matching problems. We show that the NP framework produces policies that are better than deep RL and other baseline approaches, adapting to non-stationarity, whilst satisfying structural constraints and accommodating risk measures in the resulting policies. Additional benefits of the NP framework are ease of implementation and  better explainability of the policies.",
        "bibtex": "@InProceedings{pmlr-v180-ghosh22a,\n  title = \t {Neural-progressive hedging: Enforcing constraints in reinforcement learning with stochastic programming},\n  author =       {Ghosh, Supriyo and Wynter, Laura and Lim, Shiau Hong and Nguyen, Duc Thien},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {707--717},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ghosh22a/ghosh22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ghosh22a.html},\n  abstract = \t {We propose a framework, called neural-progressive hedging (NP), that leverages stochastic programming during the online phase of executing a reinforcement learning (RL) policy. The goal is to ensure feasibility with respect to constraints  and risk-based objectives such as conditional value-at-risk (CVaR) during the execution of the policy, using probabilistic models of the state transitions to guide policy adjustments. The framework is particularly amenable to the class of sequential resource allocation problems since feasibility with respect to typical resource constraints cannot be enforced in a scalable manner. The NP framework provides an alternative that adds modest overhead during the online phase. Experimental results demonstrate the efficacy of the NP framework on two continuous real-world tasks: (i) the portfolio optimization problem with liquidity constraints for financial planning, characterized by non-stationary state distributions; and (ii) the dynamic repositioning problem in bike sharing systems, that embodies the class of supply-demand matching problems. We show that the NP framework produces policies that are better than deep RL and other baseline approaches, adapting to non-stationarity, whilst satisfying structural constraints and accommodating risk measures in the resulting policies. Additional benefits of the NP framework are ease of implementation and  better explainability of the policies.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/ghosh22a/ghosh22a.pdf",
        "supp": "",
        "pdf_size": 746651,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17530089544061573852&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Microsoft Research, Bangalore, India; IBM Research AI, Singapore; IBM Research AI, Singapore; Singapore Management University, Singapore",
        "aff_domain": "microsoft.com; ; ; ",
        "email": "microsoft.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Microsoft;IBM;Singapore Management University",
        "aff_unique_dep": "Microsoft Research;AI;",
        "aff_unique_url": "https://www.microsoft.com/en-us/research/group/microsoft-research-india;https://www.ibm.com/research;https://www.smu.edu.sg",
        "aff_unique_abbr": "MSR;IBM;SMU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Bangalore;",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "India;Singapore"
    },
    {
        "id": "3b145266d6",
        "title": "Neuro-symbolic entropy regularization",
        "site": "https://proceedings.mlr.press/v180/ahmed22a.html",
        "author": "Kareem Ahmed; Eric Wang; Kai-Wei Chang; Guy Van den Broeck",
        "abstract": "In structured output prediction, the goal is to jointly predict several output variables that together encode a structured object \u2013 a path in a graph, an entity-relation triple, or an ordering of objects. Such a large output space makes learning hard and requires vast amounts of labeled data. Different approaches leverage alternate sources of supervision. One approach \u2013 entropy regularization \u2013 posits that decision boundaries should lie in low-probability regions. It extracts supervision from unlabeled examples, but remains agnostic to the structure of the output space. Conversely, neuro-symbolic approaches exploit the knowledge that not every prediction corresponds to a valid structure in the output space. Yet, they do not further restrict the learned output distribution.This paper introduces a framework that unifies both approaches. We propose a loss, neuro-symbolic entropy regularization, that encourages the model to confidently predict a valid object. It is obtained by restricting entropy regularization to the distribution over only the valid structures. This loss can be computed efficiently when the output constraint is expressed as a tractable logic circuit. Moreover, it seamlessly integrates with other neuro-symbolic losses that eliminate invalid predictions. We demonstrate the efficacy of our approach on a series of semi-supervised and fully-supervised structured-prediction experiments, where it leads to models whose predictions are more accurate as well as more likely to be valid.",
        "bibtex": "@InProceedings{pmlr-v180-ahmed22a,\n  title = \t {Neuro-symbolic entropy regularization},\n  author =       {Ahmed, Kareem and Wang, Eric and Chang, Kai-Wei and Van den Broeck, Guy},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {43--53},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ahmed22a/ahmed22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ahmed22a.html},\n  abstract = \t {In structured output prediction, the goal is to jointly predict several output variables that together encode a structured object \u2013 a path in a graph, an entity-relation triple, or an ordering of objects. Such a large output space makes learning hard and requires vast amounts of labeled data. Different approaches leverage alternate sources of supervision. One approach \u2013 entropy regularization \u2013 posits that decision boundaries should lie in low-probability regions. It extracts supervision from unlabeled examples, but remains agnostic to the structure of the output space. Conversely, neuro-symbolic approaches exploit the knowledge that not every prediction corresponds to a valid structure in the output space. Yet, they do not further restrict the learned output distribution.This paper introduces a framework that unifies both approaches. We propose a loss, neuro-symbolic entropy regularization, that encourages the model to confidently predict a valid object. It is obtained by restricting entropy regularization to the distribution over only the valid structures. This loss can be computed efficiently when the output constraint is expressed as a tractable logic circuit. Moreover, it seamlessly integrates with other neuro-symbolic losses that eliminate invalid predictions. We demonstrate the efficacy of our approach on a series of semi-supervised and fully-supervised structured-prediction experiments, where it leads to models whose predictions are more accurate as well as more likely to be valid.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/ahmed22a/ahmed22a.pdf",
        "supp": "",
        "pdf_size": 665775,
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11715876995199882741&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1a76635810",
        "title": "NeuroBE: Escalating neural network approximations of Bucket Elimination",
        "site": "https://proceedings.mlr.press/v180/agarwal22a.html",
        "author": "Sakshi Agarwal; Kalev Kask; Alex Ihler; Rina Dechter",
        "abstract": "A major limiting factor in graphical model inference is the complexity of computing the partition function. Exact message-passing algorithms such as Bucket Elimination (BE) require exponential memory to compute the partition function; therefore, approximations are necessary. In this paper, we build upon a recently introduced methodology called Deep Bucket Elimination (DBE) that uses classical Neural Networks to approximate messages generated by BE for large buckets. The main feature of our new scheme, renamed NeuroBE, is that it customizes the architecture of the neural networks, their learning process and in particular, adapts the loss function to the internal form or distribution of messages. Our experiments demonstrate significant improvements in accuracy and time compared with the earlier DBE scheme.",
        "bibtex": "@InProceedings{pmlr-v180-agarwal22a,\n  title = \t {NeuroBE: Escalating neural network approximations of Bucket Elimination},\n  author =       {Agarwal, Sakshi and Kask, Kalev and Ihler, Alex and Dechter, Rina},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {11--21},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/agarwal22a/agarwal22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/agarwal22a.html},\n  abstract = \t {A major limiting factor in graphical model inference is the complexity of computing the partition function. Exact message-passing algorithms such as Bucket Elimination (BE) require exponential memory to compute the partition function; therefore, approximations are necessary. In this paper, we build upon a recently introduced methodology called Deep Bucket Elimination (DBE) that uses classical Neural Networks to approximate messages generated by BE for large buckets. The main feature of our new scheme, renamed NeuroBE, is that it customizes the architecture of the neural networks, their learning process and in particular, adapts the loss function to the internal form or distribution of messages. Our experiments demonstrate significant improvements in accuracy and time compared with the earlier DBE scheme.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/agarwal22a/agarwal22a.pdf",
        "supp": "",
        "pdf_size": 978973,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17012599929389548684&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5f73dc12af",
        "title": "Noisy L0-sparse subspace clustering on dimensionality reduced data",
        "site": "https://proceedings.mlr.press/v180/yang22e.html",
        "author": "Yingzhen Yang; Ping Li",
        "abstract": "Sparse subspace clustering methods with sparsity induced by L0-norm, such as L0-Sparse Subspace Clustering (L0-SSC), are demonstrated to be more effective than its L1 counterpart such as Sparse Subspace Clustering (SSC). However, the theoretical analysis of L0-SSC is restricted to clean data that lie exactly in subspaces. Real data often suffer from noise and they may lie close to subspaces. In this paper, we show that an optimal solution to the optimization problem of noisy L0-SSC achieves subspace detection property (SDP), a key element with which data from different subspaces are separated, under deterministic and semi-random model. Our results provide theoretical guarantee on the correctness of noisy L0-SSC in terms of SDP on noisy data for the first time, which reveals the advantage of noisy L0-SSC in terms of much less restrictive condition on subspace affinity. In order to improve the efficiency of noisy L0-SSC, we propose Noisy-DR-L0-SSC which provably recovers the subspaces on dimensionality reduced data. Noisy-DR-L0-SSC first projects the data onto a lower dimensional space by random projection, then performs noisy L0-SSC on the dimensionality reduced data for improved efficiency. Experimental results demonstrate the effectiveness of Noisy-DR-L0-SSC.",
        "bibtex": "@InProceedings{pmlr-v180-yang22e,\n  title = \t {Noisy L0-sparse subspace clustering on dimensionality reduced data},\n  author =       {Yang, Yingzhen and Li, Ping},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2235--2245},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yang22e/yang22e.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yang22e.html},\n  abstract = \t {Sparse subspace clustering methods with sparsity induced by L0-norm, such as L0-Sparse Subspace Clustering (L0-SSC), are demonstrated to be more effective than its L1 counterpart such as Sparse Subspace Clustering (SSC). However, the theoretical analysis of L0-SSC is restricted to clean data that lie exactly in subspaces. Real data often suffer from noise and they may lie close to subspaces. In this paper, we show that an optimal solution to the optimization problem of noisy L0-SSC achieves subspace detection property (SDP), a key element with which data from different subspaces are separated, under deterministic and semi-random model. Our results provide theoretical guarantee on the correctness of noisy L0-SSC in terms of SDP on noisy data for the first time, which reveals the advantage of noisy L0-SSC in terms of much less restrictive condition on subspace affinity. In order to improve the efficiency of noisy L0-SSC, we propose Noisy-DR-L0-SSC which provably recovers the subspaces on dimensionality reduced data. Noisy-DR-L0-SSC first projects the data onto a lower dimensional space by random projection, then performs noisy L0-SSC on the dimensionality reduced data for improved efficiency. Experimental results demonstrate the effectiveness of Noisy-DR-L0-SSC.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yang22e/yang22e.pdf",
        "supp": "",
        "pdf_size": 436549,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13650560534455093718&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "School of Computing and Augmented Intelligence, Arizona State University + Baidu Research; Baidu Research",
        "aff_domain": "asu.edu;gmail.com",
        "email": "asu.edu;gmail.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1",
        "aff_unique_norm": "Arizona State University;Baidu",
        "aff_unique_dep": "School of Computing and Augmented Intelligence;Baidu Research",
        "aff_unique_url": "https://www.asu.edu;https://research.baidu.com",
        "aff_unique_abbr": "ASU;Baidu",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Tempe;",
        "aff_country_unique_index": "0+1;1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "596b50c4fc",
        "title": "Non-parametric inference of relational dependence",
        "site": "https://proceedings.mlr.press/v180/ahsan22a.html",
        "author": "Ragib Ahsan; Zahra Fatemi; David Arbour; Elena Zheleva",
        "abstract": "Independence testing plays a central role in statistical and causal inference from observational data. Standard independence tests assume that the data samples are independent and identically distributed (i.i.d.) but that assumption is violated in many real-world datasets and applications centered on relational systems. This work examines the problem of estimating independence in data drawn from relational systems by defining sufficient representations for the sets of observations influencing individual instances. Specifically, we define marginal and conditional independence tests for relational data by considering the kernel mean embedding as a flexible aggregation function for relational variables. We propose a consistent, non-parametric, scalable kernel test to operationalize the relational independence test for non-i.i.d. observational data under a set of structural assumptions. We empirically evaluate our proposed method on a variety of synthetic and semi-synthetic networks and demonstrate its effectiveness compared to state-of-the-art kernel-based independence tests.",
        "bibtex": "@InProceedings{pmlr-v180-ahsan22a,\n  title = \t {Non-parametric inference of relational dependence},\n  author =       {Ahsan, Ragib and Fatemi, Zahra and Arbour, David and Zheleva, Elena},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {54--63},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ahsan22a/ahsan22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ahsan22a.html},\n  abstract = \t {Independence testing plays a central role in statistical and causal inference from observational data. Standard independence tests assume that the data samples are independent and identically distributed (i.i.d.) but that assumption is violated in many real-world datasets and applications centered on relational systems. This work examines the problem of estimating independence in data drawn from relational systems by defining sufficient representations for the sets of observations influencing individual instances. Specifically, we define marginal and conditional independence tests for relational data by considering the kernel mean embedding as a flexible aggregation function for relational variables. We propose a consistent, non-parametric, scalable kernel test to operationalize the relational independence test for non-i.i.d. observational data under a set of structural assumptions. We empirically evaluate our proposed method on a variety of synthetic and semi-synthetic networks and demonstrate its effectiveness compared to state-of-the-art kernel-based independence tests.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/ahsan22a/ahsan22a.pdf",
        "supp": "",
        "pdf_size": 504028,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:98w2g5fQ6-UJ:scholar.google.com/&scioq=Non-parametric+inference+of+relational+dependence&hl=en&as_sdt=0,5",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0709d43ead",
        "title": "Nonparametric exponential family graph embeddings for multiple representation learning",
        "site": "https://proceedings.mlr.press/v180/lu22a.html",
        "author": "Chien Lu; Jaakko Peltonen; Timo Nummenmaa; Jyrki Nummenmaa",
        "abstract": "In graph data, each node often serves multiple functionalities. However, most graph embedding models assume that each node can only possess one representation. We address this issue by proposing a nonparametric graph embedding model. The model allows each node to learn multiple representations where they are needed to represent the complexity of random walks in the graph. It extends the Exponential family graph embedding model with two nonparametric prior settings, the Dirichlet process and the uniform process. The model combines the ability of Exponential family graph embedding to take the number of occurrences of context nodes into account with nonparametric priors giving it the flexibility to learn more than one latent representation for each node. The learned embeddings outperform other state of the art approaches in link prediction and node classification tasks.",
        "bibtex": "@InProceedings{pmlr-v180-lu22a,\n  title = \t {Nonparametric exponential family graph embeddings for multiple representation learning},\n  author =       {Lu, Chien and Peltonen, Jaakko and Nummenmaa, Timo and Nummenmaa, Jyrki},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1275--1285},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/lu22a/lu22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/lu22a.html},\n  abstract = \t {In graph data, each node often serves multiple functionalities. However, most graph embedding models assume that each node can only possess one representation. We address this issue by proposing a nonparametric graph embedding model. The model allows each node to learn multiple representations where they are needed to represent the complexity of random walks in the graph. It extends the Exponential family graph embedding model with two nonparametric prior settings, the Dirichlet process and the uniform process. The model combines the ability of Exponential family graph embedding to take the number of occurrences of context nodes into account with nonparametric priors giving it the flexibility to learn more than one latent representation for each node. The learned embeddings outperform other state of the art approaches in link prediction and node classification tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/lu22a/lu22a.pdf",
        "supp": "",
        "pdf_size": 384895,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17816667146372069379&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0d19a513a0",
        "title": "Offline change detection under contamination",
        "site": "https://proceedings.mlr.press/v180/bhatt22a.html",
        "author": "Sujay Bhatt; Guanhua Fang; Ping Li",
        "abstract": "In this work, we propose a non-parametric and robust change detection algorithm to detect multiple change points in time series data under non-adversarial contamination. The algorithm is designed for the offline setting, where the objective is to detect changes when all data are received. We only make weak moment assumptions on the inliers (uncorrupted data) to handle a large class of distributions. The robust scan statistic in the change detection algorithm is fashioned using mean estimators based on influence functions. We establish the consistency of the estimated change point indexes as the number of samples increases, and provide empirical evidence to support the consistency results.",
        "bibtex": "@InProceedings{pmlr-v180-bhatt22a,\n  title = \t {Offline change detection under contamination},\n  author =       {Bhatt, Sujay and Fang, Guanhua and Li, Ping},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {191--201},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/bhatt22a/bhatt22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/bhatt22a.html},\n  abstract = \t {In this work, we propose a non-parametric and robust change detection algorithm to detect multiple change points in time series data under non-adversarial contamination. The algorithm is designed for the offline setting, where the objective is to detect changes when all data are received. We only make weak moment assumptions on the inliers (uncorrupted data) to handle a large class of distributions. The robust scan statistic in the change detection algorithm is fashioned using mean estimators based on influence functions. We establish the consistency of the estimated change point indexes as the number of samples increases, and provide empirical evidence to support the consistency results.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/bhatt22a/bhatt22a.pdf",
        "supp": "",
        "pdf_size": 632434,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11680799744737816587&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Cognitive Computing Lab, Baidu Research; Cognitive Computing Lab, Baidu Research; Cognitive Computing Lab, Baidu Research",
        "aff_domain": "gmail.com;gmail.com;gmail.com",
        "email": "gmail.com;gmail.com;gmail.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Baidu",
        "aff_unique_dep": "Cognitive Computing Lab",
        "aff_unique_url": "https://baidu.com",
        "aff_unique_abbr": "Baidu",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "c8e3d7ee92",
        "title": "Offline policy optimization with eligible actions",
        "site": "https://proceedings.mlr.press/v180/liu22d.html",
        "author": "Yao Liu; Yannis Flet-Berliac; Emma Brunskill",
        "abstract": "Offline policy optimization could have a large impact on many real-world decision-making problems, as online learning may be infeasible in many applications. Importance sampling and its variants are a common used type of estimator in offline policy evaluation, and such estimators typically do not require assumptions on the properties and representational capabilities of value function or decision process model function classes. In this paper, we identify an important overfitting phenomenon in optimizing the importance weighted return, in which it may be possible for the learned policy to essentially avoid making aligned decisions for part of the initial state space. We propose an algorithm to avoid this overfitting through a new per-state-neighborhood normalization constraint, and provide a theoretical justification of the proposed algorithm. We also show the limitations of previous attempts to this approach. We test our algorithm in a healthcare-inspired simulator, a logged dataset collected from real hospitals and continuous control tasks. These experiments show the proposed method yields less overfitting and better test performance compared to state-of-the-art batch reinforcement learning algorithms.",
        "bibtex": "@InProceedings{pmlr-v180-liu22d,\n  title = \t {Offline policy optimization with eligible actions},\n  author =       {Liu, Yao and Flet-Berliac, Yannis and Brunskill, Emma},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1253--1263},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/liu22d/liu22d.pdf},\n  url = \t {https://proceedings.mlr.press/v180/liu22d.html},\n  abstract = \t {Offline policy optimization could have a large impact on many real-world decision-making problems, as online learning may be infeasible in many applications. Importance sampling and its variants are a common used type of estimator in offline policy evaluation, and such estimators typically do not require assumptions on the properties and representational capabilities of value function or decision process model function classes. In this paper, we identify an important overfitting phenomenon in optimizing the importance weighted return, in which it may be possible for the learned policy to essentially avoid making aligned decisions for part of the initial state space. We propose an algorithm to avoid this overfitting through a new per-state-neighborhood normalization constraint, and provide a theoretical justification of the proposed algorithm. We also show the limitations of previous attempts to this approach. We test our algorithm in a healthcare-inspired simulator, a logged dataset collected from real hospitals and continuous control tasks. These experiments show the proposed method yields less overfitting and better test performance compared to state-of-the-art batch reinforcement learning algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/liu22d/liu22d.pdf",
        "supp": "",
        "pdf_size": 364153,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10718017592640420995&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "ByteDance; Stanford University; Stanford University",
        "aff_domain": "gmail.com;cs.stanford.edu;cs.stanford.edu",
        "email": "gmail.com;cs.stanford.edu;cs.stanford.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "ByteDance;Stanford University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.bytedance.com;https://www.stanford.edu",
        "aff_unique_abbr": "ByteDance;Stanford",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Stanford",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "207199cfbc",
        "title": "Offline reinforcement learning under value and density-ratio realizability: The power of gaps",
        "site": "https://proceedings.mlr.press/v180/chen22g.html",
        "author": "Jinglin Chen; Nan Jiang",
        "abstract": "We consider a challenging theoretical problem in offline reinforcement learning (RL): obtaining sample-efficiency guarantees with a dataset lacking sufficient coverage, under only realizability-type assumptions for the function approximators. While the existing theory has addressed learning under realizability and under non-exploratory data separately, no work has been able to address both simultaneously (except for a concurrent work which we compare in detail). Under an additional gap assumption, we provide guarantees to a simple pessimistic algorithm based on a version space formed by marginalized importance sampling (MIS), and the guarantee only requires the data to cover the optimal policy and the function classes to realize the optimal value and density-ratio functions. While similar gap assumptions have been used in other areas of RL theory, our work is the first to identify the utility and the novel mechanism of gap assumptions in offline RL with weak function approximation.",
        "bibtex": "@InProceedings{pmlr-v180-chen22g,\n  title = \t {Offline reinforcement learning under value and density-ratio realizability: The power of gaps},\n  author =       {Chen, Jinglin and Jiang, Nan},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {378--388},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/chen22g/chen22g.pdf},\n  url = \t {https://proceedings.mlr.press/v180/chen22g.html},\n  abstract = \t {We consider a challenging theoretical problem in offline reinforcement learning (RL): obtaining sample-efficiency guarantees with a dataset lacking sufficient coverage, under only realizability-type assumptions for the function approximators. While the existing theory has addressed learning under realizability and under non-exploratory data separately, no work has been able to address both simultaneously (except for a concurrent work which we compare in detail). Under an additional gap assumption, we provide guarantees to a simple pessimistic algorithm based on a version space formed by marginalized importance sampling (MIS), and the guarantee only requires the data to cover the optimal policy and the function classes to realize the optimal value and density-ratio functions. While similar gap assumptions have been used in other areas of RL theory, our work is the first to identify the utility and the novel mechanism of gap assumptions in offline RL with weak function approximation.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/chen22g/chen22g.pdf",
        "supp": "",
        "pdf_size": 363146,
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18324838674480626794&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, University of Illinois Urbana-Champaign, Urbana, IL, USA; Department of Computer Science, University of Illinois Urbana-Champaign, Urbana, IL, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e37bcb2151",
        "title": "Offline stochastic shortest path: Learning, evaluation and towards optimality",
        "site": "https://proceedings.mlr.press/v180/yin22b.html",
        "author": "Ming Yin; Wenjing Chen; Mengdi Wang; Yu-Xiang Wang",
        "abstract": "Goal-oriented Reinforcement Learning, where the agent needs to reach the goal state while simultaneously minimizing the cost, has received significant attention in real-world applications. Its theoretical formulation, stochastic shortest path (SSP), has been intensively researched in the online setting. Nevertheless, it remains understudied when such an online interaction is prohibited and only historical data is provided. In this paper, we consider the offline stochastic shortest path problem when the state space and the action space are finite. We design the simple value iteration-based algorithms for tackling both offline policy evaluation (OPE) and offline policy learning tasks. Notably, our analysis of these simple algorithms yields strong instance-dependent bounds which can imply worst-case bounds that are near-minimax optimal. We hope our study could help illuminate the fundamental statistical limits of the offline SSP problem and motivate further studies beyond the scope of current consideration.",
        "bibtex": "@InProceedings{pmlr-v180-yin22b,\n  title = \t {Offline stochastic shortest path: Learning, evaluation and towards optimality},\n  author =       {Yin, Ming and Chen, Wenjing and Wang, Mengdi and Wang, Yu-Xiang},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2278--2288},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yin22b/yin22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yin22b.html},\n  abstract = \t {Goal-oriented Reinforcement Learning, where the agent needs to reach the goal state while simultaneously minimizing the cost, has received significant attention in real-world applications. Its theoretical formulation, stochastic shortest path (SSP), has been intensively researched in the online setting. Nevertheless, it remains understudied when such an online interaction is prohibited and only historical data is provided. In this paper, we consider the offline stochastic shortest path problem when the state space and the action space are finite. We design the simple value iteration-based algorithms for tackling both offline policy evaluation (OPE) and offline policy learning tasks. Notably, our analysis of these simple algorithms yields strong instance-dependent bounds which can imply worst-case bounds that are near-minimax optimal. We hope our study could help illuminate the fundamental statistical limits of the offline SSP problem and motivate further studies beyond the scope of current consideration.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yin22b/yin22b.pdf",
        "supp": "",
        "pdf_size": 582835,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9670327056651825635&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, UC Santa Barbara + Department of Statistics and Applied Probability, UC Santa Barbara; Department of Electrical and Computer Engineering, Texas A&M University; Department of Electrical and Computer Engineering, Princeton University; Department of Computer Science, UC Santa Barbara",
        "aff_domain": "ucsb.edu;tamu.edu;princeton.edu;ucsb.edu",
        "email": "ucsb.edu;tamu.edu;princeton.edu;ucsb.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;1;2;0",
        "aff_unique_norm": "University of California, Santa Barbara;Texas A&M University;Princeton University",
        "aff_unique_dep": "Department of Computer Science;Department of Electrical and Computer Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsb.edu;https://www.tamu.edu;https://www.princeton.edu",
        "aff_unique_abbr": "UCSB;TAMU;Princeton",
        "aff_campus_unique_index": "0+0;0",
        "aff_campus_unique": "Santa Barbara;",
        "aff_country_unique_index": "0+0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8c6f0098a2",
        "title": "On early extinction and the effect of travelling in the SIR model",
        "site": "https://proceedings.mlr.press/v180/berenbrink22a.html",
        "author": "Petra Berenbrink; Colin Cooper; Cristina Gava; David Kohan Marzag\u00e3o; Frederik Mallmann-Trenn; Tomasz Radzik",
        "abstract": "We consider a population protocol version of the SIR model. In every round, an individual is chosen uniformly at random. If the individual is susceptible, then it becomes infected w.p. $\\beta I_t/N$, where $I_t$ is the number of infections at time $t$ and $N$ is the total number of individuals. If the individual is infected, then it recovers w.p. $\\gamma$, whereas, if the individual is already recovered, nothing happens. We prove sharp bounds on the probability of the disease becoming pandemic vs extinguishing early (dying out quickly). The probability of extinguishing early, $\\Pr{\\mathcal{E}_{ext}}$, is typically neglected in prior work since most use (deterministic) differential equations. Leveraging on this, using $\\Pr{\\mathcal{E}_{ext}}$, we proceed by bounding the expected size of the population that contracts the disease $\\mathbf{E}\\left[R_\\infty\\right]$. Prior work only calculated $\\mathbf{E}\\left[R_\\infty\u00a0|\u00a0\\overline{\\mathcal{E}_{ext}}\\right]$, or obtained non-closed form solutions. We then study the two-country model also accounting for the role of $\\Pr{\\mathcal{E}_{ext}}$. We assume that both countries have different infection rates $\\beta^{(i)}$, but share the same recovery rate $\\gamma$. In this model, each round has two steps: First, an individual is chosen u.a.r. and travels w.p. $p_{travel}$ to the other country. Afterwards, the process continues as before with the respective infection rates. Finally, using simulations, we characterise the influence of $p_{travel}$ on the total number of infections. Our simulations show that, depending on the $\\beta^{(i)}$, increasing $p_{travel}$ can decrease or increase the expected total number of infections $\\mathbf{E}\\left[R_\\infty\\right]$.",
        "bibtex": "@InProceedings{pmlr-v180-berenbrink22a,\n  title = \t {On early extinction and the effect of travelling in the SIR model},\n  author =       {Berenbrink, Petra and Cooper, Colin and Gava, Cristina and Kohan Marzag\\~{a}o, David and Mallmann-Trenn, Frederik and Radzik, Tomasz},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {159--169},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/berenbrink22a/berenbrink22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/berenbrink22a.html},\n  abstract = \t {We consider a population protocol version of the SIR model. In every round, an individual is chosen uniformly at random. If the individual is susceptible, then it becomes infected w.p. $\\beta I_t/N$, where $I_t$ is the number of infections at time $t$ and $N$ is the total number of individuals. If the individual is infected, then it recovers w.p. $\\gamma$, whereas, if the individual is already recovered, nothing happens. We prove sharp bounds on the probability of the disease becoming pandemic vs extinguishing early (dying out quickly). The probability of extinguishing early, $\\Pr{\\mathcal{E}_{ext}}$, is typically neglected in prior work since most use (deterministic) differential equations. Leveraging on this, using $\\Pr{\\mathcal{E}_{ext}}$, we proceed by bounding the expected size of the population that contracts the disease $\\mathbf{E}\\left[R_\\infty\\right]$. Prior work only calculated $\\mathbf{E}\\left[R_\\infty\u00a0|\u00a0\\overline{\\mathcal{E}_{ext}}\\right]$, or obtained non-closed form solutions. We then study the two-country model also accounting for the role of $\\Pr{\\mathcal{E}_{ext}}$. We assume that both countries have different infection rates $\\beta^{(i)}$, but share the same recovery rate $\\gamma$. In this model, each round has two steps: First, an individual is chosen u.a.r. and travels w.p. $p_{travel}$ to the other country. Afterwards, the process continues as before with the respective infection rates. Finally, using simulations, we characterise the influence of $p_{travel}$ on the total number of infections. Our simulations show that, depending on the $\\beta^{(i)}$, increasing $p_{travel}$ can decrease or increase the expected total number of infections $\\mathbf{E}\\left[R_\\infty\\right]$.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/berenbrink22a/berenbrink22a.pdf",
        "supp": "",
        "pdf_size": 944794,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8859250234252888795&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fb125c5b19",
        "title": "On provably robust meta-Bayesian optimization",
        "site": "https://proceedings.mlr.press/v180/dai22a.html",
        "author": "Zhongxiang Dai; Yizhou Chen; Haibin Yu; Bryan Kian Hsiang Low; Patrick Jaillet",
        "abstract": "Bayesian optimization (BO) has become popular for sequential optimization of black-box functions. When BO is used to optimize a target function, we often have access to previous evaluations of potentially related functions. This begs the question as to whether we can leverage these previous experiences to accelerate the current BO task through meta-learning (meta-BO), while ensuring robustness against potentially harmful dissimilar tasks that could sabotage the convergence of BO. This paper introduces two scalable and provably robust meta-BO algorithms: robust meta-Gaussian process-upper confidence bound (RM-GP-UCB) and RM-GP-Thompson sampling (RM-GP-TS). We prove that both algorithms are asymptotically no-regret even when some or all previous tasks are dissimilar to the current task, and show that RM-GP-UCB enjoys a better theoretical robustness than RM-GP-TS. We also exploit the theoretical guarantees to optimize the weights assigned to individual previous tasks through regret minimization via online learning, which diminishes the impact of dissimilar tasks and hence further enhances the robustness. Empirical evaluations show that (a) RM-GP-UCB performs effectively and consistently across various applications, and (b) RM-GP-TS, despite being less robust than RM-GP-UCB both in theory and in practice, performs competitively in some scenarios with less dissimilar tasks and is more computationally efficient.",
        "bibtex": "@InProceedings{pmlr-v180-dai22a,\n  title = \t {On provably robust meta-{Bayesian} optimization},\n  author =       {Dai, Zhongxiang and Chen, Yizhou and Yu, Haibin and Low, Bryan Kian Hsiang and Jaillet, Patrick},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {475--485},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/dai22a/dai22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/dai22a.html},\n  abstract = \t {Bayesian optimization (BO) has become popular for sequential optimization of black-box functions. When BO is used to optimize a target function, we often have access to previous evaluations of potentially related functions. This begs the question as to whether we can leverage these previous experiences to accelerate the current BO task through meta-learning (meta-BO), while ensuring robustness against potentially harmful dissimilar tasks that could sabotage the convergence of BO. This paper introduces two scalable and provably robust meta-BO algorithms: robust meta-Gaussian process-upper confidence bound (RM-GP-UCB) and RM-GP-Thompson sampling (RM-GP-TS). We prove that both algorithms are asymptotically no-regret even when some or all previous tasks are dissimilar to the current task, and show that RM-GP-UCB enjoys a better theoretical robustness than RM-GP-TS. We also exploit the theoretical guarantees to optimize the weights assigned to individual previous tasks through regret minimization via online learning, which diminishes the impact of dissimilar tasks and hence further enhances the robustness. Empirical evaluations show that (a) RM-GP-UCB performs effectively and consistently across various applications, and (b) RM-GP-TS, despite being less robust than RM-GP-UCB both in theory and in practice, performs competitively in some scenarios with less dissimilar tasks and is more computationally efficient.  }\n}",
        "pdf": "https://proceedings.mlr.press/v180/dai22a/dai22a.pdf",
        "supp": "",
        "pdf_size": 4949721,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12716631641840157703&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, National University of Singapore, Republic of Singapore; Department of Computer Science, National University of Singapore, Republic of Singapore; Department of Data Platform, Tencent; Department of Computer Science, National University of Singapore, Republic of Singapore; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "National University of Singapore;Tencent;Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Computer Science;Department of Data Platform;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.tencent.com;https://web.mit.edu",
        "aff_unique_abbr": "NUS;Tencent;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;1;0;2",
        "aff_country_unique": "Singapore;China;United States"
    },
    {
        "id": "174bfefa94",
        "title": "On testability of the front-door model via Verma constraints",
        "site": "https://proceedings.mlr.press/v180/bhattacharya22a.html",
        "author": "Rohit Bhattacharya; Razieh Nabi",
        "abstract": "The front-door criterion can be used to identify and compute causal effects despite the existence of unmeasured confounders between a treatment and outcome. However, the key assumptions \u2013 (i) the existence of a variable (or set of variables) that fully mediates the effect of the treatment on the outcome, and (ii) which simultaneously does not suffer from similar issues of confounding as the treatment-outcome pair \u2013 are often deemed implausible. This paper explores the testability of these assumptions. We show that under mild conditions involving an auxiliary variable, the assumptions encoded in the front-door model (and simple extensions of it) may be tested via generalized equality constraints a.k.a Verma constraints. We propose two goodness-of-fit tests based on this observation, and evaluate the efficacy of our proposal on real and synthetic data. We also provide theoretical and empirical comparisons to instrumental variable approaches to handling unmeasured confounding.",
        "bibtex": "@InProceedings{pmlr-v180-bhattacharya22a,\n  title = \t {On testability of the front-door model via {V}erma constraints},\n  author =       {Bhattacharya, Rohit and Nabi, Razieh},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {202--212},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/bhattacharya22a/bhattacharya22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/bhattacharya22a.html},\n  abstract = \t {The front-door criterion can be used to identify and compute causal effects despite the existence of unmeasured confounders between a treatment and outcome. However, the key assumptions \u2013 (i) the existence of a variable (or set of variables) that fully mediates the effect of the treatment on the outcome, and (ii) which simultaneously does not suffer from similar issues of confounding as the treatment-outcome pair \u2013 are often deemed implausible. This paper explores the testability of these assumptions. We show that under mild conditions involving an auxiliary variable, the assumptions encoded in the front-door model (and simple extensions of it) may be tested via generalized equality constraints a.k.a Verma constraints. We propose two goodness-of-fit tests based on this observation, and evaluate the efficacy of our proposal on real and synthetic data. We also provide theoretical and empirical comparisons to instrumental variable approaches to handling unmeasured confounding.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/bhattacharya22a/bhattacharya22a.pdf",
        "supp": "",
        "pdf_size": 360369,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13682037001481368611&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Computer Science, Williams College, Williamstown, Massachusetts, USA; Department of Biostatistics and Bioinformatics, Emory University, Atlanta, Georgia, USA",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Williams College;Emory University",
        "aff_unique_dep": "Department of Computer Science;Department of Biostatistics and Bioinformatics",
        "aff_unique_url": "https://www.williams.edu;https://www.emory.edu",
        "aff_unique_abbr": "Williams;Emory",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Williamstown;Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6a4e99e440",
        "title": "On the definition and computation of causal treewidth",
        "site": "https://proceedings.mlr.press/v180/chen22f.html",
        "author": "Yizuo Chen; Adnan Darwiche",
        "abstract": "Causal treewidth is a recently introduced notion allowing one to speed up Bayesian network inference and to bound its complexity in the presence of functional dependencies (causal mechanisms) whose identities are unknown. Causal treewidth is no greater than treewidth and can be bounded even when treewidth is unbounded. The utility of causal treewidth has been illustrated recently in the context of causal inference and model-based supervised learning. However, the current definition of causal treewidth is descriptive rather than perspective, therefore limiting its full exploitation in a practical setting. We provide an extensive study of causal treewidth in this paper which moves us closer to realizing the full computational potential of this notion both theoretically and practically.",
        "bibtex": "@InProceedings{pmlr-v180-chen22f,\n  title = \t {On the definition and computation of causal treewidth},\n  author =       {Chen, Yizuo and Darwiche, Adnan},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {368--377},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/chen22f/chen22f.pdf},\n  url = \t {https://proceedings.mlr.press/v180/chen22f.html},\n  abstract = \t {Causal treewidth is a recently introduced notion allowing one to speed up Bayesian network inference and to bound its complexity in the presence of functional dependencies (causal mechanisms) whose identities are unknown. Causal treewidth is no greater than treewidth and can be bounded even when treewidth is unbounded. The utility of causal treewidth has been illustrated recently in the context of causal inference and model-based supervised learning. However, the current definition of causal treewidth is descriptive rather than perspective, therefore limiting its full exploitation in a practical setting. We provide an extensive study of causal treewidth in this paper which moves us closer to realizing the full computational potential of this notion both theoretically and practically.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/chen22f/chen22f.pdf",
        "supp": "",
        "pdf_size": 761993,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8899980382493698075&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Computer Science Department, University of California, Los Angeles, USA; Computer Science Department, University of California, Los Angeles, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c397f11759",
        "title": "On the effectiveness of adversarial training against common corruptions",
        "site": "https://proceedings.mlr.press/v180/kireev22a.html",
        "author": "Klim Kireev; Maksym Andriushchenko; Nicolas Flammarion",
        "abstract": "The literature on robustness towards common corruptions shows no consensus on whether adversarial training can improve the performance in this setting. First, we show that, when used with an appropriately selected perturbation radius, Lp adversarial training can serve as a strong baseline against common corruptions improving both accuracy and calibration. Then we explain why adversarial training performs better than data augmentation with simple Gaussian noise which has been observed to be a meaningful baseline on common corruptions. Related to this, we identify the sigma-overfitting phenomenon when Gaussian augmentation overfits to a particular standard deviation used for training which has a significant detrimental effect on common corruption accuracy. We discuss how to alleviate this problem and then how to further enhance Lp adversarial training by introducing an efficient relaxation of adversarial training with learned perceptual image patch similarity as the distance metric. Through experiments on CIFAR-10 and ImageNet-100, we show that our approach does not only improve the Lp adversarial training baseline but also has cumulative gains with data augmentation methods such as AugMix, DeepAugment, ANT, and SIN, leading to state-of-the-art performance on common corruptions.",
        "bibtex": "@InProceedings{pmlr-v180-kireev22a,\n  title = \t {On the effectiveness of adversarial training against common corruptions},\n  author =       {Kireev, Klim and Andriushchenko, Maksym and Flammarion, Nicolas},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1012--1021},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/kireev22a/kireev22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/kireev22a.html},\n  abstract = \t {The literature on robustness towards common corruptions shows no consensus on whether adversarial training can improve the performance in this setting. First, we show that, when used with an appropriately selected perturbation radius, Lp adversarial training can serve as a strong baseline against common corruptions improving both accuracy and calibration. Then we explain why adversarial training performs better than data augmentation with simple Gaussian noise which has been observed to be a meaningful baseline on common corruptions. Related to this, we identify the sigma-overfitting phenomenon when Gaussian augmentation overfits to a particular standard deviation used for training which has a significant detrimental effect on common corruption accuracy. We discuss how to alleviate this problem and then how to further enhance Lp adversarial training by introducing an efficient relaxation of adversarial training with learned perceptual image patch similarity as the distance metric. Through experiments on CIFAR-10 and ImageNet-100, we show that our approach does not only improve the Lp adversarial training baseline but also has cumulative gains with data augmentation methods such as AugMix, DeepAugment, ANT, and SIN, leading to state-of-the-art performance on common corruptions.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/kireev22a/kireev22a.pdf",
        "supp": "",
        "pdf_size": 369002,
        "gs_citation": 124,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8273061595992867273&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "610c58a41b",
        "title": "On the inductive bias of neural networks for learning read-once DNFs",
        "site": "https://proceedings.mlr.press/v180/bronstein22a.html",
        "author": "Ido Bronstein; Alon Brutzkus; Amir Globerson",
        "abstract": "Learning functions over Boolean variables is a fundamental problem in machine learning. But not much is known about learning such functions using neural networks. Here we focus on learning read-once disjunctive normal forms (DNFs) under the uniform distribution with a convex neural network and gradient methods. We first observe empirically that gradient methods converge to compact solutions with neurons that are aligned with the terms of the DNF. This is despite the fact that there are many zero training error networks that do not have this property. Thus, the learning process has a clear inductive bias towards such logical formulas. Following recent results which connect the inductive bias of gradient flow (GF) to Karush-Kuhn-Tucker (KKT) points of minimum norm problems, we study these KKT points in our setting. We prove that zero training error solutions that memorize training points are not KKT points and therefore GF cannot converge to them. On the other hand, we prove that globally optimal KKT points correspond exactly to networks that are aligned with the DNF terms. These results suggest a strong connection between the inductive bias of GF and solutions that align with the DNF. We conclude with extensive experiments which verify our findings.",
        "bibtex": "@InProceedings{pmlr-v180-bronstein22a,\n  title = \t {On the inductive bias of neural networks for learning read-once DNFs},\n  author =       {Bronstein, Ido and Brutzkus, Alon and Globerson, Amir},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {255--265},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/bronstein22a/bronstein22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/bronstein22a.html},\n  abstract = \t {Learning functions over Boolean variables is a fundamental problem in machine learning. But not much is known about learning such functions using neural networks. Here we focus on learning read-once disjunctive normal forms (DNFs) under the uniform distribution with a convex neural network and gradient methods. We first observe empirically that gradient methods converge to compact solutions with neurons that are aligned with the terms of the DNF. This is despite the fact that there are many zero training error networks that do not have this property. Thus, the learning process has a clear inductive bias towards such logical formulas. Following recent results which connect the inductive bias of gradient flow (GF) to Karush-Kuhn-Tucker (KKT) points of minimum norm problems, we study these KKT points in our setting. We prove that zero training error solutions that memorize training points are not KKT points and therefore GF cannot converge to them. On the other hand, we prove that globally optimal KKT points correspond exactly to networks that are aligned with the DNF terms. These results suggest a strong connection between the inductive bias of GF and solutions that align with the DNF. We conclude with extensive experiments which verify our findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/bronstein22a/bronstein22a.pdf",
        "supp": "",
        "pdf_size": 615577,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9458592498750538337&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4c6a081540",
        "title": "On-the-fly adaptation of patrolling strategies in changing environments",
        "site": "https://proceedings.mlr.press/v180/brazdil22a.html",
        "author": "Tom\u00e1\u0161 Br\u00e1zdil; David Kla\u0161ka; Anton\u0131\u0301n Ku\u010dera; V\u0131\u0301t Musil; Petr Novotn\u00fd; Vojt\u011bch \u0158eh\u00e1k",
        "abstract": "We consider the problem of efficient patrolling strategy adaptation in a changing environment where the topology of Defender\u2019s moves and the importance of guarded targets change unpredictably. The Defender must instantly switch to a new strategy optimized for the new environment, not disrupting the ongoing patrolling task, and the new strategy must be computed promptly under all circumstances. Since strategy switching may cause unintended security risks compromising the achieved protection, our solution includes mechanisms for detecting and mitigating this problem. The efficiency of our framework is evaluated experimentally.",
        "bibtex": "@InProceedings{pmlr-v180-brazdil22a,\n  title = \t {On-the-fly adaptation of patrolling strategies in changing environments},\n  author =       {Br{\\'a}zdil, Tom{\\'a}{\\v{s}} and Kla{\\v{s}}ka, David and Ku{\\v{c}}era, Anton{\\'{\\i}}n and Musil, V{\\'{\\i}}t and Novotn{\\'y}, Petr and {\\v{R}}eh{\\'a}k, Vojt{\\v{e}}ch},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {244--254},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/brazdil22a/brazdil22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/brazdil22a.html},\n  abstract = \t { We consider the problem of efficient patrolling strategy adaptation in a changing environment where the topology of Defender\u2019s moves and the importance of guarded targets change unpredictably. The Defender must instantly switch to a new strategy optimized for the new environment, not disrupting the ongoing patrolling task, and the new strategy must be computed promptly under all circumstances. Since strategy switching may cause unintended security risks compromising the achieved protection, our solution includes mechanisms for detecting and mitigating this problem. The efficiency of our framework is evaluated experimentally.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/brazdil22a/brazdil22a.pdf",
        "supp": "",
        "pdf_size": 428864,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6731067265995482764&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "270e6c71a0",
        "title": "Optimal control of partially observable Markov decision processes with finite linear temporal logic constraints",
        "site": "https://proceedings.mlr.press/v180/kalagarla22a.html",
        "author": "Krishna C. Kalagarla; Kartik Dhruva; Dongming Shen; Rahul Jain; Ashutosh Nayyar; Pierluigi Nuzzo",
        "abstract": "Autonomous agents often operate in environments where the state is partially observed. In addition to maximizing their cumulative reward, agents must execute complex tasks with rich temporal and logical structures. These tasks can be expressed  using temporal logic languages like finite linear temporal logic. This paper, for the first time, provides a structured framework for designing agent policies that maximize the reward while ensuring that the probability of satisfying the temporal logic specification is sufficiently high. We reformulate the problem as a constrained partially observable Markov decision process (POMDP) and  provide a novel approach that can leverage off-the-shelf unconstrained POMDP solvers for solving it. Our approach guarantees approximate optimality and constraint satisfaction with high probability. We demonstrate its effectiveness by implementing it on several models of interest.",
        "bibtex": "@InProceedings{pmlr-v180-kalagarla22a,\n  title = \t {Optimal control of partially observable Markov decision processes with finite linear temporal logic constraints},\n  author =       {Kalagarla, Krishna C. and Dhruva, Kartik and Shen, Dongming and Jain, Rahul and Nayyar, Ashutosh and Nuzzo, Pierluigi},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {949--958},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/kalagarla22a/kalagarla22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/kalagarla22a.html},\n  abstract = \t {Autonomous agents often operate in environments where the state is partially observed. In addition to maximizing their cumulative reward, agents must execute complex tasks with rich temporal and logical structures. These tasks can be expressed  using temporal logic languages like finite linear temporal logic. This paper, for the first time, provides a structured framework for designing agent policies that maximize the reward while ensuring that the probability of satisfying the temporal logic specification is sufficiently high. We reformulate the problem as a constrained partially observable Markov decision process (POMDP) and  provide a novel approach that can leverage off-the-shelf unconstrained POMDP solvers for solving it. Our approach guarantees approximate optimality and constraint satisfaction with high probability. We demonstrate its effectiveness by implementing it on several models of interest.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/kalagarla22a/kalagarla22a.pdf",
        "supp": "",
        "pdf_size": 345760,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10980463494358049180&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a55ed37340",
        "title": "Ordinal causal discovery",
        "site": "https://proceedings.mlr.press/v180/ni22a.html",
        "author": "Yang Ni; Bani Mallick",
        "abstract": "Causal discovery for purely observational, categorical data is a long-standing challenging problem. Unlike continuous data, the vast majority of existing methods for categorical data focus on inferring the Markov equivalence class only, which leaves the direction of some causal relationships undetermined. This paper proposes an identifiable ordinal causal discovery method that exploits the ordinal information contained in many real-world applications to uniquely identify the causal structure. The proposed method is applicable beyond ordinal data via data discretization. Through real-world and synthetic experiments, we demonstrate that the proposed ordinal causal discovery method combined with simple score-and-search algorithms has favorable and robust performance compared to state-of-the-art alternative methods in both ordinal categorical and non-categorical data. An accompanied R package OCD is freely available at the first author\u2019s website.",
        "bibtex": "@InProceedings{pmlr-v180-ni22a,\n  title = \t {Ordinal causal discovery},\n  author =       {Ni, Yang and Mallick, Bani},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1530--1540},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ni22a/ni22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ni22a.html},\n  abstract = \t {Causal discovery for purely observational, categorical data is a long-standing challenging problem. Unlike continuous data, the vast majority of existing methods for categorical data focus on inferring the Markov equivalence class only, which leaves the direction of some causal relationships undetermined. This paper proposes an identifiable ordinal causal discovery method that exploits the ordinal information contained in many real-world applications to uniquely identify the causal structure. The proposed method is applicable beyond ordinal data via data discretization. Through real-world and synthetic experiments, we demonstrate that the proposed ordinal causal discovery method combined with simple score-and-search algorithms has favorable and robust performance compared to state-of-the-art alternative methods in both ordinal categorical and non-categorical data. An accompanied R package OCD is freely available at the first author\u2019s website.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/ni22a/ni22a.pdf",
        "supp": "",
        "pdf_size": 332596,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12795794559140297793&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Statistics, Texas A&M University, College Station, Texas, USA; Department of Statistics, Texas A&M University, College Station, Texas, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3c5b543383",
        "title": "Orthogonal Gromov-Wasserstein discrepancy with efficient lower bound",
        "site": "https://proceedings.mlr.press/v180/jin22a.html",
        "author": "Hongwei Jin; Zishun Yu; Xinhua Zhang",
        "abstract": "Comparing structured data from possibly different metric-measure spaces is a fundamental task in machine learning, with applications in, e.g., graph classification. The Gromov-Wasserstein (GW) discrepancy formulates a coupling between the structured data based on optimal transportation, tackling the incomparability between different structures by aligning the intra-relational geometries. Although efficient local solvers such as conditional gradient and Sinkhorn are available, the inherent non-convexity still prevents a tractable evaluation, and the existing lower bounds are not tight enough for practical use. To address this issue, we take inspirations from the connection with the quadratic assignment problem, and propose the orthogonal Gromov-Wasserstein (OGW) discrepancy as a surrogate of GW.  It admits an efficient and closed-form lower bound with O(n^3) complexity, and directly extends to the fused Gromov-Wasserstein distance, incorporating node features into the coupling.  Extensive experiments on both the synthetic and real-world datasets show the tightness of our lower bounds, and both OGW and its lower bounds efficiently deliver accurate predictions and satisfactory barycenters for graph sets.",
        "bibtex": "@InProceedings{pmlr-v180-jin22a,\n  title = \t {Orthogonal Gromov-Wasserstein discrepancy with efficient lower bound},\n  author =       {Jin, Hongwei and Yu, Zishun and Zhang, Xinhua},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {917--927},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/jin22a/jin22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/jin22a.html},\n  abstract = \t {Comparing structured data from possibly different metric-measure spaces is a fundamental task in machine learning, with applications in, e.g., graph classification. The Gromov-Wasserstein (GW) discrepancy formulates a coupling between the structured data based on optimal transportation, tackling the incomparability between different structures by aligning the intra-relational geometries. Although efficient local solvers such as conditional gradient and Sinkhorn are available, the inherent non-convexity still prevents a tractable evaluation, and the existing lower bounds are not tight enough for practical use. To address this issue, we take inspirations from the connection with the quadratic assignment problem, and propose the orthogonal Gromov-Wasserstein (OGW) discrepancy as a surrogate of GW.  It admits an efficient and closed-form lower bound with O(n^3) complexity, and directly extends to the fused Gromov-Wasserstein distance, incorporating node features into the coupling.  Extensive experiments on both the synthetic and real-world datasets show the tightness of our lower bounds, and both OGW and its lower bounds efficiently deliver accurate predictions and satisfactory barycenters for graph sets.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/jin22a/jin22a.pdf",
        "supp": "",
        "pdf_size": 417847,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14108364681895123825&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d34c496e22",
        "title": "PAC-Bayesian domain adaptation bounds for multiclass learners",
        "site": "https://proceedings.mlr.press/v180/sicilia22a.html",
        "author": "Anthony Sicilia; Katherine Atwell; Malihe Alikhani; Seong Jae Hwang",
        "abstract": "Multiclass neural networks are a common tool in modern unsupervised domain adaptation, yet an appropriate theoretical description for their non-uniform sample complexity is lacking in the adaptation literature. To fill this gap, we propose the first PAC-Bayesian adaptation bounds for multiclass learners. We facilitate practical use of our bounds by also proposing the first approximation techniques for the multiclass distribution divergences we consider. For divergences dependent on a Gibbs predictor, we propose additional PAC-Bayesian adaptation bounds which remove the need for inefficient Monte-Carlo estimation. Empirically, we test the efficacy of our proposed approximation techniques as well as some novel design-concepts which we include in our bounds. Finally, we apply our bounds to analyze a common adaptation algorithm that uses neural networks.",
        "bibtex": "@InProceedings{pmlr-v180-sicilia22a,\n  title = \t {PAC-Bayesian domain adaptation bounds for multiclass learners},\n  author =       {Sicilia, Anthony and Atwell, Katherine and Alikhani, Malihe and Hwang, Seong Jae},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1824--1834},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/sicilia22a/sicilia22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/sicilia22a.html},\n  abstract = \t {Multiclass neural networks are a common tool in modern unsupervised domain adaptation, yet an appropriate theoretical description for their non-uniform sample complexity is lacking in the adaptation literature. To fill this gap, we propose the first PAC-Bayesian adaptation bounds for multiclass learners. We facilitate practical use of our bounds by also proposing the first approximation techniques for the multiclass distribution divergences we consider. For divergences dependent on a Gibbs predictor, we propose additional PAC-Bayesian adaptation bounds which remove the need for inefficient Monte-Carlo estimation. Empirically, we test the efficacy of our proposed approximation techniques as well as some novel design-concepts which we include in our bounds. Finally, we apply our bounds to analyze a common adaptation algorithm that uses neural networks.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/sicilia22a/sicilia22a.pdf",
        "supp": "",
        "pdf_size": 677536,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7310728599790486342&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ac9b304c38",
        "title": "PDQ-Net: Deep probabilistic dual quaternion network for absolute pose regression on $SE(3)$",
        "site": "https://proceedings.mlr.press/v180/li22b.html",
        "author": "Wenjie Li; Wasif Naeem; Jia Liu; Dequan Zheng; Wei Hao; Lijun Chen",
        "abstract": "Accurate absolute pose regression is one of the key challenges in robotics and computer vision. Existing direct regression methods suffer from two limitations. First, some noisy scenarios such as poor illumination conditions are likely to result in the uncertainty of pose estimation. Second, the output n-dimensional feature vector in the Euclidean space $\\mathbb{R}^n$ cannot be well mapped to $SE(3)$ manifold. In this work, we propose a deep dual quaternion network that performs the absolute pose regression on $SE(3)$.  We first develop an antipodally symmetric probability distribution over the unit dual quaternion on $SE(3)$ to model uncertainties and then propose an intermediary differential representation space to replace the final output pose, which avoids the mapping problem from $\\mathbb{R}^n$ to $SE(3)$. In addition, we introduce a backpropagation method that considers the continuousness and differentiability of the proposed intermediary space. Extensive experiments on the camera re-localization task on the Cambridge Landmarks and 7-Scenes datasets demonstrate that our method greatly improves the accuracy of the pose as well as the robustness in dealing with uncertainty and ambiguity, compared to the state-of-the-art.",
        "bibtex": "@InProceedings{pmlr-v180-li22b,\n  title = \t {PDQ-Net: Deep probabilistic dual quaternion network for absolute pose regression on $SE(3)$},\n  author =       {Li, Wenjie and Naeem, Wasif and Liu, Jia and Zheng, Dequan and Hao, Wei and Chen, Lijun},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1118--1127},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/li22b/li22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/li22b.html},\n  abstract = \t {Accurate absolute pose regression is one of the key challenges in robotics and computer vision. Existing direct regression methods suffer from two limitations. First, some noisy scenarios such as poor illumination conditions are likely to result in the uncertainty of pose estimation. Second, the output n-dimensional feature vector in the Euclidean space $\\mathbb{R}^n$ cannot be well mapped to $SE(3)$ manifold. In this work, we propose a deep dual quaternion network that performs the absolute pose regression on $SE(3)$.  We first develop an antipodally symmetric probability distribution over the unit dual quaternion on $SE(3)$ to model uncertainties and then propose an intermediary differential representation space to replace the final output pose, which avoids the mapping problem from $\\mathbb{R}^n$ to $SE(3)$. In addition, we introduce a backpropagation method that considers the continuousness and differentiability of the proposed intermediary space. Extensive experiments on the camera re-localization task on the Cambridge Landmarks and 7-Scenes datasets demonstrate that our method greatly improves the accuracy of the pose as well as the robustness in dealing with uncertainty and ambiguity, compared to the state-of-the-art.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/li22b/li22b.pdf",
        "supp": "",
        "pdf_size": 2166734,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Gek9s6VrdgcJ:scholar.google.com/&scioq=PDQ-Net:+Deep+probabilistic+dual+quaternion+network+for+absolute+pose+regression+on+%24SE(3)%24&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "365f38b9fa",
        "title": "Pareto navigation gradient descent: a first-order algorithm for optimization in pareto set",
        "site": "https://proceedings.mlr.press/v180/ye22a.html",
        "author": "Mao Ye; Qiang Liu",
        "abstract": "Many modern machine learning applications, such as multi-task learning, require finding optimal model parameters to trade-off multiple objective functions that may conflict with each other. The notion of the Pareto set allows us to focus on the set of (often infinite number of) models that cannot be strictly improved. But it does not provide an actionable procedure for picking one or a few special models to return to practical users. In this paper, we consider optimization in Pareto set (OPT-in-Pareto), the problem of finding Pareto models that optimize an extra reference criterion function within the Pareto set. This function can either encode a specific preference from the users, or represent a generic diversity measure for obtaining a set of diversified Pareto models that are representative of the whole Pareto set. Unfortunately, despite being a highly useful framework, efficient algorithms for OPT-in-Pareto have been largely missing, especially for large-scale, non-convex, and non-linear objectives in deep learning. A naive approach is to apply Riemannian manifold gradient descent on the Pareto set, which yields a high computational cost due to the need for eigen-calculation of Hessian matrices. We propose a first-order algorithm that approximately solves OPT-in-Pareto using only gradient information, with both high practical efficiency and theoretically guaranteed convergence property. Empirically, we demonstrate that our method works efficiently for a variety of challenging multi-task-related problems.",
        "bibtex": "@InProceedings{pmlr-v180-ye22a,\n  title = \t {Pareto navigation gradient descent: a first-order algorithm for optimization in pareto set},\n  author =       {Ye, Mao and Liu, Qiang},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2246--2255},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ye22a/ye22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ye22a.html},\n  abstract = \t {Many modern machine learning applications, such as multi-task learning, require finding optimal model parameters to trade-off multiple objective functions that may conflict with each other. The notion of the Pareto set allows us to focus on the set of (often infinite number of) models that cannot be strictly improved. But it does not provide an actionable procedure for picking one or a few special models to return to practical users. In this paper, we consider optimization in Pareto set (OPT-in-Pareto), the problem of finding Pareto models that optimize an extra reference criterion function within the Pareto set. This function can either encode a specific preference from the users, or represent a generic diversity measure for obtaining a set of diversified Pareto models that are representative of the whole Pareto set. Unfortunately, despite being a highly useful framework, efficient algorithms for OPT-in-Pareto have been largely missing, especially for large-scale, non-convex, and non-linear objectives in deep learning. A naive approach is to apply Riemannian manifold gradient descent on the Pareto set, which yields a high computational cost due to the need for eigen-calculation of Hessian matrices. We propose a first-order algorithm that approximately solves OPT-in-Pareto using only gradient information, with both high practical efficiency and theoretically guaranteed convergence property. Empirically, we demonstrate that our method works efficiently for a variety of challenging multi-task-related problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/ye22a/ye22a.pdf",
        "supp": "",
        "pdf_size": 729264,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=386686201917828984&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "aff": "Computer Science Dept., The University of Texas at Austin; Computer Science Dept., The University of Texas at Austin",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Computer Science Dept.",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "05fe982ab1",
        "title": "Partial likelihood Thompson sampling",
        "site": "https://proceedings.mlr.press/v180/wu22c.html",
        "author": "Han Wu; Stefan Wager",
        "abstract": "We consider the problem of deciding how best to target and prioritize existing vaccines that may offer protection against new variants of an infectious disease. Sequential experiments are a promising approach; however, challenges due to delayed feedback and the overall ebb and flow of disease prevalence make available methods inapplicable for this task. We present a method, partial likelihood Thompson sampling, that can handle these challenges. Our method involves running Thompson sampling with belief updates determined by partial likelihood each time we observe an event. To test our approach, we ran a semi-synthetic experiment based on 200 days of COVID-19 infection data in the US.",
        "bibtex": "@InProceedings{pmlr-v180-wu22c,\n  title = \t {Partial likelihood Thompson sampling},\n  author =       {Wu, Han and Wager, Stefan},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2138--2147},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/wu22c/wu22c.pdf},\n  url = \t {https://proceedings.mlr.press/v180/wu22c.html},\n  abstract = \t {We consider the problem of deciding how best to target and prioritize existing vaccines that may offer protection against new variants of an infectious disease. Sequential experiments are a promising approach; however, challenges due to delayed feedback and the overall ebb and flow of disease prevalence make available methods inapplicable for this task. We present a method, partial likelihood Thompson sampling, that can handle these challenges. Our method involves running Thompson sampling with belief updates determined by partial likelihood each time we observe an event. To test our approach, we ran a semi-synthetic experiment based on 200 days of COVID-19 infection data in the US.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/wu22c/wu22c.pdf",
        "supp": "",
        "pdf_size": 607231,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8585025481414209347&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Statistics, Stanford University; Graduate School of Business, Stanford University",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "6b93500b5b",
        "title": "Partially adaptive regularized multiple regression analysis for estimating linear causal effects",
        "site": "https://proceedings.mlr.press/v180/nanmo22a.html",
        "author": "Hisayoshi Nanmo; Manabu Kuroki",
        "abstract": "This paper assumes that cause-effect relationships among variables can be described with a linear structural equation model. Then, a situation is considered where a set of observed covariates satisfies the back-door criterion but the ordinary least squares method cannot be applied to estimate linear causal effects because of multicollinearity/high-dimensional data problems. In this situation, we propose a novel regression approach, the \u201cpartially adaptive L$_p$-regularized multiple regression analysis\u201d (PAL$_p$MA) method for estimating the total effects. Different from standard regularized regression analysis, PAL$_p$MA provides a consistent or less-biased estimator of the linear causal effect. PAL$_p$MA is also applicable to evaluating direct effects through the single-door criterion.  Given space constraints, the proofs, some numerical experiments, and an industrial case study on setting up painting conditions of car bodies are provided in the Supplementary Material.",
        "bibtex": "@InProceedings{pmlr-v180-nanmo22a,\n  title = \t {Partially adaptive regularized multiple regression analysis for estimating linear causal effects},\n  author =       {Nanmo, Hisayoshi and Kuroki, Manabu},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1456--1465},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/nanmo22a/nanmo22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/nanmo22a.html},\n  abstract = \t {This paper assumes that cause-effect relationships among variables can be described with a linear structural equation model. Then, a situation is considered where a set of observed covariates satisfies the back-door criterion but the ordinary least squares method cannot be applied to estimate linear causal effects because of multicollinearity/high-dimensional data problems. In this situation, we propose a novel regression approach, the \u201cpartially adaptive L$_p$-regularized multiple regression analysis\u201d (PAL$_p$MA) method for estimating the total effects. Different from standard regularized regression analysis, PAL$_p$MA provides a consistent or less-biased estimator of the linear causal effect. PAL$_p$MA is also applicable to evaluating direct effects through the single-door criterion.  Given space constraints, the proofs, some numerical experiments, and an industrial case study on setting up painting conditions of car bodies are provided in the Supplementary Material.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/nanmo22a/nanmo22a.pdf",
        "supp": "",
        "pdf_size": 426223,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18326056067149510343&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Chugai Pharmaceutical Co., Ltd., Nihonbashi Muromachi, Chuo-ku, Tokyo, Japan; Yokohama National University, Tokiwadai, Hodogaya-ku, Yokohama, Japan",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Chugai Pharmaceutical Co., Ltd.;Yokohama National University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.chugai-pharm.co.jp;https://www.yokohama-nu.ac.jp",
        "aff_unique_abbr": ";YNU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Tokiwadai",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "fc226aadcc",
        "title": "PathFlow: A normalizing flow generator that finds transition paths",
        "site": "https://proceedings.mlr.press/v180/liu22b.html",
        "author": "Tianyi Liu; Weihao Gao; Zhirui Wang; Chong Wang",
        "abstract": "Sampling from a Boltzmann distribution to calculate important macro statistics is one of the central tasks in the study of large atomic and molecular systems.  Recently, a one-shot configuration sampler, the Boltzmann generator  [No\u00e9 et al., 2019], is introduced. Though a Boltzmann generator can directly generate independent metastable states, it lacks the ability to find transition pathways and describe the whole transition process. In this paper, we propose PathFlow that can function as a one-shot generator as well as a transition pathfinder. More specifically, a normalizing flow model is constructed to map the base distribution and linear interpolated path in the latent space to the Boltzmann distribution and a minimum (free) energy path in the configuration space simultaneously. PathFlow can be trained by standard gradient-based optimizers using the proposed gradient estimator with a theoretical guarantee. PathFlow, validated with the extensively studied examples including a synthetic M\u00fcller potential and Alanine dipeptide, shows a remarkable performance.",
        "bibtex": "@InProceedings{pmlr-v180-liu22b,\n  title = \t {PathFlow: A normalizing flow generator that finds transition paths},\n  author =       {Liu, Tianyi and Gao, Weihao and Wang, Zhirui and Wang, Chong},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1232--1242},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/liu22b/liu22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/liu22b.html},\n  abstract = \t {Sampling from a Boltzmann distribution to calculate important macro statistics is one of the central tasks in the study of large atomic and molecular systems.  Recently, a one-shot configuration sampler, the Boltzmann generator  [No\u00e9 et al., 2019], is introduced. Though a Boltzmann generator can directly generate independent metastable states, it lacks the ability to find transition pathways and describe the whole transition process. In this paper, we propose PathFlow that can function as a one-shot generator as well as a transition pathfinder. More specifically, a normalizing flow model is constructed to map the base distribution and linear interpolated path in the latent space to the Boltzmann distribution and a minimum (free) energy path in the configuration space simultaneously. PathFlow can be trained by standard gradient-based optimizers using the proposed gradient estimator with a theoretical guarantee. PathFlow, validated with the extensively studied examples including a synthetic M\u00fcller potential and Alanine dipeptide, shows a remarkable performance. }\n}",
        "pdf": "https://proceedings.mlr.press/v180/liu22b/liu22b.pdf",
        "supp": "",
        "pdf_size": 821715,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9099771179870123055&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1dbfbad940",
        "title": "Perturbation type categorization for multiple adversarial perturbation robustness",
        "site": "https://proceedings.mlr.press/v180/maini22a.html",
        "author": "Pratyush Maini; Xinyun Chen; Bo Li; Dawn Song",
        "abstract": "Recent works in adversarial robustness have proposed defenses to improve the robustness of a single model against the union of multiple perturbation types. However, these methods still suffer significant trade-offs compared to the ones specifically trained to be robust against a single perturbation type. In this work, we introduce the problem of categorizing adversarial examples based on their perturbation types. We first theoretically show on a toy task that adversarial examples of different perturbation types constitute different distributions\u2014making it possible to distinguish them. We support these arguments with experimental validation on multiple l_p attacks and common corruptions. Instead of training a single classifier, we propose PROTECTOR, a two-stage pipeline that first categorizes the perturbation type of the input, and then makes the final prediction using the classifier specifically trained against the predicted perturbation type. We theoretically show that at test time the adversary faces a natural trade-off between fooling the perturbation classifier and the succeeding classifier optimized with perturbation-specific adversarial training. This makes it challenging for an adversary to plant strong attacks against the whole pipeline. Experiments on MNIST and CIFAR-10 show that PROTECTOR outperforms prior adversarial training-based defenses by over 5% when tested against the union of l_1, l_2, l_inf attacks. Additionally, our method extends to a more diverse attack suite, also showing large robustness gains against multiple l_p, spatial and recolor attacks.",
        "bibtex": "@InProceedings{pmlr-v180-maini22a,\n  title = \t {Perturbation type categorization for multiple adversarial perturbation robustness},\n  author =       {Maini, Pratyush and Chen, Xinyun and Li, Bo and Song, Dawn},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1317--1327},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/maini22a/maini22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/maini22a.html},\n  abstract = \t {Recent works in adversarial robustness have proposed defenses to improve the robustness of a single model against the union of multiple perturbation types. However, these methods still suffer significant trade-offs compared to the ones specifically trained to be robust against a single perturbation type. In this work, we introduce the problem of categorizing adversarial examples based on their perturbation types. We first theoretically show on a toy task that adversarial examples of different perturbation types constitute different distributions\u2014making it possible to distinguish them. We support these arguments with experimental validation on multiple l_p attacks and common corruptions. Instead of training a single classifier, we propose PROTECTOR, a two-stage pipeline that first categorizes the perturbation type of the input, and then makes the final prediction using the classifier specifically trained against the predicted perturbation type. We theoretically show that at test time the adversary faces a natural trade-off between fooling the perturbation classifier and the succeeding classifier optimized with perturbation-specific adversarial training. This makes it challenging for an adversary to plant strong attacks against the whole pipeline. Experiments on MNIST and CIFAR-10 show that PROTECTOR outperforms prior adversarial training-based defenses by over 5% when tested against the union of l_1, l_2, l_inf attacks. Additionally, our method extends to a more diverse attack suite, also showing large robustness gains against multiple l_p, spatial and recolor attacks.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/maini22a/maini22a.pdf",
        "supp": "",
        "pdf_size": 680944,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7810752730279267433&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6a990b3664",
        "title": "Physics guided neural networks for spatio-temporal super-resolution of turbulent flows",
        "site": "https://proceedings.mlr.press/v180/bao22a.html",
        "author": "Tianshu Bao; Shengyu Chen; Taylor T Johnson; Peyman Givi; Shervin Sammak; Xiaowei Jia",
        "abstract": "Direct numerical simulation (DNS) of turbulent flows is computationally expensive and cannot be applied to flows with large Reynolds numbers.  Low-resolution large eddy simulation (LES) is a popular alternative, but it is unable to capture all of the scales of turbulent transport accurately. Reconstructing DNS from low-resolution LES is critical for large-scale simulation in many scientific and engineering disciplines, but it poses many challenges to existing super-resolution methods due to the complexity of turbulent flows and computational cost of generating frequent LES data.  We propose a physics-guided neural network for reconstructing frequent DNS from sparse LES data by enhancing its spatial resolution and temporal frequency. Our proposed method consists of a partial differential equation (PDE)-based recurrent unit for capturing underlying temporal processes and a physics-guided super-resolution model that incorporates additional physical constraints.  We demonstrate the effectiveness of both components in reconstructing the Taylor-Green Vortex using sparse LES data. Moreover, we show that the proposed recurrent unit can preserve the physical characteristics of turbulent flows by leveraging the physical relationships in the Navier-Stokes equation.",
        "bibtex": "@InProceedings{pmlr-v180-bao22a,\n  title = \t {Physics guided neural networks for spatio-temporal super-resolution of turbulent flows},\n  author =       {Bao, Tianshu and Chen, Shengyu and Johnson, Taylor T and Givi, Peyman and Sammak, Shervin and Jia, Xiaowei},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {118--128},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/bao22a/bao22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/bao22a.html},\n  abstract = \t {Direct numerical simulation (DNS) of turbulent flows is computationally expensive and cannot be applied to flows with large Reynolds numbers.  Low-resolution large eddy simulation (LES) is a popular alternative, but it is unable to capture all of the scales of turbulent transport accurately. Reconstructing DNS from low-resolution LES is critical for large-scale simulation in many scientific and engineering disciplines, but it poses many challenges to existing super-resolution methods due to the complexity of turbulent flows and computational cost of generating frequent LES data.  We propose a physics-guided neural network for reconstructing frequent DNS from sparse LES data by enhancing its spatial resolution and temporal frequency. Our proposed method consists of a partial differential equation (PDE)-based recurrent unit for capturing underlying temporal processes and a physics-guided super-resolution model that incorporates additional physical constraints.  We demonstrate the effectiveness of both components in reconstructing the Taylor-Green Vortex using sparse LES data. Moreover, we show that the proposed recurrent unit can preserve the physical characteristics of turbulent flows by leveraging the physical relationships in the Navier-Stokes equation.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/bao22a/bao22a.pdf",
        "supp": "",
        "pdf_size": 2356107,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10593216060171600259&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c80bec7cd2",
        "title": "Predictive Whittle networks for time series",
        "site": "https://proceedings.mlr.press/v180/yu22b.html",
        "author": "Zhongjie Yu; Fabrizio Ventola; Nils Thoma; Devendra Singh Dhami; Martin Mundt; Kristian Kersting",
        "abstract": "Recent developments have shown that modeling in the spectral domain improves the accuracy in time series forecasting. However, state-of-the-art neural spectral forecasters do not generally yield trustworthy predictions. In particular, they lack the means to gauge predictive likelihoods and provide uncertainty estimates. We propose predictive Whittle networks to bridge this gap, which exploit both the advances of neural forecasting in the spectral domain and leverage tractable likelihoods of probabilistic circuits. For this purpose, we propose a novel Whittle forecasting loss that makes use of these predictive likelihoods to guide the training of the neural forecasting component. We demonstrate how predictive Whittle networks improve real-world forecasting accuracy, while also allowing a transformation back into the time domain, in order to provide the necessary feedback of when the model\u2019s prediction may become erratic.",
        "bibtex": "@InProceedings{pmlr-v180-yu22b,\n  title = \t {Predictive Whittle networks for time series},\n  author =       {Yu, Zhongjie and Ventola, Fabrizio and Thoma, Nils and Dhami, Devendra Singh and Mundt, Martin and Kersting, Kristian},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2320--2330},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yu22b/yu22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yu22b.html},\n  abstract = \t {Recent developments have shown that modeling in the spectral domain improves the accuracy in time series forecasting. However, state-of-the-art neural spectral forecasters do not generally yield trustworthy predictions. In particular, they lack the means to gauge predictive likelihoods and provide uncertainty estimates. We propose predictive Whittle networks to bridge this gap, which exploit both the advances of neural forecasting in the spectral domain and leverage tractable likelihoods of probabilistic circuits. For this purpose, we propose a novel Whittle forecasting loss that makes use of these predictive likelihoods to guide the training of the neural forecasting component. We demonstrate how predictive Whittle networks improve real-world forecasting accuracy, while also allowing a transformation back into the time domain, in order to provide the necessary feedback of when the model\u2019s prediction may become erratic.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yu22b/yu22b.pdf",
        "supp": "",
        "pdf_size": 1267038,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9098799066298846436&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "944f8671fc",
        "title": "Principle of relevant information for graph sparsification",
        "site": "https://proceedings.mlr.press/v180/yu22c.html",
        "author": "Shujian Yu; Francesco Alesiani; Wenzhe Yin; Robert Jenssen; Jose C. Principe",
        "abstract": "Graph sparsification aims to reduce the number of edges of a graph while maintaining its structural properties. In this paper, we propose the first general and effective information-theoretic formulation of graph sparsification, by taking inspiration from the Principle of Relevant Information (PRI). To this end, we extend the PRI from a standard scalar random variable setting to structured data (i.e., graphs). Our Graph-PRI objective is achieved by operating on the graph Laplacian, made possible by expressing the graph Laplacian of a subgraph in terms of a sparse edge selection vector w. We provide both theoretical and empirical justifications on the validity of our Graph-PRI approach. We also analyze its analytical solutions in a few special cases. We finally present three representative real-world applications, namely graph sparsification, graph regularized multi-task learning, and medical imaging-derived brain network classification, to demonstrate the effectiveness, the versatility and the enhanced interpretability of our approach over prevalent sparsification techniques. Code of Graph-PRI is available at https://github.com/SJYuCNEL/PRI-Graphs.",
        "bibtex": "@InProceedings{pmlr-v180-yu22c,\n  title = \t {Principle of relevant information for graph sparsification},\n  author =       {Yu, Shujian and Alesiani, Francesco and Yin, Wenzhe and Jenssen, Robert and Principe, Jose C.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2331--2341},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yu22c/yu22c.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yu22c.html},\n  abstract = \t {Graph sparsification aims to reduce the number of edges of a graph while maintaining its structural properties. In this paper, we propose the first general and effective information-theoretic formulation of graph sparsification, by taking inspiration from the Principle of Relevant Information (PRI). To this end, we extend the PRI from a standard scalar random variable setting to structured data (i.e., graphs). Our Graph-PRI objective is achieved by operating on the graph Laplacian, made possible by expressing the graph Laplacian of a subgraph in terms of a sparse edge selection vector w. We provide both theoretical and empirical justifications on the validity of our Graph-PRI approach. We also analyze its analytical solutions in a few special cases. We finally present three representative real-world applications, namely graph sparsification, graph regularized multi-task learning, and medical imaging-derived brain network classification, to demonstrate the effectiveness, the versatility and the enhanced interpretability of our approach over prevalent sparsification techniques. Code of Graph-PRI is available at https://github.com/SJYuCNEL/PRI-Graphs.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yu22c/yu22c.pdf",
        "supp": "",
        "pdf_size": 1060745,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3897448115450913283&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "UiT - The Arctic University of Norway, Norway; NEC Laboratories Europe, Germany; University of Amsterdam, Netherlands; UiT - The Arctic University of Norway, Norway + Norwegian Computing Center, Norway + University of Copenhagen, Denmark; University of Florida, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/SJYuCNEL/PRI-Graphs",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0+3+4;5",
        "aff_unique_norm": "Arctic University of Norway;NEC Laboratories Europe;University of Amsterdam;Norwegian Computing Center;University of Copenhagen;University of Florida",
        "aff_unique_dep": ";;;;;",
        "aff_unique_url": "https://www.uit.no;https://www.nec-labs.eu;https://www.uva.nl;https://www.norskITED.no;https://www.ku.dk;https://www.ufl.edu",
        "aff_unique_abbr": "UiT;NEC LE;UvA;NCC;UCPH;UF",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2;0+0+3;4",
        "aff_country_unique": "Norway;Germany;Netherlands;Denmark;United States"
    },
    {
        "id": "2548ecfb6e",
        "title": "Privacy-aware compression for federated data analysis",
        "site": "https://proceedings.mlr.press/v180/chaudhuri22a.html",
        "author": "Kamalika Chaudhuri; Chuan Guo; Mike Rabbat",
        "abstract": "Federated data analytics is a framework for distributed data analysis where a server compiles noisy responses from a group of distributed low-bandwidth user devices to estimate aggregate statistics. Two major challenges in this framework are privacy, since user data is often sensitive, and compression, since the user devices have low network bandwidth. Prior work has addressed these challenges separately by combining standard compression algorithms with known privacy mechanisms. In this work, we take a holistic look at the problem and design a family of privacy-aware compression mechanisms that work for any given communication budget. We first propose a mechanism for transmitting a single real number that has optimal variance under certain conditions. We then show how to extend it to metric differential privacy for location privacy use-cases, as well as vectors, for application to federated learning. Our experiments illustrate that our mechanism can lead to better utility vs. compression trade-offs for the same privacy loss in a number of settings.",
        "bibtex": "@InProceedings{pmlr-v180-chaudhuri22a,\n  title = \t {Privacy-aware compression for federated data analysis},\n  author =       {Chaudhuri, Kamalika and Guo, Chuan and Rabbat, Mike},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {296--306},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/chaudhuri22a/chaudhuri22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/chaudhuri22a.html},\n  abstract = \t {Federated data analytics is a framework for distributed data analysis where a server compiles noisy responses from a group of distributed low-bandwidth user devices to estimate aggregate statistics. Two major challenges in this framework are privacy, since user data is often sensitive, and compression, since the user devices have low network bandwidth. Prior work has addressed these challenges separately by combining standard compression algorithms with known privacy mechanisms. In this work, we take a holistic look at the problem and design a family of privacy-aware compression mechanisms that work for any given communication budget. We first propose a mechanism for transmitting a single real number that has optimal variance under certain conditions. We then show how to extend it to metric differential privacy for location privacy use-cases, as well as vectors, for application to federated learning. Our experiments illustrate that our mechanism can lead to better utility vs. compression trade-offs for the same privacy loss in a number of settings.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/chaudhuri22a/chaudhuri22a.pdf",
        "supp": "",
        "pdf_size": 713711,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1084200374137487067&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b705e17b15",
        "title": "Probabilistic spatial transformer networks",
        "site": "https://proceedings.mlr.press/v180/schwobel22a.html",
        "author": "Pola Schw\u00f6bel; Frederik Rahb\u00e6k Warburg; Martin J\u00f8rgensen; Kristoffer Hougaard Madsen; S\u00f8ren Hauberg",
        "abstract": "Spatial Transformer Networks (STNs) estimate image transformations that can improve downstream tasks by \u2018zooming in\u2019 on relevant regions in an image. However, STNs are hard to train and sensitive to mis-predictions of transformations. To circumvent these limitations, we propose a probabilistic extension that estimates a stochastic transformation rather than a deterministic one. Marginalizing transformations allows us to consider each image at multiple poses, which makes the localization task easier and the training more robust. As an additional benefit, the stochastic transformations act as a localized, learned data augmentation that improves the downstream tasks. We show across standard imaging benchmarks and on a challenging real-world dataset that these two properties lead to improved classification performance, robustness and model calibration. We further demonstrate that the approach generalizes to non-visual domains by improving model performance on time-series data.",
        "bibtex": "@InProceedings{pmlr-v180-schwobel22a,\n  title = \t {Probabilistic spatial transformer networks},\n  author =       {Schw{\\\"o}bel, Pola and Warburg, Frederik Rahb{\\ae}k and J{\\o}rgensen, Martin and Madsen, Kristoffer Hougaard and Hauberg, S{\\o}ren},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1749--1759},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/schwobel22a/schwobel22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/schwobel22a.html},\n  abstract = \t {Spatial Transformer Networks (STNs) estimate image transformations that can improve downstream tasks by \u2018zooming in\u2019 on relevant regions in an image. However, STNs are hard to train and sensitive to mis-predictions of transformations. To circumvent these limitations, we propose a probabilistic extension that estimates a stochastic transformation rather than a deterministic one. Marginalizing transformations allows us to consider each image at multiple poses, which makes the localization task easier and the training more robust. As an additional benefit, the stochastic transformations act as a localized, learned data augmentation that improves the downstream tasks. We show across standard imaging benchmarks and on a challenging real-world dataset that these two properties lead to improved classification performance, robustness and model calibration. We further demonstrate that the approach generalizes to non-visual domains by improving model performance on time-series data.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/schwobel22a/schwobel22a.pdf",
        "supp": "",
        "pdf_size": 2781767,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10094834201984335560&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Section for Cognitive Systems, DTU Compute, Technical University of Denmark, Copenhagen, Denmark; Section for Cognitive Systems, DTU Compute, Technical University of Denmark, Copenhagen, Denmark; Machine Learning Research Group, Department of Engineering Science, University of Oxford, Oxford, UK; Section for Cognitive Systems, DTU Compute, Technical University of Denmark, Copenhagen, Denmark + Danish Research Centre for Magnetic Resonance, Centre for Functional and Diagnostic Imaging and Research, Copenhagen University Hospital Hvidovre, Hvidovre, Denmark; Section for Cognitive Systems, DTU Compute, Technical University of Denmark, Copenhagen, Denmark",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0+2;0",
        "aff_unique_norm": "Technical University of Denmark;University of Oxford;Copenhagen University Hospital Hvidovre",
        "aff_unique_dep": "Section for Cognitive Systems;Department of Engineering Science;Danish Research Centre for Magnetic Resonance, Centre for Functional and Diagnostic Imaging and Research",
        "aff_unique_url": "https://www.dtu.dk;https://www.ox.ac.uk;",
        "aff_unique_abbr": "DTU;Oxford;",
        "aff_campus_unique_index": "0;0;1;0+2;0",
        "aff_campus_unique": "Copenhagen;Oxford;Hvidovre",
        "aff_country_unique_index": "0;0;1;0+0;0",
        "aff_country_unique": "Denmark;United Kingdom"
    },
    {
        "id": "c93db330e7",
        "title": "Probabilistic surrogate networks for simulators with unbounded randomness",
        "site": "https://proceedings.mlr.press/v180/munk22a.html",
        "author": "Andreas Munk; Berend Zwartsenberg; Adam \u015acibior; At\u0131l\u0131m G\u00fcne\u015f G. Baydin; Andrew Stewart; Goran Fernlund; Anoush Poursartip; Frank Wood",
        "abstract": "We present a framework for automatically structuring and training fast, approximate, deep neural surrogates of stochastic simulators. Unlike traditional approaches to surrogate modeling, our surrogates retain the interpretable structure and control flow of the reference simulator. Our surrogates target stochastic simulators where the number of random variables itself can be stochastic and potentially unbounded. Our framework further enables an automatic replacement of the reference simulator with the surrogate when undertaking amortized inference. The fidelity and speed of our surrogates allow for both faster stochastic simulation and accurate and substantially faster posterior inference. Using an illustrative yet non-trivial example we show our surrogates\u2019 ability to accurately model a probabilistic program with an unbounded number of random variables. We then proceed with an example that shows our surrogates are able to accurately model a complex structure like an unbounded stack in a program synthesis example. We further demonstrate how our surrogate modeling technique makes amortized inference in complex black-box simulators an order of magnitude faster. Specifically, we do simulator-based materials quality testing, inferring safety-critical latent internal temperature profiles of composite materials undergoing curing.",
        "bibtex": "@InProceedings{pmlr-v180-munk22a,\n  title = \t {Probabilistic surrogate networks for simulators with unbounded randomness},\n  author =       {Munk, Andreas and Zwartsenberg, Berend and \\'Scibior, Adam and Baydin, At{\\i}l{\\i}m G{\\\"u}ne{\\c s} G. and Stewart, Andrew and Fernlund, Goran and Poursartip, Anoush and Wood, Frank},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1423--1433},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/munk22a/munk22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/munk22a.html},\n  abstract = \t {We present a framework for automatically structuring and training fast, approximate, deep neural surrogates of stochastic simulators. Unlike traditional approaches to surrogate modeling, our surrogates retain the interpretable structure and control flow of the reference simulator. Our surrogates target stochastic simulators where the number of random variables itself can be stochastic and potentially unbounded. Our framework further enables an automatic replacement of the reference simulator with the surrogate when undertaking amortized inference. The fidelity and speed of our surrogates allow for both faster stochastic simulation and accurate and substantially faster posterior inference. Using an illustrative yet non-trivial example we show our surrogates\u2019 ability to accurately model a probabilistic program with an unbounded number of random variables. We then proceed with an example that shows our surrogates are able to accurately model a complex structure like an unbounded stack in a program synthesis example. We further demonstrate how our surrogate modeling technique makes amortized inference in complex black-box simulators an order of magnitude faster. Specifically, we do simulator-based materials quality testing, inferring safety-critical latent internal temperature profiles of composite materials undergoing curing.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/munk22a/munk22a.pdf",
        "supp": "",
        "pdf_size": 1319402,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4747974202200034156&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d0a121c2bf",
        "title": "Proportional allocation of indivisible resources under ordinal and uncertain preferences.",
        "site": "https://proceedings.mlr.press/v180/li22d.html",
        "author": "Zihao Li; Xiaohui Bei; Zhenzhen Yan",
        "abstract": "We study a fair resource allocation problem with indivisible items. The agents\u2019 preferences over items are assumed to be ordinal and have uncertainties. We adopt stochastic dominance proportionality as our fairness notion and study a sequence of problems related to finding allocations that are fair with a high probability. We provide complexity analysis for each problem and efficient algorithms for some problems. Finally, we propose several heuristic algorithms to find an allocation that is fair with the highest probability. We thoroughly evaluate the performance of the algorithms on both synthetic and real datasets.",
        "bibtex": "@InProceedings{pmlr-v180-li22d,\n  title = \t {Proportional allocation of indivisible resources under ordinal and uncertain preferences.},\n  author =       {Li, Zihao and Bei, Xiaohui and Yan, Zhenzhen},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1148--1157},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/li22d/li22d.pdf},\n  url = \t {https://proceedings.mlr.press/v180/li22d.html},\n  abstract = \t {We study a fair resource allocation problem with indivisible items. The agents\u2019 preferences over items are assumed to be ordinal and have uncertainties. We adopt stochastic dominance proportionality as our fairness notion and study a sequence of problems related to finding allocations that are fair with a high probability. We provide complexity analysis for each problem and efficient algorithms for some problems. Finally, we propose several heuristic algorithms to find an allocation that is fair with the highest probability. We thoroughly evaluate the performance of the algorithms on both synthetic and real datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/li22d/li22d.pdf",
        "supp": "",
        "pdf_size": 287001,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18360218229228857369&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3148212ed2",
        "title": "Quadratic metric elicitation for fairness and beyond",
        "site": "https://proceedings.mlr.press/v180/hiranandani22a.html",
        "author": "Gaurush Hiranandani; Jatin Mathur; Harikrishna Narasimhan; Oluwasanmi Koyejo",
        "abstract": "Metric elicitation is a recent framework for eliciting classification performance metrics that best reflect implicit user preferences based on the task and context. However, available elicitation strategies have been limited to linear (or quasi-linear) functions of predictive rates, which can be practically restrictive for many applications including fairness. This paper develops a strategy for eliciting more flexible multiclass metrics defined by quadratic functions of rates, designed to reflect human preferences better. We show its application in eliciting quadratic violation-based group-fair metrics. Our strategy requires only relative preference feedback, is robust to noise, and achieves near-optimal query complexity. We further extend this strategy to eliciting polynomial metrics \u2013 thus broadening the use cases for metric elicitation.",
        "bibtex": "@InProceedings{pmlr-v180-hiranandani22a,\n  title = \t {Quadratic metric elicitation for fairness and beyond},\n  author =       {Hiranandani, Gaurush and Mathur, Jatin and Narasimhan, Harikrishna and Koyejo, Oluwasanmi},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {811--821},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/hiranandani22a/hiranandani22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/hiranandani22a.html},\n  abstract = \t {Metric elicitation is a recent framework for eliciting classification performance metrics that best reflect implicit user preferences based on the task and context. However, available elicitation strategies have been limited to linear (or quasi-linear) functions of predictive rates, which can be practically restrictive for many applications including fairness. This paper develops a strategy for eliciting more flexible multiclass metrics defined by quadratic functions of rates, designed to reflect human preferences better. We show its application in eliciting quadratic violation-based group-fair metrics. Our strategy requires only relative preference feedback, is robust to noise, and achieves near-optimal query complexity. We further extend this strategy to eliciting polynomial metrics \u2013 thus broadening the use cases for metric elicitation.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/hiranandani22a/hiranandani22a.pdf",
        "supp": "",
        "pdf_size": 646861,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9699232187947569083&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "59d552fb4a",
        "title": "Quantification of Credal Uncertainty in Machine Learning: A Critical Analysis and Empirical Comparison",
        "site": "https://proceedings.mlr.press/v180/hullermeier22a.html",
        "author": "Eyke H\u00fcllermeier; S\u00e9bastien Destercke; Mohammad Hossein Shaker",
        "abstract": "The representation and quantification of uncertainty has received increasing attention in machine learning in the recent past. The formalism of credal sets provides an interesting alternative in this regard, especially as it combines the representation of epistemic (lack of knowledge) and aleatoric (statistical) uncertainty in a rather natural way. In this paper, we elaborate on uncertainty measures for credal sets from the perspective of machine learning. More specifically, we provide an overview of proposals, discuss existing measures in a critical way, and also propose a new measure that is more tailored to the machine learning setting. Based on an experimental study, we conclude that theoretically well-justified measures also lead to better performance in practice. Besides, we corroborate the difficulty of the disaggregation problem, that is, of decomposing the amount of total uncertainty into aleatoric and epistemic uncertainty in a sound manner, thereby complementing theoretical findings with empirical evidence.",
        "bibtex": "@InProceedings{pmlr-v180-hullermeier22a,\n  title = \t {Quantification of Credal Uncertainty in Machine Learning: A Critical Analysis and Empirical Comparison},\n  author =       {H\\\"ullermeier, Eyke and Destercke, S\\'ebastien and Shaker, Mohammad Hossein},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {548--557},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/hullermeier22a/hullermeier22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/hullermeier22a.html},\n  abstract = \t {The representation and quantification of uncertainty has received increasing attention in machine learning in the recent past. The formalism of credal sets provides an interesting alternative in this regard, especially as it combines the representation of epistemic (lack of knowledge) and aleatoric (statistical) uncertainty in a rather natural way. In this paper, we elaborate on uncertainty measures for credal sets from the perspective of machine learning. More specifically, we provide an overview of proposals, discuss existing measures in a critical way, and also propose a new measure that is more tailored to the machine learning setting. Based on an experimental study, we conclude that theoretically well-justified measures also lead to better performance in practice. Besides, we corroborate the difficulty of the disaggregation problem, that is, of decomposing the amount of total uncertainty into aleatoric and epistemic uncertainty in a sound manner, thereby complementing theoretical findings with empirical evidence.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/hullermeier22a/hullermeier22a.pdf",
        "supp": "",
        "pdf_size": 426853,
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15873743795207417108&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c40adb939b",
        "title": "Quantum perceptron revisited: Computational-statistical tradeoffs",
        "site": "https://proceedings.mlr.press/v180/roget22a.html",
        "author": "Mathieu Roget; Giuseppe Di Molfetta; Hachem Kadri",
        "abstract": "Quantum machine learning algorithms could provide significant speed-ups over their classical counterparts; however, whether they could also achieve good generalization remains unclear. Recently, two quantum perceptron models which give a quadratic improvement over the classical perceptron algorithm using Grover\u2019s search have been proposed by Wiebe et al. While the first model reduces the complexity with respect to the size of the training set, the second one improves the bound on the number of mistakes made by the perceptron. In this paper, we introduce a hybrid quantum-classical perceptron algorithm with lower complexity and better generalization ability than the classical perceptron. We show a quadratic improvement over the classical perceptron in both the number of samples and the margin of the data. We derive a bound on the expected error of the hypothesis returned by our algorithm, which compares favorably to the one obtained with the classical online perceptron. We use numerical experiments to illustrate the trade-off between computational complexity and statistical accuracy in quantum perceptron learning and discuss some of the key practical issues surrounding the implementation of quantum perceptron models into near-term quantum devices, whose practical implementation represents a serious challenge due to inherent noise. However, the potential benefits make correcting this worthwhile.",
        "bibtex": "@InProceedings{pmlr-v180-roget22a,\n  title = \t {Quantum perceptron revisited: Computational-statistical tradeoffs},\n  author =       {Roget, Mathieu and Di Molfetta, Giuseppe and Kadri, Hachem},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1697--1706},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/roget22a/roget22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/roget22a.html},\n  abstract = \t {Quantum machine learning algorithms could provide significant speed-ups over their classical counterparts; however, whether they could also achieve good generalization remains unclear. Recently, two quantum perceptron models which give a quadratic improvement over the classical perceptron algorithm using Grover\u2019s search have been proposed by Wiebe et al. While the first model reduces the complexity with respect to the size of the training set, the second one improves the bound on the number of mistakes made by the perceptron. In this paper, we introduce a hybrid quantum-classical perceptron algorithm with lower complexity and better generalization ability than the classical perceptron. We show a quadratic improvement over the classical perceptron in both the number of samples and the margin of the data. We derive a bound on the expected error of the hypothesis returned by our algorithm, which compares favorably to the one obtained with the classical online perceptron. We use numerical experiments to illustrate the trade-off between computational complexity and statistical accuracy in quantum perceptron learning and discuss some of the key practical issues surrounding the implementation of quantum perceptron models into near-term quantum devices, whose practical implementation represents a serious challenge due to inherent noise. However, the potential benefits make correcting this worthwhile.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/roget22a/roget22a.pdf",
        "supp": "",
        "pdf_size": 473797,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11248174206640966723&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e38357d3e9",
        "title": "ReVar: Strengthening policy evaluation via reduced variance sampling",
        "site": "https://proceedings.mlr.press/v180/mukherjee22b.html",
        "author": "Subhojyoti Mukherjee; Josiah P. Hanna; Robert D Nowak",
        "abstract": "This paper studies the problem of data collection for policy evaluation in Markov decision processes (MDPs). In policy evaluation, we are given a \\textit{target} policy and asked to estimate the expected cumulative reward it will obtain in an environment formalized as an MDP. We develop theory for optimal data collection within the class of tree-structured MDPs by first deriving an oracle exploration strategy that uses knowledge of  the variance of the reward distributions. We then introduce the \\textbf{Re}duced \\textbf{Var}iance Sampling (\\rev\\!) algorithm that approximates the oracle strategy when the reward variances are unknown a priori and bound its sub-optimality compared to the oracle strategy. Finally, we empirically validate that \\rev leads to policy evaluation with mean squared error comparable to the oracle strategy and significantly lower than simply running the target policy.",
        "bibtex": "@InProceedings{pmlr-v180-mukherjee22b,\n  title = \t {ReVar: Strengthening policy evaluation via reduced variance sampling},\n  author =       {Mukherjee, Subhojyoti and Hanna, Josiah P. and Nowak, Robert D},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1413--1422},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/mukherjee22b/mukherjee22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/mukherjee22b.html},\n  abstract = \t {This paper studies the problem of data collection for policy evaluation in Markov decision processes (MDPs). In policy evaluation, we are given a \\textit{target} policy and asked to estimate the expected cumulative reward it will obtain in an environment formalized as an MDP. We develop theory for optimal data collection within the class of tree-structured MDPs by first deriving an oracle exploration strategy that uses knowledge of  the variance of the reward distributions. We then introduce the \\textbf{Re}duced \\textbf{Var}iance Sampling (\\rev\\!) algorithm that approximates the oracle strategy when the reward variances are unknown a priori and bound its sub-optimality compared to the oracle strategy. Finally, we empirically validate that \\rev leads to policy evaluation with mean squared error comparable to the oracle strategy and significantly lower than simply running the target policy.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/mukherjee22b/mukherjee22b.pdf",
        "supp": "",
        "pdf_size": 550134,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6670454714132738680&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Electrical and Computer Engineering, University of Wisconsin-Madison, USA; Computer Sciences Department, University of Wisconsin-Madison, USA; Department of Electrical and Computer Engineering, University of Wisconsin-Madison, USA",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Wisconsin-Madison",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW-Madison",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ebefba5f0e",
        "title": "Recursive Monte Carlo and variational inference with auxiliary variables",
        "site": "https://proceedings.mlr.press/v180/lew22a.html",
        "author": "Alexander K. Lew; Marco Cusumano-Towner; Vikash K. Mansinghka",
        "abstract": "A key design constraint when implementing Monte Carlo and variational inference algorithms is that it must be possible to cheaply and exactly evaluate the marginal densities of proposal distributions and variational families. This takes many interesting proposals off the table, such as those based on involved simulations or stochastic optimization. This paper broadens the design space, by presenting a framework for applying Monte Carlo and variational inference algorithms when proposal densities cannot be exactly evaluated. Our framework, recursive auxiliary-variable inference (RAVI), instead approximates the necessary densities using meta-inference: an additional layer of Monte Carlo or variational inference, that targets the proposal, rather than the model. RAVI generalizes and uni\ufb01es several existing methods for inference with expressive approximating families, which we show correspond to speci\ufb01c choices of meta-inference algorithm, and provides new theory for analyzing their bias and variance. We illustrate RAVI\u2019s design framework and theorems by using them to analyze and improve upon Salimans et al.\u2019s Markov Chain Variational Inference, and to design a novel sampler for Dirichlet process mixtures, achieving state-of-the-art results on a standard benchmark dataset from astronomy and on a challenging datacleaning task with Medicare hospital data.",
        "bibtex": "@InProceedings{pmlr-v180-lew22a,\n  title = \t {Recursive {M}onte {C}arlo and variational inference with auxiliary variables},\n  author =       {Lew, Alexander K. and Cusumano-Towner, Marco and Mansinghka, Vikash K.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1096--1106},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/lew22a/lew22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/lew22a.html},\n  abstract = \t {A key design constraint when implementing Monte Carlo and variational inference algorithms is that it must be possible to cheaply and exactly evaluate the marginal densities of proposal distributions and variational families. This takes many interesting proposals off the table, such as those based on involved simulations or stochastic optimization. This paper broadens the design space, by presenting a framework for applying Monte Carlo and variational inference algorithms when proposal densities cannot be exactly evaluated. Our framework, recursive auxiliary-variable inference (RAVI), instead approximates the necessary densities using meta-inference: an additional layer of Monte Carlo or variational inference, that targets the proposal, rather than the model. RAVI generalizes and uni\ufb01es several existing methods for inference with expressive approximating families, which we show correspond to speci\ufb01c choices of meta-inference algorithm, and provides new theory for analyzing their bias and variance. We illustrate RAVI\u2019s design framework and theorems by using them to analyze and improve upon Salimans et al.\u2019s Markov Chain Variational Inference, and to design a novel sampler for Dirichlet process mixtures, achieving state-of-the-art results on a standard benchmark dataset from astronomy and on a challenging datacleaning task with Medicare hospital data.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/lew22a/lew22a.pdf",
        "supp": "",
        "pdf_size": 524500,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3187672420774159392&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4662062ade",
        "title": "Reframed GES with a neural conditional dependence measure",
        "site": "https://proceedings.mlr.press/v180/shen22a.html",
        "author": "Xinwei Shen; Shengyu Zhu; Jiji Zhang; Shoubo Hu; Zhitang Chen",
        "abstract": "In a nonparametric setting, the causal structure is often identifiable only up to Markov equivalence, and for the purpose of causal inference, it is useful to learn a graphical representation of the Markov equivalence class (MEC).  In this paper, we revisit the Greedy Equivalence Search (GES) algorithm, which is widely cited as a score-based algorithm for learning the MEC of the underlying causal structure. We observe that in order to make the GES algorithm consistent in a nonparametric setting, it is not necessary to design a scoring metric that evaluates graphs. Instead, it suffices to plug in a consistent estimator of a measure of conditional dependence to guide the search. We therefore present a reframing of the GES algorithm, which is more flexible than the standard score-based version and readily lends itself to the nonparametric setting with a general measure of conditional dependence. In addition, we propose a neural conditional dependence (NCD) measure, which utilizes the expressive power of deep neural networks to characterize conditional independence in a nonparametric manner. We establish the optimality of the reframed GES algorithm under standard assumptions and the consistency of using our NCD estimator to decide conditional independence. Together these results justify the proposed approach. Experimental results demonstrate the effectiveness of our method in causal discovery, as well as the advantages of using our NCD measure over kernel-based measures.",
        "bibtex": "@InProceedings{pmlr-v180-shen22a,\n  title = \t {Reframed GES with a neural conditional dependence measure},\n  author =       {Shen, Xinwei and Zhu, Shengyu and Zhang, Jiji and Hu, Shoubo and Chen, Zhitang},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1782--1791},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/shen22a/shen22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/shen22a.html},\n  abstract = \t {In a nonparametric setting, the causal structure is often identifiable only up to Markov equivalence, and for the purpose of causal inference, it is useful to learn a graphical representation of the Markov equivalence class (MEC).  In this paper, we revisit the Greedy Equivalence Search (GES) algorithm, which is widely cited as a score-based algorithm for learning the MEC of the underlying causal structure. We observe that in order to make the GES algorithm consistent in a nonparametric setting, it is not necessary to design a scoring metric that evaluates graphs. Instead, it suffices to plug in a consistent estimator of a measure of conditional dependence to guide the search. We therefore present a reframing of the GES algorithm, which is more flexible than the standard score-based version and readily lends itself to the nonparametric setting with a general measure of conditional dependence. In addition, we propose a neural conditional dependence (NCD) measure, which utilizes the expressive power of deep neural networks to characterize conditional independence in a nonparametric manner. We establish the optimality of the reframed GES algorithm under standard assumptions and the consistency of using our NCD estimator to decide conditional independence. Together these results justify the proposed approach. Experimental results demonstrate the effectiveness of our method in causal discovery, as well as the advantages of using our NCD measure over kernel-based measures.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/shen22a/shen22a.pdf",
        "supp": "",
        "pdf_size": 325294,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13634126607066682008&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Hong Kong University of Science and Technology; Huawei Noah\u2019s Ark Lab; Hong Kong Baptist University; Huawei Noah\u2019s Ark Lab; Huawei Noah\u2019s Ark Lab",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1;1",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Huawei;Hong Kong Baptist University",
        "aff_unique_dep": ";Noah\u2019s Ark Lab;",
        "aff_unique_url": "https://www.ust.hk;https://www.huawei.com;https://www.hkbu.edu.hk",
        "aff_unique_abbr": "HKUST;Huawei;HKBU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "75a17ada87",
        "title": "Regret guarantees for model-based reinforcement learning with long-term average constraints",
        "site": "https://proceedings.mlr.press/v180/agarwal22b.html",
        "author": "Mridul Agarwal; Qinbo Bai; Vaneet Aggarwal",
        "abstract": "We consider the problem of constrained Markov Decision Process (CMDP) where an agent interacts with an ergodic Markov Decision Process. At every interaction, the agent obtains a reward and incurs $K$ costs. The agent aims to maximize the long-term average reward while simultaneously keeping the $K$ long-term average costs lower than a certain threshold. In this paper, we propose \\NAM, a posterior sampling based algorithm using which the agent can learn optimal policies to interact with the CMDP. We show that with the assumption of slackness, characterized by $\\kappa$, the optimization problem is feasible for the sampled MDPs. Further, for MDP with $S$ states, $A$ actions, and mixing time $T_M$, we prove that following \\NAM{} algorithm, the agent can bound the regret of not accumulating rewards from an optimal policy by $\\Tilde{O}(T_MS\\sqrt{AT})$. Further, we show that the violations for any of the $K$ constraints is also bounded by $\\Tilde{O}(T_MS\\sqrt{AT})$. To the best of our knowledge, this is the first work that obtains a $\\Tilde{O}(\\sqrt{T})$ regret bounds for ergodic MDPs with long-term average constraints using a posterior sampling method.",
        "bibtex": "@InProceedings{pmlr-v180-agarwal22b,\n  title = \t {Regret guarantees for model-based reinforcement learning with long-term average constraints},\n  author =       {Agarwal, Mridul and Bai, Qinbo and Aggarwal, Vaneet},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {22--31},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/agarwal22b/agarwal22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/agarwal22b.html},\n  abstract = \t {We consider the problem of constrained Markov Decision Process (CMDP) where an agent interacts with an ergodic Markov Decision Process. At every interaction, the agent obtains a reward and incurs $K$ costs. The agent aims to maximize the long-term average reward while simultaneously keeping the $K$ long-term average costs lower than a certain threshold. In this paper, we propose \\NAM, a posterior sampling based algorithm using which the agent can learn optimal policies to interact with the CMDP. We show that with the assumption of slackness, characterized by $\\kappa$, the optimization problem is feasible for the sampled MDPs. Further, for MDP with $S$ states, $A$ actions, and mixing time $T_M$, we prove that following \\NAM{} algorithm, the agent can bound the regret of not accumulating rewards from an optimal policy by $\\Tilde{O}(T_MS\\sqrt{AT})$. Further, we show that the violations for any of the $K$ constraints is also bounded by $\\Tilde{O}(T_MS\\sqrt{AT})$. To the best of our knowledge, this is the first work that obtains a $\\Tilde{O}(\\sqrt{T})$ regret bounds for ergodic MDPs with long-term average constraints using a posterior sampling method.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/agarwal22b/agarwal22b.pdf",
        "supp": "",
        "pdf_size": 1474532,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14138519031248018991&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "School of Electrical and Computer Engineering., Purdue University, West Lafayette, Indiana, USA+School of Industrial Engineering., Purdue University, West Lafayette, Indiana, USA; School of Electrical and Computer Engineering., Purdue University, West Lafayette, Indiana, USA+School of Industrial Engineering., Purdue University, West Lafayette, Indiana, USA; School of Industrial Engineering., Purdue University, West Lafayette, Indiana, USA+School of Electrical and Computer Engineering., Purdue University, West Lafayette, Indiana, USA",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0+0;0+0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0+0;0+0;0+0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0+0;0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "340e31bd76",
        "title": "Reinforcement learning in many-agent settings under partial observability",
        "site": "https://proceedings.mlr.press/v180/he22a.html",
        "author": "Keyang He; Prashant Doshi; Bikramjit Banerjee",
        "abstract": "Recent renewed interest in multi-agent reinforcement learning (MARL) has generated an impressive array of techniques that leverage deep RL, primarily actor-critic architectures, and can be applied to a limited range of settings in terms of observability and communication. However, a continuing limitation of much of this work is the curse of dimensionality when it comes to representations based on joint actions, which grow exponentially with the number of agents. In this paper, we squarely focus on this challenge of scalability. We apply the key insight of action anonymity to a recently presented actor-critic based MARL algorithm, interactive A2C. We introduce a Dirichlet-multinomial model for maintaining beliefs over the agent population when agents\u2019 actions are not perfectly observable. We show that the posterior is a mixture of Dirichlet distributions that we approximate as a single component for tractability. We also show that the prediction accuracy of this method increases with more agents. Finally we show empirically that our method can learn optimal behaviors in two recently introduced pragmatic domains with large agent population, and demonstrates robustness in partially observable environments.",
        "bibtex": "@InProceedings{pmlr-v180-he22a,\n  title = \t {Reinforcement learning in many-agent settings under partial observability},\n  author =       {He, Keyang and Doshi, Prashant and Banerjee, Bikramjit},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {780--789},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/he22a/he22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/he22a.html},\n  abstract = \t {Recent renewed interest in multi-agent reinforcement learning (MARL) has generated an impressive array of techniques that leverage deep RL, primarily actor-critic architectures, and can be applied to a limited range of settings in terms of observability and communication. However, a continuing limitation of much of this work is the curse of dimensionality when it comes to representations based on joint actions, which grow exponentially with the number of agents. In this paper, we squarely focus on this challenge of scalability. We apply the key insight of action anonymity to a recently presented actor-critic based MARL algorithm, interactive A2C. We introduce a Dirichlet-multinomial model for maintaining beliefs over the agent population when agents\u2019 actions are not perfectly observable. We show that the posterior is a mixture of Dirichlet distributions that we approximate as a single component for tractability. We also show that the prediction accuracy of this method increases with more agents. Finally we show empirically that our method can learn optimal behaviors in two recently introduced pragmatic domains with large agent population, and demonstrates robustness in partially observable environments.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/he22a/he22a.pdf",
        "supp": "",
        "pdf_size": 6991771,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2420821454915467934&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cbe6b72cf1",
        "title": "ResIST: Layer-wise decomposition of ResNets for distributed training",
        "site": "https://proceedings.mlr.press/v180/dun22a.html",
        "author": "Chen Dun; Cameron R. Wolfe; Christopher M. Jermaine; Anastasios Kyrillidis",
        "abstract": "We propose ResIST, a novel distributed training protocol for Residual Networks (ResNets). ResIST randomly decomposes a global ResNet into several shallow sub-ResNets that are trained independently in a distributed manner for several local iterations, before having their updates synchronized and aggregated into the global model. In the next round, new sub-ResNets are randomly generated and the process repeats until convergence. By construction, per iteration, ResIST communicates only a small portion of network parameters to each machine and never uses the full model during training. Thus, ResIST reduces the per-iteration communication, memory, and time requirements of ResNet training to only a fraction of the requirements of full-model training. In comparison to common protocols, like data-parallel training and data-parallel training with local SGD, ResIST yields a decrease in communication and compute requirements, while being competitive with respect to model performance.",
        "bibtex": "@InProceedings{pmlr-v180-dun22a,\n  title = \t {ResIST: Layer-wise decomposition of ResNets for distributed training},\n  author =       {Dun, Chen and Wolfe, Cameron R. and Jermaine, Christopher M. and Kyrillidis, Anastasios},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {610--620},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/dun22a/dun22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/dun22a.html},\n  abstract = \t {We propose ResIST, a novel distributed training protocol for Residual Networks (ResNets). ResIST randomly decomposes a global ResNet into several shallow sub-ResNets that are trained independently in a distributed manner for several local iterations, before having their updates synchronized and aggregated into the global model. In the next round, new sub-ResNets are randomly generated and the process repeats until convergence. By construction, per iteration, ResIST communicates only a small portion of network parameters to each machine and never uses the full model during training. Thus, ResIST reduces the per-iteration communication, memory, and time requirements of ResNet training to only a fraction of the requirements of full-model training. In comparison to common protocols, like data-parallel training and data-parallel training with local SGD, ResIST yields a decrease in communication and compute requirements, while being competitive with respect to model performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/dun22a/dun22a.pdf",
        "supp": "",
        "pdf_size": 817887,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11575688670607013048&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1ea0b9f2e2",
        "title": "Research on video adversarial attack with long living cycle",
        "site": "https://proceedings.mlr.press/v180/zhao22a.html",
        "author": "Zeyu Zhao; Ke Xu; Xinghao Jiang; Tanfeng Sun",
        "abstract": "In recent years, the vulnerability of networks has attracted the attention of researchers. However, in these methods, the impact of video compression coding on the added adversarial perturbation, i.e., the robustness of the video adversarial example, is not considered. When an adversarial sample is just generated, its attack capability is the strongest. However, with multiple video encoding and video decoding in Internet transmission, the added adversarial disturbance will be continuously eliminated, eventually leading to the attack on the adversarial sample performance disappearing. We define this phenomenon as the decay of the lifetime of adversarial examples. We propose an adversarial attack method based on optimized integer space to resist this performance degradation. The robustness of anti-coding, the visual concealment, and the attack success rate are all considered during the attack process. In addition, we have also reduced the rounding loss caused by normalization in the deep neural network model process. The contributions of our methods are 1) We show the performance degradation caused by video compression coding on existing video adversarial attack methods, which seems an effective way for detecting of defending video adversarial examples. 2) A robust video adversarial attack method is proposed to resist video compression coding. The experiment shows that our method performs better on the robustness of anti-coding, visual concealment, and attack success rate.",
        "bibtex": "@InProceedings{pmlr-v180-zhao22a,\n  title = \t {Research on video adversarial attack with long living cycle},\n  author =       {Zhao, Zeyu and Xu, Ke and Jiang, Xinghao and Sun, Tanfeng},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2374--2382},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/zhao22a/zhao22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/zhao22a.html},\n  abstract = \t {In recent years, the vulnerability of networks has attracted the attention of researchers. However, in these methods, the impact of video compression coding on the added adversarial perturbation, i.e., the robustness of the video adversarial example, is not considered. When an adversarial sample is just generated, its attack capability is the strongest. However, with multiple video encoding and video decoding in Internet transmission, the added adversarial disturbance will be continuously eliminated, eventually leading to the attack on the adversarial sample performance disappearing. We define this phenomenon as the decay of the lifetime of adversarial examples. We propose an adversarial attack method based on optimized integer space to resist this performance degradation. The robustness of anti-coding, the visual concealment, and the attack success rate are all considered during the attack process. In addition, we have also reduced the rounding loss caused by normalization in the deep neural network model process. The contributions of our methods are 1) We show the performance degradation caused by video compression coding on existing video adversarial attack methods, which seems an effective way for detecting of defending video adversarial examples. 2) A robust video adversarial attack method is proposed to resist video compression coding. The experiment shows that our method performs better on the robustness of anti-coding, visual concealment, and attack success rate.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/zhao22a/zhao22a.pdf",
        "supp": "",
        "pdf_size": 6616411,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2518394435549547797&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Shanghai Jiao Tong University, China; Shanghai Jiao Tong University, China; Shanghai Jiao Tong University, China; Shanghai Jiao Tong University, China",
        "aff_domain": "sjtu.edu.cn;sjtu.edu.cn;sjtu.edu.cn;sjtu.edu.cn",
        "email": "sjtu.edu.cn;sjtu.edu.cn;sjtu.edu.cn;sjtu.edu.cn",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "4bbbd27140",
        "title": "Residual bootstrap exploration for stochastic linear bandit",
        "site": "https://proceedings.mlr.press/v180/wu22a.html",
        "author": "Shuang Wu; Chi-Hua Wang; Yuantong Li; Guang Cheng",
        "abstract": "We propose a new bootstrap-based online algorithm for stochastic linear bandit problems. The key idea is to adopt residual bootstrap exploration, in which the agent estimates the next step reward by re-sampling the residuals of mean reward estimate. Our algorithm, residual bootstrap exploration for stochastic linear bandit (\\texttt{LinReBoot}), estimates the linear reward from its re-sampling distribution and pulls the arm with the highest reward estimate. In particular, we contribute a theoretical framework to demystify residual bootstrap-based exploration mechanisms in stochastic linear bandit problems. The key insight is that the strength of bootstrap exploration is based on collaborated optimism between the online-learned model and the re-sampling distribution of residuals. Such observation enables us to show that the proposed \\texttt{LinReBoot} secure a high-probability $\\tilde{O}(d \\sqrt{n})$ sub-linear regret under mild conditions. Our experiments support the easy generalizability of the \\texttt{ReBoot} principle in the various formulations of linear bandit problems and show the significant computational efficiency of \\texttt{LinReBoot}.",
        "bibtex": "@InProceedings{pmlr-v180-wu22a,\n  title = \t {Residual bootstrap exploration for stochastic linear bandit},\n  author =       {Wu, Shuang and Wang, Chi-Hua and Li, Yuantong and Cheng, Guang},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2117--2127},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/wu22a/wu22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/wu22a.html},\n  abstract = \t {We propose a new bootstrap-based online algorithm for stochastic linear bandit problems. The key idea is to adopt residual bootstrap exploration, in which the agent estimates the next step reward by re-sampling the residuals of mean reward estimate. Our algorithm, residual bootstrap exploration for stochastic linear bandit (\\texttt{LinReBoot}), estimates the linear reward from its re-sampling distribution and pulls the arm with the highest reward estimate. In particular, we contribute a theoretical framework to demystify residual bootstrap-based exploration mechanisms in stochastic linear bandit problems. The key insight is that the strength of bootstrap exploration is based on collaborated optimism between the online-learned model and the re-sampling distribution of residuals. Such observation enables us to show that the proposed \\texttt{LinReBoot} secure a high-probability $\\tilde{O}(d \\sqrt{n})$ sub-linear regret under mild conditions. Our experiments support the easy generalizability of the \\texttt{ReBoot} principle in the various formulations of linear bandit problems and show the significant computational efficiency of \\texttt{LinReBoot}. }\n}",
        "pdf": "https://proceedings.mlr.press/v180/wu22a/wu22a.pdf",
        "supp": "",
        "pdf_size": 1867568,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11985362266882455620&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2c25a298fd",
        "title": "Resolving label uncertainty with implicit posterior models",
        "site": "https://proceedings.mlr.press/v180/rolf22a.html",
        "author": "Esther Rolf; Nikolay Malkin; Alexandros Graikos; Ana Jojic; Caleb Robinson; Nebojsa Jojic",
        "abstract": "We propose a method for jointly inferring labels across a collection of data samples, where each sample consists of an observation and a prior belief about the label. By implicitly assuming the existence of a generative model for which a differentiable predictor is the posterior, we derive a training objective that allows learning under weak beliefs. This formulation unifies various machine learning settings; the weak beliefs can come in the form of noisy or incomplete labels, likelihoods given by a different prediction mechanism on auxiliary input, or common-sense priors reflecting knowledge about the structure of the problem at hand. We demonstrate the proposed algorithms on diverse problems: classification with negative training examples, learning from rankings, weakly and self-supervised aerial imagery segmentation, co-segmentation of video frames, and coarsely supervised text classification.",
        "bibtex": "@InProceedings{pmlr-v180-rolf22a,\n  title = \t {Resolving label uncertainty with implicit posterior models},\n  author =       {Rolf, Esther and Malkin, Nikolay and Graikos, Alexandros and Jojic, Ana and Robinson, Caleb and Jojic, Nebojsa},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1707--1717},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/rolf22a/rolf22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/rolf22a.html},\n  abstract = \t {We propose a method for jointly inferring labels across a collection of data samples, where each sample consists of an observation and a prior belief about the label. By implicitly assuming the existence of a generative model for which a differentiable predictor is the posterior, we derive a training objective that allows learning under weak beliefs. This formulation unifies various machine learning settings; the weak beliefs can come in the form of noisy or incomplete labels, likelihoods given by a different prediction mechanism on auxiliary input, or common-sense priors reflecting knowledge about the structure of the problem at hand. We demonstrate the proposed algorithms on diverse problems: classification with negative training examples, learning from rankings, weakly and self-supervised aerial imagery segmentation, co-segmentation of video frames, and coarsely supervised text classification.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/rolf22a/rolf22a.pdf",
        "supp": "",
        "pdf_size": 8177802,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10713908167946995253&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "University of California, Berkeley, CA, USA+Microsoft Research, Redmond, WA, USA; Mila and Universit\u00e9 de Montr\u00e9al, Montreal, QC, Canada+Microsoft Research, Redmond, WA, USA; Stony Brook University, Stony Brook, NY, USA+Microsoft Research, Redmond, WA, USA; Paul G. Allen School of Computer Science and Engineering, University of Washington, Seattle, WA, USA; Microsoft AI for Good, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2+1;3+1;4;1;1",
        "aff_unique_norm": "University of California, Berkeley;Microsoft;Universit\u00e9 de Montr\u00e9al;Stony Brook University;University of Washington",
        "aff_unique_dep": ";Microsoft Research;Mila;;Paul G. Allen School of Computer Science and Engineering",
        "aff_unique_url": "https://www.berkeley.edu;https://www.microsoft.com/en-us/research;https://www.umontreal.ca;https://www.stonybrook.edu;https://www.washington.edu",
        "aff_unique_abbr": "UC Berkeley;MSR;UdeM;SBU;UW",
        "aff_campus_unique_index": "0+1;2+1;3+1;4;1;1",
        "aff_campus_unique": "Berkeley;Redmond;Montreal;Stony Brook;Seattle",
        "aff_country_unique_index": "0+0;1+0;0+0;0;0;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "d04426e176",
        "title": "Restless and uncertain: Robust policies for restless bandits via deep multi-agent reinforcement learning",
        "site": "https://proceedings.mlr.press/v180/killian22a.html",
        "author": "Jackson A. Killian; Lily Xu; Arpita Biswas; Milind Tambe",
        "abstract": "We introduce robustness in \\textit{restless multi-armed bandits} (RMABs), a popular model for constrained resource allocation among independent stochastic processes (arms). Nearly all RMAB techniques assume stochastic dynamics are precisely known. However, in many real-world settings, dynamics are estimated with significant uncertainty, e.g., via historical data, which can lead to bad outcomes if ignored. To address this, we develop an algorithm to compute minimax regret\u2013robust policies for RMABs. Our approach uses a double oracle framework (oracles for \\textit{agent} and \\textit{nature}), which is often used for single-process robust planning but requires significant new techniques to accommodate the combinatorial nature of RMABs. Specifically, we design a deep reinforcement learning (RL) algorithm, DDLPO, which tackles the combinatorial challenge by learning an auxiliary \u201c$\\lambda$-network\u201d in tandem with policy networks per arm, greatly reducing sample complexity, with guarantees on convergence. DDLPO, of general interest, implements our reward-maximizing agent oracle. We then tackle the challenging regret-maximizing nature oracle, a non-stationary RL challenge, by formulating it as a multi-agent RL problem between a policy optimizer and adversarial nature. This formulation is of general interest\u2014we solve it for RMABs by creating a multi-agent extension of DDLPO with a shared critic. We show our approaches work well in three experimental domains.",
        "bibtex": "@InProceedings{pmlr-v180-killian22a,\n  title = \t {Restless and uncertain: Robust policies for restless bandits via deep multi-agent reinforcement learning},\n  author =       {Killian, Jackson A. and Xu, Lily and Biswas, Arpita and Tambe, Milind},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {990--1000},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/killian22a/killian22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/killian22a.html},\n  abstract = \t {We introduce robustness in \\textit{restless multi-armed bandits} (RMABs), a popular model for constrained resource allocation among independent stochastic processes (arms). Nearly all RMAB techniques assume stochastic dynamics are precisely known. However, in many real-world settings, dynamics are estimated with significant uncertainty, e.g., via historical data, which can lead to bad outcomes if ignored. To address this, we develop an algorithm to compute minimax regret\u2013robust policies for RMABs. Our approach uses a double oracle framework (oracles for \\textit{agent} and \\textit{nature}), which is often used for single-process robust planning but requires significant new techniques to accommodate the combinatorial nature of RMABs. Specifically, we design a deep reinforcement learning (RL) algorithm, DDLPO, which tackles the combinatorial challenge by learning an auxiliary \u201c$\\lambda$-network\u201d in tandem with policy networks per arm, greatly reducing sample complexity, with guarantees on convergence. DDLPO, of general interest, implements our reward-maximizing agent oracle. We then tackle the challenging regret-maximizing nature oracle, a non-stationary RL challenge, by formulating it as a multi-agent RL problem between a policy optimizer and adversarial nature. This formulation is of general interest\u2014we solve it for RMABs by creating a multi-agent extension of DDLPO with a shared critic. We show our approaches work well in three experimental domains.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/killian22a/killian22a.pdf",
        "supp": "",
        "pdf_size": 701819,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2685966982446795124&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "20b2b708c5",
        "title": "Revisiting DP-Means: fast scalable algorithms via parallelism and delayed cluster creation",
        "site": "https://proceedings.mlr.press/v180/dinari22b.html",
        "author": "Or Dinari; Oren Freifeld",
        "abstract": "DP-means, a nonparametric generalization of  K-means, extends the latter to the  case where the number of clusters is unknown. Unlike K-means, however, DP-means is hard to parallelize, a limitation hindering its usage in large-scale tasks. This work bridges this practicality gap by rendering the DP-means approach a viable, fast, and highly-scalable solution. First, we study the strengths and weaknesses of previous attempts to parallelize the DP-means algorithm. Next, we propose a new parallel algorithm, called PDC-DP-Means (Parallel Delayed Cluster DP-Means), based in part on delayed creation of clusters. Compared with DP-Means, PDC-DP-Means provides not only a major speedup but also performance gains. Finally, we propose two extensions of PDC-DP-Means. The first combines it with an existing method, leading to further speedups. The second extends PDC-DP-Means to  a Mini-Batch setting (with an optional support for an online mode),  allowing for another major speedup. We verify the utility of the proposed methods on multiple datasets. We also show that the proposed methods outperform other nonparametric methods (e.g., DBSCAN). Our highly-efficient code can be used to reproduce our experiments and is available at https://github.com/BGU-CS-VIL/pdc-dp-means",
        "bibtex": "@InProceedings{pmlr-v180-dinari22b,\n  title = \t {Revisiting DP-Means: fast scalable algorithms via parallelism and delayed cluster creation},\n  author =       {Dinari, Or and Freifeld, Oren},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {579--588},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/dinari22b/dinari22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/dinari22b.html},\n  abstract = \t {DP-means, a nonparametric generalization of  K-means, extends the latter to the  case where the number of clusters is unknown. Unlike K-means, however, DP-means is hard to parallelize, a limitation hindering its usage in large-scale tasks. This work bridges this practicality gap by rendering the DP-means approach a viable, fast, and highly-scalable solution. First, we study the strengths and weaknesses of previous attempts to parallelize the DP-means algorithm. Next, we propose a new parallel algorithm, called PDC-DP-Means (Parallel Delayed Cluster DP-Means), based in part on delayed creation of clusters. Compared with DP-Means, PDC-DP-Means provides not only a major speedup but also performance gains. Finally, we propose two extensions of PDC-DP-Means. The first combines it with an existing method, leading to further speedups. The second extends PDC-DP-Means to  a Mini-Batch setting (with an optional support for an online mode),  allowing for another major speedup. We verify the utility of the proposed methods on multiple datasets. We also show that the proposed methods outperform other nonparametric methods (e.g., DBSCAN). Our highly-efficient code can be used to reproduce our experiments and is available at https://github.com/BGU-CS-VIL/pdc-dp-means}\n}",
        "pdf": "https://proceedings.mlr.press/v180/dinari22b/dinari22b.pdf",
        "supp": "",
        "pdf_size": 766431,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=548820713812530408&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "The Department of Computer Science, Ben-Gurion University of the Negev, Be\u2019er Sheva, Israel; The Department of Computer Science, Ben-Gurion University of the Negev, Be\u2019er Sheva, Israel",
        "aff_domain": "; ",
        "email": "; ",
        "github": "https://github.com/BGU-CS-VIL/pdc-dp-means",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ben-Gurion University of the Negev",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bgu.ac.il",
        "aff_unique_abbr": "BGU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Be\u2019er Sheva",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "70267581ec",
        "title": "Revisiting the general identifiability problem",
        "site": "https://proceedings.mlr.press/v180/kivva22a.html",
        "author": "Yaroslav Kivva; Ehsan Mokhtarian; Jalal Etesami; Negar Kiyavash",
        "abstract": "We revisit the problem of general identifiability originally introduced in [Lee et al., 2019] for causal inference and note that it is necessary to add positivity assumption of observational distribution to the original definition of the problem. We show that without such an assumption the rules of do-calculus and consequently the proposed algorithm in [Lee et al., 2019] are not sound. Moreover, adding the assumption will cause the completeness proof in [Lee et al., 2019] to fail. Under positivity assumption, we present a new algorithm that is provably both sound and complete. A nice property of this new algorithm is that it establishes a connection between  general identifiability and classical identifiability by Pearl [1995] through decomposing the general identifiability problem into a series of classical identifiability  sub-problems.",
        "bibtex": "@InProceedings{pmlr-v180-kivva22a,\n  title = \t {Revisiting the general identifiability problem},\n  author =       {Kivva, Yaroslav and Mokhtarian, Ehsan and Etesami, Jalal and Kiyavash, Negar},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1022--1030},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/kivva22a/kivva22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/kivva22a.html},\n  abstract = \t {We revisit the problem of general identifiability originally introduced in [Lee et al., 2019] for causal inference and note that it is necessary to add positivity assumption of observational distribution to the original definition of the problem. We show that without such an assumption the rules of do-calculus and consequently the proposed algorithm in [Lee et al., 2019] are not sound. Moreover, adding the assumption will cause the completeness proof in [Lee et al., 2019] to fail. Under positivity assumption, we present a new algorithm that is provably both sound and complete. A nice property of this new algorithm is that it establishes a connection between  general identifiability and classical identifiability by Pearl [1995] through decomposing the general identifiability problem into a series of classical identifiability  sub-problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/kivva22a/kivva22a.pdf",
        "supp": "",
        "pdf_size": 323633,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11311561265064381663&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e410a3cc4e",
        "title": "Robust Bayesian recourse",
        "site": "https://proceedings.mlr.press/v180/nguyen22a.html",
        "author": "Tuan-Duy H. Nguyen; Ngoc Bui; Duy Nguyen; Man-Chung Yue; Viet Anh Nguyen",
        "abstract": "Algorithmic recourse aims to recommend an informative feedback to overturn an unfavorable machine learning decision. We introduce in this paper the Bayesian recourse, a model-agnostic recourse that minimizes the posterior probability odds ratio. Further, we present its min-max robust counterpart with the goal of hedging against future changes in the machine learning model parameters. The robust counterpart explicitly takes into account possible perturbations of the data in a Gaussian mixture ambiguity set prescribed using the optimal transport (Wasserstein) distance. We show that the resulting worst-case objective function can be decomposed into solving a series of two-dimensional optimization subproblems, and the min-max recourse finding problem is thus amenable to a gradient descent algorithm. Contrary to existing methods for generating robust recourses, the robust Bayesian recourse does not require a linear approximation step. The numerical experiment demonstrates the effectiveness of our proposed robust Bayesian recourse facing model shifts. Our code is available at https://github.com/VinAIResearch/robust-bayesian-recourse.",
        "bibtex": "@InProceedings{pmlr-v180-nguyen22a,\n  title = \t {Robust Bayesian recourse},\n  author =       {Nguyen, Tuan-Duy H. and Bui, Ngoc and Nguyen, Duy and Yue, Man-Chung and Nguyen, Viet Anh},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1498--1508},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/nguyen22a/nguyen22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/nguyen22a.html},\n  abstract = \t {Algorithmic recourse aims to recommend an informative feedback to overturn an unfavorable machine learning decision. We introduce in this paper the Bayesian recourse, a model-agnostic recourse that minimizes the posterior probability odds ratio. Further, we present its min-max robust counterpart with the goal of hedging against future changes in the machine learning model parameters. The robust counterpart explicitly takes into account possible perturbations of the data in a Gaussian mixture ambiguity set prescribed using the optimal transport (Wasserstein) distance. We show that the resulting worst-case objective function can be decomposed into solving a series of two-dimensional optimization subproblems, and the min-max recourse finding problem is thus amenable to a gradient descent algorithm. Contrary to existing methods for generating robust recourses, the robust Bayesian recourse does not require a linear approximation step. The numerical experiment demonstrates the effectiveness of our proposed robust Bayesian recourse facing model shifts. Our code is available at https://github.com/VinAIResearch/robust-bayesian-recourse.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/nguyen22a/nguyen22a.pdf",
        "supp": "",
        "pdf_size": 557751,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17429511419835942845&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "VinAI Research, Vietnam; VinAI Research, Vietnam; VinAI Research, Vietnam; The University of Hong Kong; VinAI Research, Vietnam",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/VinAIResearch/robust-bayesian-recourse",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "VinAI Research;University of Hong Kong",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.vin.ai;https://www.hku.hk",
        "aff_unique_abbr": "VinAI;HKU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Vietnam;China"
    },
    {
        "id": "c26a853c7b",
        "title": "Robust expected information gain for optimal Bayesian experimental design using ambiguity sets",
        "site": "https://proceedings.mlr.press/v180/go22a.html",
        "author": "Jinwoo Go; Tobin Isaac",
        "abstract": "The ranking of experiments by expected information gain (EIG) in Bayesian experimental design is sensitive to changes in the model\u2019s prior distribution, and the approximation of EIG yielded by sampling will have errors similar to the use of a perturbed prior. We define and analyze Robust Expected Information Gain(REIG), a modification of the objective in EIG maximization by minimizing an affine relaxation of EIG over an ambiguity set of distributions that are close to the original prior in KL-divergence. We show that, when combined with a sampling-based approach to estimating EIG, REIG corresponds to a \"log-sum-exp\" stabilization of the samples used to estimate EIG, meaning that it can be efficiently implemented in practice. Numerical tests combining REIG with variational nested Monte Carlo (VNMC), adaptive contrastive estimation (ACE) and mutual information neural estimation (MINE) suggest that in practice REIG also compensates for the variability of under-sampled estimators.",
        "bibtex": "@InProceedings{pmlr-v180-go22a,\n  title = \t {Robust expected information gain for optimal Bayesian experimental design using ambiguity sets},\n  author =       {Go, Jinwoo and Isaac, Tobin},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {728--737},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/go22a/go22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/go22a.html},\n  abstract = \t {The ranking of experiments by expected information gain (EIG) in Bayesian experimental design is sensitive to changes in the model\u2019s prior distribution, and the approximation of EIG yielded by sampling will have errors similar to the use of a perturbed prior. We define and analyze Robust Expected Information Gain(REIG), a modification of the objective in EIG maximization by minimizing an affine relaxation of EIG over an ambiguity set of distributions that are close to the original prior in KL-divergence. We show that, when combined with a sampling-based approach to estimating EIG, REIG corresponds to a \"log-sum-exp\" stabilization of the samples used to estimate EIG, meaning that it can be efficiently implemented in practice. Numerical tests combining REIG with variational nested Monte Carlo (VNMC), adaptive contrastive estimation (ACE) and mutual information neural estimation (MINE) suggest that in practice REIG also compensates for the variability of under-sampled estimators.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/go22a/go22a.pdf",
        "supp": "",
        "pdf_size": 884810,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13010449998216351363&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Computational Science and Engineering Dept., Georgia Institute of Technology, Atlanta, Georgia, USA; Computational Science and Engineering Dept., Georgia Institute of Technology, Atlanta, Georgia, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Computational Science and Engineering Dept.",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "41b4f4af35",
        "title": "Robust identifiability in linear structural equation models of causal inference",
        "site": "https://proceedings.mlr.press/v180/sankararaman22a.html",
        "author": "Karthik A. Sankararaman; Anand Louis; Navin Goyal",
        "abstract": "We consider the problem of robust parameter estimation from observational data in the context of linear structural equation models (LSEMs). Under various conditions on LSEMs and the model parameters the prior work provides efficient algorithms to recover the parameters. However, these results are often about generic identifiability. In practice, generic identifiability is not sufficient and we need robust identifiability: small changes in the observational data should not affect the parameters by a huge amount. Robust identifiability has received far less attention and remains poorly understood.  Sankararaman et al. (2019) recently provided a set of sufficient conditions on parameters under which robust identifiability is feasible. However, a limitation of their work is that their results only apply to a small sub-class of LSEMs, called \u201cbow-free paths.\u201d In this work, we show that for any \u201cbow-free model\u201d, in all but $\\frac{1}{\\poly(n)}$-measure of instances robust identifiability holds. Moreover, whenever an instance is robustly identifiable, the algorithm proposed in Foygel et al., (2012) can be used to recover the parameters in a robust fashion. In contrast, for generic identifiability Foygel et al., (2012) proved that with measure $1$, instances are generically identifiable. Thus, we show that robust identifiability is a strictly harder problem than generic identifiability. Finally, we validate our results on both simulated and real-world datasets.",
        "bibtex": "@InProceedings{pmlr-v180-sankararaman22a,\n  title = \t {Robust identifiability in linear structural equation models of causal inference},\n  author =       {Sankararaman, Karthik A. and Louis, Anand and Goyal, Navin},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1728--1737},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/sankararaman22a/sankararaman22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/sankararaman22a.html},\n  abstract = \t {We consider the problem of robust parameter estimation from observational data in the context of linear structural equation models (LSEMs). Under various conditions on LSEMs and the model parameters the prior work provides efficient algorithms to recover the parameters. However, these results are often about generic identifiability. In practice, generic identifiability is not sufficient and we need robust identifiability: small changes in the observational data should not affect the parameters by a huge amount. Robust identifiability has received far less attention and remains poorly understood.  Sankararaman et al. (2019) recently provided a set of sufficient conditions on parameters under which robust identifiability is feasible. However, a limitation of their work is that their results only apply to a small sub-class of LSEMs, called \u201cbow-free paths.\u201d In this work, we show that for any \u201cbow-free model\u201d, in all but $\\frac{1}{\\poly(n)}$-measure of instances robust identifiability holds. Moreover, whenever an instance is robustly identifiable, the algorithm proposed in Foygel et al., (2012) can be used to recover the parameters in a robust fashion. In contrast, for generic identifiability Foygel et al., (2012) proved that with measure $1$, instances are generically identifiable. Thus, we show that robust identifiability is a strictly harder problem than generic identifiability. Finally, we validate our results on both simulated and real-world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/sankararaman22a/sankararaman22a.pdf",
        "supp": "",
        "pdf_size": 612732,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13640046309986381958&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e2e4f63261",
        "title": "Robust learning of tractable probabilistic models",
        "site": "https://proceedings.mlr.press/v180/peddi22a.html",
        "author": "Rohith Peddi; Tahrima Rahman; Vibhav Gogate",
        "abstract": "Tractable probabilistic models (TPMs) compactly represent a joint probability distribution over a large number of random variables and admit polynomial  time computation of (1) exact likelihoods; (2) marginal probability distributions over a small subset of variables given evidence; and (3) in some cases most probable explanations over all non-observed variables given observations. In this paper, we leverage these tractability properties to solve the robust maximum likelihood parameter estimation task in TPMs under the assumption that a TPM structure and complete training data is provided as input. Specifically, we show that TPMs learned by optimizing the likelihood perform poorly when data is subject to adversarial attacks/noise/perturbations/corruption and we can address this issue by optimizing robust likelihood. To this end, we develop an efficient approach for constructing uncertainty sets that model data corruption in TPMs and derive an efficient gradient-based local search method for learning TPMs that are robust against these uncertainty sets. We empirically demonstrate the efficacy of our proposed approach on a collection of benchmark datasets.",
        "bibtex": "@InProceedings{pmlr-v180-peddi22a,\n  title = \t {Robust learning of tractable probabilistic models},\n  author =       {Peddi, Rohith and Rahman, Tahrima and Gogate, Vibhav},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1572--1581},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/peddi22a/peddi22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/peddi22a.html},\n  abstract = \t {Tractable probabilistic models (TPMs) compactly represent a joint probability distribution over a large number of random variables and admit polynomial  time computation of (1) exact likelihoods; (2) marginal probability distributions over a small subset of variables given evidence; and (3) in some cases most probable explanations over all non-observed variables given observations. In this paper, we leverage these tractability properties to solve the robust maximum likelihood parameter estimation task in TPMs under the assumption that a TPM structure and complete training data is provided as input. Specifically, we show that TPMs learned by optimizing the likelihood perform poorly when data is subject to adversarial attacks/noise/perturbations/corruption and we can address this issue by optimizing robust likelihood. To this end, we develop an efficient approach for constructing uncertainty sets that model data corruption in TPMs and derive an efficient gradient-based local search method for learning TPMs that are robust against these uncertainty sets. We empirically demonstrate the efficacy of our proposed approach on a collection of benchmark datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/peddi22a/peddi22a.pdf",
        "supp": "",
        "pdf_size": 275964,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14089914542463463920&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3e129f3129",
        "title": "Robust textual embedding against word-level adversarial attacks",
        "site": "https://proceedings.mlr.press/v180/yang22c.html",
        "author": "Yichen Yang; Xiaosen Wang; Kun He",
        "abstract": "We attribute the vulnerability of natural language processing models to the fact that similar inputs are converted to dissimilar representations in the embedding space, leading to inconsistent outputs, and we propose a novel robust training method, termed \\textit{Fast Triplet Metric Learning (FTML)}.  Specifically, we argue that the original sample should have similar representation with its adversarial counterparts and distinguish its representation from other samples for better robustness. To this end, we adopt the triplet metric learning into the standard training to pull words closer to their positive samples (\\textit{i.e.}, synonyms) and push away their negative samples (\\textit{i.e.}, non-synonyms) in the embedding space. Extensive experiments demonstrate that FTML can significantly promote the model robustness against various advanced adversarial attacks while keeping competitive classification accuracy on original samples. Besides, our method is efficient as it only needs to adjust the embedding and introduces very little overhead on the standard training. Our work shows great potential of improving the textual robustness through robust word embedding.",
        "bibtex": "@InProceedings{pmlr-v180-yang22c,\n  title = \t {Robust textual embedding against word-level adversarial attacks},\n  author =       {Yang, Yichen and Wang, Xiaosen and He, Kun},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2214--2224},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yang22c/yang22c.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yang22c.html},\n  abstract = \t {We attribute the vulnerability of natural language processing models to the fact that similar inputs are converted to dissimilar representations in the embedding space, leading to inconsistent outputs, and we propose a novel robust training method, termed \\textit{Fast Triplet Metric Learning (FTML)}.  Specifically, we argue that the original sample should have similar representation with its adversarial counterparts and distinguish its representation from other samples for better robustness. To this end, we adopt the triplet metric learning into the standard training to pull words closer to their positive samples (\\textit{i.e.}, synonyms) and push away their negative samples (\\textit{i.e.}, non-synonyms) in the embedding space. Extensive experiments demonstrate that FTML can significantly promote the model robustness against various advanced adversarial attacks while keeping competitive classification accuracy on original samples. Besides, our method is efficient as it only needs to adjust the embedding and introduces very little overhead on the standard training. Our work shows great potential of improving the textual robustness through robust word embedding.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yang22c/yang22c.pdf",
        "supp": "",
        "pdf_size": 397986,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1427796438267745155&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China",
        "aff_domain": "hust.edu.cn;hust.edu.cn;hust.edu.cn",
        "email": "hust.edu.cn;hust.edu.cn;hust.edu.cn",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Huazhong University of Science and Technology",
        "aff_unique_dep": "School of Computer Science and Technology",
        "aff_unique_url": "http://www.hust.edu.cn",
        "aff_unique_abbr": "HUST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Wuhan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "1b78fe794f",
        "title": "Robustness of model predictions under extension",
        "site": "https://proceedings.mlr.press/v180/blom22a.html",
        "author": "Tineke Blom; Joris M. Mooij",
        "abstract": "Mathematical models of the real world are simplified representations of complex systems. A caveat to using mathematical models is that predicted causal effects and conditional independences may not be robust under model extensions, limiting applicability of such models. In this work, we consider conditions under which qualitative model predictions are preserved when two models are combined. Under mild assumptions, we show how to use the technique of causal ordering to efficiently assess the robustness of qualitative model predictions. We also characterize a large class of model extensions that preserve qualitative model predictions. For dynamical systems at equilibrium, we demonstrate how novel insights help to select appropriate model extensions and to reason about the presence of feedback loops. We illustrate our ideas with a viral infection model with immune responses.",
        "bibtex": "@InProceedings{pmlr-v180-blom22a,\n  title = \t {Robustness of model predictions under extension},\n  author =       {Blom, Tineke and Mooij, Joris M.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {213--222},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/blom22a/blom22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/blom22a.html},\n  abstract = \t {Mathematical models of the real world are simplified representations of complex systems. A caveat to using mathematical models is that predicted causal effects and conditional independences may not be robust under model extensions, limiting applicability of such models. In this work, we consider conditions under which qualitative model predictions are preserved when two models are combined. Under mild assumptions, we show how to use the technique of causal ordering to efficiently assess the robustness of qualitative model predictions. We also characterize a large class of model extensions that preserve qualitative model predictions. For dynamical systems at equilibrium, we demonstrate how novel insights help to select appropriate model extensions and to reason about the presence of feedback loops. We illustrate our ideas with a viral infection model with immune responses.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/blom22a/blom22a.pdf",
        "supp": "",
        "pdf_size": 305043,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16770375337228946620&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Informatics Institute, University of Amsterdam, The Netherlands; Korteweg-De Vries Institute for Mathematics, University of Amsterdam, The Netherlands",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Amsterdam",
        "aff_unique_dep": "Informatics Institute",
        "aff_unique_url": "https://www.uva.nl",
        "aff_unique_abbr": "UvA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "3a9845f7e3",
        "title": "SASH: Efficient secure aggregation based on SHPRG for federated learning",
        "site": "https://proceedings.mlr.press/v180/liu22c.html",
        "author": "Zizhen Liu; Si Chen; Jing Ye; Junfeng Fan; Huawei Li; Xiaowei Li",
        "abstract": "To prevent private training data leakage in Federated Learning systems, we propose a novel secure aggregation scheme based on seed homomorphic pseudo-random generator (SHPRG), named SASH. SASH leverages the homomorphic property of SHPRG to simplify the masking and demasking scheme, which for each of the clients and for the server, entails a overhead linear w.r.t model size and constant w.r.t number of clients. We prove that even against worst-case colluding adversaries, SASH preserves training data privacy, while being resilient to dropouts without extra overhead. We experimentally demonstrate SASH significantly improves the efficiency to 20\u00d7 over baseline, especially in the more realistic case where the numbers of clients and model size become large, and a certain percentage of clients drop out from the system.",
        "bibtex": "@InProceedings{pmlr-v180-liu22c,\n  title = \t {SASH: Efficient secure aggregation based on SHPRG for federated learning},\n  author =       {Liu, Zizhen and Chen, Si and Ye, Jing and Fan, Junfeng and Li, Huawei and Li, Xiaowei},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1243--1252},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/liu22c/liu22c.pdf},\n  url = \t {https://proceedings.mlr.press/v180/liu22c.html},\n  abstract = \t {To prevent private training data leakage in Federated Learning systems, we propose a novel secure aggregation scheme based on seed homomorphic pseudo-random generator (SHPRG), named SASH. SASH leverages the homomorphic property of SHPRG to simplify the masking and demasking scheme, which for each of the clients and for the server, entails a overhead linear w.r.t model size and constant w.r.t number of clients. We prove that even against worst-case colluding adversaries, SASH preserves training data privacy, while being resilient to dropouts without extra overhead. We experimentally demonstrate SASH significantly improves the efficiency to 20\u00d7 over baseline, especially in the more realistic case where the numbers of clients and model size become large, and a certain percentage of clients drop out from the system.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/liu22c/liu22c.pdf",
        "supp": "",
        "pdf_size": 462094,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9965779436606181949&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0476a2f251",
        "title": "SENTINEL: taming uncertainty with ensemble based distributional reinforcement learning",
        "site": "https://proceedings.mlr.press/v180/eriksson22a.html",
        "author": "Hannes Eriksson; Debabrota Basu; Mina Alibeigi; Christos Dimitrakakis",
        "abstract": "In this paper, we consider risk-sensitive sequential decision-making in Reinforcement Learning (RL).  Our contributions are two-fold. First, we introduce a novel and coherent quantification of risk, namely composite risk, which quantifies the joint effect of aleatory and epistemic risk during the learning process. Existing works considered either aleatory or epistemic risk individually, or as an additive combination. We prove that the additive formulation is a particular case of the composite risk when the epistemic risk measure is replaced with expectation. Thus, the composite risk is more sensitive to both aleatory and epistemic uncertainty than the individual and additive formulations. We also propose an algorithm, SENTINEL-K, based on ensemble bootstrapping and distributional RL for representing epistemic and aleatory uncertainty respectively. The ensemble of K learners uses Follow The Regularised Leader (FTRL) to aggregate the return distributions and obtain the composite risk. We experimentally verify that SENTINEL-K estimates the return distribution better, and while used with composite risk estimates, demonstrates higher risk-sensitive performance than state-of-the-art risk-sensitive and distributional RL algorithms.",
        "bibtex": "@InProceedings{pmlr-v180-eriksson22a,\n  title = \t {SENTINEL: taming uncertainty with ensemble based distributional reinforcement learning},\n  author =       {Eriksson, Hannes and Basu, Debabrota and Alibeigi, Mina and Dimitrakakis, Christos},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {631--640},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/eriksson22a/eriksson22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/eriksson22a.html},\n  abstract = \t {In this paper, we consider risk-sensitive sequential decision-making in Reinforcement Learning (RL).  Our contributions are two-fold. First, we introduce a novel and coherent quantification of risk, namely composite risk, which quantifies the joint effect of aleatory and epistemic risk during the learning process. Existing works considered either aleatory or epistemic risk individually, or as an additive combination. We prove that the additive formulation is a particular case of the composite risk when the epistemic risk measure is replaced with expectation. Thus, the composite risk is more sensitive to both aleatory and epistemic uncertainty than the individual and additive formulations. We also propose an algorithm, SENTINEL-K, based on ensemble bootstrapping and distributional RL for representing epistemic and aleatory uncertainty respectively. The ensemble of K learners uses Follow The Regularised Leader (FTRL) to aggregate the return distributions and obtain the composite risk. We experimentally verify that SENTINEL-K estimates the return distribution better, and while used with composite risk estimates, demonstrates higher risk-sensitive performance than state-of-the-art risk-sensitive and distributional RL algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/eriksson22a/eriksson22a.pdf",
        "supp": "",
        "pdf_size": 566531,
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4231512895108469528&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f4d6698a2a",
        "title": "SMT-based weighted model integration with structure awareness",
        "site": "https://proceedings.mlr.press/v180/spallitta22a.html",
        "author": "Giuseppe Spallitta; Gabriele Masina; Paolo Morettin; Andrea Passerini; Roberto Sebastiani",
        "abstract": "Weighted Model Integration (WMI) is a popular formalism aimed at unifying approaches for probabilistic inference in hybrid domains, involving logical and algebraic constraints. Despite a considerable amount of recent work, allowing WMI algorithms to scale with the complexity of the hybrid problem is still a challenge. In this paper we highlight some substantial limitations of existing state-of-the-art solutions, and develop an algorithm that combines SMT-based enumeration, an efficient technique in formal verification, with an effective encoding of the problem structure.  This allows our algorithm to avoid generating redundant models, resulting in substantial computational savings. An extensive experimental evaluation on both synthetic and real-world datasets confirms the advantage of the proposed solution over existing alternatives.",
        "bibtex": "@InProceedings{pmlr-v180-spallitta22a,\n  title = \t {SMT-based weighted model integration with structure awareness},\n  author =       {Spallitta, Giuseppe and Masina, Gabriele and Morettin, Paolo and Passerini, Andrea and Sebastiani, Roberto},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1876--1885},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/spallitta22a/spallitta22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/spallitta22a.html},\n  abstract = \t {Weighted Model Integration (WMI) is a popular formalism aimed at unifying approaches for probabilistic inference in hybrid domains, involving logical and algebraic constraints. Despite a considerable amount of recent work, allowing WMI algorithms to scale with the complexity of the hybrid problem is still a challenge. In this paper we highlight some substantial limitations of existing state-of-the-art solutions, and develop an algorithm that combines SMT-based enumeration, an efficient technique in formal verification, with an effective encoding of the problem structure.  This allows our algorithm to avoid generating redundant models, resulting in substantial computational savings. An extensive experimental evaluation on both synthetic and real-world datasets confirms the advantage of the proposed solution over existing alternatives.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/spallitta22a/spallitta22a.pdf",
        "supp": "",
        "pdf_size": 1177773,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6283712330310834749&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "University of Trento; University of Trento; KU Leuven; University of Trento; University of Trento",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Trento;Katholieke Universiteit Leuven",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.unitn.it;https://www.kuleuven.be",
        "aff_unique_abbr": "UniTN;KU Leuven",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Italy;Belgium"
    },
    {
        "id": "cac6c9491d",
        "title": "ST-MAML : A stochastic-task based method for task-heterogeneous meta-learning",
        "site": "https://proceedings.mlr.press/v180/wang22c.html",
        "author": "Zhe Wang; Jake Grigsby; Arshdeep Sekhon; Yanjun Qi",
        "abstract": "Optimization-based meta-learning typically assumes tasks are sampled from a single distribution - an assumption that oversimplifies and limits the diversity of tasks that meta-learning can model. Handling tasks from multiple distributions is challenging for meta-learning because it adds ambiguity to task identities. This paper proposes a novel method, ST-MAML, that empowers model-agnostic meta-learning (MAML) to learn from multiple task distributions. ST-MAML encodes tasks using a stochastic neural network module, that summarizes every task with a stochastic representation. The proposed Stochastic Task (ST) strategy learns a distribution of solutions for an ambiguous task and allows a meta-model to self-adapt to the current task. ST-MAML also propagates the task representation to enhance input variable encodings. Empirically, we demonstrate that ST-MAML outperforms the state-of-the-art on two few-shot image classification tasks, one curve regression benchmark, one image completion problem, and a real-world temperature prediction application.",
        "bibtex": "@InProceedings{pmlr-v180-wang22c,\n  title = \t {ST-MAML : A stochastic-task based method for task-heterogeneous meta-learning},\n  author =       {Wang, Zhe and Grigsby, Jake and Sekhon, Arshdeep and Qi, Yanjun},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2066--2074},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/wang22c/wang22c.pdf},\n  url = \t {https://proceedings.mlr.press/v180/wang22c.html},\n  abstract = \t {Optimization-based meta-learning typically assumes tasks are sampled from a single distribution - an assumption that oversimplifies and limits the diversity of tasks that meta-learning can model. Handling tasks from multiple distributions is challenging for meta-learning because it adds ambiguity to task identities. This paper proposes a novel method, ST-MAML, that empowers model-agnostic meta-learning (MAML) to learn from multiple task distributions. ST-MAML encodes tasks using a stochastic neural network module, that summarizes every task with a stochastic representation. The proposed Stochastic Task (ST) strategy learns a distribution of solutions for an ambiguous task and allows a meta-model to self-adapt to the current task. ST-MAML also propagates the task representation to enhance input variable encodings. Empirically, we demonstrate that ST-MAML outperforms the state-of-the-art on two few-shot image classification tasks, one curve regression benchmark, one image completion problem, and a real-world temperature prediction application.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/wang22c/wang22c.pdf",
        "supp": "",
        "pdf_size": 2758692,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=857497944591770423&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cbcd4b0a55",
        "title": "Safety aware changepoint detection for piecewise i.i.d. bandits",
        "site": "https://proceedings.mlr.press/v180/mukherjee22a.html",
        "author": "Subhojyoti Mukherjee",
        "abstract": "In this paper, we consider the setting of piecewise i.i.d. bandits under a safety constraint. In this piecewise i.i.d. setting, there exists a finite number of changepoints where the mean of some or all arms change simultaneously. We introduce the safety constraint studied in Wu et al. (2016) to this setting such that at any round the cumulative reward is above a constant factor of the default action reward. We propose two actively adaptive algorithms for this setting that satisfy the safety constraint, detect changepoints, and restart without the knowledge of the number of changepoints or their locations. We provide regret bounds for our algorithms and show that the bounds are comparable to their counterparts from the safe bandit and piecewise i.i.d. bandit literature. We also provide the first matching lower bounds for this setting.  Empirically, we show that our safety-aware algorithms match the performance of the state-of-the-art actively adaptive algorithms that do not satisfy the safety constraint.",
        "bibtex": "@InProceedings{pmlr-v180-mukherjee22a,\n  title = \t {Safety aware changepoint detection for piecewise i.i.d. bandits},\n  author =       {Mukherjee, Subhojyoti},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1402--1412},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/mukherjee22a/mukherjee22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/mukherjee22a.html},\n  abstract = \t {In this paper, we consider the setting of piecewise i.i.d. bandits under a safety constraint. In this piecewise i.i.d. setting, there exists a finite number of changepoints where the mean of some or all arms change simultaneously. We introduce the safety constraint studied in Wu et al. (2016) to this setting such that at any round the cumulative reward is above a constant factor of the default action reward. We propose two actively adaptive algorithms for this setting that satisfy the safety constraint, detect changepoints, and restart without the knowledge of the number of changepoints or their locations. We provide regret bounds for our algorithms and show that the bounds are comparable to their counterparts from the safe bandit and piecewise i.i.d. bandit literature. We also provide the first matching lower bounds for this setting.  Empirically, we show that our safety-aware algorithms match the performance of the state-of-the-art actively adaptive algorithms that do not satisfy the safety constraint.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/mukherjee22a/mukherjee22a.pdf",
        "supp": "",
        "pdf_size": 904537,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=602806677127388352&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Electrical & Computer Engineering Department, UW-Madison, Madison, Wisconsin, USA",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Wisconsin-Madison",
        "aff_unique_dep": "Electrical & Computer Engineering Department",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW-Madison",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "483a134dd6",
        "title": "Self-distribution distillation: efficient uncertainty estimation",
        "site": "https://proceedings.mlr.press/v180/fathullah22a.html",
        "author": "Yassir Fathullah; Mark J. F. Gales",
        "abstract": "Deep learning is increasingly being applied in safety-critical domains. For these scenarios it is important to know the level of uncertainty in a model\u2019s prediction to ensure appropriate decisions are made by the system. Deep ensembles are the de-facto standard approach to obtaining various measures of uncertainty. However, ensembles often significantly increase the resources required in the training and/or deployment phases. Approaches have been developed that typically address the costs in one of these phases. In this work we propose a novel training approach, self-distribution distillation (S2D), which is able to efficiently train a single model that can estimate uncertainties. Furthermore it is possible to build ensembles of these models and apply hierarchical ensemble distillation approaches. Experiments on CIFAR-100 showed that S2D models outperformed standard models and Monte-Carlo dropout. Additional out-of-distribution detection experiments on LSUN, Tiny ImageNet, SVHN showed that even a standard deep ensemble can be outperformed using S2D based ensembles and novel distilled models.",
        "bibtex": "@InProceedings{pmlr-v180-fathullah22a,\n  title = \t {Self-distribution distillation: efficient uncertainty estimation},\n  author =       {Fathullah, Yassir and Gales, Mark J. F.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {663--673},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/fathullah22a/fathullah22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/fathullah22a.html},\n  abstract = \t {Deep learning is increasingly being applied in safety-critical domains. For these scenarios it is important to know the level of uncertainty in a model\u2019s prediction to ensure appropriate decisions are made by the system. Deep ensembles are the de-facto standard approach to obtaining various measures of uncertainty. However, ensembles often significantly increase the resources required in the training and/or deployment phases. Approaches have been developed that typically address the costs in one of these phases. In this work we propose a novel training approach, self-distribution distillation (S2D), which is able to efficiently train a single model that can estimate uncertainties. Furthermore it is possible to build ensembles of these models and apply hierarchical ensemble distillation approaches. Experiments on CIFAR-100 showed that S2D models outperformed standard models and Monte-Carlo dropout. Additional out-of-distribution detection experiments on LSUN, Tiny ImageNet, SVHN showed that even a standard deep ensemble can be outperformed using S2D based ensembles and novel distilled models.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/fathullah22a/fathullah22a.pdf",
        "supp": "",
        "pdf_size": 2532449,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13134736411002287454&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Engineering Department, University of Cambridge, UK; Engineering Department, University of Cambridge, UK",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "Engineering Department",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "c10da76eb0",
        "title": "Self-supervised representations for multi-view reinforcement learning",
        "site": "https://proceedings.mlr.press/v180/yang22b.html",
        "author": "Huanhuan Yang; Dianxi Shi; Guojun Xie; Yingxuan Peng; Yi Zhang; Yantai Yang; Shaowu Yang",
        "abstract": "Learning policies from raw, pixel images are quite important for the real-world application of deep reinforcement learning (RL). Standard model-free RL algorithms focus on single-view settings and unify the representation learning and policy learning into an end-to-end training process. However, such a learning paradigm is sample-inefficiency and sensitive to hyper-parameters when supervised merely by the reward signals. Based on this, we present Self-Supervised Representations (S2R) for multi-view reinforcement learning, a sample-efficient representation learning method for learning features from high-dimensional images. In S2R, we introduce a representation learning framework and define a novel multi-view auxiliary objective based on the multi-view image states and Conditional Entropy Bottleneck (CEB) principle. We integrate S2R with the deep RL agent to learn robust representations that preserve task-relevant information while discarding task-irrelevant information and find optimal policies that maximize the expected return. Empirically, we demonstrate the effectiveness of S2R in the visual DeepMind Control (DMControl) suite and show its better performance on the default DMControl tasks and their variants by replacing the tasks\u2019 default background with a random image or natural video.",
        "bibtex": "@InProceedings{pmlr-v180-yang22b,\n  title = \t {Self-supervised representations for multi-view reinforcement learning},\n  author =       {Yang, Huanhuan and Shi, Dianxi and Xie, Guojun and Peng, Yingxuan and Zhang, Yi and Yang, Yantai and Yang, Shaowu},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2203--2213},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yang22b/yang22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yang22b.html},\n  abstract = \t {Learning policies from raw, pixel images are quite important for the real-world application of deep reinforcement learning (RL). Standard model-free RL algorithms focus on single-view settings and unify the representation learning and policy learning into an end-to-end training process. However, such a learning paradigm is sample-inefficiency and sensitive to hyper-parameters when supervised merely by the reward signals. Based on this, we present Self-Supervised Representations (S2R) for multi-view reinforcement learning, a sample-efficient representation learning method for learning features from high-dimensional images. In S2R, we introduce a representation learning framework and define a novel multi-view auxiliary objective based on the multi-view image states and Conditional Entropy Bottleneck (CEB) principle. We integrate S2R with the deep RL agent to learn robust representations that preserve task-relevant information while discarding task-irrelevant information and find optimal policies that maximize the expected return. Empirically, we demonstrate the effectiveness of S2R in the visual DeepMind Control (DMControl) suite and show its better performance on the default DMControl tasks and their variants by replacing the tasks\u2019 default background with a random image or natural video.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yang22b/yang22b.pdf",
        "supp": "",
        "pdf_size": 11896425,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6461402419237958030&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "College of Computer, National University of Defense Technology, Changsha, China; Artificial Intelligence Research Center, Defense Innovation Institute, Beijing, China+Tianjin Artificial Intelligence Innovation Center, Tianjin, China+College of Computer, National University of Defense Technology, Changsha, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer, National University of Defense Technology, Changsha, China; Artificial Intelligence Research Center, Defense Innovation Institute, Beijing, China; Tianjin Artificial Intelligence Innovation Center, Tianjin, China; College of Computer, National University of Defense Technology, Changsha, China",
        "aff_domain": "nudt.edu.cn;nudt.edu.cn;nuaa.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn",
        "email": "nudt.edu.cn;nudt.edu.cn;nuaa.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn;nudt.edu.cn",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2+0;3;0;1;2;0",
        "aff_unique_norm": "National University of Defense Technology;Defense Innovation Institute;Tianjin Artificial Intelligence Innovation Center;Nanjing University of Aeronautics and Astronautics",
        "aff_unique_dep": "College of Computer;Artificial Intelligence Research Center;;College of Computer Science and Technology",
        "aff_unique_url": "http://www.nudt.edu.cn;;;http://www.nuaa.edu.cn",
        "aff_unique_abbr": "NUDT;;;NUAA",
        "aff_campus_unique_index": "0;1+2+0;3;0;1;2;0",
        "aff_campus_unique": "Changsha;Beijing;Tianjin;Nanjing",
        "aff_country_unique_index": "0;0+0+0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "dfbcafd394",
        "title": "Semi-supervised novelty detection using ensembles with regularized disagreement",
        "site": "https://proceedings.mlr.press/v180/tifrea22a.html",
        "author": "Alexandru Tifrea; Eric Stavarache; Fanny Yang",
        "abstract": "Deep neural networks often predict samples with high confidence even when they come from unseen classes and should instead be flagged for expert evaluation.  Current novelty detection algorithms cannot reliably identify such near OOD points unless they have access to labeled data that is similar to these novel samples. In this paper, we develop a new ensemble-based procedure for semi-supervised novelty detection (SSND) that successfully leverages a mixture of unlabeled ID and novel-class samples to achieve good detection performance.  In particular, we show how to achieve disagreement only on OOD data using early stopping regularization. While we prove this fact for a simple data distribution, our extensive experiments suggest that it holds true for more complex scenarios: our approach significantly outperforms state-of-the-art SSND methods on standard image data sets (SVHN/CIFAR-10/CIFAR-100) and medical image data sets with only a negligible increase in computation cost.",
        "bibtex": "@InProceedings{pmlr-v180-tifrea22a,\n  title = \t {Semi-supervised novelty detection using ensembles with regularized disagreement},\n  author =       {Tifrea, Alexandru and Stavarache, Eric and Yang, Fanny},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1939--1948},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/tifrea22a/tifrea22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/tifrea22a.html},\n  abstract = \t {Deep neural networks often predict samples with high confidence even when they come from unseen classes and should instead be flagged for expert evaluation.  Current novelty detection algorithms cannot reliably identify such near OOD points unless they have access to labeled data that is similar to these novel samples. In this paper, we develop a new ensemble-based procedure for semi-supervised novelty detection (SSND) that successfully leverages a mixture of unlabeled ID and novel-class samples to achieve good detection performance.  In particular, we show how to achieve disagreement only on OOD data using early stopping regularization. While we prove this fact for a simple data distribution, our extensive experiments suggest that it holds true for more complex scenarios: our approach significantly outperforms state-of-the-art SSND methods on standard image data sets (SVHN/CIFAR-10/CIFAR-100) and medical image data sets with only a negligible increase in computation cost.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/tifrea22a/tifrea22a.pdf",
        "supp": "",
        "pdf_size": 940999,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17856908764189646965&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "148f00cf87",
        "title": "Semiparametric causal sufficient dimension reduction of multidimensional treatments",
        "site": "https://proceedings.mlr.press/v180/nabi22a.html",
        "author": "Razieh Nabi; Todd McNutt; Ilya Shpitser",
        "abstract": "Cause-effect relationships are typically evaluated by comparing outcome responses to binary treatment values, representing two arms of a hypothetical randomized controlled trial. However, in certain applications, treatments of interest are continuous and multidimensional. For example, understanding the causal relationship between severity of radiation therapy, summarized by a multidimensional vector of radiation exposure values and post-treatment side effects is a problem of clinical interest in radiation oncology. An appropriate strategy for making interpretable causal conclusions is to reduce the dimension of treatment. If individual elements of a multidimensional treatment vector weakly affect the outcome, but the overall relationship between treatment and outcome is strong, careless approaches to dimension reduction may not preserve this relationship. Further, methods developed for regression problems do not directly transfer to causal inference due to confounding complications. In this paper, we use semiparametric inference theory for structural models to give a general approach to causal sufficient dimension reduction of a multidimensional treatment such that the cause-effect relationship between treatment and outcome is preserved. We illustrate the utility of our proposals through simulations and a real data application in radiation oncology.",
        "bibtex": "@InProceedings{pmlr-v180-nabi22a,\n  title = \t {Semiparametric causal sufficient dimension reduction of multidimensional treatments},\n  author =       {Nabi, Razieh and McNutt, Todd and Shpitser, Ilya},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1445--1455},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/nabi22a/nabi22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/nabi22a.html},\n  abstract = \t {Cause-effect relationships are typically evaluated by comparing outcome responses to binary treatment values, representing two arms of a hypothetical randomized controlled trial. However, in certain applications, treatments of interest are continuous and multidimensional. For example, understanding the causal relationship between severity of radiation therapy, summarized by a multidimensional vector of radiation exposure values and post-treatment side effects is a problem of clinical interest in radiation oncology. An appropriate strategy for making interpretable causal conclusions is to reduce the dimension of treatment. If individual elements of a multidimensional treatment vector weakly affect the outcome, but the overall relationship between treatment and outcome is strong, careless approaches to dimension reduction may not preserve this relationship. Further, methods developed for regression problems do not directly transfer to causal inference due to confounding complications. In this paper, we use semiparametric inference theory for structural models to give a general approach to causal sufficient dimension reduction of a multidimensional treatment such that the cause-effect relationship between treatment and outcome is preserved. We illustrate the utility of our proposals through simulations and a real data application in radiation oncology.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/nabi22a/nabi22a.pdf",
        "supp": "",
        "pdf_size": 617407,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17513509511422323437&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "218bddcde0",
        "title": "Sequential algorithmic modification with test data reuse",
        "site": "https://proceedings.mlr.press/v180/feng22a.html",
        "author": "Jean Feng; Gene Pennllo; Nicholas Petrick; Berkman Sahiner; Romain Pirracchio; Alexej Gossmann",
        "abstract": "After initial release of a machine learning algorithm, the model can be fine-tuned by retraining on subsequently gathered data, adding newly discovered features, or more. Each modification introduces a risk of deteriorating performance and must be validated on a test dataset. It may not always be practical to assemble a new dataset for testing each modification, especially when most modifications are minor or are implemented in rapid succession. Recent work has shown how one can repeatedly test modifications on the same dataset and protect against overfitting by (i) discretizing test results along a grid and (ii) applying a Bonferroni correction to adjust for the total number of modifications considered by an adaptive developer. However, the standard Bonferroni correction is overly conservative when most modifications are beneficial and/or highly correlated. This work investigates more powerful approaches using alpha-recycling and sequentially-rejective graphical procedures (SRGPs). We introduce two novel extensions that account for correlation between adaptively chosen algorithmic modifications: the first leverages the correlation between consecutive modifications using flexible fixed sequence tests, and the second leverages the correlation between the proposed modifications and those generated by a hypothetical prespecified model updating procedure. In empirical analyses, both SRGPs control the error rate of approving deleterious modifications and approve significantly more beneficial modifications than previous approaches.",
        "bibtex": "@InProceedings{pmlr-v180-feng22a,\n  title = \t {Sequential algorithmic modification with test data reuse},\n  author =       {Feng, Jean and Pennllo, Gene and Petrick, Nicholas and Sahiner, Berkman and Pirracchio, Romain and Gossmann, Alexej},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {674--684},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/feng22a/feng22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/feng22a.html},\n  abstract = \t { After initial release of a machine learning algorithm, the model can be fine-tuned by retraining on subsequently gathered data, adding newly discovered features, or more. Each modification introduces a risk of deteriorating performance and must be validated on a test dataset. It may not always be practical to assemble a new dataset for testing each modification, especially when most modifications are minor or are implemented in rapid succession. Recent work has shown how one can repeatedly test modifications on the same dataset and protect against overfitting by (i) discretizing test results along a grid and (ii) applying a Bonferroni correction to adjust for the total number of modifications considered by an adaptive developer. However, the standard Bonferroni correction is overly conservative when most modifications are beneficial and/or highly correlated. This work investigates more powerful approaches using alpha-recycling and sequentially-rejective graphical procedures (SRGPs). We introduce two novel extensions that account for correlation between adaptively chosen algorithmic modifications: the first leverages the correlation between consecutive modifications using flexible fixed sequence tests, and the second leverages the correlation between the proposed modifications and those generated by a hypothetical prespecified model updating procedure. In empirical analyses, both SRGPs control the error rate of approving deleterious modifications and approve significantly more beneficial modifications than previous approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/feng22a/feng22a.pdf",
        "supp": "",
        "pdf_size": 1566879,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1807819409881120950&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "635d5adde2",
        "title": "Set-valued prediction in hierarchical classification with constrained representation complexity",
        "site": "https://proceedings.mlr.press/v180/mortier22a.html",
        "author": "Thomas Mortier; Eyke H\u00fcllermeier; Krzysztof Dembczy\u0144ski; Willem Waegeman",
        "abstract": "Set-valued prediction is a well-known concept in multi-class classification. When a classifier is uncertain about the class label for a test instance, it can predict a set of classes instead of a single class. In this paper, we focus on hierarchical multi-class classification problems, where valid sets (typically) correspond to internal nodes of the hierarchy. We argue that this is a very strong restriction, and we propose a relaxation by introducing the notion of representation complexity for a predicted set. In combination with probabilistic classifiers, this leads to a challenging inference problem for which specific combinatorial optimization algorithms are needed. We propose three methods and evaluate them on benchmark datasets: a na\u00efve approach that is based on matrix-vector multiplication, a reformulation as a knapsack problem with conflict graph, and a recursive tree search method. Experimental results demonstrate that the last method is computationally more efficient than the other two approaches, due to a hierarchical factorization of the conditional class distribution.",
        "bibtex": "@InProceedings{pmlr-v180-mortier22a,\n  title = \t {Set-valued prediction in hierarchical classification with constrained representation complexity},\n  author =       {Mortier, Thomas and H\\\"ullermeier, Eyke and Dembczy\\'nski, Krzysztof and Waegeman, Willem},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1392--1401},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/mortier22a/mortier22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/mortier22a.html},\n  abstract = \t {Set-valued prediction is a well-known concept in multi-class classification. When a classifier is uncertain about the class label for a test instance, it can predict a set of classes instead of a single class. In this paper, we focus on hierarchical multi-class classification problems, where valid sets (typically) correspond to internal nodes of the hierarchy. We argue that this is a very strong restriction, and we propose a relaxation by introducing the notion of representation complexity for a predicted set. In combination with probabilistic classifiers, this leads to a challenging inference problem for which specific combinatorial optimization algorithms are needed. We propose three methods and evaluate them on benchmark datasets: a na\u00efve approach that is based on matrix-vector multiplication, a reformulation as a knapsack problem with conflict graph, and a recursive tree search method. Experimental results demonstrate that the last method is computationally more efficient than the other two approaches, due to a hierarchical factorization of the conditional class distribution.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/mortier22a/mortier22a.pdf",
        "supp": "",
        "pdf_size": 600386,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16010001113425714423&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "173a2c0c00",
        "title": "Shifted compression framework: generalizations and improvements",
        "site": "https://proceedings.mlr.press/v180/shulgin22a.html",
        "author": "Egor Shulgin; Peter Richt\u00e1rik",
        "abstract": "Communication is one of the key bottlenecks in the distributed training of large-scale machine learning models, and lossy compression of exchanged information, such as stochastic gradients or models, is one of the most effective instruments to alleviate this issue. Among the most studied compression techniques is the class of unbiased compression operators with variance bounded by a multiple of the square norm of the vector we wish to compress. By design, this variance may remain high, and only diminishes if the input vector approaches zero. However, unless the model being trained is overparameterized, there is no a-priori reason for the vectors we wish to compress to approach zero during the iterations of classical methods such as distributed compressed {\\sf SGD}, which has adverse effects on the convergence speed. Due to this issue, several more elaborate and seemingly very different algorithms have been proposed recently, with the goal of circumventing this issue. These methods are based on the idea of compressing the {\\em difference} between the vector we would normally wish to compress and some auxiliary vector which changes throughout the iterative process. In this work we take a step back, and develop a unified framework for studying such methods, conceptually, and theoretically. Our framework incorporates methods compressing both gradients and models, using unbiased and biased compressors, and sheds light on the construction of the auxiliary vectors. Furthermore, our general framework can lead to the improvement of several existing algorithms, and can produce new algorithms. Finally, we performed several numerical experiments which illustrate and support our theoretical findings.",
        "bibtex": "@InProceedings{pmlr-v180-shulgin22a,\n  title = \t {Shifted compression framework: generalizations and improvements},\n  author =       {Shulgin, Egor and Richt{\\'a}rik, Peter},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1813--1823},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/shulgin22a/shulgin22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/shulgin22a.html},\n  abstract = \t {Communication is one of the key bottlenecks in the distributed training of large-scale machine learning models, and lossy compression of exchanged information, such as stochastic gradients or models, is one of the most effective instruments to alleviate this issue. Among the most studied compression techniques is the class of unbiased compression operators with variance bounded by a multiple of the square norm of the vector we wish to compress. By design, this variance may remain high, and only diminishes if the input vector approaches zero. However, unless the model being trained is overparameterized, there is no a-priori reason for the vectors we wish to compress to approach zero during the iterations of classical methods such as distributed compressed {\\sf SGD}, which has adverse effects on the convergence speed. Due to this issue, several more elaborate and seemingly very different algorithms have been proposed recently, with the goal of circumventing this issue. These methods are based on the idea of compressing the {\\em difference} between the vector we would normally wish to compress and some auxiliary vector which changes throughout the iterative process. In this work we take a step back, and develop a unified framework for studying such methods, conceptually, and theoretically. Our framework incorporates methods compressing both gradients and models, using unbiased and biased compressors, and sheds light on the construction of the auxiliary vectors. Furthermore, our general framework can lead to the improvement of several existing algorithms, and can produce new algorithms. Finally, we performed several numerical experiments which illustrate and support our theoretical findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/shulgin22a/shulgin22a.pdf",
        "supp": "",
        "pdf_size": 526361,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13591638677117539753&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia; King Abdullah University of Science and Technology (KAUST), Thuwal, Saudi Arabia",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "King Abdullah University of Science and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kaust.edu.sa",
        "aff_unique_abbr": "KAUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Thuwal",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Saudi Arabia"
    },
    {
        "id": "bf62fd257a",
        "title": "Shoring up the foundations: fusing model embeddings and weak supervision",
        "site": "https://proceedings.mlr.press/v180/chen22e.html",
        "author": "Mayee F. Chen; Daniel Y. Fu; Dyah Adila; Michael Zhang; Frederic Sala; Kayvon Fatahalian; Christopher R\u00e9",
        "abstract": "Foundation models offer an exciting new paradigm for constructing models with out-of-the-box embeddings and a few labeled examples. However, it is not clear how to best apply foundation models without labeled data. A potential approach is to fuse foundation models with weak supervision frameworks, which use weak label sources\u2014pre-trained models, heuristics, crowd-workers\u2014to construct pseudolabels. The challenge is building a combination that best exploits the signal available in both foundation models and weak sources. We propose LIGER, a combination that uses foundation model embeddings to improve two crucial elements of existing weak supervision techniques. First, we produce finer estimates of weak source quality by partitioning the embedding space and learning per-part source accuracies. Second, we improve source coverage by extending source votes in embedding space. Despite the black-box nature of foundation models, we prove results characterizing how our approach improves performance and show that lift scales with the smoothness of label distributions in embedding space. On six benchmark NLP and video tasks, LIGER outperforms vanilla weak supervision by 14.1 points, weakly-supervised kNN and adapters by 11.8 points, and kNN and adapters supervised by traditional hand labels by 7.2 points.",
        "bibtex": "@InProceedings{pmlr-v180-chen22e,\n  title = \t {Shoring up the foundations: fusing model embeddings and weak supervision},\n  author =       {Chen, Mayee F. and Fu, Daniel Y. and Adila, Dyah and Zhang, Michael and Sala, Frederic and Fatahalian, Kayvon and R\\'e, Christopher},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {357--367},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/chen22e/chen22e.pdf},\n  url = \t {https://proceedings.mlr.press/v180/chen22e.html},\n  abstract = \t {Foundation models offer an exciting new paradigm for constructing models with out-of-the-box embeddings and a few labeled examples. However, it is not clear how to best apply foundation models without labeled data. A potential approach is to fuse foundation models with weak supervision frameworks, which use weak label sources\u2014pre-trained models, heuristics, crowd-workers\u2014to construct pseudolabels. The challenge is building a combination that best exploits the signal available in both foundation models and weak sources. We propose LIGER, a combination that uses foundation model embeddings to improve two crucial elements of existing weak supervision techniques. First, we produce finer estimates of weak source quality by partitioning the embedding space and learning per-part source accuracies. Second, we improve source coverage by extending source votes in embedding space. Despite the black-box nature of foundation models, we prove results characterizing how our approach improves performance and show that lift scales with the smoothness of label distributions in embedding space. On six benchmark NLP and video tasks, LIGER outperforms vanilla weak supervision by 14.1 points, weakly-supervised kNN and adapters by 11.8 points, and kNN and adapters supervised by traditional hand labels by 7.2 points.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/chen22e/chen22e.pdf",
        "supp": "",
        "pdf_size": 1433140,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2223770555891262626&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "https://arxiv.org/abs/2006.15168",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ffb376f079",
        "title": "Simplified and unified analysis of various learning problems by reduction to Multiple-Instance Learning",
        "site": "https://proceedings.mlr.press/v180/suehiro22a.html",
        "author": "Daiki Suehiro; Eiji Takimoto",
        "abstract": "In statistical learning, many problem formulations have been proposed so far, such as multi-class learning, complementarily labeled learning, multi-label learning, multi-task learning, which provide theoretical models for various real-world tasks. Although they have been extensively studied, the relationship among them has not been fully investigated. In this work, we focus on a particular problem formulation called Multiple-Instance Learning (MIL), and show that various learning problems including all the problems mentioned above with some of new problems can be reduced to MIL with theoretically guaranteed generalization bounds, where the reductions are established under a new reduction scheme we provide as a by-product. The results imply that the MIL-reduction gives a simplified and unified framework for designing and analyzing algorithms for various learning problems. Moreover, we show that the MIL-reduction framework can be kernelized.",
        "bibtex": "@InProceedings{pmlr-v180-suehiro22a,\n  title = \t {Simplified and unified analysis of various learning problems by reduction to Multiple-Instance Learning},\n  author =       {Suehiro, Daiki and Takimoto, Eiji},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1896--1906},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/suehiro22a/suehiro22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/suehiro22a.html},\n  abstract = \t {In statistical learning, many problem formulations have been proposed so far, such as multi-class learning, complementarily labeled learning, multi-label learning, multi-task learning, which provide theoretical models for various real-world tasks. Although they have been extensively studied, the relationship among them has not been fully investigated. In this work, we focus on a particular problem formulation called Multiple-Instance Learning (MIL), and show that various learning problems including all the problems mentioned above with some of new problems can be reduced to MIL with theoretically guaranteed generalization bounds, where the reductions are established under a new reduction scheme we provide as a by-product. The results imply that the MIL-reduction gives a simplified and unified framework for designing and analyzing algorithms for various learning problems. Moreover, we show that the MIL-reduction framework can be kernelized.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/suehiro22a/suehiro22a.pdf",
        "supp": "",
        "pdf_size": 344666,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7939480386112305238&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Kyushu University, Department of Advanced Information Technology; RIKEN, Center for Advanced Intelligence Project + Kyushu University, Department of Informatics",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+0",
        "aff_unique_norm": "Kyushu University;RIKEN",
        "aff_unique_dep": "Department of Advanced Information Technology;Center for Advanced Intelligence Project",
        "aff_unique_url": "https://www.kyushu-u.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "Kyushu U;RIKEN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "43ec112fe2",
        "title": "Solving structured hierarchical games using differential backward induction",
        "site": "https://proceedings.mlr.press/v180/li22a.html",
        "author": "Zun Li; Feiran Jia; Aditya Mate; Shahin Jabbari; Mithun Chakraborty; Milind Tambe; Yevgeniy Vorobeychik",
        "abstract": "From large-scale organizations to decentralized political systems, hierarchical strategic decision making is commonplace. We introduce a novel class of structured hierarchical games (SHGs) that formally capture such hierarchical strategic interactions. In an SHG, each player is a node in a tree, and strategic choices of players are sequenced from root to leaves, with root moving first, followed by its children, then followed by their children, and so on until the leaves. A player\u2019s utility in an SHG depends on its own decision, and on the choices of its parent and all the tree leaves. SHGs thus generalize simultaneous-move games, as well as Stackelberg games with many followers.  We leverage the structure of both the sequence of player moves as well as payoff dependence to develop a gradient-based back propagation-style algorithm, which we call Differential Backward Induction (DBI), for approximating equilibria of SHGs. We provide a sufficient condition for convergence of DBI and  demonstrate its efficacy in finding approximate equilibrium solutions to several SHG models of hierarchical policy-making problems.",
        "bibtex": "@InProceedings{pmlr-v180-li22a,\n  title = \t {Solving structured hierarchical games using differential backward induction},\n  author =       {Li, Zun and Jia, Feiran and Mate, Aditya and Jabbari, Shahin and Chakraborty, Mithun and Tambe, Milind and Vorobeychik, Yevgeniy},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1107--1117},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/li22a/li22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/li22a.html},\n  abstract = \t {From large-scale organizations to decentralized political systems, hierarchical strategic decision making is commonplace. We introduce a novel class of structured hierarchical games (SHGs) that formally capture such hierarchical strategic interactions. In an SHG, each player is a node in a tree, and strategic choices of players are sequenced from root to leaves, with root moving first, followed by its children, then followed by their children, and so on until the leaves. A player\u2019s utility in an SHG depends on its own decision, and on the choices of its parent and all the tree leaves. SHGs thus generalize simultaneous-move games, as well as Stackelberg games with many followers.  We leverage the structure of both the sequence of player moves as well as payoff dependence to develop a gradient-based back propagation-style algorithm, which we call Differential Backward Induction (DBI), for approximating equilibria of SHGs. We provide a sufficient condition for convergence of DBI and  demonstrate its efficacy in finding approximate equilibrium solutions to several SHG models of hierarchical policy-making problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/li22a/li22a.pdf",
        "supp": "",
        "pdf_size": 1100394,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7137263145577390002&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "University of Michigan, Ann Arbor; Pennsylvania State University; Harvard University; Drexel University; University of Michigan, Ann Arbor; Harvard University; Washington University in St. Louis",
        "aff_domain": "umich.edu;psu.edu;g.harvard.edu;drexel.edu;umich.edu;g.harvard.edu;wustl.edu",
        "email": "umich.edu;psu.edu;g.harvard.edu;drexel.edu;umich.edu;g.harvard.edu;wustl.edu",
        "github": "",
        "project": "https://arxiv.org/abs/2106.04663",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;0;2;4",
        "aff_unique_norm": "University of Michigan;Pennsylvania State University;Harvard University;Drexel University;Washington University in St. Louis",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.umich.edu;https://www.psu.edu;https://www.harvard.edu;https://www.drexel.edu;https://wustl.edu",
        "aff_unique_abbr": "UM;PSU;Harvard;Drexel;WashU",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Ann Arbor;;St. Louis",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d996bc62c1",
        "title": "Stability of SGD: Tightness analysis and improved bounds",
        "site": "https://proceedings.mlr.press/v180/zhang22b.html",
        "author": "Yikai Zhang; Wenjia Zhang; Sammy Bald; Vamsi Pingali; Chao Chen; Mayank Goswami",
        "abstract": "Stochastic Gradient Descent (SGD) based methods have been widely used for training large-scale machine learning models that also generalize well in practice. Several explanations have been offered for this generalization performance, a prominent one being algorithmic stability Hardt et al [2016]. However, there are no known examples of smooth loss functions for which the analysis can be shown to be tight. Furthermore, apart from properties of the loss function, data distribution has also been shown to be an important factor in generalization performance. This raises the question: is the stability analysis of Hardt et al [2016] tight for smooth functions, and if not, for what kind of loss functions and data distributions can the stability analysis be improved? In this paper we first settle open questions regarding tightness of bounds in the data-independent setting: we show that for general datasets, the existing analysis for convex and strongly-convex loss functions is tight, but it can be improved for non-convex loss functions. Next, we give novel and improved data-dependent bounds: we show stability upper bounds for a large class of convex regularized loss functions, with negligible  regularization parameters, and improve existing data-dependent bounds in the non-convex setting. We hope that our results will initiate further efforts to better understand the data-dependent setting under non-convex loss functions, leading to an improved understanding of the generalization abilities of deep networks.",
        "bibtex": "@InProceedings{pmlr-v180-zhang22b,\n  title = \t {Stability of {SGD}: Tightness analysis and improved bounds},\n  author =       {Zhang, Yikai and Zhang, Wenjia and Bald, Sammy and Pingali, Vamsi and Chen, Chao and Goswami, Mayank},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2364--2373},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/zhang22b/zhang22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/zhang22b.html},\n  abstract = \t {Stochastic Gradient Descent (SGD) based methods have been widely used for training large-scale machine learning models that also generalize well in practice. Several explanations have been offered for this generalization performance, a prominent one being algorithmic stability Hardt et al [2016]. However, there are no known examples of smooth loss functions for which the analysis can be shown to be tight. Furthermore, apart from properties of the loss function, data distribution has also been shown to be an important factor in generalization performance. This raises the question: is the stability analysis of Hardt et al [2016] tight for smooth functions, and if not, for what kind of loss functions and data distributions can the stability analysis be improved? In this paper we first settle open questions regarding tightness of bounds in the data-independent setting: we show that for general datasets, the existing analysis for convex and strongly-convex loss functions is tight, but it can be improved for non-convex loss functions. Next, we give novel and improved data-dependent bounds: we show stability upper bounds for a large class of convex regularized loss functions, with negligible  regularization parameters, and improve existing data-dependent bounds in the non-convex setting. We hope that our results will initiate further efforts to better understand the data-dependent setting under non-convex loss functions, leading to an improved understanding of the generalization abilities of deep networks.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/zhang22b/zhang22b.pdf",
        "supp": "",
        "pdf_size": 256547,
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1643917212778464107&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Machine Learning Research., Morgan Stanley; Computer Science Dept., Rutgers University; Computer Science Dept., Queens College of CUNY; Mathematics Dept., Indian Institue of Science; Biomedical Informatics Dept., Stony Brook University; Computer Science Dept., Queens College of CUNY",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;4;2",
        "aff_unique_norm": "Morgan Stanley;Rutgers University;Queens College of the City University of New York;Indian Institute of Science;Stony Brook University",
        "aff_unique_dep": "Machine Learning Research;Computer Science Dept.;Computer Science Department;Mathematics Dept.;Biomedical Informatics Department",
        "aff_unique_url": "https://www.morganstanley.com;https://www.rutgers.edu;https://www.qc.cuny.edu;https://www.iisc.ac.in;https://www.stonybrook.edu",
        "aff_unique_abbr": "MS;Rutgers;Queens College;IISc;SBU",
        "aff_campus_unique_index": "1;2;1",
        "aff_campus_unique": ";Queens;Stony Brook",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "cf8e14db98",
        "title": "Stackmix: a complementary mix algorithm",
        "site": "https://proceedings.mlr.press/v180/chen22b.html",
        "author": "John Chen; Samarth Sinha; Anastasios Kyrillidis",
        "abstract": "Techniques combining multiple images as input/output have proven to be effective data augmentations for training convolutional neural networks. In this paper, we present StackMix: each input is presented as a concatenation of two images, and the label is the mean of the two one-hot labels. On its own, StackMix rivals other widely used methods in the \u201cMix\u201d line of work. More importantly, unlike previous work, significant gains across a variety of benchmarks are achieved by combining StackMix with existing Mix augmentation, effectively mixing more than two images. E.g., by combining StackMix with CutMix, test error in the supervised setting is improved across a variety of settings over CutMix, including 0.8% on ImageNet, 3% on Tiny ImageNet, 2% on CIFAR-100, 0.5% on CIFAR-10, and 1.5% on STL-10. Similar results are achieved with Mixup. We further show that gains hold for robustness to common input corruptions and perturbations at varying severities with a 0.7% improvement on CIFAR-100-C, by combining StackMix with AugMix over AugMix. On its own, improvements with StackMix hold across different number of labeled samples on CIFAR-100, maintaining approximately a 2% gap in test accuracy \u2013down to using only 5% of the whole dataset\u2013 and is effective in the semi-supervised setting with a 2% improvement with the standard benchmark Pi-model. Finally, we perform an extensive ablation study to better understand the proposed methodology.",
        "bibtex": "@InProceedings{pmlr-v180-chen22b,\n  title = \t {Stackmix: a complementary mix algorithm},\n  author =       {Chen, John and Sinha, Samarth and Kyrillidis, Anastasios},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {326--335},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/chen22b/chen22b.pdf},\n  url = \t {https://proceedings.mlr.press/v180/chen22b.html},\n  abstract = \t {Techniques combining multiple images as input/output have proven to be effective data augmentations for training convolutional neural networks. In this paper, we present StackMix: each input is presented as a concatenation of two images, and the label is the mean of the two one-hot labels. On its own, StackMix rivals other widely used methods in the \u201cMix\u201d line of work. More importantly, unlike previous work, significant gains across a variety of benchmarks are achieved by combining StackMix with existing Mix augmentation, effectively mixing more than two images. E.g., by combining StackMix with CutMix, test error in the supervised setting is improved across a variety of settings over CutMix, including 0.8% on ImageNet, 3% on Tiny ImageNet, 2% on CIFAR-100, 0.5% on CIFAR-10, and 1.5% on STL-10. Similar results are achieved with Mixup. We further show that gains hold for robustness to common input corruptions and perturbations at varying severities with a 0.7% improvement on CIFAR-100-C, by combining StackMix with AugMix over AugMix. On its own, improvements with StackMix hold across different number of labeled samples on CIFAR-100, maintaining approximately a 2% gap in test accuracy \u2013down to using only 5% of the whole dataset\u2013 and is effective in the semi-supervised setting with a 2% improvement with the standard benchmark Pi-model. Finally, we perform an extensive ablation study to better understand the proposed methodology.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/chen22b/chen22b.pdf",
        "supp": "",
        "pdf_size": 1777321,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8872034140224137295&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "Computer Science Dept., Rice University, USA; Computer Science Dept., University of Toronto, Canada; Computer Science Dept., Rice University, USA",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Rice University;University of Toronto",
        "aff_unique_dep": "Computer Science Dept.;Computer Science Dept.",
        "aff_unique_url": "https://www.rice.edu;https://www.utoronto.ca",
        "aff_unique_abbr": "Rice;U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "3dfd72b0a6",
        "title": "Sublinear time algorithms for greedy selection in high dimensions",
        "site": "https://proceedings.mlr.press/v180/chen22d.html",
        "author": "Qi Chen; Kai Liu; Ruilong Yao; Hu Ding",
        "abstract": "Greedy selection is a widely used idea for solving many machine learning problems. But greedy selection algorithms often have high complexities and thus may be prohibitive for large-scale data. In this paper, we consider two fundamental optimization problems in machine learning: k-center clustering and convex hull approximation, where they both can be solved via greedy selection. We propose sublinear time algorithms for them through combining the strategies of randomization and greedy selection. Our results are similar in spirit to the linear time stochastic greedy selection algorithms for submodular maximization, but with several important differences. Our runtimes are independent of the number of input data items n. In particular, our runtime for k-center clustering significantly improves upon that of the uniform sampling approach, especially when the dimensionality is high. Our sublinear algorithms can also reduce the computational complexities for various applications, such as data selection and compression, active learning, and topic modeling, etc.",
        "bibtex": "@InProceedings{pmlr-v180-chen22d,\n  title = \t {Sublinear time algorithms for greedy selection in high dimensions},\n  author =       {Chen, Qi and Liu, Kai and Yao, Ruilong and Ding, Hu},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {346--356},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/chen22d/chen22d.pdf},\n  url = \t {https://proceedings.mlr.press/v180/chen22d.html},\n  abstract = \t {Greedy selection is a widely used idea for solving many machine learning problems. But greedy selection algorithms often have high complexities and thus may be prohibitive for large-scale data. In this paper, we consider two fundamental optimization problems in machine learning: k-center clustering and convex hull approximation, where they both can be solved via greedy selection. We propose sublinear time algorithms for them through combining the strategies of randomization and greedy selection. Our results are similar in spirit to the linear time stochastic greedy selection algorithms for submodular maximization, but with several important differences. Our runtimes are independent of the number of input data items n. In particular, our runtime for k-center clustering significantly improves upon that of the uniform sampling approach, especially when the dimensionality is high. Our sublinear algorithms can also reduce the computational complexities for various applications, such as data selection and compression, active learning, and topic modeling, etc.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/chen22d/chen22d.pdf",
        "supp": "",
        "pdf_size": 590570,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:TgkWM8ywohoJ:scholar.google.com/&scioq=Sublinear+time+algorithms+for+greedy+selection+in+high+dimensions&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": "School of Data Science, University of Science and Technology of China, Anhui, China; School of Computer Science and Technology, University of Science and Technology of China, Anhui, China; School of Computer Science and Technology, University of Science and Technology of China, Anhui, China; School of Computer Science and Technology, University of Science and Technology of China, Anhui, China",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "School of Data Science",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Anhui",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "801bcea167",
        "title": "Superposing many tickets into one: A performance booster for sparse neural network training",
        "site": "https://proceedings.mlr.press/v180/yin22a.html",
        "author": "Lu Yin; Vlado Menkovski; Meng Fang; Tianjin Huang; Yulong Pei; Mykola Pechenizkiy",
        "abstract": "Recent works on sparse neural network training have shown that a compelling trade-off between performance and efficiency can be achieved. Existing sparse training methods usually strive to find the best sparse subnetwork possible in one single run, without involving any expensive dense or pre-training steps. For instance, dynamic sparse training (DST), as one of the most prominent directions,  is capable of reaching a competitive performance of dense training by iteratively evolving the sparse topology during the course of training. In this paper, we argue that it is better to allocate the limited resources to create multiple low-loss sparse subnetworks and superpose them into a stronger one, instead of allocating all resources entirely to find an individual subnetwork. To achieve this, two desiderata are required: (1) efficiently producing many low-loss subnetworks, the so-called cheap tickets, within one training process limited to the standard training time used in dense training; (2) effectively superposing these cheap tickets into one stronger subnetwork without going over the constrained parameter budget. To corroborate our conjecture, we present a novel sparse training approach, termed \\textbf{Sup-tickets}, which can satisfy the above two desiderata concurrently in a single sparse-to-sparse training process. Across various models on CIFAR-10/100 and ImageNet, we show that Sup-tickets integrates seamlessly with the existing sparse training methods and demonstrates consistent performance improvement.",
        "bibtex": "@InProceedings{pmlr-v180-yin22a,\n  title = \t {Superposing many tickets into one: A performance booster for sparse neural network training},\n  author =       {Yin, Lu and Menkovski, Vlado and Fang, Meng and Huang, Tianjin and Pei, Yulong and Pechenizkiy, Mykola},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2267--2277},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/yin22a/yin22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/yin22a.html},\n  abstract = \t {Recent works on sparse neural network training have shown that a compelling trade-off between performance and efficiency can be achieved. Existing sparse training methods usually strive to find the best sparse subnetwork possible in one single run, without involving any expensive dense or pre-training steps. For instance, dynamic sparse training (DST), as one of the most prominent directions,  is capable of reaching a competitive performance of dense training by iteratively evolving the sparse topology during the course of training. In this paper, we argue that it is better to allocate the limited resources to create multiple low-loss sparse subnetworks and superpose them into a stronger one, instead of allocating all resources entirely to find an individual subnetwork. To achieve this, two desiderata are required: (1) efficiently producing many low-loss subnetworks, the so-called cheap tickets, within one training process limited to the standard training time used in dense training; (2) effectively superposing these cheap tickets into one stronger subnetwork without going over the constrained parameter budget. To corroborate our conjecture, we present a novel sparse training approach, termed \\textbf{Sup-tickets}, which can satisfy the above two desiderata concurrently in a single sparse-to-sparse training process. Across various models on CIFAR-10/100 and ImageNet, we show that Sup-tickets integrates seamlessly with the existing sparse training methods and demonstrates consistent performance improvement.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/yin22a/yin22a.pdf",
        "supp": "",
        "pdf_size": 460092,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=215633522840102055&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "95a118c6fe",
        "title": "SymNet 2.0: Effectively handling Non-Fluents and Actions in Generalized Neural Policies for RDDL Relational MDPs",
        "site": "https://proceedings.mlr.press/v180/sharma22a.html",
        "author": "Vishal Sharma; Daman Arora; Florian Gei\u00dfer; Mausam ; Parag Singla",
        "abstract": "Relational MDPs (RMDPs) compactly represent an infinite set of MDPs with an unbounded number of objects. Solving an RMDP requires a generalized policy that applies to all instances of a domain. Recently, Garg et al. proposed SymNet for this task\u2013 it constructs a graph neural network that shares parameters across all instances in a domain, thus making it applicable to any instance in a zero-shot manner. Our analysis of SymNet reveals that it performs no better than random on 1/4th of planning competition domains. The key reasons are its design choices: it misses important information during graph construction, leading to (1) poor generalizability, and (2) potential non-identifiability of different actions. In response, our solution, SymNet2.0, substantially augments SymNet\u2019s graph construction approach by introducing additional nodes and edges which allow a better transfer of important information about a domain. It also improves SymNet\u2019s action decoders with relevant information from objects to make different actions identifiable during scoring. Extensive experiments on twelve competition domains, where we use imitation learning over data generated from the PROST planner, demonstrate that SymNet2.0 performs vastly better than SymNet. Interestingly, even though SymNet2.0 is trained over data from PROST, it outperforms the planner on several test instances due to former\u2019s ability to scale to large instances in a zero-shot manner.",
        "bibtex": "@InProceedings{pmlr-v180-sharma22a,\n  title = \t {SymNet 2.0: Effectively handling Non-Fluents and Actions in Generalized Neural Policies for RDDL Relational MDPs},\n  author =       {Sharma, Vishal and Arora, Daman and Gei\\ss{}er, Florian and Mausam and Singla, Parag},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1771--1781},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/sharma22a/sharma22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/sharma22a.html},\n  abstract = \t {Relational MDPs (RMDPs) compactly represent an infinite set of MDPs with an unbounded number of objects. Solving an RMDP requires a generalized policy that applies to all instances of a domain. Recently, Garg et al. proposed SymNet for this task\u2013 it constructs a graph neural network that shares parameters across all instances in a domain, thus making it applicable to any instance in a zero-shot manner. Our analysis of SymNet reveals that it performs no better than random on 1/4th of planning competition domains. The key reasons are its design choices: it misses important information during graph construction, leading to (1) poor generalizability, and (2) potential non-identifiability of different actions. In response, our solution, SymNet2.0, substantially augments SymNet\u2019s graph construction approach by introducing additional nodes and edges which allow a better transfer of important information about a domain. It also improves SymNet\u2019s action decoders with relevant information from objects to make different actions identifiable during scoring. Extensive experiments on twelve competition domains, where we use imitation learning over data generated from the PROST planner, demonstrate that SymNet2.0 performs vastly better than SymNet. Interestingly, even though SymNet2.0 is trained over data from PROST, it outperforms the planner on several test instances due to former\u2019s ability to scale to large instances in a zero-shot manner.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/sharma22a/sharma22a.pdf",
        "supp": "",
        "pdf_size": 1186342,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6710606059070230962&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "aff": "Indian Institute of Technology Delhi; Indian Institute of Technology Delhi; Independent Reseacher; Indian Institute of Technology Delhi; Indian Institute of Technology Delhi",
        "aff_domain": "cse.iitd.ac.in;cse.iitd.ac.in;gmail.com;cse.iitd.ac.in;cse.iitd.ac.in",
        "email": "cse.iitd.ac.in;cse.iitd.ac.in;gmail.com;cse.iitd.ac.in;cse.iitd.ac.in",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Indian Institute of Technology Delhi;Independent Researcher",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.iitd.ac.in;",
        "aff_unique_abbr": "IIT Delhi;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Delhi;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India;"
    },
    {
        "id": "e9195833d6",
        "title": "Systematized event-aware learning for multi-object tracking",
        "site": "https://proceedings.mlr.press/v180/lee22a.html",
        "author": "Hyemin Lee; Daijin Kim",
        "abstract": "We propose an end-to-end online multi-object tracking (MOT) framework with a systematized event-aware loss, which is designed to control possible occurrences in an online MOT situation and compel the tracker to take appropriate actions when such events occur. Training samples from real candidates using a simulation tracker are generated, and a systematized event-aware association matrix is constructed for every frame to enable the tracker to learn the ideal action in a running environment. Several experiments, including ablation studies on various public MOT benchmark datasets, are conducted. The experimental results verify that each event affecting the tracking measure can be controlled, and the proposed method presents optimal results compared with recent state-of-the-art MOT methods.",
        "bibtex": "@InProceedings{pmlr-v180-lee22a,\n  title = \t {Systematized event-aware learning for multi-object tracking},\n  author =       {Lee, Hyemin and Kim, Daijin},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1074--1084},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/lee22a/lee22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/lee22a.html},\n  abstract = \t {We propose an end-to-end online multi-object tracking (MOT) framework with a systematized event-aware loss, which is designed to control possible occurrences in an online MOT situation and compel the tracker to take appropriate actions when such events occur. Training samples from real candidates using a simulation tracker are generated, and a systematized event-aware association matrix is constructed for every frame to enable the tracker to learn the ideal action in a running environment. Several experiments, including ablation studies on various public MOT benchmark datasets, are conducted. The experimental results verify that each event affecting the tracking measure can be controlled, and the proposed method presents optimal results compared with recent state-of-the-art MOT methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/lee22a/lee22a.pdf",
        "supp": "",
        "pdf_size": 1037183,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:UHffVGDuRTMJ:scholar.google.com/&scioq=Systematized+event-aware+learning+for+multi-object+tracking&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": "Department of Computer Science and Engineering, Pohang University of Science and Technology, Pohang, Korea; Department of Computer Science and Engineering, Pohang University of Science and Technology, Pohang, Korea",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Pohang University of Science and Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.postech.ac.kr",
        "aff_unique_abbr": "POSTECH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pohang",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "36aff8816e",
        "title": "Temporal abstractions-augmented temporally contrastive learning: An alternative to the Laplacian in RL",
        "site": "https://proceedings.mlr.press/v180/erraqabi22a.html",
        "author": "Akram Erraqabi; Marlos C. Machado; Mingde Zhao; Sainbayar Sukhbaatar; Alessandro Lazaric; Denoyer Ludovic; Yoshua Bengio",
        "abstract": "In reinforcement learning, the graph Laplacian has proved to be a valuable tool in the task-agnostic setting, with applications ranging from skill discovery to reward shaping. Recently, learning the Laplacian representation has been framed as the optimization of a temporally-contrastive objective to overcome its computational limitations in large (or continuous) state spaces. However, this approach requires uniform access to all states in the state space, overlooking the exploration problem that emerges during the representation learning process. In this work, we propose an alternative method that is able to recover, in a non-uniform-prior setting, the expressiveness and the desired properties of the Laplacian representation. We do so by combining the representation learning with a skill-based covering policy, which provides a better training distribution to extend and refine the representation. We also show that a simple augmentation of the representation objective with the learned temporal abstractions improves dynamics-awareness and helps exploration. We find that our method succeeds as an alternative to the Laplacian in the non-uniform setting and scales to challenging continuous control environments. Finally, even if our method is not optimized for skill discovery, the learned skills can successfully solve difficult continuous navigation tasks with sparse rewards, where standard skill discovery approaches are no so effective.",
        "bibtex": "@InProceedings{pmlr-v180-erraqabi22a,\n  title = \t {Temporal abstractions-augmented temporally contrastive learning: An alternative to the Laplacian in RL},\n  author =       {Erraqabi, Akram and Machado., Marlos C. and Zhao, Mingde and Sukhbaatar, Sainbayar and Lazaric, Alessandro and Ludovic, Denoyer and Bengio, Yoshua},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {641--651},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/erraqabi22a/erraqabi22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/erraqabi22a.html},\n  abstract = \t {In reinforcement learning, the graph Laplacian has proved to be a valuable tool in the task-agnostic setting, with applications ranging from skill discovery to reward shaping. Recently, learning the Laplacian representation has been framed as the optimization of a temporally-contrastive objective to overcome its computational limitations in large (or continuous) state spaces. However, this approach requires uniform access to all states in the state space, overlooking the exploration problem that emerges during the representation learning process. In this work, we propose an alternative method that is able to recover, in a non-uniform-prior setting, the expressiveness and the desired properties of the Laplacian representation. We do so by combining the representation learning with a skill-based covering policy, which provides a better training distribution to extend and refine the representation. We also show that a simple augmentation of the representation objective with the learned temporal abstractions improves dynamics-awareness and helps exploration. We find that our method succeeds as an alternative to the Laplacian in the non-uniform setting and scales to challenging continuous control environments. Finally, even if our method is not optimized for skill discovery, the learned skills can successfully solve difficult continuous navigation tasks with sparse rewards, where standard skill discovery approaches are no so effective.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/erraqabi22a/erraqabi22a.pdf",
        "supp": "",
        "pdf_size": 3987392,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13275347078784894756&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Mila+Universit\u00e9 de Montr\u00e9al+McGill University; Amii+University of Alberta+CIFAR AI Chair; Mila+McGill University; Meta AI; Meta AI; Meta AI; Mila+Universit\u00e9 de Montr\u00e9al+CIFAR Fellow",
        "aff_domain": "mila.quebec;ualberta.ca;mcgill.ca;meta.com;meta.com;meta.com;mila.quebec",
        "email": "mila.quebec;ualberta.ca;mcgill.ca;meta.com;meta.com;meta.com;mila.quebec",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2;3+4+5;0+2;6;6;6;0+1+5",
        "aff_unique_norm": "Mila;Universit\u00e9 de Montr\u00e9al;McGill University;Amii;University of Alberta;CIFAR;Meta",
        "aff_unique_dep": "Quebec Artificial Intelligence Institute;;;;;AI Chair;Meta AI",
        "aff_unique_url": "https://mila.quebec;https://www.umontreal.ca;https://www.mcgill.ca;https://amiilabs.ca;https://www.ualberta.ca;https://www.cifar.ca;https://meta.com",
        "aff_unique_abbr": "Mila;UdeM;McGill;Amii;UAlberta;CIFAR;Meta",
        "aff_campus_unique_index": ";;;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0+0;0+0+0;0+0;1;1;1;0+0+0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "5c532f3ded",
        "title": "Test for non-negligible adverse shifts",
        "site": "https://proceedings.mlr.press/v180/kamulete22a.html",
        "author": "Vathy M Kamulete",
        "abstract": "Statistical tests for dataset shift are susceptible to false alarms: they are sensitive to minor differences when there is in fact adequate sample coverage and predictive performance. We propose instead a framework to detect adverse shifts based on outlier scores, D-SOS for short. D-SOS holds that the new (test) sample is not substantively worse than the reference (training) sample, and not that the two are equal. The key idea is to reduce observations to outlier scores and compare contamination rates at varying weighted thresholds. Users can define what worse means in terms of relevant notions of outlyingness, including proxies for predictive performance. Compared to tests of equal distribution, our approach is uniquely tailored to serve as a robust metric for model monitoring and data validation. We show how versatile and practical D-SOS is on a wide range of real and simulated data.",
        "bibtex": "@InProceedings{pmlr-v180-kamulete22a,\n  title = \t {Test for non-negligible adverse shifts},\n  author =       {Kamulete, Vathy M},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {959--968},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/kamulete22a/kamulete22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/kamulete22a.html},\n  abstract = \t {Statistical tests for dataset shift are susceptible to false alarms: they are sensitive to minor differences when there is in fact adequate sample coverage and predictive performance. We propose instead a framework to detect adverse shifts based on outlier scores, D-SOS for short. D-SOS holds that the new (test) sample is not substantively worse than the reference (training) sample, and not that the two are equal. The key idea is to reduce observations to outlier scores and compare contamination rates at varying weighted thresholds. Users can define what worse means in terms of relevant notions of outlyingness, including proxies for predictive performance. Compared to tests of equal distribution, our approach is uniquely tailored to serve as a robust metric for model monitoring and data validation. We show how versatile and practical D-SOS is on a wide range of real and simulated data.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/kamulete22a/kamulete22a.pdf",
        "supp": "",
        "pdf_size": 218558,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10896106865075885045&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Enterprise Model Risk Management, Royal Bank of Canada, Toronto, Canada",
        "aff_domain": "rbccm.com",
        "email": "rbccm.com",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Royal Bank of Canada",
        "aff_unique_dep": "Enterprise Model Risk Management",
        "aff_unique_url": "https://www.rbc.com",
        "aff_unique_abbr": "RBC",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "4d05662251",
        "title": "The optimal noise in noise-contrastive learning is not what you think",
        "site": "https://proceedings.mlr.press/v180/chehab22a.html",
        "author": "Omar Chehab; Alexandre Gramfort; Aapo Hyv\u00e4rinen",
        "abstract": "Learning a parametric model of a data distribution is a well-known statistical problem that has seen renewed interest as it is brought to scale in deep learning. Framing the problem as a self-supervised task, where data samples are discriminated from noise samples, is at the core of state-of-the-art methods, beginning with Noise-Contrastive Estimation (NCE). Yet, such contrastive learning requires a good noise distribution, which is hard to specify; domain-specific heuristics are therefore widely used. While a comprehensive theory is missing, it is widely assumed that the optimal noise should in practice be made equal to the data, both in distribution and proportion. This setting underlies Generative Adversarial Networks (GANs) in particular. Here, we empirically and theoretically challenge this assumption on the optimal noise. We show that deviating from this assumption can actually lead to better statistical estimators, in terms of asymptotic variance. In particular, the optimal noise distribution is different from the data\u2019s and even from a different family.",
        "bibtex": "@InProceedings{pmlr-v180-chehab22a,\n  title = \t {The optimal noise in noise-contrastive learning is not what you think},\n  author =       {Chehab, Omar and Gramfort, Alexandre and Hyv{\\\"a}rinen, Aapo},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {307--316},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/chehab22a/chehab22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/chehab22a.html},\n  abstract = \t { Learning a parametric model of a data distribution is a well-known statistical problem that has seen renewed interest as it is brought to scale in deep learning. Framing the problem as a self-supervised task, where data samples are discriminated from noise samples, is at the core of state-of-the-art methods, beginning with Noise-Contrastive Estimation (NCE). Yet, such contrastive learning requires a good noise distribution, which is hard to specify; domain-specific heuristics are therefore widely used. While a comprehensive theory is missing, it is widely assumed that the optimal noise should in practice be made equal to the data, both in distribution and proportion. This setting underlies Generative Adversarial Networks (GANs) in particular. Here, we empirically and theoretically challenge this assumption on the optimal noise. We show that deviating from this assumption can actually lead to better statistical estimators, in terms of asymptotic variance. In particular, the optimal noise distribution is different from the data\u2019s and even from a different family.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/chehab22a/chehab22a.pdf",
        "supp": "",
        "pdf_size": 1041399,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=470657639654858176&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Universit\u00e9 Paris-Saclay, Inria, CEA, Palaiseau, France; Universit\u00e9 Paris-Saclay, Inria, CEA, Palaiseau, France; Department of Computer Science, University of Helsinki, Finland",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Universit\u00e9 Paris-Saclay;University of Helsinki",
        "aff_unique_dep": ";Department of Computer Science",
        "aff_unique_url": "https://www.universite-paris-saclay.fr;https://www.helsinki.fi",
        "aff_unique_abbr": "UPS;UH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Palaiseau;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "France;Finland"
    },
    {
        "id": "5d63b5d950",
        "title": "Toward learning human-aligned cross-domain robust models by countering misaligned features",
        "site": "https://proceedings.mlr.press/v180/wang22d.html",
        "author": "Haohan Wang; Zeyi Huang; Hanlin Zhang; Yong Jae Lee; Eric P. Xing",
        "abstract": "Machine learning has demonstrated remarkable prediction accuracy over i.i.d data, but the accuracy often drops when tested with data from another distribution. In this paper, we aim to offer another view of this problem in a perspective assuming the reason behind this accuracy drop is the reliance of models on the features that are not aligned well with how a data annotator considers similar across these two datasets. We refer to these features as misaligned features. We extend the conventional generalization error bound to a new one for this setup with the knowledge of how the misaligned features are associated with the label. Our analysis offers a set of techniques for this problem, and these techniques are naturally linked to many previous methods in robust machine learning literature. We also compared the empirical strength of these methods demonstrated the performance when these previous techniques are combined, with implementation available.",
        "bibtex": "@InProceedings{pmlr-v180-wang22d,\n  title = \t {Toward learning human-aligned cross-domain robust models by countering misaligned features},\n  author =       {Wang, Haohan and Huang, Zeyi and Zhang, Hanlin and Lee, Yong Jae and Xing, Eric P.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2075--2084},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/wang22d/wang22d.pdf},\n  url = \t {https://proceedings.mlr.press/v180/wang22d.html},\n  abstract = \t {Machine learning has demonstrated remarkable prediction accuracy over i.i.d data, but the accuracy often drops when tested with data from another distribution. In this paper, we aim to offer another view of this problem in a perspective assuming the reason behind this accuracy drop is the reliance of models on the features that are not aligned well with how a data annotator considers similar across these two datasets. We refer to these features as misaligned features. We extend the conventional generalization error bound to a new one for this setup with the knowledge of how the misaligned features are associated with the label. Our analysis offers a set of techniques for this problem, and these techniques are naturally linked to many previous methods in robust machine learning literature. We also compared the empirical strength of these methods demonstrated the performance when these previous techniques are combined, with implementation available.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/wang22d/wang22d.pdf",
        "supp": "",
        "pdf_size": 374968,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17656351087340732063&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA+Mohamed bin Zayed University of Arti\ufb01cial Intelligence, Abu Dhabi, United Arab Emirates+Petuum, Inc., Pittsburgh, PA, USA; Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Computer Sciences, University of Wisconsin-Madison, Madison, WI, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA+Mohamed bin Zayed University of Arti\ufb01cial Intelligence, Abu Dhabi, United Arab Emirates+Petuum, Inc., Pittsburgh, PA, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2;3;0;3;0+1+2",
        "aff_unique_norm": "Carnegie Mellon University;Mohamed bin Zayed University of Artificial Intelligence;Petuum, Inc.;University of Wisconsin-Madison",
        "aff_unique_dep": "School of Computer Science;;;Department of Computer Sciences",
        "aff_unique_url": "https://www.cmu.edu;https://mbzuai.ac.ae;https://www.petuum.com;https://www.wisc.edu",
        "aff_unique_abbr": "CMU;MBZUAI;Petuum;UW-Madison",
        "aff_campus_unique_index": "0+1+0;2;0;2;0+1+0",
        "aff_campus_unique": "Pittsburgh;Abu Dhabi;Madison",
        "aff_country_unique_index": "0+1+0;0;0;0;0+1+0",
        "aff_country_unique": "United States;United Arab Emirates"
    },
    {
        "id": "1f3977ee3c",
        "title": "Towards painless policy optimization for constrained MDPs",
        "site": "https://proceedings.mlr.press/v180/jain22a.html",
        "author": "Arushi Jain; Sharan Vaswani; Reza Babanezhad; Csaba Szepesv\u00e1ri; Doina Precup",
        "abstract": "We study policy optimization in an infinite horizon, $\\gamma$-discounted constrained Markov decision process (CMDP). Our objective is to return a policy that achieves large expected reward with a small constraint violation. We consider the online setting with linear function approximation and assume global access to the corresponding features. We propose a generic primal-dual framework that allows us to bound the reward sub-optimality and constraint violation for arbitrary algorithms in terms of their primal and dual regret on online linear optimization problems. We instantiate this framework to use coin-betting algorithms and propose the \\textbf{Coin Betting Politex (CBP)} algorithm. Assuming that the action-value functions are $\\epsilon_{\\text{\\tiny{b}}}$-close to the span of the $d$-dimensional state-action features and no sampling errors, we prove that $T$ iterations of CBP result in an $O\\left(\\frac{1}{(1 - \\gamma)^3 \\sqrt{T}} + \\frac{\\epsilon_{\\text{\\tiny{b}}} \\sqrt{d}}{(1 - \\gamma)^2} \\right)$ reward sub-optimality and an $O\\left(\\frac{1}{(1 - \\gamma)^2 \\sqrt{T}} + \\frac{\\epsilon_{\\text{\\tiny{b}}} \\sqrt{d}}{1 - \\gamma} \\right)$ constraint violation. Importantly, unlike gradient descent-ascent and other recent methods, CBP does not require extensive hyperparameter tuning. Via experiments on synthetic and Cartpole environments, we demonstrate the effectiveness and robustness of CBP.",
        "bibtex": "@InProceedings{pmlr-v180-jain22a,\n  title = \t {Towards painless policy optimization for constrained {MDP}s},\n  author =       {Jain, Arushi and Vaswani, Sharan and Babanezhad, Reza and Szepesv\\'ari, Csaba and Precup, Doina},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {895--905},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/jain22a/jain22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/jain22a.html},\n  abstract = \t {We study policy optimization in an infinite horizon, $\\gamma$-discounted constrained Markov decision process (CMDP). Our objective is to return a policy that achieves large expected reward with a small constraint violation. We consider the online setting with linear function approximation and assume global access to the corresponding features. We propose a generic primal-dual framework that allows us to bound the reward sub-optimality and constraint violation for arbitrary algorithms in terms of their primal and dual regret on online linear optimization problems. We instantiate this framework to use coin-betting algorithms and propose the \\textbf{Coin Betting Politex (CBP)} algorithm. Assuming that the action-value functions are $\\epsilon_{\\text{\\tiny{b}}}$-close to the span of the $d$-dimensional state-action features and no sampling errors, we prove that $T$ iterations of CBP result in an $O\\left(\\frac{1}{(1 - \\gamma)^3 \\sqrt{T}} + \\frac{\\epsilon_{\\text{\\tiny{b}}} \\sqrt{d}}{(1 - \\gamma)^2} \\right)$ reward sub-optimality and an $O\\left(\\frac{1}{(1 - \\gamma)^2 \\sqrt{T}} + \\frac{\\epsilon_{\\text{\\tiny{b}}} \\sqrt{d}}{1 - \\gamma} \\right)$ constraint violation. Importantly, unlike gradient descent-ascent and other recent methods, CBP does not require extensive hyperparameter tuning. Via experiments on synthetic and Cartpole environments, we demonstrate the effectiveness and robustness of CBP.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/jain22a/jain22a.pdf",
        "supp": "",
        "pdf_size": 1516881,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3234853485314330715&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "aff": "Mila, McGill University; Simon Fraser University; SAIT AI Lab, Montreal; Amii, University of Alberta + DeepMind; Mila, McGill University + DeepMind",
        "aff_domain": "mail.mcgill.ca;gmail.com; ; ; ",
        "email": "mail.mcgill.ca;gmail.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3+4;0+4",
        "aff_unique_norm": "McGill University;Simon Fraser University;SAIT AI lab;University of Alberta;DeepMind",
        "aff_unique_dep": "Mila;;AI Lab;Amii;",
        "aff_unique_url": "https://www.mcgill.ca;https://www.sfu.ca;;https://www.ualberta.ca;https://deepmind.com",
        "aff_unique_abbr": "McGill;SFU;;UAlberta;DeepMind",
        "aff_campus_unique_index": "0;0;;0",
        "aff_campus_unique": "Montreal;",
        "aff_country_unique_index": "0;0;0;0+1;0+1",
        "aff_country_unique": "Canada;United Kingdom"
    },
    {
        "id": "65553b4b4b",
        "title": "Towards unsupervised open world semantic segmentation",
        "site": "https://proceedings.mlr.press/v180/uhlemeyer22a.html",
        "author": "Svenja Uhlemeyer; Matthias Rottmann; Hanno Gottschalk",
        "abstract": "For the semantic segmentation of images, state-of-the-art deep neural networks (DNNs) achieve high segmentation accuracy if that task is restricted to a closed set of classes. However, as of now DNNs have limited ability to operate in an open world, where they are tasked to identify pixels belonging to unknown objects and eventually to learn novel classes, incrementally. Humans have the capability to say: \u201cI don\u2019t know what that is, but I\u2019ve already seen something like that\u201d. Therefore, it is desirable to perform such an incremental learning task in an unsupervised fashion. We introduce a method where unknown objects are clustered based on visual similarity. Those clusters are utilized to define new classes and serve as training data for unsupervised incremental learning. More precisely, the connected components of a predicted semantic segmentation are assessed by a segmentation quality estimate. Connected components with a low estimated prediction quality are candidates for a subsequent clustering. Additionally, the component-wise quality assessment allows for obtaining predicted segmentation masks for the image regions potentially containing unknown objects. The respective pixels of such masks are pseudo-labeled and afterwards used for re-training the DNN, i.e., without the use of ground truth generated by humans. In our experiments we demonstrate that, without access to ground truth and even with few data, a DNN\u2019s class space can be extended by a novel class, achieving considerable segmentation accuracy.",
        "bibtex": "@InProceedings{pmlr-v180-uhlemeyer22a,\n  title = \t {Towards unsupervised open world semantic segmentation},\n  author =       {Uhlemeyer, Svenja and Rottmann, Matthias and Gottschalk, Hanno},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1981--1991},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/uhlemeyer22a/uhlemeyer22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/uhlemeyer22a.html},\n  abstract = \t {For the semantic segmentation of images, state-of-the-art deep neural networks (DNNs) achieve high segmentation accuracy if that task is restricted to a closed set of classes. However, as of now DNNs have limited ability to operate in an open world, where they are tasked to identify pixels belonging to unknown objects and eventually to learn novel classes, incrementally. Humans have the capability to say: \u201cI don\u2019t know what that is, but I\u2019ve already seen something like that\u201d. Therefore, it is desirable to perform such an incremental learning task in an unsupervised fashion. We introduce a method where unknown objects are clustered based on visual similarity. Those clusters are utilized to define new classes and serve as training data for unsupervised incremental learning. More precisely, the connected components of a predicted semantic segmentation are assessed by a segmentation quality estimate. Connected components with a low estimated prediction quality are candidates for a subsequent clustering. Additionally, the component-wise quality assessment allows for obtaining predicted segmentation masks for the image regions potentially containing unknown objects. The respective pixels of such masks are pseudo-labeled and afterwards used for re-training the DNN, i.e., without the use of ground truth generated by humans. In our experiments we demonstrate that, without access to ground truth and even with few data, a DNN\u2019s class space can be extended by a novel class, achieving considerable segmentation accuracy.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/uhlemeyer22a/uhlemeyer22a.pdf",
        "supp": "",
        "pdf_size": 1626909,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9271276393630503925&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fdbfe1293e",
        "title": "Uncertainty-aware pseudo-labeling for quantum calculations",
        "site": "https://proceedings.mlr.press/v180/huang22a.html",
        "author": "Kexin Huang; Vishnu Sresht; Brajesh Rai; Mykola Bordyuh",
        "abstract": "Machine learning models have recently shown promise in predicting molecular quantum chemical properties. However, the path to real-life adoption requires (1) learning under low-resource constraints and (2) out-of-distribution generalization to unseen, structurally diverse molecules. We observe that these two challenges can be addressed via abundant labels, which is often not the case in quantum chemistry. We hypothesize that pseudo-labeling on a vast array of unlabeled molecules can serve as gold-label proxies to expand the training labeled dataset significantly. The challenge in pseudo-labeling is to prevent the bad pseudo-labels from biasing the model. Motivated by the entropy minimization framework, we develop a simple and effective strategy Pseudo that can assign pseudo-labels, detect bad pseudo-labels through evidential uncertainty, and prevent them from biasing the model using adaptive weighting. Empirically, Pseudo improves quantum calculations accuracy in full data, low data, and out-of-distribution settings.",
        "bibtex": "@InProceedings{pmlr-v180-huang22a,\n  title = \t {Uncertainty-aware pseudo-labeling for quantum calculations},\n  author =       {Huang, Kexin and Sresht, Vishnu and Rai, Brajesh and Bordyuh, Mykola},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {853--862},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/huang22a/huang22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/huang22a.html},\n  abstract = \t {Machine learning models have recently shown promise in predicting molecular quantum chemical properties. However, the path to real-life adoption requires (1) learning under low-resource constraints and (2) out-of-distribution generalization to unseen, structurally diverse molecules. We observe that these two challenges can be addressed via abundant labels, which is often not the case in quantum chemistry. We hypothesize that pseudo-labeling on a vast array of unlabeled molecules can serve as gold-label proxies to expand the training labeled dataset significantly. The challenge in pseudo-labeling is to prevent the bad pseudo-labels from biasing the model. Motivated by the entropy minimization framework, we develop a simple and effective strategy Pseudo that can assign pseudo-labels, detect bad pseudo-labels through evidential uncertainty, and prevent them from biasing the model using adaptive weighting. Empirically, Pseudo improves quantum calculations accuracy in full data, low data, and out-of-distribution settings. }\n}",
        "pdf": "https://proceedings.mlr.press/v180/huang22a/huang22a.pdf",
        "supp": "",
        "pdf_size": 918371,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3640133815315592743&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7f5c005271",
        "title": "Understanding and mitigating the limitations of prioritized experience replay",
        "site": "https://proceedings.mlr.press/v180/pan22a.html",
        "author": "Yangchen Pan; Jincheng Mei; Amir-massoud Farahmand; Martha White; Hengshuai Yao; Mohsen Rohani; Jun Luo",
        "abstract": "Prioritized Experience Replay (ER) has been empirically shown to improve sample efficiency across many domains and attracted great attention; however, there is little theoretical understanding of why such prioritized sampling helps and its limitations. In this work, we take a deep look at the prioritized ER. In a supervised learning setting, we show the equivalence between the error-based prioritized sampling method for minimizing mean squared error and the uniform sampling for cubic power loss. We then provide theoretical insight into why error-based prioritized sampling improves convergence rate upon uniform sampling when minimizing mean squared error during early learning. Based on the insight, we further point out two limitations of the prioritized ER method: 1) outdated priorities and 2) insufficient coverage of the sample space. To mitigate the limitations, we propose our model-based stochastic gradient Langevin dynamics sampling method. We show that our method does provide states distributed close to an ideal prioritized sampling distribution estimated by the brute-force method, which does not suffer from the two limitations. We conduct experiments on both discrete and continuous control problems to show our approach\u2019s efficacy and examine the practical implication of our method in an autonomous driving application.",
        "bibtex": "@InProceedings{pmlr-v180-pan22a,\n  title = \t {Understanding and mitigating the limitations of prioritized experience replay},\n  author =       {Pan, Yangchen and Mei, Jincheng and Farahmand, Amir-massoud and White, Martha and Yao, Hengshuai and Rohani, Mohsen and Luo, Jun},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1561--1571},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/pan22a/pan22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/pan22a.html},\n  abstract = \t {Prioritized Experience Replay (ER) has been empirically shown to improve sample efficiency across many domains and attracted great attention; however, there is little theoretical understanding of why such prioritized sampling helps and its limitations. In this work, we take a deep look at the prioritized ER. In a supervised learning setting, we show the equivalence between the error-based prioritized sampling method for minimizing mean squared error and the uniform sampling for cubic power loss. We then provide theoretical insight into why error-based prioritized sampling improves convergence rate upon uniform sampling when minimizing mean squared error during early learning. Based on the insight, we further point out two limitations of the prioritized ER method: 1) outdated priorities and 2) insufficient coverage of the sample space. To mitigate the limitations, we propose our model-based stochastic gradient Langevin dynamics sampling method. We show that our method does provide states distributed close to an ideal prioritized sampling distribution estimated by the brute-force method, which does not suffer from the two limitations. We conduct experiments on both discrete and continuous control problems to show our approach\u2019s efficacy and examine the practical implication of our method in an autonomous driving application. }\n}",
        "pdf": "https://proceedings.mlr.press/v180/pan22a/pan22a.pdf",
        "supp": "",
        "pdf_size": 771835,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8001150436932561511&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "University of Alberta + Huawei Noah\u2019s Ark Lab + CIFAR AI Chair; University of Alberta + Huawei Noah\u2019s Ark Lab; University of Toronto & Vector Institute + CIFAR AI Chair; University of Alberta + CIFAR AI Chair; University of Alberta; Huawei Noah\u2019s Ark Lab; Huawei Noah\u2019s Ark Lab",
        "aff_domain": "ualberta.ca;ualberta.ca; ; ; ; ; ",
        "email": "ualberta.ca;ualberta.ca; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1+2;0+1;3+2;0+2;0;1;1",
        "aff_unique_norm": "University of Alberta;Huawei;CIFAR;University of Toronto",
        "aff_unique_dep": ";Noah\u2019s Ark Lab;AI Chair;",
        "aff_unique_url": "https://www.ualberta.ca;https://www.huawei.com;https://www.cifar.ca;https://www.utoronto.ca",
        "aff_unique_abbr": "UAlberta;Huawei;CIFAR;U of T",
        "aff_campus_unique_index": ";;1;",
        "aff_campus_unique": ";Toronto",
        "aff_country_unique_index": "0+1+0;0+1;0+0;0+0;0;1;1",
        "aff_country_unique": "Canada;China"
    },
    {
        "id": "cd85afff07",
        "title": "Using hierarchies to efficiently combine evidence with Dempster\u2019s rule of combination",
        "site": "https://proceedings.mlr.press/v180/pinto-prieto22a.html",
        "author": "Daira Pinto Prieto; Ronald de Haan",
        "abstract": "Dempster\u2019s rule of combination allows us to combine various independent pieces of evidence that each have a certain degree of uncertainty. This provides a useful way for dealing with uncertain evidence, but the rule is computationally intractable. In this paper, we analyze the complexity of this rule for differently structured bodies of evidence and we consider a known algorithm by Shafer and Logan to compute this rule efficiently over a hierarchical set of evidence. We show that one can check in polynomial time whether an arbitrary set of evidence has a hierarchical shape, enabling the use of Shafer and Logan\u2019s algorithm. Moreover, we consider two different approaches to deal with non-hierarchical sets of evidence: (i) considering hierarchical subsets and (ii) taking advantage of internal hierarchical structures in the overall set. For the former case, we conclude that getting different hierarchies from an arbitrary set of pieces of evidence corresponds to the VERTEX COVER problem and we present algorithms for obtaining these hierarchies based on this correspondence. For the latter case, we present a fixed-parameter tractable algorithm which computes the belief function of any piece of evidence included in the set.",
        "bibtex": "@InProceedings{pmlr-v180-pinto-prieto22a,\n  title = \t {Using hierarchies to efficiently combine evidence with Dempster\u2019s rule of combination},\n  author =       {Pinto Prieto, Daira and de Haan, Ronald},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1634--1643},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/pinto-prieto22a/pinto-prieto22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/pinto-prieto22a.html},\n  abstract = \t {Dempster\u2019s rule of combination allows us to combine various independent pieces of evidence that each have a certain degree of uncertainty. This provides a useful way for dealing with uncertain evidence, but the rule is computationally intractable. In this paper, we analyze the complexity of this rule for differently structured bodies of evidence and we consider a known algorithm by Shafer and Logan to compute this rule efficiently over a hierarchical set of evidence. We show that one can check in polynomial time whether an arbitrary set of evidence has a hierarchical shape, enabling the use of Shafer and Logan\u2019s algorithm. Moreover, we consider two different approaches to deal with non-hierarchical sets of evidence: (i) considering hierarchical subsets and (ii) taking advantage of internal hierarchical structures in the overall set. For the former case, we conclude that getting different hierarchies from an arbitrary set of pieces of evidence corresponds to the VERTEX COVER problem and we present algorithms for obtaining these hierarchies based on this correspondence. For the latter case, we present a fixed-parameter tractable algorithm which computes the belief function of any piece of evidence included in the set.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/pinto-prieto22a/pinto-prieto22a.pdf",
        "supp": "",
        "pdf_size": 261929,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6322748984867210023&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Institute for Logic, Language and Computation, University of Amsterdam, The Netherlands; Institute for Logic, Language and Computation, University of Amsterdam, The Netherlands",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Amsterdam",
        "aff_unique_dep": "Institute for Logic, Language and Computation",
        "aff_unique_url": "https://www.uva.nl",
        "aff_unique_abbr": "UvA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Amsterdam",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "de7e36dc1a",
        "title": "VQ-Flows: Vector quantized local normalizing flows",
        "site": "https://proceedings.mlr.press/v180/sidheekh22a.html",
        "author": "Sahil Sidheekh; Chris B. Dock; Tushar Jain; Radu Balan; Maneesh K. Singh",
        "abstract": "Normalizing flows provide an elegant approach to  generative modeling that allows for efficient sampling and exact density  evaluation of unknown data distributions. However, current techniques have  significant limitations in their expressivity when the data distribution  is supported on a low-dimensional manifold or has a non-trivial topology.  We introduce a novel statistical framework for learning a mixture of  local normalizing flows as \u201cchart maps\u201d over the data manifold.  Our framework augments the expressivity of recent approaches while  preserving the signature property of normalizing flows, that they admit  exact density evaluation. We learn a suitable atlas of charts for the data  manifold via a vector quantized auto-encoder (VQ-AE) and the distributions  over them using a conditional flow. We validate experimentally that our  probabilistic framework enables existing approaches to better model data  distributions over complex manifolds.",
        "bibtex": "@InProceedings{pmlr-v180-sidheekh22a,\n  title = \t {VQ-Flows: Vector quantized local normalizing flows},\n  author =       {Sidheekh, Sahil and Dock, Chris B. and Jain, Tushar and Balan, Radu and Singh, Maneesh K.},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1835--1845},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/sidheekh22a/sidheekh22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/sidheekh22a.html},\n  abstract = \t {Normalizing flows provide an elegant approach to  generative modeling that allows for efficient sampling and exact density  evaluation of unknown data distributions. However, current techniques have  significant limitations in their expressivity when the data distribution  is supported on a low-dimensional manifold or has a non-trivial topology.  We introduce a novel statistical framework for learning a mixture of  local normalizing flows as \u201cchart maps\u201d over the data manifold.  Our framework augments the expressivity of recent approaches while  preserving the signature property of normalizing flows, that they admit  exact density evaluation. We learn a suitable atlas of charts for the data  manifold via a vector quantized auto-encoder (VQ-AE) and the distributions  over them using a conditional flow. We validate experimentally that our  probabilistic framework enables existing approaches to better model data  distributions over complex manifolds.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/sidheekh22a/sidheekh22a.pdf",
        "supp": "",
        "pdf_size": 2153132,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11128989105658860824&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 12,
        "aff": "Verisk Analytics; University of Maryland, College Park; Verisk Analytics; University of Maryland, College Park; Motive Technologies, Inc.",
        "aff_domain": "; ; ; ; ",
        "email": "; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;1;2",
        "aff_unique_norm": "Verisk Analytics;University of Maryland;Motive Technologies, Inc.",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.verisk.com;https://www/umd.edu;",
        "aff_unique_abbr": "Verisk;UMD;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";College Park",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "cd68e0972f",
        "title": "Variational message passing neural network for Maximum-A-Posteriori (MAP) inference",
        "site": "https://proceedings.mlr.press/v180/cui22a.html",
        "author": "Zijun Cui; Hanjing Wang; Tian Gao; Kartik Talamadupula; Qiang Ji",
        "abstract": "Maximum-A-Posteriori (MAP) inference is a fundamental task in probabilistic inference and belief propagation (BP) is a widely used algorithm for MAP inference. Though BP has been applied successfully to many different fields, it offers no performance guarantee and often performs poorly on loopy graphs. To improve the performance on loopy graphs and to scale up to large graphs, we propose a variational message passing neural network (V-MPNN), where we leverage both the power of neural networks in modeling complex functions and the well-established algorithmic theories on variational belief propagation. Instead of relying on a hand-crafted variational assumption, we propose a neural-augmented free energy where a general variational distribution is parameterized through a neural network. A message passing neural network is utilized for the minimization of neural-augmented free energy. Training of the MPNN is thus guided by neural-augmented free energy, without requiring exact MAP configurations as annotations. We empirically demonstrate the effectiveness of the proposed V-MPNN by comparing against both state-of-the-art training-free methods and training-based methods.",
        "bibtex": "@InProceedings{pmlr-v180-cui22a,\n  title = \t {Variational message passing neural network for Maximum-A-Posteriori (MAP) inference},\n  author =       {Cui, Zijun and Wang, Hanjing and Gao, Tian and Talamadupula, Kartik and Ji, Qiang},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {464--474},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/cui22a/cui22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/cui22a.html},\n  abstract = \t {Maximum-A-Posteriori (MAP) inference is a fundamental task in probabilistic inference and belief propagation (BP) is a widely used algorithm for MAP inference. Though BP has been applied successfully to many different fields, it offers no performance guarantee and often performs poorly on loopy graphs. To improve the performance on loopy graphs and to scale up to large graphs, we propose a variational message passing neural network (V-MPNN), where we leverage both the power of neural networks in modeling complex functions and the well-established algorithmic theories on variational belief propagation. Instead of relying on a hand-crafted variational assumption, we propose a neural-augmented free energy where a general variational distribution is parameterized through a neural network. A message passing neural network is utilized for the minimization of neural-augmented free energy. Training of the MPNN is thus guided by neural-augmented free energy, without requiring exact MAP configurations as annotations. We empirically demonstrate the effectiveness of the proposed V-MPNN by comparing against both state-of-the-art training-free methods and training-based methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/cui22a/cui22a.pdf",
        "supp": "",
        "pdf_size": 573188,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15866451830411607396&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "ECSE, Rensselaer Polytechnic Institute; ECSE, Rensselaer Polytechnic Institute; IBM Research; IBM Research; ECSE, Rensselaer Polytechnic Institute",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Rensselaer Polytechnic Institute;IBM",
        "aff_unique_dep": "ECSE;IBM Research",
        "aff_unique_url": "https://www.rpi.edu;https://www.ibm.com/research",
        "aff_unique_abbr": "RPI;IBM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d5a6b5ca53",
        "title": "Variational multiple shooting for Bayesian ODEs with Gaussian processes",
        "site": "https://proceedings.mlr.press/v180/hegde22a.html",
        "author": "Pashupati Hegde; \u00c7a\u011fatay Y\u0131ld\u0131z; Harri L\u00e4hdesm\u00e4ki; Samuel Kaski; Markus Heinonen",
        "abstract": "Recent machine learning advances have proposed black-box estimation of \\textit{unknown continuous-time system dynamics} directly from data. However, earlier works are based on approximative solutions or point estimates. We propose a novel Bayesian nonparametric model that uses Gaussian processes to infer posteriors of unknown ODE systems directly from data. We derive sparse variational inference with decoupled functional sampling to represent vector field posteriors. We also introduce a probabilistic shooting augmentation to enable efficient inference from arbitrarily long trajectories. The method demonstrates the benefit of computing vector field posteriors, with predictive uncertainty scores outperforming alternative methods on multiple ODE learning tasks.",
        "bibtex": "@InProceedings{pmlr-v180-hegde22a,\n  title = \t {Variational multiple shooting for Bayesian ODEs with Gaussian processes},\n  author =       {Hegde, Pashupati and Y{\\i}ld{\\i}z, \\c{C}a\\u{g}atay and L{\\\"a}hdesm{\\\"a}ki, Harri and Kaski, Samuel and Heinonen, Markus},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {790--799},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/hegde22a/hegde22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/hegde22a.html},\n  abstract = \t {Recent machine learning advances have proposed black-box estimation of \\textit{unknown continuous-time system dynamics} directly from data. However, earlier works are based on approximative solutions or point estimates. We propose a novel Bayesian nonparametric model that uses Gaussian processes to infer posteriors of unknown ODE systems directly from data. We derive sparse variational inference with decoupled functional sampling to represent vector field posteriors. We also introduce a probabilistic shooting augmentation to enable efficient inference from arbitrarily long trajectories. The method demonstrates the benefit of computing vector field posteriors, with predictive uncertainty scores outperforming alternative methods on multiple ODE learning tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/hegde22a/hegde22a.pdf",
        "supp": "",
        "pdf_size": 912533,
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6605853390708178405&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, Aalto University, Finland; Department of Computer Science, Aalto University, Finland; Department of Computer Science, Aalto University, Finland; Department of Computer Science, Aalto University, Finland; Department of Computer Science, Aalto University, Finland",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Aalto University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.aalto.fi",
        "aff_unique_abbr": "Aalto",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "bf36b57e8d",
        "title": "Variational- and metric-based deep latent space for out-of-distribution detection",
        "site": "https://proceedings.mlr.press/v180/dinari22a.html",
        "author": "Or Dinari; Oren Freifeld",
        "abstract": "One popular deep-learning approach for the task of Out-Of-Distribution (OOD) detection is based on thresholding the values of per-class Gaussian likelihood of deep features. However, two issues arise with that approach: first, the distributions are often far from being Gaussian; second, many OOD data points  fall within the effective support of the known classes\u2019 Gaussians. Thus, either way it is hard to find a good threshold. In contrast, our proposed solution for OOD detection is based on a new latent space where: 1) each known class is well captured by a nearly-isotropic Gaussian; 2) those Gaussians are far from each other and from the origin of the space (together, these properties effectively leave the area around the origin free for OOD data). Concretely, given a (possibly-trained) backbone deep net of choice, we use it to train a conditional variational model via a Kullback Leibler loss, a triplet loss, and a new distancing loss that pushes classes away from each other.  During inference, the class-dependent log-likelihood values of a deep feature ensemble of the test point are also weighted based on reconstruction errors, improving further the decision rule. Experiments on popular benchmarks show that our method yields state-of-the-art results, a feat achieved despite the fact that, unlike some competitors, we make no use of OOD data for training or hyperparameter tuning. Our code is available at\u00a0\\url{https://github.com/BGU-CS-VIL/vmdls}.",
        "bibtex": "@InProceedings{pmlr-v180-dinari22a,\n  title = \t {Variational- and metric-based deep latent space for out-of-distribution detection},\n  author =       {Dinari, Or and Freifeld, Oren},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {569--578},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/dinari22a/dinari22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/dinari22a.html},\n  abstract = \t {One popular deep-learning approach for the task of Out-Of-Distribution (OOD) detection is based on thresholding the values of per-class Gaussian likelihood of deep features. However, two issues arise with that approach: first, the distributions are often far from being Gaussian; second, many OOD data points  fall within the effective support of the known classes\u2019 Gaussians. Thus, either way it is hard to find a good threshold. In contrast, our proposed solution for OOD detection is based on a new latent space where: 1) each known class is well captured by a nearly-isotropic Gaussian; 2) those Gaussians are far from each other and from the origin of the space (together, these properties effectively leave the area around the origin free for OOD data). Concretely, given a (possibly-trained) backbone deep net of choice, we use it to train a conditional variational model via a Kullback Leibler loss, a triplet loss, and a new distancing loss that pushes classes away from each other.  During inference, the class-dependent log-likelihood values of a deep feature ensemble of the test point are also weighted based on reconstruction errors, improving further the decision rule. Experiments on popular benchmarks show that our method yields state-of-the-art results, a feat achieved despite the fact that, unlike some competitors, we make no use of OOD data for training or hyperparameter tuning. Our code is available at\u00a0\\url{https://github.com/BGU-CS-VIL/vmdls}.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/dinari22a/dinari22a.pdf",
        "supp": "",
        "pdf_size": 7555722,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1535505342674558650&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "The Department of Computer Science, Ben-Gurion University of the Negev, Be\u2019er Sheva, Israel; The Department of Computer Science, Ben-Gurion University of the Negev, Be\u2019er Sheva, Israel",
        "aff_domain": ";",
        "email": ";",
        "github": "https://github.com/BGU-CS-VIL/vmdls",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Ben-Gurion University of the Negev",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bgu.ac.il",
        "aff_unique_abbr": "BGU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Be\u2019er Sheva",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "3622d74dbe",
        "title": "Voronoi density estimator for high-dimensional data: Computation, compactification and convergence",
        "site": "https://proceedings.mlr.press/v180/polianskii22a.html",
        "author": "Vladislav Polianskii; Giovanni Luca Marchetti; Alexander Kravberg; Anastasiia Varava; Florian T. Pokorny; Danica Kragic",
        "abstract": "The Voronoi Density Estimator (VDE) is an established density estimation technique that adapts to the local geometry of data. However, its applicability has been so far limited to problems in two and three dimensions. This is because Voronoi cells rapidly increase in complexity as dimensions grow, making the necessary explicit computations infeasible. We define a variant of the VDE deemed Compactified Voronoi Density Estimator (CVDE), suitable for higher dimensions. We propose computationally efficient algorithms for numerical approximation of the CVDE and formally prove convergence of the estimated density to the original one. We implement and empirically validate the CVDE through a comparison with the Kernel Density Estimator (KDE). Our results indicate that the CVDE outperforms the KDE on sound and image data.",
        "bibtex": "@InProceedings{pmlr-v180-polianskii22a,\n  title = \t {Voronoi density estimator for high-dimensional data: Computation, compactification and convergence},\n  author =       {Polianskii, Vladislav and Marchetti, Giovanni Luca and Kravberg, Alexander and Varava, Anastasiia and Pokorny, Florian T. and Kragic, Danica},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1644--1653},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/polianskii22a/polianskii22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/polianskii22a.html},\n  abstract = \t {The Voronoi Density Estimator (VDE) is an established density estimation technique that adapts to the local geometry of data. However, its applicability has been so far limited to problems in two and three dimensions. This is because Voronoi cells rapidly increase in complexity as dimensions grow, making the necessary explicit computations infeasible. We define a variant of the VDE deemed Compactified Voronoi Density Estimator (CVDE), suitable for higher dimensions. We propose computationally efficient algorithms for numerical approximation of the CVDE and formally prove convergence of the estimated density to the original one. We implement and empirically validate the CVDE through a comparison with the Kernel Density Estimator (KDE). Our results indicate that the CVDE outperforms the KDE on sound and image data.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/polianskii22a/polianskii22a.pdf",
        "supp": "",
        "pdf_size": 1013043,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10146968992819365806&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "School of Electrical Engineering and Computer Science, Royal Institute of Technology (KTH), Stockholm, Sweden; School of Electrical Engineering and Computer Science, Royal Institute of Technology (KTH), Stockholm, Sweden; School of Electrical Engineering and Computer Science, Royal Institute of Technology (KTH), Stockholm, Sweden; School of Electrical Engineering and Computer Science, Royal Institute of Technology (KTH), Stockholm, Sweden; School of Electrical Engineering and Computer Science, Royal Institute of Technology (KTH), Stockholm, Sweden; School of Electrical Engineering and Computer Science, Royal Institute of Technology (KTH), Stockholm, Sweden",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Royal Institute of Technology (KTH)",
        "aff_unique_dep": "School of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "5b165fd760",
        "title": "X-MEN: guaranteed XOR-maximum entropy constrained inverse reinforcement learning",
        "site": "https://proceedings.mlr.press/v180/ding22a.html",
        "author": "Fan Ding; Yexiang Xue",
        "abstract": "Inverse Reinforcement Learning (IRL)  is a powerful way of learning from demonstrations.  In this paper, we address IRL problems with the  availability of prior knowledge that optimal policies  will never violate certain constraints. Conventional  approaches ignoring these constraints need many  demonstrations to converge. We propose XOR-Maximum Entropy  Constrained Inverse Reinforcement Learning (X-MEN),  which is guaranteed to converge to the global optimal  reward function in linear rate w.r.t. the number of  learning iterations. X-MEN embeds XOR-sampling \u2013  a provable sampling approach which transforms  the #-P complete sampling problem into queries  to NP oracles \u2013 into the framework of maximum  entropy IRL. X-MEN also guarantees the learned  IRL agent will never generate trajectories that  violate constraints. Empirical results in navigation  demonstrate that X-MEN converges faster to the  optimal rewards compared to baseline approaches  and always generates trajectories that satisfy  multi-state combinatorial constraints.",
        "bibtex": "@InProceedings{pmlr-v180-ding22a,\n  title = \t {X-MEN: guaranteed XOR-maximum entropy constrained inverse reinforcement learning},\n  author =       {Ding, Fan and Xue, Yexiang},\n  booktitle = \t {Proceedings of the Thirty-Eighth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {589--598},\n  year = \t {2022},\n  editor = \t {Cussens, James and Zhang, Kun},\n  volume = \t {180},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {01--05 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v180/ding22a/ding22a.pdf},\n  url = \t {https://proceedings.mlr.press/v180/ding22a.html},\n  abstract = \t {Inverse Reinforcement Learning (IRL)  is a powerful way of learning from demonstrations.  In this paper, we address IRL problems with the  availability of prior knowledge that optimal policies  will never violate certain constraints. Conventional  approaches ignoring these constraints need many  demonstrations to converge. We propose XOR-Maximum Entropy  Constrained Inverse Reinforcement Learning (X-MEN),  which is guaranteed to converge to the global optimal  reward function in linear rate w.r.t. the number of  learning iterations. X-MEN embeds XOR-sampling \u2013  a provable sampling approach which transforms  the #-P complete sampling problem into queries  to NP oracles \u2013 into the framework of maximum  entropy IRL. X-MEN also guarantees the learned  IRL agent will never generate trajectories that  violate constraints. Empirical results in navigation  demonstrate that X-MEN converges faster to the  optimal rewards compared to baseline approaches  and always generates trajectories that satisfy  multi-state combinatorial constraints.}\n}",
        "pdf": "https://proceedings.mlr.press/v180/ding22a/ding22a.pdf",
        "supp": "",
        "pdf_size": 716312,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3628491991689501367&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, Purdue University, West Lafayette, Indiana, USA; Department of Computer Science, Purdue University, West Lafayette, Indiana, USA",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    }
]