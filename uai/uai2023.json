[
    {
        "id": "11b0dc8606",
        "title": "$E(2)$-Equivariant Vision Transformer",
        "site": "https://proceedings.mlr.press/v216/xu23b.html",
        "author": "Renjun Xu; Kaifan Yang; Ke Liu; Fengxiang He",
        "abstract": "Vision Transformer (ViT) has achieved remarkable performance in computer vision. However, positional encoding in ViT makes it substantially difficult to learn the intrinsic equivariance in data. Ini- tial attempts have been made on designing equiv- ariant ViT but are proved defective in some cases in this paper. To address this issue, we design a Group Equivariant Vision Transformer (GE-ViT) via a novel, effective positional encoding opera- tor. We prove that GE-ViT meets all the theoreti- cal requirements of an equivariant neural network. Comprehensive experiments are conducted on standard benchmark datasets, demonstrating that GE-ViT significantly outperforms non-equivariant self-attention networks. The code is available at https://github.com/ZJUCDSYangKaifan/GEVit.",
        "bibtex": "@InProceedings{pmlr-v216-xu23b,\n  title = \t {$E(2)$-Equivariant Vision Transformer},\n  author =       {Xu, Renjun and Yang, Kaifan and Liu, Ke and He, Fengxiang},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2356--2366},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/xu23b/xu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/xu23b.html},\n  abstract = \t {Vision Transformer (ViT) has achieved remarkable performance in computer vision. However, positional encoding in ViT makes it substantially difficult to learn the intrinsic equivariance in data. Ini- tial attempts have been made on designing equiv- ariant ViT but are proved defective in some cases in this paper. To address this issue, we design a Group Equivariant Vision Transformer (GE-ViT) via a novel, effective positional encoding opera- tor. We prove that GE-ViT meets all the theoreti- cal requirements of an equivariant neural network. Comprehensive experiments are conducted on standard benchmark datasets, demonstrating that GE-ViT significantly outperforms non-equivariant self-attention networks. The code is available at https://github.com/ZJUCDSYangKaifan/GEVit.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/xu23b/xu23b.pdf",
        "supp": "",
        "pdf_size": 794177,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5459137384293039771&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "College of Computer Science and Technology, Zhejiang University; College of Computer Science and Technology, Zhejiang University + JD Explore Academy, JD.com, Inc.; College of Computer Science and Technology, Zhejiang University; AIAI, School of Informatics, University of Edinburgh",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/ZJUCDSYangKaifan/GEVit",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;0;2",
        "aff_unique_norm": "Zhejiang University;JD.com, Inc.;University of Edinburgh",
        "aff_unique_dep": "College of Computer Science and Technology;JD Explore Academy;School of Informatics",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.jd.com;https://www.ed.ac.uk",
        "aff_unique_abbr": "ZJU;JD.com;Edinburgh",
        "aff_campus_unique_index": ";1",
        "aff_campus_unique": ";Edinburgh",
        "aff_country_unique_index": "0;0+0;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "27009c6da5",
        "title": "A Bayesian approach for bandit online optimization with switching cost",
        "site": "https://proceedings.mlr.press/v216/shi23b.html",
        "author": "Zai Shi; Jian Tan; Feifei Li",
        "abstract": "As a classical problem, online optimization with switching cost has been studied for a long time due to its wide applications in various areas. However, few works have investigated the bandit setting where both the forms of the main cost function $f(x)$ evaluated at state $x$ and the switching cost function $c(x, y)$ of transitioning from state $x$ to $y$ are unknown. In this paper, we consider the situation when $\\left(f(x_t)+\\varepsilon_t,\\,{c}(x_t, x_{t-1})\\right)$ can be observed with noise $\\varepsilon_t$ after making a decision $x_t$ at time $t$, aiming to minimize the expected total cost within a time horizon. To solve this problem, we propose two algorithms from a Bayesian approach,  named Greedy Search and Alternating Search, respectively. They have different theoretical guarantees of competitive ratios under mild regularity conditions, and the latter algorithm achieves a faster running speed. Using simulations of two classical black-box optimization problems,  we demonstrate the superior performance of our algorithms compared with the classical method.",
        "bibtex": "@InProceedings{pmlr-v216-shi23b,\n  title = \t {A {B}ayesian approach for bandit online optimization with switching cost},\n  author =       {Shi, Zai and Tan, Jian and Li, Feifei},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1953--1963},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/shi23b/shi23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/shi23b.html},\n  abstract = \t {As a classical problem, online optimization with switching cost has been studied for a long time due to its wide applications in various areas. However, few works have investigated the bandit setting where both the forms of the main cost function $f(x)$ evaluated at state $x$ and the switching cost function $c(x, y)$ of transitioning from state $x$ to $y$ are unknown. In this paper, we consider the situation when $\\left(f(x_t)+\\varepsilon_t,\\,{c}(x_t, x_{t-1})\\right)$ can be observed with noise $\\varepsilon_t$ after making a decision $x_t$ at time $t$, aiming to minimize the expected total cost within a time horizon. To solve this problem, we propose two algorithms from a Bayesian approach,  named Greedy Search and Alternating Search, respectively. They have different theoretical guarantees of competitive ratios under mild regularity conditions, and the latter algorithm achieves a faster running speed. Using simulations of two classical black-box optimization problems,  we demonstrate the superior performance of our algorithms compared with the classical method.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/shi23b/shi23b.pdf",
        "supp": "",
        "pdf_size": 775321,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3677382482824018227&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7ff9cdc020",
        "title": "A Data-Driven State Aggregation Approach for Dynamic Discrete Choice Models",
        "site": "https://proceedings.mlr.press/v216/geng23a.html",
        "author": "Sinong Geng; Houssam Nassif; Carlos A. Manzanares",
        "abstract": "In dynamic discrete choice models, a commonly studied problem is estimating parameters of agent reward functions (also known as \u2019structural\u2019 parameters) using agent behavioral data. This task is also known as inverse reinforcement learning. Maximum likelihood estimation for such models requires dynamic programming, which is limited by the curse of dimensionality [Bellman, 1957]. In this work, we present a novel algorithm that provides a data-driven method for selecting and aggregating states, which lowers the computational and sample complexity of estimation. Our method works in two stages. First, we estimate agent Qfunctions, and leverage them alongside a clustering algorithm to select a subset of states that are most pivotal for driving changes in Q-functions. Second, with these selected \"aggregated\" states, we conduct maximum likelihood estimation using a popular nested fixed-point algorithm [Rust, 1987]. The proposed two-stage approach mitigates the curse of dimensionality by reducing the problem dimension. Theoretically, we derive finite-sample bounds on the associated estimation error, which also characterize the trade-off of computational complexity, estimation error, and sample complexity. We demonstrate the empirical performance of the algorithm in two classic dynamic discrete choice estimation applications.",
        "bibtex": "@InProceedings{pmlr-v216-geng23a,\n  title = \t {A Data-Driven State Aggregation Approach for Dynamic Discrete Choice Models},\n  author =       {Geng, Sinong and Nassif, Houssam and Manzanares, Carlos A.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {647--657},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/geng23a/geng23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/geng23a.html},\n  abstract = \t {In dynamic discrete choice models, a commonly studied problem is estimating parameters of agent reward functions (also known as \u2019structural\u2019 parameters) using agent behavioral data. This task is also known as inverse reinforcement learning. Maximum likelihood estimation for such models requires dynamic programming, which is limited by the curse of dimensionality [Bellman, 1957]. In this work, we present a novel algorithm that provides a data-driven method for selecting and aggregating states, which lowers the computational and sample complexity of estimation. Our method works in two stages. First, we estimate agent Qfunctions, and leverage them alongside a clustering algorithm to select a subset of states that are most pivotal for driving changes in Q-functions. Second, with these selected \"aggregated\" states, we conduct maximum likelihood estimation using a popular nested fixed-point algorithm [Rust, 1987]. The proposed two-stage approach mitigates the curse of dimensionality by reducing the problem dimension. Theoretically, we derive finite-sample bounds on the associated estimation error, which also characterize the trade-off of computational complexity, estimation error, and sample complexity. We demonstrate the empirical performance of the algorithm in two classic dynamic discrete choice estimation applications.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/geng23a/geng23a.pdf",
        "supp": "",
        "pdf_size": 436048,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8508931438191835833&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Computer Science Department, Princeton University, Princeton, NJ, USA; Meta, Seattle, WA, USA; Amazon, Seattle, WA, USA",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Princeton University;Meta;Amazon",
        "aff_unique_dep": "Computer Science Department;Meta Platforms, Inc.;Amazon",
        "aff_unique_url": "https://www.princeton.edu;https://www.meta.com;https://www.amazon.com",
        "aff_unique_abbr": "Princeton;Meta;Amazon",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Princeton;Seattle",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "bd4410ab5a",
        "title": "A constrained Bayesian approach to out-of-distribution prediction",
        "site": "https://proceedings.mlr.press/v216/wang23f.html",
        "author": "Ziyu Wang; Binjie Yuan; Jiaxun Lu; Bowen Ding; Yunfeng Shao; Qibin Wu; Jun Zhu",
        "abstract": "Consider the problem of out-of-distribution prediction given data from multiple environments. While a sufficiently diverse collection of training environments will facilitate the identification of an invariant predictor, with an optimal generalization performance, many applications only provide us with a limited number of environments. It is thus necessary to consider adapting to distribution shift using a handful of labeled test samples. We propose a constrained Bayesian approach for this task, which restricts to models with a worst-group training loss above a prespecified threshold. Our method avoids a pathology of the standard Bayesian posterior, which occurs when spurious correlations improve in-distribution prediction. We also show that on certain high-dimensional linear problems, constrained modeling improves the sample efficiency of adaptation. Synthetic and real-world experiments demonstrate the robust performance of our approach.",
        "bibtex": "@InProceedings{pmlr-v216-wang23f,\n  title = \t {A constrained {B}ayesian approach to out-of-distribution prediction},\n  author =       {Wang, Ziyu and Yuan, Binjie and Lu, Jiaxun and Ding, Bowen and Shao, Yunfeng and Wu, Qibin and Zhu, Jun},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2248--2258},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/wang23f/wang23f.pdf},\n  url = \t {https://proceedings.mlr.press/v216/wang23f.html},\n  abstract = \t {Consider the problem of out-of-distribution prediction given data from multiple environments. While a sufficiently diverse collection of training environments will facilitate the identification of an invariant predictor, with an optimal generalization performance, many applications only provide us with a limited number of environments. It is thus necessary to consider adapting to distribution shift using a handful of labeled test samples. We propose a constrained Bayesian approach for this task, which restricts to models with a worst-group training loss above a prespecified threshold. Our method avoids a pathology of the standard Bayesian posterior, which occurs when spurious correlations improve in-distribution prediction. We also show that on certain high-dimensional linear problems, constrained modeling improves the sample efficiency of adaptation. Synthetic and real-world experiments demonstrate the robust performance of our approach.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/wang23f/wang23f.pdf",
        "supp": "",
        "pdf_size": 359841,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:REJ9a5G4-KcJ:scholar.google.com/&scioq=A+constrained+Bayesian+approach+to+out-of-distribution+prediction&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "aff": "Dept. of Comp. Sci. & Tech., BNRist Center, Tsinghua-Huawei Joint Center for AI, THBI Lab, Tsinghua University; Dept. of Comp. Sci. & Tech., BNRist Center, Tsinghua-Huawei Joint Center for AI, THBI Lab, Tsinghua University; Huawei Noah\u2019s Ark Lab; Huawei Technologies Co., Ltd.; Huawei Noah\u2019s Ark Lab; Huawei Technologies Co., Ltd.; Dept. of Comp. Sci. & Tech., BNRist Center, Tsinghua-Huawei Joint Center for AI, THBI Lab, Tsinghua University",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;1;1;1;0",
        "aff_unique_norm": "Tsinghua University;Huawei",
        "aff_unique_dep": "Department of Computer Science and Technology;Noah\u2019s Ark Lab",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.huawei.com",
        "aff_unique_abbr": "THU;Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "e45f34cda2",
        "title": "A decoder suffices for query-adaptive variational inference",
        "site": "https://proceedings.mlr.press/v216/agarwal23a.html",
        "author": "Sakshi Agarwal; Gabriel Hope; Ali Younis; Erik B. Sudderth",
        "abstract": "Deep generative models like variational autoencoders (VAEs) are widely used for density estimation and dimensionality reduction, but infer latent representations via amortized inference algorithms, which require that all data dimensions are observed. VAEs thus lack a key strength of probabilistic graphical models: the ability to infer posteriors for test queries with arbitrary structure. We demonstrate that many prior methods for imputation with VAEs are costly and ineffective, and achieve superior performance via query-adaptive variational inference (QAVI) algorithms based directly on the generative decoder.  By analytically marginalizing arbitrary sets of missing features, and optimizing expressive posteriors including mixtures and density flows, our non-amortized QAVI algorithms achieve excellent performance while avoiding expensive model retraining. On standard image and tabular datasets, our approach substantially outperforms prior methods in the plausibility and diversity of imputations.  We also show that QAVI effectively generalizes to recent hierarchical VAE models for high-dimensional images.",
        "bibtex": "@InProceedings{pmlr-v216-agarwal23a,\n  title = \t {A decoder suffices for query-adaptive variational inference},\n  author =       {Agarwal, Sakshi and Hope, Gabriel and Younis, Ali and Sudderth, Erik B.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {33--44},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/agarwal23a/agarwal23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/agarwal23a.html},\n  abstract = \t {Deep generative models like variational autoencoders (VAEs) are widely used for density estimation and dimensionality reduction, but infer latent representations via amortized inference algorithms, which require that all data dimensions are observed. VAEs thus lack a key strength of probabilistic graphical models: the ability to infer posteriors for test queries with arbitrary structure. We demonstrate that many prior methods for imputation with VAEs are costly and ineffective, and achieve superior performance via query-adaptive variational inference (QAVI) algorithms based directly on the generative decoder.  By analytically marginalizing arbitrary sets of missing features, and optimizing expressive posteriors including mixtures and density flows, our non-amortized QAVI algorithms achieve excellent performance while avoiding expensive model retraining. On standard image and tabular datasets, our approach substantially outperforms prior methods in the plausibility and diversity of imputations.  We also show that QAVI effectively generalizes to recent hierarchical VAE models for high-dimensional images.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/agarwal23a/agarwal23a.pdf",
        "supp": "",
        "pdf_size": 7946877,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13914563441395268703&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science, University of California, Irvine; Department of Computer Science, University of California, Irvine; Department of Computer Science, University of California, Irvine; Department of Computer Science, University of California, Irvine",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Irvine",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uci.edu",
        "aff_unique_abbr": "UCI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Irvine",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "58c9c1bea1",
        "title": "A near-optimal high-probability swap-Regret upper bound for multi-agent bandits in unknown general-sum games",
        "site": "https://proceedings.mlr.press/v216/huang23b.html",
        "author": "Zhiming Huang; Jianping Pan",
        "abstract": "In this paper, we study a multi-agent bandit problem in an unknown general-sum game repeated for a number of rounds\u00a0(i.e., learning in a black-box game with bandit feedback), where a set of agents have no information about the underlying game structure and cannot observe each other\u2019s actions and rewards. In each round, each agent needs to play an arm\u00a0(i.e., action) from a (possibly different) arm set\u00a0(i.e., action set), and only receives the reward of the played arm that is affected by other agents\u2019 actions. The objective of each agent is to minimize her own cumulative swap regret, where the swap regret is a generic performance measure for online learning algorithms. We are the first to give a near-optimal high-probability swap-regret upper bound based on a refined martingale analysis for the exponential-weighting-based algorithms with the implicit exploration technique, which can further bound the expected swap regret instead of the pseudo-regret studied in the literature. It is also guaranteed that correlated equilibria can be achieved in a polynomial number of rounds if the algorithm is played by all agents. Furthermore, we conduct numerical experiments to verify the performance of the studied algorithm.",
        "bibtex": "@InProceedings{pmlr-v216-huang23b,\n  title = \t {A near-optimal high-probability swap-Regret upper bound for multi-agent bandits in unknown general-sum games},\n  author =       {Huang, Zhiming and Pan, Jianping},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {911--921},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/huang23b/huang23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/huang23b.html},\n  abstract = \t {In this paper, we study a multi-agent bandit problem in an unknown general-sum game repeated for a number of rounds\u00a0(i.e., learning in a black-box game with bandit feedback), where a set of agents have no information about the underlying game structure and cannot observe each other\u2019s actions and rewards. In each round, each agent needs to play an arm\u00a0(i.e., action) from a (possibly different) arm set\u00a0(i.e., action set), and only receives the reward of the played arm that is affected by other agents\u2019 actions. The objective of each agent is to minimize her own cumulative swap regret, where the swap regret is a generic performance measure for online learning algorithms. We are the first to give a near-optimal high-probability swap-regret upper bound based on a refined martingale analysis for the exponential-weighting-based algorithms with the implicit exploration technique, which can further bound the expected swap regret instead of the pseudo-regret studied in the literature. It is also guaranteed that correlated equilibria can be achieved in a polynomial number of rounds if the algorithm is played by all agents. Furthermore, we conduct numerical experiments to verify the performance of the studied algorithm.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/huang23b/huang23b.pdf",
        "supp": "",
        "pdf_size": 1521636,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5335220350480160091&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science, University of Victoria, BC, Canada; Department of Computer Science, University of Victoria, BC, Canada",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Victoria",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uvic.ca",
        "aff_unique_abbr": "UVic",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Victoria",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "fbe411605d",
        "title": "A one-sample decentralized proximal algorithm for non-convex stochastic composite optimization",
        "site": "https://proceedings.mlr.press/v216/xiao23a.html",
        "author": "Tesi Xiao; Xuxing Chen; Krishnakumar Balasubramanian; Saeed Ghadimi",
        "abstract": "We focus on decentralized stochastic non-convex optimization, where $n$ agents work together to optimize a composite objective function which is a sum of a smooth term and a non-smooth convex term. To solve this problem, we propose two single-time scale algorithms: \\texttt{Prox-DASA} and \\texttt{Prox-DASA-GT}. These algorithms can find $\\epsilon$-stationary points in $\\mathcal{O}(n^{-1}\\epsilon^{-2})$ iterations using constant batch sizes (i.e., $\\mathcal{O}(1)$). Unlike prior work, our algorithms achieve comparable complexity without requiring large batch sizes, more complex per-iteration operations (such as double loops), or stronger assumptions. Our theoretical findings are supported by extensive numerical experiments, which demonstrate the superiority of our algorithms over previous approaches. Our code is available at \\url{https://github.com/xuxingc/ProxDASA}.",
        "bibtex": "@InProceedings{pmlr-v216-xiao23a,\n  title = \t {A one-sample decentralized proximal algorithm for non-convex stochastic composite optimization},\n  author =       {Xiao, Tesi and Chen, Xuxing and Balasubramanian, Krishnakumar and Ghadimi, Saeed},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2324--2334},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/xiao23a/xiao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/xiao23a.html},\n  abstract = \t {We focus on decentralized stochastic non-convex optimization, where $n$ agents work together to optimize a composite objective function which is a sum of a smooth term and a non-smooth convex term. To solve this problem, we propose two single-time scale algorithms: \\texttt{Prox-DASA} and \\texttt{Prox-DASA-GT}. These algorithms can find $\\epsilon$-stationary points in $\\mathcal{O}(n^{-1}\\epsilon^{-2})$ iterations using constant batch sizes (i.e., $\\mathcal{O}(1)$). Unlike prior work, our algorithms achieve comparable complexity without requiring large batch sizes, more complex per-iteration operations (such as double loops), or stronger assumptions. Our theoretical findings are supported by extensive numerical experiments, which demonstrate the superiority of our algorithms over previous approaches. Our code is available at \\url{https://github.com/xuxingc/ProxDASA}.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/xiao23a/xiao23a.pdf",
        "supp": "",
        "pdf_size": 610629,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8971413710148720092&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cd52ea08f5",
        "title": "A policy gradient approach for optimization of smooth risk measures",
        "site": "https://proceedings.mlr.press/v216/vijayan23a.html",
        "author": "Nithia Vijayan; L. A. Prashanth",
        "abstract": "We propose policy gradient algorithms for solving a risk-sensitive reinforcement learning (RL) problem in on-policy as well as off-policy settings. We consider episodic Markov decision processes, and model the risk using the broad class of smooth risk measures of the cumulative discounted reward. We propose two template policy gradient algorithms that optimize a smooth risk measure in on-policy and off-policy RL settings, respectively. We derive non-asymptotic bounds that quantify the rate of convergence of our proposed algorithms to a stationary point of the smooth risk measure. As special cases, we establish that our algorithms apply to optimization of mean-variance and distortion risk measures, respectively.",
        "bibtex": "@InProceedings{pmlr-v216-vijayan23a,\n  title = \t {A policy gradient approach for optimization of smooth risk measures},\n  author =       {Vijayan, Nithia and Prashanth, L. A.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2168--2178},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/vijayan23a/vijayan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/vijayan23a.html},\n  abstract = \t {We propose policy gradient algorithms for solving a risk-sensitive reinforcement learning (RL) problem in on-policy as well as off-policy settings. We consider episodic Markov decision processes, and model the risk using the broad class of smooth risk measures of the cumulative discounted reward. We propose two template policy gradient algorithms that optimize a smooth risk measure in on-policy and off-policy RL settings, respectively. We derive non-asymptotic bounds that quantify the rate of convergence of our proposed algorithms to a stationary point of the smooth risk measure. As special cases, we establish that our algorithms apply to optimization of mean-variance and distortion risk measures, respectively.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/vijayan23a/vijayan23a.pdf",
        "supp": "",
        "pdf_size": 384942,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12611555783171966400&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science and Engineering, Indian Institute of Technology Madras, India; Department of Computer Science and Engineering, Indian Institute of Technology Madras, India",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Technology Madras",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.iitm.ac.in",
        "aff_unique_abbr": "IIT Madras",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Madras",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "0e8d618aa6",
        "title": "A scalable Walsh-Hadamard regularizer to overcome the low-degree spectral bias of neural networks",
        "site": "https://proceedings.mlr.press/v216/gorji23a.html",
        "author": "Ali Gorji; Andisheh Amrollahi; Andreas Krause",
        "abstract": "Despite the capacity of neural nets to learn arbitrary functions, models trained through gradient descent often exhibit a bias towards \u201csimpler\u201d functions. Various notions of simplicity have been introduced to characterize this behavior. Here, we focus on the case of neural networks with discrete (zero-one) inputs through the lens of their Fourier (Walsh-Hadamard) transforms, where the notion of simplicity can be captured through the degree of the Fourier coefficients. We empirically show that neural networks have a tendency to learn lower-degree frequencies. We show how this spectral bias towards simpler features can in fact hurt the neural network\u2019s generalization on real-world datasets. To remedy this we propose a new scalable functional regularization scheme that aids the neural network to learn higher degree frequencies. Our regularizer also helps avoid erroneous identification of low-degree frequencies, which further improves generalization. We extensively evaluate our regularizer on synthetic datasets to gain insights into its behavior. Finally, we show significantly improved generalization on four different datasets compared to standard neural networks and other relevant baselines.",
        "bibtex": "@InProceedings{pmlr-v216-gorji23a,\n  title = \t {A scalable {W}alsh-{H}adamard regularizer to overcome the low-degree spectral bias of neural networks},\n  author =       {Gorji, Ali and Amrollahi, Andisheh and Krause, Andreas},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {723--733},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/gorji23a/gorji23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/gorji23a.html},\n  abstract = \t {Despite the capacity of neural nets to learn arbitrary functions, models trained through gradient descent often exhibit a bias towards \u201csimpler\u201d functions. Various notions of simplicity have been introduced to characterize this behavior. Here, we focus on the case of neural networks with discrete (zero-one) inputs through the lens of their Fourier (Walsh-Hadamard) transforms, where the notion of simplicity can be captured through the degree of the Fourier coefficients. We empirically show that neural networks have a tendency to learn lower-degree frequencies. We show how this spectral bias towards simpler features can in fact hurt the neural network\u2019s generalization on real-world datasets. To remedy this we propose a new scalable functional regularization scheme that aids the neural network to learn higher degree frequencies. Our regularizer also helps avoid erroneous identification of low-degree frequencies, which further improves generalization. We extensively evaluate our regularizer on synthetic datasets to gain insights into its behavior. Finally, we show significantly improved generalization on four different datasets compared to standard neural networks and other relevant baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/gorji23a/gorji23a.pdf",
        "supp": "",
        "pdf_size": 1686584,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=128374669391190098&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Computer Science Department, ETH Zurich, Zurich, Switzerland; Computer Science Department, ETH Zurich, Zurich, Switzerland; Computer Science Department, ETH Zurich, Zurich, Switzerland",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "bce4549b4e",
        "title": "A trajectory is worth three sentences: multimodal transformer for offline reinforcement learning",
        "site": "https://proceedings.mlr.press/v216/wang23d.html",
        "author": "Yiqi Wang; Mengdi Xu; Laixi Shi; Yuejie Chi",
        "abstract": "Transformers hold tremendous promise in solving offline reinforcement learning (RL) by formulating it as a sequence modeling problem inspired by language modeling (LM). Prior works using transformers model a sample (trajectory) of RL as one sequence analogous to a sequence of words (one sentence) in LM, despite the fact that each trajectory includes tokens from three diverse modalities: state, action, and reward, while a sentence contains words only. Rather than taking a modality-agnostic approach which uniformly models the tokens from different modalities as one sequence, we propose a multimodal sequence modeling approach in which a trajectory (one \u201csentence\u201d) of three modalities (state, action, reward) is disentangled into three unimodal ones (three \u201csentences\u201d). We investigate the correlation of different modalities during sequential decision-making and use the insights to design a multimodal transformer, named Decision Transducer (DTd). DTd outperforms prior art in offline RL on the conducted D4RL benchmarks and enjoys better sample efficiency and algorithm flexibility. Our code is made publicly here.",
        "bibtex": "@InProceedings{pmlr-v216-wang23d,\n  title = \t {A trajectory is worth three sentences: multimodal transformer for offline reinforcement learning},\n  author =       {Wang, Yiqi and Xu, Mengdi and Shi, Laixi and Chi, Yuejie},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2226--2236},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/wang23d/wang23d.pdf},\n  url = \t {https://proceedings.mlr.press/v216/wang23d.html},\n  abstract = \t {Transformers hold tremendous promise in solving offline reinforcement learning (RL) by formulating it as a sequence modeling problem inspired by language modeling (LM). Prior works using transformers model a sample (trajectory) of RL as one sequence analogous to a sequence of words (one sentence) in LM, despite the fact that each trajectory includes tokens from three diverse modalities: state, action, and reward, while a sentence contains words only. Rather than taking a modality-agnostic approach which uniformly models the tokens from different modalities as one sequence, we propose a multimodal sequence modeling approach in which a trajectory (one \u201csentence\u201d) of three modalities (state, action, reward) is disentangled into three unimodal ones (three \u201csentences\u201d). We investigate the correlation of different modalities during sequential decision-making and use the insights to design a multimodal transformer, named Decision Transducer (DTd). DTd outperforms prior art in offline RL on the conducted D4RL benchmarks and enjoys better sample efficiency and algorithm flexibility. Our code is made publicly here.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/wang23d/wang23d.pdf",
        "supp": "",
        "pdf_size": 2588433,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5028744969340817862&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a43309d215",
        "title": "ASTRA: Understanding the practical impact of robustness for probabilistic programs",
        "site": "https://proceedings.mlr.press/v216/huang23a.html",
        "author": "Zixin Huang; Saikat Dutta; Sasa Misailovic",
        "abstract": "We present the first systematic study of effectiveness of robustness transformations on a diverse set of 24 probabilistic programs representing generalized linear models, mixture models, and time-series models. We evaluate five robustness transformations from literature on each model. We quantify and present insights on (1) the improvement of the posterior prediction accuracy and (2) the execution time overhead of the robustified programs, in the presence of three input noise models.  To automate the evaluation of various robustness transformations, we developed ASTRA - a novel framework for quantifying the robustness of probabilistic programs and exploring the trade-offs between robustness and execution time. Our experimental results indicate that the existing transformations are often suitable only for specific noise models, can significantly increase execution time, and have non-trivial interaction with the inference algorithms.",
        "bibtex": "@InProceedings{pmlr-v216-huang23a,\n  title = \t {{ASTRA}: Understanding the practical impact of robustness for probabilistic programs},\n  author =       {Huang, Zixin and Dutta, Saikat and Misailovic, Sasa},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {900--910},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/huang23a/huang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/huang23a.html},\n  abstract = \t {We present the first systematic study of effectiveness of robustness transformations on a diverse set of 24 probabilistic programs representing generalized linear models, mixture models, and time-series models. We evaluate five robustness transformations from literature on each model. We quantify and present insights on (1) the improvement of the posterior prediction accuracy and (2) the execution time overhead of the robustified programs, in the presence of three input noise models.  To automate the evaluation of various robustness transformations, we developed ASTRA - a novel framework for quantifying the robustness of probabilistic programs and exploring the trade-offs between robustness and execution time. Our experimental results indicate that the existing transformations are often suitable only for specific noise models, can significantly increase execution time, and have non-trivial interaction with the inference algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/huang23a/huang23a.pdf",
        "supp": "",
        "pdf_size": 545879,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12853053927994825822&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "80af486c55",
        "title": "AUC Maximization in Imbalanced Lifelong Learning",
        "site": "https://proceedings.mlr.press/v216/zhu23a.html",
        "author": "Xiangyu Zhu; Jie Hao; Yunhui Guo; Mingrui Liu",
        "abstract": "Imbalanced data is ubiquitous in machine learning, such as medical or fine-grained image datasets. The existing continual learning methods employ various techniques such as balanced sampling to improve classification accuracy in this setting. However, classification accuracy is not a suitable metric for imbalanced data, and hence these methods may not obtain a good classifier as measured by other metrics (e.g., Area under the ROC Curve). In this paper, we propose a solution to enable efficient imbalanced continual learning by designing an algorithm to effectively maximize one widely used metric in an imbalanced data setting: Area Under the ROC Curve (AUC). We find that simply replacing accuracy with AUC will cause",
        "bibtex": "@InProceedings{pmlr-v216-zhu23a,\n  title = \t {{AUC} Maximization in Imbalanced Lifelong Learning},\n  author =       {Zhu, Xiangyu and Hao, Jie and Guo, Yunhui and Liu, Mingrui},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2574--2585},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zhu23a/zhu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zhu23a.html},\n  abstract = \t {Imbalanced data is ubiquitous in machine learning, such as medical or fine-grained image datasets. The existing continual learning methods employ various techniques such as balanced sampling to improve classification accuracy in this setting. However, classification accuracy is not a suitable metric for imbalanced data, and hence these methods may not obtain a good classifier as measured by other metrics (e.g., Area under the ROC Curve). In this paper, we propose a solution to enable efficient imbalanced continual learning by designing an algorithm to effectively maximize one widely used metric in an imbalanced data setting: Area Under the ROC Curve (AUC). We find that simply replacing accuracy with AUC will cause",
        "pdf": "https://proceedings.mlr.press/v216/zhu23a/zhu23a.pdf",
        "supp": "",
        "pdf_size": 509328,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10529091726475361016&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bd89d8b97d",
        "title": "Accelerating Voting by Quantum Computation",
        "site": "https://proceedings.mlr.press/v216/liu23a.html",
        "author": "Ao Liu; Qishen Han; Lirong Xia; Nengkun Yu",
        "abstract": "Studying the computational complexity and designing fast algorithms for determining winners under voting rules are classical and fundamental questions in computational social choice. In this paper, we accelerate voting by leveraging quantum computation: we propose a quantum-accelerated voting algorithm that can be applied to any anonymous voting rule. We show that our algorithm can be quadratically faster than any classical algorithm (based on sampling with replacement) under a wide range of common voting rules, including positional scoring rules, Copeland, and single transferable voting (STV). Precisely, our quantum-accelerated voting algorithm outputs the correct winner with high probability in $\\Theta\\left(\\frac{n}{\\text{MOV}}\\right)$ time, where $n$ is the number of votes and $\\text{MOV}$ is",
        "bibtex": "@InProceedings{pmlr-v216-liu23a,\n  title = \t {Accelerating Voting by Quantum Computation},\n  author =       {Liu, Ao and Han, Qishen and Xia, Lirong and Yu, Nengkun},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1274--1283},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/liu23a/liu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/liu23a.html},\n  abstract = \t {Studying the computational complexity and designing fast algorithms for determining winners under voting rules are classical and fundamental questions in computational social choice. In this paper, we accelerate voting by leveraging quantum computation: we propose a quantum-accelerated voting algorithm that can be applied to any anonymous voting rule. We show that our algorithm can be quadratically faster than any classical algorithm (based on sampling with replacement) under a wide range of common voting rules, including positional scoring rules, Copeland, and single transferable voting (STV). Precisely, our quantum-accelerated voting algorithm outputs the correct winner with high probability in $\\Theta\\left(\\frac{n}{\\text{MOV}}\\right)$ time, where $n$ is the number of votes and $\\text{MOV}$ is",
        "pdf": "https://proceedings.mlr.press/v216/liu23a/liu23a.pdf",
        "supp": "",
        "pdf_size": 334596,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4303470728672609885&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "411025d34a",
        "title": "Active metric learning and classification using similarity queries",
        "site": "https://proceedings.mlr.press/v216/nadagouda23a.html",
        "author": "Namrata Nadagouda; Austin Xu; Mark A. Davenport",
        "abstract": "Active learning is commonly used to train label-efficient models by adaptively selecting the most informative queries. However, most active learning strategies are designed to either learn a representation of the data (e.g., embedding or metric learning) or perform well on a task (e.g., classification) on the data. However, many machine learning tasks involve a combination of both representation learning and a task-specific goal. Motivated by this, we propose a novel unified query framework that can be applied to any problem in which a key component is learning a representation of the data that reflects similarity. Our approach builds on similarity or nearest neighbor (NN) queries which seek to select samples that result in improved embeddings. The queries consist of a reference and a set of objects, with an oracle selecting the object most similar (i.e., nearest) to the reference. In order to reduce the number of solicited queries, they are chosen adaptively according to an information theoretic criterion. We demonstrate the effectiveness of the proposed strategy on two tasks - active metric learning and active classification - using a variety of synthetic and real world datasets. In particular, we demonstrate that actively selected NN queries outperform recently developed active triplet selection methods in a deep metric learning setting. Further, we show that in classification, actively selecting class labels can be reformulated as a process of selecting the most informative NN query, allowing direct application of our method.",
        "bibtex": "@InProceedings{pmlr-v216-nadagouda23a,\n  title = \t {Active metric learning and classification using similarity queries},\n  author =       {Nadagouda, Namrata and Xu, Austin and Davenport, Mark A.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1478--1488},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/nadagouda23a/nadagouda23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/nadagouda23a.html},\n  abstract = \t {Active learning is commonly used to train label-efficient models by adaptively selecting the most informative queries. However, most active learning strategies are designed to either learn a representation of the data (e.g., embedding or metric learning) or perform well on a task (e.g., classification) on the data. However, many machine learning tasks involve a combination of both representation learning and a task-specific goal. Motivated by this, we propose a novel unified query framework that can be applied to any problem in which a key component is learning a representation of the data that reflects similarity. Our approach builds on similarity or nearest neighbor (NN) queries which seek to select samples that result in improved embeddings. The queries consist of a reference and a set of objects, with an oracle selecting the object most similar (i.e., nearest) to the reference. In order to reduce the number of solicited queries, they are chosen adaptively according to an information theoretic criterion. We demonstrate the effectiveness of the proposed strategy on two tasks - active metric learning and active classification - using a variety of synthetic and real world datasets. In particular, we demonstrate that actively selected NN queries outperform recently developed active triplet selection methods in a deep metric learning setting. Further, we show that in classification, actively selecting class labels can be reformulated as a process of selecting the most informative NN query, allowing direct application of our method.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/nadagouda23a/nadagouda23a.pdf",
        "supp": "",
        "pdf_size": 3486679,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4843130435418285372&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c86f6023e6",
        "title": "Adaptive Conditional Quantile Neural Processes",
        "site": "https://proceedings.mlr.press/v216/mohseni23a.html",
        "author": "Peiman Mohseni; Nick Duffield; Bani Mallick; Arman Hasanzadeh",
        "abstract": "Neural processes are a family of probabilistic models that inherit the flexibility of neural networks to parameterize stochastic processes. Despite providing well-calibrated predictions, especially in regression problems, and quick adaptation to new tasks, the Gaussian assumption that is commonly used to represent the predictive likelihood fails to capture more complicated distributions such as multimodal ones. To overcome this limitation, we propose Conditional Quantile Neural Processes (CQNPs), a new member of the neural processes family, which exploits the attractive properties of quantile regression in modeling the distributions irrespective of their form. By introducing an extension of quantile regression where the model learns to focus on estimating",
        "bibtex": "@InProceedings{pmlr-v216-mohseni23a,\n  title = \t {Adaptive Conditional Quantile Neural Processes},\n  author =       {Mohseni, Peiman and Duffield, Nick and Mallick, Bani and Hasanzadeh, Arman},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1445--1455},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/mohseni23a/mohseni23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/mohseni23a.html},\n  abstract = \t {Neural processes are a family of probabilistic models that inherit the flexibility of neural networks to parameterize stochastic processes. Despite providing well-calibrated predictions, especially in regression problems, and quick adaptation to new tasks, the Gaussian assumption that is commonly used to represent the predictive likelihood fails to capture more complicated distributions such as multimodal ones. To overcome this limitation, we propose Conditional Quantile Neural Processes (CQNPs), a new member of the neural processes family, which exploits the attractive properties of quantile regression in modeling the distributions irrespective of their form. By introducing an extension of quantile regression where the model learns to focus on estimating",
        "pdf": "https://proceedings.mlr.press/v216/mohseni23a/mohseni23a.pdf",
        "supp": "",
        "pdf_size": 2567875,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13968556916675471884&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "709edca6d8",
        "title": "Adaptivity Complexity for Causal Graph Discovery",
        "site": "https://proceedings.mlr.press/v216/choo23a.html",
        "author": "Davin Choo; Kirankumar Shiragur",
        "abstract": "Causal discovery from interventional data is an important problem, where the task is to design an interventional strategy that learns the hidden ground truth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of performed interventions. Most prior interventional strategies broadly fall into two categories: non-adaptive and adaptive. Non-adaptive strategies decide on a single fixed set of interventions to be performed while adaptive strategies can decide on which nodes to intervene on sequentially based on past interventions. While adaptive algorithms may use exponentially fewer interventions than their non-adaptive counterparts, there are practical concerns that constrain the amount of adaptivity allowed. Motivated by this trade-off, we study the problem of $r$-adaptivity, where the algorithm designer recovers the causal graph under a total of $r$ sequential rounds whilst trying to minimize the total number of interventions. For this problem, we provide a $r$-adaptive algorithm that achieves $O(\\min\\{r,\\log n\\} \\cdot n^{1/\\min\\{r,\\log n\\}})$ approximation with respect to the verification number, a well-known lower bound for adaptive algorithms. Furthermore, for every $r$, we show that our approximation is tight. Our definition of $r$-adaptivity interpolates nicely between the non-adaptive ($r=1$) and fully adaptive ($r=n$) settings where our approximation simplifies to $O(n)$ and $O(\\log n)$ respectively, matching the best-known approximation guarantees for both extremes. Our results also extend naturally to the bounded size interventions.",
        "bibtex": "@InProceedings{pmlr-v216-choo23a,\n  title = \t {Adaptivity Complexity for Causal Graph Discovery},\n  author =       {Choo, Davin and Shiragur, Kirankumar},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {391--402},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/choo23a/choo23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/choo23a.html},\n  abstract = \t {Causal discovery from interventional data is an important problem, where the task is to design an interventional strategy that learns the hidden ground truth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of performed interventions. Most prior interventional strategies broadly fall into two categories: non-adaptive and adaptive. Non-adaptive strategies decide on a single fixed set of interventions to be performed while adaptive strategies can decide on which nodes to intervene on sequentially based on past interventions. While adaptive algorithms may use exponentially fewer interventions than their non-adaptive counterparts, there are practical concerns that constrain the amount of adaptivity allowed. Motivated by this trade-off, we study the problem of $r$-adaptivity, where the algorithm designer recovers the causal graph under a total of $r$ sequential rounds whilst trying to minimize the total number of interventions. For this problem, we provide a $r$-adaptive algorithm that achieves $O(\\min\\{r,\\log n\\} \\cdot n^{1/\\min\\{r,\\log n\\}})$ approximation with respect to the verification number, a well-known lower bound for adaptive algorithms. Furthermore, for every $r$, we show that our approximation is tight. Our definition of $r$-adaptivity interpolates nicely between the non-adaptive ($r=1$) and fully adaptive ($r=n$) settings where our approximation simplifies to $O(n)$ and $O(\\log n)$ respectively, matching the best-known approximation guarantees for both extremes. Our results also extend naturally to the bounded size interventions.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/choo23a/choo23a.pdf",
        "supp": "",
        "pdf_size": 889736,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13423102792239477129&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "School of Computing, National University of Singapore; Broad Institute of MIT and Harvard",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "National University of Singapore;Broad Institute",
        "aff_unique_dep": "School of Computing;",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.broadinstitute.org",
        "aff_unique_abbr": "NUS;Broad",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "ef32939595",
        "title": "Aligned Diffusion Schr\u00f6dinger Bridges",
        "site": "https://proceedings.mlr.press/v216/somnath23a.html",
        "author": "Vignesh Ram Somnath; Matteo Pariset; Ya-Ping Hsieh; Maria Rodriguez Martinez; Andreas Krause; Charlotte Bunne",
        "abstract": "Diffusion Schr\u00f6dinger bridges (DSBs) have recently emerged as a powerful framework for recovering stochastic dynamics via their marginal observations at different time points. Despite numerous successful applications, existing algorithms for solving DSBs have so far failed to utilize the structure of aligned data, which naturally arises in many biological phenomena. In this paper, we propose a novel algorithmic framework that, for the first time, solves DSBs while respecting the data alignment. Our approach hinges on a combination of two decades-old ideas: The classical Schr\u00f6dinger bridge theory and Doob\u2019s $h$-transform. Compared to prior methods, our approach leads to a simpler training procedure with lower variance, which we further augment with principled regularization schemes. This ultimately leads to sizeable improvements across experiments on synthetic and real data, including the tasks of predicting conformational changes in proteins and temporal evolution of cellular differentiation processes.",
        "bibtex": "@InProceedings{pmlr-v216-somnath23a,\n  title = \t {Aligned Diffusion {S}chr\u00f6dinger Bridges},\n  author =       {Somnath, Vignesh Ram and Pariset, Matteo and Hsieh, Ya-Ping and Martinez, Maria Rodriguez and Krause, Andreas and Bunne, Charlotte},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1985--1995},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/somnath23a/somnath23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/somnath23a.html},\n  abstract = \t {Diffusion Schr\u00f6dinger bridges (DSBs) have recently emerged as a powerful framework for recovering stochastic dynamics via their marginal observations at different time points. Despite numerous successful applications, existing algorithms for solving DSBs have so far failed to utilize the structure of aligned data, which naturally arises in many biological phenomena. In this paper, we propose a novel algorithmic framework that, for the first time, solves DSBs while respecting the data alignment. Our approach hinges on a combination of two decades-old ideas: The classical Schr\u00f6dinger bridge theory and Doob\u2019s $h$-transform. Compared to prior methods, our approach leads to a simpler training procedure with lower variance, which we further augment with principled regularization schemes. This ultimately leads to sizeable improvements across experiments on synthetic and real data, including the tasks of predicting conformational changes in proteins and temporal evolution of cellular differentiation processes.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/somnath23a/somnath23a.pdf",
        "supp": "",
        "pdf_size": 4441271,
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11490350314499208499&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5d602ca1d3",
        "title": "Amortized Inference for Gaussian Process Hyperparameters of Structured Kernels",
        "site": "https://proceedings.mlr.press/v216/bitzer23a.html",
        "author": "Matthias Bitzer; Mona Meister; Christoph Zimmer",
        "abstract": "Learning the kernel parameters for Gaussian processes is often the computational bottleneck in applications such as online learning, Bayesian optimization, or active learning. Amortizing parameter inference over different datasets is a promising approach to dramatically speed up training time. However, existing methods restrict the amortized inference procedure to a fixed kernel structure. The amortization network must be redesigned manually and trained again in case a different kernel is employed, which leads to a large overhead in design time and training time. We propose amortizing kernel parameter inference over a complete kernel-structure-family rather than a fixed kernel structure. We do that via defining an amortization network over pairs of datasets and kernel structures. This enables fast kernel inference for each element in the kernel family without retraining the amortization network. As a by-product, our amortization network is able to do fast ensembling over kernel structures. In our experiments, we show drastically reduced inference time combined with competitive test performance for a large set of kernels and datasets.",
        "bibtex": "@InProceedings{pmlr-v216-bitzer23a,\n  title = \t {Amortized Inference for {G}aussian Process Hyperparameters of Structured Kernels},\n  author =       {Bitzer, Matthias and Meister, Mona and Zimmer, Christoph},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {184--194},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/bitzer23a/bitzer23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/bitzer23a.html},\n  abstract = \t {Learning the kernel parameters for Gaussian processes is often the computational bottleneck in applications such as online learning, Bayesian optimization, or active learning. Amortizing parameter inference over different datasets is a promising approach to dramatically speed up training time. However, existing methods restrict the amortized inference procedure to a fixed kernel structure. The amortization network must be redesigned manually and trained again in case a different kernel is employed, which leads to a large overhead in design time and training time. We propose amortizing kernel parameter inference over a complete kernel-structure-family rather than a fixed kernel structure. We do that via defining an amortization network over pairs of datasets and kernel structures. This enables fast kernel inference for each element in the kernel family without retraining the amortization network. As a by-product, our amortization network is able to do fast ensembling over kernel structures. In our experiments, we show drastically reduced inference time combined with competitive test performance for a large set of kernels and datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/bitzer23a/bitzer23a.pdf",
        "supp": "",
        "pdf_size": 1727107,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15729623967921540921&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5a97ac590c",
        "title": "An effective negotiating agent framework based on deep offline reinforcement learning",
        "site": "https://proceedings.mlr.press/v216/chen23c.html",
        "author": "Siqi Chen; Jianing Zhao; Gerhard Weiss; Ran Su; Kaiyou Lei",
        "abstract": "Learning is crucial for automated negotiation, and recent years have witnessed a remarkable achievement in application of reinforcement learning (RL) for various negotiation tasks. Conventional RL methods focus generally on learning from active interactions with opposing negotiators. However, collecting online data is expensive in many realistic negotiation scenarios. While previous studies partially mitigate this problem through the use of opponent simulators (i.e., agents following known strategies), in reality it is usually hard to fully capture an opponent\u2019s negotiation strategy. Moreover, a further challenge lies in an agent\u2019s capability of adapting to dynamic variations of an opponent\u2019s preferences or strategies, which may happen from time to time for different reasons in subsequent negotiations. In response to these challenges, this article proposes a novel Deep Offline Reinforcement learning Negotiating Agent framework that allows to learn an effective strategy using previously collected negotiation datasets without requiring interaction with an opponent. This is in contrast to existing RL-based negotiation approaches that all rely on active interaction with opponents. Furthermore, the strategy fine-tuning mechanism is included to adjust the learned strategy in response to the preferences or strategy changes of the opponent. The performance of the proposed framework is evaluated based on a diverse set of state-of-the-art baselines under different settings. Experimental results show that the framework allows to learn effective strategies exclusively with offline datasets, and is also capable of effectively adapting to changes of an opponent\u2019s preferences or strategy.",
        "bibtex": "@InProceedings{pmlr-v216-chen23c,\n  title = \t {An effective negotiating agent framework based on deep offline reinforcement learning},\n  author =       {Chen, Siqi and Zhao, Jianing and Weiss, Gerhard and Su, Ran and Lei, Kaiyou},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {324--335},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/chen23c/chen23c.pdf},\n  url = \t {https://proceedings.mlr.press/v216/chen23c.html},\n  abstract = \t {Learning is crucial for automated negotiation, and recent years have witnessed a remarkable achievement in application of reinforcement learning (RL) for various negotiation tasks. Conventional RL methods focus generally on learning from active interactions with opposing negotiators. However, collecting online data is expensive in many realistic negotiation scenarios. While previous studies partially mitigate this problem through the use of opponent simulators (i.e., agents following known strategies), in reality it is usually hard to fully capture an opponent\u2019s negotiation strategy. Moreover, a further challenge lies in an agent\u2019s capability of adapting to dynamic variations of an opponent\u2019s preferences or strategies, which may happen from time to time for different reasons in subsequent negotiations. In response to these challenges, this article proposes a novel Deep Offline Reinforcement learning Negotiating Agent framework that allows to learn an effective strategy using previously collected negotiation datasets without requiring interaction with an opponent. This is in contrast to existing RL-based negotiation approaches that all rely on active interaction with opponents. Furthermore, the strategy fine-tuning mechanism is included to adjust the learned strategy in response to the preferences or strategy changes of the opponent. The performance of the proposed framework is evaluated based on a diverse set of state-of-the-art baselines under different settings. Experimental results show that the framework allows to learn effective strategies exclusively with offline datasets, and is also capable of effectively adapting to changes of an opponent\u2019s preferences or strategy.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/chen23c/chen23c.pdf",
        "supp": "",
        "pdf_size": 713895,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11835839776205512353&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Intelligence and Computing, Tianjin University, Tianjin, China; Department of Advanced Computing Sciences, Maastricht University, Maastricht, the Netherlands; College of Intelligence and Computing, Tianjin University, Tianjin, China; College of Computer and Information Science, Southwest University, Chongqing, China",
        "aff_domain": "tju.edu.cn;tju.edu.cn;maastrichtuniversity.nl;tju.edu.cn;163.com",
        "email": "tju.edu.cn;tju.edu.cn;maastrichtuniversity.nl;tju.edu.cn;163.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "Tianjin University;Maastricht University;Southwest University",
        "aff_unique_dep": "College of Intelligence and Computing;Department of Advanced Computing Sciences;College of Computer and Information Science",
        "aff_unique_url": "http://www.tju.edu.cn;https://www.maastrichtuniversity.nl;http://www.swu.edu.cn",
        "aff_unique_abbr": "Tianjin University;MU;",
        "aff_campus_unique_index": "0;0;1;0;2",
        "aff_campus_unique": "Tianjin;Maastricht;Chongqing",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "China;Netherlands"
    },
    {
        "id": "7de87548e4",
        "title": "An improved variational approximate posterior for the deep Wishart process",
        "site": "https://proceedings.mlr.press/v216/ober23a.html",
        "author": "Sebastian W. Ober; Ben Anson; Edward Milsom; Laurence Aitchison",
        "abstract": "Deep kernel processes are a recently introduced class of deep Bayesian models that have the flexibility of neural networks, but work entirely with Gram matrices. They operate by alternately sampling a Gram matrix from a distribution over positive semi-definite matrices, and applying a deterministic transformation. When the distribution is chosen to be Wishart, the model is called a deep Wishart process (DWP). This particular model is of interest because its prior is equivalent to a deep Gaussian process (DGP) prior, but at the same time it is invariant to rotational symmetries, leading to a simpler posterior distribution. Practical inference in the DWP was made possible in recent work (\u201cA variational approximate posterior for the deep Wishart process\u201d Ober and Aitchison, 2021a) where the authors used a generalisation of the Bartlett decomposition of the Wishart distribution as the variational approximate posterior. However, predictive performance in that paper was less impressive than one might expect, with the DWP only beating a DGP on a few of the UCI datasets used for comparison. In this paper, we show that further generalising their distribution to allow linear combinations of rows and columns in the Bartlett decomposition results in better predictive performance, while incurring negligible additional computation cost.",
        "bibtex": "@InProceedings{pmlr-v216-ober23a,\n  title = \t {An improved variational approximate posterior for the deep {W}ishart process},\n  author =       {Ober, Sebastian W. and Anson, Ben and Milsom, Edward and Aitchison, Laurence},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1555--1563},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/ober23a/ober23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/ober23a.html},\n  abstract = \t {Deep kernel processes are a recently introduced class of deep Bayesian models that have the flexibility of neural networks, but work entirely with Gram matrices. They operate by alternately sampling a Gram matrix from a distribution over positive semi-definite matrices, and applying a deterministic transformation. When the distribution is chosen to be Wishart, the model is called a deep Wishart process (DWP). This particular model is of interest because its prior is equivalent to a deep Gaussian process (DGP) prior, but at the same time it is invariant to rotational symmetries, leading to a simpler posterior distribution. Practical inference in the DWP was made possible in recent work (\u201cA variational approximate posterior for the deep Wishart process\u201d Ober and Aitchison, 2021a) where the authors used a generalisation of the Bartlett decomposition of the Wishart distribution as the variational approximate posterior. However, predictive performance in that paper was less impressive than one might expect, with the DWP only beating a DGP on a few of the UCI datasets used for comparison. In this paper, we show that further generalising their distribution to allow linear combinations of rows and columns in the Bartlett decomposition results in better predictive performance, while incurring negligible additional computation cost.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/ober23a/ober23a.pdf",
        "supp": "",
        "pdf_size": 360741,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11368044081990959977&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "67f6ca9a7a",
        "title": "Approximate Thompson Sampling via Epistemic Neural Networks",
        "site": "https://proceedings.mlr.press/v216/osband23a.html",
        "author": "Ian Osband; Zheng Wen; Seyed Mohammad Asghari; Vikranth Dwaracherla; Morteza Ibrahimi; Xiuyuan Lu; Benjamin Van Roy",
        "abstract": "Thompson sampling (TS) is a popular heuristic for action selection, but it requires sampling from a posterior distribution. Unfortunately, this can become computationally intractable in complex environments, such as those modeled using neural networks. Approximate posterior samples can produce effective actions, but only if they reasonably approximate joint predictive distributions of outputs across inputs. Notably, accuracy of marginal predictive distributions does not suffice. Epistemic neural networks (ENNs) are designed to produce accurate joint predictive distributions. We compare a range of ENNs through computational experiments that assess their performance in approximating TS across bandit and reinforcement learning environments. The results indicate that ENNs serve this purpose well and illustrate how the quality of joint predictive distributions drives performance. Further, we demonstrate that the",
        "bibtex": "@InProceedings{pmlr-v216-osband23a,\n  title = \t {Approximate {T}hompson Sampling via Epistemic Neural Networks},\n  author =       {Osband, Ian and Wen, Zheng and Asghari, Seyed Mohammad and Dwaracherla, Vikranth and Ibrahimi, Morteza and Lu, Xiuyuan and Van Roy, Benjamin},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1586--1595},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/osband23a/osband23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/osband23a.html},\n  abstract = \t {Thompson sampling (TS) is a popular heuristic for action selection, but it requires sampling from a posterior distribution. Unfortunately, this can become computationally intractable in complex environments, such as those modeled using neural networks. Approximate posterior samples can produce effective actions, but only if they reasonably approximate joint predictive distributions of outputs across inputs. Notably, accuracy of marginal predictive distributions does not suffice. Epistemic neural networks (ENNs) are designed to produce accurate joint predictive distributions. We compare a range of ENNs through computational experiments that assess their performance in approximating TS across bandit and reinforcement learning environments. The results indicate that ENNs serve this purpose well and illustrate how the quality of joint predictive distributions drives performance. Further, we demonstrate that the",
        "pdf": "https://proceedings.mlr.press/v216/osband23a/osband23a.pdf",
        "supp": "",
        "pdf_size": 609630,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2465158246900575471&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "dbf4fe71bd",
        "title": "Approximately Bayes-optimal pseudo-label selection",
        "site": "https://proceedings.mlr.press/v216/rodemann23a.html",
        "author": "Julian Rodemann; Jann Goschenhofer; Emilio Dorigatti; Thomas Nagler; Thomas Augustin",
        "abstract": "Semi-supervised learning by self-training heavily relies on pseudo-label selection (PLS). This selection often depends on the initial model fit on labeled data. Early overfitting might thus be propagated to the final model by selecting instances with overconfident but erroneous predictions, often referred to as confirmation bias. This paper introduces BPLS, a Bayesian framework for PLS that aims to mitigate this issue. At its core lies a criterion for selecting instances to label: an analytical approximation of the posterior predictive of pseudo-samples. We derive this selection criterion by proving Bayes-optimality of the posterior predictive of pseudo-samples. We further overcome computational hurdles by approximating the criterion analytically. Its relation to the marginal likelihood allows us to come up with an approximation based on Laplace\u2019s method and the Gaussian integral. We empirically assess BPLS on simulated and real-world data. When faced with high-dimensional data prone to overfitting, BPLS outperforms traditional PLS methods.",
        "bibtex": "@InProceedings{pmlr-v216-rodemann23a,\n  title = \t {Approximately {B}ayes-optimal pseudo-label selection},\n  author =       {Rodemann, Julian and Goschenhofer, Jann and Dorigatti, Emilio and Nagler, Thomas and Augustin, Thomas},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1762--1773},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/rodemann23a/rodemann23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/rodemann23a.html},\n  abstract = \t {Semi-supervised learning by self-training heavily relies on pseudo-label selection (PLS). This selection often depends on the initial model fit on labeled data. Early overfitting might thus be propagated to the final model by selecting instances with overconfident but erroneous predictions, often referred to as confirmation bias. This paper introduces BPLS, a Bayesian framework for PLS that aims to mitigate this issue. At its core lies a criterion for selecting instances to label: an analytical approximation of the posterior predictive of pseudo-samples. We derive this selection criterion by proving Bayes-optimality of the posterior predictive of pseudo-samples. We further overcome computational hurdles by approximating the criterion analytically. Its relation to the marginal likelihood allows us to come up with an approximation based on Laplace\u2019s method and the Gaussian integral. We empirically assess BPLS on simulated and real-world data. When faced with high-dimensional data prone to overfitting, BPLS outperforms traditional PLS methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/rodemann23a/rodemann23a.pdf",
        "supp": "",
        "pdf_size": 1184203,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6338542310655349296&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Statistics, Ludwig-Maximilians-Universit\u00e4t (LMU), Munich, Germany+Munich Center for Machine Learning (MCML), Munich, Germany; Department of Statistics, Ludwig-Maximilians-Universit\u00e4t (LMU), Munich, Germany+Munich Center for Machine Learning (MCML), Munich, Germany+Fraunhofer Institute for Integrated Circuits (IIS), Erlangen, Germany; Department of Statistics, Ludwig-Maximilians-Universit\u00e4t (LMU), Munich, Germany+Munich Center for Machine Learning (MCML), Munich, Germany+Institute of Computational Biology, Helmholtz-Zentrum, Neuherberg, Germany; Department of Statistics, Ludwig-Maximilians-Universit\u00e4t (LMU), Munich, Germany+Munich Center for Machine Learning (MCML), Munich, Germany; Department of Statistics, Ludwig-Maximilians-Universit\u00e4t (LMU), Munich, Germany",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/rodemann/Bayesian-pls",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1+2;0+1+3;0+1;0",
        "aff_unique_norm": "Ludwig-Maximilians-Universit\u00e4t;Munich Center for Machine Learning;Fraunhofer Institute for Integrated Circuits;Helmholtz-Zentrum",
        "aff_unique_dep": "Department of Statistics;Center for Machine Learning;Integrated Circuits;Institute of Computational Biology",
        "aff_unique_url": "https://www.lmu.de;https://www.munich-center-for-machine-learning.de;https://www.iis.fraunhofer.de;https://www.helmholtz-muenchen.de",
        "aff_unique_abbr": "LMU;MCML;IIS;",
        "aff_campus_unique_index": "0+0;0+0+1;0+0+2;0+0;0",
        "aff_campus_unique": "Munich;Erlangen;Neuherberg",
        "aff_country_unique_index": "0+0;0+0+0;0+0+0;0+0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9c1534fff6",
        "title": "Approximating probabilistic explanations via supermodular minimization",
        "site": "https://proceedings.mlr.press/v216/bounia23a.html",
        "author": "Louenas Bounia; Frederic Koriche",
        "abstract": "Explaining in accurate and intelligible terms the predictions made by classifiers is a key challenge of eXplainable Artificial Intelligence (XAI). To this end, an abductive explanation for the predicted label of some data instance is a subset-minimal collection of features such that the restriction of the instance to these features is sufficient to determine the prediction. However, due to cognitive limitations, abductive explanations are often too large to be interpretable. In those cases, we need to reduce the size of abductive explanations, while still determining the predicted label with high probability. In this paper, we show that finding such probabilistic explanations is NP-hard, even for decision trees. In order to circumvent this issue, we investigate the approximability of probabilistic explanations through the lens of supermodularity. We examine both greedy descent and greedy ascent approaches for supermodular minimization, whose approximation guarantees depend on the curvature of the \u201cunnormalized\u201d error function that evaluates the precision of the explanation. Based on various experiments for explaining decision tree predictions, we show that our greedy algorithms provide an efficient alternative to the state-of-the-art constraint optimization method.",
        "bibtex": "@InProceedings{pmlr-v216-bounia23a,\n  title = \t {Approximating probabilistic explanations via supermodular minimization},\n  author =       {Bounia, Louenas and Koriche, Frederic},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {216--225},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/bounia23a/bounia23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/bounia23a.html},\n  abstract = \t {Explaining in accurate and intelligible terms the predictions made by classifiers is a key challenge of eXplainable Artificial Intelligence (XAI). To this end, an abductive explanation for the predicted label of some data instance is a subset-minimal collection of features such that the restriction of the instance to these features is sufficient to determine the prediction. However, due to cognitive limitations, abductive explanations are often too large to be interpretable. In those cases, we need to reduce the size of abductive explanations, while still determining the predicted label with high probability. In this paper, we show that finding such probabilistic explanations is NP-hard, even for decision trees. In order to circumvent this issue, we investigate the approximability of probabilistic explanations through the lens of supermodularity. We examine both greedy descent and greedy ascent approaches for supermodular minimization, whose approximation guarantees depend on the curvature of the \u201cunnormalized\u201d error function that evaluates the precision of the explanation. Based on various experiments for explaining decision tree predictions, we show that our greedy algorithms provide an efficient alternative to the state-of-the-art constraint optimization method.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/bounia23a/bounia23a.pdf",
        "supp": "",
        "pdf_size": 349234,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7803597115008047904&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "CRIL UMR CNRS 8188, Universit\u00e9 d\u2019Artois, France; CRIL UMR CNRS 8188, Universit\u00e9 d\u2019Artois, France",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universit\u00e9 d\u2019Artois",
        "aff_unique_dep": "CRIL UMR CNRS 8188",
        "aff_unique_url": "https://www.univ-artois.fr",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "14c33b5fb2",
        "title": "Assessing the Impact of Context Inference Error and Partial Observability on RL Methods for Just-In-Time Adaptive Interventions",
        "site": "https://proceedings.mlr.press/v216/karine23a.html",
        "author": "Karine Karine; Predrag Klasnja; Susan A. Murphy; Benjamin M. Marlin",
        "abstract": "Just-in-Time Adaptive Interventions (JITAIs) are a class of personalized health interventions developed within the behavioral science community. JITAIs aim to provide the right type and amount of support by iteratively selecting a sequence of intervention options from a pre-defined set of components in response to each individual\u2019s time varying state. In this work, we explore the application of reinforcement learning methods to the problem of learning intervention option selection policies. We study the effect of context inference error and partial observability on the ability to learn effective policies. Our results show that the propagation of uncertainty from context inferences is critical to improving intervention efficacy as context uncertainty increases, while policy gradient algorithms can provide remarkable robustness to partially observed behavioral state information.",
        "bibtex": "@InProceedings{pmlr-v216-karine23a,\n  title = \t {Assessing the Impact of Context Inference Error and Partial Observability on {RL} Methods for Just-In-Time Adaptive Interventions},\n  author =       {Karine, Karine and Klasnja, Predrag and Murphy, Susan A. and Marlin, Benjamin M.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1047--1057},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/karine23a/karine23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/karine23a.html},\n  abstract = \t {Just-in-Time Adaptive Interventions (JITAIs) are a class of personalized health interventions developed within the behavioral science community. JITAIs aim to provide the right type and amount of support by iteratively selecting a sequence of intervention options from a pre-defined set of components in response to each individual\u2019s time varying state. In this work, we explore the application of reinforcement learning methods to the problem of learning intervention option selection policies. We study the effect of context inference error and partial observability on the ability to learn effective policies. Our results show that the propagation of uncertainty from context inferences is critical to improving intervention efficacy as context uncertainty increases, while policy gradient algorithms can provide remarkable robustness to partially observed behavioral state information.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/karine23a/karine23a.pdf",
        "supp": "",
        "pdf_size": 1466977,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4181788749801225028&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c22a5a1623",
        "title": "BISCUIT: Causal Representation Learning from Binary Interactions",
        "site": "https://proceedings.mlr.press/v216/lippe23a.html",
        "author": "Phillip Lippe; Sara Magliacane; Sindy L\u00f6we; Yuki M Asano; Taco Cohen; Efstratios Gavves",
        "abstract": "Identifying the causal variables of an environment and how to intervene on them is of core value in applications such as robotics and embodied AI. While an agent can commonly interact with the environment and may implicitly perturb the behavior of some of these causal variables, often the targets it affects remain unknown. In this paper, we show that causal variables can still be identified for many common setups, e.g., additive Gaussian noise models, if the agent\u2019s interactions with a causal variable can be described by an unknown binary variable. This happens when each causal variable has two different mechanisms, e.g., an observational and an interventional one. Using this identifiability result, we propose BISCUIT, a method for simultaneously learning causal variables and their corresponding binary interaction variables. On three robotic-inspired datasets, BISCUIT accurately identifies causal variables and can even be scaled to complex, realistic environments for embodied AI.",
        "bibtex": "@InProceedings{pmlr-v216-lippe23a,\n  title = \t {{BISCUIT}: Causal Representation Learning from Binary Interactions},\n  author =       {Lippe, Phillip and Magliacane, Sara and L{\\\"o}we, Sindy and Asano, Yuki M and Cohen, Taco and Gavves, Efstratios},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1263--1273},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/lippe23a/lippe23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/lippe23a.html},\n  abstract = \t {Identifying the causal variables of an environment and how to intervene on them is of core value in applications such as robotics and embodied AI. While an agent can commonly interact with the environment and may implicitly perturb the behavior of some of these causal variables, often the targets it affects remain unknown. In this paper, we show that causal variables can still be identified for many common setups, e.g., additive Gaussian noise models, if the agent\u2019s interactions with a causal variable can be described by an unknown binary variable. This happens when each causal variable has two different mechanisms, e.g., an observational and an interventional one. Using this identifiability result, we propose BISCUIT, a method for simultaneously learning causal variables and their corresponding binary interaction variables. On three robotic-inspired datasets, BISCUIT accurately identifies causal variables and can even be scaled to complex, realistic environments for embodied AI.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/lippe23a/lippe23a.pdf",
        "supp": "",
        "pdf_size": 1116264,
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11736946786313766406&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "418765e4d4",
        "title": "Bandits with costly reward observations",
        "site": "https://proceedings.mlr.press/v216/tucker23a.html",
        "author": "Aaron D. Tucker; Caleb Biddulph; Claire Wang; Thorsten Joachims",
        "abstract": "Many machine learning applications rely on large datasets that are conveniently collected from existing sources or that are labeled automatically as a by-product of user actions. However, in settings such as content moderation, accurately and reliably labeled data comes at substantial cost. If a learning algorithm has to pay for reward information, for example by asking a human for feedback, how does this change the exploration/exploitation tradeoff? We study this question in the context of bandit learning. Specifically, we investigate Bandits with Costly Reward Observations, where a cost needs to be paid in order to observe the reward of the bandit\u2019s action. We show that the observation cost implies an $\\Omega(c^{1/3}T^{2/3})$ lower bound on the regret. Furthermore, we develop a general non-adaptive bandit algorithm which matches this lower bound, and we present several competitive adaptive learning algorithms for both k-armed and contextual bandits.",
        "bibtex": "@InProceedings{pmlr-v216-tucker23a,\n  title = \t {Bandits with costly reward observations},\n  author =       {Tucker, Aaron D. and Biddulph, Caleb and Wang, Claire and Joachims, Thorsten},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2147--2156},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/tucker23a/tucker23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/tucker23a.html},\n  abstract = \t {Many machine learning applications rely on large datasets that are conveniently collected from existing sources or that are labeled automatically as a by-product of user actions. However, in settings such as content moderation, accurately and reliably labeled data comes at substantial cost. If a learning algorithm has to pay for reward information, for example by asking a human for feedback, how does this change the exploration/exploitation tradeoff? We study this question in the context of bandit learning. Specifically, we investigate Bandits with Costly Reward Observations, where a cost needs to be paid in order to observe the reward of the bandit\u2019s action. We show that the observation cost implies an $\\Omega(c^{1/3}T^{2/3})$ lower bound on the regret. Furthermore, we develop a general non-adaptive bandit algorithm which matches this lower bound, and we present several competitive adaptive learning algorithms for both k-armed and contextual bandits.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/tucker23a/tucker23a.pdf",
        "supp": "",
        "pdf_size": 466984,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8841103215276719664&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "46be9042f3",
        "title": "Bayesian inference approach for entropy regularized reinforcement learning with stochastic dynamics",
        "site": "https://proceedings.mlr.press/v216/arriojas23a.html",
        "author": "Argenis Arriojas; Jacob Adamczyk; Stas Tiomkin; Rahul V. Kulkarni",
        "abstract": "We develop a novel approach to determine the optimal policy in entropy-regularized reinforcement learning (RL) with stochastic dynamics. For deterministic dynamics, the optimal policy can be derived using Bayesian inference in the control-as-inference framework; however, for stochastic dynamics, the direct use of this approach leads to risk-taking optimistic policies. To address this issue, current approaches in entropy-regularized RL involve a constrained optimization procedure which fixes system dynamics to the original dynamics, however this approach is not consistent with the unconstrained Bayesian inference framework. In this work we resolve this inconsistency by developing an exact mapping from the constrained optimization problem in entropy-regularized RL to a different optimization problem which can be solved using the unconstrained Bayesian inference approach. We show that the optimal policies are the same for both problems, thus our results lead to the exact solution for the optimal policy in entropy-regularized RL with stochastic dynamics through Bayesian inference.",
        "bibtex": "@InProceedings{pmlr-v216-arriojas23a,\n  title = \t {Bayesian inference approach for entropy regularized reinforcement learning with stochastic dynamics},\n  author =       {Arriojas, Argenis and Adamczyk, Jacob and Tiomkin, Stas and Kulkarni, Rahul V.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {99--109},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/arriojas23a/arriojas23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/arriojas23a.html},\n  abstract = \t {We develop a novel approach to determine the optimal policy in entropy-regularized reinforcement learning (RL) with stochastic dynamics. For deterministic dynamics, the optimal policy can be derived using Bayesian inference in the control-as-inference framework; however, for stochastic dynamics, the direct use of this approach leads to risk-taking optimistic policies. To address this issue, current approaches in entropy-regularized RL involve a constrained optimization procedure which fixes system dynamics to the original dynamics, however this approach is not consistent with the unconstrained Bayesian inference framework. In this work we resolve this inconsistency by developing an exact mapping from the constrained optimization problem in entropy-regularized RL to a different optimization problem which can be solved using the unconstrained Bayesian inference approach. We show that the optimal policies are the same for both problems, thus our results lead to the exact solution for the optimal policy in entropy-regularized RL with stochastic dynamics through Bayesian inference.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/arriojas23a/arriojas23a.pdf",
        "supp": "",
        "pdf_size": 1071274,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11241733667998986622&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "959f0e5aaf",
        "title": "Bayesian inference for vertex-series-parallel partial orders",
        "site": "https://proceedings.mlr.press/v216/jiang23b.html",
        "author": "Chuxuan Jiang; Geoff K. Nicholls; Jeong Eun Lee",
        "abstract": "Partial orders are a natural model for the social hierarchies that may constrain \u201cqueue-like\u201d rank-order data. However, the computational cost of counting the linear extensions of a general partial order on a ground set with more than a few tens of elements is prohibitive. Vertex-series-parallel partial orders (VSPs) are a subclass of partial orders which admit rapid counting and represent the sorts of relations we expect to see in a social hierarchy. However, no Bayesian analysis of VSPs has been given to date. We construct a marginally consistent family of priors over VSPs with a parameter controlling the prior distribution over  VSP depth. The prior for VSPs is given in closed form. We extend an existing observation model for queue-like rank-order data to represent noise in our data and carry out Bayesian inference on \u201cRoyal Acta\u201d data and Formula 1 race data. Model comparison shows our model is a better fit to the data than Plackett-Luce mixtures, Mallows mixtures, and \u201cbucket order\u201d models and competitive with more complex models fitting general partial orders.",
        "bibtex": "@InProceedings{pmlr-v216-jiang23b,\n  title = \t {Bayesian inference for vertex-series-parallel partial orders},\n  author =       {Jiang, Chuxuan and Nicholls, Geoff K. and Lee, Jeong Eun},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {995--1004},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/jiang23b/jiang23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/jiang23b.html},\n  abstract = \t {Partial orders are a natural model for the social hierarchies that may constrain \u201cqueue-like\u201d rank-order data. However, the computational cost of counting the linear extensions of a general partial order on a ground set with more than a few tens of elements is prohibitive. Vertex-series-parallel partial orders (VSPs) are a subclass of partial orders which admit rapid counting and represent the sorts of relations we expect to see in a social hierarchy. However, no Bayesian analysis of VSPs has been given to date. We construct a marginally consistent family of priors over VSPs with a parameter controlling the prior distribution over  VSP depth. The prior for VSPs is given in closed form. We extend an existing observation model for queue-like rank-order data to represent noise in our data and carry out Bayesian inference on \u201cRoyal Acta\u201d data and Formula 1 race data. Model comparison shows our model is a better fit to the data than Plackett-Luce mixtures, Mallows mixtures, and \u201cbucket order\u201d models and competitive with more complex models fitting general partial orders.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/jiang23b/jiang23b.pdf",
        "supp": "",
        "pdf_size": 443698,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7287764211726287071&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Statistics, University of Oxford, United Kingdom; Department of Statistics, University of Oxford, United Kingdom; Department of Statistics, University of Auckland, New Zealand",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Oxford;University of Auckland",
        "aff_unique_dep": "Department of Statistics;Department of Statistics",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.auckland.ac.nz",
        "aff_unique_abbr": "Oxford;UoA",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Oxford;Auckland",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United Kingdom;New Zealand"
    },
    {
        "id": "afc38f21bd",
        "title": "Baysian numerical integration with neural networks",
        "site": "https://proceedings.mlr.press/v216/ott23a.html",
        "author": "Katharina Ott; Michael Tiemann; Philipp Hennig; Fran\u00e7ois-Xavier Briol",
        "abstract": "Bayesian probabilistic numerical methods for numerical integration offer significant advantages over their non-Bayesian counterparts: they can encode prior information about the integrand, and can quantify uncertainty over estimates of an integral. However, the most popular algorithm in this class, Bayesian quadrature, is based on Gaussian process models and is therefore associated with a high computational cost. To improve scalability, we propose an alternative approach based on Bayesian neural networks which we call Bayesian Stein networks. The key ingredients are a neural network architecture based on Stein operators, and an approximation of the Bayesian posterior based on the Laplace approximation. We show that this leads to orders of magnitude speed-ups on the popular Genz functions benchmark, and on challenging problems arising in the Bayesian analysis of dynamical systems, and the prediction of energy production for a large-scale wind farm.",
        "bibtex": "@InProceedings{pmlr-v216-ott23a,\n  title = \t {Baysian numerical integration with neural networks},\n  author =       {Ott, Katharina and Tiemann, Michael and Hennig, Philipp and Briol, Fran\\c{c}ois-Xavier},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1606--1617},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/ott23a/ott23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/ott23a.html},\n  abstract = \t {Bayesian probabilistic numerical methods for numerical integration offer significant advantages over their non-Bayesian counterparts: they can encode prior information about the integrand, and can quantify uncertainty over estimates of an integral. However, the most popular algorithm in this class, Bayesian quadrature, is based on Gaussian process models and is therefore associated with a high computational cost. To improve scalability, we propose an alternative approach based on Bayesian neural networks which we call Bayesian Stein networks. The key ingredients are a neural network architecture based on Stein operators, and an approximation of the Bayesian posterior based on the Laplace approximation. We show that this leads to orders of magnitude speed-ups on the popular Genz functions benchmark, and on challenging problems arising in the Bayesian analysis of dynamical systems, and the prediction of energy production for a large-scale wind farm.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/ott23a/ott23a.pdf",
        "supp": "",
        "pdf_size": 395652,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:NtipCkd7sAAJ:scholar.google.com/&scioq=Bayesian+numerical+integration+with+neural+networks&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9ef44e28c7",
        "title": "BeliefPPG: Uncertainty-aware heart rate estimation from PPG signals via belief propagation",
        "site": "https://proceedings.mlr.press/v216/bieri23a.html",
        "author": "Valentin Bieri; Paul Streli; Berken Utku Demirel; Christian Holz",
        "abstract": "We present a novel learning-based method that achieves state-of-the-art performance on several heart rate estimation benchmarks extracted from photoplethysmography signals (PPG). We consider the evolution of the heart rate in the context of a discrete-time stochastic process that we represent as a hidden Markov model. We derive a distribution over possible heart rate values for a given PPG signal window through a trained neural network. Using belief propagation, we incorporate the statistical distribution of heart rate changes to refine these estimates in a temporal context. From this, we obtain a quantized probability distribution over the range of possible heart rate values that captures a meaningful and well-calibrated estimate of the inherent predictive uncertainty. We show the robustness of our method on eight public datasets with three different cross-validation experiments.",
        "bibtex": "@InProceedings{pmlr-v216-bieri23a,\n  title = \t {{BeliefPPG}: Uncertainty-aware heart rate estimation from {PPG} signals via belief propagation},\n  author =       {Bieri, Valentin and Streli, Paul and Demirel, Berken Utku and Holz, Christian},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {173--183},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/bieri23a/bieri23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/bieri23a.html},\n  abstract = \t {We present a novel learning-based method that achieves state-of-the-art performance on several heart rate estimation benchmarks extracted from photoplethysmography signals (PPG). We consider the evolution of the heart rate in the context of a discrete-time stochastic process that we represent as a hidden Markov model. We derive a distribution over possible heart rate values for a given PPG signal window through a trained neural network. Using belief propagation, we incorporate the statistical distribution of heart rate changes to refine these estimates in a temporal context. From this, we obtain a quantized probability distribution over the range of possible heart rate values that captures a meaningful and well-calibrated estimate of the inherent predictive uncertainty. We show the robustness of our method on eight public datasets with three different cross-validation experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/bieri23a/bieri23a.pdf",
        "supp": "",
        "pdf_size": 374636,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14506571821090267504&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9355afff4e",
        "title": "Benefits of monotonicity in safe exploration with Gaussian processes",
        "site": "https://proceedings.mlr.press/v216/losalka23a.html",
        "author": "Arpan Losalka; Jonathan Scarlett",
        "abstract": "We consider the problem of sequentially maximising an unknown function over a set of actions while ensuring that every sampled point has a function value below a given safety threshold. We model the function using kernel-based and Gaussian process methods, while differing from previous works in our assumption that the function is monotonically increasing with respect to a safety variable. This assumption is motivated by various practical applications such as adaptive clinical trial design and robotics. Taking inspiration from the GP-UCB and SAFEOPT algorithms, we propose an algorithm, monotone safe UCB (M-SafeUCB) for this task.  We show that M-SafeUCB enjoys theoretical guarantees in terms of safety, a suitably-defined regret notion, and approximately finding the entire safe boundary. In addition, we illustrate that the monotonicity assumption yields significant benefits in terms of the guarantees obtained, as well as algorithmic simplicity and efficiency. We support our theoretical findings by performing empirical evaluations on a variety of functions, including a simulated clinical trial experiment.",
        "bibtex": "@InProceedings{pmlr-v216-losalka23a,\n  title = \t {Benefits of monotonicity in safe exploration with {G}aussian processes},\n  author =       {Losalka, Arpan and Scarlett, Jonathan},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1304--1314},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/losalka23a/losalka23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/losalka23a.html},\n  abstract = \t {We consider the problem of sequentially maximising an unknown function over a set of actions while ensuring that every sampled point has a function value below a given safety threshold. We model the function using kernel-based and Gaussian process methods, while differing from previous works in our assumption that the function is monotonically increasing with respect to a safety variable. This assumption is motivated by various practical applications such as adaptive clinical trial design and robotics. Taking inspiration from the GP-UCB and SAFEOPT algorithms, we propose an algorithm, monotone safe UCB (M-SafeUCB) for this task.  We show that M-SafeUCB enjoys theoretical guarantees in terms of safety, a suitably-defined regret notion, and approximately finding the entire safe boundary. In addition, we illustrate that the monotonicity assumption yields significant benefits in terms of the guarantees obtained, as well as algorithmic simplicity and efficiency. We support our theoretical findings by performing empirical evaluations on a variety of functions, including a simulated clinical trial experiment.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/losalka23a/losalka23a.pdf",
        "supp": "",
        "pdf_size": 852852,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16648193817652378929&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, National University of Singapore, Singapore; Department of Computer Science, National University of Singapore, Singapore + Department of Mathematics, National University of Singapore, Singapore + Institute of Data Science, National University of Singapore, Singapore",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+0+0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+0+0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "d32b06fb1b",
        "title": "Benign Overfitting in Adversarially Robust Linear Classification",
        "site": "https://proceedings.mlr.press/v216/chen23b.html",
        "author": "Jinghui Chen; Yuan Cao; Quanquan Gu",
        "abstract": "Benign overfitting, where classifiers memorize noisy training data yet still achieve a good generalization performance, has drawn great attention in the machine learning community. To explain this surprising phenomenon, a series of works have provided theoretical justification for over-parameterized linear regression, classification, and kernel methods. However, it is not clear if benign overfitting can occur in the presence of adversarial examples, i.e., examples with tiny and intentional perturbations to fool the classifiers. In this paper, we show that benign overfitting indeed occurs in adversarial training, a principled approach to defend against adversarial examples, on subGaussian mixture data. In detail, we prove the risk bounds of the adversarially trained linear classifier on the mixture of sub-Gaussian data under Lp adversarial perturbations. Our result suggests that under moderate perturbations, adversarially trained linear classifiers can achieve the near-optimal standard and adversarial risks, despite overfitting the noisy training data. Numerical experiments validate our theoretical findings.",
        "bibtex": "@InProceedings{pmlr-v216-chen23b,\n  title = \t {Benign Overfitting in Adversarially Robust Linear Classification},\n  author =       {Chen, Jinghui and Cao, Yuan and Gu, Quanquan},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {313--323},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/chen23b/chen23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/chen23b.html},\n  abstract = \t {Benign overfitting, where classifiers memorize noisy training data yet still achieve a good generalization performance, has drawn great attention in the machine learning community. To explain this surprising phenomenon, a series of works have provided theoretical justification for over-parameterized linear regression, classification, and kernel methods. However, it is not clear if benign overfitting can occur in the presence of adversarial examples, i.e., examples with tiny and intentional perturbations to fool the classifiers. In this paper, we show that benign overfitting indeed occurs in adversarial training, a principled approach to defend against adversarial examples, on subGaussian mixture data. In detail, we prove the risk bounds of the adversarially trained linear classifier on the mixture of sub-Gaussian data under Lp adversarial perturbations. Our result suggests that under moderate perturbations, adversarially trained linear classifiers can achieve the near-optimal standard and adversarial risks, despite overfitting the noisy training data. Numerical experiments validate our theoretical findings.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/chen23b/chen23b.pdf",
        "supp": "",
        "pdf_size": 533373,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11535208795950269789&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "The Pennsylvania State University; The University of Hong Kong; University of California, Los Angeles",
        "aff_domain": "psu.edu;hku.hk;cs.ucla.edu",
        "email": "psu.edu;hku.hk;cs.ucla.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Pennsylvania State University;University of Hong Kong;University of California, Los Angeles",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.psu.edu;https://www.hku.hk;https://www.ucla.edu",
        "aff_unique_abbr": "PSU;HKU;UCLA",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Hong Kong SAR;Los Angeles",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "b98048a02a",
        "title": "Best arm identification in rare events",
        "site": "https://proceedings.mlr.press/v216/bhattacharjee23a.html",
        "author": "Anirban Bhattacharjee; Sushant Vijayan; Sandeep Juneja",
        "abstract": "We consider the Best Arm Identification (BAI) problem in the stochastic multi-armed bandit framework, where each arm has a small probability of realizing large rewards, while with overwhelming probability, the reward is zero. A key application of this framework is in online advertising, where click rates of advertisements could be a fraction of a single percent and final conversion to sales, while highly profitable, may again be a small fraction of the click rates. Lately, algorithms for BAI problems have been developed that minimise sample complexity while providing statistical guarantees on the correct arm selection. As we observe, these algorithms can be computationally prohibitive. We exploit the fact that the reward process for each arm is well approximated by a Compound Poisson process and arrive at algorithms that are faster, with a small increase in sample complexity. We analyze the problem in an asymptotic regime as rarity of reward occurrence reduces to zero, and reward amounts increase to infinity. This helps illustrate the benefits of the proposed algorithm. It also sheds light on the underlying structure of the optimal BAI algorithms in the rare event setting.",
        "bibtex": "@InProceedings{pmlr-v216-bhattacharjee23a,\n  title = \t {Best arm identification in rare events},\n  author =       {Bhattacharjee, Anirban and Vijayan, Sushant and Juneja, Sandeep},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {163--172},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/bhattacharjee23a/bhattacharjee23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/bhattacharjee23a.html},\n  abstract = \t {We consider the Best Arm Identification (BAI) problem in the stochastic multi-armed bandit framework, where each arm has a small probability of realizing large rewards, while with overwhelming probability, the reward is zero. A key application of this framework is in online advertising, where click rates of advertisements could be a fraction of a single percent and final conversion to sales, while highly profitable, may again be a small fraction of the click rates. Lately, algorithms for BAI problems have been developed that minimise sample complexity while providing statistical guarantees on the correct arm selection. As we observe, these algorithms can be computationally prohibitive. We exploit the fact that the reward process for each arm is well approximated by a Compound Poisson process and arrive at algorithms that are faster, with a small increase in sample complexity. We analyze the problem in an asymptotic regime as rarity of reward occurrence reduces to zero, and reward amounts increase to infinity. This helps illustrate the benefits of the proposed algorithm. It also sheds light on the underlying structure of the optimal BAI algorithms in the rare event setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/bhattacharjee23a/bhattacharjee23a.pdf",
        "supp": "",
        "pdf_size": 281573,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4173937568638915374&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3dc2f9bf5f",
        "title": "Bidirectional Attention as a Mixture of Continuous Word Experts",
        "site": "https://proceedings.mlr.press/v216/wibisono23a.html",
        "author": "Kevin C. Wibisono; Yixin Wang",
        "abstract": "Bidirectional attention - composed of the neural network architecture of self-attention with positional encodings, together with the masked language model (MLM) objective - has emerged as a key component of modern large language models (LLMs). Despite its empirical success, few studies have examined its statistical underpinnings: What statistical model is bidirectional attention implicitly fitting? What sets it apart from its non-attention predecessors? We explore these questions in this paper. The key observation is that fitting a single-layer single-head bidirectional attention, upon reparameterization, is equivalent to fitting a continuous bag of words (CBOW) model with mixture-of-experts (MoE) weights. Further, bidirectional attention with multiple heads and multiple layers is equivalent to stacked MoEs and a mixture of MoEs, respectively. This statistical viewpoint reveals the distinct use of MoE in bidirectional attention, which aligns with its practical effectiveness in handling heterogeneous data. It also suggests an immediate extension to categorical tabular data, if we view each word location in a sentence as a tabular feature. Across empirical studies, we find that this extension outperforms existing tabular extensions of transformers in out-of-distribution (OOD) generalization. Finally, this statistical perspective of bidirectional attention enables us to theoretically characterize when linear word analogies are present in its word embeddings. These analyses show that bidirectional attention can require much stronger assumptions to exhibit linear word analogies than its non-attention predecessors.",
        "bibtex": "@InProceedings{pmlr-v216-wibisono23a,\n  title = \t {Bidirectional Attention as a Mixture of Continuous Word Experts},\n  author =       {Wibisono, Kevin C. and Wang, Yixin},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2271--2281},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/wibisono23a/wibisono23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/wibisono23a.html},\n  abstract = \t {Bidirectional attention - composed of the neural network architecture of self-attention with positional encodings, together with the masked language model (MLM) objective - has emerged as a key component of modern large language models (LLMs). Despite its empirical success, few studies have examined its statistical underpinnings: What statistical model is bidirectional attention implicitly fitting? What sets it apart from its non-attention predecessors? We explore these questions in this paper. The key observation is that fitting a single-layer single-head bidirectional attention, upon reparameterization, is equivalent to fitting a continuous bag of words (CBOW) model with mixture-of-experts (MoE) weights. Further, bidirectional attention with multiple heads and multiple layers is equivalent to stacked MoEs and a mixture of MoEs, respectively. This statistical viewpoint reveals the distinct use of MoE in bidirectional attention, which aligns with its practical effectiveness in handling heterogeneous data. It also suggests an immediate extension to categorical tabular data, if we view each word location in a sentence as a tabular feature. Across empirical studies, we find that this extension outperforms existing tabular extensions of transformers in out-of-distribution (OOD) generalization. Finally, this statistical perspective of bidirectional attention enables us to theoretically characterize when linear word analogies are present in its word embeddings. These analyses show that bidirectional attention can require much stronger assumptions to exhibit linear word analogies than its non-attention predecessors.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/wibisono23a/wibisono23a.pdf",
        "supp": "",
        "pdf_size": 342075,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:oQPSWuq1rCIJ:scholar.google.com/&scioq=Bidirectional+Attention+as+a+Mixture+of+Continuous+Word+Experts&hl=en&as_sdt=0,5",
        "gs_version_total": 9,
        "aff": "Department of Statistics, University of Michigan, Ann Arbor, MI, USA; Department of Statistics, University of Michigan, Ann Arbor, MI, USA",
        "aff_domain": "umich.edu;umich.edu",
        "email": "umich.edu;umich.edu",
        "github": "https://github.com/yixinw-lab/attention-uai",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fe7d2dde2a",
        "title": "Birds of an odd feather: guaranteed out-of-distribution (OOD) novel category detection",
        "site": "https://proceedings.mlr.press/v216/wald23a.html",
        "author": "Yoav Wald; Suchi Saria",
        "abstract": "In this work, we solve the problem of novel category detection under distribution shift. This problem is critical to ensuring the safety and efficacy of machine learning models, particularly in domains such as healthcare where timely detection of novel subgroups of patients is crucial.  To address this problem, we propose a method based on constrained learning. Our approach is guaranteed to detect a novel category under a relatively weak assumption, namely that rare events in past data have bounded frequency under the shifted distribution. Prior works on the problem do not provide such guarantees, as they either attend to very specific types of distribution shift or make stringent assumptions that limit their guarantees.  We demonstrate favorable performance of our method on challenging novel category detection problems over real world datasets.",
        "bibtex": "@InProceedings{pmlr-v216-wald23a,\n  title = \t {Birds of an odd feather: guaranteed out-of-distribution ({OOD}) novel category detection},\n  author =       {Wald, Yoav and Saria, Suchi},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2179--2191},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/wald23a/wald23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/wald23a.html},\n  abstract = \t {In this work, we solve the problem of novel category detection under distribution shift. This problem is critical to ensuring the safety and efficacy of machine learning models, particularly in domains such as healthcare where timely detection of novel subgroups of patients is crucial.  To address this problem, we propose a method based on constrained learning. Our approach is guaranteed to detect a novel category under a relatively weak assumption, namely that rare events in past data have bounded frequency under the shifted distribution. Prior works on the problem do not provide such guarantees, as they either attend to very specific types of distribution shift or make stringent assumptions that limit their guarantees.  We demonstrate favorable performance of our method on challenging novel category detection problems over real world datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/wald23a/wald23a.pdf",
        "supp": "",
        "pdf_size": 440454,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=937765250826910414&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, Johns Hopkins University, Baltimore, MD; Department of Computer Science, Johns Hopkins University, Baltimore, MD + Bayesian Health, New York, NY",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1",
        "aff_unique_norm": "Johns Hopkins University;Bayesian Health",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.jhu.edu;",
        "aff_unique_abbr": "JHU;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Baltimore;",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "93e17e9c2b",
        "title": "Blackbox optimization of unimodal functions",
        "site": "https://proceedings.mlr.press/v216/cutkosky23a.html",
        "author": "A. Cutkosky; A. Das; W. Kong; C. Lee; R. Sen",
        "abstract": "We provide an intuitive new algorithm for blackbox stochastic optimization of unimodal functions, a function class that we observe empirically can capture hyperparameter-tuning loss surfaces. Our method\u2019s convergence guarantee automatically adapts to Lipschitz constants and other problem difficulty parameters, recovering and extending prior results. We complement our theoretical development with experimental validation on hyperparameter tuning tasks.",
        "bibtex": "@InProceedings{pmlr-v216-cutkosky23a,\n  title = \t {Blackbox optimization of unimodal functions},\n  author =       {Cutkosky, A. and Das, A. and Kong, W. and Lee, C. and Sen, R.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {476--484},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/cutkosky23a/cutkosky23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/cutkosky23a.html},\n  abstract = \t {We provide an intuitive new algorithm for blackbox stochastic optimization of unimodal functions, a function class that we observe empirically can capture hyperparameter-tuning loss surfaces. Our method\u2019s convergence guarantee automatically adapts to Lipschitz constants and other problem difficulty parameters, recovering and extending prior results. We complement our theoretical development with experimental validation on hyperparameter tuning tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/cutkosky23a/cutkosky23a.pdf",
        "supp": "",
        "pdf_size": 389908,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "Boston University; Google Research, Mountain View; Google Research, Mountain View; Google, Pittsburgh; Google Research, Mountain View",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Boston University;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.bu.edu;https://research.google",
        "aff_unique_abbr": "BU;Google",
        "aff_campus_unique_index": "1;1;2;1",
        "aff_campus_unique": ";Mountain View;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7143e7ea7a",
        "title": "Boosting AND/OR-based computational protein design: dynamic heuristics and generalizable UFO",
        "site": "https://proceedings.mlr.press/v216/pezeshki23a.html",
        "author": "Bobak Pezeshki; Radu Marinescu; Alexander Ihler; Rina Dechter",
        "abstract": "Scientific computing has experienced a surge empowered by advancements in technologies such as neural networks.  However, certain important tasks are less amenable to these technologies, benefiting from innovations to traditional inference schemes.  One such task is protein re-design.  Recently a new re-design algorithm, {AOBB-K\\textsuperscript{*}}, was introduced and was competitive with state-of-the-art {BBK\\textsuperscript{*}} on small protein re-design problems. However, {AOBB-K\\textsuperscript{*}}  did not scale well.  In this work, we focus on scaling up {AOBB-K\\textsuperscript{*}} and introduce three new versions: {AOBB-K\\textsuperscript{*}}-b (boosted), {AOBB-K\\textsuperscript{*}}-{DH} (with dynamic heuristics), and {AOBB-K\\textsuperscript{*}}-{UFO} (with underflow optimization) that significantly enhance scalability.",
        "bibtex": "@InProceedings{pmlr-v216-pezeshki23a,\n  title = \t {Boosting {AND/OR}-based computational protein design: dynamic heuristics and generalizable {UFO}},\n  author =       {Pezeshki, Bobak and Marinescu, Radu and Ihler, Alexander and Dechter, Rina},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1662--1672},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/pezeshki23a/pezeshki23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/pezeshki23a.html},\n  abstract = \t {Scientific computing has experienced a surge empowered by advancements in technologies such as neural networks.  However, certain important tasks are less amenable to these technologies, benefiting from innovations to traditional inference schemes.  One such task is protein re-design.  Recently a new re-design algorithm, {AOBB-K\\textsuperscript{*}}, was introduced and was competitive with state-of-the-art {BBK\\textsuperscript{*}} on small protein re-design problems. However, {AOBB-K\\textsuperscript{*}}  did not scale well.  In this work, we focus on scaling up {AOBB-K\\textsuperscript{*}} and introduce three new versions: {AOBB-K\\textsuperscript{*}}-b (boosted), {AOBB-K\\textsuperscript{*}}-{DH} (with dynamic heuristics), and {AOBB-K\\textsuperscript{*}}-{UFO} (with underflow optimization) that significantly enhance scalability.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/pezeshki23a/pezeshki23a.pdf",
        "supp": "",
        "pdf_size": 1742452,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:2lFzOcEb0B4J:scholar.google.com/&scioq=Boosting+AND/OR-based+computational+protein+design:+dynamic+heuristics+and+generalizable+UFO&hl=en&as_sdt=0,14",
        "gs_version_total": 11,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "53ac84a056",
        "title": "Bounding the optimal value function in compositional reinforcement learning",
        "site": "https://proceedings.mlr.press/v216/adamczyk23a.html",
        "author": "Jacob Adamczyk; Volodymyr Makarenko; Argenis Arriojas; Stas Tiomkin; Rahul V. Kulkarni",
        "abstract": "In the field of reinforcement learning (RL), agents are often tasked with solving a variety of problems differing only in their reward functions. In order to quickly obtain solutions to unseen problems with new reward functions, a popular approach involves functional composition of previously solved tasks. However, previous work using such functional composition has primarily focused on specific instances of composition functions, whose limiting assumptions allow for exact zero-shot composition. Our work unifies these examples and provides a more general framework for compositionality in both standard and entropy-regularized RL. We find that, for a broad class of functions, the optimal solution for the composite task of interest can be related to the known primitive task solutions. Specifically, we present double-sided inequalities relating the optimal composite value function to the value functions for the primitive tasks. We also show that the regret of using a zero-shot policy can be bounded for this class of functions. The derived bounds can be used to develop clipping approaches for reducing uncertainty during training, allowing agents to quickly adapt to new tasks.",
        "bibtex": "@InProceedings{pmlr-v216-adamczyk23a,\n  title = \t {Bounding the optimal value function in compositional reinforcement learning},\n  author =       {Adamczyk, Jacob and Makarenko, Volodymyr and Arriojas, Argenis and Tiomkin, Stas and Kulkarni, Rahul V.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {22--32},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/adamczyk23a/adamczyk23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/adamczyk23a.html},\n  abstract = \t {In the field of reinforcement learning (RL), agents are often tasked with solving a variety of problems differing only in their reward functions. In order to quickly obtain solutions to unseen problems with new reward functions, a popular approach involves functional composition of previously solved tasks. However, previous work using such functional composition has primarily focused on specific instances of composition functions, whose limiting assumptions allow for exact zero-shot composition. Our work unifies these examples and provides a more general framework for compositionality in both standard and entropy-regularized RL. We find that, for a broad class of functions, the optimal solution for the composite task of interest can be related to the known primitive task solutions. Specifically, we present double-sided inequalities relating the optimal composite value function to the value functions for the primitive tasks. We also show that the regret of using a zero-shot policy can be bounded for this class of functions. The derived bounds can be used to develop clipping approaches for reducing uncertainty during training, allowing agents to quickly adapt to new tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/adamczyk23a/adamczyk23a.pdf",
        "supp": "",
        "pdf_size": 407633,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4830495632644452025&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Department of Physics, University of Massachusetts Boston, Boston, MA, USA; Department of Computer Engineering, San Jos\u00e9 State University, San Jos\u00e9, CA, USA; Department of Physics, University of Massachusetts Boston, Boston, MA, USA; Department of Computer Engineering, San Jos\u00e9 State University, San Jos\u00e9, CA, USA; Department of Physics, University of Massachusetts Boston, Boston, MA, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "University of Massachusetts Boston;San Jos\u00e9 State University",
        "aff_unique_dep": "Department of Physics;Department of Computer Engineering",
        "aff_unique_url": "https://www.umb.edu;https://www.sjsu.edu",
        "aff_unique_abbr": "UMass Boston;SJSU",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Boston;San Jos\u00e9",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f13be84668",
        "title": "CUE: An Uncertainty Interpretation Framework for Text Classifiers Built on Pre-Trained Language Models",
        "site": "https://proceedings.mlr.press/v216/li23d.html",
        "author": "Jiazheng Li; Zhaoyue Sun; Bin Liang; Lin Gui; Yulan He",
        "abstract": "Text classifiers built on Pre-trained Language Models (PLMs) have achieved remarkable progress in various tasks including sentiment analysis, natural language inference, and question-answering. However, the occurrence of uncertain predictions by these classifiers poses a challenge to their reliability when deployed in practical applications. Much effort has been devoted to designing various probes in order to understand what PLMs capture. But few studies have delved into factors influencing PLM-based classifiers\u2019 predictive uncertainty. In this paper, we propose a novel framework, called CUE, which aims to interpret uncertainties inherent in the predictions of PLM-based models. In particular, we first map PLM-encoded representations to a latent space via a variational auto-encoder. We then generate text representations by perturbing the latent space which causes fluctuation in predictive uncertainty. By comparing the difference in predictive uncertainty between the perturbed and the original text representations, we are able to identify the latent dimensions responsible for uncertainty and subsequently trace back to the input features that contribute to such uncertainty. Our extensive experiments on four benchmark datasets encompassing linguistic acceptability classification, emotion classification, and natural language inference show the feasibility of our proposed framework. Our source code is available at https://github.com/lijiazheng99/CUE.",
        "bibtex": "@InProceedings{pmlr-v216-li23d,\n  title = \t {{CUE}: An Uncertainty Interpretation Framework for Text Classifiers Built on Pre-Trained Language Models},\n  author =       {Li, Jiazheng and Sun, Zhaoyue and Liang, Bin and Gui, Lin and He, Yulan},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1253--1262},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/li23d/li23d.pdf},\n  url = \t {https://proceedings.mlr.press/v216/li23d.html},\n  abstract = \t {Text classifiers built on Pre-trained Language Models (PLMs) have achieved remarkable progress in various tasks including sentiment analysis, natural language inference, and question-answering. However, the occurrence of uncertain predictions by these classifiers poses a challenge to their reliability when deployed in practical applications. Much effort has been devoted to designing various probes in order to understand what PLMs capture. But few studies have delved into factors influencing PLM-based classifiers\u2019 predictive uncertainty. In this paper, we propose a novel framework, called CUE, which aims to interpret uncertainties inherent in the predictions of PLM-based models. In particular, we first map PLM-encoded representations to a latent space via a variational auto-encoder. We then generate text representations by perturbing the latent space which causes fluctuation in predictive uncertainty. By comparing the difference in predictive uncertainty between the perturbed and the original text representations, we are able to identify the latent dimensions responsible for uncertainty and subsequently trace back to the input features that contribute to such uncertainty. Our extensive experiments on four benchmark datasets encompassing linguistic acceptability classification, emotion classification, and natural language inference show the feasibility of our proposed framework. Our source code is available at https://github.com/lijiazheng99/CUE.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/li23d/li23d.pdf",
        "supp": "",
        "pdf_size": 1554932,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10897412632604390262&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/lijiazheng99/CUE",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "de9719900c",
        "title": "Causal Discovery for time series from multiple datasets with latent contexts",
        "site": "https://proceedings.mlr.press/v216/gunther23a.html",
        "author": "Wiebke G\u00fcnther; Urmi Ninad; Jakob Runge",
        "abstract": "Causal discovery from time series data is a typical problem setting across the sciences. Often, multiple datasets of the same system variables are available, for instance, time series of river runoff from different catchments. The local catchment systems then share certain causal parents, such as time-dependent large-scale weather over all catchments, but differ in other catchment-specific drivers, such as the altitude of the catchment. These drivers can be called temporal and spatial contexts, respectively, and are often partially unobserved. Pooling the datasets and considering the joint causal graph among system, context, and certain auxiliary variables enables us to overcome such latent confounding of system variables. In this work, we present a non-parametric time series causal discovery method,",
        "bibtex": "@InProceedings{pmlr-v216-gunther23a,\n  title = \t {Causal Discovery for time series from multiple datasets with latent contexts},\n  author =       {G\\\"{u}nther, Wiebke and Ninad, Urmi and Runge, Jakob},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {766--776},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/gunther23a/gunther23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/gunther23a.html},\n  abstract = \t {Causal discovery from time series data is a typical problem setting across the sciences. Often, multiple datasets of the same system variables are available, for instance, time series of river runoff from different catchments. The local catchment systems then share certain causal parents, such as time-dependent large-scale weather over all catchments, but differ in other catchment-specific drivers, such as the altitude of the catchment. These drivers can be called temporal and spatial contexts, respectively, and are often partially unobserved. Pooling the datasets and considering the joint causal graph among system, context, and certain auxiliary variables enables us to overcome such latent confounding of system variables. In this work, we present a non-parametric time series causal discovery method,",
        "pdf": "https://proceedings.mlr.press/v216/gunther23a/gunther23a.pdf",
        "supp": "",
        "pdf_size": 608432,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17330276104281525659&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "eaf16a9fc8",
        "title": "Causal Discovery with Hidden Confounders using the Algorithmic Markov Condition",
        "site": "https://proceedings.mlr.press/v216/kaltenpoth23a.html",
        "author": "David Kaltenpoth; Jilles Vreeken",
        "abstract": "Causal sufficiency is a cornerstone assumption in causal discovery. It is, however, both unlikely to hold in practice as well as unverifiable. When it does not hold, existing methods struggle to return meaningful results. In this paper, we show how to discover the causal network over both observed and unobserved variables. Moreover, we show that the causal model is identifiable in the sparse linear Gaussian case. More generally, we extend the algorithmic Markov condition to include latent confounders. We propose a consistent score based on the Minimum Description Length principle to discover the full causal network, including latent confounders. Based on this score, we develop an effective algorithm that finds those sets of nodes for which the addition of a confounding factor $Z$ is most beneficial, then fits a new causal network over both observed as well as inferred latent variables.",
        "bibtex": "@InProceedings{pmlr-v216-kaltenpoth23a,\n  title = \t {Causal Discovery with Hidden Confounders using the Algorithmic {M}arkov Condition},\n  author =       {Kaltenpoth, David and Vreeken, Jilles},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1016--1026},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/kaltenpoth23a/kaltenpoth23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/kaltenpoth23a.html},\n  abstract = \t {Causal sufficiency is a cornerstone assumption in causal discovery. It is, however, both unlikely to hold in practice as well as unverifiable. When it does not hold, existing methods struggle to return meaningful results. In this paper, we show how to discover the causal network over both observed and unobserved variables. Moreover, we show that the causal model is identifiable in the sparse linear Gaussian case. More generally, we extend the algorithmic Markov condition to include latent confounders. We propose a consistent score based on the Minimum Description Length principle to discover the full causal network, including latent confounders. Based on this score, we develop an effective algorithm that finds those sets of nodes for which the addition of a confounding factor $Z$ is most beneficial, then fits a new causal network over both observed as well as inferred latent variables.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/kaltenpoth23a/kaltenpoth23a.pdf",
        "supp": "",
        "pdf_size": 322943,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2354675860558690373&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "CISPA Helmholtz Center for Information Security, Saarbr\u00fccken; CISPA Helmholtz Center for Information Security, Saarbr\u00fccken",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "CISPA Helmholtz Center for Information Security",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cispa.de/",
        "aff_unique_abbr": "CISPA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Saarbr\u00fccken",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "ac4e931141",
        "title": "Causal effect estimation from observational and interventional data through matrix weighted linear estimators",
        "site": "https://proceedings.mlr.press/v216/kladny23a.html",
        "author": "Klaus-Rudolf Kladny; Julius von K\u00fcgelgen; Bernhard Sch\u00f6lkopf; Michael Muehlebach",
        "abstract": "We study causal effect estimation from a mixture of observational and interventional data in a confounded linear regression model with multivariate treatments. We show that the statistical efficiency in terms of expected squared error can be improved by combining estimators arising from both the observational and interventional setting. To this end, we derive methods based on matrix weighted linear estimators and prove that our methods are asymptotically unbiased in the infinite sample limit. This is an important improvement compared to the pooled estimator using the union of interventional and observational data, for which the bias only vanishes if the ratio of observational to interventional data tends to zero. Studies on synthetic data confirm our theoretical findings. In settings where confounding is substantial and the ratio of observational to interventional data is large, our estimators outperform a Stein-type estimator and various other baselines.",
        "bibtex": "@InProceedings{pmlr-v216-kladny23a,\n  title = \t {Causal effect estimation from observational and interventional data through matrix weighted linear estimators},\n  author =       {Kladny, Klaus-Rudolf and von K{\\\"u}gelgen, Julius and Sch{\\\"o}lkopf, Bernhard and Muehlebach, Michael},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1087--1097},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/kladny23a/kladny23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/kladny23a.html},\n  abstract = \t {We study causal effect estimation from a mixture of observational and interventional data in a confounded linear regression model with multivariate treatments. We show that the statistical efficiency in terms of expected squared error can be improved by combining estimators arising from both the observational and interventional setting. To this end, we derive methods based on matrix weighted linear estimators and prove that our methods are asymptotically unbiased in the infinite sample limit. This is an important improvement compared to the pooled estimator using the union of interventional and observational data, for which the bias only vanishes if the ratio of observational to interventional data tends to zero. Studies on synthetic data confirm our theoretical findings. In settings where confounding is substantial and the ratio of observational to interventional data is large, our estimators outperform a Stein-type estimator and various other baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/kladny23a/kladny23a.pdf",
        "supp": "",
        "pdf_size": 423904,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18423705515431352917&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Department of Computer Science, ETH Z\u00fcrich, Switzerland + Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany + Department of Engineering, University of Cambridge, United Kingdom; Department of Computer Science, ETH Z\u00fcrich, Switzerland + Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "aff_domain": "tue.mpg.de;tue.mpg.de;tue.mpg.de;tue.mpg.de",
        "email": "tue.mpg.de;tue.mpg.de;tue.mpg.de;tue.mpg.de",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1+2;0+1;1",
        "aff_unique_norm": "ETH Zurich;Max Planck Institute for Intelligent Systems;University of Cambridge",
        "aff_unique_dep": "Department of Computer Science;;Department of Engineering",
        "aff_unique_url": "https://www.ethz.ch;https://www.mpi-is.mpg.de;https://www.cam.ac.uk",
        "aff_unique_abbr": "ETHZ;MPI-IS;Cambridge",
        "aff_campus_unique_index": "1;1+2;1;1",
        "aff_campus_unique": ";T\u00fcbingen;Cambridge",
        "aff_country_unique_index": "0+1;1+2;0+1;1",
        "aff_country_unique": "Switzerland;Germany;United Kingdom"
    },
    {
        "id": "831f3b7377",
        "title": "Causal inference with outcome-dependent missingness and self-censoring",
        "site": "https://proceedings.mlr.press/v216/chen23f.html",
        "author": "Jacob M. Chen; Daniel Malinsky; Rohit Bhattacharya",
        "abstract": "We consider missingness in the context of causal inference when the outcome of interest may be missing. If the outcome directly affects its own missingness status, i.e., it is \u201cself-censoring\u201d, this may lead to severely biased causal effect estimates. Miao et al. (2015) proposed the shadow variable method to correct for bias due to self-censoring; however, verifying the required model assumptions can be difficult. Here, we propose a test based on a randomized incentive variable offered to encourage reporting of the outcome that can be used to verify identification assumptions that are sufficient to correct for both self-censoring and confounding bias. Concretely, the test confirms whether a given set of pre-treatment covariates is sufficient to block all backdoor paths between the treatment and outcome as well as all paths between the treatment and missingness indicator after conditioning on the outcome. We show that under these conditions, the causal effect is identified by using the treatment as a shadow variable, and it leads to an intuitive inverse probability weighting estimator that uses a product of the treatment and response weights. We evaluate the efficacy of our test and downstream estimator via simulations.",
        "bibtex": "@InProceedings{pmlr-v216-chen23f,\n  title = \t {Causal inference with outcome-dependent missingness and self-censoring},\n  author =       {Chen, Jacob M. and Malinsky, Daniel and Bhattacharya, Rohit},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {358--368},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/chen23f/chen23f.pdf},\n  url = \t {https://proceedings.mlr.press/v216/chen23f.html},\n  abstract = \t {We consider missingness in the context of causal inference when the outcome of interest may be missing. If the outcome directly affects its own missingness status, i.e., it is \u201cself-censoring\u201d, this may lead to severely biased causal effect estimates. Miao et al. (2015) proposed the shadow variable method to correct for bias due to self-censoring; however, verifying the required model assumptions can be difficult. Here, we propose a test based on a randomized incentive variable offered to encourage reporting of the outcome that can be used to verify identification assumptions that are sufficient to correct for both self-censoring and confounding bias. Concretely, the test confirms whether a given set of pre-treatment covariates is sufficient to block all backdoor paths between the treatment and outcome as well as all paths between the treatment and missingness indicator after conditioning on the outcome. We show that under these conditions, the causal effect is identified by using the treatment as a shadow variable, and it leads to an intuitive inverse probability weighting estimator that uses a product of the treatment and response weights. We evaluate the efficacy of our test and downstream estimator via simulations.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/chen23f/chen23f.pdf",
        "supp": "",
        "pdf_size": 365095,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11188210956484549310&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, Williams College; Department of Biostatistics, Columbia University; Department of Computer Science, Williams College",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Williams College;Columbia University",
        "aff_unique_dep": "Department of Computer Science;Department of Biostatistics",
        "aff_unique_url": "https://www.williams.edu;https://www.columbia.edu",
        "aff_unique_abbr": "Williams;Columbia",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "476dc7b3dd",
        "title": "Causal information splitting: Engineering proxy features for robustness to distribution shifts",
        "site": "https://proceedings.mlr.press/v216/mazaheri23a.html",
        "author": "Bijan Mazaheri; Atalanti Mastakouri; Dominik Janzing; Michaela Hardt",
        "abstract": "Statistical prediction models are often trained on data that is drawn from different probability distributions than their eventual use cases. One approach to proactively prepare for these shifts harnesses the intuition that causal mechanisms should remain invariant between environments. Here we focus on a challenging setting in which the causal and anticausal variables of the target are unobserved. Leaning on information theory, we develop feature selection and engineering techniques for the observed downstream variables that act as proxies. We identify proxies that help to build stable models and moreover utilize auxiliary training tasks to extract stability-enhancing information from proxies. We demonstrate the effectiveness of our techniques on synthetic and real data.",
        "bibtex": "@InProceedings{pmlr-v216-mazaheri23a,\n  title = \t {Causal information splitting: Engineering proxy features for robustness to distribution shifts},\n  author =       {Mazaheri, Bijan and Mastakouri, Atalanti and Janzing, Dominik and Hardt, Michaela},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1401--1411},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/mazaheri23a/mazaheri23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/mazaheri23a.html},\n  abstract = \t {Statistical prediction models are often trained on data that is drawn from different probability distributions than their eventual use cases. One approach to proactively prepare for these shifts harnesses the intuition that causal mechanisms should remain invariant between environments. Here we focus on a challenging setting in which the causal and anticausal variables of the target are unobserved. Leaning on information theory, we develop feature selection and engineering techniques for the observed downstream variables that act as proxies. We identify proxies that help to build stable models and moreover utilize auxiliary training tasks to extract stability-enhancing information from proxies. We demonstrate the effectiveness of our techniques on synthetic and real data.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/mazaheri23a/mazaheri23a.pdf",
        "supp": "",
        "pdf_size": 363214,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16056622729929628113&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fdca80af3d",
        "title": "Combinatorial categorized bandits with expert rankings",
        "site": "https://proceedings.mlr.press/v216/chowdhury23a.html",
        "author": "Sayak Ray Chowdhury; Gaurav Sinha; Nagarajan Natarajan; Amit Sharma",
        "abstract": "Many real-world systems such as e-commerce websites and content-serving platforms employ two-stage recommendation \u2014 in the first stage, multiple nominators (experts) provide ranked lists of items (one nominator per category, e.g., sports and political news articles), and in the second stage, an aggregator filters across the lists and outputs a single (short) list of K items to the users. The aggregation stage can be posed as a combinatorial multi-armed bandit problem, with the additional structure that the arms are grouped into categories (disjoint sets of items) and the ranking of arms within each category is known. We propose algorithms for selecting top K items in this setting under two learning objectives, namely minimizing regret over rounds and identifying the top K items within a fixed number of rounds. For each of the objectives, we provide sharp regret/error analysis using carefully defined notion of \u201cgap\u201d that exploits our problem structure. The resulting regret/error bounds strictly improve over prior work in combinatorial bandits literature. We also provide supporting evidence from simulations on synthetic and semi-synthetic problems.",
        "bibtex": "@InProceedings{pmlr-v216-chowdhury23a,\n  title = \t {Combinatorial categorized bandits with expert rankings},\n  author =       {Chowdhury, Sayak Ray and Sinha, Gaurav and Natarajan, Nagarajan and Sharma, Amit},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {403--412},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/chowdhury23a/chowdhury23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/chowdhury23a.html},\n  abstract = \t {Many real-world systems such as e-commerce websites and content-serving platforms employ two-stage recommendation \u2014 in the first stage, multiple nominators (experts) provide ranked lists of items (one nominator per category, e.g., sports and political news articles), and in the second stage, an aggregator filters across the lists and outputs a single (short) list of K items to the users. The aggregation stage can be posed as a combinatorial multi-armed bandit problem, with the additional structure that the arms are grouped into categories (disjoint sets of items) and the ranking of arms within each category is known. We propose algorithms for selecting top K items in this setting under two learning objectives, namely minimizing regret over rounds and identifying the top K items within a fixed number of rounds. For each of the objectives, we provide sharp regret/error analysis using carefully defined notion of \u201cgap\u201d that exploits our problem structure. The resulting regret/error bounds strictly improve over prior work in combinatorial bandits literature. We also provide supporting evidence from simulations on synthetic and semi-synthetic problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/chowdhury23a/chowdhury23a.pdf",
        "supp": "",
        "pdf_size": 432962,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14598948450115482096&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6b553d6b58",
        "title": "Composing Efficient, Robust Tests for Policy Selection",
        "site": "https://proceedings.mlr.press/v216/morrill23a.html",
        "author": "Dustin Morrill; Thomas J. Walsh; Daniel Hernandez; Peter R. Wurman; Peter Stone",
        "abstract": "Modern reinforcement learning systems produce many high-quality policies throughout the learning process. However, to choose which policy to actually deploy in the real world, they must be tested under an intractable number of environmental conditions. We introduce RPOSST, an algorithm to select a small set of test cases from a larger pool based on a relatively small number of sample evaluations. RPOSST treats the test case selection problem as a two-player game and optimizes a solution with provable $k$-of-$N$ robustness, bounding the error relative to a test that used all the test cases in the pool. Empirical results demonstrate that RPOSST finds a small set of test cases that identify high quality policies in a toy one-shot game, poker datasets, and a high-fidelity racing simulator.",
        "bibtex": "@InProceedings{pmlr-v216-morrill23a,\n  title = \t {Composing Efficient, Robust Tests for Policy Selection},\n  author =       {Morrill, Dustin and Walsh, Thomas J. and Hernandez, Daniel and Wurman, Peter R. and Stone, Peter},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1456--1466},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/morrill23a/morrill23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/morrill23a.html},\n  abstract = \t {Modern reinforcement learning systems produce many high-quality policies throughout the learning process. However, to choose which policy to actually deploy in the real world, they must be tested under an intractable number of environmental conditions. We introduce RPOSST, an algorithm to select a small set of test cases from a larger pool based on a relatively small number of sample evaluations. RPOSST treats the test case selection problem as a two-player game and optimizes a solution with provable $k$-of-$N$ robustness, bounding the error relative to a test that used all the test cases in the pool. Empirical results demonstrate that RPOSST finds a small set of test cases that identify high quality policies in a toy one-shot game, poker datasets, and a high-fidelity racing simulator.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/morrill23a/morrill23a.pdf",
        "supp": "",
        "pdf_size": 697146,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:6gJ_hh1L-jMJ:scholar.google.com/&scioq=Composing+Efficient,+Robust+Tests+for+Policy+Selection&hl=en&as_sdt=0,33",
        "gs_version_total": 8,
        "aff": "Sony AI, New York, NY, USA; Sony AI, New York, NY, USA; Sony AI, New York, NY, USA; Sony AI, New York, NY, USA; Sony AI, New York, NY, USA + Department of Computer Science, The University of Texas at Austin, Austin, TX, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0+1",
        "aff_unique_norm": "Sony AI;University of Texas at Austin",
        "aff_unique_dep": "AI;Department of Computer Science",
        "aff_unique_url": "https://www.sonyai.com;https://www.utexas.edu",
        "aff_unique_abbr": "Sony AI;UT Austin",
        "aff_campus_unique_index": "0;0;0;0;0+1",
        "aff_campus_unique": "New York;Austin",
        "aff_country_unique_index": "0;0;0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e59964dbfb",
        "title": "Concurrent Misclassification and Out-of-Distribution Detection for Semantic Segmentation via Energy-Based Normalizing Flow",
        "site": "https://proceedings.mlr.press/v216/gudovskiy23a.html",
        "author": "Denis Gudovskiy; Tomoyuki Okuno; Yohei Nakata",
        "abstract": "Recent semantic segmentation models accurately classify test-time examples that are similar to a training dataset distribution. However, their discriminative closed-set approach is not robust in practical data setups with distributional shifts and out-of-distribution (OOD) classes. As a result, the predicted probabilities can be very imprecise when used as confidence scores at test time. To address this, we propose a generative model for concurrent in-distribution misclassification (IDM) and OOD detection that relies on a normalizing flow framework. The proposed flow-based detector with an energy-based inputs (FlowEneDet) can extend previously deployed segmentation models without their time-consuming retraining. Our FlowEneDet results in a low-complexity architecture with marginal increase in the memory footprint. FlowEneDet achieves promising results on Cityscapes, Cityscapes-C, FishyScapes and SegmentMeIfYouCan benchmarks in IDM/OOD detection when applied to pretrained DeepLabV3+ and SegFormer semantic segmentation models.",
        "bibtex": "@InProceedings{pmlr-v216-gudovskiy23a,\n  title = \t {Concurrent Misclassification and Out-of-Distribution Detection for Semantic Segmentation via Energy-Based Normalizing Flow},\n  author =       {Gudovskiy, Denis and Okuno, Tomoyuki and Nakata, Yohei},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {745--755},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/gudovskiy23a/gudovskiy23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/gudovskiy23a.html},\n  abstract = \t {Recent semantic segmentation models accurately classify test-time examples that are similar to a training dataset distribution. However, their discriminative closed-set approach is not robust in practical data setups with distributional shifts and out-of-distribution (OOD) classes. As a result, the predicted probabilities can be very imprecise when used as confidence scores at test time. To address this, we propose a generative model for concurrent in-distribution misclassification (IDM) and OOD detection that relies on a normalizing flow framework. The proposed flow-based detector with an energy-based inputs (FlowEneDet) can extend previously deployed segmentation models without their time-consuming retraining. Our FlowEneDet results in a low-complexity architecture with marginal increase in the memory footprint. FlowEneDet achieves promising results on Cityscapes, Cityscapes-C, FishyScapes and SegmentMeIfYouCan benchmarks in IDM/OOD detection when applied to pretrained DeepLabV3+ and SegFormer semantic segmentation models.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/gudovskiy23a/gudovskiy23a.pdf",
        "supp": "",
        "pdf_size": 1665035,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16604393781199701770&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cb2a786e4c",
        "title": "Conditional abstraction trees for sample-efficient reinforcement learning",
        "site": "https://proceedings.mlr.press/v216/dadvar23a.html",
        "author": "Mehdi Dadvar; Rashmeet Kaur Nayyar; Siddharth Srivastava",
        "abstract": "In many real-world problems, the learning agent needs to learn a problem\u2019s abstractions and solution simultaneously. However, most such abstractions need to be designed and refined by hand for different problems and domains of application. This paper presents a novel top-down approach for constructing state abstractions while carrying out reinforcement learning (RL). Starting with state variables and a simulator, it presents a novel domain-independent approach for dynamically computing an abstraction based on the dispersion of temporal difference errors in abstract states as the agent continues acting and learning. Extensive empirical evaluation on multiple domains and problems shows that this approach automatically learns semantically rich abstractions that are finely-tuned to the problem, yield strong sample efficiency, and result in the RL agent significantly outperforming existing approaches.",
        "bibtex": "@InProceedings{pmlr-v216-dadvar23a,\n  title = \t {Conditional abstraction trees for sample-efficient reinforcement learning},\n  author =       {Dadvar, Mehdi and Nayyar, Rashmeet Kaur and Srivastava, Siddharth},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {485--495},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/dadvar23a/dadvar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/dadvar23a.html},\n  abstract = \t {In many real-world problems, the learning agent needs to learn a problem\u2019s abstractions and solution simultaneously. However, most such abstractions need to be designed and refined by hand for different problems and domains of application. This paper presents a novel top-down approach for constructing state abstractions while carrying out reinforcement learning (RL). Starting with state variables and a simulator, it presents a novel domain-independent approach for dynamically computing an abstraction based on the dispersion of temporal difference errors in abstract states as the agent continues acting and learning. Extensive empirical evaluation on multiple domains and problems shows that this approach automatically learns semantically rich abstractions that are finely-tuned to the problem, yield strong sample efficiency, and result in the RL agent significantly outperforming existing approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/dadvar23a/dadvar23a.pdf",
        "supp": "",
        "pdf_size": 2035880,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6802641676283693542&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "42c21279a2",
        "title": "Conditional counterfactual causal effect for individual attribution",
        "site": "https://proceedings.mlr.press/v216/zhao23a.html",
        "author": "Ruiqi Zhao; Lei Zhang; Shengyu Zhu; Zitong Lu; Zhenhua Dong; Chaoliang Zhang; Jun Xu; Zhi Geng; Yangbo He",
        "abstract": "Identifying the causes of an event, also termed as causal attribution, is a commonly encountered task in many application problems.  Available methods, mostly in Bayesian or causal inference literature, suffer from two main drawbacks: 1) cannot attribute for individuals, and 2) attributing one single cause at a time and cannot deal with the interaction effect among multiple causes. In this paper, based on our proposed new measurement, called conditional counterfactual causal effect (CCCE), we introduce an individual causal attribution method, which is able to utilize the individual observation as the evidence and consider common influence and interaction effect of multiple causes simultaneously. We discuss the identifiability of CCCE and also give the identification formulas under proper assumptions. Finally, we conduct experiments on simulated and real data to illustrate the effectiveness of CCCE and the results show that our proposed method outperforms significantly state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v216-zhao23a,\n  title = \t {Conditional counterfactual causal effect for individual attribution},\n  author =       {Zhao, Ruiqi and Zhang, Lei and Zhu, Shengyu and Lu, Zitong and Dong, Zhenhua and Zhang, Chaoliang and Xu, Jun and Geng, Zhi and He, Yangbo},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2519--2528},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zhao23a/zhao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zhao23a.html},\n  abstract = \t {Identifying the causes of an event, also termed as causal attribution, is a commonly encountered task in many application problems.  Available methods, mostly in Bayesian or causal inference literature, suffer from two main drawbacks: 1) cannot attribute for individuals, and 2) attributing one single cause at a time and cannot deal with the interaction effect among multiple causes. In this paper, based on our proposed new measurement, called conditional counterfactual causal effect (CCCE), we introduce an individual causal attribution method, which is able to utilize the individual observation as the evidence and consider common influence and interaction effect of multiple causes simultaneously. We discuss the identifiability of CCCE and also give the identification formulas under proper assumptions. Finally, we conduct experiments on simulated and real data to illustrate the effectiveness of CCCE and the results show that our proposed method outperforms significantly state-of-the-art methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/zhao23a/zhao23a.pdf",
        "supp": "",
        "pdf_size": 302696,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7500944808728174027&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "School of Mathematical Sciences, Peking University; Renmin University of China; Huawei Noah\u2019s Ark Lab; City University of Hong Kong; Huawei Noah\u2019s Ark Lab; Huawei Noah\u2019s Ark Lab; Renmin University of China; School of Mathematics and Statistics, Beijing Technology and Business University; School of Mathematical Sciences, Peking University",
        "aff_domain": "; ; ; ; ; ; ; ;math.pku.edu.cn",
        "email": "; ; ; ; ; ; ; ;math.pku.edu.cn",
        "github": "",
        "project": "",
        "author_num": 9,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3;2;2;1;4;0",
        "aff_unique_norm": "Peking University;Renmin University of China;Huawei;City University of Hong Kong;Beijing Technology and Business University",
        "aff_unique_dep": "School of Mathematical Sciences;;Noah\u2019s Ark Lab;;School of Mathematics and Statistics",
        "aff_unique_url": "http://www.pku.edu.cn;http://www.ruc.edu.cn;https://www.huawei.com;https://www.cityu.edu.hk;http://www.btbu.edu.cn",
        "aff_unique_abbr": "PKU;RUC;Huawei;CityU;",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Beijing;;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "a2cb95b5a2",
        "title": "Conditionally optimistic exploration for cooperative deep multi-agent reinforcement learning",
        "site": "https://proceedings.mlr.press/v216/zhao23b.html",
        "author": "Xutong Zhao; Yangchen Pan; Chenjun Xiao; Sarath Chandar; Janarthanan Rajendran",
        "abstract": "Efficient exploration is critical in cooperative deep Multi-Agent Reinforcement Learning (MARL). In this work, we propose an exploration method that effectively encourages cooperative exploration based on the idea of sequential action-computation scheme. The high-level intuition is that to perform optimism-based exploration, agents would explore cooperative strategies if each agent\u2019s optimism estimate captures a structured dependency relationship with other agents. Assuming agents compute actions following a sequential order at",
        "bibtex": "@InProceedings{pmlr-v216-zhao23b,\n  title = \t {Conditionally optimistic exploration for cooperative deep multi-agent reinforcement learning},\n  author =       {Zhao, Xutong and Pan, Yangchen and Xiao, Chenjun and Chandar, Sarath and Rajendran, Janarthanan},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2529--2540},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zhao23b/zhao23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zhao23b.html},\n  abstract = \t {Efficient exploration is critical in cooperative deep Multi-Agent Reinforcement Learning (MARL). In this work, we propose an exploration method that effectively encourages cooperative exploration based on the idea of sequential action-computation scheme. The high-level intuition is that to perform optimism-based exploration, agents would explore cooperative strategies if each agent\u2019s optimism estimate captures a structured dependency relationship with other agents. Assuming agents compute actions following a sequential order at",
        "pdf": "https://proceedings.mlr.press/v216/zhao23b/zhao23b.pdf",
        "supp": "",
        "pdf_size": 484412,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6648043947604655513&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Mila - Quebec AI Institute + \u00c9cole Polytechnique de Montr\u00e9al; University of Oxford; University of Alberta; Mila - Quebec AI Institute + \u00c9cole Polytechnique de Montr\u00e9al + Universit\u00e9 de Montr\u00e9al; Universit\u00e9 de Montr\u00e9al",
        "aff_domain": "mila.quebec;ox.ac.uk;ualberta.ca;mila.quebec;umontreal.ca",
        "email": "mila.quebec;ox.ac.uk;ualberta.ca;mila.quebec;umontreal.ca",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2;3;0+1+4;4",
        "aff_unique_norm": "Quebec AI Institute;\u00c9cole Polytechnique de Montr\u00e9al;University of Oxford;University of Alberta;Universit\u00e9 de Montr\u00e9al",
        "aff_unique_dep": "AI Institute;;;;",
        "aff_unique_url": "https://mila.quebec;https://www.polymtl.ca;https://www.ox.ac.uk;https://www.ualberta.ca;https://www.umontreal.ca",
        "aff_unique_abbr": "Mila;Polytechnique Montr\u00e9al;Oxford;UAlberta;UdeM",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Montr\u00e9al",
        "aff_country_unique_index": "0+0;1;0;0+0+0;0",
        "aff_country_unique": "Canada;United Kingdom"
    },
    {
        "id": "088fb6e673",
        "title": "Conformal Risk Control for Ordinal Classification",
        "site": "https://proceedings.mlr.press/v216/xu23a.html",
        "author": "Yunpeng Xu; Wenge Guo; Zhi Wei",
        "abstract": "As a natural extension to the standard conformal prediction method, several conformal risk control methods have been recently developed and applied to various learning problems. In this work, we seek to control the conformal risk in expectation for ordinal classification tasks, which have broad applications to many real problems. For this purpose, we firstly formulated the ordinal classification task in the conformal risk control framework, and provided theoretic risk bounds of the risk control method. Then we proposed two types of loss functions specially designed for ordinal classification tasks, and developed corresponding algorithms to determine the prediction set for each case to control their risks at a desired level. We demonstrated the effectiveness of our proposed methods, and analyzed the difference between the two types of risks on three different datasets, including a simulated dataset, the UTKFace dataset and  the diabetic retinopathy detection dataset.",
        "bibtex": "@InProceedings{pmlr-v216-xu23a,\n  title = \t {Conformal Risk Control for Ordinal Classification},\n  author =       {Xu, Yunpeng and Guo, Wenge and Wei, Zhi},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2346--2355},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/xu23a/xu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/xu23a.html},\n  abstract = \t {As a natural extension to the standard conformal prediction method, several conformal risk control methods have been recently developed and applied to various learning problems. In this work, we seek to control the conformal risk in expectation for ordinal classification tasks, which have broad applications to many real problems. For this purpose, we firstly formulated the ordinal classification task in the conformal risk control framework, and provided theoretic risk bounds of the risk control method. Then we proposed two types of loss functions specially designed for ordinal classification tasks, and developed corresponding algorithms to determine the prediction set for each case to control their risks at a desired level. We demonstrated the effectiveness of our proposed methods, and analyzed the difference between the two types of risks on three different datasets, including a simulated dataset, the UTKFace dataset and  the diabetic retinopathy detection dataset.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/xu23a/xu23a.pdf",
        "supp": "",
        "pdf_size": 788781,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2066316766522851235&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, New Jersey Institute of Technology, Newark, New Jersey, 07102, USA; Department of Mathematical Sciences, New Jersey Institute of Technology, Newark, New Jersey, 07102, USA; Department of Computer Science, New Jersey Institute of Technology, Newark, New Jersey, 07102, USA",
        "aff_domain": "njit.edu;njit.edu;njit.edu",
        "email": "njit.edu;njit.edu;njit.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "New Jersey Institute of Technology",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.njit.edu",
        "aff_unique_abbr": "NJIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "76ab648ef7",
        "title": "Content Sharing Design for Social Welfare in Networked Disclosure Game",
        "site": "https://proceedings.mlr.press/v216/jia23b.html",
        "author": "Feiran Jia; Chenxi Qiu; Sarah Rajtmajer; Anna Squicciarini",
        "abstract": "This work models the costs and benefits of personal information sharing, or self-disclosure, in online social networks as a networked disclosure game. In a networked population where edges represent visibility amongst users, we assume a leader can influence network structure through content promotion, and we seek to optimize social welfare through network design. Our approach considers user interaction non-homogeneously, where pairwise engagement amongst users can involve or not involve sharing personal information. We prove that this problem is NP-hard. As a solution, we develop a Mixed-integer Linear Programming algorithm, which can achieve an exact solution, and also develop a time-efficient heuristic algorithm that can be used at scale. We conduct numerical experiments to demonstrate the properties of the algorithms and map theoretical results to a dataset of posts and comments in 2020 and 2021 in a COVID-related Subreddit community where privacy risks and sharing tradeoffs were particularly pronounced.",
        "bibtex": "@InProceedings{pmlr-v216-jia23b,\n  title = \t {Content Sharing Design for Social Welfare in Networked Disclosure Game},\n  author =       {Jia, Feiran and Qiu, Chenxi and Rajtmajer, Sarah and Squicciarini, Anna},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {973--983},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/jia23b/jia23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/jia23b.html},\n  abstract = \t {This work models the costs and benefits of personal information sharing, or self-disclosure, in online social networks as a networked disclosure game. In a networked population where edges represent visibility amongst users, we assume a leader can influence network structure through content promotion, and we seek to optimize social welfare through network design. Our approach considers user interaction non-homogeneously, where pairwise engagement amongst users can involve or not involve sharing personal information. We prove that this problem is NP-hard. As a solution, we develop a Mixed-integer Linear Programming algorithm, which can achieve an exact solution, and also develop a time-efficient heuristic algorithm that can be used at scale. We conduct numerical experiments to demonstrate the properties of the algorithms and map theoretical results to a dataset of posts and comments in 2020 and 2021 in a COVID-related Subreddit community where privacy risks and sharing tradeoffs were particularly pronounced.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/jia23b/jia23b.pdf",
        "supp": "",
        "pdf_size": 449233,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6970666994829235345&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3d08a1a3b8",
        "title": "Contrastive learning for supervised graph matching",
        "site": "https://proceedings.mlr.press/v216/ratnayaka23a.html",
        "author": "Gathika Ratnayaka; Qing Wang; Yang Li",
        "abstract": "Deep graph matching techniques have shown promising results in recent years. In this work, we cast deep graph matching as a contrastive learning task and introduce a new objective function for contrastive mapping to exploit the relationships between matches and non-matches. To this end, we develop a hardness attention mechanism to select negative samples which captures the relatedness and informativeness of positive and negative samples. Further, we propose a novel deep graph matching framework, Stable Graph Matching (StableGM), which incorporates Sinkhorn ranking into a stable marriage algorithm to efficiently compute one-to-one node correspondences between graphs. We prove that the proposed objective function for contrastive matching is both positive and negative informative, offering theoretical guarantees to achieve dual-optimality in graph matching. We empirically verify the effectiveness of our proposed approach by conducting experiments on standard graph matching benchmarks.",
        "bibtex": "@InProceedings{pmlr-v216-ratnayaka23a,\n  title = \t {Contrastive learning for supervised graph matching},\n  author =       {Ratnayaka, Gathika and Wang, Qing and Li, Yang},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1718--1729},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/ratnayaka23a/ratnayaka23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/ratnayaka23a.html},\n  abstract = \t {Deep graph matching techniques have shown promising results in recent years. In this work, we cast deep graph matching as a contrastive learning task and introduce a new objective function for contrastive mapping to exploit the relationships between matches and non-matches. To this end, we develop a hardness attention mechanism to select negative samples which captures the relatedness and informativeness of positive and negative samples. Further, we propose a novel deep graph matching framework, Stable Graph Matching (StableGM), which incorporates Sinkhorn ranking into a stable marriage algorithm to efficiently compute one-to-one node correspondences between graphs. We prove that the proposed objective function for contrastive matching is both positive and negative informative, offering theoretical guarantees to achieve dual-optimality in graph matching. We empirically verify the effectiveness of our proposed approach by conducting experiments on standard graph matching benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/ratnayaka23a/ratnayaka23a.pdf",
        "supp": "",
        "pdf_size": 527179,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10436362685063294771&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e90fd5b175",
        "title": "Convergence rates for localized actor-critic in networked Markov potential games",
        "site": "https://proceedings.mlr.press/v216/zhou23b.html",
        "author": "Zhaoyi Zhou; Zaiwei Chen; Yiheng Lin; Adam Wierman",
        "abstract": "We introduce a class of networked Markov potential games where agents are associated with nodes in a network. Each agent has its own local potential function, and the reward of each agent depends only on the states and actions of agents within a neighborhood.  In this context, we propose a localized actor-critic algorithm.  The algorithm is scalable since each agent uses only local information and does not need access to the global state.  Further, the algorithm overcomes the curse of dimensionality through the use of function approximation.  Our main results provide finite-sample guarantees up to a localization error and a function approximation error. Specifically, we achieve an $\\tilde{\\mathcal{O}}(\\tilde{\\epsilon}^{-4})$ sample complexity measured by the averaged Nash regret. This is the first finite-sample bound for multi-agent competitive games  that does not depend on the number of agents.",
        "bibtex": "@InProceedings{pmlr-v216-zhou23b,\n  title = \t {Convergence rates for localized actor-critic in networked {M}arkov potential games},\n  author =       {Zhou, Zhaoyi and Chen, Zaiwei and Lin, Yiheng and Wierman, Adam},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2563--2573},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zhou23b/zhou23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zhou23b.html},\n  abstract = \t {We introduce a class of networked Markov potential games where agents are associated with nodes in a network. Each agent has its own local potential function, and the reward of each agent depends only on the states and actions of agents within a neighborhood.  In this context, we propose a localized actor-critic algorithm.  The algorithm is scalable since each agent uses only local information and does not need access to the global state.  Further, the algorithm overcomes the curse of dimensionality through the use of function approximation.  Our main results provide finite-sample guarantees up to a localization error and a function approximation error. Specifically, we achieve an $\\tilde{\\mathcal{O}}(\\tilde{\\epsilon}^{-4})$ sample complexity measured by the averaged Nash regret. This is the first finite-sample bound for multi-agent competitive games  that does not depend on the number of agents.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/zhou23b/zhou23b.pdf",
        "supp": "",
        "pdf_size": 276850,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4573140222174665216&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1b12e47642",
        "title": "Copula for Instance-wise Feature Selection and Rank",
        "site": "https://proceedings.mlr.press/v216/peng23a.html",
        "author": "Hanyu Peng; Guanhua Fang; Ping Li",
        "abstract": "Instance-wise feature selection and ranking methods can achieve a good selection of task-friendly features for each sample in the context of neural networks. However, existing approaches that assume feature subsets to be independent are imperfect when considering the dependency between features. To address this limitation, we propose to incorporate the Gaussian copula, a powerful mathematical technique for capturing correlations between variables, into the current feature selection framework with no additional changes needed. Experimental results on both synthetic and real datasets, in terms of performance comparison and interpretability, demonstrate that our method is capable of capturing meaningful correlations.",
        "bibtex": "@InProceedings{pmlr-v216-peng23a,\n  title = \t {Copula for Instance-wise Feature Selection and Rank},\n  author =       {Peng, Hanyu and Fang, Guanhua and Li, Ping},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1651--1661},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/peng23a/peng23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/peng23a.html},\n  abstract = \t {Instance-wise feature selection and ranking methods can achieve a good selection of task-friendly features for each sample in the context of neural networks. However, existing approaches that assume feature subsets to be independent are imperfect when considering the dependency between features. To address this limitation, we propose to incorporate the Gaussian copula, a powerful mathematical technique for capturing correlations between variables, into the current feature selection framework with no additional changes needed. Experimental results on both synthetic and real datasets, in terms of performance comparison and interpretability, demonstrate that our method is capable of capturing meaningful correlations.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/peng23a/peng23a.pdf",
        "supp": "",
        "pdf_size": 981588,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11537819425435747651&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Cognitive Computing Lab, Baidu Research, No.10 Xibeiwang East Road, Beijing 100193, China; Cognitive Computing Lab, Baidu Research, No.10 Xibeiwang East Road, Beijing 100193, China; Cognitive Computing Lab, Baidu Research, No.10 Xibeiwang East Road, Beijing 100193, China",
        "aff_domain": "gmail.com;gmail.com;gmail.com",
        "email": "gmail.com;gmail.com;gmail.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Baidu",
        "aff_unique_dep": "Cognitive Computing Lab",
        "aff_unique_url": "https://research.baidu.com",
        "aff_unique_abbr": "Baidu",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "2e444a53bc",
        "title": "Copula-based deep survival models for dependent censoring",
        "site": "https://proceedings.mlr.press/v216/gharari23a.html",
        "author": "Ali Hossein Foomani Gharari; Michael Cooper; Russell Greiner; Rahul G Krishnan",
        "abstract": "A survival dataset describes a set of instances (e.g. patients) and provides, for each, either the time until an event (e.g. death), or the censoring time (e.g. when lost to follow-up - which is a lower bound on the time until the event). We consider the challenge of survival prediction: learning, from such data, a predictive model that can produce an individual survival distribution for a novel instance. Many contemporary methods of survival prediction implicitly assume that the event and censoring distributions are independent conditional on the instance\u2019s covariates - a strong assumption that is difficult to verify (as we observe only one outcome for each instance) and which can induce significant bias when it does not hold. This paper presents a parametric model of survival that extends modern non-linear survival analysis by relaxing the assumption of conditional independence. On synthetic and semi-synthetic data, our approach significantly improves estimates of survival distributions compared to the standard that assumes conditional independence in the data.",
        "bibtex": "@InProceedings{pmlr-v216-gharari23a,\n  title = \t {Copula-based deep survival models for dependent censoring},\n  author =       {Gharari, Ali Hossein Foomani and Cooper, Michael and Greiner, Russell and Krishnan, Rahul G},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {669--680},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/gharari23a/gharari23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/gharari23a.html},\n  abstract = \t {A survival dataset describes a set of instances (e.g. patients) and provides, for each, either the time until an event (e.g. death), or the censoring time (e.g. when lost to follow-up - which is a lower bound on the time until the event). We consider the challenge of survival prediction: learning, from such data, a predictive model that can produce an individual survival distribution for a novel instance. Many contemporary methods of survival prediction implicitly assume that the event and censoring distributions are independent conditional on the instance\u2019s covariates - a strong assumption that is difficult to verify (as we observe only one outcome for each instance) and which can induce significant bias when it does not hold. This paper presents a parametric model of survival that extends modern non-linear survival analysis by relaxing the assumption of conditional independence. On synthetic and semi-synthetic data, our approach significantly improves estimates of survival distributions compared to the standard that assumes conditional independence in the data.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/gharari23a/gharari23a.pdf",
        "supp": "",
        "pdf_size": 1172757,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13193055997919855105&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computing Science, University of Alberta + Alberta Machine Intelligence Institute; Department of Computer Science, University of Toronto + Vector Institute; Department of Computing Science, University of Alberta + Alberta Machine Intelligence Institute; Department of Computer Science, University of Toronto + Department of Laboratory Medicine and Pathobiology, University of Toronto + Vector Institute",
        "aff_domain": "ualberta.ca;cs.toronto.edu;ualberta.ca;utoronto.ca",
        "email": "ualberta.ca;cs.toronto.edu;ualberta.ca;utoronto.ca",
        "github": "https://github.com/author/repo",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2+3;0+1;2+2+3",
        "aff_unique_norm": "University of Alberta;Alberta Machine Intelligence Institute;University of Toronto;Vector Institute",
        "aff_unique_dep": "Department of Computing Science;;Department of Computer Science;",
        "aff_unique_url": "https://www.ualberta.ca;https://www.ami.ualberta.ca/;https://www.utoronto.ca;https://vectorinstitute.ai/",
        "aff_unique_abbr": "UAlberta;AMII;U of T;Vector Institute",
        "aff_campus_unique_index": ";1;;1",
        "aff_campus_unique": ";Toronto",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0+0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "83ff688e4a",
        "title": "Correcting for selection bias and missing response in regression using privileged information",
        "site": "https://proceedings.mlr.press/v216/boeken23a.html",
        "author": "P Boeken; Noud de Kroon; Mathijs de Jong; Joris M. Mooij; Onno Zoeter",
        "abstract": "When estimating a regression model, we might have data where some labels are missing, or our data might be biased by a selection mechanism. When the response or selection mechanism is ignorable (i.e., independent of the response variable given the features) one can use off-the-shelf regression methods; in the nonignorable case one typically has to adjust for bias. We observe that privileged information (i.e. information that is only available during training) might render a nonignorable selection mechanism ignorable, and we refer to this scenario as Privilegedly Missing at Random (PMAR). We propose a novel imputation-based regression method, named repeated regression, that is suitable for PMAR. We also consider an importance weighted regression method, and a doubly robust combination of the two. The proposed methods are easy to implement with most popular out-of-the-box regression algorithms. We empirically assess the performance of the proposed methods with extensive simulated experiments and on a synthetically augmented real-world dataset. We conclude that repeated regression can appropriately correct for bias, and can have considerable advantage over weighted regression, especially when extrapolating to regions of the feature space where response is never observed.",
        "bibtex": "@InProceedings{pmlr-v216-boeken23a,\n  title = \t {Correcting for selection bias and missing response in regression using privileged information},\n  author =       {Boeken, P and de Kroon, Noud and de Jong, Mathijs and Mooij, Joris M. and Zoeter, Onno},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {195--205},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/boeken23a/boeken23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/boeken23a.html},\n  abstract = \t {When estimating a regression model, we might have data where some labels are missing, or our data might be biased by a selection mechanism. When the response or selection mechanism is ignorable (i.e., independent of the response variable given the features) one can use off-the-shelf regression methods; in the nonignorable case one typically has to adjust for bias. We observe that privileged information (i.e. information that is only available during training) might render a nonignorable selection mechanism ignorable, and we refer to this scenario as Privilegedly Missing at Random (PMAR). We propose a novel imputation-based regression method, named repeated regression, that is suitable for PMAR. We also consider an importance weighted regression method, and a doubly robust combination of the two. The proposed methods are easy to implement with most popular out-of-the-box regression algorithms. We empirically assess the performance of the proposed methods with extensive simulated experiments and on a synthetically augmented real-world dataset. We conclude that repeated regression can appropriately correct for bias, and can have considerable advantage over weighted regression, especially when extrapolating to regions of the feature space where response is never observed.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/boeken23a/boeken23a.pdf",
        "supp": "",
        "pdf_size": 386073,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2478612541017831070&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Korteweg-de Vries Institute for Mathematics, University of Amsterdam, The Netherlands+Booking.com, The Netherlands; Korteweg-de Vries Institute for Mathematics, University of Amsterdam, The Netherlands; Booking.com, The Netherlands; Korteweg-de Vries Institute for Mathematics, University of Amsterdam, The Netherlands; Booking.com, The Netherlands",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;1;0;1",
        "aff_unique_norm": "University of Amsterdam;Booking.com",
        "aff_unique_dep": "Korteweg-de Vries Institute for Mathematics;",
        "aff_unique_url": "https://www.uva.nl;https://www.booking.com",
        "aff_unique_abbr": ";Booking.com",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "49bf766279",
        "title": "Counting Background Knowledge Consistent Markov Equivalent Directed Acyclic Graphs",
        "site": "https://proceedings.mlr.press/v216/sharma23b.html",
        "author": "Vidya Sagar Sharma",
        "abstract": "We study the problem of counting the number of directed acyclic graphs in a Markov equivalence class (MEC) that are consistent with",
        "bibtex": "@InProceedings{pmlr-v216-sharma23b,\n  title = \t {Counting Background Knowledge Consistent {M}arkov Equivalent Directed Acyclic Graphs},\n  author =       {Sharma, Vidya Sagar},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1911--1920},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/sharma23b/sharma23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/sharma23b.html},\n  abstract = \t {We study the problem of counting the number of directed acyclic graphs in a Markov equivalence class (MEC) that are consistent with",
        "pdf": "https://proceedings.mlr.press/v216/sharma23b/sharma23b.pdf",
        "supp": "",
        "pdf_size": 303283,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13566069967255967633&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "School of Technology and Computer Science, Tata Institute of Fundamental Research, Mumbai, Maharashtra, India",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Tata Institute of Fundamental Research",
        "aff_unique_dep": "School of Technology and Computer Science",
        "aff_unique_url": "https://www.tifr.res.in",
        "aff_unique_abbr": "TIFR",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Mumbai",
        "aff_country_unique_index": "0",
        "aff_country_unique": "India"
    },
    {
        "id": "9f784920ad",
        "title": "CrysMMNet: Multimodal Representation for Crystal Property Prediction",
        "site": "https://proceedings.mlr.press/v216/das23a.html",
        "author": "Kishalay Das; Pawan Goyal; Seung-Cheol Lee; Satadeep Bhattacharjee; Niloy Ganguly",
        "abstract": "Machine Learning models have emerged as a powerful tool for fast and accurate prediction of different crystalline properties. Exiting state-of-the-art models rely on a single modality of crystal data i.e crystal graph structure, where they construct multi-graph by establishing edges between nearby atoms in 3D space and apply GNN to learn materials representation. Thereby, they encode local chemical semantics around the atoms successfully but fail to capture important global periodic structural information like space group number, crystal symmetry, rotational information etc, which influence different crystal properties.  In this work, we leverage textual descriptions of materials to model global structural information into graph structure and learn a more robust and enriched representation of crystalline materials. To this effect, we first curate a textual dataset for crystalline material databases containing descriptions of each material. Further, we propose CrysMMNet, a simple multi-modal framework, which fuses both structural and textual representation together to generate a joint multimodal representation of crystalline materials. We conduct extensive experiments on two benchmark datasets across ten different properties to show that CrysMMNet outperforms existing state-of-the-art baseline methods with a good margin. We also observe that fusing the textual representation with crystal graph structure provides consistent improvement for all the SOTA GNN models compared to their own vanilla versions. We have shared the textual dataset, that we have curated for both the benchmark material databases, with the community for future use..",
        "bibtex": "@InProceedings{pmlr-v216-das23a,\n  title = \t {{CrysMMNet}: Multimodal Representation for Crystal Property Prediction},\n  author =       {Das, Kishalay and Goyal, Pawan and Lee, Seung-Cheol and Bhattacharjee, Satadeep and Ganguly, Niloy},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {507--517},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/das23a/das23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/das23a.html},\n  abstract = \t {Machine Learning models have emerged as a powerful tool for fast and accurate prediction of different crystalline properties. Exiting state-of-the-art models rely on a single modality of crystal data i.e crystal graph structure, where they construct multi-graph by establishing edges between nearby atoms in 3D space and apply GNN to learn materials representation. Thereby, they encode local chemical semantics around the atoms successfully but fail to capture important global periodic structural information like space group number, crystal symmetry, rotational information etc, which influence different crystal properties.  In this work, we leverage textual descriptions of materials to model global structural information into graph structure and learn a more robust and enriched representation of crystalline materials. To this effect, we first curate a textual dataset for crystalline material databases containing descriptions of each material. Further, we propose CrysMMNet, a simple multi-modal framework, which fuses both structural and textual representation together to generate a joint multimodal representation of crystalline materials. We conduct extensive experiments on two benchmark datasets across ten different properties to show that CrysMMNet outperforms existing state-of-the-art baseline methods with a good margin. We also observe that fusing the textual representation with crystal graph structure provides consistent improvement for all the SOTA GNN models compared to their own vanilla versions. We have shared the textual dataset, that we have curated for both the benchmark material databases, with the community for future use..}\n}",
        "pdf": "https://proceedings.mlr.press/v216/das23a/das23a.pdf",
        "supp": "",
        "pdf_size": 476420,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3966794793425053136&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Computer Science & Engineering, Indian Institute of Technology, Kharagpur, India; Department of Computer Science & Engineering, Indian Institute of Technology, Kharagpur, India; Indo Korea Science and Technology Center, Bangalore, India; Indo Korea Science and Technology Center, Bangalore, India; Department of Computer Science & Engineering, Indian Institute of Technology, Kharagpur, India",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Indian Institute of Technology Kharagpur;Indo Korea Science and Technology Center",
        "aff_unique_dep": "Department of Computer Science & Engineering;",
        "aff_unique_url": "https://www.iitkgp.ac.in;",
        "aff_unique_abbr": "IIT Kharagpur;",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Kharagpur;Bangalore",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "a9f8d95d09",
        "title": "Deep Gaussian mixture ensembles",
        "site": "https://proceedings.mlr.press/v216/el-laham23a.html",
        "author": "Yousef El-Laham; Niccolo Dalmasso; Elizabeth Fons; Svitlana Vyetrenko",
        "abstract": "This work introduces a novel probabilistic deep learning technique called deep Gaussian mixture ensembles (DGMEs), which enables accurate quantification of both epistemic and aleatoric uncertainty. By assuming the data generating process follows that of a Gaussian mixture, DGMEs are capable of approximating complex probability distributions, such as heavy-tailed or multimodal distributions. Our contributions include the derivation of an expectation-maximization (EM) algorithm used for learning the model parameters, which results in an upper-bound on the log-likelihood of training data over that of standard deep ensembles.  Additionally, the proposed EM training procedure allows for learning of mixture weights, which is not commonly done in ensembles. Our experimental results demonstrate that DGMEs outperform state-of-the-art uncertainty quantifying deep learning models in handling complex predictive densities.",
        "bibtex": "@InProceedings{pmlr-v216-el-laham23a,\n  title = \t {Deep {G}aussian mixture ensembles},\n  author =       {El-Laham, Yousef and Dalmasso, Niccolo and Fons, Elizabeth and Vyetrenko, Svitlana},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {549--559},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/el-laham23a/el-laham23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/el-laham23a.html},\n  abstract = \t {This work introduces a novel probabilistic deep learning technique called deep Gaussian mixture ensembles (DGMEs), which enables accurate quantification of both epistemic and aleatoric uncertainty. By assuming the data generating process follows that of a Gaussian mixture, DGMEs are capable of approximating complex probability distributions, such as heavy-tailed or multimodal distributions. Our contributions include the derivation of an expectation-maximization (EM) algorithm used for learning the model parameters, which results in an upper-bound on the log-likelihood of training data over that of standard deep ensembles.  Additionally, the proposed EM training procedure allows for learning of mixture weights, which is not commonly done in ensembles. Our experimental results demonstrate that DGMEs outperform state-of-the-art uncertainty quantifying deep learning models in handling complex predictive densities.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/el-laham23a/el-laham23a.pdf",
        "supp": "",
        "pdf_size": 1198901,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14301634166226617900&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7a28428b04",
        "title": "DeepGD3: Unknown-Aware Deep Generative/Discriminative Hybrid Defect Detector for PCB Soldering Inspection",
        "site": "https://proceedings.mlr.press/v216/ma23a.html",
        "author": "Ching-Wen Ma; Yanwei Liu",
        "abstract": "We present a novel approach for detecting soldering defects in Printed Circuit Boards (PCBs) composed mainly of Surface Mount Technology (SMT) components, using advanced computer vision and deep learning techniques. The main challenge addressed is the detection of soldering defects in new components for which only samples of good soldering are available at the model training phase. To address this, we design a system composed of generative and discriminative models to leverage the knowledge gained from the soldering samples of old components to detect the soldering defects of new components. To meet industrial quality standards, we keep the leakage rate (i.e., miss detection rate) low by making the system \"unknown-aware\" with a low unknown rate. We evaluated the method on a real-world dataset from an electronics company. It significantly reduces the leakage rate from 1.827% $\\pm$ 3.063% and 1.942% $\\pm$ 1.337% to 0.063% $\\pm$ 0.075% with an unknown rate of 3.706% $\\pm$ 2.270% compared to the discriminative and generative approaches, respectively.",
        "bibtex": "@InProceedings{pmlr-v216-ma23a,\n  title = \t {{DeepGD3}: Unknown-Aware Deep Generative/Discriminative Hybrid Defect Detector for {PCB} Soldering Inspection},\n  author =       {Ma, Ching-Wen and Lui, Yanwei},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1326--1335},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/ma23a/ma23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/ma23a.html},\n  abstract = \t {We present a novel approach for detecting soldering defects in Printed Circuit Boards (PCBs) composed mainly of Surface Mount Technology (SMT) components, using advanced computer vision and deep learning techniques. The main challenge addressed is the detection of soldering defects in new components for which only samples of good soldering are available at the model training phase. To address this, we design a system composed of generative and discriminative models to leverage the knowledge gained from the soldering samples of old components to detect the soldering defects of new components. To meet industrial quality standards, we keep the leakage rate (i.e., miss detection rate) low by making the system \"unknown-aware\" with a low unknown rate. We evaluated the method on a real-world dataset from an electronics company. It significantly reduces the leakage rate from 1.827% $\\pm$ 3.063% and 1.942% $\\pm$ 1.337% to 0.063% $\\pm$ 0.075% with an unknown rate of 3.706% $\\pm$ 2.270% compared to the discriminative and generative approaches, respectively.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/ma23a/ma23a.pdf",
        "supp": "",
        "pdf_size": 6701292,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:iYKxhsSYeFQJ:scholar.google.com/&scioq=DeepGD3:+Unknown-Aware+Deep+Generative/Discriminative+Hybrid+Defect+Detector+for+PCB+Soldering+Inspection&hl=en&as_sdt=0,5",
        "gs_version_total": 7,
        "aff": "College of Artificial Intelligence, National Yang Ming Chiao Tung University, Tainan, Taiwan; College of Artificial Intelligence, National Yang Ming Chiao Tung University, Tainan, Taiwan",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National Yang Ming Chiao Tung University",
        "aff_unique_dep": "College of Artificial Intelligence",
        "aff_unique_url": "https://www.nycu.edu.tw",
        "aff_unique_abbr": "NYCU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "ba15b13bf4",
        "title": "Detection of Short-Term Temporal Dependencies in Hawkes Processes with Heterogeneous Background Dynamics",
        "site": "https://proceedings.mlr.press/v216/chen23g.html",
        "author": "Yu Chen; Fengpei Li; Anderson Schneider; Yuriy Nevmyvaka; Asohan Amarasingham; Henry Lam",
        "abstract": "Many kinds of simultaneously-observed",
        "bibtex": "@InProceedings{pmlr-v216-chen23g,\n  title = \t {Detection of Short-Term Temporal Dependencies in {H}awkes Processes with Heterogeneous Background Dynamics},\n  author =       {Chen, Yu and Li, Fengpei and Schneider, Anderson and Nevmyvaka, Yuriy and Amarasingham, Asohan and Lam, Henry},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {369--380},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/chen23g/chen23g.pdf},\n  url = \t {https://proceedings.mlr.press/v216/chen23g.html},\n  abstract = \t {Many kinds of simultaneously-observed",
        "pdf": "https://proceedings.mlr.press/v216/chen23g/chen23g.pdf",
        "supp": "",
        "pdf_size": 872469,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:yhPx0AFUxtYJ:scholar.google.com/&scioq=Detection+of+Short-Term+Temporal+Dependencies+in+Hawkes+Processes+with+Heterogeneous+Background+Dynamics&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ea453974f2",
        "title": "Differentiable user models",
        "site": "https://proceedings.mlr.press/v216/hamalainen23a.html",
        "author": "Alex H\u00e4m\u00e4l\u00e4inen; Mustafa Mert \u00c7elikok; Samuel Kaski",
        "abstract": "Probabilistic user modeling is essential for building machine learning systems in the ubiquitous cases with humans in the loop. However, modern advanced user models, often designed as cognitive behavior simulators, are incompatible with modern machine learning pipelines and computationally prohibitive for most practical applications. We address this problem by introducing widely-applicable differentiable surrogates for bypassing this computational bottleneck; the surrogates enable computationally efficient inference with modern cognitive models. We show experimentally that modeling capabilities comparable to the only available solution, existing likelihood-free inference methods, are achievable with a computational cost suitable for online applications. Finally, we demonstrate how AI-assistants can now use cognitive models for online interaction in a menu-search task, which has so far required hours of computation during interaction.",
        "bibtex": "@InProceedings{pmlr-v216-hamalainen23a,\n  title = \t {Differentiable user models},\n  author =       {H\\\"{a}m\\\"{a}l\\\"{a}inen, Alex and \\c{C}elikok, Mustafa Mert and Kaski, Samuel},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {798--808},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/hamalainen23a/hamalainen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/hamalainen23a.html},\n  abstract = \t {Probabilistic user modeling is essential for building machine learning systems in the ubiquitous cases with humans in the loop. However, modern advanced user models, often designed as cognitive behavior simulators, are incompatible with modern machine learning pipelines and computationally prohibitive for most practical applications. We address this problem by introducing widely-applicable differentiable surrogates for bypassing this computational bottleneck; the surrogates enable computationally efficient inference with modern cognitive models. We show experimentally that modeling capabilities comparable to the only available solution, existing likelihood-free inference methods, are achievable with a computational cost suitable for online applications. Finally, we demonstrate how AI-assistants can now use cognitive models for online interaction in a menu-search task, which has so far required hours of computation during interaction.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/hamalainen23a/hamalainen23a.pdf",
        "supp": "",
        "pdf_size": 274518,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17554484353552998139&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": "Department of Computer Science, Aalto University; Department of Computer Science, Aalto University; Department of Computer Science, Aalto University+Department of Computer Science, University of Manchester",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "Aalto University;University of Manchester",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.aalto.fi;https://www.manchester.ac.uk",
        "aff_unique_abbr": "Aalto;UoM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+1",
        "aff_country_unique": "Finland;United Kingdom"
    },
    {
        "id": "738125f2a2",
        "title": "Differential Privacy in Cooperative Multiagent Planning",
        "site": "https://proceedings.mlr.press/v216/chen23e.html",
        "author": "Bo Chen; Calvin Hawkins; Mustafa O. Karabag; Cyrus Neary; Matthew Hale; Ufuk Topcu",
        "abstract": "Privacy-aware multiagent systems must protect agents\u2019 sensitive data while simultaneously ensuring that agents accomplish their shared objectives. Towards this goal, we propose a framework to privatize inter-agent communications in cooperative multiagent decision-making problems. We study sequential decision-making problems formulated as cooperative Markov games with reach-avoid objectives. We apply a differential privacy mechanism to privatize agents\u2019 communicated symbolic state trajectories, and analyze tradeoffs between the strength of privacy and the team\u2019s performance. For a given level of privacy, this tradeoff is shown to depend critically upon the total correlation among agents\u2019 state-action processes. We synthesize policies that are robust to privacy by reducing the value of the total correlation. Numerical experiments demonstrate that the team\u2019s performance under these policies decreases by only 6 percent when comparing private versus non-private implementations of communication. By contrast, the team\u2019s performance decreases by 88 percent when using baseline policies that ignore total correlation and only optimize team performance.",
        "bibtex": "@InProceedings{pmlr-v216-chen23e,\n  title = \t {Differential Privacy in Cooperative Multiagent Planning},\n  author =       {Chen, Bo and Hawkins, Calvin and Karabag, Mustafa O. and Neary, Cyrus and Hale, Matthew and Topcu, Ufuk},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {347--357},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/chen23e/chen23e.pdf},\n  url = \t {https://proceedings.mlr.press/v216/chen23e.html},\n  abstract = \t {Privacy-aware multiagent systems must protect agents\u2019 sensitive data while simultaneously ensuring that agents accomplish their shared objectives. Towards this goal, we propose a framework to privatize inter-agent communications in cooperative multiagent decision-making problems. We study sequential decision-making problems formulated as cooperative Markov games with reach-avoid objectives. We apply a differential privacy mechanism to privatize agents\u2019 communicated symbolic state trajectories, and analyze tradeoffs between the strength of privacy and the team\u2019s performance. For a given level of privacy, this tradeoff is shown to depend critically upon the total correlation among agents\u2019 state-action processes. We synthesize policies that are robust to privacy by reducing the value of the total correlation. Numerical experiments demonstrate that the team\u2019s performance under these policies decreases by only 6 percent when comparing private versus non-private implementations of communication. By contrast, the team\u2019s performance decreases by 88 percent when using baseline policies that ignore total correlation and only optimize team performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/chen23e/chen23e.pdf",
        "supp": "",
        "pdf_size": 357737,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9181474917476585859&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "The University of Florida; The University of Florida; The University of Texas at Austin; The University of Texas at Austin; The University of Florida; The University of Texas at Austin",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;1;0;1",
        "aff_unique_norm": "University of Florida;University of Texas at Austin",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ufl.edu;https://www.utexas.edu",
        "aff_unique_abbr": "UF;UT Austin",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9aba8d06fb",
        "title": "Differentially Private Stochastic Convex Optimization in (Non)-Euclidean Space Revisited",
        "site": "https://proceedings.mlr.press/v216/su23b.html",
        "author": "Jinyan Su; Changhong Zhao; Di Wang",
        "abstract": "In this paper, we revisit the problem of Differentially Private Stochastic Convex Optimization (DP-SCO) in Euclidean and general $\\ell_p^d$ spaces. Specifically, we focus on three settings that are still far from well understood:  (1) DP-SCO over a  constrained and bounded (convex) set in Euclidean space; (2) unconstrained DP-SCO in $\\ell_p^d$ space; (3) DP-SCO with heavy-tailed data over a  constrained and bounded set in $\\ell_p^d$ space. For problem (1), for both convex and strongly convex loss functions, we propose methods whose outputs could achieve (expected) excess population risks that are only dependent on the Gaussian width of the constraint set,  rather than the dimension of the space. Moreover, we also show the bound for strongly convex functions is optimal up to a logarithmic factor. For problems (2) and (3), we propose several novel  algorithms and provide the first theoretical results for both cases when $1",
        "bibtex": "@InProceedings{pmlr-v216-su23b,\n  title = \t {Differentially Private Stochastic Convex Optimization in (Non)-{E}uclidean Space Revisited},\n  author =       {Su, Jinyan and Zhao, Changhong and Wang, Di},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2026--2035},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/su23b/su23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/su23b.html},\n  abstract = \t {In this paper, we revisit the problem of Differentially Private Stochastic Convex Optimization (DP-SCO) in Euclidean and general $\\ell_p^d$ spaces. Specifically, we focus on three settings that are still far from well understood:  (1) DP-SCO over a  constrained and bounded (convex) set in Euclidean space; (2) unconstrained DP-SCO in $\\ell_p^d$ space; (3) DP-SCO with heavy-tailed data over a  constrained and bounded set in $\\ell_p^d$ space. For problem (1), for both convex and strongly convex loss functions, we propose methods whose outputs could achieve (expected) excess population risks that are only dependent on the Gaussian width of the constraint set,  rather than the dimension of the space. Moreover, we also show the bound for strongly convex functions is optimal up to a logarithmic factor. For problems (2) and (3), we propose several novel  algorithms and provide the first theoretical results for both cases when $1",
        "pdf": "https://proceedings.mlr.press/v216/su23b/su23b.pdf",
        "supp": "",
        "pdf_size": 356614,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5302775588532497455&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "dad1b78e69",
        "title": "Differentially private synthetic data using KD-trees",
        "site": "https://proceedings.mlr.press/v216/kreacic23a.html",
        "author": "Eleonora Krea\u010di\u0107; Navid Nouri; Vamsi K. Potluru; Tucker Balch; Manuela Veloso",
        "abstract": "Creation of a synthetic dataset that faithfully represents the data distribution and simultaneously preserves privacy is a major research challenge. Many space partitioning based approaches have emerged in recent years for answering statistical queries in a differentially private manner. However, for synthetic data generation problem, recent research has been mainly focused on deep generative models. In contrast, we exploit space partitioning techniques together with noise perturbation and thus achieve intuitive and transparent algorithms. We propose both data independent and data dependent algorithms for $\\epsilon$-differentially private synthetic data generation whose kernel density resembles that of the real dataset. Additionally, we provide theoretical results on the utility-privacy trade-offs and show how our data dependent approach overcomes the curse of dimensionality and leads to a scalable algorithm. We show empirical utility improvements over the prior work, and discuss performance of our algorithm on a downstream classification task on a real dataset.",
        "bibtex": "@InProceedings{pmlr-v216-kreacic23a,\n  title = \t {Differentially private synthetic data using {KD}-trees},\n  author =       {Krea\\v{c}i\\'{c}, Eleonora and Nouri, Navid and Potluru, Vamsi K. and Balch, Tucker and Veloso, Manuela},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1143--1153},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/kreacic23a/kreacic23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/kreacic23a.html},\n  abstract = \t {Creation of a synthetic dataset that faithfully represents the data distribution and simultaneously preserves privacy is a major research challenge. Many space partitioning based approaches have emerged in recent years for answering statistical queries in a differentially private manner. However, for synthetic data generation problem, recent research has been mainly focused on deep generative models. In contrast, we exploit space partitioning techniques together with noise perturbation and thus achieve intuitive and transparent algorithms. We propose both data independent and data dependent algorithms for $\\epsilon$-differentially private synthetic data generation whose kernel density resembles that of the real dataset. Additionally, we provide theoretical results on the utility-privacy trade-offs and show how our data dependent approach overcomes the curse of dimensionality and leads to a scalable algorithm. We show empirical utility improvements over the prior work, and discuss performance of our algorithm on a downstream classification task on a real dataset.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/kreacic23a/kreacic23a.pdf",
        "supp": "",
        "pdf_size": 474626,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6595856747164587473&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "J.P. Morgan AI Research; J.P. Morgan AI Research; J.P. Morgan AI Research; J.P. Morgan AI Research; J.P. Morgan AI Research",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "J.P. Morgan",
        "aff_unique_dep": "AI Research",
        "aff_unique_url": "https://www.jpmorgan.com",
        "aff_unique_abbr": "JPM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b84c6a3cde",
        "title": "Dirichlet Proportions Model for Hierarchically Coherent Probabilistic Forecasting",
        "site": "https://proceedings.mlr.press/v216/das23b.html",
        "author": "A. Das; W. Kong; B. Paria; R. Sen",
        "abstract": "Probabilistic, hierarchically coherent forecasting is a key problem in many practical forecasting applications \u2013 the goal is to obtain coherent probabilistic predictions for a large number of  time series  arranged in a pre-specified tree hierarchy.  In this paper, we present an end-to-end deep  probabilistic model for hierarchical forecasting that is motivated by a classical top-down strategy. It jointly learns the distribution of the root time series, and the (dirichlet) proportions according to which each parent time-series is split among its children at any point in time. The resulting forecasts are naturally coherent, and provide probabilistic predictions over all time series in the hierarchy. We experiment on several public datasets and demonstrate significant improvements of up to 26% on most datasets compared to state-of-the-art baselines. Finally, we also provide theoretical justification for the superiority of our top-down approach compared to the more traditional bottom-up modeling.",
        "bibtex": "@InProceedings{pmlr-v216-das23b,\n  title = \t {Dirichlet Proportions Model for Hierarchically Coherent Probabilistic Forecasting},\n  author =       {Das, A. and Kong, W. and Paria, B. and Sen, R.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {518--528},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/das23b/das23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/das23b.html},\n  abstract = \t {Probabilistic, hierarchically coherent forecasting is a key problem in many practical forecasting applications \u2013 the goal is to obtain coherent probabilistic predictions for a large number of  time series  arranged in a pre-specified tree hierarchy.  In this paper, we present an end-to-end deep  probabilistic model for hierarchical forecasting that is motivated by a classical top-down strategy. It jointly learns the distribution of the root time series, and the (dirichlet) proportions according to which each parent time-series is split among its children at any point in time. The resulting forecasts are naturally coherent, and provide probabilistic predictions over all time series in the hierarchy. We experiment on several public datasets and demonstrate significant improvements of up to 26% on most datasets compared to state-of-the-art baselines. Finally, we also provide theoretical justification for the superiority of our top-down approach compared to the more traditional bottom-up modeling.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/das23b/das23b.pdf",
        "supp": "",
        "pdf_size": 776016,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8849551229290433339&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f52334184b",
        "title": "Diversity-enhanced probabilistic ensemble for uncertainty estimation",
        "site": "https://proceedings.mlr.press/v216/wang23c.html",
        "author": "Hanjing Wang; Qiang Ji",
        "abstract": "Ensemble methods combine multiple individual models for prediction, which have demonstrated their effectiveness in accurate uncertainty quantification (UQ) and strong robustness. Obtaining a diverse ensemble set of model parameters results in better model averaging performance and better approximation of the true posterior distribution of these parameters. In this paper, we propose the diversity-enhanced probabilistic ensemble method with the adaptive uncertainty-guided ensemble learning strategy for better quantifying uncertainty and further improving the model robustness. Specifically, we construct the probabilistic ensemble model by building a Gaussian distribution of the model parameters for each ensemble component using Laplacian approximation in a post-processing manner. Then a mixture of Gaussian model is established with learnable and refinable parameters in an EM-like algorithm. During ensemble training, we leverage the uncertainty estimated from previous models as guidance when training the next one such that the new model will focus more on the less explored regions by previous models. Various experiments including out-of-distribution detection and image classification under distributional shifts have demonstrated better uncertainty estimation and improved model generalization ability of our proposed method.",
        "bibtex": "@InProceedings{pmlr-v216-wang23c,\n  title = \t {Diversity-enhanced probabilistic ensemble for uncertainty estimation},\n  author =       {Wang, Hanjing and Ji, Qiang},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2214--2225},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/wang23c/wang23c.pdf},\n  url = \t {https://proceedings.mlr.press/v216/wang23c.html},\n  abstract = \t {Ensemble methods combine multiple individual models for prediction, which have demonstrated their effectiveness in accurate uncertainty quantification (UQ) and strong robustness. Obtaining a diverse ensemble set of model parameters results in better model averaging performance and better approximation of the true posterior distribution of these parameters. In this paper, we propose the diversity-enhanced probabilistic ensemble method with the adaptive uncertainty-guided ensemble learning strategy for better quantifying uncertainty and further improving the model robustness. Specifically, we construct the probabilistic ensemble model by building a Gaussian distribution of the model parameters for each ensemble component using Laplacian approximation in a post-processing manner. Then a mixture of Gaussian model is established with learnable and refinable parameters in an EM-like algorithm. During ensemble training, we leverage the uncertainty estimated from previous models as guidance when training the next one such that the new model will focus more on the less explored regions by previous models. Various experiments including out-of-distribution detection and image classification under distributional shifts have demonstrated better uncertainty estimation and improved model generalization ability of our proposed method.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/wang23c/wang23c.pdf",
        "supp": "",
        "pdf_size": 533643,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3805694696586680275&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "ECSE, Rensselaer Polytechnic Institute, Troy, New York, USA; ECSE, Rensselaer Polytechnic Institute, Troy, New York, USA",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rensselaer Polytechnic Institute",
        "aff_unique_dep": "ECSE",
        "aff_unique_url": "https://www.rpi.edu",
        "aff_unique_abbr": "RPI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Troy",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "e8b9176baa",
        "title": "Do we become wiser with time? On causal equivalence with tiered background knowledge",
        "site": "https://proceedings.mlr.press/v216/bang23a.html",
        "author": "Christine W. Bang; Vanessa Didelez",
        "abstract": "Equivalence classes of DAGs (represented by CPDAGs) may be too large to provide useful causal information. Here, we address incorporating tiered background knowledge yielding restricted equivalence classes represented by \u2018tiered MPDAGs\u2019. Tiered knowledge leads to considerable gains in informativeness and computational efficiency: We show that construction of tiered MPDAGs only requires application of Meeks 1st rule, and that tiered MPDAGs (unlike general MPDAGs) are chain graphs with chordal components. This entails simplifications e.g. of determining valid adjustment sets for causal effect estimation. Further, we characterise when one tiered ordering is more informative than another, providing insights into useful aspects of background knowledge.",
        "bibtex": "@InProceedings{pmlr-v216-bang23a,\n  title = \t {Do we become wiser with time? {O}n causal equivalence with tiered background knowledge},\n  author =       {Bang, Christine W. and Didelez, Vanessa},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {119--129},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/bang23a/bang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/bang23a.html},\n  abstract = \t {Equivalence classes of DAGs (represented by CPDAGs) may be too large to provide useful causal information. Here, we address incorporating tiered background knowledge yielding restricted equivalence classes represented by \u2018tiered MPDAGs\u2019. Tiered knowledge leads to considerable gains in informativeness and computational efficiency: We show that construction of tiered MPDAGs only requires application of Meeks 1st rule, and that tiered MPDAGs (unlike general MPDAGs) are chain graphs with chordal components. This entails simplifications e.g. of determining valid adjustment sets for causal effect estimation. Further, we characterise when one tiered ordering is more informative than another, providing insights into useful aspects of background knowledge.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/bang23a/bang23a.pdf",
        "supp": "",
        "pdf_size": 242744,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10958454848158755386&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Faculty of Mathematics and Computer Science, University of Bremen, Bremen, Germany+Leibniz Institute for Prevention Research and Epidemiology \u2013 BIPS, Bremen, Germany; Faculty of Mathematics and Computer Science, University of Bremen, Bremen, Germany+Leibniz Institute for Prevention Research and Epidemiology \u2013 BIPS, Bremen, Germany",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1",
        "aff_unique_norm": "University of Bremen;Leibniz Institute for Prevention Research and Epidemiology \u2013 BIPS",
        "aff_unique_dep": "Faculty of Mathematics and Computer Science;",
        "aff_unique_url": "https://www.uni-bremen.de;https://bips.de",
        "aff_unique_abbr": ";BIPS",
        "aff_campus_unique_index": "0+0;0+0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "6ae08e9e39",
        "title": "Does Momentum Help in Stochastic Optimization? A Sample Complexity Analysis.",
        "site": "https://proceedings.mlr.press/v216/ganesh23a.html",
        "author": "Swetha Ganesh; Rohan Deb; Gugan Thoppe; Amarjit Budhiraja",
        "abstract": "Stochastic Heavy Ball (SHB) and Nesterov\u2019s Accelerated Stochastic Gradient (ASG) are popular momentum methods in optimization. While the benefits of these acceleration ideas in deterministic settings are well understood, their advantages in stochastic optimization are unclear. Several works have recently claimed that SHB and ASG always help in stochastic optimization. Our work shows that i.) these claims are either flawed or one-sided (e.g., consider only the bias term but not the variance), and ii.) when both these terms are accounted for, SHB and ASG do not always help. Specifically, for",
        "bibtex": "@InProceedings{pmlr-v216-ganesh23a,\n  title = \t {Does Momentum Help in Stochastic Optimization? {A} Sample Complexity Analysis.},\n  author =       {Ganesh, Swetha and Deb, Rohan and Thoppe, Gugan and Budhiraja, Amarjit},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {602--612},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/ganesh23a/ganesh23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/ganesh23a.html},\n  abstract = \t {Stochastic Heavy Ball (SHB) and Nesterov\u2019s Accelerated Stochastic Gradient (ASG) are popular momentum methods in optimization. While the benefits of these acceleration ideas in deterministic settings are well understood, their advantages in stochastic optimization are unclear. Several works have recently claimed that SHB and ASG always help in stochastic optimization. Our work shows that i.) these claims are either flawed or one-sided (e.g., consider only the bias term but not the variance), and ii.) when both these terms are accounted for, SHB and ASG do not always help. Specifically, for",
        "pdf": "https://proceedings.mlr.press/v216/ganesh23a/ganesh23a.pdf",
        "supp": "",
        "pdf_size": 886191,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14664581245054857527&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b9422b7561",
        "title": "Efficient Failure Pattern Identification of Predictive Algorithms",
        "site": "https://proceedings.mlr.press/v216/nguyen23c.html",
        "author": "Bao Nguyen; Viet Anh Nguyen",
        "abstract": "Given a (machine learning) classifier and a collection of unlabeled data, how can we efficiently identify misclassification patterns presented in this dataset? To address this problem, we propose a human-machine collaborative framework that consists of a team of human annotators and a sequential recommendation algorithm. The recommendation algorithm is conceptualized as a stochastic sampler that, in each round, queries the annotators a subset of samples for their true labels and obtains the feedback information on whether the samples are misclassified. The sampling mechanism needs to balance between discovering new patterns of misclassification (exploration) and confirming the potential patterns of classification (exploitation). We construct a determinantal point process, whose intensity balances the exploration-exploitation trade-off through the weighted update of the posterior at each round to form the generator of the stochastic sampler. The numerical results empirically demonstrate the competitive performance of our framework on multiple datasets at various signal-to-noise ratios.",
        "bibtex": "@InProceedings{pmlr-v216-nguyen23c,\n  title = \t {Efficient Failure Pattern Identification of Predictive Algorithms},\n  author =       {Nguyen, Bao and Nguyen, Viet Anh},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1534--1544},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/nguyen23c/nguyen23c.pdf},\n  url = \t {https://proceedings.mlr.press/v216/nguyen23c.html},\n  abstract = \t {Given a (machine learning) classifier and a collection of unlabeled data, how can we efficiently identify misclassification patterns presented in this dataset? To address this problem, we propose a human-machine collaborative framework that consists of a team of human annotators and a sequential recommendation algorithm. The recommendation algorithm is conceptualized as a stochastic sampler that, in each round, queries the annotators a subset of samples for their true labels and obtains the feedback information on whether the samples are misclassified. The sampling mechanism needs to balance between discovering new patterns of misclassification (exploration) and confirming the potential patterns of classification (exploitation). We construct a determinantal point process, whose intensity balances the exploration-exploitation trade-off through the weighted update of the posterior at each round to form the generator of the stochastic sampler. The numerical results empirically demonstrate the competitive performance of our framework on multiple datasets at various signal-to-noise ratios.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/nguyen23c/nguyen23c.pdf",
        "supp": "",
        "pdf_size": 513670,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:a6SpkS40C6kJ:scholar.google.com/&scioq=Efficient+Failure+Pattern+Identification+of+Predictive+Algorithms&hl=en&as_sdt=0,5",
        "gs_version_total": 10,
        "aff": "School of Information and Communication Technology, Hanoi University of Science and Technology, Vietnam+College of Engineering & Computer Science, VinUni-Illinois Smart Health Center, VinUniversity, Vietnam; The Chinese University of Hong Kong",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2",
        "aff_unique_norm": "Hanoi University of Science and Technology;VinUniversity;Chinese University of Hong Kong",
        "aff_unique_dep": "School of Information and Communication Technology;College of Engineering & Computer Science;",
        "aff_unique_url": "https://www.hust.edu.vn;;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "HUST;VinUni;CUHK",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Hanoi;;Hong Kong SAR",
        "aff_country_unique_index": "0+0;1",
        "aff_country_unique": "Vietnam;China"
    },
    {
        "id": "926e071f42",
        "title": "Efficient Learning of Minimax Risk Classifiers in High Dimensions",
        "site": "https://proceedings.mlr.press/v216/bondugula23a.html",
        "author": "Kartheek Bondugula; Santiago Mazuelas; Aritz P\u00e9rez",
        "abstract": "High-dimensional data is common in multiple areas, such as health care and genomics, where the number of features can be tens of thousands. In such scenarios, the large number of features often leads to inefficient learning. Constraint generation methods have recently enabled efficient learning of L1-regularized support vector machines (SVMs). In this paper, we leverage such methods to obtain an efficient learning algorithm for the recently proposed minimax risk classifiers (MRCs). The proposed iterative algorithm also provides a sequence of worst-case error probabilities and performs feature selection. Experiments on multiple high-dimensional datasets show that the proposed algorithm is efficient in high-dimensional scenarios. In addition, the worst-case error probability provides useful information about the classifier performance, and the features selected by the algorithm are competitive with the state-of-the-art.",
        "bibtex": "@InProceedings{pmlr-v216-bondugula23a,\n  title = \t {Efficient Learning of Minimax Risk Classifiers in High Dimensions},\n  author =       {Bondugula, Kartheek and Mazuelas, Santiago and P\\'{e}rez, Aritz},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {206--215},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/bondugula23a/bondugula23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/bondugula23a.html},\n  abstract = \t {High-dimensional data is common in multiple areas, such as health care and genomics, where the number of features can be tens of thousands. In such scenarios, the large number of features often leads to inefficient learning. Constraint generation methods have recently enabled efficient learning of L1-regularized support vector machines (SVMs). In this paper, we leverage such methods to obtain an efficient learning algorithm for the recently proposed minimax risk classifiers (MRCs). The proposed iterative algorithm also provides a sequence of worst-case error probabilities and performs feature selection. Experiments on multiple high-dimensional datasets show that the proposed algorithm is efficient in high-dimensional scenarios. In addition, the worst-case error probability provides useful information about the classifier performance, and the features selected by the algorithm are competitive with the state-of-the-art.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/bondugula23a/bondugula23a.pdf",
        "supp": "",
        "pdf_size": 320251,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15802392348959555209&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "608c89b9be",
        "title": "Efficient Privacy-Preserving Stochastic Nonconvex Optimization",
        "site": "https://proceedings.mlr.press/v216/wang23b.html",
        "author": "Lingxiao Wang; Bargav Jayaraman; David Evans; Quanquan Gu",
        "abstract": "While many solutions for privacy-preserving convex empirical risk minimization (ERM) have been developed, privacy-preserving nonconvex ERM remains a challenge. We study nonconvex ERM, which takes the form of minimizing a finite-sum of nonconvex loss functions over a training set. We propose a new differentially private stochastic gradient descent algorithm for nonconvex ERM that achieves strong privacy guarantees efficiently, and provide a tight analysis of its privacy and utility guarantees, as well as its gradient complexity. Our algorithm reduces gradient complexity while matching the best-known utility guarantee. Our experiments on benchmark nonconvex ERM problems demonstrate superior performance in terms of both training cost and utility gains compared with previous differentially private methods using the same privacy budgets.",
        "bibtex": "@InProceedings{pmlr-v216-wang23b,\n  title = \t {Efficient Privacy-Preserving Stochastic Nonconvex Optimization},\n  author =       {Wang, Lingxiao and Jayaraman, Bargav and Evans, David and Gu, Quanquan},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2203--2213},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/wang23b/wang23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/wang23b.html},\n  abstract = \t {While many solutions for privacy-preserving convex empirical risk minimization (ERM) have been developed, privacy-preserving nonconvex ERM remains a challenge. We study nonconvex ERM, which takes the form of minimizing a finite-sum of nonconvex loss functions over a training set. We propose a new differentially private stochastic gradient descent algorithm for nonconvex ERM that achieves strong privacy guarantees efficiently, and provide a tight analysis of its privacy and utility guarantees, as well as its gradient complexity. Our algorithm reduces gradient complexity while matching the best-known utility guarantee. Our experiments on benchmark nonconvex ERM problems demonstrate superior performance in terms of both training cost and utility gains compared with previous differentially private methods using the same privacy budgets.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/wang23b/wang23b.pdf",
        "supp": "",
        "pdf_size": 564357,
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=643406841967423232&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "786b2d476e",
        "title": "Efficiently learning the graph for semi-supervised learning",
        "site": "https://proceedings.mlr.press/v216/sharma23a.html",
        "author": "Dravyansh Sharma; Maxwell Jones",
        "abstract": "Computational efficiency is a major bottleneck in using classic graph-based approaches for semi-supervised learning on datasets with a large number of unlabeled examples. Known techniques to improve efficiency typically involve an approximation of the graph regularization objective, but suffer two major drawbacks - first the graph is assumed to be known or constructed with heuristic hyperparameter values, second they do not provide a principled approximation guarantee for learning over the full unlabeled dataset. Building on recent work on learning graphs for semi-supervised learning from multiple datasets for problems from the same domain, and leveraging techniques for fast approximations for solving linear systems in the graph Laplacian matrix, we propose algorithms that overcome both the above limitations.  We show a formal separation in the learning-theoretic complexity of sparse and dense graph families. We further show how to approximately learn the best graphs from the sparse families efficiently using the conjugate gradient method. Our approach can also be used to learn the graph efficiently online with sub-linear regret, under mild smoothness assumptions. Our online learning results are stated generally, and may be useful for approximate and efficient parameter tuning in other problems. We implement our approach and demonstrate significant ($\\sim$10-100x) speedups over prior work on semi-supervised learning with learned graphs on benchmark datasets.",
        "bibtex": "@InProceedings{pmlr-v216-sharma23a,\n  title = \t {Efficiently learning the graph for semi-supervised learning},\n  author =       {Sharma, Dravyansh and Jones, Maxwell},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1900--1910},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/sharma23a/sharma23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/sharma23a.html},\n  abstract = \t {Computational efficiency is a major bottleneck in using classic graph-based approaches for semi-supervised learning on datasets with a large number of unlabeled examples. Known techniques to improve efficiency typically involve an approximation of the graph regularization objective, but suffer two major drawbacks - first the graph is assumed to be known or constructed with heuristic hyperparameter values, second they do not provide a principled approximation guarantee for learning over the full unlabeled dataset. Building on recent work on learning graphs for semi-supervised learning from multiple datasets for problems from the same domain, and leveraging techniques for fast approximations for solving linear systems in the graph Laplacian matrix, we propose algorithms that overcome both the above limitations.  We show a formal separation in the learning-theoretic complexity of sparse and dense graph families. We further show how to approximately learn the best graphs from the sparse families efficiently using the conjugate gradient method. Our approach can also be used to learn the graph efficiently online with sub-linear regret, under mild smoothness assumptions. Our online learning results are stated generally, and may be useful for approximate and efficient parameter tuning in other problems. We implement our approach and demonstrate significant ($\\sim$10-100x) speedups over prior work on semi-supervised learning with learned graphs on benchmark datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/sharma23a/sharma23a.pdf",
        "supp": "",
        "pdf_size": 481856,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14143784426267546912&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "School of Computer Science., Carnegie Mellon University, Pittsburgh, PA, 15213; School of Computer Science., Carnegie Mellon University, Pittsburgh, PA, 15213",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "23e5826e6c",
        "title": "Energy-based Predictive Representations for Partially Observed Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v216/zhang23b.html",
        "author": "Tianjun Zhang; Tongzheng Ren; Chenjun Xiao; Wenli Xiao; Joseph E. Gonzalez; Dale Schuurmans; Bo Dai",
        "abstract": "In real-world applications, handling partial observability is a common requirement for reinforcement learning algorithms, which is not captured by a Markov decision process (MDP). Although partially observable Markov decision processes (POMDPs) have been specifically designed to address this requirement, they present significant computational and statistical challenges in learning and planning. In this work, we introduce the",
        "bibtex": "@InProceedings{pmlr-v216-zhang23b,\n  title = \t {Energy-based Predictive Representations for Partially Observed Reinforcement Learning},\n  author =       {Zhang, Tianjun and Ren, Tongzheng and Xiao, Chenjun and Xiao, Wenli and Gonzalez, Joseph E. and Schuurmans, Dale and Dai, Bo},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2477--2487},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zhang23b/zhang23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zhang23b.html},\n  abstract = \t {In real-world applications, handling partial observability is a common requirement for reinforcement learning algorithms, which is not captured by a Markov decision process (MDP). Although partially observable Markov decision processes (POMDPs) have been specifically designed to address this requirement, they present significant computational and statistical challenges in learning and planning. In this work, we introduce the",
        "pdf": "https://proceedings.mlr.press/v216/zhang23b/zhang23b.pdf",
        "supp": "",
        "pdf_size": 567870,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14836524945964836421&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fdef753025",
        "title": "Enhancing Treatment Effect Estimation: A Model Robust Approach Integrating Randomized Experiments and External Controls using the Double Penalty Integration Estimator",
        "site": "https://proceedings.mlr.press/v216/cheng23a.html",
        "author": "Yuwen Cheng; Lili Wu; Shu Yang",
        "abstract": "Randomized experiments (REs) are the cornerstone for treatment effect evaluation. However, due to practical considerations, REs may encounter difficulty recruiting sufficient patients. External controls (ECs) can supplement REs to boost estimation efficiency. Yet, there may be incomparability between ECs and concurrent controls (CCs), resulting in misleading treatment effect evaluation. We introduce a novel bias function to measure the difference in the outcome mean functions between ECs and CCs. We show that the ANCOVA model augmented by the bias function for ECs renders a consistent estimator of the average treatment effect, regardless of whether or not the ANCOVA model is correct.  To accommodate possibly different structures of the ANCOVA model and the bias function, we propose a double penalty integration estimator (DPIE) with different penalization terms for the two functions. With an appropriate choice of penalty parameters, our DPIE ensures consistency, oracle property, and asymptotic normality even in the presence of model misspecification. DPIE is at least as efficient as the estimator derived from REs alone, validated through theoretical and experimental results.",
        "bibtex": "@InProceedings{pmlr-v216-cheng23a,\n  title = \t {Enhancing Treatment Effect Estimation: A Model Robust Approach Integrating Randomized Experiments and External Controls using the Double Penalty Integration Estimator},\n  author =       {Cheng, Yuwen and Wu, Lili and Yang, Shu},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {381--390},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/cheng23a/cheng23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/cheng23a.html},\n  abstract = \t {Randomized experiments (REs) are the cornerstone for treatment effect evaluation. However, due to practical considerations, REs may encounter difficulty recruiting sufficient patients. External controls (ECs) can supplement REs to boost estimation efficiency. Yet, there may be incomparability between ECs and concurrent controls (CCs), resulting in misleading treatment effect evaluation. We introduce a novel bias function to measure the difference in the outcome mean functions between ECs and CCs. We show that the ANCOVA model augmented by the bias function for ECs renders a consistent estimator of the average treatment effect, regardless of whether or not the ANCOVA model is correct.  To accommodate possibly different structures of the ANCOVA model and the bias function, we propose a double penalty integration estimator (DPIE) with different penalization terms for the two functions. With an appropriate choice of penalty parameters, our DPIE ensures consistency, oracle property, and asymptotic normality even in the presence of model misspecification. DPIE is at least as efficient as the estimator derived from REs alone, validated through theoretical and experimental results.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/cheng23a/cheng23a.pdf",
        "supp": "",
        "pdf_size": 337487,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16244349297197584304&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c23a4aee15",
        "title": "Establishing Markov equivalence in cyclic directed graphs",
        "site": "https://proceedings.mlr.press/v216/claassen23a.html",
        "author": "Tom Claassen; Joris M. Mooij",
        "abstract": "We present a new, efficient procedure to establish Markov equivalence between directed graphs that may or may not contain cycles. It is based on the Cyclic Equivalence Theorem (CET) in the seminal works on cyclic models by Thomas Richardson in the mid \u201990s, but now rephrased from an ancestral perspective. The resulting characterization leads to a procedure for establishing Markov equivalence between graphs that no longer requires explicit tests for $d$-separation, leading to a significantly reduced algorithmic complexity. The conceptually simplified characterization may help to reinvigorate theoretical research towards sound and complete cyclic discovery in the presence of latent confounders.",
        "bibtex": "@InProceedings{pmlr-v216-claassen23a,\n  title = \t {Establishing {M}arkov equivalence in cyclic directed graphs},\n  author =       {Claassen, Tom and Mooij, Joris M.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {433--442},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/claassen23a/claassen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/claassen23a.html},\n  abstract = \t {We present a new, efficient procedure to establish Markov equivalence between directed graphs that may or may not contain cycles. It is based on the Cyclic Equivalence Theorem (CET) in the seminal works on cyclic models by Thomas Richardson in the mid \u201990s, but now rephrased from an ancestral perspective. The resulting characterization leads to a procedure for establishing Markov equivalence between graphs that no longer requires explicit tests for $d$-separation, leading to a significantly reduced algorithmic complexity. The conceptually simplified characterization may help to reinvigorate theoretical research towards sound and complete cyclic discovery in the presence of latent confounders.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/claassen23a/claassen23a.pdf",
        "supp": "",
        "pdf_size": 502868,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14266191924399105775&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 14,
        "aff": "Institute for Computing and Information Sciences, Radboud University, Nijmegen, Netherlands; Korteweg-deVries Institute, University of Amsterdam, Amsterdam, Netherlands",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Radboud University;University of Amsterdam",
        "aff_unique_dep": "Institute for Computing and Information Sciences;Korteweg-deVries Institute",
        "aff_unique_url": "https://www.ru.nl;https://www.uva.nl",
        "aff_unique_abbr": "RU;UvA",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Nijmegen;Amsterdam",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "43533aa8ee",
        "title": "Exact Count of Boundary Pieces of ReLU Classifiers: Towards the Proper Complexity Measure for Classification",
        "site": "https://proceedings.mlr.press/v216/piwek23a.html",
        "author": "Pawe\u0142 Piwek; Adam Klukowski; Tianyang Hu",
        "abstract": "Classic learning theory suggests that proper regularization is the key to good generalization and robustness. In classification, current training schemes only target the complexity of the classifier itself, which can be misleading and ineffective. Instead, we advocate directly measuring the complexity of the decision boundary. Existing literature is limited in this area with few well-established definitions of boundary complexity. As a proof of concept, we start by analyzing ReLU neural networks, whose boundary complexity can be conveniently characterized by the number of affine pieces. With the help of tropical geometry, we develop a novel method that can explicitly count the exact number of boundary pieces, and as a by-product, the exact number of total affine pieces. Numerical experiments are conducted and distinctive properties of our boundary complexity are uncovered. First, the boundary piece count appears largely independent of other measures, e.g., total piece count, and $l_2$ norm of weights, during the training process. Second, the boundary piece count is negatively correlated with robustness, where popular robust training techniques, e.g., adversarial training or random noise injection, are found to reduce the number of boundary pieces.",
        "bibtex": "@InProceedings{pmlr-v216-piwek23a,\n  title = \t {Exact Count of Boundary Pieces of {ReLU} Classifiers: Towards the Proper Complexity Measure for Classification},\n  author =       {Piwek, Pawe\\l and Klukowski, Adam and Hu, Tianyang},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1673--1683},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/piwek23a/piwek23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/piwek23a.html},\n  abstract = \t {Classic learning theory suggests that proper regularization is the key to good generalization and robustness. In classification, current training schemes only target the complexity of the classifier itself, which can be misleading and ineffective. Instead, we advocate directly measuring the complexity of the decision boundary. Existing literature is limited in this area with few well-established definitions of boundary complexity. As a proof of concept, we start by analyzing ReLU neural networks, whose boundary complexity can be conveniently characterized by the number of affine pieces. With the help of tropical geometry, we develop a novel method that can explicitly count the exact number of boundary pieces, and as a by-product, the exact number of total affine pieces. Numerical experiments are conducted and distinctive properties of our boundary complexity are uncovered. First, the boundary piece count appears largely independent of other measures, e.g., total piece count, and $l_2$ norm of weights, during the training process. Second, the boundary piece count is negatively correlated with robustness, where popular robust training techniques, e.g., adversarial training or random noise injection, are found to reduce the number of boundary pieces.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/piwek23a/piwek23a.pdf",
        "supp": "",
        "pdf_size": 2205070,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=876520981108728497&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "University of Oxford; Huawei Noah\u2019s Ark Lab; Huawei Noah\u2019s Ark Lab",
        "aff_domain": "maths.ox.ac.uk; ;huawei.com",
        "email": "maths.ox.ac.uk; ;huawei.com",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Oxford;Huawei",
        "aff_unique_dep": ";Noah\u2019s Ark Lab",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.huawei.com",
        "aff_unique_abbr": "Oxford;Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "cf27081c63",
        "title": "Expectation consistency for calibration of neural networks",
        "site": "https://proceedings.mlr.press/v216/clarte23a.html",
        "author": "Lucas Clart\u00e9; Bruno Loureiro; Florent Krzakala; Lenka Zdeborov\u00e1",
        "abstract": "Despite their incredible performance, it is well reported that deep neural networks tend to be overoptimistic about their prediction confidence. Finding effective and efficient calibration methods for neural networks is therefore an important endeavour towards better uncertainty quantification in deep learning. In this manuscript, we introduce a novel calibration technique named expectation consistency (EC), consisting of a post-training rescaling of the last layer weights by enforcing that the average validation confidence coincides with the average proportion of correct labels. First, we show that the EC method achieves similar calibration performance to temperature scaling (TS) across different neural network architectures and data sets, all while requiring similar validation samples and computational resources. However, we argue that EC provides a principled method grounded on a Bayesian optimality principle known as the Nishimori identity. Next, we provide an asymptotic characterization of both TS and EC in a synthetic setting and show that their performance crucially depends on the target function. In particular, we discuss examples where EC significantly outperforms TS.",
        "bibtex": "@InProceedings{pmlr-v216-clarte23a,\n  title = \t {Expectation consistency for calibration of neural networks},\n  author =       {Clart\\'e, Lucas and Loureiro, Bruno and Krzakala, Florent and Zdeborov\\'a, Lenka},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {443--453},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/clarte23a/clarte23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/clarte23a.html},\n  abstract = \t {Despite their incredible performance, it is well reported that deep neural networks tend to be overoptimistic about their prediction confidence. Finding effective and efficient calibration methods for neural networks is therefore an important endeavour towards better uncertainty quantification in deep learning. In this manuscript, we introduce a novel calibration technique named expectation consistency (EC), consisting of a post-training rescaling of the last layer weights by enforcing that the average validation confidence coincides with the average proportion of correct labels. First, we show that the EC method achieves similar calibration performance to temperature scaling (TS) across different neural network architectures and data sets, all while requiring similar validation samples and computational resources. However, we argue that EC provides a principled method grounded on a Bayesian optimality principle known as the Nishimori identity. Next, we provide an asymptotic characterization of both TS and EC in a synthetic setting and show that their performance crucially depends on the target function. In particular, we discuss examples where EC significantly outperforms TS.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/clarte23a/clarte23a.pdf",
        "supp": "",
        "pdf_size": 413158,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1904583628121324947&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "682dbba0ce",
        "title": "Exploiting Inferential Structure in Neural Processes",
        "site": "https://proceedings.mlr.press/v216/tailor23a.html",
        "author": "Dharmesh Tailor; Mohammad Emtiyaz Khan; Eric Nalisnick",
        "abstract": "Neural Processes (NPs) are appealing due to their ability to perform fast adaptation based on a context set. This set is encoded by a latent variable, which is often assumed to follow a simple distribution. However, in real-word settings, the context set may be drawn from richer distributions having multiple modes, heavy tails, etc. In this work, we provide a framework that allows NPs\u2019 latent variable to be given a rich prior defined by a graphical model. These distributional assumptions directly translate into an appropriate aggregation strategy for the context set. Moreover, we describe a message-passing procedure that still allows for end-to-end optimization with stochastic gradients. We demonstrate the generality of our framework by using mixture and Student-t assumptions that yield improvements in function modelling and test-time robustness.",
        "bibtex": "@InProceedings{pmlr-v216-tailor23a,\n  title = \t {Exploiting Inferential Structure in Neural Processes},\n  author =       {Tailor, Dharmesh and Khan, Mohammad Emtiyaz and Nalisnick, Eric},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2089--2098},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/tailor23a/tailor23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/tailor23a.html},\n  abstract = \t {Neural Processes (NPs) are appealing due to their ability to perform fast adaptation based on a context set. This set is encoded by a latent variable, which is often assumed to follow a simple distribution. However, in real-word settings, the context set may be drawn from richer distributions having multiple modes, heavy tails, etc. In this work, we provide a framework that allows NPs\u2019 latent variable to be given a rich prior defined by a graphical model. These distributional assumptions directly translate into an appropriate aggregation strategy for the context set. Moreover, we describe a message-passing procedure that still allows for end-to-end optimization with stochastic gradients. We demonstrate the generality of our framework by using mixture and Student-t assumptions that yield improvements in function modelling and test-time robustness.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/tailor23a/tailor23a.pdf",
        "supp": "",
        "pdf_size": 644106,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7138614343807657020&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4c5b1ab640",
        "title": "Exploration for Free: How Does Reward Heterogeneity Improve Regret in Cooperative Multi-agent Bandits?",
        "site": "https://proceedings.mlr.press/v216/wang23a.html",
        "author": "Xuchuang Wang; Lin Yang; Yu-zhen Janice Chen; Xutong Liu; Mohammad Hajiesmaili; Don Towsley; John C.S. Lui",
        "abstract": "This paper studies a cooperative multi-agent bandit scenario in which the rewards observed by agents are heterogeneous\u2014one agent\u2019s meat can be another agent\u2019s poison. Specifically, the total reward observed by each agent is the sum of two values: an arm-specific reward, capturing the intrinsic value of the arm, and a privately-known agent-specific reward, which captures the personal preference/limitations of the agent. This heterogeneity in total reward leads to different local optimal arms for agents but creates an opportunity for \\textit{free exploration} in a cooperative setting\u2014an agent can freely explore its local optimal arm with no regret and share this free observation with some other agents who would suffer regrets if they pull this arm since the arm is not optimal for them. We first characterize a regret lower bound that captures free exploration, i.e., arms that can be freely explored have no contribution to the regret lower bound. Then, we present a cooperative bandit algorithm that takes advantage of free exploration and achieves a near-optimal regret upper bound which tightly matches the regret lower bound up to a constant factor. Lastly, we run numerical simulations to compare our algorithm with various baselines without free exploration.",
        "bibtex": "@InProceedings{pmlr-v216-wang23a,\n  title = \t {Exploration for Free: How Does Reward Heterogeneity Improve Regret in Cooperative Multi-agent Bandits?},\n  author =       {Wang, Xuchuang and Yang, Lin and Chen, Yu-zhen Janice and Liu, Xutong and Hajiesmaili, Mohammad and Towsley, Don and Lui, John C.S.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2192--2202},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/wang23a/wang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/wang23a.html},\n  abstract = \t {This paper studies a cooperative multi-agent bandit scenario in which the rewards observed by agents are heterogeneous\u2014one agent\u2019s meat can be another agent\u2019s poison. Specifically, the total reward observed by each agent is the sum of two values: an arm-specific reward, capturing the intrinsic value of the arm, and a privately-known agent-specific reward, which captures the personal preference/limitations of the agent. This heterogeneity in total reward leads to different local optimal arms for agents but creates an opportunity for \\textit{free exploration} in a cooperative setting\u2014an agent can freely explore its local optimal arm with no regret and share this free observation with some other agents who would suffer regrets if they pull this arm since the arm is not optimal for them. We first characterize a regret lower bound that captures free exploration, i.e., arms that can be freely explored have no contribution to the regret lower bound. Then, we present a cooperative bandit algorithm that takes advantage of free exploration and achieves a near-optimal regret upper bound which tightly matches the regret lower bound up to a constant factor. Lastly, we run numerical simulations to compare our algorithm with various baselines without free exploration.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/wang23a/wang23a.pdf",
        "supp": "",
        "pdf_size": 1019577,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6044261657074781656&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "daf17a8a5a",
        "title": "FLASH: Automating federated learning using CASH",
        "site": "https://proceedings.mlr.press/v216/alam23a.html",
        "author": "Md I. I. Alam; Koushik Kar; Theodoros Salonidis; Horst Samulowitz",
        "abstract": "In this paper, we present FLASH, a framework which addresses for the first time the central AutoML problem of Combined Algorithm Selection and HyperParameter (HP) Optimization (CASH) in the context of Federated Learning (FL). To limit training cost, FLASH incrementally adapts the set of algorithms to train based on their projected loss rates, while supporting decentralized (federated) implementation of the embedded hyper-parameter optimization (HPO), model selection and loss calculation problems. We provide a theoretical analysis of the training and validation loss under FLASH, and their tradeoff with the training cost measured as the data wasted in training sub-optimal algorithms. The bounds depend on the degree of dissimilarity between the datasets of the clients, a result of FL restriction that client datasets remain private. Through extensive experimental investigation on several datasets, we evaluate three variants of FLASH, and show that FLASH performs close to centralized CASH methods.",
        "bibtex": "@InProceedings{pmlr-v216-alam23a,\n  title = \t {{FLASH}: Automating federated learning using {CASH}},\n  author =       {Alam, Md I. I. and Kar, Koushik and Salonidis, Theodoros and Samulowitz, Horst},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {45--55},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/alam23a/alam23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/alam23a.html},\n  abstract = \t {In this paper, we present FLASH, a framework which addresses for the first time the central AutoML problem of Combined Algorithm Selection and HyperParameter (HP) Optimization (CASH) in the context of Federated Learning (FL). To limit training cost, FLASH incrementally adapts the set of algorithms to train based on their projected loss rates, while supporting decentralized (federated) implementation of the embedded hyper-parameter optimization (HPO), model selection and loss calculation problems. We provide a theoretical analysis of the training and validation loss under FLASH, and their tradeoff with the training cost measured as the data wasted in training sub-optimal algorithms. The bounds depend on the degree of dissimilarity between the datasets of the clients, a result of FL restriction that client datasets remain private. Through extensive experimental investigation on several datasets, we evaluate three variants of FLASH, and show that FLASH performs close to centralized CASH methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/alam23a/alam23a.pdf",
        "supp": "",
        "pdf_size": 986558,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16101886397561963054&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "032915339c",
        "title": "Fairness-aware class imbalanced learning on multiple subgroups",
        "site": "https://proceedings.mlr.press/v216/tarzanagh23a.html",
        "author": "Davoud Ataee Tarzanagh; Bojian Hou; Boning Tong; Qi Long; Li Shen",
        "abstract": "We present a novel Bayesian-based optimization framework that addresses the challenge of generalization in overparameterized models when dealing with imbalanced subgroups and limited samples per subgroup. Our proposed tri-level optimization framework utilizes",
        "bibtex": "@InProceedings{pmlr-v216-tarzanagh23a,\n  title = \t {Fairness-aware class imbalanced learning on multiple subgroups},\n  author =       {Tarzanagh, Davoud Ataee and Hou, Bojian and Tong, Boning and Long, Qi and Shen, Li},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2123--2133},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/tarzanagh23a/tarzanagh23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/tarzanagh23a.html},\n  abstract = \t {We present a novel Bayesian-based optimization framework that addresses the challenge of generalization in overparameterized models when dealing with imbalanced subgroups and limited samples per subgroup. Our proposed tri-level optimization framework utilizes",
        "pdf": "https://proceedings.mlr.press/v216/tarzanagh23a/tarzanagh23a.pdf",
        "supp": "",
        "pdf_size": 551949,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2394503848901892590&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "University of Pennsylvania; University of Pennsylvania; University of Pennsylvania; University of Pennsylvania; University of Pennsylvania",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/PennShenLab/FACIMS",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "536be33d36",
        "title": "Fast Heterogeneous Federated Learning with Hybrid Client Selection",
        "site": "https://proceedings.mlr.press/v216/song23b.html",
        "author": "Duanxiao Song; Guangyuan Shen; Dehong Gao; Libin Yang; Xukai Zhou; Shirui Pan; Wei Lou; Fang Zhou",
        "abstract": "Client selection schemes are widely adopted to handle the communication-efficient problems in recent studies of Federated Learning (FL). However, the large variance of the model updates aggregated from the randomly-selected unrepresentative subsets directly slows the FL convergence. We present a novel clustering-based client selection scheme to accelerate the FL convergence by variance reduction. Simple yet effective schemes are designed to improve the clustering effect and control the effect fluctuation, therefore, generating the client subset with certain representativeness of sampling. Theoretically, we demonstrate the improvement of the proposed scheme in variance reduction. We also present the tighter convergence guarantee of the proposed method thanks to the variance reduction. Experimental results confirm the exceed efficiency of our scheme compared to alternatives.",
        "bibtex": "@InProceedings{pmlr-v216-song23b,\n  title = \t {Fast Heterogeneous Federated Learning with Hybrid Client Selection},\n  author =       {Song, Duanxiao and Shen, Guangyuan and Gao, Dehong and Yang, Libin and Zhou, Xukai and Pan, Shirui and Lou, Wei and Zhou, Fang},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2006--2015},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/song23b/song23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/song23b.html},\n  abstract = \t {Client selection schemes are widely adopted to handle the communication-efficient problems in recent studies of Federated Learning (FL). However, the large variance of the model updates aggregated from the randomly-selected unrepresentative subsets directly slows the FL convergence. We present a novel clustering-based client selection scheme to accelerate the FL convergence by variance reduction. Simple yet effective schemes are designed to improve the clustering effect and control the effect fluctuation, therefore, generating the client subset with certain representativeness of sampling. Theoretically, we demonstrate the improvement of the proposed scheme in variance reduction. We also present the tighter convergence guarantee of the proposed method thanks to the variance reduction. Experimental results confirm the exceed efficiency of our scheme compared to alternatives.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/song23b/song23b.pdf",
        "supp": "",
        "pdf_size": 956505,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9743692290108651596&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "87416df5be",
        "title": "Fast Teammate Adaptation in the Presence of Sudden Policy Change",
        "site": "https://proceedings.mlr.press/v216/zhang23a.html",
        "author": "Ziqian Zhang; Lei Yuan; Lihe Li; Ke Xue; Chengxing Jia; Cong Guan; Chao Qian; Yang Yu",
        "abstract": "Cooperative multi-agent reinforcement learning (MARL), where agents coordinates with teammate(s) for a shared goal, may sustain non-stationary caused by the policy change of teammates.  Prior works mainly concentrate on the policy change cross episodes,  ignoring the fact that teammates may suffer from sudden policy change within an episode, which might lead to miscoordination and poor performance. We formulate the problem as an open Dec-POMDP, where we control some agents to coordinate with uncontrolled teammates, whose policies could be changed within one episode. Then we develop a new framework \\textit{\\textbf{Fas}t \\textbf{t}eammates \\textbf{a}da\\textbf{p}tation (\\textbf{Fastap})} to address the problem. Concretely, we first train versatile teammates\u2019 policies and assign them to different clusters via the Chinese Restaurant Process (CRP). Then, we train the controlled agent(s) to coordinate with the sampled uncontrolled teammates by capturing their identifications as context for fast adaptation. Finally, each agent applies its local information to anticipate the teammates\u2019 context for decision-making accordingly. This process proceeds alternately, leading to a robust policy that can adapt to any teammates during the decentralized execution phase. We show in multiple multi-agent benchmarks that Fastap can achieve superior performance than multiple baselines in stationary and non-stationary scenarios.",
        "bibtex": "@InProceedings{pmlr-v216-zhang23a,\n  title = \t {Fast Teammate Adaptation in the Presence of Sudden Policy Change},\n  author =       {Zhang, Ziqian and Yuan, Lei and Li, Lihe and Xue, Ke and Jia, Chengxing and Guan, Cong and Qian, Chao and Yu, Yang},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2465--2476},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zhang23a/zhang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zhang23a.html},\n  abstract = \t {  Cooperative multi-agent reinforcement learning (MARL), where agents coordinates with teammate(s) for a shared goal, may sustain non-stationary caused by the policy change of teammates.  Prior works mainly concentrate on the policy change cross episodes,  ignoring the fact that teammates may suffer from sudden policy change within an episode, which might lead to miscoordination and poor performance. We formulate the problem as an open Dec-POMDP, where we control some agents to coordinate with uncontrolled teammates, whose policies could be changed within one episode. Then we develop a new framework \\textit{\\textbf{Fas}t \\textbf{t}eammates \\textbf{a}da\\textbf{p}tation (\\textbf{Fastap})} to address the problem. Concretely, we first train versatile teammates\u2019 policies and assign them to different clusters via the Chinese Restaurant Process (CRP). Then, we train the controlled agent(s) to coordinate with the sampled uncontrolled teammates by capturing their identifications as context for fast adaptation. Finally, each agent applies its local information to anticipate the teammates\u2019 context for decision-making accordingly. This process proceeds alternately, leading to a robust policy that can adapt to any teammates during the decentralized execution phase. We show in multiple multi-agent benchmarks that Fastap can achieve superior performance than multiple baselines in stationary and non-stationary scenarios. }\n}",
        "pdf": "https://proceedings.mlr.press/v216/zhang23a/zhang23a.pdf",
        "supp": "",
        "pdf_size": 1446752,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12847284785804362967&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "National Key Laboratory for Novel Software Technology, Nanjing University; National Key Laboratory for Novel Software Technology, Nanjing University + Polixir Technologies; National Key Laboratory for Novel Software Technology, Nanjing University; National Key Laboratory for Novel Software Technology, Nanjing University; National Key Laboratory for Novel Software Technology, Nanjing University + Polixir Technologies; National Key Laboratory for Novel Software Technology, Nanjing University; National Key Laboratory for Novel Software Technology, Nanjing University; National Key Laboratory for Novel Software Technology, Nanjing University + Polixir Technologies",
        "aff_domain": "smail.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn;gmail.com;nju.edu.cn;nju.edu.cn",
        "email": "smail.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn;lamda.nju.edu.cn;gmail.com;nju.edu.cn;nju.edu.cn",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;0;0;0+1;0;0;0+1",
        "aff_unique_norm": "Nanjing University;Polixir Technologies",
        "aff_unique_dep": "National Key Laboratory for Novel Software Technology;",
        "aff_unique_url": "http://www.nju.edu.cn;",
        "aff_unique_abbr": "Nanjing University;",
        "aff_campus_unique_index": ";;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+1;0;0;0+1;0;0;0+1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "c130aa77f6",
        "title": "Fast and scalable score-based kernel calibration tests",
        "site": "https://proceedings.mlr.press/v216/glaser23a.html",
        "author": "Pierre Glaser; David Widmann; Fredrik Lindsten; Arthur Gretton",
        "abstract": "We introduce the Kernel Calibration Conditional Stein Discrepancy test (KCCSD test), a nonparametric, kernel-based test for assessing the calibration of probabilistic models with well-defined scores. In contrast to previous methods, our test avoids the need for possibly expensive expectation approximations while providing control over its type-I error. We achieve these improvements by using a new family of kernels for score-based probabilities that can be estimated without probability density samples, and by using a Conditional Goodness of Fit criterion for the KCCSD test\u2019s U-statistic. We demonstrate the properties of our test on various synthetic settings.",
        "bibtex": "@InProceedings{pmlr-v216-glaser23a,\n  title = \t {Fast and scalable score-based kernel calibration tests},\n  author =       {Glaser, Pierre and Widmann, David and Lindsten, Fredrik and Gretton, Arthur},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {691--700},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/glaser23a/glaser23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/glaser23a.html},\n  abstract = \t {We introduce the Kernel Calibration Conditional Stein Discrepancy test (KCCSD test), a nonparametric, kernel-based test for assessing the calibration of probabilistic models with well-defined scores. In contrast to previous methods, our test avoids the need for possibly expensive expectation approximations while providing control over its type-I error. We achieve these improvements by using a new family of kernels for score-based probabilities that can be estimated without probability density samples, and by using a Conditional Goodness of Fit criterion for the KCCSD test\u2019s U-statistic. We demonstrate the properties of our test on various synthetic settings.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/glaser23a/glaser23a.pdf",
        "supp": "",
        "pdf_size": 365116,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1839726783543109369&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1bdd863d21",
        "title": "Fed-LAMB: Layer-wise and Dimension-wise Locally Adaptive Federated Learning",
        "site": "https://proceedings.mlr.press/v216/karimi23a.html",
        "author": "Belhal Karimi; Ping Li; Xiaoyun Li",
        "abstract": "In the emerging paradigm of Federated Learning (FL), large amount of clients such as mobile devices are used to train possibly high-dimensional models on their respective data. Combining (dimension-wise) adaptive gradient methods (e.g., Adam, AMSGrad) with FL has been an active direction, which is shown to outperform traditional SGD based FL in many cases. In this paper, we focus on the problem of training federated deep neural networks, and propose a novel FL framework which further introduces layer-wise adaptivity to the local model updates to accelerate the convergence of adaptive FL methods. Our framework includes two variants based on two recent locally adaptive federated learning algorithms. Theoretically, we provide a convergence analysis of our layer-wise FL methods, coined Fed-LAMB and Mime-LAMB, which match the convergence rate of state-of-the-art results in adaptive FL and exhibits linear speedup in terms of the number of workers. Experimental results on various datasets and models, under both IID and non-IID local data settings, show that both Fed-LAMB and Mime-LAMB achieve faster convergence speed and better generalization performance, compared to various recent adaptive FL methods.",
        "bibtex": "@InProceedings{pmlr-v216-karimi23a,\n  title = \t {{Fed-LAMB}: Layer-wise and Dimension-wise Locally Adaptive Federated Learning},\n  author =       {Karimi, Belhal and Li, Ping and Li, Xiaoyun},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1037--1046},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/karimi23a/karimi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/karimi23a.html},\n  abstract = \t {In the emerging paradigm of Federated Learning (FL), large amount of clients such as mobile devices are used to train possibly high-dimensional models on their respective data. Combining (dimension-wise) adaptive gradient methods (e.g., Adam, AMSGrad) with FL has been an active direction, which is shown to outperform traditional SGD based FL in many cases. In this paper, we focus on the problem of training federated deep neural networks, and propose a novel FL framework which further introduces layer-wise adaptivity to the local model updates to accelerate the convergence of adaptive FL methods. Our framework includes two variants based on two recent locally adaptive federated learning algorithms. Theoretically, we provide a convergence analysis of our layer-wise FL methods, coined Fed-LAMB and Mime-LAMB, which match the convergence rate of state-of-the-art results in adaptive FL and exhibits linear speedup in terms of the number of workers. Experimental results on various datasets and models, under both IID and non-IID local data settings, show that both Fed-LAMB and Mime-LAMB achieve faster convergence speed and better generalization performance, compared to various recent adaptive FL methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/karimi23a/karimi23a.pdf",
        "supp": "",
        "pdf_size": 492820,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9071454370341020260&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2bbadd7a5d",
        "title": "Federated learning of models pre-trained on different features with consensus graphs",
        "site": "https://proceedings.mlr.press/v216/ma23b.html",
        "author": "Tengfei Ma; Trong Nghia Hoang; Jie Chen",
        "abstract": "Learning an effective global model on private and decentralized datasets has become an increasingly important challenge of machine learning when applied in practice. Existing distributed learning paradigms, such as Federated Learning, enable this via model aggregation which enforces a strong form of modeling homogeneity and synchronicity across clients. This is however not suitable to many practical scenarios. For example, in distributed sensing, heterogeneous sensors reading data from different views of the same phenomenon would need to use different models for different data modalities. Local learning therefore happens in isolation but inference requires merging the local models to achieve consensus. To enable consensus among local models, we propose a feature fusion approach that extracts local representations from local models and incorporates them into a global representation that improves the prediction performance. Achieving this requires addressing two non-trivial problems. First, we need to learn an alignment between similar feature components which are arbitrarily arranged across clients to enable representation aggregation. Second, we need to learn a consensus graph that captures the high-order interactions between local feature spaces and how to combine them to achieve a better prediction. This paper presents solutions to these problems and demonstrates them in real-world applications on time series data such as power grids and traffic networks.",
        "bibtex": "@InProceedings{pmlr-v216-ma23b,\n  title = \t {Federated learning of models pre-trained on different features with consensus graphs},\n  author =       {Ma, Tengfei and Hoang, Trong Nghia and Chen, Jie},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1336--1346},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/ma23b/ma23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/ma23b.html},\n  abstract = \t {Learning an effective global model on private and decentralized datasets has become an increasingly important challenge of machine learning when applied in practice. Existing distributed learning paradigms, such as Federated Learning, enable this via model aggregation which enforces a strong form of modeling homogeneity and synchronicity across clients. This is however not suitable to many practical scenarios. For example, in distributed sensing, heterogeneous sensors reading data from different views of the same phenomenon would need to use different models for different data modalities. Local learning therefore happens in isolation but inference requires merging the local models to achieve consensus. To enable consensus among local models, we propose a feature fusion approach that extracts local representations from local models and incorporates them into a global representation that improves the prediction performance. Achieving this requires addressing two non-trivial problems. First, we need to learn an alignment between similar feature components which are arbitrarily arranged across clients to enable representation aggregation. Second, we need to learn a consensus graph that captures the high-order interactions between local feature spaces and how to combine them to achieve a better prediction. This paper presents solutions to these problems and demonstrates them in real-world applications on time series data such as power grids and traffic networks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/ma23b/ma23b.pdf",
        "supp": "",
        "pdf_size": 385987,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17188199074249391046&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": "IBM Research; Washington State University; MIT-IBM Watson AI Lab + IBM Research",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2+0",
        "aff_unique_norm": "IBM;Washington State University;Massachusetts Institute of Technology",
        "aff_unique_dep": "IBM Research;;IBM Watson AI Lab",
        "aff_unique_url": "https://www.ibm.com/research;https://wsu.edu;https://www.mitibmwatsonailab.org",
        "aff_unique_abbr": "IBM;WSU;MIT-IBM AI Lab",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "056ed893ea",
        "title": "Finding Invariant Predictors Efficiently via Causal Structure",
        "site": "https://proceedings.mlr.press/v216/lee23a.html",
        "author": "Kenneth Lee; Md Musfiqur Rahman; Murat Kocaoglu",
        "abstract": "One fundamental problem in machine learning is out-of-distribution generalization. A method named the surgery estimator incorporates the causal structure in the form of a directed acyclic graph (DAG) to find predictors that are invariant across target domains using distributional invariances via Pearl\u2019s do-calculus. However, finding a surgery estimator can take exponential time as the current methods need to search through all possible predictors. In this work, we first provide a graphical characterization of the identifiability of conditional causal queries. Next, we leverage this characterization together with a greedy search step to develop a polynomial-time algorithm for finding invariant predictors using the causal graph. Given the correct causal graph, our method is guaranteed to find at least one invariant predictor, if it exists. We show that our proposed algorithm can significantly reduce the run-time both in simulated and semi-synthetic data experiments and have predictive performance that is comparable to the existing work that runs in exponential time.",
        "bibtex": "@InProceedings{pmlr-v216-lee23a,\n  title = \t {Finding Invariant Predictors Efficiently via Causal Structure},\n  author =       {Lee, Kenneth and Rahman, Md Musfiqur and Kocaoglu, Murat},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1196--1206},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/lee23a/lee23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/lee23a.html},\n  abstract = \t {One fundamental problem in machine learning is out-of-distribution generalization. A method named the surgery estimator incorporates the causal structure in the form of a directed acyclic graph (DAG) to find predictors that are invariant across target domains using distributional invariances via Pearl\u2019s do-calculus. However, finding a surgery estimator can take exponential time as the current methods need to search through all possible predictors. In this work, we first provide a graphical characterization of the identifiability of conditional causal queries. Next, we leverage this characterization together with a greedy search step to develop a polynomial-time algorithm for finding invariant predictors using the causal graph. Given the correct causal graph, our method is guaranteed to find at least one invariant predictor, if it exists. We show that our proposed algorithm can significantly reduce the run-time both in simulated and semi-synthetic data experiments and have predictive performance that is comparable to the existing work that runs in exponential time.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/lee23a/lee23a.pdf",
        "supp": "",
        "pdf_size": 758043,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2161124732760925304&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c714e2fa5c",
        "title": "Finite-sample guarantees for Nash Q-learning with linear function approximation",
        "site": "https://proceedings.mlr.press/v216/cisneros-velarde23a.html",
        "author": "Pedro Cisneros-Velarde; Sanmi Koyejo",
        "abstract": "Nash Q-learning may be considered one of the first and most known algorithms in multi-agent reinforcement learning (MARL) for learning policies that constitute a Nash equilibrium of an underlying general-sum Markov game. Its original proof provided asymptotic guarantees and was for the tabular case. Recently, finite-sample guarantees have been provided using more modern RL techniques for the tabular case. Our work analyzes Nash Q-learning using linear function approximation \u2013 a representation regime introduced when the state space is large or continuous \u2013 and provides finite-sample guarantees that indicate its sample efficiency. We find that the obtained performance nearly matches an existing efficient result for single-agent RL under the same representation and has a polynomial gap when compared to the best-known result for the tabular case.",
        "bibtex": "@InProceedings{pmlr-v216-cisneros-velarde23a,\n  title = \t {Finite-sample guarantees for {N}ash {Q}-learning with linear function approximation},\n  author =       {Cisneros-Velarde, Pedro and Koyejo, Sanmi},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {424--432},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/cisneros-velarde23a/cisneros-velarde23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/cisneros-velarde23a.html},\n  abstract = \t {Nash Q-learning may be considered one of the first and most known algorithms in multi-agent reinforcement learning (MARL) for learning policies that constitute a Nash equilibrium of an underlying general-sum Markov game. Its original proof provided asymptotic guarantees and was for the tabular case. Recently, finite-sample guarantees have been provided using more modern RL techniques for the tabular case. Our work analyzes Nash Q-learning using linear function approximation \u2013 a representation regime introduced when the state space is large or continuous \u2013 and provides finite-sample guarantees that indicate its sample efficiency. We find that the obtained performance nearly matches an existing efficient result for single-agent RL under the same representation and has a polynomial gap when compared to the best-known result for the tabular case.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/cisneros-velarde23a/cisneros-velarde23a.pdf",
        "supp": "",
        "pdf_size": 234637,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16217022716347216426&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "University of Illinois at Urbana-Champaign; Stanford University+Google Research",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Stanford University;Google",
        "aff_unique_dep": ";;Google Research",
        "aff_unique_url": "https://illinois.edu;https://www.stanford.edu;https://research.google",
        "aff_unique_abbr": "UIUC;Stanford;Google Research",
        "aff_campus_unique_index": "0;1+2",
        "aff_campus_unique": "Urbana-Champaign;Stanford;Mountain View",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2854769b5c",
        "title": "Fixed-Budget Best-Arm Identification with Heterogeneous Reward Variances",
        "site": "https://proceedings.mlr.press/v216/lalitha23a.html",
        "author": "Anusha Lalitha Lalitha; Kousha Kalantari; Yifei Ma; Anoop Deoras; Branislav Kveton",
        "abstract": "We study the problem of best-arm identification (BAI) in the fixed-budget setting with heterogeneous reward variances. We propose two variance-adaptive BAI algorithms for this setting: SHVar for known reward variances and SHAdaVar for unknown reward variances. Our algorithms rely on non-uniform budget allocations among the arms where the arms with higher reward variances are pulled more often than those with lower variances. The main algorithmic novelty is in the design of SHAdaVar, which allocates budget greedily based on overestimating the unknown reward variances. We bound probabilities of misidentifying the best arms in both SHVar and SHAdaVar. Our analyses rely on novel lower bounds on the number of pulls of an arm that do not require closed-form solutions to the budget allocation problem. Since one of our budget allocation problems is analogous to the optimal experiment design with unknown variances, we believe that our results are of a broad interest. Our experiments validate our theory, and show that SHVar and SHAdaVar outperform algorithms from prior works with analytical guarantees.",
        "bibtex": "@InProceedings{pmlr-v216-lalitha23a,\n  title = \t {Fixed-Budget Best-Arm Identification with Heterogeneous Reward Variances},\n  author =       {Lalitha, Anusha Lalitha and Kalantari, Kousha and Ma, Yifei and Deoras, Anoop and Kveton, Branislav},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1164--1173},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/lalitha23a/lalitha23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/lalitha23a.html},\n  abstract = \t {We study the problem of best-arm identification (BAI) in the fixed-budget setting with heterogeneous reward variances. We propose two variance-adaptive BAI algorithms for this setting: SHVar for known reward variances and SHAdaVar for unknown reward variances. Our algorithms rely on non-uniform budget allocations among the arms where the arms with higher reward variances are pulled more often than those with lower variances. The main algorithmic novelty is in the design of SHAdaVar, which allocates budget greedily based on overestimating the unknown reward variances. We bound probabilities of misidentifying the best arms in both SHVar and SHAdaVar. Our analyses rely on novel lower bounds on the number of pulls of an arm that do not require closed-form solutions to the budget allocation problem. Since one of our budget allocation problems is analogous to the optimal experiment design with unknown variances, we believe that our results are of a broad interest. Our experiments validate our theory, and show that SHVar and SHAdaVar outperform algorithms from prior works with analytical guarantees.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/lalitha23a/lalitha23a.pdf",
        "supp": "",
        "pdf_size": 537000,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13356553168404353517&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "AWS AI Labs; AWS AI Labs; AWS AI Labs; AWS AI Labs; AWS AI Labs",
        "aff_domain": "amazon.com;amazon.com;amazon.com;amazon.com;amazon.com",
        "email": "amazon.com;amazon.com;amazon.com;amazon.com;amazon.com",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Amazon",
        "aff_unique_dep": "AWS AI Labs",
        "aff_unique_url": "https://aws.amazon.com",
        "aff_unique_abbr": "AWS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c13915de3b",
        "title": "Functional causal Bayesian optimization",
        "site": "https://proceedings.mlr.press/v216/gultchin23a.html",
        "author": "Limor Gultchin; Virginia Aglietti; Alexis Bellot; Silvia Chiappa",
        "abstract": "We propose functional causal Bayesian optimization (fCBO), a method for finding interventions that optimize a target variable in a known causal graph. fCBO extends the CBO family of methods to enable functional interventions, which set a variable to be a deterministic function of other variables in the graph. fCBO models the unknown objectives with Gaussian processes whose inputs are defined in a reproducing kernel Hilbert space, thus allowing to compute distances among vector-valued functions. In turn, this enables to sequentially select functions to explore by maximizing an expected improvement acquisition functional while keeping the typical computational tractability of standard BO settings. We introduce graphical criteria that establish when considering functional interventions allows attaining better target effects, and conditions under which selected interventions are also optimal for conditional target effects. We demonstrate the benefits of the method in a synthetic and in a real-world causal graph.",
        "bibtex": "@InProceedings{pmlr-v216-gultchin23a,\n  title = \t {Functional causal {B}ayesian optimization},\n  author =       {Gultchin, Limor and Aglietti, Virginia and Bellot, Alexis and Chiappa, Silvia},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {756--765},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/gultchin23a/gultchin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/gultchin23a.html},\n  abstract = \t {We propose functional causal Bayesian optimization (fCBO), a method for finding interventions that optimize a target variable in a known causal graph. fCBO extends the CBO family of methods to enable functional interventions, which set a variable to be a deterministic function of other variables in the graph. fCBO models the unknown objectives with Gaussian processes whose inputs are defined in a reproducing kernel Hilbert space, thus allowing to compute distances among vector-valued functions. In turn, this enables to sequentially select functions to explore by maximizing an expected improvement acquisition functional while keeping the typical computational tractability of standard BO settings. We introduce graphical criteria that establish when considering functional interventions allows attaining better target effects, and conditions under which selected interventions are also optimal for conditional target effects. We demonstrate the benefits of the method in a synthetic and in a real-world causal graph.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/gultchin23a/gultchin23a.pdf",
        "supp": "",
        "pdf_size": 1638844,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15755222943767921238&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 10,
        "aff": "University of Oxford, The Alan Turing Institute, Work done at DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Oxford;DeepMind",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ox.ac.uk;https://deepmind.com",
        "aff_unique_abbr": "Oxford;DeepMind",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Oxford;London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "7975abc1f8",
        "title": "Gaussian Process Surrogate Models for Neural Networks",
        "site": "https://proceedings.mlr.press/v216/li23c.html",
        "author": "Michael Y. Li; Erin Grant; Thomas L. Griffiths",
        "abstract": "Not being able to understand and predict the behavior of deep learning systems makes it hard to decide what architecture and algorithm to use for a given problem. In science and engineering, modeling is a methodology used to understand complex systems whose internal processes are opaque. Modeling replaces a complex system with a simpler, more interpretable surrogate. Drawing inspiration from this, we construct a class of surrogate models for neural networks using Gaussian processes. Rather than deriving kernels for infinite neural networks, we learn kernels empirically from the naturalistic behavior of finite neural networks. We demonstrate our approach captures existing phenomena related to the spectral bias of neural networks, and then show that our surrogate models can be used to solve practical problems such as identifying which points most influence the behavior of specific neural networks and predicting which architectures and algorithms will generalize well for specific datasets.",
        "bibtex": "@InProceedings{pmlr-v216-li23c,\n  title = \t {{G}aussian Process Surrogate Models for Neural Networks},\n  author =       {Li, Michael Y. and Grant, Erin and Griffiths, Thomas L.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1241--1252},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/li23c/li23c.pdf},\n  url = \t {https://proceedings.mlr.press/v216/li23c.html},\n  abstract = \t {Not being able to understand and predict the behavior of deep learning systems makes it hard to decide what architecture and algorithm to use for a given problem. In science and engineering, modeling is a methodology used to understand complex systems whose internal processes are opaque. Modeling replaces a complex system with a simpler, more interpretable surrogate. Drawing inspiration from this, we construct a class of surrogate models for neural networks using Gaussian processes. Rather than deriving kernels for infinite neural networks, we learn kernels empirically from the naturalistic behavior of finite neural networks. We demonstrate our approach captures existing phenomena related to the spectral bias of neural networks, and then show that our surrogate models can be used to solve practical problems such as identifying which points most influence the behavior of specific neural networks and predicting which architectures and algorithms will generalize well for specific datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/li23c/li23c.pdf",
        "supp": "",
        "pdf_size": 1220769,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3580459174650725990&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "dd7cc94ebf",
        "title": "Generating Synthetic Datasets by Interpolating along Generalized Geodesics",
        "site": "https://proceedings.mlr.press/v216/fan23b.html",
        "author": "Jiaojiao Fan; David Alvarez-Melis",
        "abstract": "Data for pretraining machine learning models often consists of collections of heterogeneous datasets. Although training on their union is reasonable in agnostic settings, it might be suboptimal when the target domain \u2014where the model will ultimately be used\u2014 is known in advance. In that case, one would ideally pretrain only on the dataset(s) most similar to the target one. Instead of limiting this choice to those datasets already present in the pretraining collection, here we explore extending this search to all datasets that can be synthesized as \u2018combinations\u2019 of them. We define such combinations as multi-dataset interpolations, formalized through the notion of generalized geodesics from optimal transport (OT) theory. We compute these geodesics using a recent notion of distance between labeled datasets, and derive alternative interpolation schemes based on it: using either barycentric projections or optimal transport maps, the latter computed using recent neural OT methods. These methods are scalable, efficient, and \u2014notably\u2014 can be used to interpolate even between datasets with distinct and unrelated label sets. Through various experiments in transfer learning in computer vision, we demonstrate this is a promising new approach for targeted on-demand dataset synthesis.",
        "bibtex": "@InProceedings{pmlr-v216-fan23b,\n  title = \t {Generating Synthetic Datasets by Interpolating along Generalized Geodesics},\n  author =       {Fan, Jiaojiao and Alvarez-Melis, David},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {571--581},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/fan23b/fan23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/fan23b.html},\n  abstract = \t {Data for pretraining machine learning models often consists of collections of heterogeneous datasets. Although training on their union is reasonable in agnostic settings, it might be suboptimal when the target domain \u2014where the model will ultimately be used\u2014 is known in advance. In that case, one would ideally pretrain only on the dataset(s) most similar to the target one. Instead of limiting this choice to those datasets already present in the pretraining collection, here we explore extending this search to all datasets that can be synthesized as \u2018combinations\u2019 of them. We define such combinations as multi-dataset interpolations, formalized through the notion of generalized geodesics from optimal transport (OT) theory. We compute these geodesics using a recent notion of distance between labeled datasets, and derive alternative interpolation schemes based on it: using either barycentric projections or optimal transport maps, the latter computed using recent neural OT methods. These methods are scalable, efficient, and \u2014notably\u2014 can be used to interpolate even between datasets with distinct and unrelated label sets. Through various experiments in transfer learning in computer vision, we demonstrate this is a promising new approach for targeted on-demand dataset synthesis.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/fan23b/fan23b.pdf",
        "supp": "",
        "pdf_size": 5099515,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13399404663432499592&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Georgia Tech, Atlanta, Georgia, USA; Microsoft Research & Harvard University, Cambridge, Massachusetts, USA",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Georgia Institute of Technology;Harvard University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.gatech.edu;https://www.harvard.edu",
        "aff_unique_abbr": "Georgia Tech;Harvard",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Atlanta;Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c5736711f3",
        "title": "Graph Self-supervised Learning via Proximity Distribution Minimization",
        "site": "https://proceedings.mlr.press/v216/zhang23d.html",
        "author": "Tianyi Zhang; Zhenwei Dai; Zhaozhuo Xu; Anshumali Shrivastava",
        "abstract": "Self-supervised learning (SSL) for graphs is an essential problem since graph data are ubiquitous and labeling can be costly. We argue that existing SSL approaches for graphs have two limitations. First, they rely on corruption techniques such as node attribute perturbation and edge dropping to generate graph views for contrastive learning. These unnatural corruption techniques require extensive tuning efforts and provide marginal improvements. Second, the current approaches require the computation of multiple graph views, which is memory and computationally inefficient. These shortcomings of graph SSL call for a corruption-free single-view learning approach, but the strawman approach of using neighboring nodes as positive examples suffers two problems: it ignores the strength of connections between nodes implied by the graph structure on a macro level, and cannot deal with the high noise in real-world graphs. We propose Proximity Divergence Minimization (PDM), a corruption-free single-view graph SSL approach that overcomes these problems by leveraging node proximity to measure connection strength and denoise the graph structure. Through extensive experiments, we show that PDM achieves up to 4.55% absolute improvement in ROC-AUC on graph SSL tasks over state-of-the-art approaches while being more memory efficient. Moreover, PDM even outperforms supervised training on node classification tasks of ogbn-proteins dataset. Our code is publicly available.",
        "bibtex": "@InProceedings{pmlr-v216-zhang23d,\n  title = \t {Graph Self-supervised Learning via Proximity Distribution Minimization},\n  author =       {Zhang, Tianyi and Dai, Zhenwei and Xu, Zhaozhuo and Shrivastava, Anshumali},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2498--2508},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zhang23d/zhang23d.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zhang23d.html},\n  abstract = \t {Self-supervised learning (SSL) for graphs is an essential problem since graph data are ubiquitous and labeling can be costly. We argue that existing SSL approaches for graphs have two limitations. First, they rely on corruption techniques such as node attribute perturbation and edge dropping to generate graph views for contrastive learning. These unnatural corruption techniques require extensive tuning efforts and provide marginal improvements. Second, the current approaches require the computation of multiple graph views, which is memory and computationally inefficient. These shortcomings of graph SSL call for a corruption-free single-view learning approach, but the strawman approach of using neighboring nodes as positive examples suffers two problems: it ignores the strength of connections between nodes implied by the graph structure on a macro level, and cannot deal with the high noise in real-world graphs. We propose Proximity Divergence Minimization (PDM), a corruption-free single-view graph SSL approach that overcomes these problems by leveraging node proximity to measure connection strength and denoise the graph structure. Through extensive experiments, we show that PDM achieves up to 4.55% absolute improvement in ROC-AUC on graph SSL tasks over state-of-the-art approaches while being more memory efficient. Moreover, PDM even outperforms supervised training on node classification tasks of ogbn-proteins dataset. Our code is publicly available.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/zhang23d/zhang23d.pdf",
        "supp": "",
        "pdf_size": 6256383,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:3m8uuIaZTrIJ:scholar.google.com/&scioq=Graph+Self-supervised+Learning+via+Proximity+Distribution+Minimization&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "23558a080a",
        "title": "Graph classification Gaussian processes via spectral features",
        "site": "https://proceedings.mlr.press/v216/opolka23a.html",
        "author": "Felix L. Opolka; Yin-Cong Zhi; Pietro Li\u00f2; Xiaowen Dong",
        "abstract": "Graph classification aims to categorise graphs based on their structure and node attributes. In this work, we propose to tackle this task using tools from graph signal processing by deriving spectral features, which we then use to design two variants of Gaussian process models for graph classification. The first variant uses spectral features based on the distribution of energy of a node feature signal over the spectrum of the graph. We show that even such a simple approach, having no learned parameters, can yield competitive performance compared to strong neural network and graph kernel baselines. A second, more sophisticated variant is designed to capture multi-scale and localised patterns in the graph by learning spectral graph wavelet filters, obtaining improved performance on synthetic and real-world data sets. Finally, we show that both models produce well calibrated uncertainty estimates, enabling reliable decision making based on the model predictions.",
        "bibtex": "@InProceedings{pmlr-v216-opolka23a,\n  title = \t {Graph classification {G}aussian processes via spectral features},\n  author =       {Opolka, Felix L. and Zhi, Yin-Cong and Li\\`o, Pietro and Dong, Xiaowen},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1575--1585},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/opolka23a/opolka23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/opolka23a.html},\n  abstract = \t {Graph classification aims to categorise graphs based on their structure and node attributes. In this work, we propose to tackle this task using tools from graph signal processing by deriving spectral features, which we then use to design two variants of Gaussian process models for graph classification. The first variant uses spectral features based on the distribution of energy of a node feature signal over the spectrum of the graph. We show that even such a simple approach, having no learned parameters, can yield competitive performance compared to strong neural network and graph kernel baselines. A second, more sophisticated variant is designed to capture multi-scale and localised patterns in the graph by learning spectral graph wavelet filters, obtaining improved performance on synthetic and real-world data sets. Finally, we show that both models produce well calibrated uncertainty estimates, enabling reliable decision making based on the model predictions.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/opolka23a/opolka23a.pdf",
        "supp": "",
        "pdf_size": 849876,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=368682445909397016&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f84025df05",
        "title": "Greed is good: correspondence recovery for unlabeled linear regression",
        "site": "https://proceedings.mlr.press/v216/zhang23e.html",
        "author": "Hang Zhang; Ping Li",
        "abstract": "We consider the unlabeled linear regression reading as $\\mathbf{Y} = \\mathbf{\\Pi}^{*}\\mathbf{X}\\mathbf{B}^* + \\mathbf{W}$, where $\\mathbf{\\Pi}^{*}, \\mathbf{B}^*$ and $\\mathbf{W}$ represents missing (or incomplete) correspondence information, signals, and additive noise, respectively. Our goal is to perform data alignment between $\\mathbf{Y}$ and $\\mathbf{X}$, or equivalently, reconstruct the correspondence information encoded by $\\mathbf{\\Pi}^*$. Based on whether signal $\\mathbf{B}^*$ is given a prior, we separately propose two greedy-selection-based estimators, which both reach the mini-max optimality. Compared with previous works, our work $(i)$ supports partial recovery of the correspondence information; and $(ii)$ applies to a general matrix family rather than the permutation matrices, to put more specifically, selection matrices, where multiple rows of $\\mathbf{X}$ can correspond to the same row in $\\mathbf{Y}$. Moreover, numerical experiments are provided to corroborate our claims.",
        "bibtex": "@InProceedings{pmlr-v216-zhang23e,\n  title = \t {Greed is good: correspondence recovery for unlabeled linear regression},\n  author =       {Zhang, Hang and Li, Ping},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2509--2518},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zhang23e/zhang23e.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zhang23e.html},\n  abstract = \t {We consider the unlabeled linear regression reading as $\\mathbf{Y} = \\mathbf{\\Pi}^{*}\\mathbf{X}\\mathbf{B}^* + \\mathbf{W}$, where $\\mathbf{\\Pi}^{*}, \\mathbf{B}^*$ and $\\mathbf{W}$ represents missing (or incomplete) correspondence information, signals, and additive noise, respectively. Our goal is to perform data alignment between $\\mathbf{Y}$ and $\\mathbf{X}$, or equivalently, reconstruct the correspondence information encoded by $\\mathbf{\\Pi}^*$. Based on whether signal $\\mathbf{B}^*$ is given a prior, we separately propose two greedy-selection-based estimators, which both reach the mini-max optimality. Compared with previous works, our work $(i)$ supports partial recovery of the correspondence information; and $(ii)$ applies to a general matrix family rather than the permutation matrices, to put more specifically, selection matrices, where multiple rows of $\\mathbf{X}$ can correspond to the same row in $\\mathbf{Y}$. Moreover, numerical experiments are provided to corroborate our claims.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/zhang23e/zhang23e.pdf",
        "supp": "",
        "pdf_size": 858306,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8687060089069462095&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Cognitive Computing Lab, Baidu Research; Cognitive Computing Lab, Baidu Research",
        "aff_domain": "gmail.com;gmail.com",
        "email": "gmail.com;gmail.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Baidu",
        "aff_unique_dep": "Cognitive Computing Lab",
        "aff_unique_url": "https://baidu.com",
        "aff_unique_abbr": "Baidu",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "dc3b7fb83f",
        "title": "Guided Deep Kernel Learning",
        "site": "https://proceedings.mlr.press/v216/achituve23a.html",
        "author": "Idan Achituve; Gal Chechik; Ethan Fetaya",
        "abstract": "Combining Gaussian processes with the expressive power of deep neural networks is commonly done nowadays through deep kernel learning (DKL). Unfortunately, due to the kernel optimization process, this often results in losing their Bayesian benefits. In this study, we present a novel approach for learning deep kernels by utilizing infinite-width neural networks. We propose to use the Neural Network Gaussian Process (NNGP) model as a guide to the DKL model in the optimization process. Our approach harnesses the reliable uncertainty estimation of the NNGPs to adapt the DKL target confidence when it encounters novel data points. As a result, we get the best of both worlds, we leverage the Bayesian behavior of the NNGP, namely its robustness to overfitting, and accurate uncertainty estimation, while maintaining the generalization abilities, scalability, and flexibility of deep kernels. Empirically, we show on multiple benchmark datasets of varying sizes and dimensionality, that our method is robust to overfitting, has good predictive performance, and provides reliable uncertainty estimations.",
        "bibtex": "@InProceedings{pmlr-v216-achituve23a,\n  title = \t {Guided Deep Kernel Learning},\n  author =       {Achituve, Idan and Chechik, Gal and Fetaya, Ethan},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {11--21},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/achituve23a/achituve23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/achituve23a.html},\n  abstract = \t {Combining Gaussian processes with the expressive power of deep neural networks is commonly done nowadays through deep kernel learning (DKL). Unfortunately, due to the kernel optimization process, this often results in losing their Bayesian benefits. In this study, we present a novel approach for learning deep kernels by utilizing infinite-width neural networks. We propose to use the Neural Network Gaussian Process (NNGP) model as a guide to the DKL model in the optimization process. Our approach harnesses the reliable uncertainty estimation of the NNGPs to adapt the DKL target confidence when it encounters novel data points. As a result, we get the best of both worlds, we leverage the Bayesian behavior of the NNGP, namely its robustness to overfitting, and accurate uncertainty estimation, while maintaining the generalization abilities, scalability, and flexibility of deep kernels. Empirically, we show on multiple benchmark datasets of varying sizes and dimensionality, that our method is robust to overfitting, has good predictive performance, and provides reliable uncertainty estimations.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/achituve23a/achituve23a.pdf",
        "supp": "",
        "pdf_size": 2019125,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12944068464766899380&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8741d7b460",
        "title": "Hallucinated adversarial control for conservative offline policy evaluation",
        "site": "https://proceedings.mlr.press/v216/rothfuss23a.html",
        "author": "Jonas Rothfuss; Bhavya Sukhija; Tobias Birchler; Parnian Kassraie; Andreas Krause",
        "abstract": "We study the problem of conservative off-policy evaluation (COPE) where given an offline dataset of environment interactions, collected by other agents, we seek to obtain a (tight) lower bound on a policy\u2019s performance. This is crucial when deciding whether a given policy satisfies certain minimal performance/safety criteria before it can be deployed in the real world. To this end, we introduce HAMBO, which builds on an uncertainty-aware learned model of the transition dynamics. To form a conservative estimate of the policy\u2019s performance, HAMBO hallucinates worst-case trajectories that the policy may take, within the margin of the models\u2019 epistemic confidence regions. We prove that the resulting COPE estimates are valid lower bounds, and, under regularity conditions, show their convergence to the true expected return. Finally, we discuss scalable variants of our approach based on Bayesian Neural Networks and empirically demonstrate that they yield reliable and tight lower bounds in various continuous control environments.",
        "bibtex": "@InProceedings{pmlr-v216-rothfuss23a,\n  title = \t {Hallucinated adversarial control for conservative offline policy evaluation},\n  author =       {Rothfuss, Jonas and Sukhija, Bhavya and Birchler, Tobias and Kassraie, Parnian and Krause, Andreas},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1774--1784},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/rothfuss23a/rothfuss23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/rothfuss23a.html},\n  abstract = \t {We study the problem of conservative off-policy evaluation (COPE) where given an offline dataset of environment interactions, collected by other agents, we seek to obtain a (tight) lower bound on a policy\u2019s performance. This is crucial when deciding whether a given policy satisfies certain minimal performance/safety criteria before it can be deployed in the real world. To this end, we introduce HAMBO, which builds on an uncertainty-aware learned model of the transition dynamics. To form a conservative estimate of the policy\u2019s performance, HAMBO hallucinates worst-case trajectories that the policy may take, within the margin of the models\u2019 epistemic confidence regions. We prove that the resulting COPE estimates are valid lower bounds, and, under regularity conditions, show their convergence to the true expected return. Finally, we discuss scalable variants of our approach based on Bayesian Neural Networks and empirically demonstrate that they yield reliable and tight lower bounds in various continuous control environments.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/rothfuss23a/rothfuss23a.pdf",
        "supp": "",
        "pdf_size": 414126,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12618768973638423190&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "ETH Zurich, Switzerland; ETH Zurich, Switzerland; ETH Zurich, Switzerland; ETH Zurich, Switzerland; ETH Zurich, Switzerland",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "845732ab7b",
        "title": "Heavy-tailed linear bandit with Huber regression",
        "site": "https://proceedings.mlr.press/v216/kang23a.html",
        "author": "Minhyun Kang; Gi-Soo Kim",
        "abstract": "Linear bandit algorithms have been extensively studied and have shown successful in sequential decision tasks despite their simplicity. Many algorithms however work under the assumption that the reward is the sum of linear function of observed contexts and a sub-Gaussian error. In practical applications, errors can be heavy-tailed, especially in financial data. In such reward environments, algorithms designed for sub-Gaussian error may underexplore, resulting in suboptimal regret. In this paper, we relax the reward assumption and propose a novel linear bandit algorithm which works well under heavy-tailed errors as well. The proposed algorithm utilizes Huber regression. When contexts are stochastic with positive definite covariance matrix and the $(1+\\delta)$-th moment of the error is bounded by a constant, we show that the high-probability upper bound of the regret is $O(\\sqrt{d}T^{\\frac{1}{1+\\delta}}(\\log dT)^{\\frac{\\delta}{1+\\delta}})$, where $d$ is the dimension of context variables, $T$ is the time horizon, and $\\delta\\in (0,1]$. This bound improves on the state-of-the-art regret bound of the Median of Means and Truncation algorithm by a factor of $\\sqrt{\\log T}$ and $\\sqrt{d}$ for the case where the time horizon $T$ is unknown. We also remark that when $\\delta=1$, the order is the same as the regret bound of linear bandit algorithms designed for sub-Gaussian errors. We support our theoretical findings with synthetic experiments.",
        "bibtex": "@InProceedings{pmlr-v216-kang23a,\n  title = \t {Heavy-tailed linear bandit with {H}uber regression},\n  author =       {Kang, Minhyun and Kim, Gi-Soo},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1027--1036},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/kang23a/kang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/kang23a.html},\n  abstract = \t {Linear bandit algorithms have been extensively studied and have shown successful in sequential decision tasks despite their simplicity. Many algorithms however work under the assumption that the reward is the sum of linear function of observed contexts and a sub-Gaussian error. In practical applications, errors can be heavy-tailed, especially in financial data. In such reward environments, algorithms designed for sub-Gaussian error may underexplore, resulting in suboptimal regret. In this paper, we relax the reward assumption and propose a novel linear bandit algorithm which works well under heavy-tailed errors as well. The proposed algorithm utilizes Huber regression. When contexts are stochastic with positive definite covariance matrix and the $(1+\\delta)$-th moment of the error is bounded by a constant, we show that the high-probability upper bound of the regret is $O(\\sqrt{d}T^{\\frac{1}{1+\\delta}}(\\log dT)^{\\frac{\\delta}{1+\\delta}})$, where $d$ is the dimension of context variables, $T$ is the time horizon, and $\\delta\\in (0,1]$. This bound improves on the state-of-the-art regret bound of the Median of Means and Truncation algorithm by a factor of $\\sqrt{\\log T}$ and $\\sqrt{d}$ for the case where the time horizon $T$ is unknown. We also remark that when $\\delta=1$, the order is the same as the regret bound of linear bandit algorithms designed for sub-Gaussian errors. We support our theoretical findings with synthetic experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/kang23a/kang23a.pdf",
        "supp": "",
        "pdf_size": 332431,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10652702260097450619&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Artificial Intelligence Graduate School, UNIST, Ulsan, Republic of Korea; Artificial Intelligence Graduate School, UNIST, Ulsan, Republic of Korea + Department of Industrial Engineering, UNIST, Ulsan, Republic of Korea",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology;UNIST",
        "aff_unique_dep": "Artificial Intelligence Graduate School;Department of Industrial Engineering",
        "aff_unique_url": "https://www.unist.ac.kr;https://www.unist.ac.kr",
        "aff_unique_abbr": "UNIST;UNIST",
        "aff_campus_unique_index": "0;0+0",
        "aff_campus_unique": "Ulsan",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "e84cf7ca7c",
        "title": "Heteroskedastic Geospatial Tracking with Distributed Camera Networks",
        "site": "https://proceedings.mlr.press/v216/samplawski23a.html",
        "author": "Colin Samplawski; Shiwei Fang; Ziqi Wang; Deepak Ganesan; Mani Srivastava; Benjamin M. Marlin",
        "abstract": "Visual object tracking has seen significant progress in recent years. However, the vast majority of this work focuses on tracking objects within the image plane of a single camera and ignores the uncertainty associated with predicted object locations. In this work, we focus on the geospatial object tracking problem using data from a distributed camera network. The goal is to predict an object\u2019s track in geospatial coordinates along with uncertainty over the object\u2019s location while respecting communication constraints that prohibit centralizing raw image data. We present a novel single-object geospatial tracking data set that includes high-accuracy ground truth object locations and video data from a network of four cameras. We present a modeling framework for addressing this task including a novel backbone model and explore how uncertainty calibration and fine-tuning through a differentiable tracker affect performance.",
        "bibtex": "@InProceedings{pmlr-v216-samplawski23a,\n  title = \t {Heteroskedastic Geospatial Tracking with Distributed Camera Networks},\n  author =       {Samplawski, Colin and Fang, Shiwei and Wang, Ziqi and Ganesan, Deepak and Srivastava, Mani and Marlin, Benjamin M.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1805--1814},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/samplawski23a/samplawski23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/samplawski23a.html},\n  abstract = \t {Visual object tracking has seen significant progress in recent years. However, the vast majority of this work focuses on tracking objects within the image plane of a single camera and ignores the uncertainty associated with predicted object locations. In this work, we focus on the geospatial object tracking problem using data from a distributed camera network. The goal is to predict an object\u2019s track in geospatial coordinates along with uncertainty over the object\u2019s location while respecting communication constraints that prohibit centralizing raw image data. We present a novel single-object geospatial tracking data set that includes high-accuracy ground truth object locations and video data from a network of four cameras. We present a modeling framework for addressing this task including a novel backbone model and explore how uncertainty calibration and fine-tuning through a differentiable tracker affect performance.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/samplawski23a/samplawski23a.pdf",
        "supp": "",
        "pdf_size": 3128409,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3650836150563950687&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "5907fd0d51",
        "title": "How to use dropout correctly on residual networks with batch normalization",
        "site": "https://proceedings.mlr.press/v216/kim23a.html",
        "author": "Bum Jun Kim; Hyeyeon Choi; Hyeonah Jang; Donggeon Lee; Sang Woo Kim",
        "abstract": "For the stable optimization of deep neural networks, regularization methods such as dropout and batch normalization have been used in various tasks. Nevertheless, the correct position to apply dropout has rarely been discussed, and different positions have been employed depending on the practitioners. In this study, we investigate the correct position to apply dropout. We demonstrate that for a residual network with batch normalization, applying dropout at certain positions increases the performance, whereas applying dropout at other positions decreases the performance. Based on theoretical analysis, we provide the following guideline for the correct position to apply dropout: apply one dropout after the last batch normalization but before the last weight layer in the residual branch. We provide detailed theoretical explanations to support this claim and demonstrate them through module tests. In addition, we investigate the correct position of dropout in the head that produces the final prediction. Although the current consensus is to apply dropout after global average pooling, we prove that applying dropout before global average pooling leads to a more stable output. The proposed guidelines are validated through experiments using different datasets and models.",
        "bibtex": "@InProceedings{pmlr-v216-kim23a,\n  title = \t {How to use dropout correctly on residual networks with batch normalization},\n  author =       {Kim, Bum Jun and Choi, Hyeyeon and Jang, Hyeonah and Lee, Donggeon and Kim, Sang Woo},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1058--1067},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/kim23a/kim23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/kim23a.html},\n  abstract = \t {For the stable optimization of deep neural networks, regularization methods such as dropout and batch normalization have been used in various tasks. Nevertheless, the correct position to apply dropout has rarely been discussed, and different positions have been employed depending on the practitioners. In this study, we investigate the correct position to apply dropout. We demonstrate that for a residual network with batch normalization, applying dropout at certain positions increases the performance, whereas applying dropout at other positions decreases the performance. Based on theoretical analysis, we provide the following guideline for the correct position to apply dropout: apply one dropout after the last batch normalization but before the last weight layer in the residual branch. We provide detailed theoretical explanations to support this claim and demonstrate them through module tests. In addition, we investigate the correct position of dropout in the head that produces the final prediction. Although the current consensus is to apply dropout after global average pooling, we prove that applying dropout before global average pooling leads to a more stable output. The proposed guidelines are validated through experiments using different datasets and models.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/kim23a/kim23a.pdf",
        "supp": "",
        "pdf_size": 666789,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2818033489426578563&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, South Korea; Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, South Korea; Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, South Korea; Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, South Korea; Department of Electrical Engineering, Pohang University of Science and Technology, Pohang, South Korea",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Pohang University of Science and Technology",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.postech.ac.kr",
        "aff_unique_abbr": "POSTECH",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pohang",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "0bd1d31448",
        "title": "Human Control: Definitions and Algorithms",
        "site": "https://proceedings.mlr.press/v216/carey23a.html",
        "author": "Ryan Carey; Tom Everitt",
        "abstract": "How can humans stay in control of advanced artificial intelligence systems? One proposal is corrigibility, which requires the agent to follow the instructions of a human overseer, without inappropriately influencing them. In this paper, we formally define a variant of corrigibility called shutdown instructability, and show that it implies appropriate shutdown behavior, retention of human autonomy, and avoidance of user harm. We also analyse the related concepts of non-obstruction and shutdown alignment, three previously proposed algorithms for human control, and one new algorithm.",
        "bibtex": "@InProceedings{pmlr-v216-carey23a,\n  title = \t {Human Control: Definitions and Algorithms},\n  author =       {Carey, Ryan and Everitt, Tom},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {271--281},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/carey23a/carey23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/carey23a.html},\n  abstract = \t {How can humans stay in control of advanced artificial intelligence systems? One proposal is corrigibility, which requires the agent to follow the instructions of a human overseer, without inappropriately influencing them. In this paper, we formally define a variant of corrigibility called shutdown instructability, and show that it implies appropriate shutdown behavior, retention of human autonomy, and avoidance of user harm. We also analyse the related concepts of non-obstruction and shutdown alignment, three previously proposed algorithms for human control, and one new algorithm.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/carey23a/carey23a.pdf",
        "supp": "",
        "pdf_size": 354718,
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2934490317465724178&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Statistics, Oxford University, UK; DeepMind, UK",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Oxford University;DeepMind",
        "aff_unique_dep": "Department of Statistics;",
        "aff_unique_url": "https://www.ox.ac.uk;https://deepmind.com",
        "aff_unique_abbr": "Oxford;DeepMind",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Oxford;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "997c73268f",
        "title": "Human-in-the-Loop Mixup",
        "site": "https://proceedings.mlr.press/v216/collins23a.html",
        "author": "Katherine M. Collins; Umang Bhatt; Weiyang Liu; Vihari Piratla; Ilia Sucholutsky; Bradley Love; Adrian Weller",
        "abstract": "Aligning model representations to humans has been found to improve robustness and generalization. However, such methods often focus on standard observational data. Synthetic data is proliferating and powering many advances in machine learning; yet, it is not always clear whether synthetic labels are perceptually aligned to humans \u2013 rendering it likely model representations are not human aligned. We focus on the synthetic data used in mixup: a powerful regularizer shown to improve model robustness, generalization, and calibration. We design a comprehensive series of elicitation interfaces, which we release as HILL MixE Suite, and recruit 159 participants to provide perceptual judgments along with their uncertainties, over mixup examples. We find that human perceptions do not consistently align with the labels traditionally used for synthetic points, and begin to demonstrate the applicability of these findings to potentially increase the reliability of downstream models, particularly when incorporating human uncertainty. We release all elicited judgments in a new data hub we call H-Mix.",
        "bibtex": "@InProceedings{pmlr-v216-collins23a,\n  title = \t {Human-in-the-Loop Mixup},\n  author =       {Collins, Katherine M. and Bhatt, Umang and Liu, Weiyang and Piratla, Vihari and Sucholutsky, Ilia and Love, Bradley and Weller, Adrian},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {454--464},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/collins23a/collins23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/collins23a.html},\n  abstract = \t {Aligning model representations to humans has been found to improve robustness and generalization. However, such methods often focus on standard observational data. Synthetic data is proliferating and powering many advances in machine learning; yet, it is not always clear whether synthetic labels are perceptually aligned to humans \u2013 rendering it likely model representations are not human aligned. We focus on the synthetic data used in mixup: a powerful regularizer shown to improve model robustness, generalization, and calibration. We design a comprehensive series of elicitation interfaces, which we release as HILL MixE Suite, and recruit 159 participants to provide perceptual judgments along with their uncertainties, over mixup examples. We find that human perceptions do not consistently align with the labels traditionally used for synthetic points, and begin to demonstrate the applicability of these findings to potentially increase the reliability of downstream models, particularly when incorporating human uncertainty. We release all elicited judgments in a new data hub we call H-Mix.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/collins23a/collins23a.pdf",
        "supp": "",
        "pdf_size": 2171018,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3450120013890115328&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "University of Cambridge; University of Cambridge + The Alan Turing Institute; University of Cambridge + Max Planck Institute for Intelligent Systems; University of Cambridge; Princeton University; The Alan Turing Institute + University College London; University of Cambridge + The Alan Turing Institute",
        "aff_domain": "cam.ac.uk; ; ; ; ; ; ",
        "email": "cam.ac.uk; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;0+2;0;3;1+4;0+1",
        "aff_unique_norm": "University of Cambridge;Alan Turing Institute;Max Planck Institute for Intelligent Systems;Princeton University;University College London",
        "aff_unique_dep": ";;Intelligent Systems;;",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.turing.ac.uk;https://www.mpi-is.mpg.de;https://www.princeton.edu;https://www.ucl.ac.uk",
        "aff_unique_abbr": "Cambridge;ATI;MPI-IS;Princeton;UCL",
        "aff_campus_unique_index": "0;0;0;0;;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0+0;0+1;0;2;0+0;0+0",
        "aff_country_unique": "United Kingdom;Germany;United States"
    },
    {
        "id": "11bc9bf250",
        "title": "Implicit Training of Inference Network Models for Structured Prediction",
        "site": "https://proceedings.mlr.press/v216/shankar23a.html",
        "author": "Shiv Shankar",
        "abstract": "Most research in deep learning has predominantly focused on the development of new models and training procedures. In contrast, the exploration of training objectives has received considerably less attention, often limited to combinations of standard losses. When dealing with complex structured outputs, the effectiveness of conventional objectives as proxies for the true objective becomes can be questionable. In this study, we propose that existing inference network-based methods for structured prediction, as observed in previous works [Tu and Gimpel, 2018, Tu et al., 2020a], indirectly learn to optimize a dynamic loss objective parameterized by the energy model. Based on this insight, we propose a method that treats the energy network as a trainable loss function and employs an implicit-gradient-based technique to learn the corresponding dynamic objective. We experiment with multiple tasks such as multi-label classification, entity recognition etc., and find significant performance improvements over baseline approaches. Our results demonstrate that implicitly learning a dynamic loss landscape proves to be an effective approach for enhancing model performance in structured prediction tasks.",
        "bibtex": "@InProceedings{pmlr-v216-shankar23a,\n  title = \t {Implicit Training of Inference Network Models for Structured Prediction},\n  author =       {Shankar, Shiv},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1889--1899},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/shankar23a/shankar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/shankar23a.html},\n  abstract = \t {Most research in deep learning has predominantly focused on the development of new models and training procedures. In contrast, the exploration of training objectives has received considerably less attention, often limited to combinations of standard losses. When dealing with complex structured outputs, the effectiveness of conventional objectives as proxies for the true objective becomes can be questionable. In this study, we propose that existing inference network-based methods for structured prediction, as observed in previous works [Tu and Gimpel, 2018, Tu et al., 2020a], indirectly learn to optimize a dynamic loss objective parameterized by the energy model. Based on this insight, we propose a method that treats the energy network as a trainable loss function and employs an implicit-gradient-based technique to learn the corresponding dynamic objective. We experiment with multiple tasks such as multi-label classification, entity recognition etc., and find significant performance improvements over baseline approaches. Our results demonstrate that implicitly learning a dynamic loss landscape proves to be an effective approach for enhancing model performance in structured prediction tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/shankar23a/shankar23a.pdf",
        "supp": "",
        "pdf_size": 269862,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:UcHhJ_sSAkIJ:scholar.google.com/&scioq=Implicit+Training+of+Inference+Network+Models+for+Structured+Prediction&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "aff": "University of Massachusetts, USA",
        "aff_domain": "",
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Massachusetts",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a0122167e2",
        "title": "Improvable Gap Balancing for Multi-Task Learning",
        "site": "https://proceedings.mlr.press/v216/dai23a.html",
        "author": "Yanqi Dai; Nanyi Fei; Zhiwu Lu",
        "abstract": "In multi-task learning (MTL), gradient balancing has recently attracted more research interest than loss balancing since it often leads to better performance. However, loss balancing is much more efficient than gradient balancing, and thus it is still worth further exploration in MTL. Note that prior studies typically ignore that there exist varying improvable gaps across multiple tasks, where the improvable gap per task is defined as the distance between the current training progress and desired final training progress. Therefore, after loss balancing, the performance imbalance still arises in many cases. In this paper, following the loss balancing framework, we propose two novel improvable gap balancing (IGB) algorithms for MTL: one takes a simple heuristic, and the other (for the first time) deploys deep reinforcement learning for MTL. Particularly, instead of directly balancing the losses in MTL, both algorithms choose to dynamically assign task weights for improvable gap balancing. Moreover, we combine IGB and gradient balancing to show the complementarity between the two types of algorithms. Extensive experiments on two benchmark datasets demonstrate that our IGB algorithms lead to the best results in MTL via loss balancing and achieve further improvements when combined with gradient balancing. Code is available at https://github.com/YanqiDai/IGB4MTL.",
        "bibtex": "@InProceedings{pmlr-v216-dai23a,\n  title = \t {Improvable Gap Balancing for Multi-Task Learning},\n  author =       {Dai, Yanqi and Fei, Nanyi and Lu, Zhiwu},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {496--506},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/dai23a/dai23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/dai23a.html},\n  abstract = \t {In multi-task learning (MTL), gradient balancing has recently attracted more research interest than loss balancing since it often leads to better performance. However, loss balancing is much more efficient than gradient balancing, and thus it is still worth further exploration in MTL. Note that prior studies typically ignore that there exist varying improvable gaps across multiple tasks, where the improvable gap per task is defined as the distance between the current training progress and desired final training progress. Therefore, after loss balancing, the performance imbalance still arises in many cases. In this paper, following the loss balancing framework, we propose two novel improvable gap balancing (IGB) algorithms for MTL: one takes a simple heuristic, and the other (for the first time) deploys deep reinforcement learning for MTL. Particularly, instead of directly balancing the losses in MTL, both algorithms choose to dynamically assign task weights for improvable gap balancing. Moreover, we combine IGB and gradient balancing to show the complementarity between the two types of algorithms. Extensive experiments on two benchmark datasets demonstrate that our IGB algorithms lead to the best results in MTL via loss balancing and achieve further improvements when combined with gradient balancing. Code is available at https://github.com/YanqiDai/IGB4MTL.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/dai23a/dai23a.pdf",
        "supp": "",
        "pdf_size": 909456,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18126698146680658246&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "dc36f4f98a",
        "title": "In- or out-of-distribution detection via dual divergence estimation",
        "site": "https://proceedings.mlr.press/v216/garg23b.html",
        "author": "Sahil Garg; Sanghamitra Dutta; Mina Dalirrooyfard; Anderson Schneider; Yuriy Nevmyvaka",
        "abstract": "Detecting out-of-distribution (OOD) samples is a problem of practical importance for a reliable use of deep neural networks (DNNs) in production settings. The corollary to this problem is the detection in-distribution (ID) samples, which is applicable to domain adaptation scenarios for augmenting a train set with ID samples from other data sets, or to continual learning for replay from the past. For both ID or OOD detection, we propose a principled yet simple approach of (empirically) estimating KL-Divergence, in its dual form, for a given test set w.r.t. a known set of ID samples in order to quantify the contribution of each test sample individually towards the divergence measure and accordingly detect it as OOD or ID. Our approach is compute-efficient and enjoys strong theoretical guarantees. For WideResnet101 and ViT-L-16, by considering ImageNet-1k dataset as the ID benchmark, we evaluate the proposed OOD detector on 51 test (OOD) datasets, and observe drastically and consistently lower false positive rates w.r.t. all the competitive methods. Moreover, the proposed ID detector is evaluated, using ECG and stock price datasets, for the task of data augmentation in domain adaptation and continual learning settings, and we observe higher efficacy compared to relevant baselines.",
        "bibtex": "@InProceedings{pmlr-v216-garg23b,\n  title = \t {In- or out-of-distribution detection via dual divergence estimation},\n  author =       {Garg, Sahil and Dutta, Sanghamitra and Dalirrooyfard, Mina and Schneider, Anderson and Nevmyvaka, Yuriy},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {635--646},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/garg23b/garg23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/garg23b.html},\n  abstract = \t {Detecting out-of-distribution (OOD) samples is a problem of practical importance for a reliable use of deep neural networks (DNNs) in production settings. The corollary to this problem is the detection in-distribution (ID) samples, which is applicable to domain adaptation scenarios for augmenting a train set with ID samples from other data sets, or to continual learning for replay from the past. For both ID or OOD detection, we propose a principled yet simple approach of (empirically) estimating KL-Divergence, in its dual form, for a given test set w.r.t. a known set of ID samples in order to quantify the contribution of each test sample individually towards the divergence measure and accordingly detect it as OOD or ID. Our approach is compute-efficient and enjoys strong theoretical guarantees. For WideResnet101 and ViT-L-16, by considering ImageNet-1k dataset as the ID benchmark, we evaluate the proposed OOD detector on 51 test (OOD) datasets, and observe drastically and consistently lower false positive rates w.r.t. all the competitive methods. Moreover, the proposed ID detector is evaluated, using ECG and stock price datasets, for the task of data augmentation in domain adaptation and continual learning settings, and we observe higher efficacy compared to relevant baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/garg23b/garg23b.pdf",
        "supp": "",
        "pdf_size": 991724,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12097871824305807712&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Dept. of Machine Learning Research, Morgan Stanley, New York, New York, USA; Dept. of Electrical and Computer Engineering, University of Maryland, College Park, Maryland, USA; Dept. of Machine Learning Research, Morgan Stanley, New York, New York, USA; Dept. of Machine Learning Research, Morgan Stanley, New York, New York, USA; Dept. of Machine Learning Research, Morgan Stanley, New York, New York, USA",
        "aff_domain": "morganstanley.com;gmail.com; ; ; ",
        "email": "morganstanley.com;gmail.com; ; ; ",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Morgan Stanley;University of Maryland, College Park",
        "aff_unique_dep": "Dept. of Machine Learning Research;Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.morganstanley.com;https://www/umd.edu",
        "aff_unique_abbr": "MS;UMD",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";College Park",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "882f075296",
        "title": "Incentivising Diffusion while Preserving Differential Privacy",
        "site": "https://proceedings.mlr.press/v216/jia23a.html",
        "author": "Fengjuan. Jia; Mengxiao. Zhang; Jiamou. Liu; Bakh Khoussainov",
        "abstract": "Diffusion auction refers to an emerging paradigm of online marketplace where an auctioneer utilises a social network to attract potential buyers.  Diffusion auction poses significant privacy risks. From the auction outcome, it is possible to infer hidden, and potentially sensitive, preferences of buyers. To mitigate such risks, we initiate the study of differential privacy (DP) in diffusion auction mechanisms. DP is a well-established notion of privacy that protects a system against inference attacks. Achieving DP in diffusion auctions is non-trivial as the well-designed auction rules are required to incentivise the buyers to truthfully report their neighbourhood. We study the single-unit case and design two differentially private diffusion mechanisms (DPDMs): recursive DPDM and layered DPDM. We prove that these mechanisms guarantee differential privacy, incentive compatibility and individual rationality for both valuations and neighbourhood. We then empirically compare their performance on real and synthetic datasets.",
        "bibtex": "@InProceedings{pmlr-v216-jia23a,\n  title = \t {Incentivising Diffusion while Preserving Differential Privacy},\n  author =       {Jia, Fengjuan. and Zhang, Mengxiao. and Liu, Jiamou. and Khoussainov, Bakh},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {963--972},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/jia23a/jia23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/jia23a.html},\n  abstract = \t {Diffusion auction refers to an emerging paradigm of online marketplace where an auctioneer utilises a social network to attract potential buyers.  Diffusion auction poses significant privacy risks. From the auction outcome, it is possible to infer hidden, and potentially sensitive, preferences of buyers. To mitigate such risks, we initiate the study of differential privacy (DP) in diffusion auction mechanisms. DP is a well-established notion of privacy that protects a system against inference attacks. Achieving DP in diffusion auctions is non-trivial as the well-designed auction rules are required to incentivise the buyers to truthfully report their neighbourhood. We study the single-unit case and design two differentially private diffusion mechanisms (DPDMs): recursive DPDM and layered DPDM. We prove that these mechanisms guarantee differential privacy, incentive compatibility and individual rationality for both valuations and neighbourhood. We then empirically compare their performance on real and synthetic datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/jia23a/jia23a.pdf",
        "supp": "",
        "pdf_size": 2068091,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10405408889507267431&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "263e50c6cd",
        "title": "Incentivizing honest performative predictions with proper scoring rules",
        "site": "https://proceedings.mlr.press/v216/oesterheld23a.html",
        "author": "Caspar Oesterheld; Johannes Treutlein; Emery Cooper; Rubi Hudson",
        "abstract": "Proper scoring rules incentivize experts to accurately report beliefs, assuming predictions cannot influence outcomes. We relax this assumption and investigate incentives when predictions are performative, i.e., when they can influence the outcome of the prediction, such as when making public predictions about the stock market. We say a prediction is a fixed point if it accurately reflects the expert\u2019s beliefs after that prediction has been made. We show that in this setting, reports maximizing expected score generally do not reflect an expert\u2019s beliefs, and we give bounds on the inaccuracy of such reports. We show that, for binary predictions, if the influence of the expert\u2019s prediction on outcomes is bounded, it is possible to define scoring rules under which optimal reports are arbitrarily close to fixed points. However, this is impossible for predictions over more than two outcomes. We also perform numerical simulations in a toy setting, showing that our bounds are tight in some situations and that prediction error is often substantial (greater than 5-10%). Lastly, we discuss alternative notions of optimality, including performative stability, and show that they incentivize reporting fixed points.",
        "bibtex": "@InProceedings{pmlr-v216-oesterheld23a,\n  title = \t {Incentivizing honest performative predictions with proper scoring rules},\n  author =       {Oesterheld, Caspar and Treutlein, Johannes and Cooper, Emery and Hudson, Rubi},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1564--1574},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/oesterheld23a/oesterheld23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/oesterheld23a.html},\n  abstract = \t {Proper scoring rules incentivize experts to accurately report beliefs, assuming predictions cannot influence outcomes. We relax this assumption and investigate incentives when predictions are performative, i.e., when they can influence the outcome of the prediction, such as when making public predictions about the stock market. We say a prediction is a fixed point if it accurately reflects the expert\u2019s beliefs after that prediction has been made. We show that in this setting, reports maximizing expected score generally do not reflect an expert\u2019s beliefs, and we give bounds on the inaccuracy of such reports. We show that, for binary predictions, if the influence of the expert\u2019s prediction on outcomes is bounded, it is possible to define scoring rules under which optimal reports are arbitrarily close to fixed points. However, this is impossible for predictions over more than two outcomes. We also perform numerical simulations in a toy setting, showing that our bounds are tight in some situations and that prediction error is often substantial (greater than 5-10%). Lastly, we discuss alternative notions of optimality, including performative stability, and show that they incentivize reporting fixed points.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/oesterheld23a/oesterheld23a.pdf",
        "supp": "",
        "pdf_size": 1933028,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13410756014368578014&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "7b53d49f40",
        "title": "Increasing effect sizes of pairwise conditional independence tests between random vectors",
        "site": "https://proceedings.mlr.press/v216/hochsprung23a.html",
        "author": "Tom Hochsprung; Jonas Wahl; Andreas Gerhardus; Urmi Ninad; Jakob Runge",
        "abstract": "A simple approach to test for conditional independence of two random vectors given a third random vector is to simultaneously test for conditional independence of every pair of components of the two random vectors given the third random vector. In this work, we show that conditioning on additional components of the two random vectors that are independent given the third one increases the tests\u2019 effect sizes while leaving the validity of the overall approach unchanged. We leverage this result to derive a practical pairwise testing algorithm that first chooses tests with a relatively large effect size and then does the actual testing. We show both numerically and theoretically that our algorithm outperforms standard pairwise independence testing and other existing methods if the dependence within the two random vectors is sufficiently high.",
        "bibtex": "@InProceedings{pmlr-v216-hochsprung23a,\n  title = \t {Increasing effect sizes of pairwise conditional independence tests between random vectors},\n  author =       {Hochsprung, Tom and Wahl, Jonas and Gerhardus, Andreas and Ninad, Urmi and Runge, Jakob},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {879--889},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/hochsprung23a/hochsprung23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/hochsprung23a.html},\n  abstract = \t {A simple approach to test for conditional independence of two random vectors given a third random vector is to simultaneously test for conditional independence of every pair of components of the two random vectors given the third random vector. In this work, we show that conditioning on additional components of the two random vectors that are independent given the third one increases the tests\u2019 effect sizes while leaving the validity of the overall approach unchanged. We leverage this result to derive a practical pairwise testing algorithm that first chooses tests with a relatively large effect size and then does the actual testing. We show both numerically and theoretically that our algorithm outperforms standard pairwise independence testing and other existing methods if the dependence within the two random vectors is sufficiently high.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/hochsprung23a/hochsprung23a.pdf",
        "supp": "",
        "pdf_size": 1255894,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14628101513498356820&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8d4dc78cd9",
        "title": "Inference and sampling of point processes from diffusion excursions",
        "site": "https://proceedings.mlr.press/v216/hasan23a.html",
        "author": "Ali Hasan; Yu Chen; Yuting Ng; Mohamed Abdelghani; Anderson Schneider; Vahid Tarokh",
        "abstract": "Point processes often have a natural interpretation with respect to a continuous process. We propose a point process construction that describes arrival time observations in terms of the state of a latent diffusion process. In this framework, we relate the return times of a diffusion in a continuous path space to new arrivals of the point process. This leads to a continuous sample path that is used to describe the underlying mechanism generating the arrival distribution. These models arise in many disciplines, such as financial settings where actions in a market are determined by a hidden continuous price or in neuroscience where a latent stimulus generates spike trains. Based on the developments in It\u00f4\u2019s excursion theory, we propose methods for inferring and sampling from the point process derived from the latent diffusion process. We illustrate the approach with numerical examples using both simulated and real data. The proposed methods and framework provide a basis for interpreting point processes through the lens of diffusions.",
        "bibtex": "@InProceedings{pmlr-v216-hasan23a,\n  title = \t {Inference and sampling of point processes from diffusion excursions},\n  author =       {Hasan, Ali and Chen, Yu and Ng, Yuting and Abdelghani, Mohamed and Schneider, Anderson and Tarokh, Vahid},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {839--848},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/hasan23a/hasan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/hasan23a.html},\n  abstract = \t {Point processes often have a natural interpretation with respect to a continuous process. We propose a point process construction that describes arrival time observations in terms of the state of a latent diffusion process. In this framework, we relate the return times of a diffusion in a continuous path space to new arrivals of the point process. This leads to a continuous sample path that is used to describe the underlying mechanism generating the arrival distribution. These models arise in many disciplines, such as financial settings where actions in a market are determined by a hidden continuous price or in neuroscience where a latent stimulus generates spike trains. Based on the developments in It\u00f4\u2019s excursion theory, we propose methods for inferring and sampling from the point process derived from the latent diffusion process. We illustrate the approach with numerical examples using both simulated and real data. The proposed methods and framework provide a basis for interpreting point processes through the lens of diffusions.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/hasan23a/hasan23a.pdf",
        "supp": "",
        "pdf_size": 1929848,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18033143506362732643&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "253e895e47",
        "title": "Inference for mark-censored temporal point processes",
        "site": "https://proceedings.mlr.press/v216/boyd23a.html",
        "author": "Alex Boyd; Yuxin Chang; Stephan Mandt; Padhraic Smyth",
        "abstract": "Marked temporal point processes (MTPPs) are a general class of stochastic models for modeling the evolution of events of different types (\u201cmarks\u201d) in continuous time. These models have broad applications in areas such as medical data monitoring, financial prediction, user modeling, and communication networks. Of significant practical interest in such problems is the issue of missing or censored data over time. In this paper, we focus on the specific problem of inference for a trained MTPP model when events of certain types are not observed over a period of time during prediction. We introduce the concept of mark-censored sub-processes and use this framework to develop a novel marginalization technique for inference in the presence of censored marks. The approach is model-agnostic and applicable to any MTPP model with a well-defined intensity function. We illustrate the flexibility and utility of the method in the context of both parametric and neural MTPP models, with results across a range of datasets including data from simulated Hawkes processes, self-correcting processes, and multiple real-world event datasets.",
        "bibtex": "@InProceedings{pmlr-v216-boyd23a,\n  title = \t {Inference for mark-censored temporal point processes},\n  author =       {Boyd, Alex and Chang, Yuxin and Mandt, Stephan and Smyth, Padhraic},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {226--236},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/boyd23a/boyd23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/boyd23a.html},\n  abstract = \t {Marked temporal point processes (MTPPs) are a general class of stochastic models for modeling the evolution of events of different types (\u201cmarks\u201d) in continuous time. These models have broad applications in areas such as medical data monitoring, financial prediction, user modeling, and communication networks. Of significant practical interest in such problems is the issue of missing or censored data over time. In this paper, we focus on the specific problem of inference for a trained MTPP model when events of certain types are not observed over a period of time during prediction. We introduce the concept of mark-censored sub-processes and use this framework to develop a novel marginalization technique for inference in the presence of censored marks. The approach is model-agnostic and applicable to any MTPP model with a well-defined intensity function. We illustrate the flexibility and utility of the method in the context of both parametric and neural MTPP models, with results across a range of datasets including data from simulated Hawkes processes, self-correcting processes, and multiple real-world event datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/boyd23a/boyd23a.pdf",
        "supp": "",
        "pdf_size": 794428,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11130309922917810461&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "e9faf31fad",
        "title": "Inference for probabilistic dependency graphs",
        "site": "https://proceedings.mlr.press/v216/richardson23a.html",
        "author": "Oliver E. Richardson; Joseph Y. Halpern; Christopher De Sa",
        "abstract": "Probabilistic dependency graphs (PDGs) are a flexible class of probabilistic graphical models, subsuming Bayesian Networks and Factor Graphs. They can also capture inconsistent beliefs, and provide a way of measuring the degree of this inconsistency. We present the first tractable inference algorithm for PDGs with discrete variables, making the asymptotic complexity of PDG inference similar that of the graphical models they generalize. The key components are: (1) the observation that PDG inference can be reduced to convex optimization with exponential cone constraints, (2) a construction that allows us to express these problems compactly for PDGs of boundeed treewidth, for which we needed to further develop the theory of PDGs, and (3) an appeal to interior point methods that can solve such problems in polynomial time. We verify the correctness and time complexity of our approach, and provide an implementation of it. We then evaluate our implementation, and demonstrate that it outperforms baseline approaches.",
        "bibtex": "@InProceedings{pmlr-v216-richardson23a,\n  title = \t {Inference for probabilistic dependency graphs},\n  author =       {Richardson, Oliver E. and Halpern, Joseph Y. and De Sa, Christopher},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1741--1751},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/richardson23a/richardson23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/richardson23a.html},\n  abstract = \t {Probabilistic dependency graphs (PDGs) are a flexible class of probabilistic graphical models, subsuming Bayesian Networks and Factor Graphs. They can also capture inconsistent beliefs, and provide a way of measuring the degree of this inconsistency. We present the first tractable inference algorithm for PDGs with discrete variables, making the asymptotic complexity of PDG inference similar that of the graphical models they generalize. The key components are: (1) the observation that PDG inference can be reduced to convex optimization with exponential cone constraints, (2) a construction that allows us to express these problems compactly for PDGs of boundeed treewidth, for which we needed to further develop the theory of PDGs, and (3) an appeal to interior point methods that can solve such problems in polynomial time. We verify the correctness and time complexity of our approach, and provide an implementation of it. We then evaluate our implementation, and demonstrate that it outperforms baseline approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/richardson23a/richardson23a.pdf",
        "supp": "",
        "pdf_size": 3521576,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11492695986644455579&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f3d650b85b",
        "title": "Inference of a rumor\u2019s source in the independent cascade model",
        "site": "https://proceedings.mlr.press/v216/berenbrink23a.html",
        "author": "Petra Berenbrink; Max Hahn-Klimroth; Dominik Kaaser; Lena Krieg; Malin Rau",
        "abstract": "We consider the so-called Independent Cascade Model for rumor spreading or epidemic processes popularized by Kempe et al. (2003). In this model, a node of a network is the source of a rumor \u2013 it is informed. In discrete time steps, each informed node \u201cinfects\u201d each of its uninformed neighbors with probability p. While many facets of this process are studied in the literature, less is known about the inference problem: given a number of infected nodes in a network, can we learn the source of the rumor? In the context of epidemiology this problem is often referred to as patient zero problem. It belongs to a broader class of problems where the goal is to infer parameters of the underlying spreading model. In this work we present a maximum likelihood estimator for the rumor\u2019s source, given a snapshot of the process in terms of a set of active nodes X after t steps. Our results show that, for acyclic graphs,  the likelihood estimator undergoes a phase transition as a function of $t$. We provide a rigorous analysis for two prominent classes of acyclic network, namely d-regular trees and Galton-Watson trees, and verify empirically that our heuristics work well in various general networks.",
        "bibtex": "@InProceedings{pmlr-v216-berenbrink23a,\n  title = \t {Inference of a rumor\u2019s source in the independent cascade model},\n  author =       {Berenbrink, Petra and Hahn-Klimroth, Max and Kaaser, Dominik and Krieg, Lena and Rau, Malin},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {152--162},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/berenbrink23a/berenbrink23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/berenbrink23a.html},\n  abstract = \t {We consider the so-called Independent Cascade Model for rumor spreading or epidemic processes popularized by Kempe et al. (2003). In this model, a node of a network is the source of a rumor \u2013 it is informed. In discrete time steps, each informed node \u201cinfects\u201d each of its uninformed neighbors with probability p. While many facets of this process are studied in the literature, less is known about the inference problem: given a number of infected nodes in a network, can we learn the source of the rumor? In the context of epidemiology this problem is often referred to as patient zero problem. It belongs to a broader class of problems where the goal is to infer parameters of the underlying spreading model. In this work we present a maximum likelihood estimator for the rumor\u2019s source, given a snapshot of the process in terms of a set of active nodes X after t steps. Our results show that, for acyclic graphs,  the likelihood estimator undergoes a phase transition as a function of $t$. We provide a rigorous analysis for two prominent classes of acyclic network, namely d-regular trees and Galton-Watson trees, and verify empirically that our heuristics work well in various general networks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/berenbrink23a/berenbrink23a.pdf",
        "supp": "",
        "pdf_size": 357237,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15746727706501174933&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Universit\u00e4t Hamburg, Hamburg, Germany; TU Dortmund University, Dortmund, Germany; TU Hamburg, Hamburg, Germany; TU Dortmund University, Dortmund, Germany; Universit\u00e4t Hamburg, Hamburg, Germany",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "Universit\u00e4t Hamburg;TU Dortmund University;Technische Universit\u00e4t Hamburg",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uni-hamburg.de;https://www.tu-dortmund.de;https://www.tuhh.de/",
        "aff_unique_abbr": "UHH;TUDO;TUHH",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Hamburg;Dortmund",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "5d7b04e5c4",
        "title": "Information theoretic clustering via divergence maximization among clusters",
        "site": "https://proceedings.mlr.press/v216/garg23a.html",
        "author": "Sahil Garg; Mina Dalirrooyfard; Anderson Schneider; Yeshaya Adler; Yuriy Nevmyvaka; Yu Chen; Fengpei Li; Guillermo Cecchi",
        "abstract": "Information-theoretic clustering is one of the most promising and principled approaches to finding clusters with minimal apriori assumptions. The key criterion therein is to maximize the mutual information between the data points and their cluster labels. Such an approach, however, does not explicitly promote any type of inter-cluster behavior. We instead propose to maximize the Kullback-Leibler divergence between the underlying data distributions associated to clusters (referred to as cluster distributions). We show it to entail the mutual information criterion along with maximizing cross entropy between the cluster distributions. For practical efficiency, we propose to empirically estimate the objective of KL-D between clusters in its dual form leveraging deep neural nets as a dual function approximator. Remarkably, our theoretical analysis establishes that estimating the divergence measure in its dual form simplifies the problem of clustering to one of optimally finding k-1 cut points for k clusters in the 1-D dual functional space. Overall, our approach enables linear-time clustering algorithms with theoretical guarantees of near-optimality, owing to the submodularity of the objective. We show the empirical superiority of our approach w.r.t. current state-of-the-art methods on the challenging task of clustering noisy timeseries as observed in domains such as neuroscience, healthcare, financial markets, spatio-temporal environmental dynamics, etc.",
        "bibtex": "@InProceedings{pmlr-v216-garg23a,\n  title = \t {Information theoretic clustering via divergence maximization among clusters},\n  author =       {Garg, Sahil and Dalirrooyfard, Mina and Schneider, Anderson and Adler, Yeshaya and Nevmyvaka, Yuriy and Chen, Yu and Li, Fengpei and Cecchi, Guillermo},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {624--634},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/garg23a/garg23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/garg23a.html},\n  abstract = \t {Information-theoretic clustering is one of the most promising and principled approaches to finding clusters with minimal apriori assumptions. The key criterion therein is to maximize the mutual information between the data points and their cluster labels. Such an approach, however, does not explicitly promote any type of inter-cluster behavior. We instead propose to maximize the Kullback-Leibler divergence between the underlying data distributions associated to clusters (referred to as cluster distributions). We show it to entail the mutual information criterion along with maximizing cross entropy between the cluster distributions. For practical efficiency, we propose to empirically estimate the objective of KL-D between clusters in its dual form leveraging deep neural nets as a dual function approximator. Remarkably, our theoretical analysis establishes that estimating the divergence measure in its dual form simplifies the problem of clustering to one of optimally finding k-1 cut points for k clusters in the 1-D dual functional space. Overall, our approach enables linear-time clustering algorithms with theoretical guarantees of near-optimality, owing to the submodularity of the objective. We show the empirical superiority of our approach w.r.t. current state-of-the-art methods on the challenging task of clustering noisy timeseries as observed in domains such as neuroscience, healthcare, financial markets, spatio-temporal environmental dynamics, etc.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/garg23a/garg23a.pdf",
        "supp": "",
        "pdf_size": 712704,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18081098759170585183&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Dept. of Machine Learning Research, Morgan Stanley, New York, New York, USA; Dept. of Machine Learning Research, Morgan Stanley, New York, New York, USA; Dept. of Machine Learning Research, Morgan Stanley, New York, New York, USA; Dept. of Machine Learning Research, Morgan Stanley, New York, New York, USA; Dept. of Machine Learning Research, Morgan Stanley, New York, New York, USA; Dept. of Machine Learning Research, Morgan Stanley, New York, New York, USA; Dept. of Machine Learning Research, Morgan Stanley, New York, New York, USA; IBM T. J. Watson Research Center, Yorktown Heights, New York, USA",
        "aff_domain": "morganstanley.com;gmail.com; ; ; ; ; ; ",
        "email": "morganstanley.com;gmail.com; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0;0;1",
        "aff_unique_norm": "Morgan Stanley;IBM",
        "aff_unique_dep": "Dept. of Machine Learning Research;IBM T. J. Watson Research Center",
        "aff_unique_url": "https://www.morganstanley.com;https://www.ibm.com/research/watson",
        "aff_unique_abbr": "MS;IBM Watson",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Yorktown Heights",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4294aab779",
        "title": "Interpretable differencing of machine learning models",
        "site": "https://proceedings.mlr.press/v216/haldar23a.html",
        "author": "Swagatam Haldar; Diptikalyan Saha; Dennis Wei; Rahul Nair; Elizabeth M. Daly",
        "abstract": "Understanding the differences between machine learning (ML) models is of interest in scenarios ranging from choosing amongst a set of competing models, to updating a deployed model with new training data. In these cases, we wish to go beyond differences in overall metrics such as accuracy to identify where in the feature space do the differences occur. We formalize this problem of model differencing as one of predicting a dissimilarity function of two ML models\u2019 outputs, subject to the representation of the differences being human-interpretable. Our solution is to learn a Joint Surrogate Tree (JST), which is composed of two conjoined decision tree surrogates for the two models. A JST provides an intuitive representation of differences and places the changes in the context of the models\u2019 decision logic. Context is important as it helps users to map differences to an underlying mental model of an AI system. We also propose a refinement procedure to increase the precision of a JST. We demonstrate, through an empirical evaluation, that such contextual differencing is concise and can be achieved with no loss in fidelity over naive approaches.",
        "bibtex": "@InProceedings{pmlr-v216-haldar23a,\n  title = \t {Interpretable differencing of machine learning models},\n  author =       {Haldar, Swagatam and Saha, Diptikalyan and Wei, Dennis and Nair, Rahul and Daly, Elizabeth M.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {788--797},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/haldar23a/haldar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/haldar23a.html},\n  abstract = \t {Understanding the differences between machine learning (ML) models is of interest in scenarios ranging from choosing amongst a set of competing models, to updating a deployed model with new training data. In these cases, we wish to go beyond differences in overall metrics such as accuracy to identify where in the feature space do the differences occur. We formalize this problem of model differencing as one of predicting a dissimilarity function of two ML models\u2019 outputs, subject to the representation of the differences being human-interpretable. Our solution is to learn a Joint Surrogate Tree (JST), which is composed of two conjoined decision tree surrogates for the two models. A JST provides an intuitive representation of differences and places the changes in the context of the models\u2019 decision logic. Context is important as it helps users to map differences to an underlying mental model of an AI system. We also propose a refinement procedure to increase the precision of a JST. We demonstrate, through an empirical evaluation, that such contextual differencing is concise and can be achieved with no loss in fidelity over naive approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/haldar23a/haldar23a.pdf",
        "supp": "",
        "pdf_size": 347211,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10429367605481329833&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "IBM Research, Bangalore, India; IBM Research, Bangalore, India; IBM Research, Yorktown Heights, New York, USA; IBM Research, Dublin, Ireland; IBM Research, Dublin, Ireland",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "IBM",
        "aff_unique_dep": "IBM Research",
        "aff_unique_url": "https://www.ibm.com/research",
        "aff_unique_abbr": "IBM",
        "aff_campus_unique_index": "0;0;1;2;2",
        "aff_campus_unique": "Bangalore;Yorktown Heights;Dublin",
        "aff_country_unique_index": "0;0;1;2;2",
        "aff_country_unique": "India;United States;Ireland"
    },
    {
        "id": "a8a523aeaf",
        "title": "Investigating a Generalization of Probabilistic Material Implication and Bayesian Conditionals",
        "site": "https://proceedings.mlr.press/v216/jahn23a.html",
        "author": "Michael Jahn; Matthias Scheutz",
        "abstract": "Probabilistic \"if A then B\" rules are typically formalized as Bayesian conditionals P(B|A), as many (e.g., Pearl) have argued that Bayesian conditionals are the correct way to think about such rules. However, there are challenges with standard inferences such as modus ponens and modus tollens that might make probabilistic material implication a better candidate at times for rule-based systems employing forward-chaining; and arguably material implication is still suitable when information about prior or conditional probabilities is not available at all.  We investigate a generalization of probabilistic material implication and Bayesian conditionals that combines the advantages of both formalisms in a systematic way and prove basic properties of the generalized rule, in particular, for inference chains in graphs.",
        "bibtex": "@InProceedings{pmlr-v216-jahn23a,\n  title = \t {Investigating a Generalization of Probabilistic Material Implication and {B}ayesian Conditionals},\n  author =       {Jahn, Michael and Scheutz, Matthias},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {932--940},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/jahn23a/jahn23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/jahn23a.html},\n  abstract = \t {Probabilistic \"if A then B\" rules are typically formalized as Bayesian conditionals P(B|A), as many (e.g., Pearl) have argued that Bayesian conditionals are the correct way to think about such rules. However, there are challenges with standard inferences such as modus ponens and modus tollens that might make probabilistic material implication a better candidate at times for rule-based systems employing forward-chaining; and arguably material implication is still suitable when information about prior or conditional probabilities is not available at all.  We investigate a generalization of probabilistic material implication and Bayesian conditionals that combines the advantages of both formalisms in a systematic way and prove basic properties of the generalized rule, in particular, for inference chains in graphs.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/jahn23a/jahn23a.pdf",
        "supp": "",
        "pdf_size": 2312970,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2229981017134896191&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Human-Robot Interaction Laboratory Department of Computer Science, Tufts University, Medford, MA 02155, USA; Human-Robot Interaction Laboratory Department of Computer Science, Tufts University, Medford, MA 02155, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tufts University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.tufts.edu",
        "aff_unique_abbr": "Tufts",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Medford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "aaad586100",
        "title": "Is the volume of a credal set a good measure for epistemic uncertainty?",
        "site": "https://proceedings.mlr.press/v216/sale23a.html",
        "author": "Yusuf Sale; Michele Caprio; Eyke H\u00f6llermeier",
        "abstract": "Adequate uncertainty representation and quantification have become imperative in various scientific disciplines, especially in machine learning and artificial intelligence. As an alternative to representing uncertainty via one single probability measure, we consider credal sets (convex sets of probability measures). The geometric representation of credal sets as d-dimensional polytopes implies a geometric intuition about (epistemic) uncertainty. In this paper, we show that the volume of the geometric representation of a credal set is a meaningful measure of epistemic uncertainty in the case of binary classification, but less so for multi-class classification. Our theoretical findings highlight the crucial role of specifying and employing  uncertainty measures in machine learning in an appropriate way, and for being aware of possible pitfalls.",
        "bibtex": "@InProceedings{pmlr-v216-sale23a,\n  title = \t {Is the volume of a credal set a good measure for epistemic uncertainty?},\n  author =       {Sale, Yusuf and Caprio, Michele and H\\\"{o}llermeier, Eyke},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1795--1804},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/sale23a/sale23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/sale23a.html},\n  abstract = \t {Adequate uncertainty representation and quantification have become imperative in various scientific disciplines, especially in machine learning and artificial intelligence. As an alternative to representing uncertainty via one single probability measure, we consider credal sets (convex sets of probability measures). The geometric representation of credal sets as d-dimensional polytopes implies a geometric intuition about (epistemic) uncertainty. In this paper, we show that the volume of the geometric representation of a credal set is a meaningful measure of epistemic uncertainty in the case of binary classification, but less so for multi-class classification. Our theoretical findings highlight the crucial role of specifying and employing  uncertainty measures in machine learning in an appropriate way, and for being aware of possible pitfalls.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/sale23a/sale23a.pdf",
        "supp": "",
        "pdf_size": 1573085,
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14775583309056438612&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3d44d179c4",
        "title": "Jana: Jointly amortized neural approximation of complex Bayesian models",
        "site": "https://proceedings.mlr.press/v216/radev23a.html",
        "author": "Stefan T. Radev; Marvin Schmitt; Valentin Pratz; Umberto Picchini; Ullrich K\u00f6the; Paul-Christian B\u00fcrkner",
        "abstract": "This work proposes \u201cjointly amortized neural approximation\u201d (JANA) of intractable likelihood functions and posterior densities arising in Bayesian surrogate modeling and simulation-based inference. We train three complementary networks in an end-to-end fashion: 1) a summary network to compress individual data points, sets, or time series into informative embedding vectors; 2) a posterior network to learn an amortized approximate posterior; and 3) a likelihood network to learn an amortized approximate likelihood. Their interaction opens a new route to amortized marginal likelihood and posterior predictive estimation \u2013 two important ingredients of Bayesian workflows that are often too expensive for standard methods. We benchmark the fidelity of JANA on a variety of simulation models against state of-the-art Bayesian methods and propose a powerful and interpretable diagnostic for joint calibration. In addition, we investigate the ability of recurrent likelihood networks to emulate complex time series models without resorting to hand-crafted summary statistics.",
        "bibtex": "@InProceedings{pmlr-v216-radev23a,\n  title = \t {Jana: Jointly amortized neural approximation of complex {B}ayesian models},\n  author =       {Radev, Stefan T. and Schmitt, Marvin and Pratz, Valentin and Picchini, Umberto and K\\\"othe, Ullrich and B\\\"urkner, Paul-Christian},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1695--1706},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/radev23a/radev23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/radev23a.html},\n  abstract = \t {This work proposes \u201cjointly amortized neural approximation\u201d (JANA) of intractable likelihood functions and posterior densities arising in Bayesian surrogate modeling and simulation-based inference. We train three complementary networks in an end-to-end fashion: 1) a summary network to compress individual data points, sets, or time series into informative embedding vectors; 2) a posterior network to learn an amortized approximate posterior; and 3) a likelihood network to learn an amortized approximate likelihood. Their interaction opens a new route to amortized marginal likelihood and posterior predictive estimation \u2013 two important ingredients of Bayesian workflows that are often too expensive for standard methods. We benchmark the fidelity of JANA on a variety of simulation models against state of-the-art Bayesian methods and propose a powerful and interpretable diagnostic for joint calibration. In addition, we investigate the ability of recurrent likelihood networks to emulate complex time series models without resorting to hand-crafted summary statistics.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/radev23a/radev23a.pdf",
        "supp": "",
        "pdf_size": 1351694,
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9889389963876965867&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Cluster of Excellence STRUCTURES, Heidelberg University; Cluster of Excellence SimTech, University of Stuttgart; Visual Learning Lab, Heidelberg University; Department of Mathematical Sciences, Chalmers University of Technology & University of Gothenburg; Visual Learning Lab, Heidelberg University; Cluster of Excellence SimTech, University of Stuttgart",
        "aff_domain": "; ; ; ; ; ",
        "email": "; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;2;0;1",
        "aff_unique_norm": "Heidelberg University;University of Stuttgart;Chalmers University of Technology",
        "aff_unique_dep": "Cluster of Excellence STRUCTURES;Cluster of Excellence SimTech;Department of Mathematical Sciences",
        "aff_unique_url": "https://www.uni-heidelberg.de;https://www.uni-stuttgart.de;https://www.chalmers.se",
        "aff_unique_abbr": "Uni Heidelberg;;Chalmers",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Heidelberg;",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "Germany;Sweden"
    },
    {
        "id": "7e9ac54bc2",
        "title": "Keep-Alive Caching for the Hawkes process",
        "site": "https://proceedings.mlr.press/v216/narayana23a.html",
        "author": "Sushirdeep Narayana; Ian A. Kash",
        "abstract": "We study the design of caching policies in applications such as serverless computing where there is not a fixed size cache to be filled, but rather there is a cost associated with the time an item stays in the cache.  We present a model for such caching policies which captures the trade-off between this cost and the cost of cache misses. We characterize optimal caching policies in general and apply this characterization by deriving a closed form for Hawkes processes. Since optimal policies for Hawkes processes depend on the history of arrivals, we also develop history-independent policies which achieve near-optimal average performance. We evaluate the performances of the optimal policy and approximate polices using simulations and a data trace of Azure Functions, Microsoft\u2019s FaaS (Function as a Service) platform for serverless computing",
        "bibtex": "@InProceedings{pmlr-v216-narayana23a,\n  title = \t {Keep-Alive Caching for the {H}awkes process},\n  author =       {Narayana, Sushirdeep and Kash, Ian A.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1499--1509},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/narayana23a/narayana23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/narayana23a.html},\n  abstract = \t {We study the design of caching policies in applications such as serverless computing where there is not a fixed size cache to be filled, but rather there is a cost associated with the time an item stays in the cache.  We present a model for such caching policies which captures the trade-off between this cost and the cost of cache misses. We characterize optimal caching policies in general and apply this characterization by deriving a closed form for Hawkes processes. Since optimal policies for Hawkes processes depend on the history of arrivals, we also develop history-independent policies which achieve near-optimal average performance. We evaluate the performances of the optimal policy and approximate polices using simulations and a data trace of Azure Functions, Microsoft\u2019s FaaS (Function as a Service) platform for serverless computing}\n}",
        "pdf": "https://proceedings.mlr.press/v216/narayana23a/narayana23a.pdf",
        "supp": "",
        "pdf_size": 1845338,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:eHLOuVUrEaEJ:scholar.google.com/&scioq=Keep-Alive+Caching+for+the+Hawkes+process&hl=en&as_sdt=0,5",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, University of Illinois at Chicago, Chicago, Illinois, USA; Department of Computer Science, University of Illinois at Chicago, Chicago, Illinois, USA",
        "aff_domain": "uic.edu;uic.edu",
        "email": "uic.edu;uic.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois at Chicago",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uic.edu",
        "aff_unique_abbr": "UIC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5c99ed8517",
        "title": "Knowledge Intensive Learning of Cutset Networks",
        "site": "https://proceedings.mlr.press/v216/mathur23a.html",
        "author": "Saurabh Mathur; Vibhav Gogate; Sriraam Natarajan",
        "abstract": "Cutset networks (CNs) are interpretable probabilistic representations that combine probability trees and tree Bayesian networks, to model and reason about large multi-dimensional probability distributions. Motivated by high-stakes applications in domains such as healthcare where (a) rich domain knowledge in the form of qualitative influences is readily available and (b) use of interpretable models that the user can efficiently probe and infer over is often necessary, we focus on learning CNs in the presence of qualitative influences. We propose a penalized objective function that uses the influences as constraints, and develop a gradient-based learning algorithm, KICN. We show that because CNs are tractable, KICN is guaranteed to converge to a local maximum of the penalized objective function. Our experiments on several benchmark data sets show that our new algorithm is superior to the state-of-the-art, especially when the data is scarce or noisy.",
        "bibtex": "@InProceedings{pmlr-v216-mathur23a,\n  title = \t {Knowledge Intensive Learning of Cutset Networks},\n  author =       {Mathur, Saurabh and Gogate, Vibhav and Natarajan, Sriraam},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1380--1389},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/mathur23a/mathur23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/mathur23a.html},\n  abstract = \t {Cutset networks (CNs) are interpretable probabilistic representations that combine probability trees and tree Bayesian networks, to model and reason about large multi-dimensional probability distributions. Motivated by high-stakes applications in domains such as healthcare where (a) rich domain knowledge in the form of qualitative influences is readily available and (b) use of interpretable models that the user can efficiently probe and infer over is often necessary, we focus on learning CNs in the presence of qualitative influences. We propose a penalized objective function that uses the influences as constraints, and develop a gradient-based learning algorithm, KICN. We show that because CNs are tractable, KICN is guaranteed to converge to a local maximum of the penalized objective function. Our experiments on several benchmark data sets show that our new algorithm is superior to the state-of-the-art, especially when the data is scarce or noisy.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/mathur23a/mathur23a.pdf",
        "supp": "",
        "pdf_size": 261654,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1661251190555188424&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "82f622e89a",
        "title": "KrADagrad: Kronecker approximation-domination gradient preconditioned stochastic optimization",
        "site": "https://proceedings.mlr.press/v216/mei23a.html",
        "author": "Jonathan Mei; Alexander Moreno; Luke Walters",
        "abstract": "Second order stochastic optimizers allow parameter update step size and direction to adapt to loss curvature, but have traditionally required too much memory and compute for deep learning. Recently, Shampoo [Gupta et al., 2018] introduced a Kronecker factored preconditioner to reduce these requirements: it is used for large deep models [Anil et al., 2020] and in production [Anil et al., 2022]. However, it takes inverse matrix roots of ill-conditioned matrices. This requires 64-bit precision, imposing strong hardware constraints. In this paper, we propose a novel factorization, Kronecker Approximation-Domination (KrAD). Using KrAD, we update a matrix that directly approximates the inverse empirical Fisher matrix (like full matrix AdaGrad), avoiding inversion and hence 64-bit precision. We then propose KrADagrad , with similar computational costs to Shampoo and the same regret. Synthetic ill-conditioned experiments show improved performance over Shampoo for 32-bit precision, while for several real datasets we have comparable or better generalization.",
        "bibtex": "@InProceedings{pmlr-v216-mei23a,\n  title = \t {{KrADagrad}: {K}ronecker approximation-domination gradient preconditioned stochastic optimization},\n  author =       {Mei, Jonathan and Moreno, Alexander and Walters, Luke},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1412--1422},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/mei23a/mei23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/mei23a.html},\n  abstract = \t {Second order stochastic optimizers allow parameter update step size and direction to adapt to loss curvature, but have traditionally required too much memory and compute for deep learning. Recently, Shampoo [Gupta et al., 2018] introduced a Kronecker factored preconditioner to reduce these requirements: it is used for large deep models [Anil et al., 2020] and in production [Anil et al., 2022]. However, it takes inverse matrix roots of ill-conditioned matrices. This requires 64-bit precision, imposing strong hardware constraints. In this paper, we propose a novel factorization, Kronecker Approximation-Domination (KrAD). Using KrAD, we update a matrix that directly approximates the inverse empirical Fisher matrix (like full matrix AdaGrad), avoiding inversion and hence 64-bit precision. We then propose KrADagrad , with similar computational costs to Shampoo and the same regret. Synthetic ill-conditioned experiments show improved performance over Shampoo for 32-bit precision, while for several real datasets we have comparable or better generalization.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/mei23a/mei23a.pdf",
        "supp": "",
        "pdf_size": 1142985,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2320969953041676387&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ab0e633980",
        "title": "Learning Choice Functions with Gaussian Processes",
        "site": "https://proceedings.mlr.press/v216/benavoli23a.html",
        "author": "Alessio Benavoli; Dario Azzimonti; Dario Piga",
        "abstract": "In consumer theory, ranking available objects by means of preference relations yields the most common description of individual choices. However, preference-based models assume that individuals: (1) give their preferences only between pairs of objects; (2) are always able to pick the best preferred object. In many situations, they may be instead choosing out of a set with more than two elements and, because of lack of information and/or incomparability (objects with contradictory characteristics), they may not be able to select a single most preferred object. To address these situations, we need a choice model which allows an individual to express a set-valued choice. Choice functions provide such a mathematical framework. We propose a Gaussian Process model to learn choice functions from choice data. The model assumes a multiple utility representation of a choice function based on the concept of Pareto rationalization, and derives a strategy to learn both the number and the values of these latent multiple utilities. Simulation experiments demonstrate that the proposed model outperforms the state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v216-benavoli23a,\n  title = \t {Learning Choice Functions with {G}aussian Processes},\n  author =       {Benavoli, Alessio and Azzimonti, Dario and Piga, Dario},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {141--151},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/benavoli23a/benavoli23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/benavoli23a.html},\n  abstract = \t {In consumer theory, ranking available objects by means of preference relations yields the most common description of individual choices. However, preference-based models assume that individuals: (1) give their preferences only between pairs of objects; (2) are always able to pick the best preferred object. In many situations, they may be instead choosing out of a set with more than two elements and, because of lack of information and/or incomparability (objects with contradictory characteristics), they may not be able to select a single most preferred object. To address these situations, we need a choice model which allows an individual to express a set-valued choice. Choice functions provide such a mathematical framework. We propose a Gaussian Process model to learn choice functions from choice data. The model assumes a multiple utility representation of a choice function based on the concept of Pareto rationalization, and derives a strategy to learn both the number and the values of these latent multiple utilities. Simulation experiments demonstrate that the proposed model outperforms the state-of-the-art methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/benavoli23a/benavoli23a.pdf",
        "supp": "",
        "pdf_size": 402810,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14889961900066093004&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3c14c13b52",
        "title": "Learning Nonlinear Causal Effect via Kernel Anchor Regression",
        "site": "https://proceedings.mlr.press/v216/shi23a.html",
        "author": "Wenqi Shi; Wenkai Xu",
        "abstract": "Learning causal effects is a fundamental problem in science. Anchor regression has been developed to address this problem for a large class of causal graphical models, though the relationships between the variables are assumed to be linear. In this work, we tackle the nonlinear setting by proposing kernel anchor regression (KAR). Beyond a classic two-stage least square (2SLS) estimator, we also study an improved variant that involves nonparametric kernel regression in three separate stages. We provide convergence results for the proposed KAR estimators and the identifiability conditions for KAR to learn the nonlinear structural equation models (SEM). Experimental results demonstrate the superior performances of the proposed KAR estimators over existing baselines.",
        "bibtex": "@InProceedings{pmlr-v216-shi23a,\n  title = \t {Learning Nonlinear Causal Effect via Kernel Anchor Regression},\n  author =       {Shi, Wenqi and Xu, Wenkai},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1942--1952},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/shi23a/shi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/shi23a.html},\n  abstract = \t {Learning causal effects is a fundamental problem in science. Anchor regression has been developed to address this problem for a large class of causal graphical models, though the relationships between the variables are assumed to be linear. In this work, we tackle the nonlinear setting by proposing kernel anchor regression (KAR). Beyond a classic two-stage least square (2SLS) estimator, we also study an improved variant that involves nonparametric kernel regression in three separate stages. We provide convergence results for the proposed KAR estimators and the identifiability conditions for KAR to learn the nonlinear structural equation models (SEM). Experimental results demonstrate the superior performances of the proposed KAR estimators over existing baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/shi23a/shi23a.pdf",
        "supp": "",
        "pdf_size": 1442820,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1613082359303551657&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Industrial Engineering, Tsinghua University; Department of Statistics, University of Oxford",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Tsinghua University;University of Oxford",
        "aff_unique_dep": "Department of Industrial Engineering;Department of Statistics",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.ox.ac.uk",
        "aff_unique_abbr": "Tsinghua;Oxford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Oxford",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "da24d63a89",
        "title": "Learning To Invert: Simple Adaptive Attacks for Gradient Inversion in Federated Learning",
        "site": "https://proceedings.mlr.press/v216/wu23a.html",
        "author": "Ruihan Wu; Xiangyu Chen; Chuan Guo; Kilian Q. Weinberger",
        "abstract": "Gradient inversion attack enables recovery of training samples from model gradients in federated learning (FL), and constitutes a serious threat to data privacy. To mitigate this vulnerability, prior work proposed both principled defenses based on differential privacy, as well as heuristic defenses based on gradient compression as countermeasures. These defenses have so far been very effective, in particular those based on gradient compression that allow the model to maintain high accuracy while greatly reducing the effectiveness of attacks. In this work, we argue that such findings underestimate the privacy risk in FL. As a counterexample, we show that existing defenses can be broken by a simple adaptive attack, where a model trained on auxiliary data is able to invert gradients on both vision and language tasks.",
        "bibtex": "@InProceedings{pmlr-v216-wu23a,\n  title = \t {Learning To Invert: Simple Adaptive Attacks for Gradient Inversion in Federated Learning},\n  author =       {Wu, Ruihan and Chen, Xiangyu and Guo, Chuan and Weinberger, Kilian Q.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2293--2303},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/wu23a/wu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/wu23a.html},\n  abstract = \t {Gradient inversion attack enables recovery of training samples from model gradients in federated learning (FL), and constitutes a serious threat to data privacy. To mitigate this vulnerability, prior work proposed both principled defenses based on differential privacy, as well as heuristic defenses based on gradient compression as countermeasures. These defenses have so far been very effective, in particular those based on gradient compression that allow the model to maintain high accuracy while greatly reducing the effectiveness of attacks. In this work, we argue that such findings underestimate the privacy risk in FL. As a counterexample, we show that existing defenses can be broken by a simple adaptive attack, where a model trained on auxiliary data is able to invert gradients on both vision and language tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/wu23a/wu23a.pdf",
        "supp": "",
        "pdf_size": 3119501,
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11990339273105932439&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Cornell University, USA; Cornell University, USA; Meta AI, USA; Cornell University, USA",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Cornell University;Meta",
        "aff_unique_dep": ";Meta AI",
        "aff_unique_url": "https://www.cornell.edu;https://meta.ai",
        "aff_unique_abbr": "Cornell;Meta AI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1063207e90",
        "title": "Learning from Low Rank Tensor Data: A Random Tensor Theory Perspective",
        "site": "https://proceedings.mlr.press/v216/seddik23a.html",
        "author": "Mohamed El Amine Seddik; Malik Tiomoko; Alexis Decurninge; Maxim Panov; Maxime Gauillaud",
        "abstract": "Under a simplified data model, this paper provides a theoretical analysis of learning from data that have an underlying low-rank tensor structure in both supervised and unsupervised settings. For the supervised setting, we provide an analysis of a Ridge classifier (with high regularization parameter) with and without knowledge of the low-rank structure of the data. Our results quantify analytically the gain in misclassification errors achieved by exploiting the low-rank structure for denoising purposes, as opposed to treating data as mere vectors. We further provide a similar analysis in the context of clustering, thereby quantifying the exact performance gap between tensor methods and standard approaches which treat data as simple vectors.",
        "bibtex": "@InProceedings{pmlr-v216-seddik23a,\n  title = \t {Learning from Low Rank Tensor Data: A Random Tensor Theory Perspective},\n  author =       {Seddik, Mohamed El Amine and Tiomoko, Malik and Decurninge, Alexis and Panov, Maxim and Gauillaud, Maxime},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1858--1867},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/seddik23a/seddik23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/seddik23a.html},\n  abstract = \t {Under a simplified data model, this paper provides a theoretical analysis of learning from data that have an underlying low-rank tensor structure in both supervised and unsupervised settings. For the supervised setting, we provide an analysis of a Ridge classifier (with high regularization parameter) with and without knowledge of the low-rank structure of the data. Our results quantify analytically the gain in misclassification errors achieved by exploiting the low-rank structure for denoising purposes, as opposed to treating data as mere vectors. We further provide a similar analysis in the context of clustering, thereby quantifying the exact performance gap between tensor methods and standard approaches which treat data as simple vectors.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/seddik23a/seddik23a.pdf",
        "supp": "",
        "pdf_size": 482078,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1313035410458385420&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 14,
        "aff": "Technology Innovation Institute, PO Box: 9639, Masdar City, Abu Dhabi, UAE; Huawei Technologies France, Paris, France; Huawei Technologies France, Paris, France; Technology Innovation Institute, PO Box: 9639, Masdar City, Abu Dhabi, UAE; Inria / CITI Laboratory, 6 avenue des Arts, 69621 Villeurbanne, France",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;0;2",
        "aff_unique_norm": "Technology Innovation Institute;Huawei;INRIA",
        "aff_unique_dep": ";Huawei Technologies;CITI Laboratory",
        "aff_unique_url": ";https://www.huawei.com/fr;https://www.inria.fr",
        "aff_unique_abbr": ";Huawei;Inria",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Masdar City;Paris;",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "United Arab Emirates;France"
    },
    {
        "id": "8d2189bec1",
        "title": "Learning good interventions in causal graphs via covering",
        "site": "https://proceedings.mlr.press/v216/sawarni23a.html",
        "author": "Ayush Sawarni; Rahul Madhavan; Gaurav Sinha; Siddharth Barman",
        "abstract": "We study the causal bandit problem that entails identifying a near-optimal intervention from a specified set A of (possibly non-atomic) interventions over a given causal graph. Here, an optimal intervention in A is one that maximizes the expected value for a designated reward variable in the graph, and we use the standard notion of simple regret to quantify near optimality. Considering Bernoulli random variables and for causal graphs on N vertices with constant in-degree, prior work has achieved a worst case guarantee of O(N/sqrt(T)) for simple regret. The current work utilizes the idea of covering interventions (which are not necessarily contained within A) and establishes a simple regret guarantee of O(sqrt(N/T)). Notably, and in contrast to prior work, our simple regret bound depends only on explicit parameters of the problem instance. We also go beyond prior work and achieve a simple regret guarantee for causal graphs with unobserved variables. Further, we perform experiments to show improvements over baselines in this setting.",
        "bibtex": "@InProceedings{pmlr-v216-sawarni23a,\n  title = \t {Learning good interventions in causal graphs via covering},\n  author =       {Sawarni, Ayush and Madhavan, Rahul and Sinha, Gaurav and Barman, Siddharth},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1827--1836},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/sawarni23a/sawarni23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/sawarni23a.html},\n  abstract = \t {We study the causal bandit problem that entails identifying a near-optimal intervention from a specified set A of (possibly non-atomic) interventions over a given causal graph. Here, an optimal intervention in A is one that maximizes the expected value for a designated reward variable in the graph, and we use the standard notion of simple regret to quantify near optimality. Considering Bernoulli random variables and for causal graphs on N vertices with constant in-degree, prior work has achieved a worst case guarantee of O(N/sqrt(T)) for simple regret. The current work utilizes the idea of covering interventions (which are not necessarily contained within A) and establishes a simple regret guarantee of O(sqrt(N/T)). Notably, and in contrast to prior work, our simple regret bound depends only on explicit parameters of the problem instance. We also go beyond prior work and achieve a simple regret guarantee for causal graphs with unobserved variables. Further, we perform experiments to show improvements over baselines in this setting.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/sawarni23a/sawarni23a.pdf",
        "supp": "",
        "pdf_size": 310028,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7637462838243708260&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "8d836fe2d4",
        "title": "Learning in online MDPs: is there a price for handling the communicating case?",
        "site": "https://proceedings.mlr.press/v216/chandrasekaran23a.html",
        "author": "Gautam Chandrasekaran; Ambuj Tewari",
        "abstract": "It is a remarkable fact that the same $O(\\sqrt{T})$ regret rate can be achieved in both the Experts Problem and the Adversarial Multi-Armed Bandit problem albeit with a worse dependence on number of actions in the latter case. In contrast, it has been shown that handling online MDPs with communicating structure and bandit information incurs $\\Omega(T^{2/3})$ regret even in the case of deterministic transitions. Is this the price we pay for handling communicating structure or is it because we also have bandit feedback? In this paper we show that with full information, online MDPs can still be learned at an $O(\\sqrt{T})$ rate even in the presence of communicating structure. We first show this by proposing an efficient follow the perturbed leader (FPL) algorithm for the deterministic transition case. We then extend our scope to consider stochastic transitions where we first give an inefficient $O(\\sqrt{T})$-regret algorithm (with a mild additional condition on the dynamics). Then we show how to achieve $O\\left(\\sqrt{\\frac{T}{\\alpha}}\\right)$ regret rate using an oracle-efficient algorithm but with the additional restriction that the starting state distribution has mass at least $\\alpha$ on each state.",
        "bibtex": "@InProceedings{pmlr-v216-chandrasekaran23a,\n  title = \t {Learning in online {MDPs}: is there a price for handling the communicating case?},\n  author =       {Chandrasekaran, Gautam and Tewari, Ambuj},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {293--302},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/chandrasekaran23a/chandrasekaran23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/chandrasekaran23a.html},\n  abstract = \t {It is a remarkable fact that the same $O(\\sqrt{T})$ regret rate can be achieved in both the Experts Problem and the Adversarial Multi-Armed Bandit problem albeit with a worse dependence on number of actions in the latter case. In contrast, it has been shown that handling online MDPs with communicating structure and bandit information incurs $\\Omega(T^{2/3})$ regret even in the case of deterministic transitions. Is this the price we pay for handling communicating structure or is it because we also have bandit feedback? In this paper we show that with full information, online MDPs can still be learned at an $O(\\sqrt{T})$ rate even in the presence of communicating structure. We first show this by proposing an efficient follow the perturbed leader (FPL) algorithm for the deterministic transition case. We then extend our scope to consider stochastic transitions where we first give an inefficient $O(\\sqrt{T})$-regret algorithm (with a mild additional condition on the dynamics). Then we show how to achieve $O\\left(\\sqrt{\\frac{T}{\\alpha}}\\right)$ regret rate using an oracle-efficient algorithm but with the additional restriction that the starting state distribution has mass at least $\\alpha$ on each state.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/chandrasekaran23a/chandrasekaran23a.pdf",
        "supp": "",
        "pdf_size": 245404,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12427924970588438244&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, University of Texas at Austin, Austin, Texas, USA; Department of Statistics, University of Michigan, Ann Arbor, Michigan, USA",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Texas at Austin;University of Michigan",
        "aff_unique_dep": "Department of Computer Science;Department of Statistics",
        "aff_unique_url": "https://www.utexas.edu;https://www.umich.edu",
        "aff_unique_abbr": "UT Austin;UM",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Austin;Ann Arbor",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "29cd693f73",
        "title": "Learning robust representation for reinforcement learning with distractions by reward sequence prediction",
        "site": "https://proceedings.mlr.press/v216/zhou23a.html",
        "author": "Qi Zhou; Jie Wang; Qiyuan Liu; Yufei Kuang; Wengang Zhou; Houqiang Li",
        "abstract": "Reinforcement learning algorithms have achieved remarkable success in acquiring behavioral skills directly from pixel inputs. However, their application in real-world scenarios presents challenges due to their sensitivity to visual distractions (e.g., changes in viewpoint and light). A key factor contributing to this challenge is that the learned representations often suffer from overfitting task-irrelevant information. By comparing several representation learning methods, we find that the key to alleviating overfitting in representation learning is to choose proper prediction targets. Motivated by our comparison, we propose a novel representation learning approach\u2014namely, reward sequence prediction (RSP)\u2014that uses reward sequences or their transforms (e.g., discrete time Fourier transform) as prediction targets. RSP can efficiently learn robust representations as reward sequences rarely contain task-irrelevant information while providing a large number of supervised signals to accelerate representation learning. An appealing feature is that RSP makes no assumption about the type of distractions and thus can improve performance even when multiple types of distractions exist. We evaluate our approach in Distracting Control Suite. Experiments show that our method achieves state-of-the-art sample efficiency and generalization ability in tasks with distractions.",
        "bibtex": "@InProceedings{pmlr-v216-zhou23a,\n  title = \t {Learning robust representation for reinforcement learning with distractions by reward sequence prediction},\n  author =       {Zhou, Qi and Wang, Jie and Liu, Qiyuan and Kuang, Yufei and Zhou, Wengang and Li, Houqiang},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2551--2562},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zhou23a/zhou23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zhou23a.html},\n  abstract = \t {Reinforcement learning algorithms have achieved remarkable success in acquiring behavioral skills directly from pixel inputs. However, their application in real-world scenarios presents challenges due to their sensitivity to visual distractions (e.g., changes in viewpoint and light). A key factor contributing to this challenge is that the learned representations often suffer from overfitting task-irrelevant information. By comparing several representation learning methods, we find that the key to alleviating overfitting in representation learning is to choose proper prediction targets. Motivated by our comparison, we propose a novel representation learning approach\u2014namely, reward sequence prediction (RSP)\u2014that uses reward sequences or their transforms (e.g., discrete time Fourier transform) as prediction targets. RSP can efficiently learn robust representations as reward sequences rarely contain task-irrelevant information while providing a large number of supervised signals to accelerate representation learning. An appealing feature is that RSP makes no assumption about the type of distractions and thus can improve performance even when multiple types of distractions exist. We evaluate our approach in Distracting Control Suite. Experiments show that our method achieves state-of-the-art sample efficiency and generalization ability in tasks with distractions.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/zhou23a/zhou23a.pdf",
        "supp": "",
        "pdf_size": 845061,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16863249280346515985&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "1CAS Key Laboratory of Technology in GIPAS, University of Science and Technology of China + 2Institute of Arti\ufb01cial Intelligence, Hefei Comprehensive National Science Center; 1CAS Key Laboratory of Technology in GIPAS, University of Science and Technology of China + 2Institute of Arti\ufb01cial Intelligence, Hefei Comprehensive National Science Center; 1CAS Key Laboratory of Technology in GIPAS, University of Science and Technology of China; 1CAS Key Laboratory of Technology in GIPAS, University of Science and Technology of China; 1CAS Key Laboratory of Technology in GIPAS, University of Science and Technology of China + 2Institute of Arti\ufb01cial Intelligence, Hefei Comprehensive National Science Center; 1CAS Key Laboratory of Technology in GIPAS, University of Science and Technology of China + 2Institute of Arti\ufb01cial Intelligence, Hefei Comprehensive National Science Center",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0;0;0+1;0+1",
        "aff_unique_norm": "University of Science and Technology of China;Hefei Comprehensive National Science Center",
        "aff_unique_dep": "Key Laboratory of Technology in GIPAS;Institute of Arti\ufb01cial Intelligence",
        "aff_unique_url": "http://www.ustc.edu.cn/;http://www.hfcn.edu.cn",
        "aff_unique_abbr": "USTC;",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Hefei",
        "aff_country_unique_index": "0+0;0+0;0;0;0+0;0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "9c1bcd5d58",
        "title": "Learning to reason about contextual knowledge for planning under uncertainty",
        "site": "https://proceedings.mlr.press/v216/cui23a.html",
        "author": "Cheng Cui; Saeid Amiri; Yan Ding; Xingyue Zhan; Shiqi Zhang",
        "abstract": "Sequential decision-making (SDM) methods enable AI agents to compute an action policy toward achieving long-term goals under uncertainty. Existing research has shown that contextual knowledge in declarative forms can be used for improving the performance of SDM methods. However, the contextual knowledge from people tends to be incomplete and sometimes inaccurate, which greatly limits the applicability of knowledge-based SDM methods. In this paper, we develop a novel algorithm for knowledge-based SDM, called PERIL, that learns from interaction experience to reason about contextual knowledge, as applied to urban driving scenarios. Experiments have been conducted using CARLA, a widely used autonomous driving simulator. Results demonstrate PERIL\u2019s superiority in comparison to existing knowledge-based SDM baselines.",
        "bibtex": "@InProceedings{pmlr-v216-cui23a,\n  title = \t {Learning to reason about contextual knowledge for planning under uncertainty},\n  author =       {Cui, Cheng and Amiri, Saeid and Ding, Yan and Zhan, Xingyue and Zhang, Shiqi},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {465--475},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/cui23a/cui23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/cui23a.html},\n  abstract = \t {Sequential decision-making (SDM) methods enable AI agents to compute an action policy toward achieving long-term goals under uncertainty. Existing research has shown that contextual knowledge in declarative forms can be used for improving the performance of SDM methods. However, the contextual knowledge from people tends to be incomplete and sometimes inaccurate, which greatly limits the applicability of knowledge-based SDM methods. In this paper, we develop a novel algorithm for knowledge-based SDM, called PERIL, that learns from interaction experience to reason about contextual knowledge, as applied to urban driving scenarios. Experiments have been conducted using CARLA, a widely used autonomous driving simulator. Results demonstrate PERIL\u2019s superiority in comparison to existing knowledge-based SDM baselines.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/cui23a/cui23a.pdf",
        "supp": "",
        "pdf_size": 5488432,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:qOoiA-BJjCkJ:scholar.google.com/&scioq=Learning+to+reason+about+contextual+knowledge+for+planning+under+uncertainty&hl=en&as_sdt=0,33",
        "gs_version_total": 7,
        "aff": "Department of Computer Science, SUNY Binghamton, Binghamton, New York, USA + Cognex Corporation, Natick, Massachusetts, USA; Department of Computer Science, SUNY Binghamton, Binghamton, New York, USA; Department of Computer Science, SUNY Binghamton, Binghamton, New York, USA; Department of Computer Science, SUNY Binghamton, Binghamton, New York, USA; Department of Computer Science, SUNY Binghamton, Binghamton, New York, USA",
        "aff_domain": "binghamton.edu;binghamton.edu;binghamton.edu;binghamton.edu;binghamton.edu",
        "email": "binghamton.edu;binghamton.edu;binghamton.edu;binghamton.edu;binghamton.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0;0;0",
        "aff_unique_norm": "State University of New York at Binghamton;Cognex Corporation",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.binghamton.edu;https://www.cognex.com",
        "aff_unique_abbr": "SUNY Binghamton;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Binghamton;",
        "aff_country_unique_index": "0+0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d594a49506",
        "title": "Lifelong bandit optimization: no prior and no regret",
        "site": "https://proceedings.mlr.press/v216/schur23a.html",
        "author": "Felix Schur; Parnian Kassraie; Jonas Rothfuss; Andreas Krause",
        "abstract": "Machine learning algorithms are often repeatedly. applied to problems with similar structure over and over again. We focus on solving a sequence of bandit optimization tasks and develop LIBO, an algorithm which adapts to the environment by learning from past experience and becomes more sample-efficient in the process. We assume a kernelized structure where the kernel is unknown but shared across all tasks. LIBO sequentially meta-learns a kernel that approximates the true kernel and solves the incoming tasks with the latest kernel estimate. Our algorithm can be paired with any kernelized or linear bandit algorithm and guarantees oracle optimal performance, meaning that as more tasks are solved, the regret of LIBO on each task converges to the regret of the bandit algorithm with oracle knowledge of the true kernel. Naturally, if paired with a sublinear bandit algorithm, LIBO yields a sublinear lifelong regret. We also show that direct access to the data from each task is not necessary for attaining sublinear regret. We propose F-LIBO, which solves the lifelong problem in a federated manner.",
        "bibtex": "@InProceedings{pmlr-v216-schur23a,\n  title = \t {Lifelong bandit optimization: no prior and no regret},\n  author =       {Schur, Felix and Kassraie, Parnian and Rothfuss, Jonas and Krause, Andreas},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1847--1857},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/schur23a/schur23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/schur23a.html},\n  abstract = \t {Machine learning algorithms are often repeatedly. applied to problems with similar structure over and over again. We focus on solving a sequence of bandit optimization tasks and develop LIBO, an algorithm which adapts to the environment by learning from past experience and becomes more sample-efficient in the process. We assume a kernelized structure where the kernel is unknown but shared across all tasks. LIBO sequentially meta-learns a kernel that approximates the true kernel and solves the incoming tasks with the latest kernel estimate. Our algorithm can be paired with any kernelized or linear bandit algorithm and guarantees oracle optimal performance, meaning that as more tasks are solved, the regret of LIBO on each task converges to the regret of the bandit algorithm with oracle knowledge of the true kernel. Naturally, if paired with a sublinear bandit algorithm, LIBO yields a sublinear lifelong regret. We also show that direct access to the data from each task is not necessary for attaining sublinear regret. We propose F-LIBO, which solves the lifelong problem in a federated manner.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/schur23a/schur23a.pdf",
        "supp": "",
        "pdf_size": 573872,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12990268462869958373&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9483e51d26",
        "title": "Local Message Passing on Frustrated Systems",
        "site": "https://proceedings.mlr.press/v216/schmid23a.html",
        "author": "Luca Schmid; Joshua Brenk; Laurent Schmalen",
        "abstract": "Message passing on factor graphs is a powerful framework for probabilistic inference, which finds important applications in various scientific domains. The most wide-spread message passing scheme is the sum-product algorithm (SPA) which gives exact results on trees but often fails on graphs with many small cycles. We search for an alternative message passing algorithm that works particularly well on such cyclic graphs. Therefore, we challenge the extrinsic principle of the SPA, which loses its objective on graphs with cycles. We further replace the local SPA message update rule at the factor nodes of the underlying graph with a generic mapping, which is optimized in a data-driven fashion. These modifications lead to a considerable improvement in performance while preserving the simplicity of the SPA. We evaluate our method for two classes of cyclic graphs: the 2x2 fully connected Ising grid and factor graphs for symbol detection on linear communication channels with inter-symbol interference. To enable the method for large graphs as they occur in practical applications, we develop a novel loss function that is inspired by the Bethe approximation from statistical physics and allows for training in an unsupervised fashion.",
        "bibtex": "@InProceedings{pmlr-v216-schmid23a,\n  title = \t {Local Message Passing on Frustrated Systems},\n  author =       {Schmid, Luca and Brenk, Joshua and Schmalen, Laurent},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1837--1846},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/schmid23a/schmid23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/schmid23a.html},\n  abstract = \t {Message passing on factor graphs is a powerful framework for probabilistic inference, which finds important applications in various scientific domains. The most wide-spread message passing scheme is the sum-product algorithm (SPA) which gives exact results on trees but often fails on graphs with many small cycles. We search for an alternative message passing algorithm that works particularly well on such cyclic graphs. Therefore, we challenge the extrinsic principle of the SPA, which loses its objective on graphs with cycles. We further replace the local SPA message update rule at the factor nodes of the underlying graph with a generic mapping, which is optimized in a data-driven fashion. These modifications lead to a considerable improvement in performance while preserving the simplicity of the SPA. We evaluate our method for two classes of cyclic graphs: the 2x2 fully connected Ising grid and factor graphs for symbol detection on linear communication channels with inter-symbol interference. To enable the method for large graphs as they occur in practical applications, we develop a novel loss function that is inspired by the Bethe approximation from statistical physics and allows for training in an unsupervised fashion.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/schmid23a/schmid23a.pdf",
        "supp": "",
        "pdf_size": 478880,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14515692638505798267&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c96e6cf32e",
        "title": "Locally Regularized Sparse Graph by Fast Proximal Gradient Descent",
        "site": "https://proceedings.mlr.press/v216/sun23c.html",
        "author": "Dongfang Sun; Yingzhen Yang",
        "abstract": "Sparse graphs built by sparse representation has been demonstrated to be effective in clustering high-dimensional data. Albeit the compelling empirical performance, the vanilla sparse graph ignores the geometric information of the data by performing sparse representation for each datum separately. In order to obtain a sparse graph aligned with the local geometric structure of data, we propose a novel Support Regularized Sparse Graph, abbreviated as SRSG, for data clustering. SRSG encourages local smoothness on the neighborhoods of nearby data points by a well-defined support regularization term. We propose a fast proximal gradient descent method to solve the non-convex optimization problem of SRSG with the convergence matching the Nesterov\u2019s optimal convergence rate of first-order methods on smooth and convex objective function with Lipschitz continuous gradient. Extensive experimental results on various real data sets demonstrate the superiority of SRSG over other competing clustering methods.",
        "bibtex": "@InProceedings{pmlr-v216-sun23c,\n  title = \t {Locally Regularized Sparse Graph by Fast Proximal Gradient Descent},\n  author =       {Sun, Dongfang and Yang, Yingzhen},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2069--2077},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/sun23c/sun23c.pdf},\n  url = \t {https://proceedings.mlr.press/v216/sun23c.html},\n  abstract = \t {Sparse graphs built by sparse representation has been demonstrated to be effective in clustering high-dimensional data. Albeit the compelling empirical performance, the vanilla sparse graph ignores the geometric information of the data by performing sparse representation for each datum separately. In order to obtain a sparse graph aligned with the local geometric structure of data, we propose a novel Support Regularized Sparse Graph, abbreviated as SRSG, for data clustering. SRSG encourages local smoothness on the neighborhoods of nearby data points by a well-defined support regularization term. We propose a fast proximal gradient descent method to solve the non-convex optimization problem of SRSG with the convergence matching the Nesterov\u2019s optimal convergence rate of first-order methods on smooth and convex objective function with Lipschitz continuous gradient. Extensive experimental results on various real data sets demonstrate the superiority of SRSG over other competing clustering methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/sun23c/sun23c.pdf",
        "supp": "",
        "pdf_size": 415290,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:L0I46hgSsagJ:scholar.google.com/&scioq=Locally+Regularized+Sparse+Graph+by+Fast+Proximal+Gradient+Descent&hl=en&as_sdt=0,33",
        "gs_version_total": 9,
        "aff": "School of Computing and Augmented Intelligence, Arizona State University, Tempe, AZ 85281, USA; School of Computing and Augmented Intelligence, Arizona State University, Tempe, AZ 85281, USA",
        "aff_domain": "asu.edu;asu.edu",
        "email": "asu.edu;asu.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School of Computing and Augmented Intelligence",
        "aff_unique_url": "https://asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ea0a5cc26f",
        "title": "Logit-based ensemble distribution distillation for robust autoregressive sequence uncertainties",
        "site": "https://proceedings.mlr.press/v216/fathullah23a.html",
        "author": "Yassir Fathullah; Guoxuan Xia; Mark J. F. Gales",
        "abstract": "Efficiently and reliably estimating uncertainty is an important objective in deep learning. It is especially pertinent to autoregressive sequence tasks, where training and inference costs are typically very high. However, existing research has predominantly focused on tasks with static data such as image classification. In this work, we investigate Ensemble Distribution Distillation (EDD) applied to large-scale natural language sequence-to-sequence data. EDD aims to compress the superior uncertainty performance of an expensive (teacher) ensemble into a cheaper (student) single model. Importantly, the ability to separate knowledge (epistemic) and data (aleatoric) uncertainty is retained. Existing probability-space approaches to EDD, however, are difficult to scale to large vocabularies. We show, for modern transformer architectures on large-scale translation tasks, that modelling the ensemble",
        "bibtex": "@InProceedings{pmlr-v216-fathullah23a,\n  title = \t {Logit-based ensemble distribution distillation for robust autoregressive sequence uncertainties},\n  author =       {Fathullah, Yassir and Xia, Guoxuan and J. F. Gales, Mark},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {582--591},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/fathullah23a/fathullah23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/fathullah23a.html},\n  abstract = \t {Efficiently and reliably estimating uncertainty is an important objective in deep learning. It is especially pertinent to autoregressive sequence tasks, where training and inference costs are typically very high. However, existing research has predominantly focused on tasks with static data such as image classification. In this work, we investigate Ensemble Distribution Distillation (EDD) applied to large-scale natural language sequence-to-sequence data. EDD aims to compress the superior uncertainty performance of an expensive (teacher) ensemble into a cheaper (student) single model. Importantly, the ability to separate knowledge (epistemic) and data (aleatoric) uncertainty is retained. Existing probability-space approaches to EDD, however, are difficult to scale to large vocabularies. We show, for modern transformer architectures on large-scale translation tasks, that modelling the ensemble",
        "pdf": "https://proceedings.mlr.press/v216/fathullah23a/fathullah23a.pdf",
        "supp": "",
        "pdf_size": 679015,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9243790181089978210&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Engineering Department, University of Cambridge, UK; Department of Electrical & Electronic Engineering, Imperial College London, UK; Engineering Department, University of Cambridge, UK",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Cambridge;Imperial College London",
        "aff_unique_dep": "Engineering Department;Department of Electrical & Electronic Engineering",
        "aff_unique_url": "https://www.cam.ac.uk;https://www.imperial.ac.uk",
        "aff_unique_abbr": "Cambridge;ICL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "7556d242ac",
        "title": "Loosely consistent emphatic temporal-difference learning",
        "site": "https://proceedings.mlr.press/v216/he23a.html",
        "author": "Jiamin He; Fengdi Che; Yi Wan; A. Rupam Mahmood",
        "abstract": "There has been significant interest in searching for off-policy Temporal-Difference (TD) algorithms that find the same solution that would have been obtained in the on-policy regime. An important property of such algorithms is that their expected update has the same fixed point as that of On-policy TD($\\lambda$), which we call",
        "bibtex": "@InProceedings{pmlr-v216-he23a,\n  title = \t {Loosely consistent emphatic temporal-difference learning},\n  author =       {He, Jiamin and Che, Fengdi and Wan, Yi and Mahmood, A. Rupam},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {849--859},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/he23a/he23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/he23a.html},\n  abstract = \t {There has been significant interest in searching for off-policy Temporal-Difference (TD) algorithms that find the same solution that would have been obtained in the on-policy regime. An important property of such algorithms is that their expected update has the same fixed point as that of On-policy TD($\\lambda$), which we call",
        "pdf": "https://proceedings.mlr.press/v216/he23a/he23a.pdf",
        "supp": "",
        "pdf_size": 2028434,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2468229729324969344&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4dae580b6c",
        "title": "Low-rank matrix recovery with unknown correspondence",
        "site": "https://proceedings.mlr.press/v216/tang23a.html",
        "author": "Zhiwei Tang; Tsung-Hui Chang; Xiaojing Ye; Hongyuan Zha",
        "abstract": "We study a matrix recovery problem with unknown correspondence: given the observation matrix $M_o=[A,\\tilde P B]$, where $\\tilde P$ is an unknown permutation matrix, we aim to recover the underlying matrix $M=[A,B]$. Such problem commonly arises in many applications where heterogeneous data are utilized and the correspondence among them are unknown, e.g., due to data mishandling or privacy concern. We show that, in some applications, it is possible to recover $M$ via solving a nuclear norm minimization problem. Moreover, under a proper low-rank condition on $M$, we derive a non-asymptotic error bound for the recovery of $M$. We propose an algorithm, $\\text{M}^3\\text{O}$ (Matrix recovery via Min-Max Optimization) which recasts this combinatorial problem as a continuous minimax optimization problem and solves it by proximal gradient with a Max-Oracle. $\\text{M}^3\\text{O}$ can also be applied to a more general scenario where we have missing entries in $M_o$ and multiple groups of data with distinct unknown correspondence. Experiments on  simulated data, the MovieLens 100K dataset and Yale B database show that $\\text{M}^3\\text{O}$ achieves state-of-the-art performance over several baselines and can recover the ground-truth correspondence with high accuracy.",
        "bibtex": "@InProceedings{pmlr-v216-tang23a,\n  title = \t {Low-rank matrix recovery with unknown correspondence},\n  author =       {Tang, Zhiwei and Chang, Tsung-Hui and Ye, Xiaojing and Zha, Hongyuan},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2111--2122},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/tang23a/tang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/tang23a.html},\n  abstract = \t {We study a matrix recovery problem with unknown correspondence: given the observation matrix $M_o=[A,\\tilde P B]$, where $\\tilde P$ is an unknown permutation matrix, we aim to recover the underlying matrix $M=[A,B]$. Such problem commonly arises in many applications where heterogeneous data are utilized and the correspondence among them are unknown, e.g., due to data mishandling or privacy concern. We show that, in some applications, it is possible to recover $M$ via solving a nuclear norm minimization problem. Moreover, under a proper low-rank condition on $M$, we derive a non-asymptotic error bound for the recovery of $M$. We propose an algorithm, $\\text{M}^3\\text{O}$ (Matrix recovery via Min-Max Optimization) which recasts this combinatorial problem as a continuous minimax optimization problem and solves it by proximal gradient with a Max-Oracle. $\\text{M}^3\\text{O}$ can also be applied to a more general scenario where we have missing entries in $M_o$ and multiple groups of data with distinct unknown correspondence. Experiments on  simulated data, the MovieLens 100K dataset and Yale B database show that $\\text{M}^3\\text{O}$ achieves state-of-the-art performance over several baselines and can recover the ground-truth correspondence with high accuracy.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/tang23a/tang23a.pdf",
        "supp": "",
        "pdf_size": 873051,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3403683036323793941&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "The Chinese University of Hong Kong, Shenzhen; The Chinese University of Hong Kong, Shenzhen; Georgia State University; The Chinese University of Hong Kong, Shenzhen",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/TZW1998/MRUC",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Georgia State University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cuhk.edu.cn;https://www.gsu.edu",
        "aff_unique_abbr": "CUHK;GSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "d9bcba89d7",
        "title": "MDPose: real-time multi-person pose estimation via mixture density model",
        "site": "https://proceedings.mlr.press/v216/seo23a.html",
        "author": "Seunghyeon Seo; Jaeyoung Yoo; Jihye Hwang; Nojun Kwak",
        "abstract": "One of the major challenges in multi-person pose estimation is instance-aware keypoint estimation. Previous methods address this problem by leveraging an off-the-shelf detector, heuristic post-grouping process or explicit instance identification process, hindering further improvements in the inference speed which is an important factor for practical applications. From the statistical point of view, those additional processes for identifying instances are necessary to bypass learning the high-dimensional joint distribution of human keypoints, which is a critical factor for another major challenge, the occlusion scenario. In this work, we propose a novel framework of single-stage instance-aware pose estimation by modeling the joint distribution of human keypoints with a mixture density model, termed as MDPose. Our MDPose estimates the distribution of human keypoints\u2019 coordinates using a mixture density model with an instance-aware keypoint head consisting simply of 8 convolutional layers. It is trained by minimizing the negative log-likelihood of the ground truth keypoints. Also, we propose a simple yet effective training strategy, Random Keypoint Grouping (RKG), which significantly alleviates the underflow problem leading to successful learning of relations between keypoints. On OCHuman dataset, which consists of images with highly occluded people, our MDPose achieves state-of-the-art performance by successfully learning the high-dimensional joint distribution of human keypoints. Furthermore, our MDPose shows significant improvement in inference speed with a competitive accuracy on MS COCO, a widely-used human keypoint dataset, thanks to the proposed much simpler single-stage pipeline.",
        "bibtex": "@InProceedings{pmlr-v216-seo23a,\n  title = \t {{MDPose}: real-time multi-person pose estimation via mixture density model},\n  author =       {Seo, Seunghyeon and Yoo, Jaeyoung and Hwang, Jihye and Kwak, Nojun},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1868--1878},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/seo23a/seo23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/seo23a.html},\n  abstract = \t {One of the major challenges in multi-person pose estimation is instance-aware keypoint estimation. Previous methods address this problem by leveraging an off-the-shelf detector, heuristic post-grouping process or explicit instance identification process, hindering further improvements in the inference speed which is an important factor for practical applications. From the statistical point of view, those additional processes for identifying instances are necessary to bypass learning the high-dimensional joint distribution of human keypoints, which is a critical factor for another major challenge, the occlusion scenario. In this work, we propose a novel framework of single-stage instance-aware pose estimation by modeling the joint distribution of human keypoints with a mixture density model, termed as MDPose. Our MDPose estimates the distribution of human keypoints\u2019 coordinates using a mixture density model with an instance-aware keypoint head consisting simply of 8 convolutional layers. It is trained by minimizing the negative log-likelihood of the ground truth keypoints. Also, we propose a simple yet effective training strategy, Random Keypoint Grouping (RKG), which significantly alleviates the underflow problem leading to successful learning of relations between keypoints. On OCHuman dataset, which consists of images with highly occluded people, our MDPose achieves state-of-the-art performance by successfully learning the high-dimensional joint distribution of human keypoints. Furthermore, our MDPose shows significant improvement in inference speed with a competitive accuracy on MS COCO, a widely-used human keypoint dataset, thanks to the proposed much simpler single-stage pipeline.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/seo23a/seo23a.pdf",
        "supp": "",
        "pdf_size": 4393212,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1282652528648239266&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "205fba0322",
        "title": "MFA: Multi-layer Feature-aware Attack for Object Detection",
        "site": "https://proceedings.mlr.press/v216/chen23d.html",
        "author": "Wen Chen; Yushan Zhang; Zhiheng Li; Yuehuan Wang",
        "abstract": "Physical adversarial attacks can mislead detectors in real-world scenarios and have attracted increasing attention. However, most existing works manipulate the detector\u2019s final outputs as attack targets while ignoring the inherent characteristics of objects. This can result in attacks being trapped in model-specific local optima and reduced transferability. To address this issue, we propose a",
        "bibtex": "@InProceedings{pmlr-v216-chen23d,\n  title = \t {{MFA}: Multi-layer Feature-aware Attack for Object Detection},\n  author =       {Chen, Wen and Zhang, Yushan and Li, Zhiheng and Wang, Yuehuan},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {336--346},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/chen23d/chen23d.pdf},\n  url = \t {https://proceedings.mlr.press/v216/chen23d.html},\n  abstract = \t {Physical adversarial attacks can mislead detectors in real-world scenarios and have attracted increasing attention. However, most existing works manipulate the detector\u2019s final outputs as attack targets while ignoring the inherent characteristics of objects. This can result in attacks being trapped in model-specific local optima and reduced transferability. To address this issue, we propose a",
        "pdf": "https://proceedings.mlr.press/v216/chen23d/chen23d.pdf",
        "supp": "",
        "pdf_size": 21421877,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17718724357940274724&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": "School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; Shanghai Institute of Satellite Engineering, Shanghai, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China; School of Artificial Intelligence and Automation, Huazhong University of Science and Technology, Wuhan, China + National Key Lab of Science and Technology on Multi-spectral Information Processing, Wuhan, China",
        "aff_domain": "hust.edu.cn;shanghaiinst.com;hust.edu.cn;hust.edu.cn",
        "email": "hust.edu.cn;shanghaiinst.com;hust.edu.cn;hust.edu.cn",
        "github": "https://github.com/ChenWen1997/MFA",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0+2",
        "aff_unique_norm": "Huazhong University of Science and Technology;Shanghai Institute of Satellite Engineering;National Key Lab of Science and Technology on Multi-spectral Information Processing",
        "aff_unique_dep": "School of Artificial Intelligence and Automation;;",
        "aff_unique_url": "http://www.hust.edu.cn;;",
        "aff_unique_abbr": "HUST;;",
        "aff_campus_unique_index": "0;1;0;0+0",
        "aff_campus_unique": "Wuhan;Shanghai",
        "aff_country_unique_index": "0;0;0;0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "e259d3978d",
        "title": "MMEL: A Joint Learning Framework for Multi-Mention Entity Linking",
        "site": "https://proceedings.mlr.press/v216/yang23d.html",
        "author": "Chengmei Yang; Bowei He; Yimeng Wu; Chao Xing; Lianghua He; Chen Ma",
        "abstract": "Entity linking, bridging mentions in the contexts with their corresponding entities in the knowledge bases, has attracted wide attention due to many potential applications. Recently, plenty of multimodal entity linking approaches have been proposed to take full advantage of the visual information rather than solely the textual modality. Although feasible, these methods mainly focus on the single-mention scenarios and neglect the scenarios where multiple mentions exist simultaneously in the same context, which limits the performance. In fact, such multi-mention scenarios are pretty common in public datasets and real-world applications. To solve this challenge, we first propose a joint feature extraction module to learn the representations of context and entity candidates, from both the visual and textual perspectives. Then, we design a pairwise training scheme (for training) and a multi-mention collaborative ranking method (for testing) to model the potential connections between different mentions. We evaluate our method on a public dataset and a self-constructed dataset, NYTimes-MEL, under both text-only and multimodal scenarios. The experimental results demonstrate that our method can largely outperform the state-of-the-art methods, especially in multi-mention scenarios. Our dataset and source code are publicly available at https://github.com/ycm094/MMEL-main.",
        "bibtex": "@InProceedings{pmlr-v216-yang23d,\n  title = \t {{MMEL}: A Joint Learning Framework for Multi-Mention Entity Linking},\n  author =       {Yang, Chengmei and He, Bowei and Wu, Yimeng and Xing, Chao and He, Lianghua and Ma, Chen},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2411--2421},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/yang23d/yang23d.pdf},\n  url = \t {https://proceedings.mlr.press/v216/yang23d.html},\n  abstract = \t {Entity linking, bridging mentions in the contexts with their corresponding entities in the knowledge bases, has attracted wide attention due to many potential applications. Recently, plenty of multimodal entity linking approaches have been proposed to take full advantage of the visual information rather than solely the textual modality. Although feasible, these methods mainly focus on the single-mention scenarios and neglect the scenarios where multiple mentions exist simultaneously in the same context, which limits the performance. In fact, such multi-mention scenarios are pretty common in public datasets and real-world applications. To solve this challenge, we first propose a joint feature extraction module to learn the representations of context and entity candidates, from both the visual and textual perspectives. Then, we design a pairwise training scheme (for training) and a multi-mention collaborative ranking method (for testing) to model the potential connections between different mentions. We evaluate our method on a public dataset and a self-constructed dataset, NYTimes-MEL, under both text-only and multimodal scenarios. The experimental results demonstrate that our method can largely outperform the state-of-the-art methods, especially in multi-mention scenarios. Our dataset and source code are publicly available at https://github.com/ycm094/MMEL-main.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/yang23d/yang23d.pdf",
        "supp": "",
        "pdf_size": 5460238,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16003887263027770194&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "https://github.com/ycm094/MMEL-main",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3d5eaa05de",
        "title": "Massively parallel reweighted wake-sleep",
        "site": "https://proceedings.mlr.press/v216/heap23a.html",
        "author": "Thomas Heap; Gavin Leech; Laurence Aitchison",
        "abstract": "Reweighted wake-sleep (RWS) is a machine learning method for performing Bayesian inference in a very general class of models. RWS draws $K$ samples from an underlying approximate posterior, then uses importance weighting to provide a better estimate of the true posterior. RWS then updates its approximate posterior towards the importance-weighted estimate of the true posterior. However, recent work [Chattergee and Diaconis, 2018] indicates that the number of samples required for effective importance weighting is exponential in the number of latent variables. Attaining such a large number of importance samples is intractable in all but the smallest models. Here, we develop massively parallel RWS, which circumvents this issue by drawing $K$ samples of all $n$ latent variables, and individually reasoning about all $K^n$ possible combinations of samples. While reasoning about $K^n$ combinations might seem intractable, the required computations can be performed in polynomial time by exploiting conditional independencies in the generative model. We show considerable improvements over standard \u201cglobal\u201d RWS, which draws $K$ samples from the full joint.",
        "bibtex": "@InProceedings{pmlr-v216-heap23a,\n  title = \t {Massively parallel reweighted wake-sleep},\n  author =       {Heap, Thomas and Leech, Gavin and Aitchison, Laurence},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {870--878},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/heap23a/heap23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/heap23a.html},\n  abstract = \t {Reweighted wake-sleep (RWS) is a machine learning method for performing Bayesian inference in a very general class of models. RWS draws $K$ samples from an underlying approximate posterior, then uses importance weighting to provide a better estimate of the true posterior. RWS then updates its approximate posterior towards the importance-weighted estimate of the true posterior. However, recent work [Chattergee and Diaconis, 2018] indicates that the number of samples required for effective importance weighting is exponential in the number of latent variables. Attaining such a large number of importance samples is intractable in all but the smallest models. Here, we develop massively parallel RWS, which circumvents this issue by drawing $K$ samples of all $n$ latent variables, and individually reasoning about all $K^n$ possible combinations of samples. While reasoning about $K^n$ combinations might seem intractable, the required computations can be performed in polynomial time by exploiting conditional independencies in the generative model. We show considerable improvements over standard \u201cglobal\u201d RWS, which draws $K$ samples from the full joint.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/heap23a/heap23a.pdf",
        "supp": "",
        "pdf_size": 436494,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13759052831338772584&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, University of Bristol, Bristol; Department of Computer Science, University of Bristol, Bristol; Department of Computer Science, University of Bristol, Bristol",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bristol",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bristol.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bristol",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "5ec180bb2b",
        "title": "Maximizing submodular functions under submodular constraints",
        "site": "https://proceedings.mlr.press/v216/padmanabhan23a.html",
        "author": "Madhavan R. Padmanabhan; Yanhui Zhu; Samik Basu; A. Pavan",
        "abstract": "We consider the problem of maximizing submodular functions under submodular constraints by formulating the problem in two ways: SCSKC and DiffC. Given two submodular functions f and g where f is monotone, the objective of SCSKC problem is to find a  set S of size at most k  that maximizes f(S) under the constraint that g(S) < theta, for a given value of theta. The problem of DiffC focuses on finding a set S of size at most k such that h(S) = f(S)-g(S) is maximized. It is known that these problems are highly inapproximable and do not admit any constant factor multiplicative approximation algorithms unless NP is easy. Known approximation algorithms involve  data-dependent approximation factors that are not efficiently computable.  We initiate a study of the design of approximation algorithms where the approximation factors are efficiently computable. For the problem of SCSKC, we prove that the greedy algorithm produces a solution whose value is at least (1-1/e)f(OPT) - A, where A is the data-dependent additive error. For the DiffC problem, we design an algorithm that uses the SCSKC greedy algorithm as a subroutine. This algorithm produces a solution whose value is at least (1-1/e)h(OPT)-B, where B is also a data-dependent additive error. A salient feature of our approach is that the additive error terms can be computed efficiently, thus enabling us to ascertain the quality of the solutions produced.",
        "bibtex": "@InProceedings{pmlr-v216-padmanabhan23a,\n  title = \t {Maximizing submodular functions under submodular constraints},\n  author =       {Padmanabhan, Madhavan R. and Zhu, Yanhui and Basu, Samik and Pavan, A.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1618--1627},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/padmanabhan23a/padmanabhan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/padmanabhan23a.html},\n  abstract = \t {We consider the problem of maximizing submodular functions under submodular constraints by formulating the problem in two ways: SCSKC and DiffC. Given two submodular functions f and g where f is monotone, the objective of SCSKC problem is to find a  set S of size at most k  that maximizes f(S) under the constraint that g(S) < theta, for a given value of theta. The problem of DiffC focuses on finding a set S of size at most k such that h(S) = f(S)-g(S) is maximized. It is known that these problems are highly inapproximable and do not admit any constant factor multiplicative approximation algorithms unless NP is easy. Known approximation algorithms involve  data-dependent approximation factors that are not efficiently computable.  We initiate a study of the design of approximation algorithms where the approximation factors are efficiently computable. For the problem of SCSKC, we prove that the greedy algorithm produces a solution whose value is at least (1-1/e)f(OPT) - A, where A is the data-dependent additive error. For the DiffC problem, we design an algorithm that uses the SCSKC greedy algorithm as a subroutine. This algorithm produces a solution whose value is at least (1-1/e)h(OPT)-B, where B is also a data-dependent additive error. A salient feature of our approach is that the additive error terms can be computed efficiently, thus enabling us to ascertain the quality of the solutions produced.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/padmanabhan23a/padmanabhan23a.pdf",
        "supp": "",
        "pdf_size": 312207,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5736118644359762923&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4d1e4e5684",
        "title": "Memory Mechanism for Unsupervised Anomaly Detection",
        "site": "https://proceedings.mlr.press/v216/li23a.html",
        "author": "Jiahao Li; Yiqiang Chen; Yunbing Xing",
        "abstract": "Unsupervised anomaly detection is a binary classification that detects anomalies in unseen samples given only unlabeled normal data. Reconstruction-based approaches are widely used, which perform reconstruction error minimization on training data to learn normal patterns and quantify the degree of anomalies by reconstruction errors on testing data. However, this approach tends to miss anomalies when the normal data has multi-pattern. Because the model generalizes unrestrictedly beyond normal patterns even to include anomaly patterns. In this paper, we proposed a memory mechanism that memorizes typical normal patterns through a capacity-controlled external differentiable matrix so that the generalization of the model to anomalies is limited by the retrieval of the matrix. We achieved state-of-the-art performance on several public benchmarks.",
        "bibtex": "@InProceedings{pmlr-v216-li23a,\n  title = \t {Memory Mechanism for Unsupervised Anomaly Detection},\n  author =       {Li, Jiahao and Chen, Yiqiang and Xing, Yunbing},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1219--1229},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/li23a/li23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/li23a.html},\n  abstract = \t {Unsupervised anomaly detection is a binary classification that detects anomalies in unseen samples given only unlabeled normal data. Reconstruction-based approaches are widely used, which perform reconstruction error minimization on training data to learn normal patterns and quantify the degree of anomalies by reconstruction errors on testing data. However, this approach tends to miss anomalies when the normal data has multi-pattern. Because the model generalizes unrestrictedly beyond normal patterns even to include anomaly patterns. In this paper, we proposed a memory mechanism that memorizes typical normal patterns through a capacity-controlled external differentiable matrix so that the generalization of the model to anomalies is limited by the retrieval of the matrix. We achieved state-of-the-art performance on several public benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/li23a/li23a.pdf",
        "supp": "",
        "pdf_size": 8541022,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=334524255782411910&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "80aca3f8f3",
        "title": "Meta-learning Control Variates: Variance Reduction with Limited Data",
        "site": "https://proceedings.mlr.press/v216/sun23a.html",
        "author": "Zhuo Sun; Chris J Oates; Fran\u00e7ois-Xavier Briol",
        "abstract": "Control variates can be a powerful tool to reduce the variance of Monte Carlo estimators, but constructing effective control variates can be challenging when the number of samples is small. In this paper, we show that when a large number of related integrals need to be computed, it is possible to leverage the similarity between these integration tasks to improve performance even when the number of samples per task is very small. Our approach, called meta learning CVs (Meta-CVs),  can be used for up to hundreds or thousands of tasks. Our empirical assessment indicates that Meta-CVs can lead to significant variance reduction in such settings, and our theoretical analysis establishes general conditions under which Meta-CVs can be successfully trained.",
        "bibtex": "@InProceedings{pmlr-v216-sun23a,\n  title = \t {Meta-learning Control Variates: Variance Reduction with Limited Data},\n  author =       {Sun, Zhuo and Oates, Chris J and Briol, Fran\\c{c}ois-Xavier},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2047--2057},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/sun23a/sun23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/sun23a.html},\n  abstract = \t {Control variates can be a powerful tool to reduce the variance of Monte Carlo estimators, but constructing effective control variates can be challenging when the number of samples is small. In this paper, we show that when a large number of related integrals need to be computed, it is possible to leverage the similarity between these integration tasks to improve performance even when the number of samples per task is very small. Our approach, called meta learning CVs (Meta-CVs),  can be used for up to hundreds or thousands of tasks. Our empirical assessment indicates that Meta-CVs can lead to significant variance reduction in such settings, and our theoretical analysis establishes general conditions under which Meta-CVs can be successfully trained.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/sun23a/sun23a.pdf",
        "supp": "",
        "pdf_size": 429792,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3847142244400526160&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6ae64b9363",
        "title": "Mitigating Transformer Overconfidence via Lipschitz Regularization",
        "site": "https://proceedings.mlr.press/v216/ye23a.html",
        "author": "Wenqian Ye; Yunsheng Ma; Xu Cao; Kun Tang",
        "abstract": "Though Transformers have achieved promising results in many computer vision tasks, they tend to be over-confident in predictions, as the standard Dot Product Self-Attention (DPSA) can barely preserve distance for the unbounded input domain. In this work, we fill this gap by proposing a novel Lipschitz Regularized Transformer (LRFormer). Specifically, we present a new similarity function with the distance within Banach Space to ensure the Lipschitzness and also regularize the term by a contractive Lipschitz Bound. The proposed method is analyzed with a theoretical guarantee, providing a rigorous basis for its effectiveness and reliability. Extensive experiments conducted on standard vision benchmarks demonstrate that our method outperforms the state-of-the-art single forward pass approaches in prediction, calibration, and uncertainty estimation.",
        "bibtex": "@InProceedings{pmlr-v216-ye23a,\n  title = \t {Mitigating Transformer Overconfidence via {L}ipschitz Regularization},\n  author =       {Ye, Wenqian and Ma, Yunsheng and Cao, Xu and Tang, Kun},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2422--2432},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/ye23a/ye23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/ye23a.html},\n  abstract = \t {Though Transformers have achieved promising results in many computer vision tasks, they tend to be over-confident in predictions, as the standard Dot Product Self-Attention (DPSA) can barely preserve distance for the unbounded input domain. In this work, we fill this gap by proposing a novel Lipschitz Regularized Transformer (LRFormer). Specifically, we present a new similarity function with the distance within Banach Space to ensure the Lipschitzness and also regularize the term by a contractive Lipschitz Bound. The proposed method is analyzed with a theoretical guarantee, providing a rigorous basis for its effectiveness and reliability. Extensive experiments conducted on standard vision benchmarks demonstrate that our method outperforms the state-of-the-art single forward pass approaches in prediction, calibration, and uncertainty estimation.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/ye23a/ye23a.pdf",
        "supp": "",
        "pdf_size": 1327120,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15203008009729655075&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2f19225c70",
        "title": "Mixture of Normalizing Flows for European Option Pricing",
        "site": "https://proceedings.mlr.press/v216/yang23b.html",
        "author": "Yongxin Yang; Timothy M. Hospedales",
        "abstract": "We present a mixture of normalizing flows (MoNF) approach to European option pricing with guarantees that its estimations are free from static arbitrage. In contrast to many existing methods that meet economic rationality constraints (e.g., non-arbitrage) by introducing auxiliary losses, our solution meets those constraints exactly by design. To achieve this, we propose to build a model for risk neutral density using normalizing flows, which results in a pricing model, instead of modelling the option pricing function directly. First, we convert the constraints for direct pricing models to the constraints for models backed by risk neutral density estimation, then we design a specific NF architecture that meets these constraints. Furthermore, we find that employing a mixture of such normalizing flows improves the performance significantly, compared to using a deeper single NF. Finally, we present a mechanism to regularise the proposed model, and this regularisation can serve as a bridge between our method and any sample-based mathematical finance method. The evaluations on five option datasets show superiority of our method compared to mathematical finance solutions and some other neural networks based methods. The code is available at \\url{https://github.com/qmfin/MoNF}.",
        "bibtex": "@InProceedings{pmlr-v216-yang23b,\n  title = \t {Mixture of Normalizing Flows for {E}uropean Option Pricing},\n  author =       {Yang, Yongxin and Hospedales, Timothy M.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2390--2399},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/yang23b/yang23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/yang23b.html},\n  abstract = \t {We present a mixture of normalizing flows (MoNF) approach to European option pricing with guarantees that its estimations are free from static arbitrage. In contrast to many existing methods that meet economic rationality constraints (e.g., non-arbitrage) by introducing auxiliary losses, our solution meets those constraints exactly by design. To achieve this, we propose to build a model for risk neutral density using normalizing flows, which results in a pricing model, instead of modelling the option pricing function directly. First, we convert the constraints for direct pricing models to the constraints for models backed by risk neutral density estimation, then we design a specific NF architecture that meets these constraints. Furthermore, we find that employing a mixture of such normalizing flows improves the performance significantly, compared to using a deeper single NF. Finally, we present a mechanism to regularise the proposed model, and this regularisation can serve as a bridge between our method and any sample-based mathematical finance method. The evaluations on five option datasets show superiority of our method compared to mathematical finance solutions and some other neural networks based methods. The code is available at \\url{https://github.com/qmfin/MoNF}.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/yang23b/yang23b.pdf",
        "supp": "",
        "pdf_size": 278405,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11584237146417537997&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Queen Mary University of London; University of Edinburgh + Samsung AI Centre, Cambridge",
        "aff_domain": "; ",
        "email": "; ",
        "github": "https://github.com/qmfin/MoNF",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2",
        "aff_unique_norm": "Queen Mary University of London;University of Edinburgh;Samsung",
        "aff_unique_dep": ";;AI Centre",
        "aff_unique_url": "https://www.qmul.ac.uk;https://www.ed.ac.uk;https://www.samsung.com/global/campaign/ai-research-centre/",
        "aff_unique_abbr": "QMUL;Edinburgh;SAC",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "London;;Cambridge",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "724e32ab84",
        "title": "MixupE: Understanding and improving Mixup from directional derivative perspective",
        "site": "https://proceedings.mlr.press/v216/zou23a.html",
        "author": "Yingtian Zou; Vikas Verma; Sarthak Mittal; Wai Hoh Tang; Hieu Pham; Juho Kannala; Yoshua Bengio; Arno Solin; Kenji Kawaguchi",
        "abstract": "Mixup is a popular data augmentation technique for training deep neural networks where additional samples are generated by linearly interpolating pairs of inputs and their labels. This technique is known to improve the generalization performance in many learning paradigms and applications. In this work, we first analyze Mixup and show that it implicitly regularizes infinitely many directional derivatives of all orders. Based on this new insight, we propose an improved version of Mixup, theoretically justified to deliver better generalization performance than the vanilla Mixup. To demonstrate the effectiveness of the proposed method, we conduct experiments across various domains such as images, tabular data, speech, and graphs. Our results show that the proposed method improves Mixup across multiple datasets using a variety of architectures, for instance, exhibiting an improvement over Mixup by 0.8% in ImageNet top-1 accuracy.",
        "bibtex": "@InProceedings{pmlr-v216-zou23a,\n  title = \t {{MixupE}: Understanding and improving Mixup from directional derivative perspective},\n  author =       {Zou, Yingtian and Verma, Vikas and Mittal, Sarthak and Tang, Wai Hoh and Pham, Hieu and Kannala, Juho and Bengio, Yoshua and Solin, Arno and Kawaguchi, Kenji},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2597--2607},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zou23a/zou23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zou23a.html},\n  abstract = \t {Mixup is a popular data augmentation technique for training deep neural networks where additional samples are generated by linearly interpolating pairs of inputs and their labels. This technique is known to improve the generalization performance in many learning paradigms and applications. In this work, we first analyze Mixup and show that it implicitly regularizes infinitely many directional derivatives of all orders. Based on this new insight, we propose an improved version of Mixup, theoretically justified to deliver better generalization performance than the vanilla Mixup. To demonstrate the effectiveness of the proposed method, we conduct experiments across various domains such as images, tabular data, speech, and graphs. Our results show that the proposed method improves Mixup across multiple datasets using a variety of architectures, for instance, exhibiting an improvement over Mixup by 0.8% in ImageNet top-1 accuracy.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/zou23a/zou23a.pdf",
        "supp": "",
        "pdf_size": 310037,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6326788447479722491&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "National University of Singapore, Singapore; Universite de Montreal, Mila, Canada + Aalto University, Finland; Universite de Montreal, Mila, Canada; National University of Singapore, Singapore; Google Brain, USA; Aalto University, Finland; Universite de Montreal, Mila, Canada; Aalto University, Finland; National University of Singapore, Singapore",
        "aff_domain": ";;;;;;;;",
        "email": ";;;;;;;;",
        "github": "https://github.com/oneHuster/MixupE",
        "project": "",
        "author_num": 9,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2;1;0;3;2;1;2;0",
        "aff_unique_norm": "National University of Singapore;Universite de Montreal;Aalto University;Google",
        "aff_unique_dep": ";Mila;;Google Brain",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.umontreal.ca;https://www.aalto.fi;https://brain.google.com",
        "aff_unique_abbr": "NUS;UM;Aalto;Google Brain",
        "aff_campus_unique_index": ";1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;1+2;1;0;3;2;1;2;0",
        "aff_country_unique": "Singapore;Canada;Finland;United States"
    },
    {
        "id": "e5e6887368",
        "title": "Mnemonist: Locating Model Parameters that Memorize Training Examples",
        "site": "https://proceedings.mlr.press/v216/shahin-shamsabadi23a.html",
        "author": "Ali Shahin Shamsabadi; Jamie Hayes; Borja Balle; Adrian Weller",
        "abstract": "Recent work has shown that an adversary can reconstruct training examples given access to the parameters of a deep learning image classification model. We show that the quality of reconstruction depends heavily on the type of activation functions used. In particular, we show that ReLU activations lead to much lower quality reconstructions compared to smooth activation functions. We explore if this phenomenon is a fundamental property of models with ReLU activations, or if it is a weakness of current attack strategies. We first study the training dynamics of small MLPs with ReLU activations and identify redundant model parameters that do not memorise training examples. Building on this, we propose our Mnemonist method, which is able to detect redundant model parameters, and then guide current attacks to focus on informative parameters to improve the quality of reconstructions of training examples from ReLU models.",
        "bibtex": "@InProceedings{pmlr-v216-shahin-shamsabadi23a,\n  title = \t {Mnemonist: Locating Model Parameters that Memorize Training Examples},\n  author =       {Shahin Shamsabadi, Ali and Hayes, Jamie and Balle, Borja and Weller, Adrian},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1879--1888},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/shahin-shamsabadi23a/shahin-shamsabadi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/shahin-shamsabadi23a.html},\n  abstract = \t {Recent work has shown that an adversary can reconstruct training examples given access to the parameters of a deep learning image classification model. We show that the quality of reconstruction depends heavily on the type of activation functions used. In particular, we show that ReLU activations lead to much lower quality reconstructions compared to smooth activation functions. We explore if this phenomenon is a fundamental property of models with ReLU activations, or if it is a weakness of current attack strategies. We first study the training dynamics of small MLPs with ReLU activations and identify redundant model parameters that do not memorise training examples. Building on this, we propose our Mnemonist method, which is able to detect redundant model parameters, and then guide current attacks to focus on informative parameters to improve the quality of reconstructions of training examples from ReLU models.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/shahin-shamsabadi23a/shahin-shamsabadi23a.pdf",
        "supp": "",
        "pdf_size": 829346,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7213603967499879646&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "54ce6420c5",
        "title": "Modified Retrace for Off-Policy Temporal Difference Learning",
        "site": "https://proceedings.mlr.press/v216/chen23a.html",
        "author": "Xingguo Chen; Xingzhou Ma; Yang Li; Guang Yang; Shangdong Yang; Yang Gao",
        "abstract": "Off-policy learning is a key to extend reinforcement learning as it allows to learn  a target policy from a different behavior policy that generates the data. However, it is well known as \u201cthe deadly triad\u201d when combined with bootstrapping and function approximation. Retrace is an efficient and  convergent off-policy algorithm with tabular value functions which employs  truncated importance sampling ratios. Unfortunately, Retrace is known to be unstable with linear function approximation. In this paper, we propose modified Retrace  to correct the  off-policy return, derive a new off-policy temporal difference learning algorithm (TD-MRetrace) with linear function approximation, and obtain a convergence guarantee under standard assumptions. Experimental results on counterexamples and control tasks validate the effectiveness of the proposed algorithm compared with traditional algorithms.",
        "bibtex": "@InProceedings{pmlr-v216-chen23a,\n  title = \t {Modified Retrace for Off-Policy Temporal Difference Learning},\n  author =       {Chen, Xingguo and Ma, Xingzhou and Li, Yang and Yang, Guang and Yang, Shangdong and Gao, Yang},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {303--312},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/chen23a/chen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/chen23a.html},\n  abstract = \t {Off-policy learning is a key to extend reinforcement learning as it allows to learn  a target policy from a different behavior policy that generates the data. However, it is well known as \u201cthe deadly triad\u201d when combined with bootstrapping and function approximation. Retrace is an efficient and  convergent off-policy algorithm with tabular value functions which employs  truncated importance sampling ratios. Unfortunately, Retrace is known to be unstable with linear function approximation. In this paper, we propose modified Retrace  to correct the  off-policy return, derive a new off-policy temporal difference learning algorithm (TD-MRetrace) with linear function approximation, and obtain a convergence guarantee under standard assumptions. Experimental results on counterexamples and control tasks validate the effectiveness of the proposed algorithm compared with traditional algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/chen23a/chen23a.pdf",
        "supp": "",
        "pdf_size": 1565474,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=622156292532045679&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Jiangsu Key Laboratory of Big Data Security & Intelligent Processing, Nanjing University of Posts and Telecommunications, Nanjing, Jiangsu, China+National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; Jiangsu Key Laboratory of Big Data Security & Intelligent Processing, Nanjing University of Posts and Telecommunications, Nanjing, Jiangsu, China; Jiangsu Key Laboratory of Big Data Security & Intelligent Processing, Nanjing University of Posts and Telecommunications, Nanjing, Jiangsu, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; Jiangsu Key Laboratory of Big Data Security & Intelligent Processing, Nanjing University of Posts and Telecommunications, Nanjing, Jiangsu, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China+Shenzhen Research Institute of Nanjing University, Shenzhen, China",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0;1;0;1+1",
        "aff_unique_norm": "Nanjing University of Posts and Telecommunications;Nanjing University",
        "aff_unique_dep": "Jiangsu Key Laboratory of Big Data Security & Intelligent Processing;National Key Laboratory for Novel Software Technology",
        "aff_unique_url": "http://www.njupt.edu.cn;http://www.nju.edu.cn",
        "aff_unique_abbr": "NUPT;Nanjing U",
        "aff_campus_unique_index": "0+0;0;0;0;0;0+1",
        "aff_campus_unique": "Nanjing;Shenzhen",
        "aff_country_unique_index": "0+0;0;0;0;0;0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "2036936d40",
        "title": "Molecule Design by Latent Space Energy-Based Modeling and Gradual Distribution Shifting",
        "site": "https://proceedings.mlr.press/v216/kong23a.html",
        "author": "Deqian Kong; Bo Pang; Tian Han; Ying Nian Wu",
        "abstract": "Generation of molecules with desired chemical and biological properties such as high drug-likeness, high binding affinity to target proteins, is critical for drug discovery. In this paper, we propose a probabilistic generative model to capture the joint distribution of molecules and their properties. Our model assumes an energy-based model (EBM) in the latent space. Conditional on the latent vector, the molecule and its properties are modeled by a molecule generation model and a property regression model respectively.  To search for molecules with desired properties,  we propose a sampling with gradual distribution shifting (SGDS) algorithm, so that after learning the model initially on the training data of existing molecules and their properties, the proposed algorithm gradually shifts the model distribution towards the region supported by molecules with desired values of properties. Our experiments show that our method achieves very strong performances on various molecule design tasks.",
        "bibtex": "@InProceedings{pmlr-v216-kong23a,\n  title = \t {Molecule Design by Latent Space Energy-Based Modeling and Gradual Distribution Shifting},\n  author =       {Kong, Deqian and Pang, Bo and Han, Tian and Wu, Ying Nian},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1109--1120},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/kong23a/kong23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/kong23a.html},\n  abstract = \t {Generation of molecules with desired chemical and biological properties such as high drug-likeness, high binding affinity to target proteins, is critical for drug discovery. In this paper, we propose a probabilistic generative model to capture the joint distribution of molecules and their properties. Our model assumes an energy-based model (EBM) in the latent space. Conditional on the latent vector, the molecule and its properties are modeled by a molecule generation model and a property regression model respectively.  To search for molecules with desired properties,  we propose a sampling with gradual distribution shifting (SGDS) algorithm, so that after learning the model initially on the training data of existing molecules and their properties, the proposed algorithm gradually shifts the model distribution towards the region supported by molecules with desired values of properties. Our experiments show that our method achieves very strong performances on various molecule design tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/kong23a/kong23a.pdf",
        "supp": "",
        "pdf_size": 444845,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15205794096481132522&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Statistics, University of California, Los Angeles; Salesforce Research; Department of Computer Science, Stevens Institute of Technology; Department of Statistics, University of California, Los Angeles",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/deqiankong/SGDS",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of California, Los Angeles;Salesforce;Stevens Institute of Technology",
        "aff_unique_dep": "Department of Statistics;Salesforce Research;Department of Computer Science",
        "aff_unique_url": "https://www.ucla.edu;https://research.salesforce.com;https://www.stevens.edu",
        "aff_unique_abbr": "UCLA;Salesforce;SIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "47e2681a96",
        "title": "Monte-Carlo Search for an Equilibrium in Dec-POMDPs",
        "site": "https://proceedings.mlr.press/v216/you23a.html",
        "author": "Yang You; Vincent Thomas; Francis Colas; Olivier Buffet",
        "abstract": "Decentralized partially observable Markov decision processes (Dec-POMDPs) formalize the problem of designing individual controllers for a group of collaborative agents under stochastic dynamics and partial observability. Seeking a global optimum is difficult (NEXP complete), but seeking a Nash equilibrium - each agent policy being a best response to the other agents - is more accessible, and allowed addressing infinite-horizon problems with solutions in the form of finite state controllers. In this paper, we show that this approach can be adapted to cases where only a generative model (a simulator) of the Dec-POMDP is available. This requires relying on a simulation-based POMDP solver to construct an agent\u2019s FSC node by node. A related process is used to heuristically derive initial FSCs. Experiment with benchmarks shows that MC-JESP is competitive with existing Dec-POMDP solvers, even better than many offline methods using explicit models.",
        "bibtex": "@InProceedings{pmlr-v216-you23a,\n  title = \t {Monte-{C}arlo Search for an Equilibrium in {Dec-POMDPs}},\n  author =       {You, Yang and Thomas, Vincent and Colas, Francis and Buffet, Olivier},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2444--2453},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/you23a/you23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/you23a.html},\n  abstract = \t {Decentralized partially observable Markov decision processes (Dec-POMDPs) formalize the problem of designing individual controllers for a group of collaborative agents under stochastic dynamics and partial observability. Seeking a global optimum is difficult (NEXP complete), but seeking a Nash equilibrium - each agent policy being a best response to the other agents - is more accessible, and allowed addressing infinite-horizon problems with solutions in the form of finite state controllers. In this paper, we show that this approach can be adapted to cases where only a generative model (a simulator) of the Dec-POMDP is available. This requires relying on a simulation-based POMDP solver to construct an agent\u2019s FSC node by node. A related process is used to heuristically derive initial FSCs. Experiment with benchmarks shows that MC-JESP is competitive with existing Dec-POMDP solvers, even better than many offline methods using explicit models.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/you23a/you23a.pdf",
        "supp": "",
        "pdf_size": 591154,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1229761676837694457&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "be5a0335d6",
        "title": "Multi-View Independent Component Analysis with Shared and Individual Sources",
        "site": "https://proceedings.mlr.press/v216/pandeva23a.html",
        "author": "Teodora Pandeva; Patrick Forr\u00e9",
        "abstract": "Independent component analysis (ICA) is a blind source separation method for linear disentanglement of independent latent sources from observed data. We investigate the special setting of noisy linear ICA, referred to as ShIndICA,  where the observations are split among different views, each receiving a mixture of shared and individual sources. We prove that the corresponding linear structure is identifiable and the sources distribution can be recovered. To computationally estimate the sources, we optimize a constrained form of the joint log-likelihood of the observed data among all views. Furthermore, we propose a model selection procedure for recovering the number of shared sources. Finally, we empirically demonstrate the advantages of our model over baselines. We apply  ShIndICA in a challenging real-life task, using three transcriptome datasets provided by three different labs (three different views). The recovered sources were used for a downstream graph inference task, facilitating the discovery of a plausible representation of the data\u2019s underlying graph structure.",
        "bibtex": "@InProceedings{pmlr-v216-pandeva23a,\n  title = \t {Multi-View Independent Component Analysis with Shared and Individual Sources},\n  author =       {Pandeva, Teodora and Forr\\'e, Patrick},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1639--1650},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/pandeva23a/pandeva23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/pandeva23a.html},\n  abstract = \t {Independent component analysis (ICA) is a blind source separation method for linear disentanglement of independent latent sources from observed data. We investigate the special setting of noisy linear ICA, referred to as ShIndICA,  where the observations are split among different views, each receiving a mixture of shared and individual sources. We prove that the corresponding linear structure is identifiable and the sources distribution can be recovered. To computationally estimate the sources, we optimize a constrained form of the joint log-likelihood of the observed data among all views. Furthermore, we propose a model selection procedure for recovering the number of shared sources. Finally, we empirically demonstrate the advantages of our model over baselines. We apply  ShIndICA in a challenging real-life task, using three transcriptome datasets provided by three different labs (three different views). The recovered sources were used for a downstream graph inference task, facilitating the discovery of a plausible representation of the data\u2019s underlying graph structure.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/pandeva23a/pandeva23a.pdf",
        "supp": "",
        "pdf_size": 1957407,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12721787444630490920&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "AI4Science, AMLab, University of Amsterdam, The Netherlands+Swammerdam Institute for Life Sciences, University of Amsterdam, The Netherlands; AI4Science, AMLab, University of Amsterdam, The Netherlands",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0",
        "aff_unique_norm": "University of Amsterdam",
        "aff_unique_dep": "AI4Science, AMLab",
        "aff_unique_url": "https://www.uva.nl",
        "aff_unique_abbr": "UvA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "5e7a4bf7f4",
        "title": "Multi-modal differentiable unsupervised feature selection",
        "site": "https://proceedings.mlr.press/v216/yang23c.html",
        "author": "Junchen Yang; Ofir Lindenbaum; Yuval Kluger; Ariel Jaffe",
        "abstract": "Multi-modal high throughput biological data presents a great scientific opportunity and a significant computational challenge. In multi-modal measurements, every sample is observed simultaneously by two or more sets of sensors. In such settings, many observed variables in both modalities are often nuisance and do not carry information about the phenomenon of interest. Here, we propose a multi-modal unsupervised feature selection framework: identifying informative variables based on coupled high-dimensional measurements. Our method is designed to identify features associated with two types of latent low-dimensional structures: (i) shared structures that govern the observations in both modalities, and (ii) differential structures that appear in only one modality. To that end,  we propose two Laplacian-based scoring operators. We incorporate the scores with differentiable gates that mask nuisance features and enhance the accuracy of the structure captured by the graph Laplacian. The performance of the new scheme is illustrated using synthetic and real datasets, including an extended biological application to single-cell multi-omics.",
        "bibtex": "@InProceedings{pmlr-v216-yang23c,\n  title = \t {Multi-modal differentiable unsupervised feature selection},\n  author =       {Yang, Junchen and Lindenbaum, Ofir and Kluger, Yuval and Jaffe, Ariel},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2400--2410},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/yang23c/yang23c.pdf},\n  url = \t {https://proceedings.mlr.press/v216/yang23c.html},\n  abstract = \t {Multi-modal high throughput biological data presents a great scientific opportunity and a significant computational challenge. In multi-modal measurements, every sample is observed simultaneously by two or more sets of sensors. In such settings, many observed variables in both modalities are often nuisance and do not carry information about the phenomenon of interest. Here, we propose a multi-modal unsupervised feature selection framework: identifying informative variables based on coupled high-dimensional measurements. Our method is designed to identify features associated with two types of latent low-dimensional structures: (i) shared structures that govern the observations in both modalities, and (ii) differential structures that appear in only one modality. To that end,  we propose two Laplacian-based scoring operators. We incorporate the scores with differentiable gates that mask nuisance features and enhance the accuracy of the structure captured by the graph Laplacian. The performance of the new scheme is illustrated using synthetic and real datasets, including an extended biological application to single-cell multi-omics.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/yang23c/yang23c.pdf",
        "supp": "",
        "pdf_size": 6445564,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7793936725609780441&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b93ea96252",
        "title": "Multi-view graph contrastive learning for solving vehicle routing problems",
        "site": "https://proceedings.mlr.press/v216/jiang23a.html",
        "author": "Yuan Jiang; Zhiguang Cao; Yaoxin Wu; Jie Zhang",
        "abstract": "Recently, neural heuristics based on deep learning have reported encouraging results for solving vehicle routing problems (VRPs), especially on independent and identically distributed (i.i.d.) instances, e.g.",
        "bibtex": "@InProceedings{pmlr-v216-jiang23a,\n  title = \t {Multi-view graph contrastive learning for solving vehicle routing problems},\n  author =       {Jiang, Yuan and Cao, Zhiguang and Wu, Yaoxin and Zhang, Jie},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {984--994},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/jiang23a/jiang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/jiang23a.html},\n  abstract = \t {Recently, neural heuristics based on deep learning have reported encouraging results for solving vehicle routing problems (VRPs), especially on independent and identically distributed (i.i.d.) instances, e.g.",
        "pdf": "https://proceedings.mlr.press/v216/jiang23a/jiang23a.pdf",
        "supp": "",
        "pdf_size": 1028868,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=772732847666175269&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore; Department of Industrial Engineering & Innovation Sciences, Eindhoven University of Technology, Netherlands; School of Computer Science and Engineering, Nanyang Technological University, Singapore",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Nanyang Technological University;Singapore Management University;Eindhoven University of Technology",
        "aff_unique_dep": "School of Computer Science and Engineering;School of Computing and Information Systems;Department of Industrial Engineering & Innovation Sciences",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.smu.edu.sg;https://www.tue.nl",
        "aff_unique_abbr": "NTU;SMU;TU/e",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Singapore;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Singapore;Netherlands"
    },
    {
        "id": "3469a44128",
        "title": "Neural probabilistic logic programming in discrete-continuous domains",
        "site": "https://proceedings.mlr.press/v216/de-smet23a.html",
        "author": "Lennert De Smet; Pedro Zuidberg Dos Martires; Robin Manhaeve; Giuseppe Marra; Angelika Kimmig; Luc De Readt",
        "abstract": "Neural-symbolic AI (NeSy) allows neural networks to exploit symbolic background knowledge in the form of logic. It has been shown to aid learning in the limited data regime and to facilitate inference on out-of-distribution data. Probabilistic NeSy focuses on integrating neural networks with both logic and probability theory, which additionally allows learning under uncertainty. A major limitation of current probabilistic NeSy systems, such as DeepProbLog, is their restriction to finite probability distributions, i.e., discrete random variables. In contrast, deep probabilistic programming (DPP) excels in modelling and optimising continuous probability distributions. Hence, we introduce DeepSeaProbLog, a neural probabilistic logic programming language that incorporates DPP techniques into NeSy. Doing so results in the support of inference and learning of both discrete and continuous probability distributions under logical constraints. Our main contributions are 1) the semantics of DeepSeaProbLog and its corresponding inference algorithm, 2) a proven asymptotically unbiased learning algorithm, and 3) a series of experiments that illustrate the versatility of our approach.",
        "bibtex": "@InProceedings{pmlr-v216-de-smet23a,\n  title = \t {Neural probabilistic logic programming in discrete-continuous domains},\n  author =       {De Smet, Lennert and Zuidberg Dos Martires, Pedro and Manhaeve, Robin and Marra, Giuseppe and Kimmig, Angelika and De Readt, Luc},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {529--538},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/de-smet23a/de-smet23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/de-smet23a.html},\n  abstract = \t {Neural-symbolic AI (NeSy) allows neural networks to exploit symbolic background knowledge in the form of logic. It has been shown to aid learning in the limited data regime and to facilitate inference on out-of-distribution data. Probabilistic NeSy focuses on integrating neural networks with both logic and probability theory, which additionally allows learning under uncertainty. A major limitation of current probabilistic NeSy systems, such as DeepProbLog, is their restriction to finite probability distributions, i.e., discrete random variables. In contrast, deep probabilistic programming (DPP) excels in modelling and optimising continuous probability distributions. Hence, we introduce DeepSeaProbLog, a neural probabilistic logic programming language that incorporates DPP techniques into NeSy. Doing so results in the support of inference and learning of both discrete and continuous probability distributions under logical constraints. Our main contributions are 1) the semantics of DeepSeaProbLog and its corresponding inference algorithm, 2) a proven asymptotically unbiased learning algorithm, and 3) a series of experiments that illustrate the versatility of our approach.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/de-smet23a/de-smet23a.pdf",
        "supp": "",
        "pdf_size": 471484,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16408888874990316150&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "aff": "Department of Computer Science, KU Leuven, Belgium; Center for Applied Autonomous Systems, \u00d6rebro, Sweden; Department of Computer Science, KU Leuven, Belgium; Department of Computer Science, KU Leuven, Belgium; Department of Computer Science, KU Leuven, Belgium; Department of Computer Science, KU Leuven, Belgium+Center for Applied Autonomous Systems, \u00d6rebro, Sweden",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;0;0+1",
        "aff_unique_norm": "KU Leuven;Center for Applied Autonomous Systems",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.kuleuven.be;",
        "aff_unique_abbr": "KU Leuven;",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";\u00d6rebro",
        "aff_country_unique_index": "0;1;0;0;0;0+1",
        "aff_country_unique": "Belgium;Sweden"
    },
    {
        "id": "8a3f81128e",
        "title": "Neural tangent kernel at initialization: linear width suffices",
        "site": "https://proceedings.mlr.press/v216/banerjee23a.html",
        "author": "Arindam Banerjee; Pedro Cisneros-Velarde; Libin Zhu; Mikhail Belkin",
        "abstract": "In this paper we study the problem of lower bounding the minimum eigenvalue of the neural tangent kernel (NTK) at initialization, an important quantity for the theoretical analysis of training in neural networks. We consider feedforward neural networks with smooth activation functions. Without any distributional assumptions on the input, we present a novel result: we show that for suitable initialization variance, $\\widetilde{\\Omega}(n)$ width, where $n$ is the number of training samples, suffices to ensure that the NTK at initialization is positive definite, improving prior results for smooth activations under our setting. Prior to our work, the sufficiency of linear width has only been shown either for networks with ReLU activation functions, and sublinear width has been shown for smooth networks but with additional conditions on the distribution of the data. The technical challenge in the analysis stems from the layerwise inhomogeneity of smooth activation functions and we handle the challenge using {\\em generalized} Hermite series expansion of such activations.",
        "bibtex": "@InProceedings{pmlr-v216-banerjee23a,\n  title = \t {Neural tangent kernel at initialization: linear width suffices},\n  author =       {Banerjee, Arindam and Cisneros-Velarde, Pedro and Zhu, Libin and Belkin, Mikhail},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {110--118},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/banerjee23a/banerjee23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/banerjee23a.html},\n  abstract = \t {In this paper we study the problem of lower bounding the minimum eigenvalue of the neural tangent kernel (NTK) at initialization, an important quantity for the theoretical analysis of training in neural networks. We consider feedforward neural networks with smooth activation functions. Without any distributional assumptions on the input, we present a novel result: we show that for suitable initialization variance, $\\widetilde{\\Omega}(n)$ width, where $n$ is the number of training samples, suffices to ensure that the NTK at initialization is positive definite, improving prior results for smooth activations under our setting. Prior to our work, the sufficiency of linear width has only been shown either for networks with ReLU activation functions, and sublinear width has been shown for smooth networks but with additional conditions on the distribution of the data. The technical challenge in the analysis stems from the layerwise inhomogeneity of smooth activation functions and we handle the challenge using {\\em generalized} Hermite series expansion of such activations.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/banerjee23a/banerjee23a.pdf",
        "supp": "",
        "pdf_size": 411167,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17442501744674526124&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f186331ec7",
        "title": "No-Regret Linear Bandits beyond Realizability",
        "site": "https://proceedings.mlr.press/v216/liu23c.html",
        "author": "Chong Liu; Ming Yin; Yu-Xiang Wang",
        "abstract": "We study linear bandits when the underlying reward function is",
        "bibtex": "@InProceedings{pmlr-v216-liu23c,\n  title = \t {No-Regret Linear Bandits beyond Realizability},\n  author =       {Liu, Chong and Yin, Ming and Wang, Yu-Xiang},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1294--1303},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/liu23c/liu23c.pdf},\n  url = \t {https://proceedings.mlr.press/v216/liu23c.html},\n  abstract = \t {We study linear bandits when the underlying reward function is",
        "pdf": "https://proceedings.mlr.press/v216/liu23c/liu23c.pdf",
        "supp": "",
        "pdf_size": 260716,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5617449819361009001&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d02d536eac",
        "title": "Noisy adversarial representation learning for effective and efficient image obfuscation",
        "site": "https://proceedings.mlr.press/v216/jeong23a.html",
        "author": "Jonghu Jeong; Minyong Cho; Philipp Benz; Tae-hoon Kim",
        "abstract": "Recent real-world applications of deep learning have led to the development of machine learning as a service (MLaaS). However, the scenario of client-server inference presents privacy concerns, where the server processes raw data sent from the user\u2019s client device. One solution to this issue is to provide an obfuscator function to the client device using Adversarial Representation Learning (ARL). Prior works have primarily focused on the privacy-utility trade-off while overlooking the computational cost and memory burden on the client side. In this paper, we propose an effective and efficient ARL method that incorporates feature noise into the ARL pipeline. We evaluated our approach on various datasets, comparing it with state-of-the-art ARL techniques. Our experimental results indicate that our method achieves better accuracy, lower computation and memory overheads, and improved resistance to information leakage and reconstruction attacks.",
        "bibtex": "@InProceedings{pmlr-v216-jeong23a,\n  title = \t {Noisy adversarial representation learning for effective and efficient image obfuscation},\n  author =       {Jeong, Jonghu and Cho, Minyong and Benz, Philipp and Kim, Tae-hoon},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {953--962},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/jeong23a/jeong23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/jeong23a.html},\n  abstract = \t {Recent real-world applications of deep learning have led to the development of machine learning as a service (MLaaS). However, the scenario of client-server inference presents privacy concerns, where the server processes raw data sent from the user\u2019s client device. One solution to this issue is to provide an obfuscator function to the client device using Adversarial Representation Learning (ARL). Prior works have primarily focused on the privacy-utility trade-off while overlooking the computational cost and memory burden on the client side. In this paper, we propose an effective and efficient ARL method that incorporates feature noise into the ARL pipeline. We evaluated our approach on various datasets, comparing it with state-of-the-art ARL techniques. Our experimental results indicate that our method achieves better accuracy, lower computation and memory overheads, and improved resistance to information leakage and reconstruction attacks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/jeong23a/jeong23a.pdf",
        "supp": "",
        "pdf_size": 3104495,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7587826326897487116&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Deeping Source Inc., Seoul, Republic of Korea; Deeping Source Inc., Seoul, Republic of Korea; Deeping Source Inc., Seoul, Republic of Korea; Deeping Source Inc., Seoul, Republic of Korea",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/DeepingSource/noisy-arlrace",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Deeping Source Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "e8a71056e9",
        "title": "Nonconvex stochastic scaled gradient descent and generalized eigenvector problems",
        "site": "https://proceedings.mlr.press/v216/li23b.html",
        "author": "Chris Junchi Li; Michael I Jordan",
        "abstract": "Motivated by the problem of online canonical correlation analysis, we propose the",
        "bibtex": "@InProceedings{pmlr-v216-li23b,\n  title = \t {Nonconvex stochastic scaled gradient descent and generalized eigenvector problems},\n  author =       {Li, Chris Junchi and Jordan, Michael I},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1230--1240},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/li23b/li23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/li23b.html},\n  abstract = \t {Motivated by the problem of online canonical correlation analysis, we propose the",
        "pdf": "https://proceedings.mlr.press/v216/li23b/li23b.pdf",
        "supp": "",
        "pdf_size": 564769,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12111952492950978631&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Electrical Engineering and Computer Sciences, UC Berkeley; Department of Electrical Engineering and Computer Sciences, UC Berkeley + Department of Statistics, UC Berkeley",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0+0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "104aa80284",
        "title": "Nystr\u00f6m $M$-Hilbert-Schmidt independence criterion",
        "site": "https://proceedings.mlr.press/v216/kalinke23a.html",
        "author": "Florian Kalinke; Zolt\u00e1n Szab\u00f3",
        "abstract": "Kernel techniques are among the most popular and powerful approaches of data science. Among the key features that make kernels ubiquitous are (i) the number of domains they have been designed for, (ii) the Hilbert structure of the function class associated to kernels facilitating their statistical analysis, and (iii) their ability to represent probability distributions without loss of information. These properties give rise to the immense success of Hilbert-Schmidt independence criterion (HSIC) which is able to capture joint independence of random variables under mild conditions, and permits closed-form estimators with quadratic computational complexity (w.r.t. the sample size). In order to alleviate the quadratic computational bottleneck in large-scale applications, multiple HSIC approximations have been proposed, however these estimators are restricted to $M=2$ random variables, do not extend naturally to the $M\\ge 2$ case, and lack theoretical guarantees. In this work, we propose an alternative Nystr\u00f6m-based HSIC estimator which handles the $M\\ge 2$ case, prove its consistency, and  demonstrate its applicability in multiple contexts, including synthetic examples, dependency testing of media annotations, and causal discovery.",
        "bibtex": "@InProceedings{pmlr-v216-kalinke23a,\n  title = \t {Nystr\u00f6m $M$-{H}ilbert-{S}chmidt independence criterion},\n  author =       {Kalinke, Florian and Szab\\'{o}, Zolt\\'{a}n},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1005--1015},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/kalinke23a/kalinke23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/kalinke23a.html},\n  abstract = \t {Kernel techniques are among the most popular and powerful approaches of data science. Among the key features that make kernels ubiquitous are (i) the number of domains they have been designed for, (ii) the Hilbert structure of the function class associated to kernels facilitating their statistical analysis, and (iii) their ability to represent probability distributions without loss of information. These properties give rise to the immense success of Hilbert-Schmidt independence criterion (HSIC) which is able to capture joint independence of random variables under mild conditions, and permits closed-form estimators with quadratic computational complexity (w.r.t. the sample size). In order to alleviate the quadratic computational bottleneck in large-scale applications, multiple HSIC approximations have been proposed, however these estimators are restricted to $M=2$ random variables, do not extend naturally to the $M\\ge 2$ case, and lack theoretical guarantees. In this work, we propose an alternative Nystr\u00f6m-based HSIC estimator which handles the $M\\ge 2$ case, prove its consistency, and  demonstrate its applicability in multiple contexts, including synthetic examples, dependency testing of media annotations, and causal discovery.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/kalinke23a/kalinke23a.pdf",
        "supp": "",
        "pdf_size": 498238,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1870821625216143772&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 16,
        "aff": "Institute for Program Structures and Data Organization, Karlsruhe Institute of Technology, Karlsruhe, Germany; Department of Statistics, London School of Economics, London, UK",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Karlsruhe Institute of Technology;London School of Economics",
        "aff_unique_dep": "Institute for Program Structures and Data Organization;Department of Statistics",
        "aff_unique_url": "https://www.kit.edu;https://www.lse.ac.uk",
        "aff_unique_abbr": "KIT;LSE",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Karlsruhe;London",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Germany;United Kingdom"
    },
    {
        "id": "88b8cd6b8f",
        "title": "On Identifiability of Conditional Causal Effects",
        "site": "https://proceedings.mlr.press/v216/kivva23a.html",
        "author": "Yaroslav Kivva; Jalal Etesami; Negar Kiyavash",
        "abstract": "We address the problem of identifiability of an arbitrary",
        "bibtex": "@InProceedings{pmlr-v216-kivva23a,\n  title = \t {On Identifiability of Conditional Causal Effects},\n  author =       {Kivva, Yaroslav and Etesami, Jalal and Kiyavash, Negar},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1078--1086},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/kivva23a/kivva23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/kivva23a.html},\n  abstract = \t {We address the problem of identifiability of an arbitrary",
        "pdf": "https://proceedings.mlr.press/v216/kivva23a/kivva23a.pdf",
        "supp": "",
        "pdf_size": 290246,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16690472314167551694&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "02b7646fa2",
        "title": "On Minimizing the Impact of Dataset Shifts on Actionable Explanations",
        "site": "https://proceedings.mlr.press/v216/meyer23a.html",
        "author": "Anna P. Meyer; Dan Ley; Suraj Srinivas; Himabindu Lakkaraju",
        "abstract": "The Right to Explanation is an important regulatory principle that allows individuals to request actionable explanations for algorithmic decisions. However, several technical challenges arise when providing such actionable explanations in practice. For instance, models are periodically retrained to handle dataset shifts. This process may invalidate some of the previously prescribed explanations, thus rendering them unactionable. But, it is unclear if and when such invalidations occur, and what factors determine explanation stability i.e., if an explanation remains unchanged amidst model retraining due to dataset shifts. In this paper, we address the aforementioned gaps and provide one of the first theoretical and empirical characterizations of the factors influencing explanation stability. To this end, we conduct rigorous theoretical analysis to demonstrate that model curvature, weight decay parameters while training, and the magnitude of the dataset shift are key factors that determine the extent of explanation (in)stability. Extensive experimentation with real-world datasets not only validates our theoretical results, but also demonstrates that the aforementioned factors dramatically impact the stability of explanations produced by various state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v216-meyer23a,\n  title = \t {On Minimizing the Impact of Dataset Shifts on Actionable Explanations},\n  author =       {Meyer, Anna P. and Ley, Dan and Srinivas, Suraj and Lakkaraju, Himabindu},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1434--1444},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/meyer23a/meyer23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/meyer23a.html},\n  abstract = \t {The Right to Explanation is an important regulatory principle that allows individuals to request actionable explanations for algorithmic decisions. However, several technical challenges arise when providing such actionable explanations in practice. For instance, models are periodically retrained to handle dataset shifts. This process may invalidate some of the previously prescribed explanations, thus rendering them unactionable. But, it is unclear if and when such invalidations occur, and what factors determine explanation stability i.e., if an explanation remains unchanged amidst model retraining due to dataset shifts. In this paper, we address the aforementioned gaps and provide one of the first theoretical and empirical characterizations of the factors influencing explanation stability. To this end, we conduct rigorous theoretical analysis to demonstrate that model curvature, weight decay parameters while training, and the magnitude of the dataset shift are key factors that determine the extent of explanation (in)stability. Extensive experimentation with real-world datasets not only validates our theoretical results, but also demonstrates that the aforementioned factors dramatically impact the stability of explanations produced by various state-of-the-art methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/meyer23a/meyer23a.pdf",
        "supp": "",
        "pdf_size": 1244848,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12915645933165732105&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f11c1d9354",
        "title": "On Testability and Goodness of Fit Tests in Missing Data Models",
        "site": "https://proceedings.mlr.press/v216/nabi23a.html",
        "author": "Razieh Nabi; Rohit Bhattacharya",
        "abstract": "Significant progress has been made in developing identification and estimation techniques for missing data problems where modeling assumptions can be described via a directed acyclic graph. The validity of results using such techniques rely on the assumptions encoded by the graph holding true; however, verification of these assumptions has not received sufficient attention in prior work. In this paper, we provide new insights on the testable implications of three broad classes of missing data graphical models, and design goodness-of-fit tests for them. The classes of models explored are: sequential missing-at-random and  missing-not-at-random models which can be used for modeling longitudinal studies with dropout/censoring, and a  no self-censoring model which can be applied to cross-sectional studies and surveys.",
        "bibtex": "@InProceedings{pmlr-v216-nabi23a,\n  title = \t {On Testability and Goodness of Fit Tests in Missing Data Models},\n  author =       {Nabi, Razieh and Bhattacharya, Rohit},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1467--1477},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/nabi23a/nabi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/nabi23a.html},\n  abstract = \t {Significant progress has been made in developing identification and estimation techniques for missing data problems where modeling assumptions can be described via a directed acyclic graph. The validity of results using such techniques rely on the assumptions encoded by the graph holding true; however, verification of these assumptions has not received sufficient attention in prior work. In this paper, we provide new insights on the testable implications of three broad classes of missing data graphical models, and design goodness-of-fit tests for them. The classes of models explored are: sequential missing-at-random and  missing-not-at-random models which can be used for modeling longitudinal studies with dropout/censoring, and a  no self-censoring model which can be applied to cross-sectional studies and surveys.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/nabi23a/nabi23a.pdf",
        "supp": "",
        "pdf_size": 413922,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8917917168733279554&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "aff": "Department of Biostatistics and Bioinformatics, Emory University, Atlanta, Georgia, USA; Department of Computer Science, Williams College, Williamstown, Massachusetts, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Emory University;Williams College",
        "aff_unique_dep": "Department of Biostatistics and Bioinformatics;Department of Computer Science",
        "aff_unique_url": "https://www.emory.edu;https://www.williams.edu",
        "aff_unique_abbr": "Emory;Williams",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Atlanta;Williamstown",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "abc5bc1acb",
        "title": "On inference and learning with probabilistic generating circuits",
        "site": "https://proceedings.mlr.press/v216/harviainen23b.html",
        "author": "Juha Harviainen; Vaidyanathan Peruvemba Ramaswamy; Mikko Koivisto",
        "abstract": "Probabilistic generating circuits (PGCs) are economical representations of multivariate probability generating polynomials (PGPs). They unify and extend decomposable probabilistic circuits and determinantal point processes, admitting tractable computation of marginal probabilities. However, the need for addition and multiplication of high-degree polynomials incurs a significant additional factor in the complexity of inference. Here, we give a new inference algorithm that eliminates this extra factor. Specifically, we show that it suffices to keep track of the highest degree coefficients of the computed polynomials, rendering the algorithm linear in the circuit size. In addition, we show that determinant-based circuits need not be expanded to division-free circuits, but can be handled by division-based fast algorithms. While these advances enhance the appeal of PGCs, we also discover an obstacle to learning them from data: it is NP-hard to recognize whether a given PGC encodes a PGP. We discuss the implications of our ambivalent findings and sketch a method, in which learning is restricted to PGCs that are composed of moderate-size subcircuits.",
        "bibtex": "@InProceedings{pmlr-v216-harviainen23b,\n  title = \t {On inference and learning with probabilistic generating circuits},\n  author =       {Harviainen, Juha and Peruvemba Ramaswamy, Vaidyanathan and Koivisto, Mikko},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {829--838},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/harviainen23b/harviainen23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/harviainen23b.html},\n  abstract = \t {Probabilistic generating circuits (PGCs) are economical representations of multivariate probability generating polynomials (PGPs). They unify and extend decomposable probabilistic circuits and determinantal point processes, admitting tractable computation of marginal probabilities. However, the need for addition and multiplication of high-degree polynomials incurs a significant additional factor in the complexity of inference. Here, we give a new inference algorithm that eliminates this extra factor. Specifically, we show that it suffices to keep track of the highest degree coefficients of the computed polynomials, rendering the algorithm linear in the circuit size. In addition, we show that determinant-based circuits need not be expanded to division-free circuits, but can be handled by division-based fast algorithms. While these advances enhance the appeal of PGCs, we also discover an obstacle to learning them from data: it is NP-hard to recognize whether a given PGC encodes a PGP. We discuss the implications of our ambivalent findings and sketch a method, in which learning is restricted to PGCs that are composed of moderate-size subcircuits.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/harviainen23b/harviainen23b.pdf",
        "supp": "",
        "pdf_size": 304665,
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3932297403233642048&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9ce4abb3ea",
        "title": "On the Convergence of Continual Learning with Adaptive Methods",
        "site": "https://proceedings.mlr.press/v216/han23a.html",
        "author": "Seungyub Han; Yeongmo Kim; Taehyun Cho; Jungwoo Lee",
        "abstract": "One of the objectives of continual learning is to prevent catastrophic forgetting in learning multiple tasks sequentially, and the existing solutions have been driven by the conceptualization of the plasticity-stability dilemma. However, the convergence of continual learning for each sequential task is less studied so far. In this paper, we provide a convergence analysis of memory-based continual learning with stochastic gradient descent and empirical evidence that training current tasks causes the cumulative degradation of previous tasks. We propose an adaptive method for nonconvex continual learning (NCCL), which adjusts step sizes of both previous and current tasks with the gradients. The proposed method can achieve the same convergence rate as the SGD method when the catastrophic forgetting term which we define in the paper is suppressed at each iteration. Further, we demonstrate that the proposed algorithm improves the performance of continual learning over existing methods for several image classification tasks.",
        "bibtex": "@InProceedings{pmlr-v216-han23a,\n  title = \t {On the Convergence of Continual Learning with Adaptive Methods},\n  author =       {Han, Seungyub and Kim, Yeongmo and Cho, Taehyun and Lee, Jungwoo},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {809--818},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/han23a/han23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/han23a.html},\n  abstract = \t {One of the objectives of continual learning is to prevent catastrophic forgetting in learning multiple tasks sequentially, and the existing solutions have been driven by the conceptualization of the plasticity-stability dilemma. However, the convergence of continual learning for each sequential task is less studied so far. In this paper, we provide a convergence analysis of memory-based continual learning with stochastic gradient descent and empirical evidence that training current tasks causes the cumulative degradation of previous tasks. We propose an adaptive method for nonconvex continual learning (NCCL), which adjusts step sizes of both previous and current tasks with the gradients. The proposed method can achieve the same convergence rate as the SGD method when the catastrophic forgetting term which we define in the paper is suppressed at each iteration. Further, we demonstrate that the proposed algorithm improves the performance of continual learning over existing methods for several image classification tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/han23a/han23a.pdf",
        "supp": "",
        "pdf_size": 361702,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8319835146270659276&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3105f150b3",
        "title": "On the Relation between Policy Improvement and Off-Policy Minimum-Variance Policy Evaluation",
        "site": "https://proceedings.mlr.press/v216/metelli23a.html",
        "author": "Alberto Maria Metelli; Samuele Meta; Marcello Restelli",
        "abstract": "Off-policy methods are the basis of a large number of effective Policy Optimization (PO) algorithms. In this setting, Importance Sampling (IS) is typically employed for off-policy evaluation, with the goal of estimating the performance of a target policy, given samples collected with a different behavioral policy. However, in Monte Carlo simulation, IS represents a variance minimization approach. In this field, a suitable behavioral distribution is employed for sampling, allowing diminishing the variance of the estimator below the one achievable when sampling from the target distribution. In this paper, we analyze IS in these two guises in the context of PO. We provide a novel view of off-policy PO, showing a connection between the policy improvement and variance minimization objectives. Then, we illustrate how minimizing the off-policy variance can, in some circumstances, lead to a policy improvement, with the advantage, compared with direct off-policy learning, of implicitly enforcing a trust region. Finally, we present numerical simulations on continuous RL benchmarks, with a particular focus on the robustness to small batch sizes.",
        "bibtex": "@InProceedings{pmlr-v216-metelli23a,\n  title = \t {On the Relation between Policy Improvement and Off-Policy Minimum-Variance Policy Evaluation},\n  author =       {Metelli, Alberto Maria and Meta, Samuele and Restelli, Marcello},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1423--1433},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/metelli23a/metelli23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/metelli23a.html},\n  abstract = \t {Off-policy methods are the basis of a large number of effective Policy Optimization (PO) algorithms. In this setting, Importance Sampling (IS) is typically employed for off-policy evaluation, with the goal of estimating the performance of a target policy, given samples collected with a different behavioral policy. However, in Monte Carlo simulation, IS represents a variance minimization approach. In this field, a suitable behavioral distribution is employed for sampling, allowing diminishing the variance of the estimator below the one achievable when sampling from the target distribution. In this paper, we analyze IS in these two guises in the context of PO. We provide a novel view of off-policy PO, showing a connection between the policy improvement and variance minimization objectives. Then, we illustrate how minimizing the off-policy variance can, in some circumstances, lead to a policy improvement, with the advantage, compared with direct off-policy learning, of implicitly enforcing a trust region. Finally, we present numerical simulations on continuous RL benchmarks, with a particular focus on the robustness to small batch sizes.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/metelli23a/metelli23a.pdf",
        "supp": "",
        "pdf_size": 476097,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17195502530758544499&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "242828f053",
        "title": "On the Role of Generalization in Transferability of Adversarial Examples",
        "site": "https://proceedings.mlr.press/v216/wang23g.html",
        "author": "Yilin Wang; Farzan Farnia",
        "abstract": "Black-box adversarial attacks designing adversarial examples for unseen deep neural networks (DNNs) have received great attention over the past years. However, the underlying factors driving the transferability of black-box adversarial examples still lack a thorough understanding. In this paper, we aim to demonstrate the role of the generalization behavior of the substitute classifier used for generating adversarial examples in the transferability of the attack scheme to unobserved DNN classifiers. To do this, we apply the max-min adversarial example game framework and show the importance of the generalization properties of the substitute DNN from training to test data in the success of the black-box attack scheme in application to different DNN classifiers. We prove theoretical generalization bounds on the difference between the attack transferability rates on training and test samples. Our bounds suggest that operator norm-based regularization methods could improve the transferability of the designed adversarial examples. We support our theoretical results by performing several numerical experiments showing the role of the substitute network\u2019s generalization in generating transferable adversarial examples. Our empirical results indicate the power of Lipschitz regularization and early stopping methods in improving the transferability of designed adversarial examples.",
        "bibtex": "@InProceedings{pmlr-v216-wang23g,\n  title = \t {On the Role of Generalization in Transferability of Adversarial Examples},\n  author =       {Wang, Yilin and Farnia, Farzan},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2259--2270},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/wang23g/wang23g.pdf},\n  url = \t {https://proceedings.mlr.press/v216/wang23g.html},\n  abstract = \t {Black-box adversarial attacks designing adversarial examples for unseen deep neural networks (DNNs) have received great attention over the past years. However, the underlying factors driving the transferability of black-box adversarial examples still lack a thorough understanding. In this paper, we aim to demonstrate the role of the generalization behavior of the substitute classifier used for generating adversarial examples in the transferability of the attack scheme to unobserved DNN classifiers. To do this, we apply the max-min adversarial example game framework and show the importance of the generalization properties of the substitute DNN from training to test data in the success of the black-box attack scheme in application to different DNN classifiers. We prove theoretical generalization bounds on the difference between the attack transferability rates on training and test samples. Our bounds suggest that operator norm-based regularization methods could improve the transferability of the designed adversarial examples. We support our theoretical results by performing several numerical experiments showing the role of the substitute network\u2019s generalization in generating transferable adversarial examples. Our empirical results indicate the power of Lipschitz regularization and early stopping methods in improving the transferability of designed adversarial examples.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/wang23g/wang23g.pdf",
        "supp": "",
        "pdf_size": 2918210,
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7521200067609030445&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong SAR; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong SAR",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9bb77021b7",
        "title": "On the informativeness of supervision signals",
        "site": "https://proceedings.mlr.press/v216/sucholutsky23a.html",
        "author": "Ilia Sucholutsky; Ruairidh M. Battleday; Katherine M. Collins; Raja Marjieh; Joshua Peterson; Pulkit Singh; Umang Bhatt; Nori Jacoby; Adrian Weller; Thomas L. Griffiths",
        "abstract": "Supervised learning typically focuses on learning transferable representations from training examples annotated by humans. While rich annotations (like soft labels) carry more information than sparse annotations (like hard labels), they are also more expensive to collect. For example, while hard labels only provide information about the closest class an object belongs to (e.g., \u201cthis is a dog\u201d), soft labels provide information about the object\u2019s relationship with multiple classes (e.g., \u201cthis is most likely a dog, but it could also be a wolf or a coyote\u201d). We use information theory to compare how a number of commonly-used supervision signals contribute to representation-learning performance, as well as how their capacity is affected by factors such as the number of labels, classes, dimensions, and noise. Our framework provides theoretical justification for using hard labels in the big-data regime, but richer supervision signals for few-shot learning and out-of-distribution generalization. We validate these results empirically in a series of experiments with over 1 million crowdsourced image annotations and conduct a cost-benefit analysis to establish a tradeoff curve that enables users to optimize the cost of supervising representation learning on their own datasets.",
        "bibtex": "@InProceedings{pmlr-v216-sucholutsky23a,\n  title = \t {On the informativeness of supervision signals},\n  author =       {Sucholutsky, Ilia and Battleday, Ruairidh M. and Collins, Katherine M. and Marjieh, Raja and Peterson, Joshua and Singh, Pulkit and Bhatt, Umang and Jacoby, Nori and Weller, Adrian and Griffiths, Thomas L.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2036--2046},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/sucholutsky23a/sucholutsky23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/sucholutsky23a.html},\n  abstract = \t {Supervised learning typically focuses on learning transferable representations from training examples annotated by humans. While rich annotations (like soft labels) carry more information than sparse annotations (like hard labels), they are also more expensive to collect. For example, while hard labels only provide information about the closest class an object belongs to (e.g., \u201cthis is a dog\u201d), soft labels provide information about the object\u2019s relationship with multiple classes (e.g., \u201cthis is most likely a dog, but it could also be a wolf or a coyote\u201d). We use information theory to compare how a number of commonly-used supervision signals contribute to representation-learning performance, as well as how their capacity is affected by factors such as the number of labels, classes, dimensions, and noise. Our framework provides theoretical justification for using hard labels in the big-data regime, but richer supervision signals for few-shot learning and out-of-distribution generalization. We validate these results empirically in a series of experiments with over 1 million crowdsourced image annotations and conduct a cost-benefit analysis to establish a tradeoff curve that enables users to optimize the cost of supervising representation learning on their own datasets.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/sucholutsky23a/sucholutsky23a.pdf",
        "supp": "",
        "pdf_size": 1045475,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14348343173693416409&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Dept. of Computer Science, Princeton University; Dept. of Computer Science, Princeton University; Dept. of Engineering, University of Cambridge; Dept. of Psychology, Princeton University; Dept. of Computer Science, Princeton University; Dept. of Computer Science, Princeton University; Dept. of Engineering, University of Cambridge + Alan Turing Institute; Max Planck Institute for Empirical Aesthetics; Dept. of Engineering, University of Cambridge + Alan Turing Institute; Dept. of Computer Science, Princeton University + Dept. of Engineering, University of Cambridge",
        "aff_domain": ";;;;;;;;;",
        "email": ";;;;;;;;;",
        "github": "",
        "project": "",
        "author_num": 10,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;0;0;1+2;3;1+2;0+1",
        "aff_unique_norm": "Princeton University;University of Cambridge;Alan Turing Institute;Max Planck Institute for Empirical Aesthetics",
        "aff_unique_dep": "Department of Computer Science;Dept. of Engineering;;",
        "aff_unique_url": "https://www.princeton.edu;https://www.cam.ac.uk;https://www.turing.ac.uk;https://www.ea.mpg.de",
        "aff_unique_abbr": "Princeton;Cambridge;ATI;MPIEA",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;1;0;0;0;1+1;2;1+1;0+1",
        "aff_country_unique": "United States;United Kingdom;Germany"
    },
    {
        "id": "3ef7f2aadd",
        "title": "On the limitations of Markovian rewards to express multi-objective, risk-sensitive, and modal tasks",
        "site": "https://proceedings.mlr.press/v216/skalse23a.html",
        "author": "Joar Skalse; Alessandro Abate",
        "abstract": "In this paper, we study the expressivity of scalar, Markovian reward functions in Reinforcement Learning (RL), and identify several limitations to what they can express. Specifically, we look at three classes of RL tasks; multi-objective RL, risk-sensitive RL, and modal RL. For each class, we derive necessary and sufficient conditions that describe when a problem in this class can be expressed using a scalar, Markovian reward. Moreover, we find that scalar, Markovian rewards are unable to express most of the instances in each of these three classes. We thereby contribute to a more complete understanding of what standard reward functions can and cannot express. In addition to this, we also call attention to modal problems as a new class of problems, since they have so far not been given any systematic treatment in the RL literature. We also briefly outline some approaches for solving some of the problems we discuss, by means of bespoke RL algorithms.",
        "bibtex": "@InProceedings{pmlr-v216-skalse23a,\n  title = \t {On the limitations of {M}arkovian rewards to express multi-objective, risk-sensitive, and modal tasks},\n  author =       {Skalse, Joar and Abate, Alessandro},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1974--1984},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/skalse23a/skalse23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/skalse23a.html},\n  abstract = \t {In this paper, we study the expressivity of scalar, Markovian reward functions in Reinforcement Learning (RL), and identify several limitations to what they can express. Specifically, we look at three classes of RL tasks; multi-objective RL, risk-sensitive RL, and modal RL. For each class, we derive necessary and sufficient conditions that describe when a problem in this class can be expressed using a scalar, Markovian reward. Moreover, we find that scalar, Markovian rewards are unable to express most of the instances in each of these three classes. We thereby contribute to a more complete understanding of what standard reward functions can and cannot express. In addition to this, we also call attention to modal problems as a new class of problems, since they have so far not been given any systematic treatment in the RL literature. We also briefly outline some approaches for solving some of the problems we discuss, by means of bespoke RL algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/skalse23a/skalse23a.pdf",
        "supp": "",
        "pdf_size": 263449,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15078457245708206014&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Computer Science Department, Oxford University, Oxford, UK + The Future of Humanity Institute, Oxford, UK; Computer Science Department, Oxford University, Oxford, UK",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0",
        "aff_unique_norm": "Oxford University;University of Oxford",
        "aff_unique_dep": "Computer Science Department;The Future of Humanity Institute",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.humanity.ox.ac.uk",
        "aff_unique_abbr": "Oxford;FOHI",
        "aff_campus_unique_index": "0+0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0+0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "7db69f8b4b",
        "title": "On the role of model uncertainties in Bayesian optimisation",
        "site": "https://proceedings.mlr.press/v216/foldager23a.html",
        "author": "Jonathan Foldager; Mikkel Jordahn; Lars K. Hansen; Michael R. Andersen",
        "abstract": "Bayesian Optimization (BO) is a popular method for black-box optimization, which relies on uncertainty as part of its decision-making process when deciding which experiment to perform next. However, not much work has addressed the effect of uncertainty on the performance of the BO algorithm and to what extent calibrated uncertainties improve the ability to find the global optimum. In this work, we provide an extensive study of the relationship between the BO performance (regret) and uncertainty calibration for popular surrogate models and acquisition functions, and compare them across both synthetic and real-world experiments. Our results show that Gaussian Processes, and more surprisingly, Deep Ensembles are strong surrogate models. Our results further show a positive association between calibration error and regret, but interestingly, this association disappears  when we control for the type of surrogate model in the analysis. We also study the effect of recalibration and demonstrate that it generally does not lead to improved regret. Finally, we provide theoretical justification for why uncertainty calibration might be difficult to combine with BO due to the small sample sizes commonly used.",
        "bibtex": "@InProceedings{pmlr-v216-foldager23a,\n  title = \t {On the role of model uncertainties in {B}ayesian optimisation},\n  author =       {Foldager, Jonathan and Jordahn, Mikkel and Hansen, Lars K. and Andersen, Michael R.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {592--601},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/foldager23a/foldager23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/foldager23a.html},\n  abstract = \t {Bayesian Optimization (BO) is a popular method for black-box optimization, which relies on uncertainty as part of its decision-making process when deciding which experiment to perform next. However, not much work has addressed the effect of uncertainty on the performance of the BO algorithm and to what extent calibrated uncertainties improve the ability to find the global optimum. In this work, we provide an extensive study of the relationship between the BO performance (regret) and uncertainty calibration for popular surrogate models and acquisition functions, and compare them across both synthetic and real-world experiments. Our results show that Gaussian Processes, and more surprisingly, Deep Ensembles are strong surrogate models. Our results further show a positive association between calibration error and regret, but interestingly, this association disappears  when we control for the type of surrogate model in the analysis. We also study the effect of recalibration and demonstrate that it generally does not lead to improved regret. Finally, we provide theoretical justification for why uncertainty calibration might be difficult to combine with BO due to the small sample sizes commonly used.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/foldager23a/foldager23a.pdf",
        "supp": "",
        "pdf_size": 347298,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15918063516850553333&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f58ef04e40",
        "title": "Online Heavy-tailed Change-point detection",
        "site": "https://proceedings.mlr.press/v216/sankararaman23a.html",
        "author": "Abishek Sankararaman; Balakrishnan Narayanaswamy",
        "abstract": "We study algorithms for online  change-point detection (OCPD), where samples that are potentially heavy-tailed, are presented one at a time and a change in the underlying mean must be detected as early as possible. We present an algorithm based on clipped Stochastic Gradient Descent (SGD), that works even if we only assume that the second moment of the data generating process is bounded. We derive guarantees on worst-case, finite-sample false-positive rate (FPR) over the family of all distributions with bounded second moment. Thus, our method is the first OCPD algorithm that guarantees finite-sample FPR, even if the data is high dimensional and  the underlying distributions are heavy-tailed. The technical contribution of our paper is to show that clipped-SGD can estimate the mean of a random vector and simultaneously provide confidence bounds at all confidence values. We combine this robust estimate with a union bound argument and construct a sequential change-point algorithm with finite-sample FPR guarantees. We show empirically that our algorithm works well in a variety of situations, whether the underlying data are heavy-tailed, light-tailed, high dimensional or discrete. No other algorithm achieves bounded FPR theoretically or empirically, over all settings we study simultaneously.",
        "bibtex": "@InProceedings{pmlr-v216-sankararaman23a,\n  title = \t {Online Heavy-tailed Change-point detection},\n  author =       {Sankararaman, Abishek and Narayanaswamy, Balakrishnan},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1815--1826},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/sankararaman23a/sankararaman23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/sankararaman23a.html},\n  abstract = \t {We study algorithms for online  change-point detection (OCPD), where samples that are potentially heavy-tailed, are presented one at a time and a change in the underlying mean must be detected as early as possible. We present an algorithm based on clipped Stochastic Gradient Descent (SGD), that works even if we only assume that the second moment of the data generating process is bounded. We derive guarantees on worst-case, finite-sample false-positive rate (FPR) over the family of all distributions with bounded second moment. Thus, our method is the first OCPD algorithm that guarantees finite-sample FPR, even if the data is high dimensional and  the underlying distributions are heavy-tailed. The technical contribution of our paper is to show that clipped-SGD can estimate the mean of a random vector and simultaneously provide confidence bounds at all confidence values. We combine this robust estimate with a union bound argument and construct a sequential change-point algorithm with finite-sample FPR guarantees. We show empirically that our algorithm works well in a variety of situations, whether the underlying data are heavy-tailed, light-tailed, high dimensional or discrete. No other algorithm achieves bounded FPR theoretically or empirically, over all settings we study simultaneously.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/sankararaman23a/sankararaman23a.pdf",
        "supp": "",
        "pdf_size": 1497573,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2836866071189226823&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "AWS AI Labs; AWS AI Labs",
        "aff_domain": "amazon.com; ",
        "email": "amazon.com; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Amazon",
        "aff_unique_dep": "AWS AI Labs",
        "aff_unique_url": "https://aws.amazon.com",
        "aff_unique_abbr": "AWS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "82a46ecf86",
        "title": "Online estimation of similarity matrices with incomplete data",
        "site": "https://proceedings.mlr.press/v216/yu23a.html",
        "author": "Fangchen Yu; Yicheng Zeng; Jianfeng Mao; Wenye Li",
        "abstract": "The similarity matrix measures pairwise similarities between a set of data points and is an essential concept in data processing, routinely used in practical applications. Obtaining a similarity matrix is typically straightforward when data points are completely observed. However, incomplete observations can make it challenging to obtain a high-quality similarity matrix, which becomes even more complex in online data. To address this challenge, we propose matrix correction algorithms that leverage the positive semi-definiteness (PSD) of the similarity matrix to improve similarity estimation in both offline and online scenarios. Our approaches have a solid theoretical guarantee of performance and excellent potential for parallel execution on large-scale data. Empirical evaluations demonstrate their high effectiveness and efficiency with significantly improved results over classical imputation-based methods, benefiting downstream applications with superior performance. Our code is available at \\url{https://github.com/CUHKSZ-Yu/OnMC}.",
        "bibtex": "@InProceedings{pmlr-v216-yu23a,\n  title = \t {Online estimation of similarity matrices with incomplete data},\n  author =       {Yu, Fangchen and Zeng, Yicheng and Mao, Jianfeng and Li, Wenye},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2454--2464},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/yu23a/yu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/yu23a.html},\n  abstract = \t {The similarity matrix measures pairwise similarities between a set of data points and is an essential concept in data processing, routinely used in practical applications. Obtaining a similarity matrix is typically straightforward when data points are completely observed. However, incomplete observations can make it challenging to obtain a high-quality similarity matrix, which becomes even more complex in online data. To address this challenge, we propose matrix correction algorithms that leverage the positive semi-definiteness (PSD) of the similarity matrix to improve similarity estimation in both offline and online scenarios. Our approaches have a solid theoretical guarantee of performance and excellent potential for parallel execution on large-scale data. Empirical evaluations demonstrate their high effectiveness and efficiency with significantly improved results over classical imputation-based methods, benefiting downstream applications with superior performance. Our code is available at \\url{https://github.com/CUHKSZ-Yu/OnMC}.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/yu23a/yu23a.pdf",
        "supp": "",
        "pdf_size": 460097,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1598552899434482186&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "The Chinese University of Hong Kong, Shenzhen; Shenzhen Research Institute of Big Data; The Chinese University of Hong Kong, Shenzhen + Shenzhen Research Institute of Big Data; The Chinese University of Hong Kong, Shenzhen + Shenzhen Research Institute of Big Data",
        "aff_domain": "link.cuhk.edu.cn;sribd.cn;cuhk.edu.cn;cuhk.edu.cn",
        "email": "link.cuhk.edu.cn;sribd.cn;cuhk.edu.cn;cuhk.edu.cn",
        "github": "https://github.com/CUHKSZ-Yu/OnMC",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0+1;0+1",
        "aff_unique_norm": "Chinese University of Hong Kong;Shenzhen Research Institute of Big Data",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cuhk.edu.cn;http://www.sribd.cn",
        "aff_unique_abbr": "CUHK;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen;",
        "aff_country_unique_index": "0;0;0+0;0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "d18081d549",
        "title": "Optimal Budget Allocation for Crowdsourcing Labels for Graphs",
        "site": "https://proceedings.mlr.press/v216/kulkarni23a.html",
        "author": "Adithya Kulkarni; Mohna Chakraborty; Sihong Xie; Qi Li",
        "abstract": "Crowdsourcing is an effective and efficient paradigm for obtaining labels for unlabeled corpus employing crowd workers. This work considers the budget allocation problem for a generalized setting on a graph of instances to be labeled where edges encode instance dependencies. Specifically, given a graph and a labeling budget, we propose an optimal policy to allocate the budget among the instances to maximize the overall labeling accuracy. We formulate the problem as a Bayesian Markov Decision Process (MDP), where we define our task as an optimization problem that maximizes the overall label accuracy under budget constraints. Then, we propose a novel stage-wise reward function that considers the effect of worker labels on the whole graph at each timestamp. This reward function is utilized to find an optimal policy for the optimization problem. Theoretically, we show that our proposed policies are consistent when the budget is infinite. We conduct extensive experiments on five real-world graph datasets and demonstrate the effectiveness of the proposed policies to achieve a higher label accuracy under budget constraints.",
        "bibtex": "@InProceedings{pmlr-v216-kulkarni23a,\n  title = \t {Optimal Budget Allocation for Crowdsourcing Labels for Graphs},\n  author =       {Kulkarni, Adithya and Chakraborty, Mohna and Xie, Sihong and Li, Qi},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1154--1163},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/kulkarni23a/kulkarni23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/kulkarni23a.html},\n  abstract = \t {Crowdsourcing is an effective and efficient paradigm for obtaining labels for unlabeled corpus employing crowd workers. This work considers the budget allocation problem for a generalized setting on a graph of instances to be labeled where edges encode instance dependencies. Specifically, given a graph and a labeling budget, we propose an optimal policy to allocate the budget among the instances to maximize the overall labeling accuracy. We formulate the problem as a Bayesian Markov Decision Process (MDP), where we define our task as an optimization problem that maximizes the overall label accuracy under budget constraints. Then, we propose a novel stage-wise reward function that considers the effect of worker labels on the whole graph at each timestamp. This reward function is utilized to find an optimal policy for the optimization problem. Theoretically, we show that our proposed policies are consistent when the budget is infinite. We conduct extensive experiments on five real-world graph datasets and demonstrate the effectiveness of the proposed policies to achieve a higher label accuracy under budget constraints.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/kulkarni23a/kulkarni23a.pdf",
        "supp": "",
        "pdf_size": 779519,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14171982113041110350&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/kulkarniadithya/GraphOBA",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fc5dcce645",
        "title": "Optimistic Thompson Sampling-based algorithms for episodic reinforcement learning",
        "site": "https://proceedings.mlr.press/v216/hu23a.html",
        "author": "Bingshan Hu; Tianyue H. Zhang; Nidhi Hegde; Mark Schmidt",
        "abstract": "We propose two  Thompson Sampling-like, model-based learning algorithms  for episodic Markov decision processes (MDPs) with a finite time horizon. Our proposed algorithms are inspired by Optimistic Thompson Sampling (O-TS), empirically studied in Chapelle and Li [2011], May et al. [2012] for stochastic multi-armed bandits. The key idea for the original O-TS is to clip the posterior distribution in an optimistic way  to ensure that the sampled models are always better than the empirical models. Both of our proposed algorithms are easy to implement and only need one posterior sample to construct an episode-dependent model. Our first  algorithm, Optimistic Thompson Sampling for MDPs (O-TS-MDP), achieves a $\\widetilde{O} \\left(\\sqrt{AS^2H^4T} \\right)$ regret bound, where $S$ is the size of the state space, $A$ is the size of the action space, $H$ is the number of time-steps per episode and $T$ is the number of episodes. Our second algorithm, Optimistic Thompson Sampling plus for MDPs (O-TS-MDP$^+$),  achieves the (near)-optimal $\\widetilde{O} \\left(\\sqrt{ASH^3T} \\right)$ regret bound by taking a more aggressive clipping strategy.  Since O-TS was only empirically studied previously, we derive regret bounds of O-TS for stochastic bandits. In addition, we propose,  O-TS-Bandit$^+$, a randomized version of UCB1 [Auer et al., 2002], for stochastic bandits. Both O-TS and O-TS-Bandit$^+$ achieve the optimal $O\\left(\\frac{A\\ln(T)}{\\Delta} \\right)$ problem-dependent regret bound, where $\\Delta$ denotes the sub-optimality gap.",
        "bibtex": "@InProceedings{pmlr-v216-hu23a,\n  title = \t {Optimistic {T}hompson Sampling-based algorithms for episodic reinforcement learning},\n  author =       {Hu, Bingshan and Zhang, Tianyue H. and Hegde, Nidhi and Schmidt, Mark},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {890--899},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/hu23a/hu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/hu23a.html},\n  abstract = \t {We propose two  Thompson Sampling-like, model-based learning algorithms  for episodic Markov decision processes (MDPs) with a finite time horizon. Our proposed algorithms are inspired by Optimistic Thompson Sampling (O-TS), empirically studied in Chapelle and Li [2011], May et al. [2012] for stochastic multi-armed bandits. The key idea for the original O-TS is to clip the posterior distribution in an optimistic way  to ensure that the sampled models are always better than the empirical models. Both of our proposed algorithms are easy to implement and only need one posterior sample to construct an episode-dependent model. Our first  algorithm, Optimistic Thompson Sampling for MDPs (O-TS-MDP), achieves a $\\widetilde{O} \\left(\\sqrt{AS^2H^4T} \\right)$ regret bound, where $S$ is the size of the state space, $A$ is the size of the action space, $H$ is the number of time-steps per episode and $T$ is the number of episodes. Our second algorithm, Optimistic Thompson Sampling plus for MDPs (O-TS-MDP$^+$),  achieves the (near)-optimal $\\widetilde{O} \\left(\\sqrt{ASH^3T} \\right)$ regret bound by taking a more aggressive clipping strategy.  Since O-TS was only empirically studied previously, we derive regret bounds of O-TS for stochastic bandits. In addition, we propose,  O-TS-Bandit$^+$, a randomized version of UCB1 [Auer et al., 2002], for stochastic bandits. Both O-TS and O-TS-Bandit$^+$ achieve the optimal $O\\left(\\frac{A\\ln(T)}{\\Delta} \\right)$ problem-dependent regret bound, where $\\Delta$ denotes the sub-optimality gap.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/hu23a/hu23a.pdf",
        "supp": "",
        "pdf_size": 419277,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9292908557177313909&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bb34a2d2c0",
        "title": "Overcoming Language Priors for Visual Question Answering via Loss Rebalancing Label and Global Context",
        "site": "https://proceedings.mlr.press/v216/cao23a.html",
        "author": "Runlin Cao; Zhixin Li",
        "abstract": "Despite the advances in Visual Question Answering (VQA), many VQA models currently suffer from language priors (i.e. generating answers directly from questions without using images), which severely reduces their robustness in real-world scenarios. We propose a novel training strategy called Loss Rebalancing Label and Global Context (LRLGC) to alleviate the above problem. Specifically, the Loss Rebalancing Label (LRL) is dynamically constructed based on the degree of sample bias to accurately adjust losses across samples and ensure a more balanced form of total losses in VQA. In addition, the Global Context (GC) provides the model with valid global information to assist the model in predicting answers more accurately. Finally, the model is trained through an ensemble-based approach that retains the beneficial effects of biased samples on the model while reducing their importance. Our approach is model-agnostic and enables end-to-end training. Extensive experimental results show that LRLGC (1) improves performance for various VQA models and (2) performs competitively in the VQA-CP v2 benchmark test.",
        "bibtex": "@InProceedings{pmlr-v216-cao23a,\n  title = \t {Overcoming Language Priors for Visual Question Answering via Loss Rebalancing Label and Global Context},\n  author =       {Cao, Runlin and Li, Zhixin},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {249--259},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/cao23a/cao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/cao23a.html},\n  abstract = \t {Despite the advances in Visual Question Answering (VQA), many VQA models currently suffer from language priors (i.e. generating answers directly from questions without using images), which severely reduces their robustness in real-world scenarios. We propose a novel training strategy called Loss Rebalancing Label and Global Context (LRLGC) to alleviate the above problem. Specifically, the Loss Rebalancing Label (LRL) is dynamically constructed based on the degree of sample bias to accurately adjust losses across samples and ensure a more balanced form of total losses in VQA. In addition, the Global Context (GC) provides the model with valid global information to assist the model in predicting answers more accurately. Finally, the model is trained through an ensemble-based approach that retains the beneficial effects of biased samples on the model while reducing their importance. Our approach is model-agnostic and enables end-to-end training. Extensive experimental results show that LRLGC (1) improves performance for various VQA models and (2) performs competitively in the VQA-CP v2 benchmark test.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/cao23a/cao23a.pdf",
        "supp": "",
        "pdf_size": 421471,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13882811219258491295&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Key Lab of Education Blockchain and Intelligent Technology, Ministry of Education, Guangxi Normal University, Guilin 541004, China+Guangxi Key Lab of Multi-source Information Mining and Security, Guangxi Normal University, Guilin 541004, China; Key Lab of Education Blockchain and Intelligent Technology, Ministry of Education, Guangxi Normal University, Guilin 541004, China+Guangxi Key Lab of Multi-source Information Mining and Security, Guangxi Normal University, Guilin 541004, China",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0+0",
        "aff_unique_norm": "Guangxi Normal University",
        "aff_unique_dep": "Key Lab of Education Blockchain and Intelligent Technology",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0+0;0+0",
        "aff_campus_unique": "Guilin",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "3910725236",
        "title": "Pandering in a (flexible) representative democracy",
        "site": "https://proceedings.mlr.press/v216/sun23b.html",
        "author": "Xiaolin Sun; Jacob Masur; Ben Abramowitz; Nicholas Mattei; Zizhan Zheng",
        "abstract": "In representative democracies, regular election cycles are supposed to prevent misbehavior by elected officials, hold them accountable, and subject them to the \u201cwill of the people.\" Pandering, or dishonest preference reporting by candidates campaigning for election, undermines this democratic idea. Much of the work on Computational Social Choice to date has investigated strategic actions in only a single election. We introduce a novel formal model of pandering and examine the resilience of two voting systems, Representative Democracy (RD) and Flexible Representative Democracy (FRD), to pandering within a single election and across multiple rounds of elections. For both voting systems, our analysis centers on the types of strategies candidates employ and how voters update their views of candidates based on how the candidates have pandered in the past. We provide theoretical results on the complexity of pandering in our setting for a single election, formulate our problem for multiple cycles as a Markov Decision Process, and use reinforcement learning to study the effects of pandering by single candidates and groups of candidates over many rounds.",
        "bibtex": "@InProceedings{pmlr-v216-sun23b,\n  title = \t {Pandering in a (flexible) representative democracy},\n  author =       {Sun, Xiaolin and Masur, Jacob and Abramowitz, Ben and Mattei, Nicholas and Zheng, Zizhan},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2058--2068},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/sun23b/sun23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/sun23b.html},\n  abstract = \t {In representative democracies, regular election cycles are supposed to prevent misbehavior by elected officials, hold them accountable, and subject them to the \u201cwill of the people.\" Pandering, or dishonest preference reporting by candidates campaigning for election, undermines this democratic idea. Much of the work on Computational Social Choice to date has investigated strategic actions in only a single election. We introduce a novel formal model of pandering and examine the resilience of two voting systems, Representative Democracy (RD) and Flexible Representative Democracy (FRD), to pandering within a single election and across multiple rounds of elections. For both voting systems, our analysis centers on the types of strategies candidates employ and how voters update their views of candidates based on how the candidates have pandered in the past. We provide theoretical results on the complexity of pandering in our setting for a single election, formulate our problem for multiple cycles as a Markov Decision Process, and use reinforcement learning to study the effects of pandering by single candidates and groups of candidates over many rounds.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/sun23b/sun23b.pdf",
        "supp": "",
        "pdf_size": 584144,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11113310151192303375&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Computer Science, Tulane University, New Orleans, Louisiana, USA; Department of Computer Science, Tulane University, New Orleans, Louisiana, USA; Department of Computer Science, Tulane University, New Orleans, Louisiana, USA; Department of Computer Science, Tulane University, New Orleans, Louisiana, USA; Department of Computer Science, Tulane University, New Orleans, Louisiana, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tulane University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.tulane.edu",
        "aff_unique_abbr": "Tulane",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New Orleans",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2d8e0eb7d4",
        "title": "Parity calibration",
        "site": "https://proceedings.mlr.press/v216/chung23a.html",
        "author": "Youngseog Chung; Aaron Rumack; Chirag Gupta",
        "abstract": "In a sequential regression setting, a decision-maker may be primarily concerned with whether the future observation will increase or decrease compared to the current one, rather than the actual value of the future observation. In this context, we introduce the notion of parity calibration, which captures the goal of calibrated forecasting for the increase-decrease (or \u201cparity\") event in a timeseries. Parity probabilities can be extracted from a forecasted distribution for the output, but we show that such a strategy leads to theoretical unpredictability and poor practical performance. We then observe that although the original task was regression, parity calibration can be expressed as binary calibration. Drawing on this connection, we use an online binary calibration method to achieve parity calibration. We demonstrate the effectiveness of our approach on real-world case studies in epidemiology, weather forecasting, and model-based control in nuclear fusion.",
        "bibtex": "@InProceedings{pmlr-v216-chung23a,\n  title = \t {Parity calibration},\n  author =       {Chung, Youngseog and Rumack, Aaron and Gupta, Chirag},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {413--423},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/chung23a/chung23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/chung23a.html},\n  abstract = \t {In a sequential regression setting, a decision-maker may be primarily concerned with whether the future observation will increase or decrease compared to the current one, rather than the actual value of the future observation. In this context, we introduce the notion of parity calibration, which captures the goal of calibrated forecasting for the increase-decrease (or \u201cparity\") event in a timeseries. Parity probabilities can be extracted from a forecasted distribution for the output, but we show that such a strategy leads to theoretical unpredictability and poor practical performance. We then observe that although the original task was regression, parity calibration can be expressed as binary calibration. Drawing on this connection, we use an online binary calibration method to achieve parity calibration. We demonstrate the effectiveness of our approach on real-world case studies in epidemiology, weather forecasting, and model-based control in nuclear fusion.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/chung23a/chung23a.pdf",
        "supp": "",
        "pdf_size": 545704,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17446937829699146791&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "34254d3d75",
        "title": "Partial identification of dose responses with hidden confounders",
        "site": "https://proceedings.mlr.press/v216/marmarelis23a.html",
        "author": "Myrl G. Marmarelis; Elizabeth Haddad; Andrew Jesson; Neda Jahanshad; Aram Galstyan; Greg Ver Steeg",
        "abstract": "Inferring causal effects of continuous-valued treatments from observational data is a crucial task promising to better inform policy- and decision-makers. A critical assumption needed to identify these effects is that all confounding variables\u2014causal parents of both the treatment and the outcome\u2014are included as covariates. Unfortunately, given observational data alone, we cannot know with certainty that this criterion is satisfied. Sensitivity analyses provide principled ways to give bounds on causal estimates when confounding variables are hidden. While much attention is focused on sensitivity analyses for discrete-valued treatments, much less is paid to continuous-valued treatments. We present novel methodology to bound both average and conditional average continuous-valued treatment-effect estimates when they cannot be point identified due to hidden confounding. A semi-synthetic benchmark on multiple datasets shows our method giving tighter coverage of the true dose-response curve than a recently proposed continuous sensitivity model and baselines. Finally, we apply our method to a real-world observational case study to demonstrate the value of identifying dose-dependent causal effects.",
        "bibtex": "@InProceedings{pmlr-v216-marmarelis23a,\n  title = \t {Partial identification of dose responses with hidden confounders},\n  author =       {Marmarelis, Myrl G. and Haddad, Elizabeth and Jesson, Andrew and Jahanshad, Neda and Galstyan, Aram and Ver Steeg, Greg},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1368--1379},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/marmarelis23a/marmarelis23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/marmarelis23a.html},\n  abstract = \t {Inferring causal effects of continuous-valued treatments from observational data is a crucial task promising to better inform policy- and decision-makers. A critical assumption needed to identify these effects is that all confounding variables\u2014causal parents of both the treatment and the outcome\u2014are included as covariates. Unfortunately, given observational data alone, we cannot know with certainty that this criterion is satisfied. Sensitivity analyses provide principled ways to give bounds on causal estimates when confounding variables are hidden. While much attention is focused on sensitivity analyses for discrete-valued treatments, much less is paid to continuous-valued treatments. We present novel methodology to bound both average and conditional average continuous-valued treatment-effect estimates when they cannot be point identified due to hidden confounding. A semi-synthetic benchmark on multiple datasets shows our method giving tighter coverage of the true dose-response curve than a recently proposed continuous sensitivity model and baselines. Finally, we apply our method to a real-world observational case study to demonstrate the value of identifying dose-dependent causal effects.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/marmarelis23a/marmarelis23a.pdf",
        "supp": "",
        "pdf_size": 479574,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7647312561206408933&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c0a7631c38",
        "title": "Personalized federated domain adaptation for item-to-item recommendation",
        "site": "https://proceedings.mlr.press/v216/fan23a.html",
        "author": "Ziwei Fan; Hao Ding; Anoop Deoras; Trong Nghia Hoang",
        "abstract": "Item-to-Item (I2I) recommendation is an important function that suggests replacement or complement options for an item based on their functional similarities or synergies. To capture such item relationships effectively, the recommenders need to understand why subsets of items are co-viewed or co-purchased by the customers. Graph-based models, such as graph neural networks (GNNs), provide a natural framework to combine, ingest and extract valuable insights from such high-order item relationships. However, learning GNNs effectively for I2I requires ingesting a large amount of relational data, which might not always be available, especially in new, emerging market segments. To mitigate this data bottleneck, we postulate that recommendation patterns learned from existing market segments (with private data) could be adapted to build effective warm-start models for emerging ones. To achieve this, we introduce a personalized graph adaptation model based on GNNs to summarize, assemble and adapt recommendation patterns across market segments with heterogeneous customer behaviors into effective local models.",
        "bibtex": "@InProceedings{pmlr-v216-fan23a,\n  title = \t {Personalized federated domain adaptation for item-to-item recommendation},\n  author =       {Fan, Ziwei and Ding, Hao and Deoras, Anoop and Hoang, Trong Nghia},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {560--570},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/fan23a/fan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/fan23a.html},\n  abstract = \t {Item-to-Item (I2I) recommendation is an important function that suggests replacement or complement options for an item based on their functional similarities or synergies. To capture such item relationships effectively, the recommenders need to understand why subsets of items are co-viewed or co-purchased by the customers. Graph-based models, such as graph neural networks (GNNs), provide a natural framework to combine, ingest and extract valuable insights from such high-order item relationships. However, learning GNNs effectively for I2I requires ingesting a large amount of relational data, which might not always be available, especially in new, emerging market segments. To mitigate this data bottleneck, we postulate that recommendation patterns learned from existing market segments (with private data) could be adapted to build effective warm-start models for emerging ones. To achieve this, we introduce a personalized graph adaptation model based on GNNs to summarize, assemble and adapt recommendation patterns across market segments with heterogeneous customer behaviors into effective local models.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/fan23a/fan23a.pdf",
        "supp": "",
        "pdf_size": 854953,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2214870099107129225&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "AWS AI Labs, California, Santa Clara, USA; AWS AI Labs, California, Santa Clara, USA; AWS AI Labs, California, Santa Clara, USA; Washington State University, Washington, Pullman, USA",
        "aff_domain": "*; ; ; \u2020",
        "email": "*; ; ; \u2020",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "AWS AI Labs;Washington State University",
        "aff_unique_dep": "AI Labs;",
        "aff_unique_url": "https://aws.amazon.com/research;https://wsu.edu",
        "aff_unique_abbr": "AWS AI Labs;WSU",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Santa Clara;Pullman",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a6599220b5",
        "title": "Pessimistic Model Selection for Offline Deep Reinforcement Learning",
        "site": "https://proceedings.mlr.press/v216/yang23a.html",
        "author": "Chao-Han Huck Yang; Zhengling Qi; Yifan Cui; Pin-Yu Chen",
        "abstract": "Deep Reinforcement Learning (DRL) has demonstrated great potentials in solving sequential decision making problems in many applications. Despite its promising performance, practical gaps exist when deploying DRL in real-world scenarios. One main barrier is the over-fitting issue that leads to poor generalizability of the policy learned by DRL. In particular, for offline DRL with observational data, model selection is a challenging task as there is no ground truth available for performance demonstration, in contrast with the online setting with simulated environments. In this work, we propose a pessimistic model selection (PMS) approach for offline DRL with a theoretical guarantee, which features a provably effective framework for finding the best policy among a set of candidate models. Two refined approaches are also proposed to address the potential bias of DRL model in identifying the optimal policy. Numerical studies demonstrated the superior performance of our approach over existing methods.",
        "bibtex": "@InProceedings{pmlr-v216-yang23a,\n  title = \t {Pessimistic Model Selection for Offline Deep Reinforcement Learning},\n  author =       {Yang, Chao-Han Huck and Qi, Zhengling and Cui, Yifan and Chen, Pin-Yu},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2379--2389},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/yang23a/yang23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/yang23a.html},\n  abstract = \t {Deep Reinforcement Learning (DRL) has demonstrated great potentials in solving sequential decision making problems in many applications. Despite its promising performance, practical gaps exist when deploying DRL in real-world scenarios. One main barrier is the over-fitting issue that leads to poor generalizability of the policy learned by DRL. In particular, for offline DRL with observational data, model selection is a challenging task as there is no ground truth available for performance demonstration, in contrast with the online setting with simulated environments. In this work, we propose a pessimistic model selection (PMS) approach for offline DRL with a theoretical guarantee, which features a provably effective framework for finding the best policy among a set of candidate models. Two refined approaches are also proposed to address the potential bias of DRL model in identifying the optimal policy. Numerical studies demonstrated the superior performance of our approach over existing methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/yang23a/yang23a.pdf",
        "supp": "",
        "pdf_size": 559247,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5633105735638276872&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Georgia Institute of Technology, USA; George Washington University, USA; Zhejiang University, China; IBM Research AI, USA",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Georgia Institute of Technology;George Washington University;Zhejiang University;IBM",
        "aff_unique_dep": ";;;AI",
        "aff_unique_url": "https://www.gatech.edu;https://www.gwu.edu;http://www.zju.edu.cn;https://www.ibm.com/research",
        "aff_unique_abbr": "Georgia Tech;GWU;ZJU;IBM AI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "27caf7b32f",
        "title": "Phase-shifted adversarial training",
        "site": "https://proceedings.mlr.press/v216/kim23b.html",
        "author": "Yeachan Kim; Seongyeon Kim; Ihyeok Seo; Bonggun Shin",
        "abstract": "Adversarial training (AT) has been considered an imperative component for safely deploying neural network-based applications. However, it typically comes with slow convergence and worse performance on clean samples (i.e., non-adversarial samples). In this work, we analyze the behavior of neural networks during learning with adversarial samples through the lens of response frequency. Interestingly, we observe that AT causes neural networks to converge slowly to high-frequency information, resulting in highly oscillatory predictions near each data point. To learn high-frequency content efficiently, we first prove that a universal phenomenon, the frequency principle (i.e., lower frequencies are learned first), still holds in AT. Building upon this theoretical foundation, we present a novel approach to AT, which we call phase-shifted adversarial training (PhaseAT). In PhaseAT, the high-frequency components, which are a contributing factor to slow convergence, are adaptively shifted into the low-frequency range where faster convergence occurs. For evaluation, we conduct extensive experiments on CIFAR-10 and ImageNet, using an adaptive attack that is carefully designed for reliable evaluation. Comprehensive results show that PhaseAT substantially improves convergence for high-frequency information, thereby leading to improved adversarial robustness.",
        "bibtex": "@InProceedings{pmlr-v216-kim23b,\n  title = \t {Phase-shifted adversarial training},\n  author =       {Kim, Yeachan and Kim, Seongyeon and Seo, Ihyeok and Shin, Bonggun},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1068--1077},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/kim23b/kim23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/kim23b.html},\n  abstract = \t {Adversarial training (AT) has been considered an imperative component for safely deploying neural network-based applications. However, it typically comes with slow convergence and worse performance on clean samples (i.e., non-adversarial samples). In this work, we analyze the behavior of neural networks during learning with adversarial samples through the lens of response frequency. Interestingly, we observe that AT causes neural networks to converge slowly to high-frequency information, resulting in highly oscillatory predictions near each data point. To learn high-frequency content efficiently, we first prove that a universal phenomenon, the frequency principle (i.e., lower frequencies are learned first), still holds in AT. Building upon this theoretical foundation, we present a novel approach to AT, which we call phase-shifted adversarial training (PhaseAT). In PhaseAT, the high-frequency components, which are a contributing factor to slow convergence, are adaptively shifted into the low-frequency range where faster convergence occurs. For evaluation, we conduct extensive experiments on CIFAR-10 and ImageNet, using an adaptive attack that is carefully designed for reliable evaluation. Comprehensive results show that PhaseAT substantially improves convergence for high-frequency information, thereby leading to improved adversarial robustness.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/kim23b/kim23b.pdf",
        "supp": "",
        "pdf_size": 357042,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13467106725676835893&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Deargen Inc., Seoul, Republic of Korea; School of Mathematics, Korea Institute for Advanced Study, Seoul, Republic of Korea; Department of Mathematics, Sungkyunkwan University, Suwon, Republic of Korea; Deargen USA Inc., Atlanta, GA",
        "aff_domain": "; ; ; ",
        "email": "; ; ; ",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Deargen Inc.;Korea Institute for Advanced Study;Sungkyunkwan University;Deargen USA Inc.",
        "aff_unique_dep": ";School of Mathematics;Department of Mathematics;",
        "aff_unique_url": ";http://www.kias.re.kr;http://www.sungkyunkwan.edu;",
        "aff_unique_abbr": ";KIAS;SKKU;",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Seoul;Suwon",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "64ae496110",
        "title": "Piecewise Deterministic Markov Processes for Bayesian Neural Networks",
        "site": "https://proceedings.mlr.press/v216/goan23a.html",
        "author": "Ethan Goan; Dimitri Perrin; Kerrie Mengersen; Clinton Fookes",
        "abstract": "Inference on modern Bayesian Neural Networks (BNNs) often relies on a variational inference treatment, imposing violated assumptions of independence and the form of the posterior. Traditional MCMC approaches avoid these assumptions at the cost of increased computation due to its incompatibility to subsampling of the likelihood. New Piecewise Deterministic Markov Process (PDMP) samplers permit subsampling, though introduce a model-specific inhomogenous Poisson Process (IPPs) which is difficult to sample from. This work introduces a new generic and adaptive thinning scheme for sampling from these IPPs, and demonstrates how this approach can accelerate the application of PDMPs for inference in BNNs. Experimentation illustrates how inference with these methods is computationally feasible, can improve predictive accuracy, MCMC mixing performance, and provide informative uncertainty measurements when compared against other approximate inference schemes.",
        "bibtex": "@InProceedings{pmlr-v216-goan23a,\n  title = \t {Piecewise Deterministic {M}arkov Processes for {B}ayesian Neural Networks},\n  author =       {Goan, Ethan and Perrin, Dimitri and Mengersen, Kerrie and Fookes, Clinton},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {712--722},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/goan23a/goan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/goan23a.html},\n  abstract = \t {Inference on modern Bayesian Neural Networks (BNNs) often relies on a variational inference treatment, imposing violated assumptions of independence and the form of the posterior. Traditional MCMC approaches avoid these assumptions at the cost of increased computation due to its incompatibility to subsampling of the likelihood. New Piecewise Deterministic Markov Process (PDMP) samplers permit subsampling, though introduce a model-specific inhomogenous Poisson Process (IPPs) which is difficult to sample from. This work introduces a new generic and adaptive thinning scheme for sampling from these IPPs, and demonstrates how this approach can accelerate the application of PDMPs for inference in BNNs. Experimentation illustrates how inference with these methods is computationally feasible, can improve predictive accuracy, MCMC mixing performance, and provide informative uncertainty measurements when compared against other approximate inference schemes.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/goan23a/goan23a.pdf",
        "supp": "",
        "pdf_size": 2241919,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16060475691909423902&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0d350c7971",
        "title": "Posterior sampling-based online learning for the stochastic shortest path model",
        "site": "https://proceedings.mlr.press/v216/jafarnia-jahromi23a.html",
        "author": "Mehdi Jafarnia-Jahromi; Liyu Chen; Rahul Jain; Haipeng Luo",
        "abstract": "We consider the problem of online reinforcement learning for the Stochastic Shortest Path (SSP) problem modeled as an unknown MDP with an absorbing state. We propose PSRL-SSP, a simple posterior sampling-based reinforcement learning algorithm for the SSP problem. The algorithm operates in epochs. At the beginning of each epoch, a sample is drawn from the posterior distribution on the unknown model dynamics, and the optimal policy with respect to the drawn sample is followed during that epoch. An epoch completes if either the  number of visits to the goal state in the current epoch exceeds that of the previous epoch, or the number of visits to any of the state-action pairs is doubled. We establish a Bayesian regret bound of $\\tilde{\\mathcal{O}}(B_{\\ast} S\\sqrt{AK})$, where $B_{\\ast}$ is an upper bound on the expected cost of the optimal policy, $S$ is the size of the state space, $A$ is the size of the action space, and $K$ is the number of episodes. The algorithm only requires the knowledge of the prior distribution, and has no hyper-parameters to tune. It is the first such posterior sampling algorithm and outperforms numerically previously proposed optimism-based algorithms.",
        "bibtex": "@InProceedings{pmlr-v216-jafarnia-jahromi23a,\n  title = \t {Posterior sampling-based online learning for the stochastic shortest path model},\n  author =       {Jafarnia-Jahromi, Mehdi and Chen, Liyu and Jain, Rahul and Luo, Haipeng},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {922--931},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/jafarnia-jahromi23a/jafarnia-jahromi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/jafarnia-jahromi23a.html},\n  abstract = \t {We consider the problem of online reinforcement learning for the Stochastic Shortest Path (SSP) problem modeled as an unknown MDP with an absorbing state. We propose PSRL-SSP, a simple posterior sampling-based reinforcement learning algorithm for the SSP problem. The algorithm operates in epochs. At the beginning of each epoch, a sample is drawn from the posterior distribution on the unknown model dynamics, and the optimal policy with respect to the drawn sample is followed during that epoch. An epoch completes if either the  number of visits to the goal state in the current epoch exceeds that of the previous epoch, or the number of visits to any of the state-action pairs is doubled. We establish a Bayesian regret bound of $\\tilde{\\mathcal{O}}(B_{\\ast} S\\sqrt{AK})$, where $B_{\\ast}$ is an upper bound on the expected cost of the optimal policy, $S$ is the size of the state space, $A$ is the size of the action space, and $K$ is the number of episodes. The algorithm only requires the knowledge of the prior distribution, and has no hyper-parameters to tune. It is the first such posterior sampling algorithm and outperforms numerically previously proposed optimism-based algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/jafarnia-jahromi23a/jafarnia-jahromi23a.pdf",
        "supp": "",
        "pdf_size": 789808,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8066836619304297540&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0fff335353",
        "title": "Practical privacy-preserving Gaussian process regression via secret sharing",
        "site": "https://proceedings.mlr.press/v216/luo23a.html",
        "author": "Jinglong Luo; Yehong Zhang; Jiaqi Zhang; Shuang Qin; Hui Wang; Yue Yu; Zenglin Xu",
        "abstract": "Gaussian process regression (GPR) is a non-parametric model that has been used in many real-world applications that involve sensitive personal data (e.g., healthcare, finance, etc.) from multiple data owners. To fully and securely exploit the value of different data sources, this paper proposes a privacy-preserving GPR method based on secret sharing (SS), a secure multi-party computation (SMPC) technique. In contrast to existing studies that protect the data privacy of GPR via homomorphic encryption, differential privacy, or federated learning, our proposed method is more practical and can be used to preserve the data privacy of both the model inputs and outputs for various data-sharing scenarios (e.g., horizontally/vertically-partitioned data). However, it is non-trivial to directly apply SS on the conventional GPR algorithm, as it includes some operations whose accuracy and/or efficiency have not been well-enhanced in the current SMPC protocol. To address this issue, we derive a new SS-based exponentiation operation through the idea of \u201cconfusion-correction\u201d and construct an SS-based matrix inversion algorithm based on Cholesky decomposition. More importantly, we theoretically analyze the communication cost and the security of the proposed SS-based operations. Empirical results show that our proposed method can achieve reasonable accuracy and efficiency under the premise of preserving data privacy.",
        "bibtex": "@InProceedings{pmlr-v216-luo23a,\n  title = \t {Practical privacy-preserving {G}aussian process regression via secret sharing},\n  author =       {Luo, Jinglong and Zhang, Yehong and Zhang, Jiaqi and Qin, Shuang and Wang, Hui and Yu, Yue and Xu, Zenglin},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1315--1325},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/luo23a/luo23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/luo23a.html},\n  abstract = \t {Gaussian process regression (GPR) is a non-parametric model that has been used in many real-world applications that involve sensitive personal data (e.g., healthcare, finance, etc.) from multiple data owners. To fully and securely exploit the value of different data sources, this paper proposes a privacy-preserving GPR method based on secret sharing (SS), a secure multi-party computation (SMPC) technique. In contrast to existing studies that protect the data privacy of GPR via homomorphic encryption, differential privacy, or federated learning, our proposed method is more practical and can be used to preserve the data privacy of both the model inputs and outputs for various data-sharing scenarios (e.g., horizontally/vertically-partitioned data). However, it is non-trivial to directly apply SS on the conventional GPR algorithm, as it includes some operations whose accuracy and/or efficiency have not been well-enhanced in the current SMPC protocol. To address this issue, we derive a new SS-based exponentiation operation through the idea of \u201cconfusion-correction\u201d and construct an SS-based matrix inversion algorithm based on Cholesky decomposition. More importantly, we theoretically analyze the communication cost and the security of the proposed SS-based operations. Empirical results show that our proposed method can achieve reasonable accuracy and efficiency under the premise of preserving data privacy.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/luo23a/luo23a.pdf",
        "supp": "",
        "pdf_size": 2035530,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16742819989670874938&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Harbin Institute of Technology, Shenzhen, China+Peng Cheng Laboratory, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; Peng Cheng Laboratory, Shenzhen, China; Harbin Institute of Technology, Shenzhen, China+Peng Cheng Laboratory, Shenzhen, China",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1;1;1;1;1;0+1",
        "aff_unique_norm": "Harbin Institute of Technology;Pengcheng Laboratory",
        "aff_unique_dep": ";Peng Cheng Laboratory",
        "aff_unique_url": "http://en.hhit.edu.cn/;",
        "aff_unique_abbr": "HIT;",
        "aff_campus_unique_index": "0+0;0;0;0;0;0;0+0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0+0;0;0;0;0;0;0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "a3b065b689",
        "title": "Private Prediction Strikes Back! Private Kernelized Nearest Neighbors with Individual R\u00e9nyi Filter",
        "site": "https://proceedings.mlr.press/v216/zhu23b.html",
        "author": "Yuqing Zhu; Xuandong Zhao; Chuan Guo; Yu-Xiang Wang",
        "abstract": "Most existing approaches of differentially private (DP) machine learning focus on",
        "bibtex": "@InProceedings{pmlr-v216-zhu23b,\n  title = \t {Private Prediction Strikes Back! {P}rivate Kernelized Nearest Neighbors with Individual {R}\u00e9nyi Filter},\n  author =       {Zhu, Yuqing and Zhao, Xuandong and Guo, Chuan and Wang, Yu-Xiang},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2586--2596},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zhu23b/zhu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zhu23b.html},\n  abstract = \t {Most existing approaches of differentially private (DP) machine learning focus on",
        "pdf": "https://proceedings.mlr.press/v216/zhu23b/zhu23b.pdf",
        "supp": "",
        "pdf_size": 441748,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10916591963696422063&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "UC Santa Barbara; UC Santa Barbara; FAIR / Meta AI; UC Santa Barbara",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "https://github.com/jeremy43/Ind_kNN",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of California, Santa Barbara;Meta",
        "aff_unique_dep": ";Meta AI",
        "aff_unique_url": "https://www.ucsb.edu;https://ai.facebook.com",
        "aff_unique_abbr": "UCSB;Meta AI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Santa Barbara;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1099a82406",
        "title": "Probabilistic Flow Circuits: Towards Unified Deep Models for Tractable Probabilistic Inference",
        "site": "https://proceedings.mlr.press/v216/sidheekh23a.html",
        "author": "Sahil Sidheekh; Kristian Kersting; Sriraam Natarajan",
        "abstract": "We consider the problem of increasing the expressivity of probabilistic circuits by augmenting them with the successful generative models of normalizing flows. To this effect, we theoretically establish the requirement of decomposability for such combinations to retain tractability of the learned models. Our model, called Probabilistic Flow Circuits, essentially extends circuits by allowing for normalizing flows at the leaves. Our empirical evaluation clearly establishes the expressivity and tractability of this new class of probabilistic circuits.",
        "bibtex": "@InProceedings{pmlr-v216-sidheekh23a,\n  title = \t {Probabilistic Flow Circuits: Towards Unified Deep Models for Tractable Probabilistic Inference},\n  author =       {Sidheekh, Sahil and Kersting, Kristian and Natarajan, Sriraam},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1964--1973},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/sidheekh23a/sidheekh23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/sidheekh23a.html},\n  abstract = \t {We consider the problem of increasing the expressivity of probabilistic circuits by augmenting them with the successful generative models of normalizing flows. To this effect, we theoretically establish the requirement of decomposability for such combinations to retain tractability of the learned models. Our model, called Probabilistic Flow Circuits, essentially extends circuits by allowing for normalizing flows at the leaves. Our empirical evaluation clearly establishes the expressivity and tractability of this new class of probabilistic circuits.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/sidheekh23a/sidheekh23a.pdf",
        "supp": "",
        "pdf_size": 1309834,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6144368807831563942&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "22b4c8959e",
        "title": "Probabilistic Multi-Dimensional Classification",
        "site": "https://proceedings.mlr.press/v216/nguyen23b.html",
        "author": "Vu-Linh Nguyen; Yang Yang; Cassio De Campos",
        "abstract": "Multi-dimensional classification (MDC) can be employed in a range of applications where one needs to predict multiple class variables for each given instance. Many existing MDC methods suffer from at least one of inaccuracy, scalability, limited use to certain types of data, hardness of interpretation or lack of probabilistic (uncertainty) estimations. This paper is an attempt to address all these disadvantages simultaneously. We propose a formal framework for probabilistic MDC in which learning an optimal multi-dimensional classifier can be decomposed, without loss of generality, into learning a set of (smaller) single-variable multi-class probabilistic classifiers and a directed acyclic graph. Current and future developments of both probabilistic classification and graphical model learning can directly enhance our framework, which is flexible and provably optimal. A collection of experiments is conducted to highlight the usefulness of this MDC framework.",
        "bibtex": "@InProceedings{pmlr-v216-nguyen23b,\n  title = \t {Probabilistic Multi-Dimensional Classification},\n  author =       {Nguyen, Vu-Linh and Yang, Yang and De Campos, Cassio},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1522--1533},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/nguyen23b/nguyen23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/nguyen23b.html},\n  abstract = \t {Multi-dimensional classification (MDC) can be employed in a range of applications where one needs to predict multiple class variables for each given instance. Many existing MDC methods suffer from at least one of inaccuracy, scalability, limited use to certain types of data, hardness of interpretation or lack of probabilistic (uncertainty) estimations. This paper is an attempt to address all these disadvantages simultaneously. We propose a formal framework for probabilistic MDC in which learning an optimal multi-dimensional classifier can be decomposed, without loss of generality, into learning a set of (smaller) single-variable multi-class probabilistic classifiers and a directed acyclic graph. Current and future developments of both probabilistic classification and graphical model learning can directly enhance our framework, which is flexible and provably optimal. A collection of experiments is conducted to highlight the usefulness of this MDC framework.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/nguyen23b/nguyen23b.pdf",
        "supp": "",
        "pdf_size": 429304,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16085811952187747544&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Heudiasyc Laboratory, University of Technology of Compi\u00e8gne, France; Department of Computer Science, KU Leuven, Belgium; Eindhoven University of Technology, The Netherlands",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Technology of Compi\u00e8gne;KU Leuven;Eindhoven University of Technology",
        "aff_unique_dep": "Heudiasyc Laboratory;Department of Computer Science;",
        "aff_unique_url": "https://www.utt.fr;https://www.kuleuven.be;https://www.tue.nl",
        "aff_unique_abbr": ";KU Leuven;TU/e",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;2",
        "aff_country_unique": "France;Belgium;Netherlands"
    },
    {
        "id": "4d2e1d3217",
        "title": "Probabilistic circuits that know what they don\u2019t know",
        "site": "https://proceedings.mlr.press/v216/ventola23a.html",
        "author": "Fabrizio Ventola; Steven Braun; Yu Zhongjie; Martin Mundt; Kristian Kersting",
        "abstract": "Probabilistic circuits (PCs) are models that allow exact and tractable probabilistic inference. In contrast to neural networks, they are often assumed to be well-calibrated and robust to out-of-distribution (OOD) data. In this paper, we show that PCs are in fact not robust to OOD data, i.e., they don\u2019t know what they don\u2019t know. We then show how this challenge can be overcome by model uncertainty quantification. To this end, we propose tractable dropout inference (TDI), an inference procedure to estimate uncertainty by deriving an analytical solution to Monte Carlo dropout (MCD) through variance propagation. Unlike MCD in neural networks, which comes at the cost of multiple network evaluations, TDI provides tractable sampling-free uncertainty estimates in a single forward pass. TDI improves the robustness of PCs to distribution shift and OOD data, demonstrated through a series of experiments evaluating the classification confidence and uncertainty estimates on real-world data.",
        "bibtex": "@InProceedings{pmlr-v216-ventola23a,\n  title = \t {Probabilistic circuits that know what they don\u2019t know},\n  author =       {Ventola, Fabrizio and Braun, Steven and Zhongjie, Yu and Mundt, Martin and Kersting, Kristian},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2157--2167},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/ventola23a/ventola23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/ventola23a.html},\n  abstract = \t {Probabilistic circuits (PCs) are models that allow exact and tractable probabilistic inference. In contrast to neural networks, they are often assumed to be well-calibrated and robust to out-of-distribution (OOD) data. In this paper, we show that PCs are in fact not robust to OOD data, i.e., they don\u2019t know what they don\u2019t know. We then show how this challenge can be overcome by model uncertainty quantification. To this end, we propose tractable dropout inference (TDI), an inference procedure to estimate uncertainty by deriving an analytical solution to Monte Carlo dropout (MCD) through variance propagation. Unlike MCD in neural networks, which comes at the cost of multiple network evaluations, TDI provides tractable sampling-free uncertainty estimates in a single forward pass. TDI improves the robustness of PCs to distribution shift and OOD data, demonstrated through a series of experiments evaluating the classification confidence and uncertainty estimates on real-world data.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/ventola23a/ventola23a.pdf",
        "supp": "",
        "pdf_size": 334302,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14146911794091611036&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "afcb2b1883",
        "title": "Probabilistically robust conformal prediction",
        "site": "https://proceedings.mlr.press/v216/ghosh23a.html",
        "author": "Subhankar Ghosh; Yuanjie Shi; Taha Belkhouja; Yan Yan; Jana Doppa; Brian Jones",
        "abstract": "Conformal prediction (CP) is a framework to quantify uncertainty of machine learning classifiers including deep neural networks. Given a testing example and a trained classifier, CP produces a prediction set of candidate labels with a user-specified  coverage (i.e., true class label is contained with high probability). Almost all the existing work on CP assumes clean testing data and there is not much known about the robustness of CP algorithms w.r.t natural/adversarial perturbations to testing examples. This paper studies the problem of probabilistically robust conformal prediction (PRCP) which ensures robustness to most perturbations around clean input examples. PRCP generalizes the standard CP (cannot handle perturbations) and adversarially robust CP (ensures robustness w.r.t worst-case perturbations) to achieve better trade-offs between nominal performance and robustness.  We propose a novel adaptive PRCP (aPRCP) algorithm to achieve probabilistically robust coverage. The key idea behind aPRCP is to determine two parallel thresholds, one for data samples and another one for the perturbations on data (aka \"quantile-of-quantile\u201d design). We provide theoretical analysis to show that aPRCP algorithm achieves robust coverage. Our experiments on CIFAR-10, CIFAR-100, and ImageNet datasets using deep neural networks demonstrate that aPRCP achieves better trade-offs than state-of-the-art CP and adversarially robust CP algorithms.",
        "bibtex": "@InProceedings{pmlr-v216-ghosh23a,\n  title = \t {Probabilistically robust conformal prediction},\n  author =       {Ghosh, Subhankar and Shi, Yuanjie and Belkhouja, Taha and Yan, Yan and Doppa, Jana and Jones, Brian},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {681--690},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/ghosh23a/ghosh23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/ghosh23a.html},\n  abstract = \t {Conformal prediction (CP) is a framework to quantify uncertainty of machine learning classifiers including deep neural networks. Given a testing example and a trained classifier, CP produces a prediction set of candidate labels with a user-specified  coverage (i.e., true class label is contained with high probability). Almost all the existing work on CP assumes clean testing data and there is not much known about the robustness of CP algorithms w.r.t natural/adversarial perturbations to testing examples. This paper studies the problem of probabilistically robust conformal prediction (PRCP) which ensures robustness to most perturbations around clean input examples. PRCP generalizes the standard CP (cannot handle perturbations) and adversarially robust CP (ensures robustness w.r.t worst-case perturbations) to achieve better trade-offs between nominal performance and robustness.  We propose a novel adaptive PRCP (aPRCP) algorithm to achieve probabilistically robust coverage. The key idea behind aPRCP is to determine two parallel thresholds, one for data samples and another one for the perturbations on data (aka \"quantile-of-quantile\u201d design). We provide theoretical analysis to show that aPRCP algorithm achieves robust coverage. Our experiments on CIFAR-10, CIFAR-100, and ImageNet datasets using deep neural networks demonstrate that aPRCP achieves better trade-offs than state-of-the-art CP and adversarially robust CP algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/ghosh23a/ghosh23a.pdf",
        "supp": "",
        "pdf_size": 1026351,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2069747665837106461&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "School of Electrical Engineering and Computer Science, Washington State University; School of Electrical Engineering and Computer Science, Washington State University; School of Electrical Engineering and Computer Science, Washington State University; School of Electrical Engineering and Computer Science, Washington State University; School of Electrical Engineering and Computer Science, Washington State University; Proofpoint Inc.",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Washington State University;Proofpoint",
        "aff_unique_dep": "School of Electrical Engineering and Computer Science;",
        "aff_unique_url": "https://www.wsu.edu;https://www.proofpoint.com",
        "aff_unique_abbr": "WSU;Proofpoint",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "812114712d",
        "title": "Provably Efficient Adversarial Imitation Learning with Unknown Transitions",
        "site": "https://proceedings.mlr.press/v216/xu23c.html",
        "author": "Tian Xu; Ziniu Li; Yang Yu; Zhi-Quan Luo",
        "abstract": "Imitation learning (IL) has proven to be an effective method for learning good policies from expert demonstrations. Adversarial imitation learning (AIL), a subset of IL methods, is particularly promising, but its theoretical foundation in the presence of unknown transitions has yet to be fully developed. This paper explores the theoretical underpinnings of AIL in this context, where the stochastic and uncertain nature of environment transitions presents a challenge.  We examine the expert sample complexity and interaction complexity required to recover good policies. To this end, we establish a framework connecting reward-free exploration and AIL, and propose an algorithm, MB-TAIL, that achieves the minimax optimal expert sample complexity of $\\widetilde{\\mathcal{O}} (H^{3/2} |\\mathcal{S}|/\\varepsilon)$ and interaction complexity of $\\widetilde{\\mathcal{O}} (H^{3} |\\mathcal{S}|^2 |\\mathcal{A}|/\\varepsilon^2)$. Here, $H$ represents the planning horizon, $|\\mathcal{S}|$ is the state space size, $|\\mathcal{A}|$ is the action space size, and $\\varepsilon$ is the desired imitation gap. MB-TAIL is the first algorithm to achieve this level of expert sample complexity in the unknown transition setting and improves upon the interaction complexity of the best-known algorithm, OAL, by $\\mathcal{O} (H)$. Additionally, we demonstrate the generalization ability of MB-TAIL by extending it to the function approximation setting and proving that it can achieve expert sample and interaction complexity independent of $|\\mathcal{S}|$.",
        "bibtex": "@InProceedings{pmlr-v216-xu23c,\n  title = \t {Provably Efficient Adversarial Imitation Learning with Unknown Transitions},\n  author =       {Xu, Tian and Li, Ziniu and Yu, Yang and Luo, Zhi-Quan},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2367--2378},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/xu23c/xu23c.pdf},\n  url = \t {https://proceedings.mlr.press/v216/xu23c.html},\n  abstract = \t {Imitation learning (IL) has proven to be an effective method for learning good policies from expert demonstrations. Adversarial imitation learning (AIL), a subset of IL methods, is particularly promising, but its theoretical foundation in the presence of unknown transitions has yet to be fully developed. This paper explores the theoretical underpinnings of AIL in this context, where the stochastic and uncertain nature of environment transitions presents a challenge.  We examine the expert sample complexity and interaction complexity required to recover good policies. To this end, we establish a framework connecting reward-free exploration and AIL, and propose an algorithm, MB-TAIL, that achieves the minimax optimal expert sample complexity of $\\widetilde{\\mathcal{O}} (H^{3/2} |\\mathcal{S}|/\\varepsilon)$ and interaction complexity of $\\widetilde{\\mathcal{O}} (H^{3} |\\mathcal{S}|^2 |\\mathcal{A}|/\\varepsilon^2)$. Here, $H$ represents the planning horizon, $|\\mathcal{S}|$ is the state space size, $|\\mathcal{A}|$ is the action space size, and $\\varepsilon$ is the desired imitation gap. MB-TAIL is the first algorithm to achieve this level of expert sample complexity in the unknown transition setting and improves upon the interaction complexity of the best-known algorithm, OAL, by $\\mathcal{O} (H)$. Additionally, we demonstrate the generalization ability of MB-TAIL by extending it to the function approximation setting and proving that it can achieve expert sample and interaction complexity independent of $|\\mathcal{S}|$.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/xu23c/xu23c.pdf",
        "supp": "",
        "pdf_size": 347020,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14050438350252009327&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "bd9c4b1f10",
        "title": "Provably efficient representation selection in Low-rank Markov Decision Processes: from online to offline RL",
        "site": "https://proceedings.mlr.press/v216/zhang23c.html",
        "author": "W. Zhang; J. He; D. Zhou; Q. Gu; A. Zhang",
        "abstract": "The success of deep reinforcement learning (DRL) lies in its ability to learn a representation that is well-suited for the exploration and exploitation task. To understand how the choice of representation can improve the efficiency of reinforcement learning (RL), we study representation selection for a class of low-rank Markov Decision Processes (MDPs) where the transition kernel can be represented in a bilinear form. We propose an efficient algorithm, called ReLEX, for representation learning in both online and offline RL. Specifically, we show that the online version of ReLEX, called ReLEX-UCB, always performs no worse than the state-of-the-art algorithm without representation selection, and achieves a strictly better constant regret if the representation function class has a \"coverage\" property over the entire state-action space. For the offline counterpart, ReLEX-LCB, we show that the algorithm can find the optimal policy if the representation class can cover the state-action space and achieves gap-dependent sample complexity. This is the first result with constant sample complexity for representation learning in offline RL.",
        "bibtex": "@InProceedings{pmlr-v216-zhang23c,\n  title = \t {Provably efficient representation selection in Low-rank {M}arkov Decision Processes: from online to offline {RL}},\n  author =       {Zhang, W. and He, J. and Zhou, D. and Gu, Q. and Zhang, A.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2488--2497},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zhang23c/zhang23c.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zhang23c.html},\n  abstract = \t {The success of deep reinforcement learning (DRL) lies in its ability to learn a representation that is well-suited for the exploration and exploitation task. To understand how the choice of representation can improve the efficiency of reinforcement learning (RL), we study representation selection for a class of low-rank Markov Decision Processes (MDPs) where the transition kernel can be represented in a bilinear form. We propose an efficient algorithm, called ReLEX, for representation learning in both online and offline RL. Specifically, we show that the online version of ReLEX, called ReLEX-UCB, always performs no worse than the state-of-the-art algorithm without representation selection, and achieves a strictly better constant regret if the representation function class has a \"coverage\" property over the entire state-action space. For the offline counterpart, ReLEX-LCB, we show that the algorithm can find the optimal policy if the representation class can cover the state-action space and achieves gap-dependent sample complexity. This is the first result with constant sample complexity for representation learning in offline RL.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/zhang23c/zhang23c.pdf",
        "supp": "",
        "pdf_size": 300720,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10711947575774554303&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, University of California, Los Angeles, California, USA; Department of Computer Science, University of California, Los Angeles, California, USA; Department of Computer Science, University of California, Los Angeles, California, USA; Department of Electrical and Computer Engineering, University of Texas at Austin, Texas, USA + Facebook AI Research; Department of Computer Science, University of California, Los Angeles, California, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1+2;0",
        "aff_unique_norm": "University of California, Los Angeles;University of Texas at Austin;Meta",
        "aff_unique_dep": "Department of Computer Science;Department of Electrical and Computer Engineering;Facebook AI Research",
        "aff_unique_url": "https://www.ucla.edu;https://www.utexas.edu;https://research.facebook.com",
        "aff_unique_abbr": "UCLA;UT Austin;FAIR",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Los Angeles;Austin;",
        "aff_country_unique_index": "0;0;0;0+0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "eb5fbc4703",
        "title": "Quantifying aleatoric and epistemic uncertainty in machine learning: Are conditional entropy and mutual information appropriate measures?",
        "site": "https://proceedings.mlr.press/v216/wimmer23a.html",
        "author": "Lisa Wimmer; Yusuf Sale; Paul Hofman; Bernd Bischl; Eyke H\u00fcllermeier",
        "abstract": "The quantification of aleatoric and epistemic uncertainty in terms of conditional entropy and mutual information, respectively, has recently become quite common in machine learning. While the properties of these measures, which are rooted in information theory, seem appealing at first glance, we identify various incoherencies that call their appropriateness into question. In addition to the measures themselves, we critically discuss the idea of an additive decomposition of total uncertainty into its aleatoric and epistemic constituents. Experiments across different computer vision tasks support our theoretical findings and raise concerns about current practice in uncertainty quantification.",
        "bibtex": "@InProceedings{pmlr-v216-wimmer23a,\n  title = \t {Quantifying aleatoric and epistemic uncertainty in machine learning: Are conditional entropy and mutual information appropriate measures?},\n  author =       {Wimmer, Lisa and Sale, Yusuf and Hofman, Paul and Bischl, Bernd and H\\\"ullermeier, Eyke},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2282--2292},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/wimmer23a/wimmer23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/wimmer23a.html},\n  abstract = \t {The quantification of aleatoric and epistemic uncertainty in terms of conditional entropy and mutual information, respectively, has recently become quite common in machine learning. While the properties of these measures, which are rooted in information theory, seem appealing at first glance, we identify various incoherencies that call their appropriateness into question. In addition to the measures themselves, we critically discuss the idea of an additive decomposition of total uncertainty into its aleatoric and epistemic constituents. Experiments across different computer vision tasks support our theoretical findings and raise concerns about current practice in uncertainty quantification.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/wimmer23a/wimmer23a.pdf",
        "supp": "",
        "pdf_size": 1416621,
        "gs_citation": 83,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17880981708001339272&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Statistics, LMU Munich, Germany + Munich Center for Machine Learning (MCML), Germany; Institute of Informatics, LMU Munich, Germany + Munich Center for Machine Learning (MCML), Germany; Institute of Informatics, LMU Munich, Germany + Munich Center for Machine Learning (MCML), Germany; Department of Statistics, LMU Munich, Germany + Munich Center for Machine Learning (MCML), Germany; Institute of Informatics, LMU Munich, Germany + Munich Center for Machine Learning (MCML), Germany",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0+1;0+1;0+1",
        "aff_unique_norm": "LMU Munich;Munich Center for Machine Learning",
        "aff_unique_dep": "Department of Statistics;Center for Machine Learning",
        "aff_unique_url": "https://www.lmu.de;https://www.munich-center-for-machine-learning.de",
        "aff_unique_abbr": "LMU;MCML",
        "aff_campus_unique_index": "0+0;0+0;0+0;0+0;0+0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0+0;0+0;0+0;0+0;0+0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "197c7d4648",
        "title": "Quantifying lottery tickets under label noise: accuracy, calibration, and complexity",
        "site": "https://proceedings.mlr.press/v216/arora23a.html",
        "author": "Viplove Arora; Daniele Irto; Sebastian Goldt; Guido Sanguinetti",
        "abstract": "Pruning deep neural networks is a widely used strategy to alleviate the computational burden in machine learning. Overwhelming empirical evidence suggests that pruned models retain very high accuracy even with a tiny fraction of parameters. However, relatively little work has gone into characterising the small pruned networks obtained, beyond a measure of their accuracy. In this paper, we use the sparse double descent approach to identify univocally and characterise pruned models associated with classification tasks. We observe empirically that, for a given task, iterative magnitude pruning (IMP) tends to converge to networks of comparable sizes even when starting from full networks with sizes ranging over orders of magnitude. We analyse the best pruned models in a controlled experimental setup and show that their number of parameters reflects task difficulty and that they are much better than full networks at capturing the true conditional probability distribution of the labels. On real data, we similarly observe that pruned models are less prone to overconfident predictions. Our results suggest that pruned models obtained via IMP not only have advantageous computational properties but also provide a better representation of uncertainty in learning.",
        "bibtex": "@InProceedings{pmlr-v216-arora23a,\n  title = \t {Quantifying lottery tickets under label noise: accuracy, calibration, and complexity},\n  author =       {Arora, Viplove and Irto, Daniele and Goldt, Sebastian and Sanguinetti, Guido},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {88--98},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/arora23a/arora23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/arora23a.html},\n  abstract = \t {Pruning deep neural networks is a widely used strategy to alleviate the computational burden in machine learning. Overwhelming empirical evidence suggests that pruned models retain very high accuracy even with a tiny fraction of parameters. However, relatively little work has gone into characterising the small pruned networks obtained, beyond a measure of their accuracy. In this paper, we use the sparse double descent approach to identify univocally and characterise pruned models associated with classification tasks. We observe empirically that, for a given task, iterative magnitude pruning (IMP) tends to converge to networks of comparable sizes even when starting from full networks with sizes ranging over orders of magnitude. We analyse the best pruned models in a controlled experimental setup and show that their number of parameters reflects task difficulty and that they are much better than full networks at capturing the true conditional probability distribution of the labels. On real data, we similarly observe that pruned models are less prone to overconfident predictions. Our results suggest that pruned models obtained via IMP not only have advantageous computational properties but also provide a better representation of uncertainty in learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/arora23a/arora23a.pdf",
        "supp": "",
        "pdf_size": 1066177,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7227442024775398961&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fc7d485e76",
        "title": "Quasi-Bayesian nonparametric density estimation via autoregressive predictive updates",
        "site": "https://proceedings.mlr.press/v216/ghalebikesabi23a.html",
        "author": "Sahra Ghalebikesabi; Chris C. Holmes; Edwin Fong; Brieuc Lehmann",
        "abstract": "Bayesian methods are a popular choice for statistical inference in small-data regimes due to the regularization effect induced by the prior. %, which serves to counteract overfitting. In the context of density estimation, the standard nonparametric Bayesian approach is to target the posterior predictive of the Dirichlet process mixture model. In general, direct estimation of the posterior predictive is intractable and so methods typically resort to approximating the posterior distribution as an intermediate step. The recent development of quasi-Bayesian predictive copula updates, however, has made it possible to perform tractable predictive density estimation without the need for posterior approximation. Although these estimators are computationally appealing, they struggle on non-smooth data distributions. This is due to the comparatively restrictive form of the likelihood models from which the proposed copula updates were derived. To address this shortcoming, we consider a Bayesian nonparametric model with an autoregressive likelihood decomposition and a Gaussian process prior. While the predictive update of such a model is typically intractable, we derive a quasi-Bayesian update that achieves state-of-the-art results in small-data regimes.",
        "bibtex": "@InProceedings{pmlr-v216-ghalebikesabi23a,\n  title = \t {Quasi-{B}ayesian nonparametric density estimation via autoregressive predictive updates},\n  author =       {Ghalebikesabi, Sahra and Holmes, Chris C. and Fong, Edwin and Lehmann, Brieuc},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {658--668},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/ghalebikesabi23a/ghalebikesabi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/ghalebikesabi23a.html},\n  abstract = \t {Bayesian methods are a popular choice for statistical inference in small-data regimes due to the regularization effect induced by the prior. %, which serves to counteract overfitting. In the context of density estimation, the standard nonparametric Bayesian approach is to target the posterior predictive of the Dirichlet process mixture model. In general, direct estimation of the posterior predictive is intractable and so methods typically resort to approximating the posterior distribution as an intermediate step. The recent development of quasi-Bayesian predictive copula updates, however, has made it possible to perform tractable predictive density estimation without the need for posterior approximation. Although these estimators are computationally appealing, they struggle on non-smooth data distributions. This is due to the comparatively restrictive form of the likelihood models from which the proposed copula updates were derived. To address this shortcoming, we consider a Bayesian nonparametric model with an autoregressive likelihood decomposition and a Gaussian process prior. While the predictive update of such a model is typically intractable, we derive a quasi-Bayesian update that achieves state-of-the-art results in small-data regimes.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/ghalebikesabi23a/ghalebikesabi23a.pdf",
        "supp": "",
        "pdf_size": 1309969,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3578716147099646118&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "University of Oxford; Novo Nordisk; Novo Nordisk + University College London; University College London",
        "aff_domain": "oxford.ac.uk;novonordisk.com;novonordisk.com;ucl.ac.uk",
        "email": "oxford.ac.uk;novonordisk.com;novonordisk.com;ucl.ac.uk",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1+2;2",
        "aff_unique_norm": "University of Oxford;Novo Nordisk;University College London",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.novonordisk.com;https://www.ucl.ac.uk",
        "aff_unique_abbr": "Oxford;NN;UCL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1+0;0",
        "aff_country_unique": "United Kingdom;Denmark"
    },
    {
        "id": "8042bf1644",
        "title": "RDM-DC: Poisoning Resilient Dataset Condensation with Robust Distribution Matching",
        "site": "https://proceedings.mlr.press/v216/zheng23a.html",
        "author": "Tianhang Zheng; Baochun Li",
        "abstract": "Dataset condensation aims to condense the original training dataset into a small synthetic dataset for data-efficient learning. The recently proposed dataset condensation techniques allow the model trainers with limited resources to learn acceptable deep learning models on a small amount of synthetic data. However, in an adversarial environment, given the original dataset as a poisoned dataset, dataset condensation may encode the poisoning information into the condensed synthetic dataset. To explore the vulnerability of dataset condensation to data poisoning, we revisit the state-of-the-art targeted data poisoning method and customize a targeted data poisoning algorithm for dataset condensation. By executing the two poisoning methods, we demonstrate that, when the synthetic dataset is condensed from a poisoned dataset, the models trained on the synthetic dataset may predict the targeted sample as the attack-targeted label. To defend against data poisoning, we introduce the concept of poisoned deviation to quantify the poisoning effect. We further propose a poisoning-resilient dataset condensation algorithm with a calibration method to reduce poisoned deviation. Extensive evaluations demonstrate that our proposed algorithm can protect the synthetic dataset from data poisoning with minor performance drop.",
        "bibtex": "@InProceedings{pmlr-v216-zheng23a,\n  title = \t {{RDM-DC}: Poisoning Resilient Dataset Condensation with Robust Distribution Matching},\n  author =       {Zheng, Tianhang and Li, Baochun},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2541--2550},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zheng23a/zheng23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zheng23a.html},\n  abstract = \t {Dataset condensation aims to condense the original training dataset into a small synthetic dataset for data-efficient learning. The recently proposed dataset condensation techniques allow the model trainers with limited resources to learn acceptable deep learning models on a small amount of synthetic data. However, in an adversarial environment, given the original dataset as a poisoned dataset, dataset condensation may encode the poisoning information into the condensed synthetic dataset. To explore the vulnerability of dataset condensation to data poisoning, we revisit the state-of-the-art targeted data poisoning method and customize a targeted data poisoning algorithm for dataset condensation. By executing the two poisoning methods, we demonstrate that, when the synthetic dataset is condensed from a poisoned dataset, the models trained on the synthetic dataset may predict the targeted sample as the attack-targeted label. To defend against data poisoning, we introduce the concept of poisoned deviation to quantify the poisoning effect. We further propose a poisoning-resilient dataset condensation algorithm with a calibration method to reduce poisoned deviation. Extensive evaluations demonstrate that our proposed algorithm can protect the synthetic dataset from data poisoning with minor performance drop.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/zheng23a/zheng23a.pdf",
        "supp": "",
        "pdf_size": 1203859,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10652525649304991198&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Electrical and Computer Engineering, University of Toronto; Department of Electrical and Computer Engineering, University of Toronto",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "29a4bb6a37",
        "title": "Random Reshuffling with Variance Reduction: New Analysis and Better Rates",
        "site": "https://proceedings.mlr.press/v216/malinovsky23a.html",
        "author": "Grigory Malinovsky; Alibek Sailanbayev; Peter Richt\u00e1rik",
        "abstract": "Virtually all state-of-the-art methods for training supervised machine learning models are variants of Stochastic Gradient Descent (SGD), enhanced with a number of additional tricks, such as minibatching, momentum, and adaptive stepsizes. However, one of the most basic questions in the design of  successful SGD methods, one that is orthogonal to the aforementioned tricks, is the choice of the next training data point to be learning from. Standard variants of SGD employ a  sampling with replacement strategy, which means that the next training data point is sampled from the entire data set, often independently of all previous samples. While standard SGD is well understood theoretically,  virtually all widely used machine learning software is based on  sampling without replacement as this is often empirically superior. That is, the training data is randomly shuffled/permuted, either only once at the beginning, strategy known as random shuffling (RS), or before every epoch, strategy known as random reshuffling (RR),  and  training proceeds in the data order dictated by the shuffling.  RS and RR strategies  have for a long time remained beyond the reach of  theoretical analysis that would satisfactorily explain their success. However, very recently, Mishchenko et al. [2020] provided tight  sublinear convergence rates through a novel analysis, and showed that these strategies can improve upon standard SGD in certain regimes. Inspired by these results, we seek to further  improve the rates of shuffling-based methods. In particular, we show that it is possible to enhance them with a variance reduction mechanism, obtaining linear convergence rates.\tTo the best of our knowledge, our linear convergence rates are the best for any method based on sampling without replacement.",
        "bibtex": "@InProceedings{pmlr-v216-malinovsky23a,\n  title = \t {Random Reshuffling with Variance Reduction: New Analysis and Better Rates},\n  author =       {Malinovsky, Grigory and Sailanbayev, Alibek and Richt\\'{a}rik, Peter},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1347--1357},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/malinovsky23a/malinovsky23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/malinovsky23a.html},\n  abstract = \t {Virtually all state-of-the-art methods for training supervised machine learning models are variants of Stochastic Gradient Descent (SGD), enhanced with a number of additional tricks, such as minibatching, momentum, and adaptive stepsizes. However, one of the most basic questions in the design of  successful SGD methods, one that is orthogonal to the aforementioned tricks, is the choice of the next training data point to be learning from. Standard variants of SGD employ a  sampling with replacement strategy, which means that the next training data point is sampled from the entire data set, often independently of all previous samples. While standard SGD is well understood theoretically,  virtually all widely used machine learning software is based on  sampling without replacement as this is often empirically superior. That is, the training data is randomly shuffled/permuted, either only once at the beginning, strategy known as random shuffling (RS), or before every epoch, strategy known as random reshuffling (RR),  and  training proceeds in the data order dictated by the shuffling.  RS and RR strategies  have for a long time remained beyond the reach of  theoretical analysis that would satisfactorily explain their success. However, very recently, Mishchenko et al. [2020] provided tight  sublinear convergence rates through a novel analysis, and showed that these strategies can improve upon standard SGD in certain regimes. Inspired by these results, we seek to further  improve the rates of shuffling-based methods. In particular, we show that it is possible to enhance them with a variance reduction mechanism, obtaining linear convergence rates.\tTo the best of our knowledge, our linear convergence rates are the best for any method based on sampling without replacement.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/malinovsky23a/malinovsky23a.pdf",
        "supp": "",
        "pdf_size": 547582,
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9667188409516974531&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "fc166807e2",
        "title": "Regularized online DR-submodular optimization",
        "site": "https://proceedings.mlr.press/v216/zuo23a.html",
        "author": "Pengyu Zuo; Yao Wang; Shaojie Tang",
        "abstract": "The utilization of online optimization techniques is prevalent in many fields of artificial intelligence, enabling systems to continuously learn and adjust to their surroundings. This paper outlines a regularized online optimization problem, where the regularizer is defined on the average of the actions taken. The objective is to maximize  the sum of rewards and the regularizer value while adhering to resource constraints, where the reward function is assumed to be DR-submodular. Both concave and DR-submodular regularizers are analyzed. Concave functions are useful in describing the impartiality of decisions, while DR-submodular functions can be employed to represent the overall effect of decisions on all relevant parties. We have developed two algorithms for each of the concave and DR-submodular regularizers. These algorithms are easy to implement, efficient, and produce sublinear regret in both cases. The performance of the proposed algorithms and regularizers has been verified through numerical experiments in the context of internet advertising.",
        "bibtex": "@InProceedings{pmlr-v216-zuo23a,\n  title = \t {Regularized online {DR}-submodular optimization},\n  author =       {Zuo, Pengyu and Wang, Yao and Tang, Shaojie},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2608--2617},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/zuo23a/zuo23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/zuo23a.html},\n  abstract = \t {The utilization of online optimization techniques is prevalent in many fields of artificial intelligence, enabling systems to continuously learn and adjust to their surroundings. This paper outlines a regularized online optimization problem, where the regularizer is defined on the average of the actions taken. The objective is to maximize  the sum of rewards and the regularizer value while adhering to resource constraints, where the reward function is assumed to be DR-submodular. Both concave and DR-submodular regularizers are analyzed. Concave functions are useful in describing the impartiality of decisions, while DR-submodular functions can be employed to represent the overall effect of decisions on all relevant parties. We have developed two algorithms for each of the concave and DR-submodular regularizers. These algorithms are easy to implement, efficient, and produce sublinear regret in both cases. The performance of the proposed algorithms and regularizers has been verified through numerical experiments in the context of internet advertising.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/zuo23a/zuo23a.pdf",
        "supp": "",
        "pdf_size": 400626,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:GBy3mjCXzKkJ:scholar.google.com/&scioq=Regularized+online+DR-submodular+optimization&hl=en&as_sdt=0,33",
        "gs_version_total": 6,
        "aff": "Xi\u2019an Jiaotong University, Xi\u2019an, China; Xi\u2019an Jiaotong University, Xi\u2019an, China; The University of Texas at Dallas, Richardson, USA",
        "aff_domain": "gmail.com;gmail.com;utdallas.edu",
        "email": "gmail.com;gmail.com;utdallas.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Xi'an Jiao Tong University;University of Texas at Dallas",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.xjtu.edu.cn;https://www.utdallas.edu",
        "aff_unique_abbr": "XJTU;UT Dallas",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Xi'an;Richardson",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "406e5c5b31",
        "title": "Residual-based error bound for physics-informed neural networks",
        "site": "https://proceedings.mlr.press/v216/liu23b.html",
        "author": "Shuheng Liu; Xiyue Huang; Pavlos Protopapas",
        "abstract": "Neural networks are universal approximators and are studied for their use in solving differential equations.  However, a major criticism is the lack of error bounds for obtained solutions.  This paper proposes a technique to rigorously evaluate the error bound of Physics-Informed Neural Networks (PINNs) on most linear ordinary differential equations (ODEs), certain nonlinear ODEs, and first-order linear partial differential equations (PDEs).  The error bound is based purely on equation structure and residual information and does not depend on assumptions of how well the networks are trained.  We propose algorithms that bound the error efficiently. Some proposed algorithms provide tighter bounds than others at the cost of longer run time.",
        "bibtex": "@InProceedings{pmlr-v216-liu23b,\n  title = \t {Residual-based error bound for physics-informed neural networks},\n  author =       {Liu, Shuheng and Huang, Xiyue and Protopapas, Pavlos},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1284--1293},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/liu23b/liu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/liu23b.html},\n  abstract = \t {Neural networks are universal approximators and are studied for their use in solving differential equations.  However, a major criticism is the lack of error bounds for obtained solutions.  This paper proposes a technique to rigorously evaluate the error bound of Physics-Informed Neural Networks (PINNs) on most linear ordinary differential equations (ODEs), certain nonlinear ODEs, and first-order linear partial differential equations (PDEs).  The error bound is based purely on equation structure and residual information and does not depend on assumptions of how well the networks are trained.  We propose algorithms that bound the error efficiently. Some proposed algorithms provide tighter bounds than others at the cost of longer run time.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/liu23b/liu23b.pdf",
        "supp": "",
        "pdf_size": 657360,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17721631455108197574&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Institute for Applied Computational Science, Harvard University; Data Science Institute, Columbia University; Institute for Applied Computational Science, Harvard University",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Harvard University;Columbia University",
        "aff_unique_dep": "Institute for Applied Computational Science;Data Science Institute",
        "aff_unique_url": "https://www.harvard.edu;https://www.columbia.edu",
        "aff_unique_abbr": "Harvard;Columbia",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "fe97bfa35f",
        "title": "Revisiting Bayesian network learning with small vertex cover",
        "site": "https://proceedings.mlr.press/v216/harviainen23a.html",
        "author": "Juha Harviainen; Mikko Koivisto",
        "abstract": "The problem of structure learning in Bayesian networks asks for a directed acyclic graph (DAG) that maximizes a given scoring function. Since the problem is NP-hard, research effort has been put into discovering restricted classes of DAGs for which the search problem can be solved in polynomial time. Here, we initiate investigation of questions that have received less attention thus far: Are the known polynomial algorithms close to the best possible, or is there room for significant improvements? If the interest is in Bayesian learning, that is, in sampling or weighted counting of DAGs, can we obtain similar complexity results? Focusing on DAGs with bounded vertex cover number\u2014a class studied in Korhonen and Parviainen\u2019s seminal work (NIPS 2015)\u2014we answer the questions in the affirmative. We also give, apparently the first, proof that the counting problem is $#$P-hard in general. In addition, we show that under the vertex-cover constraint counting is $#$W[1]-hard.",
        "bibtex": "@InProceedings{pmlr-v216-harviainen23a,\n  title = \t {Revisiting {B}ayesian network learning with small vertex cover},\n  author =       {Harviainen, Juha and Koivisto, Mikko},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {819--828},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/harviainen23a/harviainen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/harviainen23a.html},\n  abstract = \t {The problem of structure learning in Bayesian networks asks for a directed acyclic graph (DAG) that maximizes a given scoring function. Since the problem is NP-hard, research effort has been put into discovering restricted classes of DAGs for which the search problem can be solved in polynomial time. Here, we initiate investigation of questions that have received less attention thus far: Are the known polynomial algorithms close to the best possible, or is there room for significant improvements? If the interest is in Bayesian learning, that is, in sampling or weighted counting of DAGs, can we obtain similar complexity results? Focusing on DAGs with bounded vertex cover number\u2014a class studied in Korhonen and Parviainen\u2019s seminal work (NIPS 2015)\u2014we answer the questions in the affirmative. We also give, apparently the first, proof that the counting problem is $#$P-hard in general. In addition, we show that under the vertex-cover constraint counting is $#$W[1]-hard.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/harviainen23a/harviainen23a.pdf",
        "supp": "",
        "pdf_size": 258823,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14499046946065594665&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Computer Science, University of Helsinki, Helsinki, Finland; Department of Computer Science, University of Helsinki, Helsinki, Finland",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Helsinki",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.helsinki.fi",
        "aff_unique_abbr": "UH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Helsinki",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "67134654d7",
        "title": "Reward-machine-guided, self-paced reinforcement learning",
        "site": "https://proceedings.mlr.press/v216/koprulu23a.html",
        "author": "Cevahir Koprulu; Ufuk Topcu",
        "abstract": "Self-paced reinforcement learning (RL) aims to improve the data efficiency of learning by automatically creating sequences, namely curricula, of probability distributions over contexts. However, existing techniques for self-paced RL fail in long-horizon planning tasks that involve temporally extended behaviors. We hypothesize that taking advantage of prior knowledge about the underlying task structure can improve the effectiveness of self-paced RL. We develop a self-paced RL algorithm guided by reward machines, i.e., a type of finite-state machine that encodes the underlying task structure. The algorithm integrates reward machines in 1) the update of the policy and value functions obtained by any RL algorithm of choice, and 2) the update of the automated curriculum that generates context distributions. Our empirical results evidence that the proposed algorithm achieves optimal behavior reliably even in cases in which existing baselines cannot make any meaningful progress. It also decreases the curriculum length and reduces the variance in the curriculum generation process by up to one-fourth and four orders of magnitude, respectively.",
        "bibtex": "@InProceedings{pmlr-v216-koprulu23a,\n  title = \t {Reward-machine-guided, self-paced reinforcement learning},\n  author =       {Koprulu, Cevahir and Topcu, Ufuk},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1121--1131},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/koprulu23a/koprulu23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/koprulu23a.html},\n  abstract = \t {Self-paced reinforcement learning (RL) aims to improve the data efficiency of learning by automatically creating sequences, namely curricula, of probability distributions over contexts. However, existing techniques for self-paced RL fail in long-horizon planning tasks that involve temporally extended behaviors. We hypothesize that taking advantage of prior knowledge about the underlying task structure can improve the effectiveness of self-paced RL. We develop a self-paced RL algorithm guided by reward machines, i.e., a type of finite-state machine that encodes the underlying task structure. The algorithm integrates reward machines in 1) the update of the policy and value functions obtained by any RL algorithm of choice, and 2) the update of the automated curriculum that generates context distributions. Our empirical results evidence that the proposed algorithm achieves optimal behavior reliably even in cases in which existing baselines cannot make any meaningful progress. It also decreases the curriculum length and reduces the variance in the curriculum generation process by up to one-fourth and four orders of magnitude, respectively.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/koprulu23a/koprulu23a.pdf",
        "supp": "",
        "pdf_size": 857784,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9747753878096353340&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "The University of Texas at Austin, USA; The University of Texas at Austin, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c56538d45f",
        "title": "Risk-aware curriculum generation for heavy-tailed task distributions",
        "site": "https://proceedings.mlr.press/v216/koprulu23b.html",
        "author": "Cevahir Koprulu; Thiago D. Sim\u00e3o; Nils Jansen; Ufuk Topcu",
        "abstract": "Automated curriculum generation for reinforcement learning (RL) aims to speed up learning by designing a sequence of tasks of increasing difficulty. Such tasks are usually drawn from probability distributions with exponentially bounded tails, such as uniform or Gaussian distributions. However, existing approaches overlook heavy-tailed distributions. Under such distributions, current methods may fail to learn optimal policies in rare and risky tasks, which fall under the tails and yield the lowest returns, respectively. We address this challenge by proposing a risk-aware curriculum generation algorithm that simultaneously creates two curricula: 1) a primary curriculum that aims to maximize the expected discounted return with respect to a distribution over target tasks, and an auxiliary curriculum that identifies and over-samples rare and risky tasks observed in the primary curriculum. Our empirical results evidence that the proposed algorithm achieves significantly higher returns in frequent as well as rare tasks compared to the state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v216-koprulu23b,\n  title = \t {Risk-aware curriculum generation for heavy-tailed task distributions},\n  author =       {Koprulu, Cevahir and Sim\\~{a}o, Thiago D. and Jansen, Nils and Topcu, Ufuk},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1132--1142},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/koprulu23b/koprulu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/koprulu23b.html},\n  abstract = \t {Automated curriculum generation for reinforcement learning (RL) aims to speed up learning by designing a sequence of tasks of increasing difficulty. Such tasks are usually drawn from probability distributions with exponentially bounded tails, such as uniform or Gaussian distributions. However, existing approaches overlook heavy-tailed distributions. Under such distributions, current methods may fail to learn optimal policies in rare and risky tasks, which fall under the tails and yield the lowest returns, respectively. We address this challenge by proposing a risk-aware curriculum generation algorithm that simultaneously creates two curricula: 1) a primary curriculum that aims to maximize the expected discounted return with respect to a distribution over target tasks, and an auxiliary curriculum that identifies and over-samples rare and risky tasks observed in the primary curriculum. Our empirical results evidence that the proposed algorithm achieves significantly higher returns in frequent as well as rare tasks compared to the state-of-the-art methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/koprulu23b/koprulu23b.pdf",
        "supp": "",
        "pdf_size": 602047,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17988897793198417728&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6b4dfffbf9",
        "title": "Risk-limiting financial audits via weighted sampling without replacement",
        "site": "https://proceedings.mlr.press/v216/shekhar23a.html",
        "author": "Shubhanshu Shekhar; Ziyu Xu; Zachary Lipton; Pierre Liang; Aaditya Ramdas",
        "abstract": "We introduce the notion of risk-limiting financial audits\u00a0(RLFA): procedures that manually evaluate a subset of $N$ financial transactions to  check the validity of a claimed assertion $\\mathcal{A}$ about the transactions. More specifically, RLFA satisfy two properties: (i) if $\\mathcal{A}$ is false, they correctly disprove it with probability at least $1-\\delta$, and (ii) they validate the correctness of $\\mathcal{A}$ with probability $1$, if it is true. We propose a general RLFA strategy, by  constructing new confidence sequences\u00a0(CSs)  for the weighted average of $N$ unknown values,  based on samples drawn without replacement  from a (randomized) weighted sampling scheme.  Next, we develop methods to improve the quality of CSs by incorporating side information about  the unknown values. We show that when the side information is sufficiently accurate, it can directly drive the sampling. For the case where the accuracy is unknown",
        "bibtex": "@InProceedings{pmlr-v216-shekhar23a,\n  title = \t {Risk-limiting financial audits via weighted sampling without replacement},\n  author =       {Shekhar, Shubhanshu and Xu, Ziyu and Lipton, Zachary and Liang, Pierre and Ramdas, Aaditya},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1932--1941},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/shekhar23a/shekhar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/shekhar23a.html},\n  abstract = \t {We introduce the notion of risk-limiting financial audits\u00a0(RLFA): procedures that manually evaluate a subset of $N$ financial transactions to  check the validity of a claimed assertion $\\mathcal{A}$ about the transactions. More specifically, RLFA satisfy two properties: (i) if $\\mathcal{A}$ is false, they correctly disprove it with probability at least $1-\\delta$, and (ii) they validate the correctness of $\\mathcal{A}$ with probability $1$, if it is true. We propose a general RLFA strategy, by  constructing new confidence sequences\u00a0(CSs)  for the weighted average of $N$ unknown values,  based on samples drawn without replacement  from a (randomized) weighted sampling scheme.  Next, we develop methods to improve the quality of CSs by incorporating side information about  the unknown values. We show that when the side information is sufficiently accurate, it can directly drive the sampling. For the case where the accuracy is unknown",
        "pdf": "https://proceedings.mlr.press/v216/shekhar23a/shekhar23a.pdf",
        "supp": "",
        "pdf_size": 343068,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5320905022550607219&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Statistics and Data Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA+Machine Learning Department, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Department of Statistics and Data Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA+Machine Learning Department, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Machine Learning Department, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA+Tepper School of Business, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Tepper School of Business, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Department of Statistics and Data Science, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA+Machine Learning Department, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0+0;0+0;0;0+0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Statistics and Data Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0+0;0+0;0+0;0;0+0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0+0;0+0;0+0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a1434815f9",
        "title": "Robust Gaussian process regression with the trimmed marginal likelihood",
        "site": "https://proceedings.mlr.press/v216/andrade23a.html",
        "author": "Daniel Andrade; Akiko Takeda",
        "abstract": "Accurate outlier detection is not only a necessary preprocessing step, but can itself give important insights into the data. However, especially, for non-linear regression the detection of outliers is non-trivial, and actually ambiguous. We propose a new method that identifies outliers by finding a subset of data points T such that the marginal likelihood of all remaining data points S is maximized. Though the idea is more general, it is particular appealing for Gaussian processes regression, where the marginal likelihood has an analytic solution. While maximizing the marginal likelihood for hyper-parameter optimization is a well established non-convex optimization problem, optimizing the set of data points S is not. Indeed, even a greedy approximation is computationally challenging due to the high cost of evaluating the marginal likelihood. As a remedy, we propose an efficient projected gradient descent method with provable convergence guarantees. Moreover, we also establish the breakdown point when jointly optimizing hyper-parameters and S. For various datasets and types of outliers, our experiments demonstrate that the proposed method can improve outlier detection and robustness when compared with several popular alternatives like the student-t likelihood.",
        "bibtex": "@InProceedings{pmlr-v216-andrade23a,\n  title = \t {Robust {G}aussian process regression with the trimmed marginal likelihood},\n  author =       {Andrade, Daniel and Takeda, Akiko},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {67--76},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/andrade23a/andrade23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/andrade23a.html},\n  abstract = \t {Accurate outlier detection is not only a necessary preprocessing step, but can itself give important insights into the data. However, especially, for non-linear regression the detection of outliers is non-trivial, and actually ambiguous. We propose a new method that identifies outliers by finding a subset of data points T such that the marginal likelihood of all remaining data points S is maximized. Though the idea is more general, it is particular appealing for Gaussian processes regression, where the marginal likelihood has an analytic solution. While maximizing the marginal likelihood for hyper-parameter optimization is a well established non-convex optimization problem, optimizing the set of data points S is not. Indeed, even a greedy approximation is computationally challenging due to the high cost of evaluating the marginal likelihood. As a remedy, we propose an efficient projected gradient descent method with provable convergence guarantees. Moreover, we also establish the breakdown point when jointly optimizing hyper-parameters and S. For various datasets and types of outliers, our experiments demonstrate that the proposed method can improve outlier detection and robustness when compared with several popular alternatives like the student-t likelihood.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/andrade23a/andrade23a.pdf",
        "supp": "",
        "pdf_size": 488902,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15319175955667714826&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Education and Research Center for Artificial Intelligence and Data Innovation, Hiroshima University, Hiroshima, Japan; Department of Mathematical Informatics, The University of Tokyo, Tokyo, Japan + Center for Advanced Intelligence Project, RIKEN, Tokyo, Japan",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1+2",
        "aff_unique_norm": "Hiroshima University;University of Tokyo;RIKEN",
        "aff_unique_dep": "Education and Research Center for Artificial Intelligence and Data Innovation;Department of Mathematical Informatics;Center for Advanced Intelligence Project",
        "aff_unique_url": "https://www.hiroshima-u.ac.jp;https://www.u-tokyo.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "Hiroshima U;UTokyo;RIKEN",
        "aff_campus_unique_index": "0;1+1",
        "aff_campus_unique": "Hiroshima;Tokyo",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "241abe72d4",
        "title": "Robust Quickest Change Detection for Unnormalized Models",
        "site": "https://proceedings.mlr.press/v216/wu23c.html",
        "author": "Suya Wu; Enmao Diao; Jie Ding; Taposh Banerjee; Vahid Tarokh",
        "abstract": "Detecting an abrupt and persistent change in the underlying distribution of online data streams is an important problem in many applications. This paper proposes a new robust score-based algorithm called RSCUSUM, which can be applied to unnormalized models and addresses the issue of unknown post-change distributions. RSCUSUM replaces the Kullback-Leibler divergence with the Fisher divergence between pre- and post-change distributions for computational efficiency in unnormalized statistical models and introduces a notion of the \u201cleast favorable\u201d distribution for robust change detection. The algorithm and its theoretical analysis are demonstrated through simulation studies.",
        "bibtex": "@InProceedings{pmlr-v216-wu23c,\n  title = \t {Robust Quickest Change Detection for Unnormalized Models},\n  author =       {Wu, Suya and Diao, Enmao and Ding, Jie and Banerjee, Taposh and Tarokh, Vahid},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2314--2323},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/wu23c/wu23c.pdf},\n  url = \t {https://proceedings.mlr.press/v216/wu23c.html},\n  abstract = \t {Detecting an abrupt and persistent change in the underlying distribution of online data streams is an important problem in many applications. This paper proposes a new robust score-based algorithm called RSCUSUM, which can be applied to unnormalized models and addresses the issue of unknown post-change distributions. RSCUSUM replaces the Kullback-Leibler divergence with the Fisher divergence between pre- and post-change distributions for computational efficiency in unnormalized statistical models and introduces a notion of the \u201cleast favorable\u201d distribution for robust change detection. The algorithm and its theoretical analysis are demonstrated through simulation studies.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/wu23c/wu23c.pdf",
        "supp": "",
        "pdf_size": 1241530,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15804686753310781802&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Electrical and Computer Engineering, Duke University; Department of Electrical and Computer Engineering, Duke University; Department of Industrial Engineering, University of Pittsburgh; School of Statistics, University of Minnesota Twin Cities; Department of Electrical and Computer Engineering, Duke University",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Duke University;University of Pittsburgh;University of Minnesota",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Industrial Engineering;School of Statistics",
        "aff_unique_url": "https://www.duke.edu;https://www.pitt.edu;https://www.stat.umn.edu",
        "aff_unique_abbr": "Duke;Pitt;UMN",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Twin Cities",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "83d408fad0",
        "title": "Robust distillation for worst-class performance: on the interplay between teacher and student objectives",
        "site": "https://proceedings.mlr.press/v216/wang23e.html",
        "author": "Serena Wang; Harikrishna Narasimhan; Yichen Zhou; Sara Hooker; Michal Lukasik; Aditya Krishna Menon",
        "abstract": "Knowledge distillation is a popular technique that has been shown to produce remarkable gains in average accuracy. However, recent work has shown that these gains are not uniform across subgroups in the data, and can often come at the cost of accuracy on rare subgroups and classes. Robust optimization is a common remedy to improve worst-class accuracy in standard learning settings, but in distillation it is unknown whether it is best to apply robust objectives when training the teacher, the student, or both. This work studies the interplay between robust objectives for the teacher and student. Empirically, we show that that jointly modifying the teacher and student objectives can lead to better worst-class student performance and even Pareto improvement in the trade-off between worst-class and overall performance. Theoretically, we show that the",
        "bibtex": "@InProceedings{pmlr-v216-wang23e,\n  title = \t {Robust distillation for worst-class performance: on the interplay between teacher and student objectives},\n  author =       {Wang, Serena and Narasimhan, Harikrishna and Zhou, Yichen and Hooker, Sara and Lukasik, Michal and Menon, Aditya Krishna},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2237--2247},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/wang23e/wang23e.pdf},\n  url = \t {https://proceedings.mlr.press/v216/wang23e.html},\n  abstract = \t {Knowledge distillation is a popular technique that has been shown to produce remarkable gains in average accuracy. However, recent work has shown that these gains are not uniform across subgroups in the data, and can often come at the cost of accuracy on rare subgroups and classes. Robust optimization is a common remedy to improve worst-class accuracy in standard learning settings, but in distillation it is unknown whether it is best to apply robust objectives when training the teacher, the student, or both. This work studies the interplay between robust objectives for the teacher and student. Empirically, we show that that jointly modifying the teacher and student objectives can lead to better worst-class student performance and even Pareto improvement in the trade-off between worst-class and overall performance. Theoretically, we show that the",
        "pdf": "https://proceedings.mlr.press/v216/wang23e/wang23e.pdf",
        "supp": "",
        "pdf_size": 303891,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4417152433396994193&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d225472ed6",
        "title": "Robust statistical comparison of random variables with locally varying scale of measurement",
        "site": "https://proceedings.mlr.press/v216/jansen23a.html",
        "author": "Christoph Jansen; Georg Schollmeyer; Hannah Blocher; Julian Rodemann; Thomas Augustin",
        "abstract": "Spaces with locally varying scale of measurement, like multidimensional structures with differently scaled dimensions, are pretty common in statistics and machine learning. Nevertheless, it is still understood as an open question how to exploit the entire information encoded in them properly. We address this problem by considering an order based on (sets of) expectations of random variables mapping into such non-standard spaces. This order contains stochastic dominance and expectation order as extreme cases when no, or respectively perfect, cardinal structure is given.  We derive a (regularized) statistical test for our proposed generalized stochastic dominance (GSD) order, operationalize it by linear optimization, and robustify it by imprecise probability models. Our findings are illustrated with data from multidimensional poverty measurement, finance, and medicine.",
        "bibtex": "@InProceedings{pmlr-v216-jansen23a,\n  title = \t {Robust statistical comparison of random variables with locally varying scale of measurement},\n  author =       {Jansen, Christoph and Schollmeyer, Georg and Blocher, Hannah and Rodemann, Julian and Augustin, Thomas},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {941--952},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/jansen23a/jansen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/jansen23a.html},\n  abstract = \t {Spaces with locally varying scale of measurement, like multidimensional structures with differently scaled dimensions, are pretty common in statistics and machine learning. Nevertheless, it is still understood as an open question how to exploit the entire information encoded in them properly. We address this problem by considering an order based on (sets of) expectations of random variables mapping into such non-standard spaces. This order contains stochastic dominance and expectation order as extreme cases when no, or respectively perfect, cardinal structure is given.  We derive a (regularized) statistical test for our proposed generalized stochastic dominance (GSD) order, operationalize it by linear optimization, and robustify it by imprecise probability models. Our findings are illustrated with data from multidimensional poverty measurement, finance, and medicine.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/jansen23a/jansen23a.pdf",
        "supp": "",
        "pdf_size": 505140,
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7271203543372625431&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Statistics, Ludwig-Maximilians-Universit\u00e4t, Munich, Bavaria, Germany; Department of Statistics, Ludwig-Maximilians-Universit\u00e4t, Munich, Bavaria, Germany; Department of Statistics, Ludwig-Maximilians-Universit\u00e4t, Munich, Bavaria, Germany; Department of Statistics, Ludwig-Maximilians-Universit\u00e4t, Munich, Bavaria, Germany; Department of Statistics, Ludwig-Maximilians-Universit\u00e4t, Munich, Bavaria, Germany",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Ludwig-Maximilians-Universit\u00e4t",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.lmu.de",
        "aff_unique_abbr": "LMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "c9e799d4af",
        "title": "SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models",
        "site": "https://proceedings.mlr.press/v216/thangarasa23a.html",
        "author": "Vithursan Thangarasa; Abhay Gupta; William Marshall; Tianda Li; Kevin Leong; Dennis DeCoste; Sean Lie; Shreyas Saxena",
        "abstract": "The pre-training and fine-tuning paradigm has contributed to a number of breakthroughs in Natural Language Processing (NLP). Instead of directly training on a downstream task, language models are first pre-trained on large datasets with cross-domain knowledge (e.g., Pile, MassiveText, etc.) and then fine-tuned on task-specific data (e.g., natural language generation, text summarization, etc.). Scaling the model and dataset size has helped improve the performance of LLMs, but unfortunately, this also lead to highly prohibitive computational costs. Pre-training LLMs often require orders of magnitude more FLOPs than fine-tuning and the model capacity often remains the same between the two phases. To achieve training efficiency\u00a0w.r.t training FLOPs, we propose to decouple the model capacity between the two phases and introduce Sparse Pre-training and Dense Fine-tuning (SPDF). In this work, we show the benefits of using unstructured weight sparsity to train only a subset of weights during pre-training (Sparse Pre-training) and then recover the representational capacity by allowing the zeroed weights to learn (Dense Fine-tuning). We demonstrate that we can induce up to 75% sparsity into a 1.3B parameter GPT-3 XL model resulting in a 2.5x reduction in pre-training FLOPs, without a significant loss in accuracy on the downstream tasks relative to the dense baseline. By rigorously evaluating multiple downstream tasks, we also establish a relationship between sparsity, task complexity and dataset size. Our work presents a promising direction to train large GPT models at a fraction of the training FLOPs using weight sparsity, while retaining the benefits of pre-trained textual representations for downstream tasks.",
        "bibtex": "@InProceedings{pmlr-v216-thangarasa23a,\n  title = \t {{SPDF}: Sparse Pre-training and Dense Fine-tuning for Large Language Models},\n  author =       {Thangarasa, Vithursan and Gupta, Abhay and Marshall, William and Li, Tianda and Leong, Kevin and DeCoste, Dennis and Lie, Sean and Saxena, Shreyas},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2134--2146},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/thangarasa23a/thangarasa23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/thangarasa23a.html},\n  abstract = \t {The pre-training and fine-tuning paradigm has contributed to a number of breakthroughs in Natural Language Processing (NLP). Instead of directly training on a downstream task, language models are first pre-trained on large datasets with cross-domain knowledge (e.g., Pile, MassiveText, etc.) and then fine-tuned on task-specific data (e.g., natural language generation, text summarization, etc.). Scaling the model and dataset size has helped improve the performance of LLMs, but unfortunately, this also lead to highly prohibitive computational costs. Pre-training LLMs often require orders of magnitude more FLOPs than fine-tuning and the model capacity often remains the same between the two phases. To achieve training efficiency\u00a0w.r.t training FLOPs, we propose to decouple the model capacity between the two phases and introduce Sparse Pre-training and Dense Fine-tuning (SPDF). In this work, we show the benefits of using unstructured weight sparsity to train only a subset of weights during pre-training (Sparse Pre-training) and then recover the representational capacity by allowing the zeroed weights to learn (Dense Fine-tuning). We demonstrate that we can induce up to 75% sparsity into a 1.3B parameter GPT-3 XL model resulting in a 2.5x reduction in pre-training FLOPs, without a significant loss in accuracy on the downstream tasks relative to the dense baseline. By rigorously evaluating multiple downstream tasks, we also establish a relationship between sparsity, task complexity and dataset size. Our work presents a promising direction to train large GPT models at a fraction of the training FLOPs using weight sparsity, while retaining the benefits of pre-trained textual representations for downstream tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/thangarasa23a/thangarasa23a.pdf",
        "supp": "",
        "pdf_size": 353604,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2440545415482176161&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "411ac21c0d",
        "title": "Sample Boosting Algorithm (SamBA) - An interpretable greedy ensemble classifier based on local expertise for fat data",
        "site": "https://proceedings.mlr.press/v216/bauvin23a.html",
        "author": "Baptiste Bauvin; C\u00e9cile Capponi; Florence Clerc; Pascal Germain; Sokol Ko\u00e7o; Jacques Corbeil",
        "abstract": "Ensemble methods are a very diverse family of algorithms with a wide range of applications. One of the most commonly used is boosting, with the prominent Adaboost. Adaboost relies on greedily learning base classifiers that rectify the error from previous iterations. Then, it combines them through a weighted majority vote, based on their quality on the entire learning set. In this paper, we propose a supervised binary classification framework that propagates the local knowledge acquired during the boosting iterations to the prediction function. Based on this general framework, we introduce SamBA, an interpretable greedy ensemble method designed for fat datasets, with a large number of dimensions and a small number of samples. SamBA learns local classifiers and combines them, using a similarity function, to optimize its efficiency in data extraction. We provide a theoretical analysis of SamBA, yielding convergence and generalization guarantees. In addition, we highlight SamBA\u2019s empirical behavior in an extensive experimental analysis on both real biological and generated datasets, comparing it to state-of-the-art ensemble methods and similarity-based approaches.",
        "bibtex": "@InProceedings{pmlr-v216-bauvin23a,\n  title = \t {Sample {B}oosting {A}lgorithm ({SamBA}) - An interpretable greedy ensemble classifier based on local expertise for fat data},\n  author =       {Bauvin, Baptiste and Capponi, C\\'{e}cile and Clerc, Florence and Germain, Pascal and Ko\\c{c}o, Sokol and Corbeil, Jacques},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {130--140},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/bauvin23a/bauvin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/bauvin23a.html},\n  abstract = \t {Ensemble methods are a very diverse family of algorithms with a wide range of applications. One of the most commonly used is boosting, with the prominent Adaboost. Adaboost relies on greedily learning base classifiers that rectify the error from previous iterations. Then, it combines them through a weighted majority vote, based on their quality on the entire learning set. In this paper, we propose a supervised binary classification framework that propagates the local knowledge acquired during the boosting iterations to the prediction function. Based on this general framework, we introduce SamBA, an interpretable greedy ensemble method designed for fat datasets, with a large number of dimensions and a small number of samples. SamBA learns local classifiers and combines them, using a similarity function, to optimize its efficiency in data extraction. We provide a theoretical analysis of SamBA, yielding convergence and generalization guarantees. In addition, we highlight SamBA\u2019s empirical behavior in an extensive experimental analysis on both real biological and generated datasets, comparing it to state-of-the-art ensemble methods and similarity-based approaches.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/bauvin23a/bauvin23a.pdf",
        "supp": "",
        "pdf_size": 4630907,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:BmsjO8pLcccJ:scholar.google.com/&scioq=Sample+Boosting+Algorithm+(SamBA)+-+An+interpretable+greedy+ensemble+classifier+based+on+local+expertise+for+fat+data&hl=en&as_sdt=0,33",
        "gs_version_total": 5,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "3292f8e1a5",
        "title": "Scalable and robust tensor ring decomposition for large-scale data",
        "site": "https://proceedings.mlr.press/v216/he23b.html",
        "author": "Yicong He; George K. Atia",
        "abstract": "Tensor ring (TR) decomposition has recently received increased attention due to its superior expressive performance for high-order tensors. However, the applicability of traditional TR decomposition algorithms to real-world applications is hindered by prevalent large data sizes, missing entries, and corruption with outliers. In this work, we propose a scalable and robust TR decomposition algorithm capable of handling large-scale tensor data with missing entries and gross corruptions. We first develop a novel auto-weighted steepest descent method that can adaptively fill the missing entries and identify the outliers during the decomposition process. Further, taking advantage of the tensor ring model, we develop a novel fast Gram matrix computation (FGMC) approach and a randomized subtensor sketching (RStS) strategy which yield significant reduction in storage and computational complexity. Experimental results demonstrate that the proposed method outperforms existing TR decomposition methods in the presence of outliers, and runs significantly faster than existing robust tensor completion algorithms.",
        "bibtex": "@InProceedings{pmlr-v216-he23b,\n  title = \t {Scalable and robust tensor ring decomposition for large-scale data},\n  author =       {He, Yicong and Atia, George K.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {860--869},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/he23b/he23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/he23b.html},\n  abstract = \t {Tensor ring (TR) decomposition has recently received increased attention due to its superior expressive performance for high-order tensors. However, the applicability of traditional TR decomposition algorithms to real-world applications is hindered by prevalent large data sizes, missing entries, and corruption with outliers. In this work, we propose a scalable and robust TR decomposition algorithm capable of handling large-scale tensor data with missing entries and gross corruptions. We first develop a novel auto-weighted steepest descent method that can adaptively fill the missing entries and identify the outliers during the decomposition process. Further, taking advantage of the tensor ring model, we develop a novel fast Gram matrix computation (FGMC) approach and a randomized subtensor sketching (RStS) strategy which yield significant reduction in storage and computational complexity. Experimental results demonstrate that the proposed method outperforms existing TR decomposition methods in the presence of outliers, and runs significantly faster than existing robust tensor completion algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/he23b/he23b.pdf",
        "supp": "",
        "pdf_size": 4269872,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14355367290538711722&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL, 32816, USA+Department of Computer Science, University of Central Florida, Orlando, FL, 32816, USA; Department of Electrical and Computer Engineering, University of Central Florida, Orlando, FL, 32816, USA+Department of Computer Science, University of Central Florida, Orlando, FL, 32816, USA",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;0+0",
        "aff_unique_norm": "University of Central Florida",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucf.edu",
        "aff_unique_abbr": "UCF",
        "aff_campus_unique_index": "0+0;0+0",
        "aff_campus_unique": "Orlando",
        "aff_country_unique_index": "0+0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9796e67375",
        "title": "Scalable nonparametric Bayesian learning for dynamic velocity fields",
        "site": "https://proceedings.mlr.press/v216/chakraborty23a.html",
        "author": "Sunrit Chakraborty; Aritra Guha; Rayleigh Lei; XuanLong Nguyen",
        "abstract": "Learning and understanding heterogeneous patterns in complex spatio-temporal data is an important and challenging task across domains in science and engineering. In this work, we develop a model for learning heterogeneous and dynamic patterns of velocity field data, motivated by applications in the transportation domain. We draw from basic nonparametric Bayesian modeling elements such as the infinite hidden Markov model and Gaussian process and focus on making the learning of such a stochastic model scalable for voluminous and streaming data. This is achieved by employing sequential MAP estimates from the infinite HMM model, an efficient sequential sparse GP posterior computation, and refinement of the estimates using the Viterbi algorithm, which is shown to work effectively on a careful simulation study. We demonstrate the efficacy of our techniques to the NGSIM dataset of complex multi-vehicle interactions.",
        "bibtex": "@InProceedings{pmlr-v216-chakraborty23a,\n  title = \t {Scalable nonparametric {B}ayesian learning for dynamic velocity fields},\n  author =       {Chakraborty, Sunrit and Guha, Aritra and Lei, Rayleigh and Nguyen, XuanLong},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {282--292},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/chakraborty23a/chakraborty23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/chakraborty23a.html},\n  abstract = \t {Learning and understanding heterogeneous patterns in complex spatio-temporal data is an important and challenging task across domains in science and engineering. In this work, we develop a model for learning heterogeneous and dynamic patterns of velocity field data, motivated by applications in the transportation domain. We draw from basic nonparametric Bayesian modeling elements such as the infinite hidden Markov model and Gaussian process and focus on making the learning of such a stochastic model scalable for voluminous and streaming data. This is achieved by employing sequential MAP estimates from the infinite HMM model, an efficient sequential sparse GP posterior computation, and refinement of the estimates using the Viterbi algorithm, which is shown to work effectively on a careful simulation study. We demonstrate the efficacy of our techniques to the NGSIM dataset of complex multi-vehicle interactions.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/chakraborty23a/chakraborty23a.pdf",
        "supp": "",
        "pdf_size": 980050,
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:DhKRj3652OgJ:scholar.google.com/&scioq=Scalable+nonparametric+Bayesian+learning+for+dynamic+velocity+fields&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "aff": "Department of Statistics, University of Michigan, Ann Arbor, MI, USA; Data Science & AI Research, Chief Data Office, AT&T, Bedminster, NJ, USA; Department of Statistics, University of Washington, Seattle, WA, USA; Department of Statistics, University of Michigan, Ann Arbor, MI, USA",
        "aff_domain": "umich.edu; ; ; ",
        "email": "umich.edu; ; ; ",
        "github": "",
        "project": "http://ops.fhwa.dot.gov/traf\ufb01canalysistools/ngsim.htm",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Michigan;AT&T;University of Washington",
        "aff_unique_dep": "Department of Statistics;Chief Data Office;Department of Statistics",
        "aff_unique_url": "https://www.umich.edu;https://www.att.com;https://www.washington.edu",
        "aff_unique_abbr": "UM;AT&T;UW",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Ann Arbor;Bedminster;Seattle",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "659741f74f",
        "title": "Scaling integer arithmetic in probabilistic programs",
        "site": "https://proceedings.mlr.press/v216/cao23b.html",
        "author": "William X. Cao; Poorva Garg; Ryan Tjoa; Steven Holtzen; Todd Millstein; Guy Van den Broeck",
        "abstract": "Distributions on integers are ubiquitous in probabilistic modeling but remain challenging for many of today\u2019s probabilistic programming languages (PPLs). The core challenge comes from discrete structure: many of today\u2019s PPL inference strategies rely on enumeration, sampling, or differentiation in order to scale, which fail for high-dimensional complex discrete distributions involving integers. Our insight is that there is structure in arithmetic that these approaches are not using. We present a binary encoding strategy for discrete distributions that exploits the rich logical structure of integer operations like summation and comparison. We leverage this structured encoding with knowledge compilation to perform exact probabilistic inference, and show that this approach scales to much larger integer distributions with arithmetic.",
        "bibtex": "@InProceedings{pmlr-v216-cao23b,\n  title = \t {Scaling integer arithmetic in probabilistic programs},\n  author =       {Cao, William X. and Garg, Poorva and Tjoa, Ryan and Holtzen, Steven and Millstein, Todd and {Van den Broeck}, Guy},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {260--270},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/cao23b/cao23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/cao23b.html},\n  abstract = \t {Distributions on integers are ubiquitous in probabilistic modeling but remain challenging for many of today\u2019s probabilistic programming languages (PPLs). The core challenge comes from discrete structure: many of today\u2019s PPL inference strategies rely on enumeration, sampling, or differentiation in order to scale, which fail for high-dimensional complex discrete distributions involving integers. Our insight is that there is structure in arithmetic that these approaches are not using. We present a binary encoding strategy for discrete distributions that exploits the rich logical structure of integer operations like summation and comparison. We leverage this structured encoding with knowledge compilation to perform exact probabilistic inference, and show that this approach scales to much larger integer distributions with arithmetic.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/cao23b/cao23b.pdf",
        "supp": "",
        "pdf_size": 307563,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2149573451894545038&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "4308368340",
        "title": "Semi-supervised learning of partial differential operators and dynamical flows",
        "site": "https://proceedings.mlr.press/v216/rotman23a.html",
        "author": "Michael Rotman; Amit Dekel; Ran Ilan Ber; Lior Wolf; Yaron Oz",
        "abstract": "The evolution of many dynamical systems is generically governed by nonlinear partial differential equations (PDEs), whose solution, in a simulation framework, requires vast amounts of computational resources. In this work, we present a novel method that combines a hyper-network solver with a Fourier Neural Operator architecture. Our method treats time and space separately and as a result, it successfully propagates initial conditions in continuous time steps by employing the general composition properties of the partial differential operators. Following previous works, supervision is provided at a specific time point. We test our method on various time evolution PDEs, including nonlinear fluid flows in one, two, or three spatial dimensions. The results show that the new method improves the learning accuracy at the time of the supervision point, and can interpolate the solutions to any intermediate time.",
        "bibtex": "@InProceedings{pmlr-v216-rotman23a,\n  title = \t {Semi-supervised learning of partial differential operators and dynamical flows},\n  author =       {Rotman, Michael and Dekel, Amit and Ilan Ber, Ran and Wolf, Lior and Oz, Yaron},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1785--1794},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/rotman23a/rotman23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/rotman23a.html},\n  abstract = \t {The evolution of many dynamical systems is generically governed by nonlinear partial differential equations (PDEs), whose solution, in a simulation framework, requires vast amounts of computational resources. In this work, we present a novel method that combines a hyper-network solver with a Fourier Neural Operator architecture. Our method treats time and space separately and as a result, it successfully propagates initial conditions in continuous time steps by employing the general composition properties of the partial differential operators. Following previous works, supervision is provided at a specific time point. We test our method on various time evolution PDEs, including nonlinear fluid flows in one, two, or three spatial dimensions. The results show that the new method improves the learning accuracy at the time of the supervision point, and can interpolate the solutions to any intermediate time.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/rotman23a/rotman23a.pdf",
        "supp": "",
        "pdf_size": 530595,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7638457215727254674&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "School of Computer Science, Tel-Aviv University, Israel+Amazon Prime Video; Univrses, Sweden; K Health, New York, NY; School of Computer Science, Tel-Aviv University, Israel; School of Physics and Astronomy, Tel-Aviv University, Israel",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "https://github.com/rotmanmi/Semi-Supervised-Learning-of-Dynamical-Flows",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;2;3;0;0",
        "aff_unique_norm": "Tel-Aviv University;Amazon;Univrses;K Health",
        "aff_unique_dep": "School of Computer Science;Prime Video;;",
        "aff_unique_url": "https://www.tau.ac.il;https://www.primevideo.com;;",
        "aff_unique_abbr": "TAU;Amazon Prime Video;;",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Tel-Aviv;;New York",
        "aff_country_unique_index": "0+1;2;1;0;0",
        "aff_country_unique": "Israel;United States;Sweden"
    },
    {
        "id": "aa9e655b4e",
        "title": "Simple Transferability Estimation for Regression Tasks",
        "site": "https://proceedings.mlr.press/v216/nguyen23a.html",
        "author": "Cuong N. Nguyen; Phong Tran; Lam Si Tung Ho; Vu Dinh; Anh T. Tran; Tal Hassner; Cuong V. Nguyen",
        "abstract": "We consider transferability estimation, the problem of estimating how well deep learning models transfer from a source to a target task. We focus on regression tasks, which received little previous attention, and propose two simple and computationally efficient approaches that estimate transferability based on the negative regularized mean squared error of a linear regression model. We prove novel theoretical results connecting our approaches to the actual transferability of the optimal target models obtained from the transfer learning process. Despite their simplicity, our approaches significantly outperform existing state-of-the-art regression transferability estimators in both accuracy and efficiency. On two large-scale keypoint regression benchmarks, our approaches yield 12% to 36% better results on average while being at least 27% faster than previous state-of-the-art methods.",
        "bibtex": "@InProceedings{pmlr-v216-nguyen23a,\n  title = \t {Simple Transferability Estimation for Regression Tasks},\n  author =       {Nguyen, Cuong N. and Tran, Phong and Ho, Lam Si Tung and Dinh, Vu and Tran, Anh T. and Hassner, Tal and Nguyen, Cuong V.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1510--1521},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/nguyen23a/nguyen23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/nguyen23a.html},\n  abstract = \t {We consider transferability estimation, the problem of estimating how well deep learning models transfer from a source to a target task. We focus on regression tasks, which received little previous attention, and propose two simple and computationally efficient approaches that estimate transferability based on the negative regularized mean squared error of a linear regression model. We prove novel theoretical results connecting our approaches to the actual transferability of the optimal target models obtained from the transfer learning process. Despite their simplicity, our approaches significantly outperform existing state-of-the-art regression transferability estimators in both accuracy and efficiency. On two large-scale keypoint regression benchmarks, our approaches yield 12% to 36% better results on average while being at least 27% faster than previous state-of-the-art methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/nguyen23a/nguyen23a.pdf",
        "supp": "",
        "pdf_size": 826423,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10911708311829176121&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "df110d8d72",
        "title": "Size-constrained k-submodular maximization in near-linear time",
        "site": "https://proceedings.mlr.press/v216/nie23a.html",
        "author": "Guanyu Nie; Yanhui Zhu; Yididiya Y. Nadew; Samik Basu; A. Pavan; Christopher John Quinn",
        "abstract": "We investigate the problems of maximizing k-submodular functions over total size constraints and over individual size constraints. k-submodularity is a generalization of submodularity beyond just picking items of a ground set, instead associating one of k types to chosen items.  For sensor selection problems, for instance, this enables modeling of which type  of sensor to put at a location, not simply whether to put a sensor or not.   We propose and analyze threshold-greedy algorithms for both types of constraints.  We prove that our proposed algorithms achieve the best known approximation ratios for both constraint types, up to a user-chosen parameter that balances computational complexity and the approximation ratio, while only using a number of function evaluations that depends linearly (up to poly-logarithmic terms) on the number of elements n, the number of types k, and the inverse of the user chosen parameter.  Other algorithms that achieve the best-known deterministic approximation ratios require a number of  function evaluations that depends linearly on the budget B, while our methods do not.  We empirically demonstrate our algorithms\u2019 performance in applications of sensor placement with k types and influence maximization with k topics.",
        "bibtex": "@InProceedings{pmlr-v216-nie23a,\n  title = \t {Size-constrained k-submodular maximization in near-linear time},\n  author =       {Nie, Guanyu and Zhu, Yanhui and Nadew, Yididiya Y. and Basu, Samik and Pavan, A. and Quinn, Christopher John},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1545--1554},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/nie23a/nie23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/nie23a.html},\n  abstract = \t {We investigate the problems of maximizing k-submodular functions over total size constraints and over individual size constraints. k-submodularity is a generalization of submodularity beyond just picking items of a ground set, instead associating one of k types to chosen items.  For sensor selection problems, for instance, this enables modeling of which type  of sensor to put at a location, not simply whether to put a sensor or not.   We propose and analyze threshold-greedy algorithms for both types of constraints.  We prove that our proposed algorithms achieve the best known approximation ratios for both constraint types, up to a user-chosen parameter that balances computational complexity and the approximation ratio, while only using a number of function evaluations that depends linearly (up to poly-logarithmic terms) on the number of elements n, the number of types k, and the inverse of the user chosen parameter.  Other algorithms that achieve the best-known deterministic approximation ratios require a number of  function evaluations that depends linearly on the budget B, while our methods do not.  We empirically demonstrate our algorithms\u2019 performance in applications of sensor placement with k types and influence maximization with k topics.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/nie23a/nie23a.pdf",
        "supp": "",
        "pdf_size": 2511437,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10260448105700571899&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6df696785d",
        "title": "Solving multi-model MDPs by coordinate ascent and dynamic programming",
        "site": "https://proceedings.mlr.press/v216/su23a.html",
        "author": "Xihong Su; Marek Petrik",
        "abstract": "Multi-model Markov decision process (MMDP) is a promising framework for computing policies that are robust to parameter uncertainty in MDPs. MMDPs aim to find a policy that maximizes the expected return over a distribution of MDP models. Because MMDPs are NP-hard to solve, most methods resort to approximations. In this paper, we derive the policy gradient of MMDPs and propose CADP, which combines a coordinate ascent method and a dynamic programming algorithm for solving MMDPs. The main innovation of CADP compared with earlier algorithms is to take the coordinate ascent perspective to adjust model weights iteratively to guarantee monotone policy improvements to a local maximum. A theoretical analysis of CADP proves that it never performs worse than previous dynamic programming algorithms like WSU. Our numerical results indicate that CADP substantially outperforms existing methods on several benchmark problems.",
        "bibtex": "@InProceedings{pmlr-v216-su23a,\n  title = \t {Solving multi-model {MDPs} by coordinate ascent and dynamic programming},\n  author =       {Su, Xihong and Petrik, Marek},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2016--2025},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/su23a/su23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/su23a.html},\n  abstract = \t {Multi-model Markov decision process (MMDP) is a promising framework for computing policies that are robust to parameter uncertainty in MDPs. MMDPs aim to find a policy that maximizes the expected return over a distribution of MDP models. Because MMDPs are NP-hard to solve, most methods resort to approximations. In this paper, we derive the policy gradient of MMDPs and propose CADP, which combines a coordinate ascent method and a dynamic programming algorithm for solving MMDPs. The main innovation of CADP compared with earlier algorithms is to take the coordinate ascent perspective to adjust model weights iteratively to guarantee monotone policy improvements to a local maximum. A theoretical analysis of CADP proves that it never performs worse than previous dynamic programming algorithms like WSU. Our numerical results indicate that CADP substantially outperforms existing methods on several benchmark problems.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/su23a/su23a.pdf",
        "supp": "",
        "pdf_size": 937165,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8663904245120966649&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Department of Computer Science, University of New Hampshire, Durham, NH, USA; Department of Computer Science, University of New Hampshire, Durham, NH, USA",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of New Hampshire",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.unh.edu",
        "aff_unique_abbr": "UNH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Durham",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "348a55bc1d",
        "title": "Split, count, and share: a differentially private set intersection cardinality estimation protocol",
        "site": "https://proceedings.mlr.press/v216/purcell23a.html",
        "author": "Michael Purcell; Yang Li; Kee Siong Ng",
        "abstract": "We describe a simple two-party protocol in which each party contributes a set as input. The output of the protocol is an estimate of the cardinality of the intersection of the two input sets. We show that our protocol is efficient and secure. We show that the space complexity and communication complexity are constant, the time complexity for each party is proportional to the size of their input set, and that our protocol is differentially private. We also analyze the distribution of the output of the protocol, deriving both its asymptotic distribution and finite-sample bounds on its tail probabilities. These analyses show that, when the input sets are large, our protocol produces accurate set intersection cardinality estimates. We claim that our protocol is an attractive alternative to traditional private set intersection cardinality (PSI-CA) protocols when the input sets are large, exact precision is not required, and differential privacy on its own can provide sufficient protection to the underlying sensitive data.",
        "bibtex": "@InProceedings{pmlr-v216-purcell23a,\n  title = \t {Split, count, and share: a differentially private set intersection cardinality estimation protocol},\n  author =       {Purcell, Michael and Li, Yang and Ng, Kee Siong},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1684--1694},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/purcell23a/purcell23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/purcell23a.html},\n  abstract = \t {We describe a simple two-party protocol in which each party contributes a set as input. The output of the protocol is an estimate of the cardinality of the intersection of the two input sets. We show that our protocol is efficient and secure. We show that the space complexity and communication complexity are constant, the time complexity for each party is proportional to the size of their input set, and that our protocol is differentially private. We also analyze the distribution of the output of the protocol, deriving both its asymptotic distribution and finite-sample bounds on its tail probabilities. These analyses show that, when the input sets are large, our protocol produces accurate set intersection cardinality estimates. We claim that our protocol is an attractive alternative to traditional private set intersection cardinality (PSI-CA) protocols when the input sets are large, exact precision is not required, and differential privacy on its own can provide sufficient protection to the underlying sensitive data.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/purcell23a/purcell23a.pdf",
        "supp": "",
        "pdf_size": 514954,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11569983361288726817&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1db456ee5c",
        "title": "Stochastic Generative Flow Networks",
        "site": "https://proceedings.mlr.press/v216/pan23a.html",
        "author": "Ling Pan; Dinghuai Zhang; Moksh Jain; Longbo Huang; Yoshua Bengio",
        "abstract": "Generative Flow Networks (or GFlowNets for short) are a family of probabilistic agents that learn to sample complex combinatorial structures through the lens of \u201cinference as control\u201d. They have shown great potential in generating high-quality and diverse candidates from a given energy landscape. However, existing GFlowNets can be applied only to deterministic environments, and fail in more general tasks with stochastic dynamics, which can limit their applicability. To overcome this challenge, this paper introduces Stochastic GFlowNets, a new algorithm that extends GFlowNets to stochastic environments. By decomposing state transitions into two steps, Stochastic GFlowNets isolate environmental stochasticity and learn a dynamics model to capture it. Extensive experimental results demonstrate that Stochastic GFlowNets offer significant advantages over standard GFlowNets as well as MCMC- and RL-based approaches, on a variety of standard benchmarks with stochastic dynamics.",
        "bibtex": "@InProceedings{pmlr-v216-pan23a,\n  title = \t {Stochastic Generative Flow Networks},\n  author =       {Pan, Ling and Zhang, Dinghuai and Jain, Moksh and Huang, Longbo and Bengio, Yoshua},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1628--1638},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/pan23a/pan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/pan23a.html},\n  abstract = \t {Generative Flow Networks (or GFlowNets for short) are a family of probabilistic agents that learn to sample complex combinatorial structures through the lens of \u201cinference as control\u201d. They have shown great potential in generating high-quality and diverse candidates from a given energy landscape. However, existing GFlowNets can be applied only to deterministic environments, and fail in more general tasks with stochastic dynamics, which can limit their applicability. To overcome this challenge, this paper introduces Stochastic GFlowNets, a new algorithm that extends GFlowNets to stochastic environments. By decomposing state transitions into two steps, Stochastic GFlowNets isolate environmental stochasticity and learn a dynamics model to capture it. Extensive experimental results demonstrate that Stochastic GFlowNets offer significant advantages over standard GFlowNets as well as MCMC- and RL-based approaches, on a variety of standard benchmarks with stochastic dynamics.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/pan23a/pan23a.pdf",
        "supp": "",
        "pdf_size": 1877861,
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12660486904553556&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Mila - Qu\u00e9bec AI Institute+Universit\u00e9 de Montr\u00e9al; Mila - Qu\u00e9bec AI Institute+Universit\u00e9 de Montr\u00e9al; Mila - Qu\u00e9bec AI Institute+Universit\u00e9 de Montr\u00e9al; Tsinghua University; Mila - Qu\u00e9bec AI Institute+Universit\u00e9 de Montr\u00e9al+CIFAR AI Chair",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0+1;0+1;2;0+1+3",
        "aff_unique_norm": "Qu\u00e9bec AI Institute;Universit\u00e9 de Montr\u00e9al;Tsinghua University;CIFAR",
        "aff_unique_dep": "AI Institute;;;AI Chair",
        "aff_unique_url": "https://mila.quebec;https://www.umontreal.ca;https://www.tsinghua.edu.cn;https://www.cifar.ca",
        "aff_unique_abbr": "Mila;UdeM;THU;CIFAR",
        "aff_campus_unique_index": ";;;",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0+0;0+0;0+0;1;0+0+0",
        "aff_country_unique": "Canada;China"
    },
    {
        "id": "4283f6e83e",
        "title": "Stochastic Graphical Bandits with Heavy-Tailed Rewards",
        "site": "https://proceedings.mlr.press/v216/gou23a.html",
        "author": "Yutian Gou; Jinfeng Yi; Lijun Zhang",
        "abstract": "We consider stochastic graphical bandits, where after pulling an arm, the decision maker observes rewards of not only the chosen arm but also its neighbors in a feedback graph. Most of existing work assumes that the rewards are drawn from bounded or at least sub-Gaussian distributions, which however may be violated in many practical scenarios such as social advertising and financial markets. To settle this issue, we investigate stochastic graphical bandits with heavy-tailed rewards, where the distributions have finite moments of order $1+\\epsilon$, for some $\\epsilon\\in(0, 1]$. Firstly, we develop one UCB-type algorithm, whose expected regret is upper bounded by a sum of gap-based quantities over the",
        "bibtex": "@InProceedings{pmlr-v216-gou23a,\n  title = \t {Stochastic Graphical Bandits with Heavy-Tailed Rewards},\n  author =       {Gou, Yutian and Yi, Jinfeng and Zhang, Lijun},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {734--744},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/gou23a/gou23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/gou23a.html},\n  abstract = \t {We consider stochastic graphical bandits, where after pulling an arm, the decision maker observes rewards of not only the chosen arm but also its neighbors in a feedback graph. Most of existing work assumes that the rewards are drawn from bounded or at least sub-Gaussian distributions, which however may be violated in many practical scenarios such as social advertising and financial markets. To settle this issue, we investigate stochastic graphical bandits with heavy-tailed rewards, where the distributions have finite moments of order $1+\\epsilon$, for some $\\epsilon\\in(0, 1]$. Firstly, we develop one UCB-type algorithm, whose expected regret is upper bounded by a sum of gap-based quantities over the",
        "pdf": "https://proceedings.mlr.press/v216/gou23a/gou23a.pdf",
        "supp": "",
        "pdf_size": 828571,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7217840705271779051&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China; JD AI Research, Beijing 100176, China; National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing 210023, China",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Nanjing University;JD",
        "aff_unique_dep": "National Key Laboratory for Novel Software Technology;JD AI Research",
        "aff_unique_url": "http://www.nju.edu.cn;",
        "aff_unique_abbr": "Nanjing U;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Nanjing;Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "2fcf572fd7",
        "title": "Structure-aware robustness certificates for graph classification",
        "site": "https://proceedings.mlr.press/v216/osselin23a.html",
        "author": "Pierre Osselin; Henry Kenlay; Xiaowen Dong",
        "abstract": "Certifying the robustness of a graph-based machine learning model poses a critical challenge for safety. Current robustness certificates for graph classifiers guarantee output invariance with respect to the total number of node pair flips (edge addition or edge deletion), which amounts to an {$l_{0}$} ball centred on the adjacency matrix. Although theoretically attractive, this type of isotropic structural noise can be too restrictive in practical scenarios where some node pairs are more critical than others in determining the classifier\u2019s output. The certificate, in this case, gives a pessimistic depiction of the robustness of the graph model. To tackle this issue, we develop a randomised smoothing method based on adding an anisotropic noise distribution to the input graph structure. We show that our process generates structural-aware certificates for our classifiers, whereby the magnitude of robustness certificates can vary across different pre-defined structures of the graph. We demonstrate the benefits of these certificates in both synthetic and real-world experiments.",
        "bibtex": "@InProceedings{pmlr-v216-osselin23a,\n  title = \t {Structure-aware robustness certificates for graph classification},\n  author =       {Osselin, Pierre and Kenlay, Henry and Dong, Xiaowen},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1596--1605},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/osselin23a/osselin23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/osselin23a.html},\n  abstract = \t {Certifying the robustness of a graph-based machine learning model poses a critical challenge for safety. Current robustness certificates for graph classifiers guarantee output invariance with respect to the total number of node pair flips (edge addition or edge deletion), which amounts to an {$l_{0}$} ball centred on the adjacency matrix. Although theoretically attractive, this type of isotropic structural noise can be too restrictive in practical scenarios where some node pairs are more critical than others in determining the classifier\u2019s output. The certificate, in this case, gives a pessimistic depiction of the robustness of the graph model. To tackle this issue, we develop a randomised smoothing method based on adding an anisotropic noise distribution to the input graph structure. We show that our process generates structural-aware certificates for our classifiers, whereby the magnitude of robustness certificates can vary across different pre-defined structures of the graph. We demonstrate the benefits of these certificates in both synthetic and real-world experiments.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/osselin23a/osselin23a.pdf",
        "supp": "",
        "pdf_size": 1788243,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3385658699639978399&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "005707f316",
        "title": "Studying the Effect of GNN Spatial Convolutions On The Embedding Space\u2019s Geometry",
        "site": "https://proceedings.mlr.press/v216/donnat23a.html",
        "author": "Claire Donnat; So Won Jeong",
        "abstract": "By recursively summing node features over entire neighborhoods, spatial graph convolution operators have been heralded as key to the success of Graph Neural Networks (GNNs). Yet, despite the multiplication of GNN methods across tasks and applications, the effect of this aggregation operation has yet to be analyzed. In fact, while most recent efforts in the GNN community have focused on optimizing the architecture of the neural network, fewer works have attempted to characterize",
        "bibtex": "@InProceedings{pmlr-v216-donnat23a,\n  title = \t {Studying the Effect of {GNN} Spatial Convolutions On The Embedding Space\u2019s Geometry},\n  author =       {Donnat, Claire and Jeong, So Won},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {539--548},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/donnat23a/donnat23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/donnat23a.html},\n  abstract = \t {By recursively summing node features over entire neighborhoods, spatial graph convolution operators have been heralded as key to the success of Graph Neural Networks (GNNs). Yet, despite the multiplication of GNN methods across tasks and applications, the effect of this aggregation operation has yet to be analyzed. In fact, while most recent efforts in the GNN community have focused on optimizing the architecture of the neural network, fewer works have attempted to characterize",
        "pdf": "https://proceedings.mlr.press/v216/donnat23a/donnat23a.pdf",
        "supp": "",
        "pdf_size": 1024123,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11937444079183854500&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "aff": "Department of Statistics, The University of Chicago, Chicago, Illinois, USA; Department of Statistics, The University of Chicago, Chicago, Illinois, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Chicago",
        "aff_unique_dep": "Department of Statistics",
        "aff_unique_url": "https://www.uchicago.edu",
        "aff_unique_abbr": "UChicago",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f89b19f467",
        "title": "SubMix: Learning to Mix Graph Sampling Heuristics",
        "site": "https://proceedings.mlr.press/v216/abu-el-haija23a.html",
        "author": "Sami Abu-El-Haija; Joshua V. Dillon; Bahare Fatemi; Kyriakos Axiotis; Neslihan Bulut; Johannes Gasteiger; Bryan Perozzi; Mohammadhossein Bateni",
        "abstract": "Sampling subgraphs for training Graph Neural Networks (GNNs) is receiving much attention from the GNN community. While a variety of methods have been proposed, each method samples the graph according to its own heuristic. However, there has been little work in mixing these heuristics in an end-to-end trainable manner. In this work, we design a generative framework for graph sampling. Our method, SubMix, parameterizes subgraph sampling as a convex combination of heuristics. We show that a continuous relaxation of the discrete sampling process allows us to efficiently obtain analytical gradients for training the sampling parameters. Our experimental results illustrate the usefulness of learning graph sampling in three scenarios: (1) robust training of GNNs by automatically learning to discard noisy edge sources; (2) improving model performance by trainable and online edge subset selection; and (3) by integrating our framework into decoupled GNN models improves their performance on standard benchmarks.",
        "bibtex": "@InProceedings{pmlr-v216-abu-el-haija23a,\n  title = \t {SubMix: Learning to Mix Graph Sampling Heuristics},\n  author =       {Abu-El-Haija, Sami and Dillon, Joshua V. and Fatemi, Bahare and Axiotis, Kyriakos and Bulut, Neslihan and Gasteiger, Johannes and Perozzi, Bryan and Bateni, Mohammadhossein},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1--10},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/abu-el-haija23a/abu-el-haija23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/abu-el-haija23a.html},\n  abstract = \t {Sampling subgraphs for training Graph Neural Networks (GNNs) is receiving much attention from the GNN community. While a variety of methods have been proposed, each method samples the graph according to its own heuristic. However, there has been little work in mixing these heuristics in an end-to-end trainable manner. In this work, we design a generative framework for graph sampling. Our method, SubMix, parameterizes subgraph sampling as a convex combination of heuristics. We show that a continuous relaxation of the discrete sampling process allows us to efficiently obtain analytical gradients for training the sampling parameters. Our experimental results illustrate the usefulness of learning graph sampling in three scenarios: (1) robust training of GNNs by automatically learning to discard noisy edge sources; (2) improving model performance by trainable and online edge subset selection; and (3) by integrating our framework into decoupled GNN models improves their performance on standard benchmarks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/abu-el-haija23a/abu-el-haija23a.pdf",
        "supp": "",
        "pdf_size": 551806,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=504875847882783508&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Google Research, Mountain View, California, USA; Google Research, Mountain View, California, USA; Google Research, Montreal, Queb\u00e9c, Canada; Google Research, New York, NY, USA; Google Research, Mountain View, California, USA; Google Research, Z\u00fcrich, Switzerland; Google Research, Montreal, Queb\u00e9c, Canada; Google Research, Montreal, Queb\u00e9c, Canada",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "https://github.com/tensorflow/gnn/tree/main/tensorflow_gnn/models/submix",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Google Research",
        "aff_unique_url": "https://research.google",
        "aff_unique_abbr": "Google",
        "aff_campus_unique_index": "0;0;1;2;0;3;1;1",
        "aff_campus_unique": "Mountain View;Montreal;New York;Z\u00fcrich",
        "aff_country_unique_index": "0;0;1;0;0;2;1;1",
        "aff_country_unique": "United States;Canada;Switzerland"
    },
    {
        "id": "3a0ec59cdb",
        "title": "Sufficient identification conditions and semiparametric estimation under missing not at random mechanisms",
        "site": "https://proceedings.mlr.press/v216/guo23a.html",
        "author": "Anna Guo; Jiwei Zhao; Razieh Nabi",
        "abstract": "Conducting valid statistical analyses is challenging in the presence of missing-not-at-random (MNAR) data, where the missingness mechanism is dependent on the missing values themselves even conditioned on the observed data. Here, we consider a MNAR model that generalizes several prior popular MNAR models in two ways: first, it is less restrictive in terms of statistical independence assumptions imposed on the underlying joint data distribution, and second, it allows for all variables in the observed sample to have missing values. This MNAR model corresponds to a so-called criss-cross structure considered in the literature on graphical models of missing data that prevents nonparametric identification of the entire missing data model. Nonetheless, part of the complete-data distribution remains nonparametrically identifiable. By exploiting this fact and considering a rich class of exponential family distributions, we establish sufficient conditions for identification of the complete-data distribution as well as the entire missingness mechanism. We then propose methods for testing the independence restrictions encoded in such models using odds ratio as our parameter of interest. We adopt two semiparametric approaches for estimating the odds ratio parameter and establish the corresponding asymptotic theories: one involves maximizing a conditional likelihood with order statistics and the other uses estimating equations. The utility of our methods is illustrated via simulation studies.",
        "bibtex": "@InProceedings{pmlr-v216-guo23a,\n  title = \t {Sufficient identification conditions and semiparametric estimation under missing not at random mechanisms},\n  author =       {Guo, Anna and Zhao, Jiwei and Nabi, Razieh},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {777--787},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/guo23a/guo23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/guo23a.html},\n  abstract = \t {Conducting valid statistical analyses is challenging in the presence of missing-not-at-random (MNAR) data, where the missingness mechanism is dependent on the missing values themselves even conditioned on the observed data. Here, we consider a MNAR model that generalizes several prior popular MNAR models in two ways: first, it is less restrictive in terms of statistical independence assumptions imposed on the underlying joint data distribution, and second, it allows for all variables in the observed sample to have missing values. This MNAR model corresponds to a so-called criss-cross structure considered in the literature on graphical models of missing data that prevents nonparametric identification of the entire missing data model. Nonetheless, part of the complete-data distribution remains nonparametrically identifiable. By exploiting this fact and considering a rich class of exponential family distributions, we establish sufficient conditions for identification of the complete-data distribution as well as the entire missingness mechanism. We then propose methods for testing the independence restrictions encoded in such models using odds ratio as our parameter of interest. We adopt two semiparametric approaches for estimating the odds ratio parameter and establish the corresponding asymptotic theories: one involves maximizing a conditional likelihood with order statistics and the other uses estimating equations. The utility of our methods is illustrated via simulation studies.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/guo23a/guo23a.pdf",
        "supp": "",
        "pdf_size": 419238,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17739278498593058194&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Dept. of Biostatistics and Bioinformatics, Emory University, Atlanta, Georgia, USA; Dept. of Biostatistics & Medical Informatics, University of Wisconsin, Madison, Wisconsin, USA; Dept. of Biostatistics and Bioinformatics, Emory University, Atlanta, Georgia, USA",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Emory University;University of Wisconsin",
        "aff_unique_dep": "Dept. of Biostatistics and Bioinformatics;Dept. of Biostatistics & Medical Informatics",
        "aff_unique_url": "https://www.emory.edu;https://www.wisc.edu",
        "aff_unique_abbr": "Emory;UW",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Atlanta;Madison",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "cb444aea46",
        "title": "SymNet 3.0: Exploiting Long-Range Influences in Learning Generalized Neural Policies for Relational MDPs",
        "site": "https://proceedings.mlr.press/v216/sharma23c.html",
        "author": "Vishal Sharma; Daman Arora; ; Parag Singla",
        "abstract": "We focus on the learning of generalized neural policies for Relational Markov Decision Processes (RMDPs) expressed in RDDL. Recent work first converts the instances of a relational domain into an instance graph, and then trains a Graph Attention Network (GAT) of fixed depth with parameters shared across instances to learn a state representation, which can be decoded to get the policy [sharma et al., 22]. Unfortunately, this approach struggles to learn policies that exploit long-range dependencies \u2013 a fact we formally prove in this paper. As a remedy, we first construct a novel influence graph characterized by edges capturing one-step influence (dependence) between nodes based on the transition model. We then define influence distance between two nodes as the shortest path between them in this graph \u2013 a feature we exploit to represent long-range dependencies. We show that our architecture, referred to as Symbolic Influence Network (SymNet3.0), with its distance-based features, does not suffer from the representational issues faced by earlier approaches. Extensive experimentation demonstrates that we are competitive with existing baselines on 12 standard IPPC domains, and perform significantly better on six additional domains (including IPPC variants), designed to test a model\u2019s capability in capturing long-range dependencies. Further analysis shows that SymNet3.0 automatically learns to focus on nodes that have key information for representing policies that capture long-range dependencies.",
        "bibtex": "@InProceedings{pmlr-v216-sharma23c,\n  title = \t {{SymNet 3.0}: Exploiting Long-Range Influences in Learning Generalized Neural Policies for Relational {MDPs}},\n  author =       {Sharma, Vishal and Arora, Daman and Mausam and Singla, Parag},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1921--1931},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/sharma23c/sharma23c.pdf},\n  url = \t {https://proceedings.mlr.press/v216/sharma23c.html},\n  abstract = \t {We focus on the learning of generalized neural policies for Relational Markov Decision Processes (RMDPs) expressed in RDDL. Recent work first converts the instances of a relational domain into an instance graph, and then trains a Graph Attention Network (GAT) of fixed depth with parameters shared across instances to learn a state representation, which can be decoded to get the policy [sharma et al., 22]. Unfortunately, this approach struggles to learn policies that exploit long-range dependencies \u2013 a fact we formally prove in this paper. As a remedy, we first construct a novel influence graph characterized by edges capturing one-step influence (dependence) between nodes based on the transition model. We then define influence distance between two nodes as the shortest path between them in this graph \u2013 a feature we exploit to represent long-range dependencies. We show that our architecture, referred to as Symbolic Influence Network (SymNet3.0), with its distance-based features, does not suffer from the representational issues faced by earlier approaches. Extensive experimentation demonstrates that we are competitive with existing baselines on 12 standard IPPC domains, and perform significantly better on six additional domains (including IPPC variants), designed to test a model\u2019s capability in capturing long-range dependencies. Further analysis shows that SymNet3.0 automatically learns to focus on nodes that have key information for representing policies that capture long-range dependencies.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/sharma23c/sharma23c.pdf",
        "supp": "",
        "pdf_size": 1430041,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6247796567537622127&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Indian Institute of Technology Delhi; Indian Institute of Technology Delhi; Indian Institute of Technology Delhi; Indian Institute of Technology Delhi",
        "aff_domain": "cse.iitd.ac.in;cse.iitd.ac.in;cse.iitd.ac.in;cse.iitd.ac.in",
        "email": "cse.iitd.ac.in;cse.iitd.ac.in;cse.iitd.ac.in;cse.iitd.ac.in",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Indian Institute of Technology Delhi",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iitd.ac.in",
        "aff_unique_abbr": "IIT Delhi",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Delhi",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "07b5311346",
        "title": "TCE: A Test-Based Approach to Measuring Calibration Error",
        "site": "https://proceedings.mlr.press/v216/matsubara23a.html",
        "author": "Takuo Matsubara; Niek Tax; Richard Mudd; Ido Guy",
        "abstract": "This paper proposes a new metric to measure the calibration error of probabilistic binary classifiers, called test-based calibration error (TCE). TCE incorporates a novel loss function based on a statistical test to examine the extent to which model predictions differ from probabilities estimated from data. It offers (i) a clear interpretation, (ii) a consistent scale that is unaffected by class imbalance, and (iii) an enhanced visual representation with respect to the standard reliability diagram. In addition, we introduce an optimality criterion for the binning procedure of calibration error metrics based on a minimal estimation error of the empirical probabilities. We provide a novel computational algorithm for optimal bins under bin-size constraints. We demonstrate properties of TCE through a range of experiments, including multiple real-world imbalanced datasets and ImageNet 1000.",
        "bibtex": "@InProceedings{pmlr-v216-matsubara23a,\n  title = \t {{TCE}: A Test-Based Approach to Measuring Calibration Error},\n  author =       {Matsubara, Takuo and Tax, Niek and Mudd, Richard and Guy, Ido},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1390--1400},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/matsubara23a/matsubara23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/matsubara23a.html},\n  abstract = \t {This paper proposes a new metric to measure the calibration error of probabilistic binary classifiers, called test-based calibration error (TCE). TCE incorporates a novel loss function based on a statistical test to examine the extent to which model predictions differ from probabilities estimated from data. It offers (i) a clear interpretation, (ii) a consistent scale that is unaffected by class imbalance, and (iii) an enhanced visual representation with respect to the standard reliability diagram. In addition, we introduce an optimality criterion for the binning procedure of calibration error metrics based on a minimal estimation error of the empirical probabilities. We provide a novel computational algorithm for optimal bins under bin-size constraints. We demonstrate properties of TCE through a range of experiments, including multiple real-world imbalanced datasets and ImageNet 1000.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/matsubara23a/matsubara23a.pdf",
        "supp": "",
        "pdf_size": 736265,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1946477951360649416&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "2db4be0c7e",
        "title": "Testing conventional wisdom (of the crowd)",
        "site": "https://proceedings.mlr.press/v216/burrell23a.html",
        "author": "Noah Burrell; Grant Schoenebeck",
        "abstract": "Do common assumptions about the way that crowd workers make mistakes in microtask (labeling) applications manifest in real crowdsourcing data? Prior work only addresses this question indirectly. Instead, it primarily focuses on designing new label aggregation algorithms, seeming to imply that better performance justifies any additional assumptions. However, empirical evidence in past instances has raised significant challenges to common assumptions. We continue this line of work, using crowdsourcing data itself as directly as possible to interrogate several basic assumptions about workers and tasks. We find strong evidence that the assumption that workers respond correctly to each task with a constant probability, which is common in theoretical work, is implausible in real data. We also illustrate how heterogeneity among tasks and workers can take different forms, which have different implications for the design and evaluation of label aggregation algorithms.",
        "bibtex": "@InProceedings{pmlr-v216-burrell23a,\n  title = \t {Testing conventional wisdom (of the crowd)},\n  author =       {Burrell, Noah and Schoenebeck, Grant},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {237--248},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/burrell23a/burrell23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/burrell23a.html},\n  abstract = \t {Do common assumptions about the way that crowd workers make mistakes in microtask (labeling) applications manifest in real crowdsourcing data? Prior work only addresses this question indirectly. Instead, it primarily focuses on designing new label aggregation algorithms, seeming to imply that better performance justifies any additional assumptions. However, empirical evidence in past instances has raised significant challenges to common assumptions. We continue this line of work, using crowdsourcing data itself as directly as possible to interrogate several basic assumptions about workers and tasks. We find strong evidence that the assumption that workers respond correctly to each task with a constant probability, which is common in theoretical work, is implausible in real data. We also illustrate how heterogeneity among tasks and workers can take different forms, which have different implications for the design and evaluation of label aggregation algorithms.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/burrell23a/burrell23a.pdf",
        "supp": "",
        "pdf_size": 328366,
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10820947987334625762&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of Michigan, Ann Arbor, Michigan, USA; University of Michigan, Ann Arbor, Michigan, USA",
        "aff_domain": "; ",
        "email": "; ",
        "github": "https://github.com/burrelln/Testing-Conventional-Wisdom",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "8c80203135",
        "title": "The Shrinkage-Delinkage Trade-off: an Analysis of Factorized Gaussian Approximations for Variational Inference",
        "site": "https://proceedings.mlr.press/v216/margossian23a.html",
        "author": "Charles C. Margossian; Lawrence K. Saul",
        "abstract": "When factorized approximations are used for variational inference (VI), they tend to underestimate the uncertainty\u2014as measured in various ways\u2014of the distributions they are meant to approximate. We consider two popular ways to measure the uncertainty deficit of VI: (i) the degree to which it underestimates the componentwise variance, and (ii) the degree to which it underestimates the entropy. To better understand these effects, and the relationship between them, we examine an informative setting where they can be explicitly (and elegantly) analyzed: the approximation of a Gaussian,\u00a0$p$, with a dense covariance matrix, by a Gaussian,\u00a0$q$, with a diagonal covariance matrix. We prove that $q$ always underestimates both the componentwise variance and the entropy of $p$,",
        "bibtex": "@InProceedings{pmlr-v216-margossian23a,\n  title = \t {The Shrinkage-Delinkage Trade-off: an Analysis of Factorized {G}aussian Approximations for Variational Inference},\n  author =       {Margossian, Charles C. and Saul, Lawrence K.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1358--1367},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/margossian23a/margossian23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/margossian23a.html},\n  abstract = \t {When factorized approximations are used for variational inference (VI), they tend to underestimate the uncertainty\u2014as measured in various ways\u2014of the distributions they are meant to approximate. We consider two popular ways to measure the uncertainty deficit of VI: (i) the degree to which it underestimates the componentwise variance, and (ii) the degree to which it underestimates the entropy. To better understand these effects, and the relationship between them, we examine an informative setting where they can be explicitly (and elegantly) analyzed: the approximation of a Gaussian,\u00a0$p$, with a dense covariance matrix, by a Gaussian,\u00a0$q$, with a diagonal covariance matrix. We prove that $q$ always underestimates both the componentwise variance and the entropy of $p$,",
        "pdf": "https://proceedings.mlr.press/v216/margossian23a/margossian23a.pdf",
        "supp": "",
        "pdf_size": 304332,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2978475217904960660&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Center for Computational Mathematics, Flatiron Institute, New York, NY, USA; Center for Computational Mathematics, Flatiron Institute, New York, NY, USA",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Flatiron Institute",
        "aff_unique_dep": "Center for Computational Mathematics",
        "aff_unique_url": "https://flatironinstitute.org",
        "aff_unique_abbr": "Flatiron",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5deb7e9688",
        "title": "The past does matter: correlation of subsequent states in trajectory predictions of Gaussian Process models",
        "site": "https://proceedings.mlr.press/v216/ridderbusch23a.html",
        "author": "Steffen Ridderbusch; Sina Ober-Bl\u00f6baum; Paul Goulart",
        "abstract": "Computing the distribution of trajectories from a Gaussian Process model of a dynamical system is an important challenge in utilizing such models. Motivated by the computational cost of sampling-based approaches, we consider approximations of the model\u2019s output and trajectory distribution. We show that previous work on uncertainty propagation, focussed on discrete state-space models, incorrectly included an independence assumption between subsequent states of the predicted trajectories. Expanding these ideas to continuous ordinary differential equation models, we illustrate the implications of this assumption and propose a novel piecewise linear approximation of Gaussian Processes to mitigate them.",
        "bibtex": "@InProceedings{pmlr-v216-ridderbusch23a,\n  title = \t {The past does matter: correlation of subsequent states in trajectory predictions of {G}aussian Process models},\n  author =       {Ridderbusch, Steffen and Ober-Bl\\\"obaum, Sina and Goulart, Paul},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1752--1761},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/ridderbusch23a/ridderbusch23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/ridderbusch23a.html},\n  abstract = \t {Computing the distribution of trajectories from a Gaussian Process model of a dynamical system is an important challenge in utilizing such models. Motivated by the computational cost of sampling-based approaches, we consider approximations of the model\u2019s output and trajectory distribution. We show that previous work on uncertainty propagation, focussed on discrete state-space models, incorrectly included an independence assumption between subsequent states of the predicted trajectories. Expanding these ideas to continuous ordinary differential equation models, we illustrate the implications of this assumption and propose a novel piecewise linear approximation of Gaussian Processes to mitigate them.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/ridderbusch23a/ridderbusch23a.pdf",
        "supp": "",
        "pdf_size": 1192202,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8043539387424316775&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "87aa5bcab9",
        "title": "Time-Conditioned Generative Modeling of Object-Centric Representations for Video Decomposition and Prediction",
        "site": "https://proceedings.mlr.press/v216/gao23a.html",
        "author": "Chengmin Gao; Bin Li",
        "abstract": "When perceiving the world from multiple viewpoints, humans have the ability to reason about the complete objects in a compositional manner even when an object is completely occluded from certain viewpoints. Meanwhile, humans are able to imagine novel views after observing multiple viewpoints. Recent remarkable advances in multi-view object-centric learning still leaves some unresolved problems: 1) The shapes of partially or completely occluded objects can not be well reconstructed. 2) The novel viewpoint prediction depends on expensive viewpoint annotations rather than implicit rules in view representations. In this paper, we introduce a time-conditioned generative model for videos. To reconstruct the complete shape of an object accurately, we enhance the disentanglement between the latent representations of objects and views, where the latent representations of time-conditioned views are jointly inferred with a Transformer and then are input to a sequential extension of Slot Attention to learn object-centric representations. In addition, Gaussian processes are employed as priors of view latent variables for video generation and novel-view prediction without viewpoint annotations. Experiments on multiple datasets demonstrate that the proposed model can make object-centric video decomposition, reconstruct the complete shapes of occluded objects, and make novel-view predictions.",
        "bibtex": "@InProceedings{pmlr-v216-gao23a,\n  title = \t {Time-Conditioned Generative Modeling of Object-Centric Representations for Video Decomposition and Prediction},\n  author =       {Gao, Chengmin and Li, Bin},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {613--623},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/gao23a/gao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/gao23a.html},\n  abstract = \t {When perceiving the world from multiple viewpoints, humans have the ability to reason about the complete objects in a compositional manner even when an object is completely occluded from certain viewpoints. Meanwhile, humans are able to imagine novel views after observing multiple viewpoints. Recent remarkable advances in multi-view object-centric learning still leaves some unresolved problems: 1) The shapes of partially or completely occluded objects can not be well reconstructed. 2) The novel viewpoint prediction depends on expensive viewpoint annotations rather than implicit rules in view representations. In this paper, we introduce a time-conditioned generative model for videos. To reconstruct the complete shape of an object accurately, we enhance the disentanglement between the latent representations of objects and views, where the latent representations of time-conditioned views are jointly inferred with a Transformer and then are input to a sequential extension of Slot Attention to learn object-centric representations. In addition, Gaussian processes are employed as priors of view latent variables for video generation and novel-view prediction without viewpoint annotations. Experiments on multiple datasets demonstrate that the proposed model can make object-centric video decomposition, reconstruct the complete shapes of occluded objects, and make novel-view predictions.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/gao23a/gao23a.pdf",
        "supp": "",
        "pdf_size": 3237955,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4871205948005916540&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "School of Computer Science, Fudan University; School of Computer Science, Fudan University",
        "aff_domain": "fudan.edu.cn;fudan.edu.cn",
        "email": "fudan.edu.cn;fudan.edu.cn",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Fudan University",
        "aff_unique_dep": "School of Computer Science",
        "aff_unique_url": "https://www.fudan.edu.cn",
        "aff_unique_abbr": "Fudan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9107636e99",
        "title": "Towards Physically Reliable Molecular Representation Learning",
        "site": "https://proceedings.mlr.press/v216/yi23a.html",
        "author": "Seunghoon Yi; Youngwoo Cho; Jinhwan Sul; Seung Woo Ko; Soo Kyung Kim; Jaegul Choo; Hongkee Yoon; Joonseok Lee",
        "abstract": "Estimating the energetic properties of molecular systems is a critical task in material design. Machine learning has shown remarkable promise on this task over classical force fields, but a fully data-driven approach suffers from limited labeled data; not just the amount of available data lacks, but the distribution of labeled examples is highly skewed to stable states. In this work, we propose a molecular representation learning method that extrapolates well beyond the training distribution, powered by physics-driven parameter estimation from classical energy equations and self-supervised learning inspired from masked language modeling. To ensure reliability of the proposed model, we introduce a series of novel evaluation schemes in multifaceted ways, beyond the energy or force accuracy that has been dominantly used. From extensive experiments, we demonstrate that the proposed method is effective in discovering molecular structures, outperforming other baselines. Furthermore, we extrapolate it to the chemical reaction pathways beyond stable states, taking a step towards physically reliable molecular representation learning.",
        "bibtex": "@InProceedings{pmlr-v216-yi23a,\n  title = \t {Towards Physically Reliable Molecular Representation Learning},\n  author =       {Yi, Seunghoon and Cho, Youngwoo and Sul, Jinhwan and Ko, Seung Woo and Kim, Soo Kyung and Choo, Jaegul and Yoon, Hongkee and Lee, Joonseok},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2433--2443},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/yi23a/yi23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/yi23a.html},\n  abstract = \t {Estimating the energetic properties of molecular systems is a critical task in material design. Machine learning has shown remarkable promise on this task over classical force fields, but a fully data-driven approach suffers from limited labeled data; not just the amount of available data lacks, but the distribution of labeled examples is highly skewed to stable states. In this work, we propose a molecular representation learning method that extrapolates well beyond the training distribution, powered by physics-driven parameter estimation from classical energy equations and self-supervised learning inspired from masked language modeling. To ensure reliability of the proposed model, we introduce a series of novel evaluation schemes in multifaceted ways, beyond the energy or force accuracy that has been dominantly used. From extensive experiments, we demonstrate that the proposed method is effective in discovering molecular structures, outperforming other baselines. Furthermore, we extrapolate it to the chemical reaction pathways beyond stable states, taking a step towards physically reliable molecular representation learning.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/yi23a/yi23a.pdf",
        "supp": "",
        "pdf_size": 1157118,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8945395508982022033&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6a9915d468",
        "title": "Towards better certified segmentation via diffusion models",
        "site": "https://proceedings.mlr.press/v216/laousy23a.html",
        "author": "Othmane Laousy; Alexandre Araujo; Guillaume Chassagnon; Marie-Pierre Revel; Siddharth Garg; Farshad Khorrami; Maria Vakalopoulou",
        "abstract": "The robustness of image segmentation has been an important research topic in the past few years as segmentation models have reached production-level accuracy. However, like classification models, segmentation models can be vulnerable to adversarial perturbations, which hinders their use in critical-decision systems like healthcare or autonomous driving. Recently, randomized smoothing has been proposed to certify segmentation predictions by adding Gaussian noise to the input to obtain theoretical guarantees. However, this method exhibits a trade-off between the amount of added noise and the level of certification achieved. In this paper, we address the problem of certifying segmentation prediction using a combination of randomized smoothing and diffusion models. Our experiments show that combining randomized smoothing and diffusion models significantly improves certified robustness, with results indicating a mean improvement of 21 points in accuracy compared to previous state-of-the-art methods on Pascal-Context and Cityscapes public datasets. Our method is independent of the selected segmentation model and does not need any additional specialized training procedure.",
        "bibtex": "@InProceedings{pmlr-v216-laousy23a,\n  title = \t {Towards better certified segmentation via diffusion models},\n  author =       {Laousy, Othmane and Araujo, Alexandre and Chassagnon, Guillaume and Revel, Marie-Pierre and Garg, Siddharth and Khorrami, Farshad and Vakalopoulou, Maria},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1185--1195},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/laousy23a/laousy23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/laousy23a.html},\n  abstract = \t {The robustness of image segmentation has been an important research topic in the past few years as segmentation models have reached production-level accuracy. However, like classification models, segmentation models can be vulnerable to adversarial perturbations, which hinders their use in critical-decision systems like healthcare or autonomous driving. Recently, randomized smoothing has been proposed to certify segmentation predictions by adding Gaussian noise to the input to obtain theoretical guarantees. However, this method exhibits a trade-off between the amount of added noise and the level of certification achieved. In this paper, we address the problem of certifying segmentation prediction using a combination of randomized smoothing and diffusion models. Our experiments show that combining randomized smoothing and diffusion models significantly improves certified robustness, with results indicating a mean improvement of 21 points in accuracy compared to previous state-of-the-art methods on Pascal-Context and Cityscapes public datasets. Our method is independent of the selected segmentation model and does not need any additional specialized training procedure.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/laousy23a/laousy23a.pdf",
        "supp": "",
        "pdf_size": 16189358,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13882511642508528842&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;;;;",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9850650cb7",
        "title": "Transfer learning for individual treatment effect estimation",
        "site": "https://proceedings.mlr.press/v216/aloui23a.html",
        "author": "Ahmed Aloui; Juncheng Dong; Cat P Le; Vahid Tarokh",
        "abstract": "This work considers the problem of transferring causal knowledge between tasks for Individual Treatment Effect (ITE) estimation. To this end, we theoretically assess the feasibility of transferring ITE knowledge and present a practical framework for efficient transfer. A lower bound is introduced on the ITE error of the target task to demonstrate that ITE knowledge transfer is challenging due to the absence of counterfactual information. Nevertheless, we establish generalization upper bounds on the counterfactual loss and ITE error of the target task, demonstrating the feasibility of ITE knowledge transfer. Subsequently, we introduce a framework with a new Causal Inference Task Affinity (CITA) measure for ITE knowledge transfer. Specifically, we use CITA to find the closest source task to the target task and utilize it for ITE knowledge transfer. Empirical studies are provided, demonstrating the efficacy of the proposed method. We observe that ITE knowledge transfer can significantly (up to 95%) reduce the amount of data required for ITE estimation.",
        "bibtex": "@InProceedings{pmlr-v216-aloui23a,\n  title = \t {Transfer learning for individual treatment effect estimation},\n  author =       {Aloui, Ahmed and Dong, Juncheng and Le, Cat P and Tarokh, Vahid},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {56--66},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/aloui23a/aloui23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/aloui23a.html},\n  abstract = \t {This work considers the problem of transferring causal knowledge between tasks for Individual Treatment Effect (ITE) estimation. To this end, we theoretically assess the feasibility of transferring ITE knowledge and present a practical framework for efficient transfer. A lower bound is introduced on the ITE error of the target task to demonstrate that ITE knowledge transfer is challenging due to the absence of counterfactual information. Nevertheless, we establish generalization upper bounds on the counterfactual loss and ITE error of the target task, demonstrating the feasibility of ITE knowledge transfer. Subsequently, we introduce a framework with a new Causal Inference Task Affinity (CITA) measure for ITE knowledge transfer. Specifically, we use CITA to find the closest source task to the target task and utilize it for ITE knowledge transfer. Empirical studies are provided, demonstrating the efficacy of the proposed method. We observe that ITE knowledge transfer can significantly (up to 95%) reduce the amount of data required for ITE estimation.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/aloui23a/aloui23a.pdf",
        "supp": "",
        "pdf_size": 1299395,
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8949437069307068370&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b3cedf72e0",
        "title": "Two Sides of Miscalibration: Identifying Over and Under-Confidence Prediction for Network Calibration",
        "site": "https://proceedings.mlr.press/v216/ao23a.html",
        "author": "Shuang Ao; Stefan Rueger; Advaith Siddharthan",
        "abstract": "Proper confidence calibration of deep neural networks is essential for reliable predictions in safety-critical tasks. Miscalibration can lead to model over-confidence and/or under-confidence; i.e., the model\u2019s confidence in its prediction can be greater or less than the model\u2019s accuracy. Recent studies have highlighted the over-confidence issue by introducing calibration techniques and demonstrated success on various tasks. However, miscalibration through under-confidence has not yet to receive much attention. In this paper, we address the necessity of paying attention to the under-confidence issue. We first introduce a novel metric, a miscalibration score, to identify the overall and class-wise calibration status, including being over or under-confident. Our proposed metric reveals the pitfalls of existing calibration techniques, where they often overly calibrate the model and worsen under-confident predictions. Then we utilize the class-wise miscalibration score as a proxy to design a calibration technique that can tackle both over and under-confidence. We report extensive experiments that show our proposed methods substantially outperforming existing calibration techniques. We also validate our proposed calibration technique on an automatic failure detection task with a risk-coverage curve, reporting that our methods improve failure detection as well as trustworthiness of the model. The code are available at \\url{https://github.com/AoShuang92/miscalibration_TS}.",
        "bibtex": "@InProceedings{pmlr-v216-ao23a,\n  title = \t {Two Sides of Miscalibration: Identifying Over and Under-Confidence Prediction for Network Calibration},\n  author =       {Ao, Shuang and Rueger, Stefan and Siddharthan, Advaith},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {77--87},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/ao23a/ao23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/ao23a.html},\n  abstract = \t {Proper confidence calibration of deep neural networks is essential for reliable predictions in safety-critical tasks. Miscalibration can lead to model over-confidence and/or under-confidence; i.e., the model\u2019s confidence in its prediction can be greater or less than the model\u2019s accuracy. Recent studies have highlighted the over-confidence issue by introducing calibration techniques and demonstrated success on various tasks. However, miscalibration through under-confidence has not yet to receive much attention. In this paper, we address the necessity of paying attention to the under-confidence issue. We first introduce a novel metric, a miscalibration score, to identify the overall and class-wise calibration status, including being over or under-confident. Our proposed metric reveals the pitfalls of existing calibration techniques, where they often overly calibrate the model and worsen under-confident predictions. Then we utilize the class-wise miscalibration score as a proxy to design a calibration technique that can tackle both over and under-confidence. We report extensive experiments that show our proposed methods substantially outperforming existing calibration techniques. We also validate our proposed calibration technique on an automatic failure detection task with a risk-coverage curve, reporting that our methods improve failure detection as well as trustworthiness of the model. The code are available at \\url{https://github.com/AoShuang92/miscalibration_TS}.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/ao23a/ao23a.pdf",
        "supp": "",
        "pdf_size": 368808,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5463287412023323946&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "a074d455f2",
        "title": "Two-phase Attacks in Security Games",
        "site": "https://proceedings.mlr.press/v216/nagorko23a.html",
        "author": "Andrzej Nagorko; Pawel Ciosmak; Tomasz Michalak",
        "abstract": "A standard model of a security game assumes a one-off assault during which the attacker cannot update their strategy even if new actionable insights are gained in the process. In this paper, we propose a version of a security game that takes into account a possibility of a two-phase attack. Specifically, in the first phase, the attacker makes a preliminary move to gain extra information about this particular instance of the game. Based on this information, the attacker chooses an optimal concluding move. We derive a compact-form mixed-integer linear program that computes an optimal strategy of the defender. Our simulation shows that this strategy mitigates serious losses incurred to the defender by a two-phase attack while still protecting well against less sophisticated attackers.",
        "bibtex": "@InProceedings{pmlr-v216-nagorko23a,\n  title = \t {Two-phase Attacks in Security Games},\n  author =       {Nagorko, Andrzej and Ciosmak, Pawel and Michalak, Tomasz},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1489--1498},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/nagorko23a/nagorko23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/nagorko23a.html},\n  abstract = \t {A standard model of a security game assumes a one-off assault during which the attacker cannot update their strategy even if new actionable insights are gained in the process. In this paper, we propose a version of a security game that takes into account a possibility of a two-phase attack. Specifically, in the first phase, the attacker makes a preliminary move to gain extra information about this particular instance of the game. Based on this information, the attacker chooses an optimal concluding move. We derive a compact-form mixed-integer linear program that computes an optimal strategy of the defender. Our simulation shows that this strategy mitigates serious losses incurred to the defender by a two-phase attack while still protecting well against less sophisticated attackers.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/nagorko23a/nagorko23a.pdf",
        "supp": "",
        "pdf_size": 243268,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5095306878266079235&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "ef93c521fb",
        "title": "Two-stage Kernel Bayesian Optimization in High Dimensions",
        "site": "https://proceedings.mlr.press/v216/tan23a.html",
        "author": "Jian Tan; Niv Nayman",
        "abstract": "Bayesian optimization is a popular method for optimizing expensive black-box functions. Yet it oftentimes struggles in high dimensions, where the computation could be prohibitively heavy. While a complex kernel with many length scales is prone to overfitting and expensive to train, a simple coarse kernel with too few length scales cannot effectively capture the variations of the high dimensional function in different directions. To alleviate this problem, we introduce CobBO: a Bayesian optimization algorithm with two-stage kernels and a coordinate backoff stopping rule. It adaptively selects a promising low dimensional subspace and projects past measurements into it using a computational efficient coarse kernel. Within the subspace, the computational cost of conducting Bayesian optimization with a more flexible and accurate kernel becomes affordable and thus a sequence of consecutive observations in the same subspace are collected until a stopping rule is met. Extensive evaluations show that CobBO finds solutions comparable to or better than other state-of-the-art methods for dimensions ranging from tens to hundreds, while reducing both the trial complexity and computational costs.",
        "bibtex": "@InProceedings{pmlr-v216-tan23a,\n  title = \t {Two-stage Kernel {B}ayesian Optimization in High Dimensions},\n  author =       {Tan, Jian and Nayman, Niv},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2099--2110},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/tan23a/tan23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/tan23a.html},\n  abstract = \t {Bayesian optimization is a popular method for optimizing expensive black-box functions. Yet it oftentimes struggles in high dimensions, where the computation could be prohibitively heavy. While a complex kernel with many length scales is prone to overfitting and expensive to train, a simple coarse kernel with too few length scales cannot effectively capture the variations of the high dimensional function in different directions. To alleviate this problem, we introduce CobBO: a Bayesian optimization algorithm with two-stage kernels and a coordinate backoff stopping rule. It adaptively selects a promising low dimensional subspace and projects past measurements into it using a computational efficient coarse kernel. Within the subspace, the computational cost of conducting Bayesian optimization with a more flexible and accurate kernel becomes affordable and thus a sequence of consecutive observations in the same subspace are collected until a stopping rule is met. Extensive evaluations show that CobBO finds solutions comparable to or better than other state-of-the-art methods for dimensions ranging from tens to hundreds, while reducing both the trial complexity and computational costs.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/tan23a/tan23a.pdf",
        "supp": "",
        "pdf_size": 4342302,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18086179208586047410&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "aff": "Alibaba Group, Sunnyvale, California, USA; Technion - Israel Institute of Technology, Haifa, Israel",
        "aff_domain": "; ",
        "email": "; ",
        "github": "https://github.com/Alibaba-MIIL/CobBO",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Alibaba Group;Technion - Israel Institute of Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.alibaba.com;https://www.technion.ac.il",
        "aff_unique_abbr": "Alibaba;Technion",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Sunnyvale;Haifa",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "8f7c86b27b",
        "title": "Two-stage holistic and contrastive explanation of image classification",
        "site": "https://proceedings.mlr.press/v216/xie23a.html",
        "author": "Weiyan Xie; Xiao-Hui Li; Zhi Lin; Leonard K. M. Poon; Caleb Chen Cao; Nevin L. Zhang",
        "abstract": "The need to explain the output of a deep neural network classifier is now widely recognized. While previous methods typically explain a single class in the output, we advocate explaining the whole output, which is a probability distribution over multiple classes. A whole-output explanation can help a human user gain an overall understanding of model behaviour instead of only one aspect of it. It can also provide a natural framework where one can examine the evidence used to discriminate between\tcompeting classes, and thereby obtain contrastive explanations. In this paper, we propose a contrastive whole-output explanation (CWOX) method for image classification, and evaluate it using quantitative metrics and through human subject studies. The source code of CWOX is available at https://github.com/vaynexie/CWOX.",
        "bibtex": "@InProceedings{pmlr-v216-xie23a,\n  title = \t {Two-stage holistic and contrastive explanation of image classification},\n  author =       {Xie, Weiyan and Li, Xiao-Hui and Lin, Zhi and Poon, Leonard K. M. and Cao, Caleb Chen and Zhang, Nevin L.},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2335--2345},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/xie23a/xie23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/xie23a.html},\n  abstract = \t {The need to explain the output of a deep neural network classifier is now widely recognized. While previous methods typically explain a single class in the output, we advocate explaining the whole output, which is a probability distribution over multiple classes. A whole-output explanation can help a human user gain an overall understanding of model behaviour instead of only one aspect of it. It can also provide a natural framework where one can examine the evidence used to discriminate between\tcompeting classes, and thereby obtain contrastive explanations. In this paper, we propose a contrastive whole-output explanation (CWOX) method for image classification, and evaluate it using quantitative metrics and through human subject studies. The source code of CWOX is available at https://github.com/vaynexie/CWOX.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/xie23a/xie23a.pdf",
        "supp": "",
        "pdf_size": 5553724,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6430810686221531186&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "408aed2435",
        "title": "USIM-DAL: Uncertainty-aware Statistical Image Modeling-based Dense Active Learning for Super-resolution",
        "site": "https://proceedings.mlr.press/v216/rangnekar23a.html",
        "author": "Vikrant Rangnekar; Uddeshya Upadhyay; Zeynep Akata; Biplab Banerjee",
        "abstract": "Dense regression is a widely used approach in computer vision for tasks such as image super-resolution, enhancement, depth estimation, etc. However, the high cost of annotation and labeling makes it challenging to achieve accurate results. We propose incorporating active learning into dense regression models to address this problem. Active learning allows models to select the most informative samples for labeling, reducing the overall annotation cost while improving performance. Despite its potential, active learning has not been widely explored in high-dimensional computer vision regression tasks like super-resolution. We address this research gap and propose a new framework called USIM-DAL that leverages the statistical properties of colour images to learn informative priors using probabilistic deep neural networks that model the heteroscedastic predictive distribution allowing uncertainty quantification. Moreover, the aleatoric uncertainty from the network serves as a proxy for error that is used for active learning. Our experiments on a wide variety of datasets spanning applications in natural images (visual genome, BSD100), medical imaging (histopathology slides), and remote sensing (satellite images) demonstrate the efficacy of the newly proposed USIM-DAL and superiority over several dense regression active learning methods.",
        "bibtex": "@InProceedings{pmlr-v216-rangnekar23a,\n  title = \t {{USIM-DAL}: Uncertainty-aware Statistical Image Modeling-based Dense Active Learning for Super-resolution},\n  author =       {Rangnekar, Vikrant and Upadhyay, Uddeshya and Akata, Zeynep and Banerjee, Biplab},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1707--1717},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/rangnekar23a/rangnekar23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/rangnekar23a.html},\n  abstract = \t {Dense regression is a widely used approach in computer vision for tasks such as image super-resolution, enhancement, depth estimation, etc. However, the high cost of annotation and labeling makes it challenging to achieve accurate results. We propose incorporating active learning into dense regression models to address this problem. Active learning allows models to select the most informative samples for labeling, reducing the overall annotation cost while improving performance. Despite its potential, active learning has not been widely explored in high-dimensional computer vision regression tasks like super-resolution. We address this research gap and propose a new framework called USIM-DAL that leverages the statistical properties of colour images to learn informative priors using probabilistic deep neural networks that model the heteroscedastic predictive distribution allowing uncertainty quantification. Moreover, the aleatoric uncertainty from the network serves as a proxy for error that is used for active learning. Our experiments on a wide variety of datasets spanning applications in natural images (visual genome, BSD100), medical imaging (histopathology slides), and remote sensing (satellite images) demonstrate the efficacy of the newly proposed USIM-DAL and superiority over several dense regression active learning methods.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/rangnekar23a/rangnekar23a.pdf",
        "supp": "",
        "pdf_size": 17580354,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15683934712051868174&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "c713dc037e",
        "title": "Uniform-PAC Guarantees for Model-Based RL with Bounded Eluder Dimension",
        "site": "https://proceedings.mlr.press/v216/wu23b.html",
        "author": "Yue Wu; Jiafan He; Quanquan Gu",
        "abstract": "Recently, there has been remarkable progress in reinforcement learning (RL) with general function approximation. However, all these works only provide regret or sample complexity guarantees. It is still an open question if one can achieve stronger performance guarantees, i.e., the uniform probably approximate correctness (Uniform-PAC) guarantee that can imply both a sub-linear regret bound and a polynomial sample complexity for any target learning accuracy.  We study this problem by proposing algorithms for both nonlinear bandits and model-based episodic RL using the general function class with a bounded eluder dimension. The key idea of the proposed algorithms is to assign each action to different levels according to its width with respect to the confidence set. The achieved Uniform-PAC sample complexity is tight in the sense that it matches the state-of-the-art regret bounds or sample complexity guarantees when reduced to the linear case. To the best of our knowledge, this is the first work for Uniform-PAC guarantees on bandit and RL that goes beyond linear cases.",
        "bibtex": "@InProceedings{pmlr-v216-wu23b,\n  title = \t {Uniform-{PAC} Guarantees for Model-Based {RL} with Bounded Eluder Dimension},\n  author =       {Wu, Yue and He, Jiafan and Gu, Quanquan},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2304--2313},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/wu23b/wu23b.pdf},\n  url = \t {https://proceedings.mlr.press/v216/wu23b.html},\n  abstract = \t {Recently, there has been remarkable progress in reinforcement learning (RL) with general function approximation. However, all these works only provide regret or sample complexity guarantees. It is still an open question if one can achieve stronger performance guarantees, i.e., the uniform probably approximate correctness (Uniform-PAC) guarantee that can imply both a sub-linear regret bound and a polynomial sample complexity for any target learning accuracy.  We study this problem by proposing algorithms for both nonlinear bandits and model-based episodic RL using the general function class with a bounded eluder dimension. The key idea of the proposed algorithms is to assign each action to different levels according to its width with respect to the confidence set. The achieved Uniform-PAC sample complexity is tight in the sense that it matches the state-of-the-art regret bounds or sample complexity guarantees when reduced to the linear case. To the best of our knowledge, this is the first work for Uniform-PAC guarantees on bandit and RL that goes beyond linear cases.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/wu23b/wu23b.pdf",
        "supp": "",
        "pdf_size": 274954,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12280081191206915126&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Computer Science Department, University of California, Los Angeles, California, USA; Computer Science Department, University of California, Los Angeles, California, USA; Computer Science Department, University of California, Los Angeles, California, USA",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "a2a033367f",
        "title": "Universal Graph Contrastive Learning with a Novel Laplacian Perturbation",
        "site": "https://proceedings.mlr.press/v216/ko23a.html",
        "author": "Taewook Ko; Yoonhyuk Choi; Chong-Kwon Kim",
        "abstract": "Graph Contrastive Learning (GCL) is an effective method for discovering meaningful patterns in graph data. By evaluating diverse augmentations of the graph, GCL learns discriminative representations and provides a flexible and scalable mechanism for various graph mining tasks. This paper proposes a novel contrastive learning framework by introducing Laplacian perturbation. The proposed framework offers a distinct advantage by employing an indirect perturbation method, which provides a more stable approach while maintaining the perturbation effects. Moreover, it exhibits a wide range of applicability by not being restricted to specific graph types. We demonstrate that a spectral graph convolution based on the Laplacian successfully extracts representations from diverse graph types. Our extensive experiments on a variety of real-world datasets, covering multiple graph types, show that the proposed model outperforms state-of-the-art baselines in both node classification and link sign prediction tasks.",
        "bibtex": "@InProceedings{pmlr-v216-ko23a,\n  title = \t {Universal Graph Contrastive Learning with a Novel {L}aplacian Perturbation},\n  author =       {Ko, Taewook and Choi, Yoonhyuk and Kim, Chong-Kwon},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1098--1108},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/ko23a/ko23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/ko23a.html},\n  abstract = \t {Graph Contrastive Learning (GCL) is an effective method for discovering meaningful patterns in graph data. By evaluating diverse augmentations of the graph, GCL learns discriminative representations and provides a flexible and scalable mechanism for various graph mining tasks. This paper proposes a novel contrastive learning framework by introducing Laplacian perturbation. The proposed framework offers a distinct advantage by employing an indirect perturbation method, which provides a more stable approach while maintaining the perturbation effects. Moreover, it exhibits a wide range of applicability by not being restricted to specific graph types. We demonstrate that a spectral graph convolution based on the Laplacian successfully extracts representations from diverse graph types. Our extensive experiments on a variety of real-world datasets, covering multiple graph types, show that the proposed model outperforms state-of-the-art baselines in both node classification and link sign prediction tasks.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/ko23a/ko23a.pdf",
        "supp": "",
        "pdf_size": 888934,
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2386205466607814400&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": "Department of Computer Science and Engineering, Seoul National University; Department of Computer Science and Engineering, Seoul National University; Research Institute of Energy AI, Korea Institute of Energy Technology",
        "aff_domain": "; ; ",
        "email": "; ; ",
        "github": "https://github.com/twko05/UGCL.git",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Seoul National University;Korea Institute of Energy Technology",
        "aff_unique_dep": "Department of Computer Science and Engineering;Research Institute of Energy AI",
        "aff_unique_url": "https://www.snu.ac.kr;https://www.kiet.re.kr",
        "aff_unique_abbr": "SNU;KIENT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "4fd5de51cb",
        "title": "Vacant holes for unsupervised detection of the outliers in compact latent representation",
        "site": "https://proceedings.mlr.press/v216/glazunov23a.html",
        "author": "Misha Glazunov; Apostolis Zarras",
        "abstract": "Detection of the outliers is pivotal for any machine learning model deployed and operated in real-world. It is essential for the Deep Neural Networks that were shown to be overconfident with such inputs. Moreover, even deep generative models that allow estimation of the probability density of the input fail in achieving this task. In this work, we concentrate on the specific type of these models: Variational Autoencoders (VAEs). First, we unveil a significant theoretical flaw in the assumption of the classical VAE model. Second, we enforce an accommodating topological property to the image of the deep neural mapping to the latent space: compactness to alleviate the flaw and obtain the means to provably bound the image within the determined limits by squeezing both inliers and outliers together. We enforce compactness using two approaches: $(i)$\u00a0Alexandroff extension and  $(ii)$\u00a0fixed Lipschitz continuity constant on the mapping of the encoder of the VAEs. Finally and most importantly, we discover that the anomalous inputs predominantly tend to land on the vacant latent holes within the compact space, enabling their successful identification. For that reason, we introduce a specifically devised score for hole detection and evaluate the solution against several baseline benchmarks achieving promising results.",
        "bibtex": "@InProceedings{pmlr-v216-glazunov23a,\n  title = \t {Vacant holes for unsupervised detection of the outliers in compact latent representation},\n  author =       {Glazunov, Misha and Zarras, Apostolis},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {701--711},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/glazunov23a/glazunov23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/glazunov23a.html},\n  abstract = \t {Detection of the outliers is pivotal for any machine learning model deployed and operated in real-world. It is essential for the Deep Neural Networks that were shown to be overconfident with such inputs. Moreover, even deep generative models that allow estimation of the probability density of the input fail in achieving this task. In this work, we concentrate on the specific type of these models: Variational Autoencoders (VAEs). First, we unveil a significant theoretical flaw in the assumption of the classical VAE model. Second, we enforce an accommodating topological property to the image of the deep neural mapping to the latent space: compactness to alleviate the flaw and obtain the means to provably bound the image within the determined limits by squeezing both inliers and outliers together. We enforce compactness using two approaches: $(i)$\u00a0Alexandroff extension and  $(ii)$\u00a0fixed Lipschitz continuity constant on the mapping of the encoder of the VAEs. Finally and most importantly, we discover that the anomalous inputs predominantly tend to land on the vacant latent holes within the compact space, enabling their successful identification. For that reason, we introduce a specifically devised score for hole detection and evaluate the solution against several baseline benchmarks achieving promising results.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/glazunov23a/glazunov23a.pdf",
        "supp": "",
        "pdf_size": 4668088,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2795940560865075020&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "aff": "Delft University of Technology, the Netherlands; University of Piraeus, Greece",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Delft University of Technology;University of Piraeus",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tudelft.nl;https://www.unipi.gr",
        "aff_unique_abbr": "TUDelft;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Netherlands;Greece"
    },
    {
        "id": "bac573fb8f",
        "title": "Validation of composite systems by discrepancy propagation",
        "site": "https://proceedings.mlr.press/v216/reeb23a.html",
        "author": "David Reeb; Kanil Patel; Karim Said Barsim; Martin Schiegg; Sebastian Gerwinn",
        "abstract": "Assessing the validity of a real-world system with respect to given quality criteria is a common yet costly task in industrial applications due to the vast number of required real-world tests. Validating such systems by means of simulation offers a promising and less expensive alternative, but requires an assessment of the simulation accuracy and therefore end-to-end measurements. Additionally, covariate shifts between simulations and actual usage can cause difficulties for estimating the reliability of such systems. In this work, we present a validation method that propagates bounds on distributional discrepancy measures through a composite system, thereby allowing us to derive an upper bound on the failure probability of the real system from potentially inaccurate simulations. Each propagation step entails an optimization problem, where \u2013 for measures such as maximum mean discrepancy (MMD) \u2013 we develop tight convex relaxations based on semidefinite programs. We demonstrate that our propagation method yields valid and useful bounds for composite systems exhibiting a variety of realistic effects. In particular, we show that the proposed method can successfully account for data shifts within the experimental design as well as model inaccuracies within the simulation.",
        "bibtex": "@InProceedings{pmlr-v216-reeb23a,\n  title = \t {Validation of composite systems by discrepancy propagation},\n  author =       {Reeb, David and Patel, Kanil and Barsim, Karim Said and Schiegg, Martin and Gerwinn, Sebastian},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1730--1740},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/reeb23a/reeb23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/reeb23a.html},\n  abstract = \t {Assessing the validity of a real-world system with respect to given quality criteria is a common yet costly task in industrial applications due to the vast number of required real-world tests. Validating such systems by means of simulation offers a promising and less expensive alternative, but requires an assessment of the simulation accuracy and therefore end-to-end measurements. Additionally, covariate shifts between simulations and actual usage can cause difficulties for estimating the reliability of such systems. In this work, we present a validation method that propagates bounds on distributional discrepancy measures through a composite system, thereby allowing us to derive an upper bound on the failure probability of the real system from potentially inaccurate simulations. Each propagation step entails an optimization problem, where \u2013 for measures such as maximum mean discrepancy (MMD) \u2013 we develop tight convex relaxations based on semidefinite programs. We demonstrate that our propagation method yields valid and useful bounds for composite systems exhibiting a variety of realistic effects. In particular, we show that the proposed method can successfully account for data shifts within the experimental design as well as model inaccuracies within the simulation.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/reeb23a/reeb23a.pdf",
        "supp": "",
        "pdf_size": 371850,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15833924764100272328&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Bosch Center for Artificial Intelligence, Robert Bosch GmbH, 71272 Renningen, Germany; Bosch Center for Artificial Intelligence, Robert Bosch GmbH, 71272 Renningen, Germany; Bosch Center for Artificial Intelligence, Robert Bosch GmbH, 71272 Renningen, Germany; Bosch Center for Artificial Intelligence, Robert Bosch GmbH, 71272 Renningen, Germany; Bosch Center for Artificial Intelligence, Robert Bosch GmbH, 71272 Renningen, Germany",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Robert Bosch GmbH",
        "aff_unique_dep": "Bosch Center for Artificial Intelligence",
        "aff_unique_url": "https://www.bosch.com",
        "aff_unique_abbr": "Bosch",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Renningen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "e9829412a7",
        "title": "Variable importance matching for causal inference",
        "site": "https://proceedings.mlr.press/v216/lanners23a.html",
        "author": "Quinn Lanners; Harsh Parikh; Alexander Volfovsky; Cynthia Rudin; David Page",
        "abstract": "Our goal is to produce methods for observational causal inference that are auditable, easy to troubleshoot, yield accurate treatment effect estimates, and scalable to high-dimensional data. We describe a general framework called Model-to-Match that achieves these goals by (i) learning a distance metric via outcome modeling, (ii) creating matched groups using the distance metric, and (iii) using the matched groups to estimate treatment effects. Model-to-Match uses variable importance measurements to construct a distance metric, making it a flexible framework that can be adapted to various applications. Concentrating on the scalability of the problem in the number of potential confounders, we operationalize the Model-to-Match framework with LASSO. We derive performance guarantees for settings where LASSO outcome modeling consistently identifies all confounders (importantly without requiring the linear model to be correctly specified). We also provide experimental results demonstrating the auditability of matches, as well as extensions to more general nonparametric outcome modeling.",
        "bibtex": "@InProceedings{pmlr-v216-lanners23a,\n  title = \t {Variable importance matching for causal inference},\n  author =       {Lanners, Quinn and Parikh, Harsh and Volfovsky, Alexander and Rudin, Cynthia and Page, David},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1174--1184},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/lanners23a/lanners23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/lanners23a.html},\n  abstract = \t {Our goal is to produce methods for observational causal inference that are auditable, easy to troubleshoot, yield accurate treatment effect estimates, and scalable to high-dimensional data. We describe a general framework called Model-to-Match that achieves these goals by (i) learning a distance metric via outcome modeling, (ii) creating matched groups using the distance metric, and (iii) using the matched groups to estimate treatment effects. Model-to-Match uses variable importance measurements to construct a distance metric, making it a flexible framework that can be adapted to various applications. Concentrating on the scalability of the problem in the number of potential confounders, we operationalize the Model-to-Match framework with LASSO. We derive performance guarantees for settings where LASSO outcome modeling consistently identifies all confounders (importantly without requiring the linear model to be correctly specified). We also provide experimental results demonstrating the auditability of matches, as well as extensions to more general nonparametric outcome modeling.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/lanners23a/lanners23a.pdf",
        "supp": "",
        "pdf_size": 1530014,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7152378607617625764&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Dept. of Biostatistics, Duke University, Durham, NC, USA; Dept. of Computer Science, Duke University, Durham, NC, USA; Dept. of Statistical Science, Duke University, Durham, NC, USA; Dept. of Computer Science, Duke University, Durham, NC, USA; Dept. of Biostatistics, Duke University, Durham, NC, USA",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "Department of Biostatistics",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Durham",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "ad1d7bdadd",
        "title": "ViBid: Linear Vision Transformer with Bidirectional Normalization",
        "site": "https://proceedings.mlr.press/v216/song23a.html",
        "author": "Jeonggeun Song; Heung-Chang Lee",
        "abstract": "The vision transformer has achieved state-of-the-art performance in various vision tasks; however, the memory consumption is larger than those of previous convolutional neural network based models because of $O(N^2)$ time and memory complexity of the general self-attention models. Many approaches aim to change the complexity to $O(N)$ to solve this problem; however, they stack deep convolutional layers to retain locality or complicate the architecture as seen in window attention, to compensate for the performance degradation. To solve these problems, we propose ViBid algorithm, which resolves the complexity problem of $O(N^2)$ by replacing Softmax with bidirectional normalization (BiNorm). In addition, it has a much simpler architecture than the existing transformer model with $O(N)$ complexity. Owing to our simple architecture, we were able to use larger resolutions for training, and we obtained a lighter and superior GPU throughput model with competitive performance. ViBid can be used with any transformer method that uses queries, keys, and values (QKV) because of BiNorm, and it is quite universal due to its simple architectural structure.",
        "bibtex": "@InProceedings{pmlr-v216-song23a,\n  title = \t {{ViBid}: Linear Vision Transformer with Bidirectional Normalization},\n  author =       {Song, Jeonggeun and Lee, Heung-Chang},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1996--2005},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/song23a/song23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/song23a.html},\n  abstract = \t {The vision transformer has achieved state-of-the-art performance in various vision tasks; however, the memory consumption is larger than those of previous convolutional neural network based models because of $O(N^2)$ time and memory complexity of the general self-attention models. Many approaches aim to change the complexity to $O(N)$ to solve this problem; however, they stack deep convolutional layers to retain locality or complicate the architecture as seen in window attention, to compensate for the performance degradation. To solve these problems, we propose ViBid algorithm, which resolves the complexity problem of $O(N^2)$ by replacing Softmax with bidirectional normalization (BiNorm). In addition, it has a much simpler architecture than the existing transformer model with $O(N)$ complexity. Owing to our simple architecture, we were able to use larger resolutions for training, and we obtained a lighter and superior GPU throughput model with competitive performance. ViBid can be used with any transformer method that uses queries, keys, and values (QKV) because of BiNorm, and it is quite universal due to its simple architectural structure.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/song23a/song23a.pdf",
        "supp": "",
        "pdf_size": 1788446,
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=198366590205609526&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "AI Lab & Service, Kakao Enterprise, Seongnam-si, South Korea; AI Lab & Service, Kakao Enterprise, Seongnam-si, South Korea",
        "aff_domain": "; ",
        "email": "; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Kakao Enterprise",
        "aff_unique_dep": "AI Lab & Service",
        "aff_unique_url": "https://www.kakaoenterprise.com",
        "aff_unique_abbr": "Kakao Enterprise",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seongnam-si",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9ef67442e4",
        "title": "When are post-hoc conceptual explanations identifiable?",
        "site": "https://proceedings.mlr.press/v216/leemann23a.html",
        "author": "Tobias Leemann; Michael Kirchhof; Yao Rong; Enkelejda Kasneci; Gjergji Kasneci",
        "abstract": "Interest in understanding and factorizing learned embedding spaces through conceptual explanations is steadily growing. When no human concept labels are available, concept discovery methods search trained embedding spaces for interpretable concepts like object shape or color that can provide post-hoc explanations for decisions. Unlike previous work, we argue that concept discovery should be identifiable, meaning that a number of known concepts can be provably recovered to guarantee reliability of the explanations. As a starting point, we explicitly make the connection between concept discovery and classical methods like Principal Component Analysis and Independent Component Analysis by showing that they can recover independent concepts under non-Gaussian distributions. For dependent concepts, we propose two novel approaches that exploit functional compositionality properties of image-generating processes. Our provably identifiable concept discovery methods substantially outperform competitors on a battery of experiments including hundreds of trained models and dependent concepts, where they exhibit up to 29 % better alignment with the ground truth. Our results highlight the strict conditions under which reliable concept discovery without human labels can be guaranteed and provide a formal foundation for the domain. Our code is available online.",
        "bibtex": "@InProceedings{pmlr-v216-leemann23a,\n  title = \t {When are post-hoc conceptual explanations identifiable?},\n  author =       {Leemann, Tobias and Kirchhof, Michael and Rong, Yao and Kasneci, Enkelejda and Kasneci, Gjergji},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {1207--1218},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/leemann23a/leemann23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/leemann23a.html},\n  abstract = \t {Interest in understanding and factorizing learned embedding spaces through conceptual explanations is steadily growing. When no human concept labels are available, concept discovery methods search trained embedding spaces for interpretable concepts like object shape or color that can provide post-hoc explanations for decisions. Unlike previous work, we argue that concept discovery should be identifiable, meaning that a number of known concepts can be provably recovered to guarantee reliability of the explanations. As a starting point, we explicitly make the connection between concept discovery and classical methods like Principal Component Analysis and Independent Component Analysis by showing that they can recover independent concepts under non-Gaussian distributions. For dependent concepts, we propose two novel approaches that exploit functional compositionality properties of image-generating processes. Our provably identifiable concept discovery methods substantially outperform competitors on a battery of experiments including hundreds of trained models and dependent concepts, where they exhibit up to 29 % better alignment with the ground truth. Our results highlight the strict conditions under which reliable concept discovery without human labels can be guaranteed and provide a formal foundation for the domain. Our code is available online.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/leemann23a/leemann23a.pdf",
        "supp": "",
        "pdf_size": 1765765,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17366916016098937291&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "University of T\u00fcbingen, T\u00fcbingen, Germany+Technical University of Munich, Munich, Germany; University of T\u00fcbingen, T\u00fcbingen, Germany; University of T\u00fcbingen, T\u00fcbingen, Germany+Technical University of Munich, Munich, Germany; Technical University of Munich, Munich, Germany; Technical University of Munich, Munich, Germany",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;0+1;1;1",
        "aff_unique_norm": "University of T\u00fcbingen;Technical University of Munich",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uni-tuebingen.de/;https://www.tum.de",
        "aff_unique_abbr": "Uni T\u00fcbingen;TUM",
        "aff_campus_unique_index": "0+1;0;0+1;1;1",
        "aff_campus_unique": "T\u00fcbingen;Munich",
        "aff_country_unique_index": "0+0;0;0+0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "3819ad4e7b",
        "title": "Why Out-of-Distribution detection experiments are not reliable - subtle experimental details muddle the OOD detector rankings",
        "site": "https://proceedings.mlr.press/v216/szyc23a.html",
        "author": "Kamil Szyc; Tomasz Walkowiak; Henryk Maciejewski",
        "abstract": "Reliable detection of out-of-distribution (OOD) instances is becoming a critical requirement for machine learning systems deployed in safety-critical applications. Recently, many OOD detectors have been developed in the literature, and their performance has been evaluated using empirical studies based on well-established benchmark datasets. However, these studies do not provide a conclusive recommendation because the performance of OOD detection depends on the benchmark datasets. In this work, we want to question the reliability of the OOD detection performance numbers obtained from many of these empirical experiments. We report several experimental conditions that are not controlled and lead to significant changes in OOD detector performance and rankings of OOD methods. These include the technicalities related to how the DNN was trained (such as seed, train/test split, etc.), which do not change the accuracy of closed-set DNN models but may significantly change the performance of OOD detection methods that rely on representation from these DNNs. We performed extensive sensitivity studies in image and text domains to quantify the instability of OOD performance measures due to unintuitive experimental factors. These factors need to be more rigorously controlled and accounted for in many current OOD experiments. Experimental studies in OOD detection should improve methodological standards regarding experiment control and replication.",
        "bibtex": "@InProceedings{pmlr-v216-szyc23a,\n  title = \t {Why Out-of-Distribution detection experiments are not reliable - subtle experimental details muddle the {OOD} detector rankings},\n  author =       {Szyc, Kamil and Walkowiak, Tomasz and Maciejewski, Henryk},\n  booktitle = \t {Proceedings of the Thirty-Ninth Conference on Uncertainty in Artificial Intelligence},\n  pages = \t {2078--2088},\n  year = \t {2023},\n  editor = \t {Evans, Robin J. and Shpitser, Ilya},\n  volume = \t {216},\n  series = \t {Proceedings of Machine Learning Research},\n  month = \t {31 Jul--04 Aug},\n  publisher =    {PMLR},\n  pdf = \t {https://proceedings.mlr.press/v216/szyc23a/szyc23a.pdf},\n  url = \t {https://proceedings.mlr.press/v216/szyc23a.html},\n  abstract = \t {Reliable detection of out-of-distribution (OOD) instances is becoming a critical requirement for machine learning systems deployed in safety-critical applications. Recently, many OOD detectors have been developed in the literature, and their performance has been evaluated using empirical studies based on well-established benchmark datasets. However, these studies do not provide a conclusive recommendation because the performance of OOD detection depends on the benchmark datasets. In this work, we want to question the reliability of the OOD detection performance numbers obtained from many of these empirical experiments. We report several experimental conditions that are not controlled and lead to significant changes in OOD detector performance and rankings of OOD methods. These include the technicalities related to how the DNN was trained (such as seed, train/test split, etc.), which do not change the accuracy of closed-set DNN models but may significantly change the performance of OOD detection methods that rely on representation from these DNNs. We performed extensive sensitivity studies in image and text domains to quantify the instability of OOD performance measures due to unintuitive experimental factors. These factors need to be more rigorously controlled and accounted for in many current OOD experiments. Experimental studies in OOD detection should improve methodological standards regarding experiment control and replication.}\n}",
        "pdf": "https://proceedings.mlr.press/v216/szyc23a/szyc23a.pdf",
        "supp": "",
        "pdf_size": 189573,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6974821899813792041&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    }
]