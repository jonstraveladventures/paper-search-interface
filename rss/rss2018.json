[
    {
        "id": "809e911781",
        "title": "A Novel Whisker Sensor Used for 3D Contact Point Determination and Contour Extraction",
        "site": "https://www.roboticsproceedings.org/rss14/p59.html",
        "author": "Hannah Emnett; Matthew Graff; Mitra Hartmann",
        "abstract": "We developed a novel whisker-follicle sensor that measures three mechanical signals at the whisker base.  The first two signals are closely related to the two bending moments, and the third is an approximation to the axial force.  Previous simulation studies have shown that these three signals are sufficient to determine the three-dimensional (3D) location at which the whisker makes contact with an object. Here we demonstrate hardware implementation of 3D contact point determination and then use continuous sweeps of the whisker to show proof-of principle 3D contour extraction. We begin by using simulations to confirm the uniqueness of the mapping between the mechanical signals at the whisker base and the 3D contact point location for the specific dimensions of the hardware whisker. Multi-output random forest regression is then used to predict the contact point locations of objects based on observed mechanical signals. When calibrated to the simulated data, signals from the hardware whisker can correctly predict contact point locations to within 1.5 cm about 74% of the time. However, if normalized output voltages from the hardware whiskers are used to train the algorithm (without calibrating to simulation), predictions improve to within 1.5 cm for about 96% of contact points and to within 0.6 cm for about 78% of contact points. This improvement suggests that as long as three appropriate predictor signals are chosen, calibrating to simulations may not be required.  The sensor was next used to perform contour extraction on a cylinder and a cone. We show that basic contour extraction can be obtained with just two sweeps of the sensor. With further sweeps, it is expected that full 3D shape reconstruction could be achieved.",
        "bibtex": "@INPROCEEDINGS{Emnett-RSS-18, \r\n    AUTHOR    = {Hannah Emnett AND Matthew Graff AND Mitra Hartmann}, \r\n    TITLE     = {A Novel Whisker Sensor Used for 3D Contact Point Determination and Contour Extraction}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.059} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p59.pdf",
        "supp": "",
        "pdf_size": 631582,
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10079274797851889281&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Department of Mechanical Engineering; Department of Mechanical Engineering; Department of Mechanical Engineering + Department of Biomedical Engineering",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "Mechanical Engineering;Department of Biomedical Engineering",
        "aff_unique_dep": "Department of Mechanical Engineering;Biomedical Engineering",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "0e6251d7d0",
        "title": "A Real-Time Game Theoretic Planner for Autonomous Two-Player Drone Racing",
        "site": "https://www.roboticsproceedings.org/rss14/p40.html",
        "author": "Riccardo Spica; Davide Falanga; Eric Cristofalo; Eduardo Montijano; Davide Scaramuzza; Mac Schwager",
        "abstract": "To be successful in multi-player drone racing, a player must not only follow the race track in an optimal way, but also compete with other drones through strategic blocking, faking, and opportunistic passing while avoiding collisions. Since unveiling one's own strategy to the adversaries is not desirable, this requires each player to independently predict the other players' future actions. Nash equilibria are a powerful tool to model this and similar multi-agent coordination problems in which the absence of communication impedes full coordination between the agents. In this paper, we propose a novel receding horizon planning algorithm that, exploiting sensitivity analysis within an iterated best response computational scheme, can approximate Nash equilibria in real time. We demonstrate that our solution effectively competes against alternative strategies in a large number of drone racing simulations.",
        "bibtex": "@INPROCEEDINGS{Spica-RSS-18, \r\n    AUTHOR    = {Riccardo Spica AND Davide Falanga AND Eric Cristofalo AND Eduardo Montijano AND Davide Scaramuzza AND Mac Schwager}, \r\n    TITLE     = {A Real-Time Game Theoretic Planner for Autonomous Two-Player Drone Racing}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.040} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p40.pdf",
        "supp": "",
        "pdf_size": 2279996,
        "gs_citation": 195,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=920043389044597058&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 19,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "807e001a11",
        "title": "A Real-time Augmented Reality Surgical System for Overlaying Stiffness Information",
        "site": "https://www.roboticsproceedings.org/rss14/p26.html",
        "author": "Nicolas Zevallos; Arun Srivatsan Rangaprasad; Hadi Salman; Lu Li; Jianing Qian; Saumya Saxena; Mengyun Xu; Kartik Patath; Howie Choset",
        "abstract": "We describe a surgical system that autonomously searches for tumors and  dynamically displays a computer graphic model of them super-imposed on the organ (or in our case, phantom). Once localized, the phantom is tracked in real time and augmented with overlaid stiffness information in 3D. We believe that such a system has the potential to quickly reveal the location and shape of tumors and the visual overlay will reduce the cognitive overload of the surgeon. The contribution of this paper is the integration of disparate technologies to achieve this system. In fact, to the best of our knowledge, our approach is one of the first to incorporate state-of-the-art methods in registration, force sensing and tumor localization into a unified surgical system. First, the preoperative model is registered to the intra-operative scene using a Bingham distribution-based filtering approach. An active level set estimation is then used to find the location and the shape of the tumors. We use a recently developed miniature force sensor to perform the palpation. The estimated stiffness map is then dynamically overlaid onto the registered preoperative model of the organ. We demonstrate the efficacy of our system by performing experiments on a phantom prostate model and other silicone organs with embedded stiff inclusions using the da Vinci research kit.",
        "bibtex": "@INPROCEEDINGS{Zevallos-RSS-18, \r\n    AUTHOR    = {Nicolas Zevallos AND Arun Srivatsan Rangaprasad AND Hadi Salman AND Lu Li AND Jianing Qian AND Saumya Saxena AND Mengyun Xu AND Kartik Patath AND Howie Choset}, \r\n    TITLE     = {A Real-time Augmented Reality Surgical System for Overlaying Stiffness Information}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.026} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p26.pdf",
        "supp": "",
        "pdf_size": 5579012,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12979307667409786801&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "aff_domain": "andrew.cmu.edu; ; ; ; ; ; ; ;",
        "email": "andrew.cmu.edu; ; ; ; ; ; ; ;",
        "github": "",
        "project": "",
        "author_num": 9,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "190e2c8aee",
        "title": "A Variable Stiffness Gripper with Antagonistic Magnetic Springs for Enhancing Manipulation",
        "site": "https://www.roboticsproceedings.org/rss14/p53.html",
        "author": "Amirhossein Memar; Ehsan Esfahani",
        "abstract": "Robot grasping of objects based on variable stiffness actuation not only improves the safety and robustness of the grasp but also enhances dynamic manipulation. In this paper, we present the design aspects of a variable stiffness gripper and demonstrate how the controllable compliance of the fingers can improve the performance in dynamic manipulation tasks such as hammering/hitting. The proposed gripper consists of two parallel fingers and repulsive magnets are used as the nonlinear springs between gripper actuators and fingers. The position and force-stiffness characteristics of the fingers are adjusted simultaneously, by controlling the air-gaps between magnets. Finally, the application of the gripper in a nail hammering task is studied as an example of dynamic manipulation. For this purpose, an optimal stiffness control problem is solved to maximize the impact force of the hammering task through maximizing the kinetic energy of the grasped object at the hitting instance. Despite the simplicity of the design, experimental results indicate the effectiveness of the gripper for dynamic manipulation.",
        "bibtex": "@INPROCEEDINGS{Memar-RSS-18, \r\n    AUTHOR    = {Amirhossein Memar AND Ehsan Esfahani}, \r\n    TITLE     = {A Variable Stiffness Gripper with Antagonistic Magnetic Springs for Enhancing Manipulation}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.053} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p53.pdf",
        "supp": "",
        "pdf_size": 2350781,
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6650767031343404181&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Mechanical and Aerospace Engineering, University at Buffalo; Department of Mechanical and Aerospace Engineering, University at Buffalo",
        "aff_domain": "buffalo.edu;buffalo.edu",
        "email": "buffalo.edu;buffalo.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University at Buffalo",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.buffalo.edu",
        "aff_unique_abbr": "UB",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Buffalo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "d4f414c364",
        "title": "Adaptive Bias and Attitude Observer on the Special Orthogonal Group for True-North Gyrocompass Systems: Theory and Preliminary Results",
        "site": "https://www.roboticsproceedings.org/rss14/p34.html",
        "author": "Andrew Spielvogel; Louis Whitcomb",
        "abstract": "This paper reports an adaptive sensor bias estimator and attitude observer operating directly on SO(3) for true-North gyrocompass systems that utilize six-degree of freedom inertial measurement units (IMUs) with three-axis accelerometers and three-axis gyroscopes (without magnetometers). Most present-day low-cost robotic vehicles employ attitude estimation systems that employ micro-electromechanical systems (MEMS) magnetometers, angular rate gyros, and accelerometers to estimate magnetic heading and attitude with limited heading accuracy. Present day MEMS gyros are not sensitive enough to dynamically detect Earth's rotation, and thus cannot be used to estimate true-North geodetic heading. In contrast, the reported gyrocompass system utilizes fiber optic gyroscope (FOG) IMU gyro and MEMS accelerometer measurements (without magnetometers) to dynamically estimate the instrument's time-varying attitude in real-time while the instrument is subject to a priori unknown rotations.  Stability proofs, preliminary simulations, and a fullscale vehicle trial are reported that suggest the viability of the true-North gyrocompass system to provide dynamic real-time true-North heading, pitch, and roll while utilizing a comparatively low-cost FOG IMU.",
        "bibtex": "@INPROCEEDINGS{Spielvogel-RSS-18, \r\n    AUTHOR    = {Andrew Spielvogel AND Louis Whitcomb}, \r\n    TITLE     = {Adaptive Bias and Attitude Observer on the Special Orthogonal Group for True-North Gyrocompass Systems: Theory and Preliminary Results}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.034} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p34.pdf",
        "supp": "",
        "pdf_size": 3968707,
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10317982948569701780&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Johns Hopkings University; Johns Hopkins University",
        "aff_domain": "jhu.edu;jhu.edu",
        "email": "jhu.edu;jhu.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "942525250c",
        "title": "Agile Autonomous Driving using End-to-End Deep Imitation Learning",
        "site": "https://www.roboticsproceedings.org/rss14/p56.html",
        "author": "Yunpeng Pan; Ching-An Cheng; Kamil Saigol; Keuntaek Lee; Xinyan Yan; Evangelos Theodorou; Byron Boots",
        "abstract": "We present an end-to-end imitation learning system for agile, off-road autonomous driving using only low-cost on-board sensors. By imitating a model predictive controller equipped with advanced sensors, we train a deep neural network control policy to map raw, high-dimensional observations to continuous steering and throttle commands. Compared with recent approaches to similar tasks, our method requires neither state estimation nor on-the-fly planning to navigate the vehicle. Our approach relies on, and experimentally validates, recent imitation learning theory. Empirically, we show that  policies trained with online imitation learning overcome well-known challenges related to covariate shift and generalize better than policies trained with batch imitation learning. Built on these insights, our autonomous driving system demonstrates successful high-speed off-road driving, matching the state-of-the-art performance.",
        "bibtex": "@INPROCEEDINGS{Pan-RSS-18, \r\n    AUTHOR    = {Yunpeng Pan AND Ching-An Cheng AND Kamil Saigol AND Keuntaek Lee AND Xinyan Yan AND Evangelos Theodorou AND Byron Boots}, \r\n    TITLE     = {Agile Autonomous Driving using End-to-End Deep Imitation Learning}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.056} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p56.pdf",
        "supp": "",
        "pdf_size": 8505930,
        "gs_citation": 396,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17147387469803564607&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Institute for Robotics and Intelligent Machines; Institute for Robotics and Intelligent Machines; Institute for Robotics and Intelligent Machines; School of Electrical and Computer Engineering; Institute for Robotics and Intelligent Machines; Institute for Robotics and Intelligent Machines; Institute for Robotics and Intelligent Machines + JD.com American Technologies Corporation",
        "aff_domain": "gatech.edu;gatech.edu;gatech.edu;gatech.edu;gatech.edu;gatech.edu;cc.gatech.edu",
        "email": "gatech.edu;gatech.edu;gatech.edu;gatech.edu;gatech.edu;gatech.edu;cc.gatech.edu",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0;0;0+2",
        "aff_unique_norm": "Institute for Robotics and Intelligent Machines;Institution not specified;JD.com American Technologies Corporation",
        "aff_unique_dep": "Robotics and Intelligent Machines;Electrical and Computer Engineering;",
        "aff_unique_url": ";;",
        "aff_unique_abbr": ";;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0+0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "eea6c0225d",
        "title": "Analytical Derivatives of Rigid Body Dynamics Algorithms",
        "site": "https://www.roboticsproceedings.org/rss14/p38.html",
        "author": "Justin Carpentier; Nicolas Mansard",
        "abstract": "Rigid body dynamics is a well-established framework in robotics. It can be used to expose the analytic form of kinematic and dynamic functions of the robot model. So far, two major algorithms, namely the recursive Newton-Euler algorithm (RNEA) and the articulated body algorithm (ABA), have been proposed to compute the inverse dynamics and the forward dynamics in a few microseconds. Evaluating their derivatives is an important challenge for various robotic applications (optimal control, estimation, co-design or reinforcement learning). However it remains time consuming, whether using finite differences or automatic differentiation. In this paper, we propose new algorithms to efficiently compute them thanks to closed-form formulations. Using the chain rule and adequate algebraic differentiation of spatial algebra, we firstly differentiate explicitly RNEA. Then, using properties about the derivative of function composition, we show that the same algorithm can also be used to compute the derivatives of ABA with a marginal additional cost. For this purpose, we introduce a new algorithm to compute the inverse of the joint-space inertia matrix, without explicitly computing the matrix itself. All the algorithms are implemented in our open-source C++ framework called Pinocchio. Benchmarks show computational costs varying between 3 microseconds (for a 7-dof arm) up to 17 microseconds (for a 36-dof humanoid), outperforming the alternative approaches of the state of the art.",
        "bibtex": "@INPROCEEDINGS{Carpentier-RSS-18, \r\n    AUTHOR    = {Justin Carpentier AND Nicolas Mansard}, \r\n    TITLE     = {Analytical Derivatives of Rigid Body Dynamics Algorithms}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.038} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p38.pdf",
        "supp": "",
        "pdf_size": 281814,
        "gs_citation": 198,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15967610091499521081&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Laboratoire d\u2019Analyse et d\u2019Architecture des Syst\u00e8mes; Universit\u00e9 de Toulouse",
        "aff_domain": "laas.fr; ",
        "email": "laas.fr; ",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Laboratoire d'Analyse et d'Architecture des Syst\u00e8mes;Universit\u00e9 de Toulouse",
        "aff_unique_dep": "Laboratoire d'Analyse et d'Architecture des Syst\u00e8mes;",
        "aff_unique_url": "https://www.laas.fr/;https://www.univ-toulouse.fr",
        "aff_unique_abbr": "LAAS;UT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "4be49ed060",
        "title": "Asymmetric Actor Critic for Image-Based Robot Learning",
        "site": "https://www.roboticsproceedings.org/rss14/p08.html",
        "author": "Lerrel Pinto; Marcin Andrychowicz; Peter Welinder; Wojciech Zaremba; Pieter Abbeel",
        "abstract": "Deep reinforcement learning (RL) has proven a powerful technique in many sequential decision making domains. However, robotics poses many challenges for RL, most notably training on a physical system can be expensive and dangerous, which has sparked significant interest in learning control policies using a physics simulator. While several recent works have shown promising results in transferring policies trained in simulation to the real world, they often do not fully utilize the advantage of working with a simulator. In this work, we propose the Asymmetric Actor Critic, which learns a vision-based control policy while taking advantage of access to the underlying state to significantly speed up training. Concretely, our algorithm employs an actor-critic training algorithm in which the critic is trained on full states while the actor (or policy) is trained on images. We show that using these asymmetric inputs improves performance on a range of simulated tasks. Finally, we combine this method with domain randomization and show real robot experiments for several tasks like picking, pushing, and moving a block. We achieve this simulation to real-world transfer without training on any real-world data. Videos of these experiments can be found in www.goo.gl/b57WTs.",
        "bibtex": "@INPROCEEDINGS{Pinto-RSS-18, \r\n    AUTHOR    = {Lerrel Pinto AND Marcin Andrychowicz AND Peter Welinder AND Wojciech Zaremba AND Pieter Abbeel}, \r\n    TITLE     = {Asymmetric Actor Critic for Image-Based Robot Learning}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.008} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p08.pdf",
        "supp": "",
        "pdf_size": 4660651,
        "gs_citation": 452,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1178580442251068837&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Carnegie Mellon University; OpenAI; OpenAI; OpenAI; OpenAI",
        "aff_domain": "cs.cmu.edu;openai.com;openai.com;openai.com;openai.com",
        "email": "cs.cmu.edu;openai.com;openai.com;openai.com;openai.com",
        "github": "",
        "project": "www.goo.gl/b57WTs",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Carnegie Mellon University;OpenAI",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://openai.com",
        "aff_unique_abbr": "CMU;OpenAI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "858e8fc773",
        "title": "Autonomous Adaptive Modification of Unstructured Environments",
        "site": "https://www.roboticsproceedings.org/rss14/p70.html",
        "author": "Maira Saboia da Silva; Vivek Thangavelu; Walker  Gosrich; Nils Napp",
        "abstract": "We present and validate a property-driven autonomous system that modifies its environment to achieve and maintain navigability over a highly irregular 3-dimensional terrain. In our approach we use decision procedures that tie building actions to the terrain model, giving rise to adaptive and robust building behavior. The building algorithm is driven by continuous evaluation and reaction to terrain properties, rather than relying on a structure blueprint. This capability is essential in robotic systems that operate in unstructured outdoor or remote environments, either on their own or as part of a team. We demonstrate the effectiveness of our approach by running a low-cost robot system that can build with compliant bags in a variety of irregular terrains.",
        "bibtex": "@INPROCEEDINGS{da Silva-RSS-18, \r\n    AUTHOR    = {Maira Saboia da Silva AND Vivek Thangavelu AND Walker  Gosrich AND Nils Napp}, \r\n    TITLE     = {Autonomous Adaptive Modification of Unstructured Environments}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.070} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p70.pdf",
        "supp": "",
        "pdf_size": 6118457,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17573937442531501570&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science and Engineering; Department of Computer Science and Engineering; Department of Computer Science and Engineering + Department of Mechanical and Aerospace Engineering; Department of Computer Science and Engineering",
        "aff_domain": "buffalo.edu;buffalo.edu;buffalo.edu;buffalo.edu",
        "email": "buffalo.edu;buffalo.edu;buffalo.edu;buffalo.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1;0",
        "aff_unique_norm": "University of California, San Diego;University",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://cse.ucsd.edu;",
        "aff_unique_abbr": "UCSD CSE;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "c4175cd0da",
        "title": "Autonomous Thermalling as a Partially Observable Markov Decision Process",
        "site": "https://www.roboticsproceedings.org/rss14/p68.html",
        "author": "Iain Guilliard; Rick Rogahn; Jim Piavi; Andrey Kolobov",
        "abstract": "Small uninhabited aerial vehicles (sUAVs) commonly rely on active propulsion to stay airborne, which limits flight time and range. To address this, autonomous soaring seeks to utilize free atmospheric energy in the form of updrafts (thermals). However, their irregular nature at low altitudes makes them hard to exploit for existing methods. We model autonomous thermalling as a POMDP and present a receding-horizon controller based on it. We implement it as part of ArduPlane, a popular open-source autopilot, and compare it to an existing alternative in a series of live flight tests involving two sUAVs thermalling simultaneously, with our POMDP-based controller showing a significant advantage.",
        "bibtex": "@INPROCEEDINGS{Guilliard-RSS-18, \r\n    AUTHOR    = {Iain Guilliard AND Rick Rogahn AND Jim Piavi AND Andrey Kolobov}, \r\n    TITLE     = {Autonomous Thermalling as a Partially Observable Markov Decision Process}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.068} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p68.pdf",
        "supp": "",
        "pdf_size": 2443526,
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "aff": "Australian National University; Microsoft Research; Microsoft Research; Microsoft Research",
        "aff_domain": "anu.edu.au;microsoft.com;microsoft.com;microsoft.com",
        "email": "anu.edu.au;microsoft.com;microsoft.com;microsoft.com",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Australian National University;Microsoft",
        "aff_unique_dep": ";Microsoft Research",
        "aff_unique_url": "https://www.anu.edu.au;https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "ANU;MSR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "dc8c0d2f79",
        "title": "Bayesian Tactile Exploration for Compliant Docking With Uncertain Shapes",
        "site": "https://www.roboticsproceedings.org/rss14/p51.html",
        "author": "Kris Hauser",
        "abstract": "This paper presents a Bayesian approach for active tactile exploration of a planar shape in the presence of both localization and shape uncertainty.  The goal is to dock the robot's end-effector against the shape -- reaching a point of contact that resists a desired load -- with as few probing actions as possible.  The proposed method repeatedly performs inference, planning, and execution steps. Given a prior probability distribution over object shape and sensor readings from previously executed motions, the posterior distribution is inferred using a novel and efficient Hamiltonian Monte Carlo method.  The optimal docking site is chosen to maximize docking probability, using a closed-form probabilistic simulation that accepts rigid and compliant motion models under Coulomb friction.   Numerical experiments demonstrate that this method requires fewer exploration actions to dock than heuristics and information-gain strategies.",
        "bibtex": "@INPROCEEDINGS{Hauser-RSS-18, \r\n    AUTHOR    = {Kris Hauser}, \r\n    TITLE     = {Bayesian Tactile Exploration for Compliant Docking With Uncertain Shapes}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.051} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p51.pdf",
        "supp": "",
        "pdf_size": 1119475,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3583772091950837221&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "Dept. of Electrical and Computer Engineering, Duke University",
        "aff_domain": "duke.edu",
        "email": "duke.edu",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5ecd60176c",
        "title": "Closing the Loop for Robotic Grasping: A Real-time, Generative Grasp Synthesis Approach",
        "site": "https://www.roboticsproceedings.org/rss14/p21.html",
        "author": "Douglas Morrison; Juxi Leitner; Peter Corke",
        "abstract": "This paper presents a real-time, object-independent grasp synthesis method which can be used for closed-loop grasping.  Our proposed Generative Grasping Convolutional Neural Network (GG-CNN) predicts the quality and pose of grasps at every pixel. This one-to-one mapping from a depth image overcomes limitations of current deep-learning grasping techniques by avoiding discrete sampling of grasp candidates and long computation times.  Additionally, our GG-CNN is orders of magnitude smaller while detecting stable grasps with equivalent performance to current state-of-the-art techniques. The light-weight and single-pass generative nature of our GG-CNN allows for closed-loop control at up to 50Hz, enabling accurate grasping in non-static environments where objects move and in the presence of robot control inaccuracies.  In our real-world tests, we achieve an 83% grasp success rate on a set of previously unseen objects with adversarial geometry and 88% on a set of household objects that are moved during the grasp attempt.  We also achieve 81% accuracy when grasping in dynamic clutter.",
        "bibtex": "@INPROCEEDINGS{Morrison-RSS-18, \r\n    AUTHOR    = {Douglas Morrison AND Juxi Leitner AND Peter Corke}, \r\n    TITLE     = {Closing the Loop for Robotic Grasping: A Real-time, Generative Grasp Synthesis Approach}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.021} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p21.pdf",
        "supp": "",
        "pdf_size": 3260332,
        "gs_citation": 703,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10967466169233364503&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "Australian Centre for Robotic Vision; Australian Centre for Robotic Vision; Australian Centre for Robotic Vision",
        "aff_domain": "hdr.qut.edu.au; ; ",
        "email": "hdr.qut.edu.au; ; ",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Australian Centre for Robotic Vision",
        "aff_unique_dep": "",
        "aff_unique_url": "https://roboticvision.org/",
        "aff_unique_abbr": "ACRV",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "0147395c34",
        "title": "Constant Factor Time Optimal Multi-Robot Routing on High-Dimensional Grids",
        "site": "https://www.roboticsproceedings.org/rss14/p13.html",
        "author": "Jingjin Yu",
        "abstract": "Let G = (V, E) be an m_1 \\times \\ldots \\times m_k grid  for some arbitrary constant k. We establish that O(\\sum_{i=1}^km_i)  (makespan) time-optimal labeled (i.e., each robot has a specific goal)  multi-robot path planning can be realized on G in O(|V|^2) running  time, even when vertices of G are fully occupied by robots. When all  dimensions are of equal sizes, the running time approaches O(|V|).  Using this base line algorithm, which provides average case  O(1)-approximate (i.e., constant-factor) time-optimal solutions, we  further develop a first worst case O(1)-approximate algorithm that again  runs in O(|V|^2) time for two and three dimensions. We note that the  problem has a worst case running time lower bound of \\Omega(|V|^2).",
        "bibtex": "@INPROCEEDINGS{Yu-RSS-18, \r\n    AUTHOR    = {Jingjin Yu}, \r\n    TITLE     = {Constant Factor Time Optimal Multi-Robot Routing on High-Dimensional Grids}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.013} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p13.pdf",
        "supp": "",
        "pdf_size": 680920,
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=767941758387052623&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, New Jersey, USA",
        "aff_domain": "cs.rutgers.edu",
        "email": "cs.rutgers.edu",
        "github": "",
        "project": "",
        "author_num": 1,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "540ba40873",
        "title": "Contact-Aided Invariant Extended Kalman Filtering for Legged Robot State Estimation",
        "site": "https://www.roboticsproceedings.org/rss14/p50.html",
        "author": "Ross Hartley; Maani Ghaffari Jadidi; Jessy Grizzle; Ryan M Eustice",
        "abstract": "This paper derives a contact-aided inertial navigation observer for a 3D bipedal robot using the theory of invariant observer design. Aided inertial navigation is fundamentally a nonlinear observer design problem; thus, current solutions are based on approximations of the system dynamics, such as an Extended Kalman Filter (EKF), which uses a system's Jacobian linearization along the current best estimate of its trajectory. On the basis of the theory of invariant observer design by Barrau and Bonnabel, and in particular, the Invariant EKF (InEKF), we show that the error dynamics of the point contact-inertial system follows a log-linear autonomous differential equation; hence, the observable state variables can be rendered convergent with a domain of attraction that is independent of the system's trajectory. Due to the log-linear form of the error dynamics, it is not necessary to perform a nonlinear observability analysis to show that when using an Inertial Measurement Unit (IMU) and contact sensors, the absolute position of the robot and a rotation about the gravity vector (yaw) are unobservable. We further augment the state of the developed InEKF with IMU biases, as the online estimation of these parameters has a crucial impact on system performance. We evaluate the convergence of the proposed system with the commonly used quaternion-based EKF observer using a Monte-Carlo simulation. In addition, our experimental evaluation using a Cassie-series bipedal robot shows that the contact-aided InEKF provides better performance in comparison with the quaternion-based EKF as a result of exploiting symmetries present in the system dynamics.",
        "bibtex": "@INPROCEEDINGS{Hartley-RSS-18, \r\n    AUTHOR    = {Ross Hartley AND Maani Ghaffari Jadidi AND Jessy Grizzle AND Ryan M Eustice}, \r\n    TITLE     = {Contact-Aided Invariant Extended Kalman Filtering for Legged Robot State Estimation}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.050} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p50.pdf",
        "supp": "",
        "pdf_size": 5114892,
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2805760949155404174&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "College of Engineering, University of Michigan, Ann Arbor, MI, USA; College of Engineering, University of Michigan, Ann Arbor, MI, USA; College of Engineering, University of Michigan, Ann Arbor, MI, USA; College of Engineering, University of Michigan, Ann Arbor, MI, USA",
        "aff_domain": "umich.edu;umich.edu;umich.edu;umich.edu",
        "email": "umich.edu;umich.edu;umich.edu;umich.edu",
        "github": "https://github.com/UMich-BipedLab/Contact-Aided-Invariant-EKF",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "College of Engineering",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "14ac5590c4",
        "title": "Contact-Implicit Optimization of Locomotion Trajectories for a Quadrupedal Microrobot",
        "site": "https://www.roboticsproceedings.org/rss14/p41.html",
        "author": "Neel Doshi; Kaushik Jayaram; Benjamin Goldberg; Zachary Manchester; Robert Wood; Scott Kuindersma",
        "abstract": "Planning locomotion trajectories for legged microrobots is challenging because of their complex morphology, high frequency passive dynamics, and discontinuous contact interactions with their environment. Consequently, such research is often driven by time-consuming experimental methods. As an alternative, we present a framework for systematically modeling, planning, and controlling legged microrobots. We develop a three-dimensional dynamic model of a 1.5 g quadrupedal microrobot with complexity (e.g., number of degrees of freedom) similar to larger-scale legged robots. We then adapt a recently developed variational contact-implicit trajectory optimization method to generate feasible whole-body locomotion plans for this microrobot, and we demonstrate that these plans can be tracked with simple joint-space controllers. We plan and execute periodic gaits at multiple stride frequencies and on various surfaces.  These gaits achieve high per-cycle velocities, including a maximum of 10.87 mm/cycle, which is 15\\% faster than previously measured velocities for this microrobot. Furthermore, we plan and execute a vertical jump of 9.96 mm, which is 78% of the microrobot's center-of-mass height. To the best of our knowledge, this is the first end-to-end demonstration of planning and tracking whole-body dynamic locomotion on a millimeter-scale legged microrobot.",
        "bibtex": "@INPROCEEDINGS{Doshi-RSS-18, \r\n    AUTHOR    = {Neel Doshi AND Kaushik Jayaram AND Benjamin Goldberg AND Zachary Manchester AND Robert Wood AND Scott Kuindersma}, \r\n    TITLE     = {Contact-Implicit Optimization of Locomotion Trajectories for a Quadrupedal Microrobot}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.041} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p41.pdf",
        "supp": "",
        "pdf_size": 6667176,
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18232560578722261672&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "aff": ";;;;;",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "https://youtu.be/xwbRQpKukg",
        "author_num": 6,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f17532cebe",
        "title": "Coordination of back bending and leg movements for quadrupedal locomotion",
        "site": "https://www.roboticsproceedings.org/rss14/p20.html",
        "author": "Baxi Chong; Yasemin Ozkan Aydin; Chaohui Gong; Guillaume Sartoretti; Yunjin Wu; Jennifer Rieser; Haosen Xing; Jeffery Rankin; Krijn Michel; Alfredo Nicieza; John Hutchinson; Daniel Goldman; Howie Choset",
        "abstract": "Many quadrupedal animals have lateral degrees of freedom in their backs that assist locomotion. This paper seeks to use a robotic model to demonstrate that back bending assists not only forward motion, but also lateral and turning motions. This paper uses geometric mechanics to prescribe gaits that coordinate both leg movements and back bending motion. Using these geometric tools, we show that back-bending can improve stride displacement in the forward, rotational, and lateral directions. In addition to locomotion performance improvement, the back bending can also expand the target position space a robot can reach within one gait cycle. Our results are verified by conducting experiments with a robot moving on granular materials.",
        "bibtex": "@INPROCEEDINGS{Chong-RSS-18, \r\n    AUTHOR    = {Baxi Chong AND Yasemin Ozkan Aydin AND Chaohui Gong AND Guillaume Sartoretti AND Yunjin Wu AND Jennifer Rieser AND Haosen Xing AND Jeffery Rankin AND Krijn Michel AND Alfredo Nicieza AND John Hutchinson AND Daniel Goldman AND Howie Choset}, \r\n    TITLE     = {Coordination of back bending and leg movements for quadrupedal locomotion}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.020} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p20.pdf",
        "supp": "",
        "pdf_size": 3942506,
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5306644131620420498&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Carnegie Mellon Institution; Georgia Institute of Technology; Carnegie Mellon Institution; Carnegie Mellon Institution; Carnegie Mellon Institution; Georgia Institute of Technology; Carnegie Mellon Institution; Rancho Research Institute; Royal Veterinary College; Royal Veterinary College; University of Oviedo; Georgia Institute of Technology; Carnegie Mellon Institution",
        "aff_domain": ";;;;;;;;;;;;",
        "email": ";;;;;;;;;;;;",
        "github": "",
        "project": "",
        "author_num": 13,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0;0;0;1;0;2;3;3;4;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Georgia Institute of Technology;Rancho Research Institute;Royal Veterinary College;University of Oviedo",
        "aff_unique_dep": ";;;;",
        "aff_unique_url": "https://www.cmu.edu;https://www.gatech.edu;;https://www.rvc.ac.uk;https://www.uniovi.es",
        "aff_unique_abbr": "CMU;Georgia Tech;;RVC;UNIOVI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;1;1;2;0;0",
        "aff_country_unique": "United States;United Kingdom;Spain"
    },
    {
        "id": "9de1db8e58",
        "title": "Creating Foldable Polyhedral Nets Using Evolution Control",
        "site": "https://www.roboticsproceedings.org/rss14/p07.html",
        "author": "Yue Hao; Yun-hyeong Kim; Zhonghua Xi; Jyh-Ming Lien",
        "abstract": "Recent innovations enable robots to be manufactured using low-cost planar active material and self-folded into 3D structures. The current practice for designing such structures often uses two decoupled steps: generating an unfolding (called net) from a 3D shape and then finding the collision-free folding motion that brings the net back to the 3D shape. This raises a foldability problem, namely that there is no guarantee that continuous motion can be found in the latter step, given a net generated in the former step. Direct evaluation on the foldability of a net is nontrivial and can be computationally expensive. This paper presents a novel learning strategy that generates foldable nets using an optimized genetic-based unfolder. The proposed strategy yields a fitness function that combines the geometric and topological properties of a net to approximate the foldability. The fitness function is then optimized in an evolution control framework to generate foldable nets. The experimental results show that our new unfolder generates valid unfoldings that are easy to fold. Consequently, our approach opens a door to automate the design of more complex self-folding machines.",
        "bibtex": "@INPROCEEDINGS{Hao-RSS-18, \r\n    AUTHOR    = {Yue Hao AND Yun-hyeong Kim AND Zhonghua Xi AND Jyh-Ming Lien}, \r\n    TITLE     = {Creating Foldable Polyhedral Nets Using Evolution Control}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.007} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p07.pdf",
        "supp": "",
        "pdf_size": 6059485,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12078697232909954601&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "d42cb49c4d",
        "title": "Data-Driven Measurement Models for Active Localization in Sparse Environments",
        "site": "https://www.roboticsproceedings.org/rss14/p45.html",
        "author": "Ian Abraham; Anastasia Mavrommati; Todd Murphey",
        "abstract": "We develop an algorithm to explore an environment to generate a measurement model for use in future localization tasks. Ergodic exploration with respect to the likelihood of a particular class of measurement (e.g., a contact detection measurement in tactile sensing) enables construction of the measurement model. Exploration with respect to the information density based on the data-driven measurement model enables localization. We test the two-stage approach in simulations of tactile sensing, illustrating that the algorithm is capable of identifying and localizing objects based on sparsely distributed binary contacts. Comparisons with our method show that visiting low probability regions lead to acquisition of new information rather than increasing the likelihood of known information. Experiments with the Sphero SPRK robot validate the efficacy of this method for collision-based estimation and localization of the environment.",
        "bibtex": "@INPROCEEDINGS{Abraham-RSS-18, \r\n    AUTHOR    = {Ian Abraham AND Anastasia Mavrommati AND Todd Murphey}, \r\n    TITLE     = {Data-Driven Measurement Models for Active Localization in Sparse Environments}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.045} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p45.pdf",
        "supp": "",
        "pdf_size": 5031858,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13856162385386423116&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "04c5f6dad4",
        "title": "Differentiable Particle Filters: End-to-End Learning with Algorithmic Priors",
        "site": "https://www.roboticsproceedings.org/rss14/p01.html",
        "author": "Rico Jonschkowski; Divyam Rastogi; Oliver Brock",
        "abstract": "We present differentiable particle filters (DPFs): a differentiable implementation of the particle filter algorithm with learnable motion and measurement models. Since DPFs are end-to-end differentiable, we can efficiently train their models by optimizing end-to-end state estimation performance, rather than proxy objectives such as model accuracy. DPFs encode the structure of recursive state estimation with prediction and measurement update that operate on a probability distribution over states. This structure represents an algorithmic prior that improves learning performance in state estimation problems while enabling explainability of the learned model. Our experiments on simulated and real data show substantial benefits from end-to-end learning with algorithmic priors, e.g. reducing error rates by ~80%. Our experiments also show that, unlike long short-term memory networks, DPFs learn localization in a policy-agnostic way and thus greatly improve generalization. Source code is available at https://github.com/tu-rbo/differentiable-particle-filters.",
        "bibtex": "@INPROCEEDINGS{Jonschkowski-RSS-18, \r\n    AUTHOR    = {Rico Jonschkowski AND Divyam Rastogi AND Oliver Brock}, \r\n    TITLE     = {Differentiable Particle Filters: End-to-End Learning with Algorithmic Priors}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.001} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p01.pdf",
        "supp": "",
        "pdf_size": 3316229,
        "gs_citation": 170,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2184833702641947776&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Robotics and Biology Laboratory, Technische Universit \u00a8at Berlin, Germany; Robotics and Biology Laboratory, Technische Universit \u00a8at Berlin, Germany; Robotics and Biology Laboratory, Technische Universit \u00a8at Berlin, Germany",
        "aff_domain": ";;",
        "email": ";;",
        "github": "https://github.com/tu-rbo/differentiable-particle-\ufb01lters",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Berlin",
        "aff_unique_dep": "Robotics and Biology Laboratory",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "3e3d0c11a6",
        "title": "Differentiable Physics and Stable Modes for Tool-Use and Manipulation Planning",
        "site": "https://www.roboticsproceedings.org/rss14/p44.html",
        "author": "Marc Toussaint; Kelsey Allen; Kevin Smith; Joshua Tenenbaum",
        "abstract": "We consider the problem of sequential manipulation and tool-use   planning in domains that include physical interactions such as   hitting and throwing. The approach integrates a Task And Motion   Planning formulation with primitives that either impose stable   kinematic constraints or differentiable dynamical and impulse   exchange constraints at the path optimization level. We demonstrate   our approach on a variety of physical puzzles that involve tool use   and dynamic interactions. We then compare manipulation sequences   generated by our approach to human actions on analogous tasks,   suggesting future directions and illuminating current limitations.",
        "bibtex": "@INPROCEEDINGS{Toussaint-RSS-18, \r\n    AUTHOR    = {Marc Toussaint AND Kelsey Allen AND Kevin Smith AND Joshua Tenenbaum}, \r\n    TITLE     = {Differentiable Physics and Stable Modes for Tool-Use and Manipulation Planning}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.044} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p44.pdf",
        "supp": "",
        "pdf_size": 1992383,
        "gs_citation": 346,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10342169019935480143&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "aff": "Machine Learning & Robotics Lab, University of Stuttgart, Germany + Massachusetts Institute of Technology, Cambridge, MA 02139; Massachusetts Institute of Technology, Cambridge, MA 02139; Massachusetts Institute of Technology, Cambridge, MA 02139; Massachusetts Institute of Technology, Cambridge, MA 02139",
        "aff_domain": "informatik.uni-stuttgart.de;mit.edu;mit.edu;mit.edu",
        "email": "informatik.uni-stuttgart.de;mit.edu;mit.edu;mit.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1;1;1",
        "aff_unique_norm": "University of Stuttgart;Massachusetts Institute of Technology",
        "aff_unique_dep": "Machine Learning & Robotics Lab;",
        "aff_unique_url": "https://www.uni-stuttgart.de;https://www.mit.edu",
        "aff_unique_abbr": ";MIT",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0+1;1;1;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "93bcc54c91",
        "title": "Directionally Controlled Time-of-Flight Ranging for Mobile Sensing Platforms",
        "site": "https://www.roboticsproceedings.org/rss14/p11.html",
        "author": "Zaid Tasneem; Dingkang Wang; Huikai Xie; Koppal Sanjeev",
        "abstract": "Scanning time-of-flight (TOF) sensors obtain depth measurements by directing modulated light beams across a scene. We demonstrate that control of the directional scanning patterns can enable novel algorithms and applications. Our analysis occurs entirely in the angular domain and consists of two ideas. First, we show how to exploit the angular support of the light beam to improve reconstruction results. Second, we describe how to control the light beam direction in a way that maximizes a well-known information theoretic measure. Using these two ideas, we demonstrate novel applications such as adaptive TOF sensing, LIDAR zoom, LIDAR edge sensing for gradient-based reconstruction and energy efficient LIDAR scanning. Our contributions can apply equally to sensors using mechanical, optoelectronic or MEMS-based approaches to modulate the light beam, and we show results here on a MEMS mirror-based LIDAR system. In short, we describe new adaptive directionally controlled TOF sensing algorithms which can impact mobile sensing platforms such as robots, wearable devices and IoT nodes.",
        "bibtex": "@INPROCEEDINGS{Tasneem-RSS-18, \r\n    AUTHOR    = {Zaid Tasneem AND Dingkang Wang AND Huikai Xie AND Koppal Sanjeev}, \r\n    TITLE     = {Directionally Controlled Time-of-Flight Ranging for Mobile Sensing Platforms}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.011} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p11.pdf",
        "supp": "",
        "pdf_size": 5528686,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13536118821390445258&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "University of Florida; University of Florida; University of Florida; University of Florida",
        "aff_domain": "ufl.edu;ufl.edu;ufl.edu;ece.ufl.edu",
        "email": "ufl.edu;ufl.edu;ufl.edu;ece.ufl.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Florida",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ufl.edu",
        "aff_unique_abbr": "UF",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "83bfee0fde",
        "title": "Dual-Speed MR Safe Pneumatic Stepper Motors",
        "site": "https://www.roboticsproceedings.org/rss14/p30.html",
        "author": "Vincent Groenhuis; Fran\u00c3\u00a7oise  Siepel; Stefano Stramigioli",
        "abstract": "In breast cancer detection it is essential to perform precise interventions to determine the diagnosis. Robotic systems actuated by MR safe pneumatic stepper motors could improve accuracy to target the tumor. The achievable accuracy or speed is limited due to long pneumatic tubes connecting the motors to the electromagnetic valves in the control room. This paper presents the design of two dual-speed stepper motors in order to solve this limitation.   The linear motor measures 50x32x14 mm (excluding racks) and has step sizes 1.7 mm and 0.3 mm. The maximum speed under load is 20 mm/s, measured force is 24 N and positioning accuracy is 0.1 mm. The rotational motor measures \u00c3\u02dc30x32 mm (excluding axles) and has step sizes 10\u00c2\u00b0 and 12.9\u00c2\u00b0. Under load its maximum angular speed is 229\u00c2\u00b0/s or 38.2 RPM, maximum torque is 74 N mm and positioning accuracy is 1\u00c2\u00b0. By operating the valves in a coordinated way high-speed and precise position control can be achieved. With these specifications the motors have high potential to actuate MR safe surgical robots.",
        "bibtex": "@INPROCEEDINGS{Groenhuis-RSS-18, \r\n    AUTHOR    = {Vincent Groenhuis AND Fran\u00c3\u00a7oise  Siepel AND Stefano Stramigioli}, \r\n    TITLE     = {Dual-Speed MR Safe Pneumatic Stepper Motors}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.030} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p30.pdf",
        "supp": "",
        "pdf_size": 4673897,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5340674072278570950&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Robotics and Mechatronics, University of Twente, Enschede, The Netherlands; Robotics and Mechatronics, University of Twente, Enschede, The Netherlands; Robotics and Mechatronics, University of Twente, Enschede, The Netherlands + ITMO, Saint Petersburg, Russia",
        "aff_domain": "utwente.nl; ; ",
        "email": "utwente.nl; ; ",
        "github": "",
        "project": "http://www.vincentgroenhuis.nl/DualSpeedMotors.mp4",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0+1",
        "aff_unique_norm": "University of Twente;ITMO University",
        "aff_unique_dep": "Robotics and Mechatronics;",
        "aff_unique_url": "https://www.utwente.nl;https://www.itmo.ru",
        "aff_unique_abbr": "UT;ITMO",
        "aff_campus_unique_index": "0;0;0+1",
        "aff_campus_unique": "Enschede;Saint Petersburg",
        "aff_country_unique_index": "0;0;0+1",
        "aff_country_unique": "Netherlands;Russian Federation"
    },
    {
        "id": "f5a7193f24",
        "title": "EV-FlowNet: Self-Supervised Optical Flow Estimation for Event-based Cameras",
        "site": "https://www.roboticsproceedings.org/rss14/p62.html",
        "author": "Alex Zhu; Liangzhe Yuan; Kenneth Chaney; Kostas Daniilidis",
        "abstract": "Event-based cameras have shown great promise in a variety of situations where frame based cameras suffer, such as high speed motions and high dynamic range scenes. However, developing algorithms for event measurements requires a new class of hand crafted algorithms. Deep learning has shown great success in providing model free solutions to many problems in the vision community, but existing networks have been developed with frame based images in mind, and there does not exist the wealth of labeled data for events as there does for images for supervised training. To these points, we present EV-FlowNet, a novel self-supervised deep learning pipeline for optical flow estimation for event based cameras. In particular, we introduce an image based representation of a given event stream, which is fed into a self-supervised neural network as the sole input. The corresponding grayscale images captured from the same camera at the same time as the events are then used as a supervisory signal to provide a loss function at training time, given the estimated flow from the network. We show that the resulting network is able to accurately predict optical flow from events only in a variety of different scenes, with performance competitive to image based networks. This method not only allows for accurate estimation of dense optical flow, but also provides a framework for the transfer of other self-supervised methods to the event-based domain.",
        "bibtex": "@INPROCEEDINGS{Zhu-RSS-18, \r\n    AUTHOR    = {Alex Zhu AND Liangzhe Yuan AND Kenneth Chaney AND Kostas Daniilidis}, \r\n    TITLE     = {EV-FlowNet: Self-Supervised Optical Flow Estimation for Event-based Cameras}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.062} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p62.pdf",
        "supp": "",
        "pdf_size": 1526962,
        "gs_citation": 571,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12306638280105622655&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "School of Engineering and Applied Science, University of Pennsylvania; School of Engineering and Applied Science, University of Pennsylvania; School of Engineering and Applied Science, University of Pennsylvania; School of Engineering and Applied Science, University of Pennsylvania",
        "aff_domain": "seas.upenn.edu;seas.upenn.edu;seas.upenn.edu;seas.upenn.edu",
        "email": "seas.upenn.edu;seas.upenn.edu;seas.upenn.edu;seas.upenn.edu",
        "github": "",
        "project": "https://daniilidis-group.github.io/mvsec/",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "School of Engineering and Applied Science",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b3b76b16e6",
        "title": "Efficient Surfel-Based SLAM using 3D Laser Range Data in Urban Environments",
        "site": "https://www.roboticsproceedings.org/rss14/p16.html",
        "author": "Jens Behley; Cyrill Stachniss",
        "abstract": "Accurate and reliable localization and mapping is a fundamental building block for most autonomous robots. For this purpose, we propose a novel, dense approach to laser-based mapping that operates on three-dimensional point clouds obtained from rotating laser sensors. We construct a surfel-based map and estimate the changes in the robot's pose by exploiting the projective data association between the current scan and a rendered model view from that surfel map. For detection and verification of a loop closure, we leverage the map representation to compose a virtual view of the map before a potential loop closure, which enables a more robust detection even with low overlap between the scan and the already mapped areas. Our approach is efficient and enables real-time capable registration. At the same time, it is able to detect loop closures and to perform map updates in an online fashion. Our experiments show that we are able to estimate globally consistent maps in large scale environments solely based on point cloud data.",
        "bibtex": "@INPROCEEDINGS{Behley-RSS-18, \r\n    AUTHOR    = {Jens Behley AND Cyrill Stachniss}, \r\n    TITLE     = {Efficient Surfel-Based SLAM using 3D Laser Range Data in Urban Environments}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.016} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p16.pdf",
        "supp": "",
        "pdf_size": 3584838,
        "gs_citation": 559,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6474440133129171572&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Institute of Geodesy and Geoinformation, University of Bonn, Germany; Institute of Geodesy and Geoinformation, University of Bonn, Germany",
        "aff_domain": "igg.uni-bonn.de;igg.uni-bonn.de",
        "email": "igg.uni-bonn.de;igg.uni-bonn.de",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Institute of Geodesy and Geoinformation",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "81d27cbdd2",
        "title": "Efficiently Sampling from Underlying Models",
        "site": "https://www.roboticsproceedings.org/rss14/p57.html",
        "author": "Greydon Foil; David Wettergreen",
        "abstract": "The capability and mobility of exploration robots is increasing rapidly, yet missions will always be constrained by one main resource: time. Time limits the number of samples a robot can collect, sites it can analyze, and the availability of human oversight, so it is imperative the robot is able to make intelligent actions when it comes to choosing when, where, and what to sample, a process known as adaptive sampling.  This work advances the state of the art in adaptive sampling for exploration robotics. We take advantage of the fact that rover operations are typically not performed in a vacuum; extensive contextual data is often present, most often in the form of orbital imagery, rover navigation images, and prior instrument measurements. Using this context, we apply Bayesian and nonparametric models to decide where best to sample under a limited budget, using real X-ray lithochemistry data.  We find that our methods improve both the diversity of samples collected as well as select samples that are representative of the dataset. We find that model-based approaches made scalable with Dirichlet processes improve sampling results when the underlying number classes and class distribution is unknown. Unlike previous works, our approaches reduce the impact of noise on sampling location, a common problem when selecting samples based on noisy or incomplete contextual data.",
        "bibtex": "@INPROCEEDINGS{ Foil-RSS-18, \r\n    AUTHOR    = {Greydon Foil AND David Wettergreen}, \r\n    TITLE     = {Efficiently Sampling from Underlying Models}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.057} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p57.pdf",
        "supp": "",
        "pdf_size": 7046702,
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3000500974299004266&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "aff_domain": "alumni.cmu.edu;ri.cmu.edu",
        "email": "alumni.cmu.edu;ri.cmu.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "3d5a2205ef",
        "title": "Embedded High Precision Control and Corn Stand Counting Algorithms for an Ultra-Compact 3D Printed Field Robot",
        "site": "https://www.roboticsproceedings.org/rss14/p36.html",
        "author": "Erkan Kayacan; Zhongzhong Zhang; Girish Chowdhary",
        "abstract": "This paper presents embedded high precision control and corn stands counting algorithms for a low-cost, ultra-compact 3D printed and autonomous field robot for agricultural operations. Currently, plant traits, such as emergence rate, biomass, vigor and stand counting are measured manually. This is highly labor intensive and prone to errors. The robot, termed TerraSentia, is designed to automate the measurement of plant traits for efficient phenotyping as an alternative to manual measurements. In this paper, we formulate a nonlinear moving horizon estimator that identifies key terrain parameters using onboard robot sensors and a learning-based nonlinear model predictive control (NMPC) that ensures high precision path tracking in the presence of unknown wheel-terrain interaction. Moreover, we develop a machine vision algorithm to enable TerraSentia to count corn stands by driving through the fields autonomously. We present results of an extensive field-test study that shows that i) the robot can track paths precisely with less than 5cm error so that the robot is less likely to damage plants, and ii) the machine vision algorithm is robust against interferences from leaves and weeds, and the system has been verified in corn fields at the growth stage of V4, V6, VT, R2, and R6 from five different locations. The robot predictions agree well with the ground truth with the correlation coefficient R=0.96.",
        "bibtex": "@INPROCEEDINGS{Kayacan-RSS-18, \r\n    AUTHOR    = {Erkan Kayacan AND Zhongzhong Zhang AND Girish Chowdhary}, \r\n    TITLE     = {Embedded High Precision Control and Corn Stand Counting Algorithms for an Ultra-Compact 3D Printed Field Robot}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.036} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p36.pdf",
        "supp": "",
        "pdf_size": 918743,
        "gs_citation": 64,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14809542527527504007&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Coordinated Science Laboratory; Distributed Autonomous Systems Laboratory; Department of Agricultural and Biological Engineering, University of Illinois at Urbana-Champaign",
        "aff_domain": "mit.edu;illinois.edu;illinois.edu",
        "email": "mit.edu;illinois.edu;illinois.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Distributed Autonomous Systems Laboratory",
        "aff_unique_dep": "Coordinated Science Laboratory;Distributed Autonomous Systems Laboratory",
        "aff_unique_url": "https://www.csl.illinois.edu;",
        "aff_unique_abbr": "CSL;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "8ea82c5e19",
        "title": "Exploiting Stochasticity for the Control of Transitions in Gyre Flows",
        "site": "https://www.roboticsproceedings.org/rss14/p60.html",
        "author": "Dhanushka Kularatne; Eric Forgoston; M. Ani Hsieh",
        "abstract": "We present a control strategy to control the inter-gyre switching time of an agent operating in a gyre flow. The proposed control strategy exploits the stochasticity of the underlying environment to affect inter-gyre transitions. We show how control can be used to enhance or abate the mean escape time and present a strategy to achieve a desired mean escape time. We show that the proposed control strategy can achieve any desired escape time in an interval governed by the maximum available control. We demonstrate the effectiveness of the strategy in simulations.",
        "bibtex": "@INPROCEEDINGS{Kularatne-RSS-18, \r\n    AUTHOR    = {Dhanushka Kularatne AND Eric Forgoston AND M. Ani Hsieh}, \r\n    TITLE     = {Exploiting Stochasticity for the Control of Transitions in Gyre Flows}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.060} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p60.pdf",
        "supp": "",
        "pdf_size": 784186,
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15041134648158198547&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "aff": "Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, USA; Department of Mathematical Sciences, Montclair State University Montclair, NJ, USA; Mechanical Engineering and Applied Mechanics, University of Pennsylvania, Philadelphia, PA, USA",
        "aff_domain": "seas.upenn.edu;montclair.edu;seas.upenn.edu",
        "email": "seas.upenn.edu;montclair.edu;seas.upenn.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Pennsylvania;Montclair State University",
        "aff_unique_dep": "Mechanical Engineering and Applied Mechanics;Department of Mathematical Sciences",
        "aff_unique_url": "https://www.upenn.edu;https://www.montclair.edu",
        "aff_unique_abbr": "UPenn;MSU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Philadelphia;Montclair",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "7c34e28772",
        "title": "Fast Online Trajectory Optimization for the Bipedal Robot Cassie",
        "site": "https://www.roboticsproceedings.org/rss14/p54.html",
        "author": "Taylor Apgar; Patrick Clary; Kevin Green; Alan Fern; Jonathan Hurst",
        "abstract": "We apply fast online trajectory optimization for multi-step motion planning to Cassie, a bipedal robot designed to exploit natural spring-mass locomotion dynamics using lightweight, compliant legs. Our motion planning formulation simultaneously optimizes over center of mass motion, footholds, and center of pressure for a simplified model that combines transverse linear inverted pendulum and vertical spring dynamics. A vertex-based representation of the support area combined with this simplified dynamic model that allows closed form integration leads to a fast nonlinear programming problem formulation. This optimization problem is continuously solved online in a model predictive control approach. The output of the reduced-order planner is fed into a quadratic programming based operational space controller for execution on the full-order system. We present simulation results showing the performance and robustness to disturbances of the planning and control framework. Preliminary results on the physical robot show functionality of the operational space control system, with integration of the trajectory planner a work in progress.",
        "bibtex": "@INPROCEEDINGS{Apgar-RSS-18, \r\n    AUTHOR    = {Taylor Apgar AND Patrick Clary AND Kevin Green AND Alan Fern AND Jonathan Hurst}, \r\n    TITLE     = {Fast Online Trajectory Optimization for the Bipedal Robot Cassie}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.054} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p54.pdf",
        "supp": "",
        "pdf_size": 572898,
        "gs_citation": 190,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10072907451660974035&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": ";;;;",
        "aff_domain": ";;;;",
        "email": ";;;;",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "f6700ee957",
        "title": "FlashFusion: Real-time Globally Consistent Dense 3D Reconstruction using CPU Computing",
        "site": "https://www.roboticsproceedings.org/rss14/p06.html",
        "author": "Lei Han; Lu Fang",
        "abstract": "Aiming at the practical usage of dense 3D reconstruction on portable devices, we propose FlashFusion, a Fast LArge-Scale High-resolution (sub-centimeter level) 3D reconstruction system without the use of GPU computing. It enables globally-consistent localization through a robust yet fast global bundle adjustment scheme, and realizes spatial hashing based volumetric fusion running at 300Hz and rendering at 25Hz via highly efficient valid chunk selection and mesh extraction schemes. Extensive experiments on both real world and synthetic datasets demonstrate that FlashFusion succeeds to enable real-time, globally consistent, high-resolution (5mm), and large-scale dense 3D reconstruction using highly-constrained computation, i.e., the CPU computing on portable devices.",
        "bibtex": "@INPROCEEDINGS{Han-RSS-18, \r\n    AUTHOR    = {Lei Han AND Lu Fang}, \r\n    TITLE     = {FlashFusion: Real-time Globally Consistent Dense 3D Reconstruction using CPU Computing}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.006} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p06.pdf",
        "supp": "",
        "pdf_size": 2421949,
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9562048613299141995&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "Tsinghua-Berkeley Shenzhen Institute; Tsinghua-Berkeley Shenzhen Institute + Hong Kong University of Science and Technology",
        "aff_domain": "connect.ust.hk;sz.tsinghua.edu.cn",
        "email": "connect.ust.hk;sz.tsinghua.edu.cn",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1",
        "aff_unique_norm": "Tsinghua-Berkeley Shenzhen Institute;Hong Kong University of Science and Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.tbsi.edu.cn/;https://www.ust.hk",
        "aff_unique_abbr": "TBSI;HKUST",
        "aff_campus_unique_index": "0;0+1",
        "aff_campus_unique": "Shenzhen;Hong Kong SAR",
        "aff_country_unique_index": "0;0+0",
        "aff_country_unique": "China"
    },
    {
        "id": "cf3bf96c5f",
        "title": "Following High-level Navigation Instructions on a Simulated Quadcopter with Imitation Learning",
        "site": "https://www.roboticsproceedings.org/rss14/p66.html",
        "author": "Valts Blukis; Nataly Brukhim; Andrew Bennett; Ross Knepper; Yoav Artzi",
        "abstract": "We introduce a method for following high-level navigation instructions by mapping directly from images, instructions and pose estimates to continuous low-level velocity commands for real-time control. The Grounded Semantic Mapping Network (GSMN) is a fully-differentiable neural network architecture that builds an explicit semantic map in the world reference frame by incorporating a pinhole camera projection model within the network. The information stored in the map is learned from experience, while the local-to-world transformation  is computed explicitly. We train the model using DAggerFM, a modified variant of DAgger that trades tabular convergence guarantees for improved training speed and memory use. We test GSMN in  virtual environments on a realistic quadcopter simulator and show that incorporating an explicit mapping and grounding modules allows GSMN to outperform strong neural baselines and almost reach an expert policy performance. Finally, we analyze the learned map representations and show that using an explicit map leads to an interpretable instruction-following model.",
        "bibtex": "@INPROCEEDINGS{Blukis-RSS-18, \r\n    AUTHOR    = {Valts Blukis AND Nataly Brukhim AND Andrew Bennett AND Ross Knepper AND Yoav Artzi}, \r\n    TITLE     = {Following High-level Navigation Instructions on a Simulated Quadcopter with Imitation Learning}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.066} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p66.pdf",
        "supp": "",
        "pdf_size": 4107522,
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11253932618942576561&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "Department of Computer Science, Cornell University, Ithaca, New York, USA+Cornell Tech, Cornell University, New York, New York, USA; Tel Aviv University, Tel Aviv-Yafo, Israel; Department of Computer Science, Cornell University, Ithaca, New York, USA+Cornell Tech, Cornell University, New York, New York, USA; Department of Computer Science, Cornell University, Ithaca, New York, USA+Cornell Tech, Cornell University, New York, New York, USA; Department of Computer Science, Cornell University, Ithaca, New York, USA+Cornell Tech, Cornell University, New York, New York, USA",
        "aff_domain": "cs.cornell.edu;mail.tau.ac.il;cs.cornell.edu;cs.cornell.edu;cs.cornell.edu",
        "email": "cs.cornell.edu;mail.tau.ac.il;cs.cornell.edu;cs.cornell.edu;cs.cornell.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+0;1;0+0;0+0;0+0",
        "aff_unique_norm": "Cornell University;Tel Aviv University",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.cornell.edu;https://www.tau.ac.il",
        "aff_unique_abbr": "Cornell;TAU",
        "aff_campus_unique_index": "0+1;2;0+1;0+1;0+1",
        "aff_campus_unique": "Ithaca;New York;Tel Aviv-Yafo",
        "aff_country_unique_index": "0+0;1;0+0;0+0;0+0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "5f11cbd627",
        "title": "Full-Frame Scene Coordinate Regression for Image-Based Localization",
        "site": "https://www.roboticsproceedings.org/rss14/p15.html",
        "author": "Xiaotian Li; Juha Ylioinas; Juho  Kannala",
        "abstract": "Image-based localization, or camera relocalization, is a fundamental problem in computer vision and robotics, and it refers to estimating camera pose from an image. Recent state-of-the-art approaches use learning based methods, such as Random Forests (RFs) and Convolutional Neural Networks (CNNs), to regress for each pixel in the image its corresponding position in the scene's world coordinate frame, and solve the final pose via a RANSAC-based optimization scheme using the predicted correspondences. In this paper, instead of in a patch-based manner, we propose to perform the scene coordinate regression in a full-frame manner to make the computation efficient at test time and, more importantly, to add more global context to the regression process to improve the robustness. To do so, we adopt a fully convolutional encoder-decoder neural network architecture which accepts a whole image as input and produces scene coordinate predictions for all pixels in the image. However, using more global context is prone to overfitting. To alleviate this issue, we propose to use data augmentation to generate more data for training. In addition to the data augmentation in 2D image space, we also augment the data in 3D space.  We evaluate our approach on the publicly available 7-Scenes dataset, and experiments show that it has better scene coordinate predictions and achieves state-of-the-art results in localization with improved robustness on the hardest frames (e.g., frames with repeated structures).",
        "bibtex": "@INPROCEEDINGS{Li-RSS-18, \r\n    AUTHOR    = {Xiaotian Li AND Juha Ylioinas AND Juho  Kannala}, \r\n    TITLE     = {Full-Frame Scene Coordinate Regression for Image-Based Localization}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.015} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p15.pdf",
        "supp": "",
        "pdf_size": 2309460,
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13400986963660663043&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Aalto University; Aalto University; Aalto University",
        "aff_domain": "aalto.fi;aalto.fi;aalto.fi",
        "email": "aalto.fi;aalto.fi;aalto.fi",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Aalto University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.aalto.fi",
        "aff_unique_abbr": "Aalto",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "b246a4c23e",
        "title": "GPU-Based Max Flow Maps in the Plane",
        "site": "https://www.roboticsproceedings.org/rss14/p52.html",
        "author": "Renato Farias; Marcelo Kallmann",
        "abstract": "One main challenge in multi-agent navigation is to generate trajectories minimizing bottlenecks in  environments cluttered with obstacles. In this paper we approach this problem globally by taking into account the maximum flow capacity of a given polygonal environment.  Given the difficulty in solving the continuous maximum flow of a planar environment, we introduce in this paper a GPU-based methodology which leads to a practical method for  computing maximum flow maps in arbitrary two-dimensional polygonal domains. Once the flow is computed, we then propose a method to extract lane trajectories according to the size of the agents and to optimize the trajectories in length while keeping constant the maximum flow achieved by the system of trajectories.  As a result we are able to generate trajectories of maximum flow from source to sink edges across a generic set of polygonal obstacles, enabling the deployment of large numbers of agents optimally with respect to the maximum flow capacity of the environment. Our approach eliminates bottlenecks by producing trajectories which are globally-optimal with respect to the flow capacity and locally-optimal with respect to the total length of the system of trajectories.",
        "bibtex": "@INPROCEEDINGS{Farias-RSS-18, \r\n    AUTHOR    = {Renato Farias AND Marcelo Kallmann}, \r\n    TITLE     = {GPU-Based Max Flow Maps in the Plane}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.052} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p52.pdf",
        "supp": "",
        "pdf_size": 984377,
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10329453180571277305&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "aff": "Computer Science and Engineering Department, University of California, Merced, CA, 95343; Computer Science and Engineering Department, University of California, Merced, CA, 95343",
        "aff_domain": "ucmerced.edu;ucmerced.edu",
        "email": "ucmerced.edu;ucmerced.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Merced",
        "aff_unique_dep": "Computer Science and Engineering Department",
        "aff_unique_url": "https://www.ucmerced.edu",
        "aff_unique_abbr": "UC Merced",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Merced",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "37336f5874",
        "title": "Generalized WarpDriver: Unified Collision Avoidance for Multi-Robot Systems in Arbitrarily Complex Environments",
        "site": "https://www.roboticsproceedings.org/rss14/p65.html",
        "author": "David Wolinski; Ming Lin",
        "abstract": "In this paper we present a unified collision-avoidance algorithm for the navigation of arbitrary agents, from pedestrians to various types of robots, including vehicles. This approach significantly extends the WarpDriver algorithm specialized for disc-like agents (e.g. crowds) to a wide array of robots in the following ways: (1) the new algorithm is more robust by unifiying the original set of Warp Operators for different non-linear extrapolations of motion into a single, general operator; (2) the algorithm is generalized to support agent dynamics and additional shapes beyond just circles; and (3) with addition of few, simple soft constraints, the algorithm can be used to simulate vehicle traffic. Thanks to the generality of the unified algorithm without special case handling, the new capabilities are tighly integrated at the level of collision avoidance, rather than as added layers of multiple heuristics on top of various collision-avoidance schemes designed independently for pedestrians vs. different types of robots and vehicles.",
        "bibtex": "@INPROCEEDINGS{Wolinski-RSS-18, \r\n    AUTHOR    = {David Wolinski AND Ming Lin}, \r\n    TITLE     = {Generalized WarpDriver: Unified Collision Avoidance for Multi-Robot Systems in Arbitrarily Complex Environments}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.065} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p65.pdf",
        "supp": "",
        "pdf_size": 2501216,
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3205494087823938198&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "aff": ";",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "6270364b30",
        "title": "Geometry-aware Tracking of Manipulability Ellipsoids",
        "site": "https://www.roboticsproceedings.org/rss14/p27.html",
        "author": "No\u00c3\u00a9mie Jaquier; Leonel Rozo; Darwin Caldwell; Sylvain Calinon",
        "abstract": "Body posture can greatly influence human performance when carrying out manipulation tasks. Adopting an appropriate pose helps us regulate our motion and strengthen our capability to achieve a given task. This effect is also observed in robotic manipulation where the robot joint configuration affects not only the ability to move freely in all directions in the workspace, but also the capability to generate forces along different axes. In this context, manipulability ellipsoids arise as a powerful descriptor to analyze, control and design the robot dexterity as a function of the articulatory joint configuration. This paper presents a new tracking control scheme in which the robot is requested to follow a desired profile of manipulability ellipsoids, either as its main task or as a secondary objective. The proposed formulation exploits tensor-based representations and takes into account that manipulability ellipsoids lie on the manifold of symmetric positive definite matrices. The proposed mathematical development is compatible with statistical methods providing 4th-order covariances, which are here exploited to reflect the tracking precision required by the task. Extensive evaluations in simulation and two experiments with a real redundant manipulator validate the feasibility of the approach, and show that this control formulation outperforms previously proposed approaches.",
        "bibtex": "@INPROCEEDINGS{Jaquier-RSS-18, \r\n    AUTHOR    = {No\u00c3\u00a9mie Jaquier AND Leonel Rozo AND Darwin Caldwell AND Sylvain Calinon}, \r\n    TITLE     = {Geometry-aware Tracking of Manipulability Ellipsoids}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.027} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p27.pdf",
        "supp": "",
        "pdf_size": 6661508,
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9540154023419711462&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "aff": "Idiap Research Institute; Idiap Research Institute + Department of Advanced Robotics, IIT; Department of Advanced Robotics, IIT; Idiap Research Institute + Department of Advanced Robotics, IIT",
        "aff_domain": "idiap.ch;iit.it;iit.it;idiap.ch",
        "email": "idiap.ch;iit.it;iit.it;idiap.ch",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;1;0+1",
        "aff_unique_norm": "Idiap Research Institute;Istituto Italiano di Tecnologia",
        "aff_unique_dep": ";Department of Advanced Robotics",
        "aff_unique_url": "https://www.idiap.ch;https://www.iit.it",
        "aff_unique_abbr": "Idiap;IIT",
        "aff_campus_unique_index": ";",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0+1;1;0+1",
        "aff_country_unique": "Switzerland;Italy"
    },
    {
        "id": "aba2515990",
        "title": "Handling implicit and explicit constraints in manipulation planning",
        "site": "https://www.roboticsproceedings.org/rss14/p18.html",
        "author": "Florent Lamiraux; Joseph Mirabel",
        "abstract": "This paper deals with manipulation planning. The problem consists in automatically computing paths for a system composed of one or several robots, with one or several grippers and one or several objects that can be grasped and moved by the robots. The problem gives rise to constraints that can be explicit -- an object is in a gripper -- or implicit -- an object is hold by two different grippers.   This paper proposes an algorithm that handles such sets of constraints and solves them in an explicit way as much as possible. When all constraints cannot be made explicit, substitution is operated between variables to make the resulting implicit constraint with as few variables as possible.   The manipulation planning problem is modelled as a constraint graph that stores all the constraints of the problem.",
        "bibtex": "@INPROCEEDINGS{Lamiraux-RSS-18, \r\n    AUTHOR    = {Florent Lamiraux AND Joseph Mirabel}, \r\n    TITLE     = {Handling implicit and explicit constraints in manipulation planning}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.018} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p18.pdf",
        "supp": "",
        "pdf_size": 969015,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6445777905137179658&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "LAAS, University of Toulouse, CNRS, Toulouse, France; LAAS, University of Toulouse, CNRS, Toulouse, France",
        "aff_domain": "laas.fr;laas.fr",
        "email": "laas.fr;laas.fr",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Toulouse",
        "aff_unique_dep": "LAAS",
        "aff_unique_url": "https://www.univ-toulouse.fr",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toulouse",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "93a29b023c",
        "title": "HyP-DESPOT: A Hybrid Parallel Algorithm for Online Planning under Uncertainty",
        "site": "https://www.roboticsproceedings.org/rss14/p04.html",
        "author": "Panpan Cai; Yuanfu Luo; David Hsu; Wee Sun Lee",
        "abstract": "Planning under uncertainty is critical for robust robot performance in uncertain, dynamic environments, but it incurs high computational cost. State-of-the-art online search algorithms, such as DESPOT, have vastly improved the computational efficiency of planning under uncertainty and made it a valuable tool for robotics in practice.  This work takes one step further by leveraging both CPU and GPU parallelization in order to achieve near real-time online planning performance for complex tasks with large state, action, and observation spaces.  Specifically,  we propose Hybrid Parallel DESPOT (HyP-DESPOT), a massively parallel online planning algorithm that integrates CPU and GPU parallelism in a multi-level scheme.  It performs parallel DESPOT tree search by simultaneously traversing multiple independent paths using multi-core CPUs and performs parallel Monte-Carlo simulations at the leaf nodes of the search tree using GPUs.  Experimental results show that HyP-DESPOT speeds up online planning by up to hundreds of times, compared with the original DESPOT, in several challenging robotic tasks in simulation.",
        "bibtex": "@INPROCEEDINGS{Cai-RSS-18, \r\n    AUTHOR    = {Panpan Cai AND Yuanfu Luo AND David Hsu AND Wee Sun Lee}, \r\n    TITLE     = {HyP-DESPOT: A Hybrid Parallel Algorithm for Online Planning under Uncertainty}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.004} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p04.pdf",
        "supp": "",
        "pdf_size": 2472361,
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9231440145760295348&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "0912725090",
        "title": "Improving Multi-Robot Behavior Using Learning-Based Receding Horizon Task Allocation",
        "site": "https://www.roboticsproceedings.org/rss14/p31.html",
        "author": "Philipp Schillinger; Mathias Buerger; Dimos Dimarogonas",
        "abstract": "Planning efficient and coordinated policies for a team of robots is a computationally demanding problem, especially when the system faces uncertainty in the outcome or duration of actions. In practice, approximation methods are usually employed to plan reasonable team policies in an acceptable time. At the same time, many typical robotic tasks include a repetitive pattern. On the one hand, this multiplies the increased cost of inefficient solutions. But on the other hand, it also provides the potential for improving an initial, inefficient solution over time. In this paper, we consider the case that a single mission specification is given to a multi-robot system, describing repetitive tasks which allow the robots to parallelize work. We propose here a decentralized coordination scheme which enables the robots to decompose the full specification, execute distributed tasks, and improve their strategy over time.",
        "bibtex": "@INPROCEEDINGS{Schillinger-RSS-18, \r\n    AUTHOR    = {Philipp Schillinger AND Mathias Buerger AND Dimos Dimarogonas}, \r\n    TITLE     = {Improving Multi-Robot Behavior Using Learning-Based Receding Horizon Task Allocation}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.031} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p31.pdf",
        "supp": "",
        "pdf_size": 405674,
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16736327926760956148&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Bosch Center for Artificial Intelligence, Renningen, Germany + KTH Centre for Autonomous Systems and ACCESS Linnaeus Center EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Bosch Center for Artificial Intelligence, Renningen, Germany; KTH Centre for Autonomous Systems and ACCESS Linnaeus Center EECS, KTH Royal Institute of Technology, Stockholm, Sweden",
        "aff_domain": "de.bosch.com;de.bosch.com;kth.se",
        "email": "de.bosch.com;de.bosch.com;kth.se",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;0;1",
        "aff_unique_norm": "Bosch Center for Artificial Intelligence;KTH Royal Institute of Technology",
        "aff_unique_dep": "Artificial Intelligence;Centre for Autonomous Systems and ACCESS Linnaeus Center EECS",
        "aff_unique_url": "https://www.bosch-ai.com;https://www.kth.se",
        "aff_unique_abbr": "BCAI;KTH",
        "aff_campus_unique_index": "0+1;0;1",
        "aff_campus_unique": "Renningen;Stockholm",
        "aff_country_unique_index": "0+1;0;1",
        "aff_country_unique": "Germany;Sweden"
    },
    {
        "id": "0256b04f1c",
        "title": "In-Hand Manipulation via Motion Cones",
        "site": "https://www.roboticsproceedings.org/rss14/p58.html",
        "author": "Nikhil Chavan Dafle; Rachel Holladay; Alberto Rodriguez",
        "abstract": "In this paper we present the mechanics and algorithms to compute the set of feasible motions of an object pushed in a plane. This set is known as the motion cone and was previously described for non-prehensile manipulation tasks in the horizontal plane. We generalize its geometric construction to a broader set of planar tasks, where external forces such as gravity influence the dynamics of pushing, and prehensile tasks, where there are complex interactions between the gripper, object, and pusher. We show that the motion cone is defined by a set of low-curvature surfaces and provide a polyhedral cone approximation to it. We verify its validity with 2000 pushing experiments recorded with motion tracking system. Motion cones abstract the algebra involved in simulating frictional pushing by providing bounds on the set of feasible motions and by characterizing which pushes will stick or slip. We demonstrate their use for the dynamic propagation step in a sampling-based planning algorithm for in-hand manipulation. The planner generates trajectories that involve sequences of continuous pushes with 5-1000x speed improvements to equivalent algorithms.",
        "bibtex": "@INPROCEEDINGS{Dafle-RSS-18, \r\n    AUTHOR    = {Nikhil Chavan Dafle AND Rachel Holladay AND Alberto Rodriguez}, \r\n    TITLE     = {In-Hand Manipulation via Motion Cones}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.058} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p58.pdf",
        "supp": "",
        "pdf_size": 2224701,
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4167948987053038755&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "aff_domain": "mit.edu;mit.edu;mit.edu",
        "email": "mit.edu;mit.edu;mit.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5eabfaaa2a",
        "title": "Interactive Visual Grounding of Referring Expressions for Human-Robot Interaction",
        "site": "https://www.roboticsproceedings.org/rss14/p28.html",
        "author": "Mohit Shridhar; David Hsu",
        "abstract": "This paper presents INGRESS, a robot system that follows human natural language instructions to pick and place everyday objects. The core issue here is the grounding of referring expressions: infer objects and their relationships from input images and language expressions. INGRESS allows for unconstrained object categories and unconstrained language expressions. Further, it asks questions to disambiguate referring expressions interactively. To achieve these, we take the approach of grounding by generation and propose a two-stage neural-network model for grounding. The first stage uses a neural network to generate visual descriptions of objects, compares them with the input language expression, and identifies a set of candidate objects. The second stage uses another neural network to examine all pairwise relations between the candidates and infers the most likely referred object. The same neural networks are used for both grounding and question generation for disambiguation. Experiments show that INGRESS outperformed a state-of-the-art method on the RefCOCO dataset and in robot experiments with humans.",
        "bibtex": "@INPROCEEDINGS{Shridhar-RSS-18, \r\n    AUTHOR    = {Mohit Shridhar AND David Hsu}, \r\n    TITLE     = {Interactive Visual Grounding of Referring Expressions for Human-Robot Interaction}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.028} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p28.pdf",
        "supp": "",
        "pdf_size": 5342472,
        "gs_citation": 159,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1668058095748391862&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "aff": "School of Computing, National University of Singapore; School of Computing, National University of Singapore",
        "aff_domain": "u.nus.edu;comp.nus.edu.sg",
        "email": "u.nus.edu;comp.nus.edu.sg",
        "github": "",
        "project": "http://bit.ly/INGRESSvid",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "e998d06788",
        "title": "Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations",
        "site": "https://www.roboticsproceedings.org/rss14/p49.html",
        "author": "Aravind Rajeswaran; Vikash Kumar; Abhishek Gupta; Giulia Vezzani; John Schulman; Emanuel Todorov; Sergey Levine",
        "abstract": "Dexterous multi-fingered hands are extremely versatile and provide a generic way to perform a multitude of tasks in human-centric environments. However, effectively controlling them remains challenging due to their high dimensionality and large number of potential contacts. Deep reinforcement learning (DRL) provides a model-agnostic approach to control complex dynamical systems, but has not been shown to scale to high-dimensional dexterous manipulation. Furthermore, deployment of DRL on physical systems remains challenging due to sample inefficiency. Consequently, the success of DRL in robotics has thus far been limited to simpler manipulators and tasks. In this work, we show that model-free DRL can effectively scale up to complex manipulation tasks with a high-dimensional 24-DoF hand, and solve them from scratch in simulated experiments. Furthermore, with the use of a small number of human demonstrations, the sample complexity can be significantly reduced, which enables learning with sample sizes equivalent to a few hours of robot experience. The use of demonstrations result in policies that exhibit very natural movements and, surprisingly, are also substantially more robust. We demonstrate successful policies for object relocation, in-hand manipulation, tool use, and door opening, which are shown in the supplementary video.",
        "bibtex": "@INPROCEEDINGS{Rajeswaran-RSS-18, \r\n    AUTHOR    = {Aravind Rajeswaran AND Vikash Kumar AND Abhishek Gupta AND Giulia Vezzani AND John Schulman AND Emanuel Todorov AND Sergey Levine}, \r\n    TITLE     = {Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.049} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p49.pdf",
        "supp": "",
        "pdf_size": 3047585,
        "gs_citation": 1325,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=517139139959431326&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "University of Washington Seattle; University of Washington Seattle + OpenAI; University of California Berkeley; Istituto Italiano di Tecnologia; OpenAI; University of Washington Seattle; University of California Berkeley",
        "aff_domain": "cs.washington.edu;cs.washington.edu; ; ; ; ; ",
        "email": "cs.washington.edu;cs.washington.edu; ; ; ; ; ",
        "github": "",
        "project": "http://sites.google.com/view/deeprl-dexterous-manipulation",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0+1;2;3;1;0;2",
        "aff_unique_norm": "University of Washington;OpenAI;University of California, Berkeley;Istituto Italiano di Tecnologia",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.washington.edu;https://openai.com;https://www.berkeley.edu;https://www.iit.it",
        "aff_unique_abbr": "UW;OpenAI;UC Berkeley;IIT",
        "aff_campus_unique_index": "0;0;2;0;2",
        "aff_campus_unique": "Seattle;;Berkeley",
        "aff_country_unique_index": "0;0+0;0;1;0;0;0",
        "aff_country_unique": "United States;Italy"
    },
    {
        "id": "b3d4f6bbc1",
        "title": "Learning Task-Oriented Grasping for Tool Manipulation from Simulated Self-Supervision",
        "site": "https://www.roboticsproceedings.org/rss14/p12.html",
        "author": "Kuan Fang; Yuke Zhu; Animesh Garg; Andrey Kurenkov; Viraj  Mehta; Li Fei-Fei; Silvio Savarese",
        "abstract": "Tool manipulation is vital for facilitating robots to complete challenging task goals. It requires reasoning about the desired effect of the task and thus properly grasping and manipulating the tool to achieve the task. Task-agnostic grasping optimizes for grasp robustness while ignoring crucial task-specific constraints. In this paper, we propose the Task-Oriented Grasping Network (TOG-Net) to jointly optimize both task-oriented grasping of a tool and the manipulation policy for that tool. The training process of the model is based on large-scale simulated self-supervision with procedurally generated tool objects. We perform both simulated and real-world experiments on two tool-based manipulation tasks: sweeping and hammering. Our model achieves overall 71.1% task success rate for sweeping and 80.0% task success rate for hammering. Supplementary material is available at: bit.ly/task-oriented-grasp.",
        "bibtex": "@INPROCEEDINGS{Fang-RSS-18, \r\n    AUTHOR    = {Kuan Fang AND Yuke Zhu AND Animesh Garg AND Andrey Kurenkov AND Viraj  Mehta AND Li Fei-Fei AND Silvio Savarese}, \r\n    TITLE     = {Learning Task-Oriented Grasping for Tool Manipulation from Simulated Self-Supervision}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.012} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p12.pdf",
        "supp": "",
        "pdf_size": 6171025,
        "gs_citation": 259,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14617354787559265698&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 18,
        "aff": "Stanford University, Stanford, CA 94305 USA; Stanford University, Stanford, CA 94305 USA; Stanford University, Stanford, CA 94305 USA; Stanford University, Stanford, CA 94305 USA; Stanford University, Stanford, CA 94305 USA; Stanford University, Stanford, CA 94305 USA; Stanford University, Stanford, CA 94305 USA",
        "aff_domain": ";;;;;;",
        "email": ";;;;;;",
        "github": "",
        "project": "bit.ly/task-oriented-grasp",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9cf6a1aa92",
        "title": "Lightweight Unsupervised Deep Loop Closure",
        "site": "https://www.roboticsproceedings.org/rss14/p32.html",
        "author": "Nathaniel  Merrill; Guoquan  Huang",
        "abstract": "Robust efficient loop closure detection is essential for large-scale real-time SLAM. In this paper, we propose a novel unsupervised deep neural network architecture of a feature embedding for visual loop closure that is both reliable and compact. Our model is built upon the autoencoder architecture, tailored specifically to the problem at hand. To train our network, we inflict random noise on our input data as the denoising autoencoder does, but, instead of applying random dropout, we warp images with randomized projective transformations to emulate natural viewpoint changes due to robot motion. Moreover, we utilize the geometric information and illumination invariance provided by histogram of oriented gradients (HOG), forcing the encoder to reconstruct a HOG descriptor instead of the original image. As a result, our trained model extracts features robust to extreme variations in appearance directly from raw images, without the need for labeled training data or environment-specific training. We perform extensive experiments on various challenging datasets, showing that the proposed deep loop-closure model consistently outperforms the state-of-the-art methods in terms of effectiveness and efficiency. Our model is fast and reliable enough to close loops in real time with no dimensionality reduction, and capable of replacing generic off-the-shelf networks in state-of-the-art ConvNet-based loop closure systems.",
        "bibtex": "@INPROCEEDINGS{Merrill-RSS-18, \r\n    AUTHOR    = {Nathaniel  Merrill AND Guoquan  Huang}, \r\n    TITLE     = {Lightweight Unsupervised Deep Loop Closure}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.032} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p32.pdf",
        "supp": "",
        "pdf_size": 3066715,
        "gs_citation": 197,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7730112749983933923&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Dept. of Computer and Information Sciences and Dept. of Mechanical Engineering, University of Delaware; Dept. of Computer and Information Sciences and Dept. of Mechanical Engineering, University of Delaware",
        "aff_domain": "udel.edu;udel.edu",
        "email": "udel.edu;udel.edu",
        "github": "https://github.com/rpng/calc",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Dept. of Computer and Information Sciences",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5c048c4274",
        "title": "LoST? Appearance-Invariant Place Recognition for Opposite Viewpoints using Visual Semantics",
        "site": "https://www.roboticsproceedings.org/rss14/p22.html",
        "author": "Sourav Garg; Niko Suenderhauf; Michael Milford",
        "abstract": "Human visual scene understanding is so remarkable that we are able to recognize a revisited place when entering it from the opposite direction it was first visited, even in the presence of extreme variations in appearance. This capability is especially apparent during driving: a human driver can recognize where they are when traveling in the reverse direction along a route for the first time, without having to turn back and look. The difficulty of this problem exceeds any addressed in past appearance- and viewpoint-invariant visual place recognition (VPR) research, in part because large parts of the scene are not commonly observable from opposite directions. Consequently, as shown in this paper, the precision-recall performance of current state-of-the-art viewpoint- and appearance-invariant VPR techniques is orders of magnitude below what would be usable in a closed-loop system. Current engineered solutions predominantly rely on panoramic camera or LIDAR sensing setups; an eminently suitable engineering solution but one that is clearly very different to how humans navigate, which also has implications for how naturally humans could interact and communicate with the navigation system. In this paper, we develop a suite of novel semantic- and appearance-based techniques to enable for the first time high-performance place recognition in this challenging scenario. We first propose a novel Local Semantic Tensor (LoST) descriptor of images using the convolutional feature maps from a state-of-the-art dense semantic segmentation network. Then, to verify the spatial semantic arrangement of the top matching candidates, we develop a novel approach for mining semantically-salient keypoint correspondences. On publicly available benchmark datasets that involve both 180-degree viewpoint change and extreme appearance change, we show how meaningful recall at 100% precision can be achieved using our proposed system where existing systems often fail to ever reach 100% precision. We also present analysis delving into the performance differences between a current and the proposed system and characterize unique properties of the opposite direction localization problem including the metric matching offset. The source code is available online at https://github.com/oravus/lostX.",
        "bibtex": "@INPROCEEDINGS{Garg-RSS-18, \r\n    AUTHOR    = {Sourav Garg AND Niko Suenderhauf AND Michael Milford}, \r\n    TITLE     = {LoST? Appearance-Invariant Place Recognition for Opposite Viewpoints using Visual Semantics}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.022} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p22.pdf",
        "supp": "",
        "pdf_size": 9104947,
        "gs_citation": 160,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7274527830344267357&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "aff": "Australian Centre for Robotic Vision, Robotics and Autonomous Systems, Queensland University of Technology, Brisbane; Australian Centre for Robotic Vision, Robotics and Autonomous Systems, Queensland University of Technology, Brisbane; Australian Centre for Robotic Vision, Robotics and Autonomous Systems, Queensland University of Technology, Brisbane",
        "aff_domain": "hdr.qut.edu.au; ; ",
        "email": "hdr.qut.edu.au; ; ",
        "github": "https://github.com/oravus/lostX",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queensland University of Technology",
        "aff_unique_dep": "Australian Centre for Robotic Vision, Robotics and Autonomous Systems",
        "aff_unique_url": "https://www.qut.edu.au",
        "aff_unique_abbr": "QUT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "87ed08dfe5",
        "title": "Multi-Objective Analysis of Ridesharing in Automated Mobility-on-Demand",
        "site": "https://www.roboticsproceedings.org/rss14/p39.html",
        "author": "Michal Cap; Javier Alonso-Mora",
        "abstract": "Self-driving technology is expected to enable the realization of large-scale mobility-on-demand systems that employ massive ridesharing.  The technology is being celebrated as a potential cure for urban congestion and others negative externalities of individual automobile transportation.  In this paper we quantify the potential of ridesharing with a fleet of autonomous vehicles by considering all possible trade-offs between the quality of service and operation cost of the system that can be achieved by sharing rides. We formulate a multi-objective fleet routing problem and present a solution technique that can compute Pareto-optimal fleet operation plans that achieve different trade-offs between the two objectives. Given a set of requests and a set of vehicles, our method can recover a trade-off curve that quantifies the potential of ridesharing with given fleet. We provide a formal optimality proof and demonstrate that the proposed method is scalable and able to compute such trade-off curves for instances with hundreds of vehicles and requests optimally. Such an analytical tool helps with systematic design of shared mobility system, in particular, it can be used to do principled decisions about the required fleet size.",
        "bibtex": "@INPROCEEDINGS{Cap-RSS-18, \r\n    AUTHOR    = {Michal Cap AND Javier Alonso-Mora}, \r\n    TITLE     = {Multi-Objective Analysis of Ridesharing in Automated Mobility-on-Demand}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.039} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p39.pdf",
        "supp": "",
        "pdf_size": 1197001,
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17442449621776020189&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "aff": "Dept. of Cognitive Robotics, 3ME, TU Delft, the Netherlands; Dept. of Cognitive Robotics, 3ME, TU Delft, the Netherlands",
        "aff_domain": ";",
        "email": ";",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Department of Cognitive Robotics",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "91c933389e",
        "title": "Near-Optimal Budgeted Data Exchange for Distributed Loop Closure Detection",
        "site": "https://www.roboticsproceedings.org/rss14/p71.html",
        "author": "Yulun Tian; Kasra Khosoussi; Matthew Giamou; Jonathan How; Jonathan Kelly",
        "abstract": "Inter-robot loop closure detection is a core problem in collaborative SLAM (CSLAM). Establishing inter-robot loop closures is a resource-demanding process, during which robots must consume a substantial amount of mission-critical resources (e.g., battery and bandwidth) to exchange sensory data. However, even with the most resource-efficient techniques, the resources available onboard may be insufficient for verifying every potential loop closure. This work addresses this critical challenge by proposing a resource-adaptive framework for distributed loop closure detection. We seek to maximize task-oriented objectives subject to a budget constraint on total data transmission. This problem is in general NP-hard. We approach this problem from different perspectives and leverage existing results on monotone submodular maximization to provide efficient approximation algorithms with performance guarantees. The proposed approach is extensively evaluated using the KITTI odometry benchmark dataset and synthetic Manhattan-like datasets.",
        "bibtex": "@INPROCEEDINGS{Tian-RSS-18, \r\n    AUTHOR    = {Yulun Tian AND Kasra Khosoussi AND Matthew Giamou AND Jonathan How AND Jonathan Kelly}, \r\n    TITLE     = {Near-Optimal Budgeted Data Exchange for Distributed Loop Closure Detection}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.071} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p71.pdf",
        "supp": "",
        "pdf_size": 477222,
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=686715859794194341&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": "Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology; Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology; Space & Terrestrial Autonomous Robotic Systems (STARS) Laboratory, University of Toronto Institute for Aerospace Studies (UTIAS); Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology; Space & Terrestrial Autonomous Robotic Systems (STARS) Laboratory, University of Toronto Institute for Aerospace Studies (UTIAS)",
        "aff_domain": "mit.edu;mit.edu;robotics.utias.utoronto.ca;mit.edu;robotics.utias.utoronto.ca",
        "email": "mit.edu;mit.edu;robotics.utias.utoronto.ca;mit.edu;robotics.utias.utoronto.ca",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Toronto Institute for Aerospace Studies",
        "aff_unique_dep": "Laboratory for Information and Decision Systems (LIDS);Space & Terrestrial Autonomous Robotic Systems Laboratory",
        "aff_unique_url": "https://web.mit.edu;https://www.ias.uToronto.ca",
        "aff_unique_abbr": "MIT;UTIAS",
        "aff_campus_unique_index": "0;0;1;0;1",
        "aff_campus_unique": "Cambridge;Toronto",
        "aff_country_unique_index": "0;0;1;0;1",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "961a889b65",
        "title": "On the interaction between Autonomous Mobility-on-Demand systems and the power network: models and coordination algorithms",
        "site": "https://www.roboticsproceedings.org/rss14/p37.html",
        "author": "Federico Rossi; Ramon Iglesias; Mahnoosh Alizadeh; Marco Pavone",
        "abstract": "This paper studies the interaction between a fleet of electric, self-driving vehicles servicing on-demand transportation requests (referred to as Autonomous Mobility-on-Demand, or AMoD, system) and the electric power network. We propose a joint linear model that captures the coupling between the two systems stemming from the vehicles\u2019 charging requirements. The model subsumes existing network flow models for AMoD systems and DC models for the power network, and it captures time-varying customer demand and power generation costs, road congestion, and power transmission and distribution constraints. We then leverage the model to jointly optimize the operation of both systems. We devise an algorithmic procedure to losslessly reduce the problem size by bundling customer requests, allowing it to be efficiently solved by off-the-shelf linear programming solvers. We then study the implementation of a hypothetical electric-powered AMoD system in Dallas-Fort Worth, and its impact on the Texas power network. We show that coordination between the AMoD system and the power network can reduce the overall energy expenditure compared to the case where no cars are present (despite the increased demand for electricity) and yield savings of $182M/year compared to an uncoordinated scenario. Finally, we provide a closed-loop receding-horizon implementation. Collectively, the results of this paper provide a first-of-a-kind characterization of the interaction between electric-powered AMoD systems and the power network, and shed additional light on the economic and societal value of AMoD.",
        "bibtex": "@INPROCEEDINGS{Rossi-RSS-18, \r\n    AUTHOR    = {Federico Rossi AND Ramon Iglesias AND Mahnoosh Alizadeh AND Marco Pavone}, \r\n    TITLE     = {On the interaction between Autonomous Mobility-on-Demand systems and the power network: models and coordination algorithms}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.037} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p37.pdf",
        "supp": "",
        "pdf_size": 1405859,
        "gs_citation": 145,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14056677373323035798&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "Department of Aeronautics & Astronautics, Stanford University; Department of Civil and Environmental Engineering, Stanford University; Electrical & Computer Engineering Department, University of California, Santa Barbara; Department of Aeronautics & Astronautics, Stanford University",
        "aff_domain": "stanford.edu;stanford.edu;ece.ucsb.edu;stanford.edu",
        "email": "stanford.edu;stanford.edu;ece.ucsb.edu;stanford.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Stanford University;University of California, Santa Barbara",
        "aff_unique_dep": "Department of Aeronautics & Astronautics;Electrical & Computer Engineering Department",
        "aff_unique_url": "https://www.stanford.edu;https://www.ucsb.edu",
        "aff_unique_abbr": "Stanford;UCSB",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Stanford;Santa Barbara",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f5c908826d",
        "title": "One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning",
        "site": "https://www.roboticsproceedings.org/rss14/p02.html",
        "author": "Tianhe Yu; Chelsea Finn; Sudeep Dasari; Annie Xie; Tianhao Zhang; Pieter Abbeel; Sergey Levine",
        "abstract": "Humans and animals are capable of learning a new behavior by observing others perform the skill just once. We consider the problem of allowing a robot to do the same -- learning from a video of a human, even when there is domain shift in the perspective, environment, and embodiment between the robot and the observed human. Prior approaches to this problem have hand-specified how human and robot actions correspond and often relied on explicit human pose detection systems. In this work, we present an approach for one-shot learning from a video of a human by using human and robot demonstration data from a variety of previous tasks to build up prior knowledge through meta-learning. Then, combining this prior knowledge and only a single video demonstration from a human, the robot can perform the task that the human demonstrated. We show experiments on both a PR2 arm and a Sawyer arm, demonstrating that after meta-learning, the robot can learn to place, push, and pick-and-place new objects using just one video of a human performing the manipulation.",
        "bibtex": "@INPROCEEDINGS{Yu-RSS-18, \r\n    AUTHOR    = {Tianhe Yu AND Chelsea Finn AND Sudeep Dasari AND Annie Xie AND Tianhao Zhang AND Pieter Abbeel AND Sergey Levine}, \r\n    TITLE     = {One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.002} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p02.pdf",
        "supp": "",
        "pdf_size": 8447332,
        "gs_citation": 435,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14497349184750486315&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley",
        "aff_domain": "berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu",
        "email": "berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu",
        "github": "",
        "project": "https://sites.google.com/view/daml",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "571b813e81",
        "title": "Online User Assessment for Minimal Intervention During Task-Based Robotic Assistance",
        "site": "https://www.roboticsproceedings.org/rss14/p46.html",
        "author": "Aleksandra Kalinowska; Kathleen Fitzsimons; Julius Dewald; Todd Murphey",
        "abstract": "We propose a novel criterion for evaluating user input for human-robot interfaces for known tasks. We use the mode insertion gradient (MIG)---a tool from hybrid control theory---as a filtering criterion that instantaneously assesses the impact of user actions on a dynamic system over a time window into the future. As a result, the filter is permissive to many chosen strategies, minimally engaging, and skill-sensitive---qualities desired when evaluating human actions. Through a human study with 28 healthy volunteers, we show that the criterion exhibits a low, but significant, negative correlation between skill level, as estimated from task-specific measures in unassisted trials, and the rate of controller intervention during assistance. Moreover, a MIG-based filter can be utilized to create a shared control scheme for training or assistance. In the human study, we observe a substantial training effect when using a MIG-based filter to perform cart-pendulum inversion, particularly when comparing improvement via the RMS error measure. Using simulation of a controlled spring-loaded inverted pendulum (SLIP) as a test case, we observe that the MIG criterion could be used for assistance to guarantee either task completion or safety of a joint human-robot system, while maintaining the system's flexibility with respect to user-chosen strategies.",
        "bibtex": "@INPROCEEDINGS{Kalinowska-RSS-18, \r\n    AUTHOR    = {Aleksandra Kalinowska AND Kathleen Fitzsimons AND Julius Dewald AND Todd Murphey}, \r\n    TITLE     = {Online User Assessment for Minimal Intervention During Task-Based Robotic Assistance}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.046} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p46.pdf",
        "supp": "",
        "pdf_size": 1427768,
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3914525660580754167&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 13,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "dc2d53c25a",
        "title": "Optimal Solution of the Generalized Dubins Interval Problem",
        "site": "https://www.roboticsproceedings.org/rss14/p35.html",
        "author": "Petr V\u00e1\u0148a; Jan Faigl",
        "abstract": "The problem addressed in this paper is motivated by surveillance mission planning with curvature-constrained trajectories for Dubins vehicles that can be formulated as the Dubins Traveling Salesman Problem with Neighborhoods (DTSPN). We aim to provide a tight lower bound of the DTSPN, especially for the cases where the sequence of visits to the given regions is available. A problem to find the shortest Dubins path connecting two regions with prescribed intervals for possible departure and arrival heading angles of the vehicle is introduced. This new problem is called the Generalized Dubins Interval Problem (GDIP) and its optimal solution is addressed. Based on the solution of the GDIP, a tight lower bound of the above mentioned DTSPN is provided which is used to steer sampling-based algorithm to determine a feasible solution that is close to the optimum.",
        "bibtex": "@INPROCEEDINGS{V\u00e1\u0148a-RSS-18, \r\n    AUTHOR    = {Petr V\u00e1\u0148a AND Jan Faigl}, \r\n    TITLE     = {Optimal Solution of the Generalized Dubins Interval Problem}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.035} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p35.pdf",
        "supp": "",
        "pdf_size": 772658,
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1574468847925065339&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "aff": "Dept. of Computer Science, Czech Technical University in Prague; Dept. of Computer Science, Czech Technical University in Prague",
        "aff_domain": "fel.cvut.cz;fel.cvut.cz",
        "email": "fel.cvut.cz;fel.cvut.cz",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Dept. of Computer Science",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "2f7697c74b",
        "title": "Passive Static Equilibrium with Frictional Contacts and Application to Grasp Stability Analysis",
        "site": "https://www.roboticsproceedings.org/rss14/p64.html",
        "author": "Maximilian Haas-Heger; Christos  Papadimitriou; Mihalis Yannakakis; Garud Iyengar; Matei Ciocarlie",
        "abstract": "This paper studies the problem of passive grasp stability under an external disturbance, that is, the ability of a grasp to resist a disturbance through passive responses at the contacts. To obtain physically consistent results, such a model must account for friction phenomena at each contact; the difficulty is that friction forces depend in non-linear fashion on contact behavior (stick or slip). We develop the first polynomial- time algorithm which either solves such complex equilibrium constraints for two-dimensional grasps, or otherwise concludes that no solution exists. To achieve this, we show that the number of possible \u201cslip states\u201d (where each contact is labeled as either sticking or slipping) that must be considered is polynomial (in fact quadratic) in the number of contacts, and not exponential as previously thought. Our algorithm captures passive response behaviors at each contact, while accounting for constraints on friction forces such as the maximum dissipation principle.",
        "bibtex": "@INPROCEEDINGS{Haas-Heger-RSS-18, \r\n    AUTHOR    = {Maximilian Haas-Heger AND Christos  Papadimitriou AND Mihalis Yannakakis AND Garud Iyengar AND Matei Ciocarlie}, \r\n    TITLE     = {Passive Static Equilibrium with Frictional Contacts and Application to Grasp Stability Analysis}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.064} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p64.pdf",
        "supp": "",
        "pdf_size": 639328,
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10293702549373300749&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Mechanical Engineering; Department of Computer Science; Department of Computer Science; Department of Industrial Engineering and Operations Research; Department of Mechanical Engineering",
        "aff_domain": "columbia.edu;cs.columbia.edu;cs.columbia.edu;ieor.columbia.edu;columbia.edu",
        "email": "columbia.edu;cs.columbia.edu;cs.columbia.edu;ieor.columbia.edu;columbia.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1;2;0",
        "aff_unique_norm": "Mechanical Engineering;Unknown Institution;University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Computer Science;Department of Industrial Engineering and Operations Research",
        "aff_unique_url": ";;https://ieor.berkeley.edu",
        "aff_unique_abbr": ";;UC Berkeley IEOR",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "e6bc61bdd4",
        "title": "Plug-and-Play Supervisory Control Using Muscle and Brain Signals for Real-Time Gesture and Error Detection",
        "site": "https://www.roboticsproceedings.org/rss14/p63.html",
        "author": "Joseph DelPreto; Andres F. Salazar-Gomez; Stephanie Gil; Ramin M. Hasani; Frank H. Guenther; Daniela  Rus",
        "abstract": "Control of robots in safety-critical tasks and situations where costly errors may occur is paramount for realizing the vision of pervasive human-robot collaborations.  For these cases, the ability to use human cognition in the loop can be key for recuperating safe robot operation.  This paper combines two streams of human biosignals, electrical muscle and brain activity via EMG and EEG, respectively, to achieve fast and accurate human intervention in a supervisory control task.  In particular, this paper presents an end-to-end system for continuous rolling-window classification of gestures that allows the human to actively correct the robot on demand, discrete classification of Error-Related Potential signals (unconsciously produced by the human supervisor's brain when observing a robot error), and a framework that integrates these two classification streams for fast and effective human intervention.  The system also allows 'plug-and-play' operation, demonstrating accurate performance even with new users whose biosignals have not been used for training the classifiers.  The resulting hybrid control system for safety-critical situations is evaluated with 7 untrained human subjects in a supervisory control scenario where an autonomous robot performs a multi-target selection task.",
        "bibtex": "@INPROCEEDINGS{DelPreto-RSS-18, \r\n    AUTHOR    = {Joseph DelPreto AND Andres F. Salazar-Gomez AND Stephanie Gil AND Ramin M. Hasani AND Frank H. Guenther AND Daniela  Rus}, \r\n    TITLE     = {Plug-and-Play Supervisory Control Using Muscle and Brain Signals for Real-Time Gesture and Error Detection}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.063} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p63.pdf",
        "supp": "",
        "pdf_size": 10095044,
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13986159944165700343&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 21,
        "aff": "MIT Distributed Robotics Lab, Cambridge, MA 02139; MIT Distributed Robotics Lab, Cambridge, MA 02139; MIT Distributed Robotics Lab, Cambridge, MA 02139; Vienna University of Technology Cyber-Physical Systems Group, Austria; Boston University Guenther Lab, Boston, MA 02215; MIT Distributed Robotics Lab, Cambridge, MA 02139",
        "aff_domain": "csail.mit.edu;csail.mit.edu;csail.mit.edu;tuwien.ac.at;bu.edu;csail.mit.edu",
        "email": "csail.mit.edu;csail.mit.edu;csail.mit.edu;tuwien.ac.at;bu.edu;csail.mit.edu",
        "github": "",
        "project": "http://people.csail.mit.edu/delpreto/rss2018",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Vienna University of Technology;Boston University",
        "aff_unique_dep": "Distributed Robotics Lab;Cyber-Physical Systems Group;Guenther Lab",
        "aff_unique_url": "https://web.mit.edu;https://www.tuwien.ac.at;https://www.bu.edu",
        "aff_unique_abbr": "MIT;TU Wien;BU",
        "aff_campus_unique_index": "0;0;0;2;0",
        "aff_campus_unique": "Cambridge;;Boston",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United States;Austria"
    },
    {
        "id": "59b8e5d276",
        "title": "PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes",
        "site": "https://www.roboticsproceedings.org/rss14/p19.html",
        "author": "Yu Xiang; Tanner Schmidt; Venkatraman Narayanan; Dieter Fox",
        "abstract": "Estimating the 6D pose of known objects is important for robots to interact with the real world. The problem is challenging due to the variety of objects as well as the complexity of a scene caused by clutter and occlusions between objects. In this work, we introduce PoseCNN, a new Convolutional Neural Network for 6D object pose estimation. PoseCNN estimates the 3D translation of an object by localizing its center in the image and predicting its distance from the camera. The 3D rotation of the object is estimated by regressing to a quaternion representation. We also introduce a novel loss function that enables PoseCNN to handle symmetric objects. In addition, we contribute a large scale video dataset for 6D object pose estimation named the YCB-Video dataset. Our dataset provides accurate 6D poses of 21 objects from the YCB dataset observed in 92 videos with 133,827 frames. We conduct extensive experiments on our YCB-Video dataset and the OccludedLINEMOD dataset to show that PoseCNN is highly robust to occlusions, can handle symmetric objects, and provide accurate pose estimation using only color images as input. When using depth data to further refine the poses, our approach achieves state-of-the-art results on the challenging OccludedLINEMOD dataset. Our code and dataset are available at https://rse-lab.cs.washington.edu/projects/posecnn/.",
        "bibtex": "@INPROCEEDINGS{Xiang-RSS-18, \r\n    AUTHOR    = {Yu Xiang AND Tanner Schmidt AND Venkatraman Narayanan AND Dieter Fox}, \r\n    TITLE     = {PoseCNN: A Convolutional Neural Network for 6D Object Pose Estimation in Cluttered Scenes}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.019} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p19.pdf",
        "supp": "",
        "pdf_size": 4168793,
        "gs_citation": 2452,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11360676440004425199&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 15,
        "aff": "NVIDIA Research; University of Washington; Carnegie Mellon University; NVIDIA Research + University of Washington",
        "aff_domain": "nvidia.com;cs.washington.edu;cs.cmu.edu;nvidia.com",
        "email": "nvidia.com;cs.washington.edu;cs.cmu.edu;nvidia.com",
        "github": "",
        "project": "https://rse-lab.cs.washington.edu/projects/posecnn/",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;2;0+1",
        "aff_unique_norm": "NVIDIA;University of Washington;Carnegie Mellon University",
        "aff_unique_dep": "NVIDIA Research;;",
        "aff_unique_url": "https://www.nvidia.com/research;https://www.washington.edu;https://www.cmu.edu",
        "aff_unique_abbr": "NVIDIA;UW;CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0+0",
        "aff_country_unique": "United States"
    },
    {
        "id": "2d2b1b41e1",
        "title": "Probabilistically Safe Robot Planning with Confidence-Based Human Predictions",
        "site": "https://www.roboticsproceedings.org/rss14/p69.html",
        "author": "Jaime Fisac; Andrea Bajcsy; Sylvia Herbert; David Fridovich-Keil; Steven Wang; Claire Tomlin; Anca Dragan",
        "abstract": "In order to safely operate around humans, robots can employ predictive models of human motion. Unfortunately, these models cannot capture the full complexity of human behavior and necessarily introduce simplifying assumptions. As a result, predictions may degrade whenever the observed human behavior departs from the assumed structure, which can have negative implications for safety. In this paper, we observe that how rational human actions appear under a particular model can be viewed as an indicator of that model's ability to describe the human's current motion. By reasoning about this model confidence in a real-time Bayesian framework, we show that the robot can very quickly modulate its predictions to become more uncertain when the model performs poorly. Building on recent work in provably-safe trajectory planning, we leverage these confidence-aware human motion predictions to generate assured autonomous robot motion. Our new analysis combines worst-case tracking error guarantees for the physical robot with probabilistic time-varying human predictions, yielding a quantitative, probabilistic safety certificate. We demonstrate our approach with a quadcopter navigating around a human.",
        "bibtex": "@INPROCEEDINGS{Fisac-RSS-18, \r\n    AUTHOR    = {Jaime Fisac AND Andrea Bajcsy AND Sylvia Herbert AND David Fridovich-Keil AND Steven Wang AND Claire Tomlin AND Anca Dragan}, \r\n    TITLE     = {Probabilistically Safe Robot Planning with Confidence-Based Human Predictions}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.069} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p69.pdf",
        "supp": "",
        "pdf_size": 9707459,
        "gs_citation": 169,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16787347265291079195&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley; Department of Electrical Engineering and Computer Sciences, University of California, Berkeley",
        "aff_domain": "berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu",
        "email": "berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu;berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 7,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "1383d762c6",
        "title": "Push-Net: Deep Planar Pushing for Objects with Unknown Physical Properties",
        "site": "https://www.roboticsproceedings.org/rss14/p24.html",
        "author": "Juekun Li; Wee Sun Lee; David Hsu",
        "abstract": "This paper introduces Push-Net, a deep recurrent neural network model, which enables a robot to push ob- jects of unknown physical properties for re-positioning and re-orientation, using only visual camera images as input. The unknown physical properties is a major challenge for pushing. Push-Net overcomes the challenge by tracking a history of push interactions with an LSTM module and training an auxiliary objective function that estimates an object\u2019s center of mass. We trained Push-Net entirely in simulation and tested it extensively on many different objects in both simulation and on two real robots, a Fetch arm and a Kinova MICO arm. Experiments suggest that Push-Net is robust and efficient. It achieved over 97% success rate in simulation on average and succeeded in all real robot experiments with a small number of pushes.",
        "bibtex": "@INPROCEEDINGS{Li-RSS-18, \r\n    AUTHOR    = {Juekun Li AND Wee Sun Lee AND David Hsu}, \r\n    TITLE     = {Push-Net: Deep Planar Pushing for Objects with Unknown Physical Properties}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.024} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p24.pdf",
        "supp": "",
        "pdf_size": 7606974,
        "gs_citation": 87,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17240678123369897765&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 0,
        "aff": ";;",
        "aff_domain": ";;",
        "email": ";;",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "cfac11665a",
        "title": "Reinforcement and Imitation Learning for Diverse Visuomotor Skills",
        "site": "https://www.roboticsproceedings.org/rss14/p09.html",
        "author": "Yuke Zhu; Ziyu Wang; Josh Merel; Andrei Rusu; Tom Erez; Serkan Cabi; Saran  Tunyasuvunakool; J\u00c3\u00a1nos Kram\u00c3\u00a1r; Raia Hadsell; Nando de Freitas; Nicolas Heess",
        "abstract": "We propose a general model-free deep reinforcement learning method and apply it to robotic manipulation tasks. Our approach leverages a small amount of demonstration data to assist a reinforcement learning agent. We train end-to-end visuomotor policies to learn a direct mapping from RGB camera inputs to joint velocities. We demonstrate that the same agent, trained with the same algorithm, can solve a wide variety of visuomotor tasks, where engineering a scripted controller can be laborious. In experiments, our reinforcement and imitation agent achieves significantly better performances than agents trained with reinforcement learning or imitation learning alone. We also illustrate that these policies, trained with large visual and dynamics variations, can achieve preliminary successes in zero-shot sim2real transfer.",
        "bibtex": "@INPROCEEDINGS{Zhu-RSS-18, \r\n    AUTHOR    = {Yuke Zhu AND Ziyu Wang AND Josh Merel AND Andrei Rusu AND Tom Erez AND Serkan Cabi AND Saran  Tunyasuvunakool AND J\u00c3\u00a1nos Kram\u00c3\u00a1r AND Raia Hadsell AND Nando de Freitas AND Nicolas Heess}, \r\n    TITLE     = {Reinforcement and Imitation Learning for Diverse Visuomotor Skills}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.009} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p09.pdf",
        "supp": "",
        "pdf_size": 6179546,
        "gs_citation": 398,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16353226391702260751&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "aff": "Computer Science Department, Stanford University, USA+DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK; DeepMind, London, UK",
        "aff_domain": "cs.stanford.edu; ; ; ; ; ; ; ; ; ; ",
        "email": "cs.stanford.edu; ; ; ; ; ; ; ; ; ; ",
        "github": "",
        "project": "",
        "author_num": 11,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0+1;1;1;1;1;1;1;1;1;1;1",
        "aff_unique_norm": "Stanford University;DeepMind",
        "aff_unique_dep": "Computer Science Department;",
        "aff_unique_url": "https://www.stanford.edu;https://deepmind.com",
        "aff_unique_abbr": "Stanford;DeepMind",
        "aff_campus_unique_index": "0+1;1;1;1;1;1;1;1;1;1;1",
        "aff_campus_unique": "Stanford;London",
        "aff_country_unique_index": "0+1;1;1;1;1;1;1;1;1;1;1",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "75dfa28b49",
        "title": "RelaxedIK: Real-time Synthesis of Accurate and Feasible Robot Arm Motion",
        "site": "https://www.roboticsproceedings.org/rss14/p43.html",
        "author": "Daniel Rakita; Bilge Mutlu; Michael Gleicher",
        "abstract": "We present a real-time motion-synthesis method for robot manipulators, called RelaxedIK, that is able to not only accurately match end-effector pose goals as done by traditional IK solvers, but also create smooth, feasible motions that avoid joint-space discontinuities, self-collisions, and kinematic singularities.  To achieve these objectives on-the-fly, we cast the standard IK formulation as a weighted-sum non-linear optimization problem, such that motion goals in addition to end-effector pose matching can be encoded as terms in the sum.  We present a normalization procedure such that our method is able to effectively make trade-offs to simultaneously reconcile many, and potentially competing, objectives.  Using these trade-offs, our formulation allows features to be relaxed when in conflict with other features deemed more important at a given time.  We compare performance against a state-of-the-art IK solver and a real-time motion-planning approach in several geometric and real-world tasks on seven robot platforms ranging from 5-DOF to 8-DOF.  We show that our method achieves motions that effectively follow position and orientation end-effector goals without sacrificing motion feasibility, resulting in more successful execution of tasks compared to the baseline approaches.",
        "bibtex": "@INPROCEEDINGS{Rakita-RSS-18, \r\n    AUTHOR    = {Daniel Rakita AND Bilge Mutlu AND Michael Gleicher}, \r\n    TITLE     = {RelaxedIK: Real-time Synthesis of Accurate and Feasible Robot Arm Motion}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.043} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p43.pdf",
        "supp": "",
        "pdf_size": 2474614,
        "gs_citation": 142,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8358970669977750030&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Computer Sciences, University of Wisconsin\u2013Madison; Department of Computer Sciences, University of Wisconsin\u2013Madison; Department of Computer Sciences, University of Wisconsin\u2013Madison",
        "aff_domain": "cs.wisc.edu;cs.wisc.edu;cs.wisc.edu",
        "email": "cs.wisc.edu;cs.wisc.edu;cs.wisc.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Wisconsin\u2013Madison",
        "aff_unique_dep": "Department of Computer Sciences",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW\u2013Madison",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4cb35c4c4f",
        "title": "Robust Obstacle Avoidance using Tube NMPC",
        "site": "https://www.roboticsproceedings.org/rss14/p55.html",
        "author": "Gowtham Garimella; Matthew Sheckells; Joseph Moore; Marin Kobilarov",
        "abstract": "This work considers the problem of avoiding obstacles for general nonlinear systems subject to disturbances. Obstacle avoidance is achieved by computing disturbance invariant sets along a nominal trajectory and ensuring these invariant sets do not intersect with obstacles. We develop a novel technique to compute approximate disturbance invariant sets for general nonlinear systems using a set of finite dimensional optimizations. A bi-level NMPC optimization strategy alternates between optimizing over the nominal trajectory and finding the disturbance invariant sets. Simulation results show that the proposed algorithm is able to generate disturbance invariant sets for standard 3D aerial and planar ground vehicles models, and the NMPC algorithm successfully computes obstacle avoidance trajectories using the disturbance invariant sets.",
        "bibtex": "@INPROCEEDINGS{Garimella-RSS-18, \r\n    AUTHOR    = {Gowtham Garimella AND Matthew Sheckells AND Joseph Moore AND Marin Kobilarov}, \r\n    TITLE     = {Robust Obstacle Avoidance using Tube NMPC}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.055} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p55.pdf",
        "supp": "",
        "pdf_size": 2877411,
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3686450508101292744&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Department of Computer Science and Mechanical Engineering, Johns Hopkins University; Department of Computer Science and Mechanical Engineering, Johns Hopkins University; The Johns Hopkins University Applied Physics Laboratory; Department of Computer Science and Mechanical Engineering, Johns Hopkins University",
        "aff_domain": "jhu.edu;jhu.edu;jhuapl.edu;jhu.edu",
        "email": "jhu.edu;jhu.edu;jhuapl.edu;jhu.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Computer Science and Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "236f1a56b2",
        "title": "Robust Sampling Based Model Predictive Control with Sparse Objective Information",
        "site": "https://www.roboticsproceedings.org/rss14/p42.html",
        "author": "Grady Williams; Brian Goldfain; Paul Drews; Kamil Saigol; James Rehg; Evangelos Theodorou",
        "abstract": "We present an algorithmic framework for stochastic model predictive control that is able to optimize non-linear systems with cost functions that have sparse, discontinuous gradient information. The proposed framework combines the benefits of sampling-based model predictive control with linearization-based trajectory optimization methods. The resulting algorithm consists of a novel utilization of Tube-based model predictive control. We demonstrate robust algorithmic performance on a variety of simulated tasks, and on a real-world fast autonomous driving task.",
        "bibtex": "@INPROCEEDINGS{Williams-RSS-18, \r\n    AUTHOR    = {Grady Williams AND Brian Goldfain AND Paul Drews AND Kamil Saigol AND James Rehg AND Evangelos Theodorou}, \r\n    TITLE     = {Robust Sampling Based Model Predictive Control with Sparse Objective Information}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.042} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p42.pdf",
        "supp": "",
        "pdf_size": 4253081,
        "gs_citation": 91,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17588568796790790236&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "aff": "Institute for Robotics and Intelligent Machines; Institute for Robotics and Intelligent Machines; Institute for Robotics and Intelligent Machines; Institute for Robotics and Intelligent Machines; Institute for Robotics and Intelligent Machines; Institute for Robotics and Intelligent Machines",
        "aff_domain": ";;;;;",
        "email": ";;;;;",
        "github": "",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Institute for Robotics and Intelligent Machines",
        "aff_unique_dep": "Robotics and Intelligent Machines",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "f4952dbf76",
        "title": "Safe Motion Planning in Unknown Environments: Optimality Benchmarks and Tractable Policies",
        "site": "https://www.roboticsproceedings.org/rss14/p61.html",
        "author": "Lucas Janson; Tommy Hu; Marco Pavone",
        "abstract": "This paper addresses the problem of planning a safe (i.e., collision-free) trajectory from an initial state to a goal region when the obstacle space is a-priori unknown and is incrementally revealed online, e.g., through line-of-sight perception. Despite its ubiquitous nature, this formulation of motion planning has received relatively little theoretical investigation, as opposed to the setup where the environment is assumed known. A fundamental challenge is that, unlike motion planning with known obstacles, it is not even clear what an optimal policy to strive for is. Our contribution is threefold. First, we present a notion of optimality for safe planning in unknown environments in the spirit of comparative (as opposed to competitive) analysis, with the goal of obtaining a benchmark that is, at least conceptually, attainable. Second, by leveraging this theoretical benchmark, we derive a pseudo-optimal class of policies that can seamlessly incorporate any amount of prior or learned information while still guaranteeing the robot never collides. Finally, we demonstrate the practicality of our algorithmic approach in numerical experiments using a range of environment types and dynamics, including a comparison with a state of the art method. A key aspect of our framework is that it automatically and implicitly weighs exploration versus exploitation in a way that is optimal with respect to the information available.",
        "bibtex": "@INPROCEEDINGS{Janson-RSS-18, \r\n    AUTHOR    = {Lucas Janson AND Tommy Hu AND Marco Pavone}, \r\n    TITLE     = {Safe Motion Planning in Unknown Environments: Optimality Benchmarks and Tractable Policies}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.061} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p61.pdf",
        "supp": "",
        "pdf_size": 605253,
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10050372329769665978&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "Department of Statistics, Harvard University; Department of Mechanical Engineering, Stanford University; Department of Aeronautics and Astronautics, Stanford University",
        "aff_domain": "fas.harvard.edu;stanford.edu;stanford.edu",
        "email": "fas.harvard.edu;stanford.edu;stanford.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Harvard University;Stanford University",
        "aff_unique_dep": "Department of Statistics;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.harvard.edu;https://www.stanford.edu",
        "aff_unique_abbr": "Harvard;Stanford",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Cambridge;Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "28a015ba76",
        "title": "Sampling-Based Approximation Algorithms for Reachability Analysis with Provable Guarantees",
        "site": "https://www.roboticsproceedings.org/rss14/p14.html",
        "author": "Lucas Liebenwein; Cenk Baykal; Igor Gilitschenski; Sertac Karaman; Daniela  Rus",
        "abstract": "The successful deployment of many autonomous systems in part hinges on providing rigorous guarantees on their performance and safety through a formal verification method, such as reachability analysis. In this work, we present a simple-to-implement, sampling-based algorithm for reachability analysis that is provably optimal up to any desired approximation accuracy. Our method achieves computational efficiency by judiciously sampling a finite subset of the state space and generating an approximate reachable set by conducting reachability analysis on this finite set of states. We prove that the reachable set generated by our algorithm approximates the ground-truth reachable set for any user-specified approximation accuracy. As a corollary to our main method, we introduce an asymptotically-optimal, anytime algorithm for reachability analysis. We present simulation results that reaffirm the theoretical properties of our algorithm and demonstrate its effectiveness in real-world inspired scenarios.",
        "bibtex": "@INPROCEEDINGS{Liebenwein-RSS-18, \r\n    AUTHOR    = {Lucas Liebenwein AND Cenk Baykal AND Igor Gilitschenski AND Sertac Karaman AND Daniela  Rus}, \r\n    TITLE     = {Sampling-Based Approximation Algorithms for Reachability Analysis with Provable Guarantees}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.014} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p14.pdf",
        "supp": "",
        "pdf_size": 1364171,
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8275261522313006094&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "aff": "Massachusetts Institute of Technology, USA; Massachusetts Institute of Technology, USA; Massachusetts Institute of Technology, USA; Massachusetts Institute of Technology, USA; Massachusetts Institute of Technology, USA",
        "aff_domain": "mit.edu;mit.edu;mit.edu;mit.edu;mit.edu",
        "email": "mit.edu;mit.edu;mit.edu;mit.edu;mit.edu",
        "github": "",
        "project": "",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "b5f6bb69c4",
        "title": "SegMap: 3D Segment Mapping using Data-Driven Descriptors",
        "site": "https://www.roboticsproceedings.org/rss14/p03.html",
        "author": "Renaud Dub\u00c3\u00a9; Andrei Cramariuc; Daniel Dugas; Juan Nieto; Roland Siegwart; Cesar Cadena",
        "abstract": "When performing localization and mapping, working at the level of structure can be advantageous in terms of robustness to environmental changes and differences in illumination. This paper presents SegMap: a map representation solution to the localization and mapping problem based on the extraction of segments in 3D point clouds. In addition to facilitating the computationally intensive task of processing 3D point clouds, working at the level of segments addresses the data compression requirements of real-time single- and multi-robot systems. While current methods extract descriptors for the single task of localization, SegMap leverages a data-driven descriptor in order to extract meaningful features that can also be used for reconstructing a dense 3D map of the environment and for extracting semantic information. This is particularly interesting for navigation tasks and for providing visual feedback to end-users such as robot operators, for example in search and rescue scenarios. These capabilities are demonstrated in multiple urban driving and search and rescue experiments. Our method leads to an increase of area under the ROC curve of 28.3% over current state of the art using eigenvalue based features. We also obtain very similar reconstruction capabilities to a model specifically trained for this task. The SegMap implementation is available open-source along with easy to run demonstrations at www.github.com/ethz-asl/segmap.",
        "bibtex": "@INPROCEEDINGS{Dub\u00c3\u00a9-RSS-18, \r\n    AUTHOR    = {Renaud Dub\u00c3\u00a9 AND Andrei Cramariuc AND Daniel Dugas AND Juan Nieto AND Roland Siegwart AND Cesar Cadena}, \r\n    TITLE     = {SegMap: 3D Segment Mapping using Data-Driven Descriptors}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.003} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p03.pdf",
        "supp": "",
        "pdf_size": 5644134,
        "gs_citation": 218,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4959934824683086369&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": "Autonomous Systems Lab, ETH, Zurich; Autonomous Systems Lab, ETH, Zurich; Autonomous Systems Lab, ETH, Zurich; Autonomous Systems Lab, ETH, Zurich; Autonomous Systems Lab, ETH, Zurich; Autonomous Systems Lab, ETH, Zurich",
        "aff_domain": "gmail.com;gmail.com;ethz.ch;ethz.ch;ethz.ch;ethz.ch",
        "email": "gmail.com;gmail.com;ethz.ch;ethz.ch;ethz.ch;ethz.ch",
        "github": "www.github.com/ethz-asl/segmap",
        "project": "",
        "author_num": 6,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "f757ee308a",
        "title": "Sequence-to-Sequence Language Grounding of Non-Markovian Task Specifications",
        "site": "https://www.roboticsproceedings.org/rss14/p67.html",
        "author": "Nakul Gopalan; Dilip Arumugam; Lawson Wong; Stefanie Tellex",
        "abstract": "Often times, natural language commands issued to robots not only specify a particular target configuration or goal state but also outline constraints on how the robot goes about its execution. That is, the path taken to achieving some goal state is given equal importance to the goal state itself. One example of this could be instructing a wheeled robot to go to the living room but avoid the kitchen, in order to avoid scuffing the floor. This class of behaviors poses a serious obstacle to existing language understanding for robotics approaches that map to either action sequences or goal state representations. Due to the non-Markovian nature of the objective, approaches in the former category must map to potentially unbounded action sequences whereas approaches in the latter category would require folding the entirety of a robot's trajectory into a (traditionally Markovian) state representation, resulting in an intractable decision-making problem. To resolve this challenge, we use a recently introduced probabilistic variant of Linear Temporal Logic (LTL) as a goal specification language for a Markov Decision Process (MDP). While demonstrating that standard neural sequence-to-sequence learning models can successfully ground language to this semantic representation, we also provide analysis that highlights generalization to novel, unseen logical forms as an open problem for this class of model. We evaluate our system within two simulated robot domains as well as on a physical robot, demonstrating accurate language grounding alongside a significant expansion in the space of interpretable robot behaviors.",
        "bibtex": "@INPROCEEDINGS{Gopalan-RSS-18, \r\n    AUTHOR    = {Nakul Gopalan AND Dilip Arumugam AND Lawson Wong AND Stefanie Tellex}, \r\n    TITLE     = {Sequence-to-Sequence Language Grounding of Non-Markovian Task Specifications}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.067} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p67.pdf",
        "supp": "",
        "pdf_size": 1412260,
        "gs_citation": 74,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17975210455602376746&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "aff": "Computer Science Department, Brown University; Computer Science Department, Brown University; Computer Science Department, Brown University; Computer Science Department, Brown University",
        "aff_domain": "cs.brown.edu;cs.brown.edu;cs.brown.edu;cs.brown.edu",
        "email": "cs.brown.edu;cs.brown.edu;cs.brown.edu;cs.brown.edu",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Brown University",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.brown.edu",
        "aff_unique_abbr": "Brown",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "4f1ef6ed86",
        "title": "Shared Autonomy via Deep Reinforcement Learning",
        "site": "https://www.roboticsproceedings.org/rss14/p05.html",
        "author": "Siddharth Reddy; Anca Dragan; Sergey Levine",
        "abstract": "In shared autonomy, user input is combined with semi-autonomous control to achieve a common goal. The goal is often unknown ex-ante, so prior work enables agents to infer the goal from user input and assist with the task. Such methods tend to assume some combination of knowledge of the dynamics of the environment, the user's policy given their goal, and the set of possible goals the user might target, which limits their application to real-world scenarios. We propose a deep reinforcement learning framework for model-free shared autonomy that lifts these assumptions. We use human-in-the-loop reinforcement learning with neural network function approximation to learn an end-to-end mapping from environmental observation and user input to agent action values, with task reward as the only form of supervision. This approach poses the challenge of following user commands closely enough to provide the user with real-time action feedback and thereby ensure high-quality user input, but also deviating from the user's actions when they are suboptimal. We balance these two needs by discarding actions whose values fall below some threshold, then selecting the remaining action closest to the user's input. Controlled studies with users (n = 12) and synthetic pilots playing a video game, and a pilot study with users (n = 4) flying a real quadrotor, demonstrate the ability of our algorithm to assist users with real-time control tasks in which the agent cannot directly access the user's private information through observations, but receives a reward signal and user input that both depend on the user's intent. The agent learns to assist the user without access to this private information, implicitly inferring it from the user's input. This enables the assisted user to complete the task more effectively than the user or an autonomous agent could on their own. This paper is a proof of concept that illustrates the potential for deep reinforcement learning to enable flexible and practical assistive systems.",
        "bibtex": "@INPROCEEDINGS{Reddy-RSS-18, \r\n    AUTHOR    = {Siddharth Reddy AND Anca Dragan AND Sergey Levine}, \r\n    TITLE     = {Shared Autonomy via Deep Reinforcement Learning}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.005} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p05.pdf",
        "supp": "",
        "pdf_size": 788384,
        "gs_citation": 218,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9053131619393272627&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Dept. of Electrical Engineering and Computer Science, University of California, Berkeley; Dept. of Electrical Engineering and Computer Science, University of California, Berkeley; Dept. of Electrical Engineering and Computer Science, University of California, Berkeley",
        "aff_domain": "berkeley.edu;berkeley.edu;berkeley.edu",
        "email": "berkeley.edu;berkeley.edu;berkeley.edu",
        "github": "",
        "project": "https://sites.google.com/view/deep-assist",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Dept. of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "bf17f2e08a",
        "title": "Sim-to-Real: Learning Agile Locomotion For Quadruped Robots",
        "site": "https://www.roboticsproceedings.org/rss14/p10.html",
        "author": "Jie Tan; Tingnan Zhang; Erwin Coumans; Atil Iscen; Yunfei Bai; Danijar Hafner; Steven Bohez; Vincent Vanhoucke",
        "abstract": "Designing agile locomotion for quadruped robots often requires extensive expertise and tedious manual tuning. In this paper, we present a system to automate this process by leveraging deep reinforcement learning techniques. Our system can learn quadruped locomotion from scratch using simple reward signals. In addition, users can provide an open loop reference  to guide the learning process when more control over the learned gait is needed. The control policies are learned in a physics simulator and then deployed on real robots. In robotics, policies trained in simulation often do not transfer to the real world. We narrow this reality gap by improving the physics simulator and learning robust policies. We improve the simulation using system identification, developing an accurate actuator model and simulating latency. We learn robust controllers by randomizing the physical environments, adding perturbations and designing a compact observation space. We evaluate our system on two agile locomotion gaits: trotting and galloping. After learning in simulation, a quadruped robot can successfully perform both gaits in the real world.",
        "bibtex": "@INPROCEEDINGS{Tan-RSS-18, \r\n    AUTHOR    = {Jie Tan AND Tingnan Zhang AND Erwin Coumans AND Atil Iscen AND Yunfei Bai AND Danijar Hafner AND Steven Bohez AND Vincent Vanhoucke}, \r\n    TITLE     = {Sim-to-Real: Learning Agile Locomotion For Quadruped Robots}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.010} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p10.pdf",
        "supp": "",
        "pdf_size": 978720,
        "gs_citation": 992,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7754418142016342053&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "1889873f5a",
        "title": "Simplifying Reward Design through Divide-and-Conquer",
        "site": "https://www.roboticsproceedings.org/rss14/p48.html",
        "author": "Ellis Ratner; Dylan Hadfield-Menell; Anca Dragan",
        "abstract": "Designing a good reward function is essential to robot planning and reinforcement learning, however it can be both challenging and frustrating. The reward needs to work across multiple different environments, and that often requires many iterations of tuning. We introduce a novel divide-and-conquer approach that enables the designer to specify a reward separately for each environment. By treating these separate reward functions as observations about the underlying true reward, we derive an approach to infer a common reward across all environments. We conduct user studies in an abstract grid world domain and a motion planning domain for a 7-DOF manipulator that measure user effort and solution quality. We show that our method is faster, easier to use, and produces a higher quality solution than the typical method of designing a reward jointly across all environments. We additionally conduct a series of experiments that measure the sensitivity of these results to different properties of the reward design task such as number of environments, the number of feasible solutions per environment, and the fraction of the total features that vary within each environment. We find that independent reward design compares favorably with the standard, joint, reward design process but works best when the design problem can be divided into simpler subproblems.",
        "bibtex": "@INPROCEEDINGS{Ratner-RSS-18, \r\n    AUTHOR    = {Ellis Ratner AND Dylan Hadfield-Menell AND Anca Dragan}, \r\n    TITLE     = {Simplifying Reward Design through Divide-and-Conquer}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.048} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p48.pdf",
        "supp": "",
        "pdf_size": 1069289,
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5492759232193198536&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "aff": "University of California, Berkeley; University of California, Berkeley; University of California, Berkeley",
        "aff_domain": "berkeley.edu;berkeley.edu;berkeley.edu",
        "email": "berkeley.edu;berkeley.edu;berkeley.edu",
        "github": "",
        "project": "",
        "author_num": 3,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "0e1f094866",
        "title": "SurfelWarp: Efficient Non-Volumetric Single View Dynamic Reconstruction",
        "site": "https://www.roboticsproceedings.org/rss14/p29.html",
        "author": "Wei Gao; Russ Tedrake",
        "abstract": "We contribute a dense SLAM system that takes a live stream of depth images as input and reconstructs non-rigid deforming scenes in real time, without templates or prior models. In contrast to existing approaches, we do not maintain any volumetric data structures, such as truncated signed distance function (TSDF) fields or deformation fields, which are performance and memory intensive. Our system works with flat point (surfel) based representation of geometry, which can be directly acquired from commodity depth sensors. Standard graphics pipelines and general purpose GPU (GPGPU) computing are leveraged for all central operations: i.e., nearest neighbor maintenance, non-rigid deformation field estimation and fusion of depth measurements. Our pipeline inherently avoids expensive volumetric operations such as marching cubes, volumetric fusion and dense deformation field update, leading to significantly improved performance. Furthermore, the explicit and flexible surfel based geometry representation enables efficient tackling of topology changes and tracking failures, which makes our reconstructions consistent with updated depth observations. Our system allows robots maintain a scene description with non-rigidly deformed objects that potentially enables interactions with dynamic working environments.",
        "bibtex": "@INPROCEEDINGS{Gao-RSS-18, \r\n    AUTHOR    = {Wei Gao AND Russ Tedrake}, \r\n    TITLE     = {SurfelWarp: Efficient Non-Volumetric Single View Dynamic Reconstruction}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.029} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p29.pdf",
        "supp": "",
        "pdf_size": 5504221,
        "gs_citation": 87,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3481916839460216118&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "aff_domain": "mit.edu;mit.edu",
        "email": "mit.edu;mit.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "5e8cfbd6c4",
        "title": "The Critical Radius in Sampling-based Motion Planning",
        "site": "https://www.roboticsproceedings.org/rss14/p17.html",
        "author": "Kiril Solovey; Michal Kleinbort",
        "abstract": "We develop a new analysis of sampling-based motion planning in Euclidean space with uniform random sampling, which significantly improves upon the celebrated result of Karaman and Frazzoli (2011) and subsequent work. Particularly, we prove the existence of a critical connection radius proportional to Theta(n^(-1/d)) for n samples and d dimensions: Below this value the planner is guaranteed to fail (similarly shown by the aforementioned work, ibid.). More importantly, for larger radius values the planner is asymptotically (near-)optimal. Furthermore, our analysis yields an explicit lower bound of 1-O(n^(-1)) on the probability of success. A practical implication of our work is that asymptotic (near-)optimality is achieved when each sample is connected to only Theta(1) neighbors. This is in stark contrast to previous work which requires Theta(log n) connections, that are induced by a radius of order (log n/n)^(1/d).  Our analysis is not restricted to PRM and applies to a variety of PRM-based planners, including RRG, FMT* and BTT. Continuum percolation plays an important role in our proofs.",
        "bibtex": "@INPROCEEDINGS{Solovey-RSS-18, \r\n    AUTHOR    = {Kiril Solovey AND Michal Kleinbort}, \r\n    TITLE     = {The Critical Radius in Sampling-based Motion Planning}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.017} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p17.pdf",
        "supp": "",
        "pdf_size": 685505,
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16372429707828920076&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "aff": "Blavatnik School of Computer Science, Tel Aviv University, Israel; Blavatnik School of Computer Science, Tel Aviv University, Israel",
        "aff_domain": "post.tau.ac.il;gmail.com",
        "email": "post.tau.ac.il;gmail.com",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tel Aviv University",
        "aff_unique_dep": "Blavatnik School of Computer Science",
        "aff_unique_url": "https://www.tau.ac.il",
        "aff_unique_abbr": "TAU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tel Aviv",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Israel"
    },
    {
        "id": "1ee4489046",
        "title": "The Transfer of Human Trust in Robot Capabilities across Tasks",
        "site": "https://www.roboticsproceedings.org/rss14/p33.html",
        "author": "Harold Soh; Shu Pan; Chen Min; David Hsu",
        "abstract": "Trust is crucial in shaping human interactions with one another and with robots. This work investigates how human trust in robot capabilities transfers across  tasks. We present a human-subjects study of two distinct task domains: a Fetch robot performing household tasks and a virtual reality simulation of an autonomous vehicle performing driving and parking maneuvers. Our findings lead to a functional view of trust and two novel predictive models\u2014a recurrent neural network architecture and a Bayesian Gaussian process\u2014that  capture trust evolution and transfer via latent task representations. Experiments show that the two proposed models outperform existing approaches when predicting trust across unseen tasks and participants. These results indicate that (i) a task-dependent functional trust model captures human trust in robot capabilities more accurately, and (ii) trust transfer across tasks can be inferred to a good degree. The latter enables trust-based robot decision-making for fluent human-robot interaction. In particular, our models can be used to derive robot policies that mitigate under-trust or over-trust by human teammates in collaborative multi-task settings.",
        "bibtex": "@INPROCEEDINGS{Soh-RSS-18, \r\n    AUTHOR    = {Harold Soh AND Shu Pan AND Chen Min AND David Hsu}, \r\n    TITLE     = {The Transfer of Human Trust in Robot Capabilities across Tasks}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.033} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p33.pdf",
        "supp": "",
        "pdf_size": 1131871,
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15736165826392055113&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "aff": ";;;",
        "aff_domain": ";;;",
        "email": ";;;",
        "github": "",
        "project": "",
        "author_num": 4,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "9db0a9ad28",
        "title": "Toward Specification-Guided Active Mars Exploration for Cooperative Robot Teams",
        "site": "https://www.roboticsproceedings.org/rss14/p47.html",
        "author": "Petter Nilsson; Sofie Haesaert; Rohan Thakker; Kyohei Otsu; Cristian-Ioan Vasile; Ali Agha; Richard Murray; Aaron Ames",
        "abstract": "As a step towards achieving autonomy in space exploration missions, we consider a cooperative robotics system consisting of a copter and a rover. The goal of the copter is to explore an unknown environment so as to maximize knowledge about a science mission expressed in linear temporal logic that is to be executed by the rover. We model environmental uncertainty as a belief space Markov decision process and formulate the problem as a two-step stochastic dynamic program that we solve in a way that leverages the decomposed nature of the overall system. We demonstrate in simulations that the robot team makes intelligent decisions in the face of uncertainty.",
        "bibtex": "@INPROCEEDINGS{Nilsson-RSS-18, \r\n    AUTHOR    = {Petter Nilsson AND Sofie Haesaert AND Rohan Thakker AND Kyohei Otsu AND Cristian-Ioan Vasile AND Ali Agha AND Richard Murray AND Aaron Ames}, \r\n    TITLE     = {Toward Specification-Guided Active Mars Exploration for Cooperative Robot Teams}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.047} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p47.pdf",
        "supp": "",
        "pdf_size": 2971006,
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17612919665357970616&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "aff": ";;;;;;;",
        "aff_domain": ";;;;;;;",
        "email": ";;;;;;;",
        "github": "",
        "project": "",
        "author_num": 8,
        "track": "main",
        "status": "Poster"
    },
    {
        "id": "b811f85190",
        "title": "Trajectory Optimization On Manifolds with Applications to SO(3) and R3XS2",
        "site": "https://www.roboticsproceedings.org/rss14/p23.html",
        "author": "Michael Watterson; Sikang Liu; Ke Sun; Trey Smith; Vijay Kumar",
        "abstract": "Manifolds are used in almost all robotics applications even if they are not explicitly modeled.  We propose a differential geometric approach for optimizing trajectories on a Riemannian manifold with obstacles. The optimization problem depends on a metric and collision function specific to a manifold.  We then propose our Safe Corridor on Manifolds (SCM) method of computationally optimizing trajectories for robotics applications via a constrained optimization problem.  Our method does not need equality constraints, which eliminates the need to project back to a feasible manifold during optimization.  We then demonstrate how this algorithm works on an example problem on SO(3) and a perception-aware planning example for visual-inertially guided robots navigating in 3 dimensions. Formulating field of view constraints naturally results in modeling with the manifold R3XS2 which cannot be modeled as a Lie group.",
        "bibtex": "@INPROCEEDINGS{Watterson-RSS-18, \r\n    AUTHOR    = {Michael Watterson AND Sikang Liu AND Ke Sun AND Trey Smith AND Vijay Kumar}, \r\n    TITLE     = {Trajectory Optimization On Manifolds with Applications to SO(3) and R3XS2}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.023} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p23.pdf",
        "supp": "",
        "pdf_size": 6810712,
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1164455376148839490&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "aff": "GRASP Lab, University of Pennsylvania; GRASP Lab, University of Pennsylvania; GRASP Lab, University of Pennsylvania; NASA Intellegent Robotics Group, NASA Ames Research Center; GRASP Lab, University of Pennsylvania",
        "aff_domain": "seas.upenn.edu;seas.upenn.edu;seas.upenn.edu;nasa.gov;seas.upenn.edu",
        "email": "seas.upenn.edu;seas.upenn.edu;seas.upenn.edu;nasa.gov;seas.upenn.edu",
        "github": "",
        "project": "https://youtu.be/gu8Tb7XjU0o",
        "author_num": 5,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Pennsylvania;NASA Ames Research Center",
        "aff_unique_dep": "GRASP Lab;NASA Intelligent Robotics Group",
        "aff_unique_url": "https://www.upenn.edu;https://www.nasa.gov/ames",
        "aff_unique_abbr": "UPenn;NASA Ames",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "c4baf6923c",
        "title": "View Selection with Geometric Uncertainty Modeling",
        "site": "https://www.roboticsproceedings.org/rss14/p25.html",
        "author": "Cheng Peng; Volkan Isler",
        "abstract": "Estimating positions of world points from features observed in   images is a key problem  in 3D reconstruction, image mosaicking,   simultaneous localization and mapping and structure from motion. We   consider a special instance in which there is a dominant ground plane G viewed from a parallel viewing plane S above it. Such instances commonly arise, for example, in aerial   photography. Consider a world point g in G and its worst case reconstruction uncertainty epsilon(g,S obtained by merging all possible views of g chosen from S. We first show that one can pick two views s_p and s_q such   that the uncertainty epsilon(g,{s_p,s_q}) obtained using only these two views is almost as good as (i.e. within a small constant factor of) epsilon(g,S). Next, we extend the result to the entire ground plane G and show that one can pick a small subset S' of S (which grows only linearly with the area of G) and still obtain a constant   factor approximation, for every point g in G, to the   minimum worst case estimate obtained by merging all views in S. Finally, we present a multi-resolution view selection method which extends our techniques to non-planar scenes.  We show that the method can     produce rich and accurate dense reconstructions with a small number of views.    Our results provide a view selection mechanism with provable   performance guarantees which can drastically increase the speed of   scene reconstruction algorithms. In addition to theoretical results,   we demonstrate their effectiveness in an application where aerial   imagery is used for monitoring farms and orchards.",
        "bibtex": "@INPROCEEDINGS{Peng-RSS-18, \r\n    AUTHOR    = {Cheng Peng AND Volkan Isler}, \r\n    TITLE     = {View Selection with Geometric Uncertainty Modeling}, \r\n    BOOKTITLE = {Proceedings of Robotics: Science and Systems}, \r\n    YEAR      = {2018}, \r\n    ADDRESS   = {Pittsburgh, Pennsylvania}, \r\n    MONTH     = {June}, \r\n    DOI       = {10.15607/RSS.2018.XIV.025} \r\n}",
        "pdf": "https://www.roboticsproceedings.org/rss14/p25.pdf",
        "supp": "",
        "pdf_size": 1576927,
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15523111832638213350&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "aff": "College of Science and Engineering, University of Minnesota; College of Science and Engineering, University of Minnesota",
        "aff_domain": "umn.edu;umn.edu",
        "email": "umn.edu;umn.edu",
        "github": "",
        "project": "",
        "author_num": 2,
        "track": "main",
        "status": "Poster",
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "College of Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    }
]