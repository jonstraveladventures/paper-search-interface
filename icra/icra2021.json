[
    {
        "id": "9561755",
        "title": "0-MMS: Zero-Shot Multi-Motion Segmentation With A Monocular Event Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "Segmentation of moving objects in dynamic scenes is a key process in scene understanding for navigation tasks. Classical cameras suffer from motion blur in such scenarios rendering them effete. On the contrary, event cameras, because of their high temporal resolution and lack of motion blur, are tailor-made for this problem. We present an approach for monocular multi-motion segmentation, which combines bottom-up feature tracking and top-down motion compensation into a unified pipeline, which is the first of its kind to our knowledge. Using the events within a time-interval, our method segments the scene into multiple motions by splitting and merging. We further speed up our method by using the concept of motion propagation and cluster keyslices.The approach was successfully evaluated on both challenging real-world and synthetic scenarios from the EV-IMO, EED, and MOD datasets and outperformed the state-of-the-art detection rate by 12%, achieving a new state-of-the-art average detection rate of 81.06%, 94.2% and 82.35% on the aforementioned datasets. To enable further research and systematic evaluation of multi-motion segmentation, we present and open-source a new dataset/benchmark called MOD++, which includes challenging sequences and extensive data stratification in-terms of camera and object motion, velocity magnitudes, direction, and rotational speeds.",
        "primary_area": "",
        "author": "Chethan M. Parameshwara;Nitin J. Sanket;Chahat Deep Singh;Cornelia Ferm\u00fcller;Yiannis Aloimonos;Chethan M. Parameshwara;Nitin J. Sanket;Chahat Deep Singh;Cornelia Ferm\u00fcller;Yiannis Aloimonos",
        "authorids": "/37086581058;/37086390746;/37086392092;/37269887600;/37282631400;/37086581058;/37086390746;/37086392092;/37269887600;/37282631400",
        "aff": "Perception and Robotics Group, University of Maryland, College Park; Perception and Robotics Group, University of Maryland, College Park; Perception and Robotics Group, University of Maryland, College Park; Perception and Robotics Group, University of Maryland, College Park; Perception and Robotics Group, University of Maryland, College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561755/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17282910354775721337&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "Perception and Robotics Group",
        "aff_unique_url": "https://www.umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561845",
        "title": "3D Collision-Force-Map for Safe Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "The need to guarantee safety of collaborative robots limits their performance, in particular, their speed and hence cycle time. The standard ISO/TS 15066 defines the Power and Force Limiting operation mode and prescribes force thresholds that a moving robot is allowed to exert on human body parts during impact, along with a simple formula to obtain maximum allowed speed of the robot in the whole workspace. In this work, we measure the forces exerted by two collaborative manipulators (UR10e and KUKA LBR iiwa) moving downward against an impact measuring device. First, we empirically show that the impact forces can vary by more than 100 percent within the robot workspace. The forces are negatively correlated with the distance from the robot base and the height in the workspace. Second, we present a data-driven model, 3D Collision-Force-Map, predicting impact forces from distance, height, and velocity and demonstrate that it can be trained on a limited number of data points. Third, we analyze the force evolution upon impact and find that clamping never occurs for the UR10e. We show that formulas relating robot mass, velocity, and impact forces from ISO/TS 15066 are insufficient\u2014leading both to significant underestimation and overestimation and thus to unnecessarily long cycle times or even dangerous applications. We propose an empirical method that can be deployed to quickly determine the optimal speed and position where a task can be safely performed with maximum efficiency.",
        "primary_area": "",
        "author": "Petr Svarny;Jakub Rozlivek;Lukas Rustler;Matej Hoffmann;Petr Svarny;Jakub Rozlivek;Lukas Rustler;Matej Hoffmann",
        "authorids": "/37087322921;/37088990465;/37088992503;/37594773300;/37087322921;/37088990465;/37088992503;/37594773300",
        "aff": "Department of Cybernetics, Faculty of Electrical Engineering, Czech Technical University, Prague; Department of Cybernetics, Faculty of Electrical Engineering, Czech Technical University, Prague; Department of Cybernetics, Faculty of Electrical Engineering, Czech Technical University, Prague; Department of Cybernetics, Faculty of Electrical Engineering, Czech Technical University, Prague",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561845/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14505354504086097071&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Czech Technical University",
        "aff_unique_dep": "Department of Cybernetics, Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "9561738",
        "title": "3D Motion Capture of an Unmodified Drone with Single-chip Millimeter Wave Radar",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate motion capture of aerial robots in 3D is a key enabler for autonomous operation in indoor environments such as warehouses or factories, as well as driving forward research in these areas. The most commonly used solutions at present are optical motion capture (e.g. VICON) and Ultrawide-band (UWB), but these are costly and cumbersome to deploy, due to their requirement of multiple cameras/anchors spaced around the tracking area. They also require the drone to be modified to carry an active or passive marker. In this work, we present an inexpensive system that can be rapidly installed, based on single-chip millimeter wave (mmWave) radar. Importantly, the drone does not need to be modified or equipped with any markers, as we exploit the Doppler signals from the rotating propellers. Furthermore, 3D tracking is possible from a single point, greatly simplifying deployment. We develop a novel deep neural network and demonstrate decimeter level 3D tracking at 10Hz, achieving better performance than classical baselines. Our hope is that this low-cost system will act to catalyse inexpensive drone research and increased autonomy.",
        "primary_area": "",
        "author": "Peijun Zhao;Chris Xiaoxuan Lu;Bing Wang;Niki Trigoni;Andrew Markham;Peijun Zhao;Chris Xiaoxuan Lu;Bing Wang;Niki Trigoni;Andrew Markham",
        "authorids": "/37086940063;/37086107301;/37088504237;/37297514400;/37410667900;/37086940063;/37086107301;/37088504237;/37297514400;/37410667900",
        "aff": "Department of Computer Science, University of Oxford, United Kingdom; School of Informatics, University of Edinburgh, United Kingdom; Department of Computer Science, University of Oxford, United Kingdom; Department of Computer Science, University of Oxford, United Kingdom; Department of Computer Science, University of Oxford, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561738/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3956429020003737600&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University of Oxford;University of Edinburgh",
        "aff_unique_dep": "Department of Computer Science;School of Informatics",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.ed.ac.uk",
        "aff_unique_abbr": "Oxford;Edinburgh",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Oxford;Edinburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561852",
        "title": "3D Multi-Object Tracking using Random Finite Set-based Multiple Measurement Models Filtering (RFS-M3) for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Multiple object tracking (MOT) is a critical module for enabling autonomous vehicles to achieve safe planing and navigation in cluttered environments. In tracking-by-detection systems, there are inevitably many false positives and misses among learning-based input detections. The challenge for MOT is to combine these detections into tracks, and filter them based on their uncertainties, states, and temporal consistency to achieve accurate and persistent tracks. In this paper, we propose to solve the 3D MOT problem for autonomous driving applications using a random finite set-based (RFS) Multiple Measurement Models filter (RFS-M3). In partiuclar, we propose multiple measurement models for a Poisson multi-Bernoulli mixture (PMBM) filter in support of different application scenarios. Our RFS-M3 filter can naturally model these uncertainties accurately and elegantly. We combine the learning-based detections with our RFS-M3 tracker through incorporating the detection confidence score into the PMBM prediction and update step. The superior experimental results of our RFS-M3 tracker on Waymo, Argoverse and nuSceness datasets illustrate that our RFS-M3 tracker outperforms state-of-the-art deep learning-based and traditional filter-based approaches. To the best of our knowledge, this represents a first successful attempt for employing an RFS-based approach in conjunction with 3D learning-based amodal detections for 3D MOT applications with comprehensive validation using challenging datasets made available by industry leaders.",
        "primary_area": "",
        "author": "Su Pang;Daniel Morris;Hayder Radha;Su Pang;Daniel Morris;Hayder Radha",
        "authorids": "/37086815663;/37085641369;/37269513400;/37086815663;/37085641369;/37269513400",
        "aff": "Department of Electrical and Computer Engineering, College of Engineering, Michigan State University, East Lansing, Michigan, United States; Department of Electrical and Computer Engineering, College of Engineering, Michigan State University, East Lansing, Michigan, United States; Department of Electrical and Computer Engineering, College of Engineering, Michigan State University, East Lansing, Michigan, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561852/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4652866013594528082&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Michigan State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.msu.edu",
        "aff_unique_abbr": "MSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "East Lansing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560870",
        "title": "3D Periodic Magnetic Servoing System for Microrobot Actuation Using Decoupled Asynchronous Repetitive Control Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "To date, untethered microrobots have been receiving tremendous attention for playing implacable roles of maneuverable tools in fields such as microfabrication and biomanipulation. Typical actuation of such untethered tiny robots is the magnetic field-based approaches, including gradient and rotational methods. Compared to the gradient type method, the rotational approach requires much less magnetic field strength to generate efficient actuation for magnetic microrobots. To actuate microrobots desirably, a precise periodic magnetic field should be provided. To generate precise periodic magnetic field with enhanced strength, this paper develops a prototype of 3D magnetic servoing system based on integrated solenoids, performance of which are enhanced by employing iron cores and extended number of coils. Each solenoid is equipped with a Hall sensor to provide real-time feedback signal for performing precise magnetic field control. To precisely regulate this setup, a decoupled asynchronous repetitive control (DARC) scheme is established to generate a desirable 3D periodic magnetic field with noise-level tracking error under the situation of missing execution opportunity randomly. Experimental results demonstrate the effectiveness of the proposed magnetic servoing system, which is promising for dynamic properties characterization of magnetic microrobots.",
        "primary_area": "",
        "author": "Zhiyong Sun;Yu Cheng;Chao Zhou;Erkang Cheng;Gengliang Chen;Lixin Dong;Bo Song;Zhiyong Sun;Yu Cheng;Chao Zhou;Erkang Cheng;Gengliang Chen;Lixin Dong;Bo Song",
        "authorids": "/37085395655;/37085377130;/37876898300;/37088874018;/37088578554;/37275019100;/37400698100;/37085395655;/37085377130;/37876898300;/37088874018;/37088578554;/37275019100;/37400698100",
        "aff": "Institute of Intelligent Machines, Hefei Institute of Physical Science, CAS, Hefei, China; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Institute of Plasma Physics, Hefei Institute of Physical Science, CAS, Hefei, China; Institute of Intelligent Machines, Hefei Institute of Physical Science, CAS, Hefei, China; Shenzhen Academy of Robotics, Shenzhen Technology University, Shenzhen, Guangdong, China; Department of Biomedical Engineering, City University of Hong Kong, Hong Kong, China; Institute of Intelligent Machines, Hefei Institute of Physical Science, CAS, Hefei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560870/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14300081902324791906&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;2;3;0",
        "aff_unique_norm": "Hefei Institute of Physical Science;Michigan State University;Shenzhen Technology University;City University of Hong Kong",
        "aff_unique_dep": "Institute of Intelligent Machines;Department of Electrical and Computer Engineering;Shenzhen Academy of Robotics;Department of Biomedical Engineering",
        "aff_unique_url": ";https://www.msu.edu;;https://www.cityu.edu.hk",
        "aff_unique_abbr": ";MSU;;CityU",
        "aff_campus_unique_index": "0;1;0;0;2;3;0",
        "aff_campus_unique": "Hefei;East Lansing;Shenzhen;Hong Kong",
        "aff_country_unique_index": "0;1;0;0;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561772",
        "title": "3D Reconstruction of Deformable Colon Structures based on Preoperative Model and Deep Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "In colonoscopy procedures, it is important to rebuild and visualize the colonic surface to minimize the missing regions and reinspect for abnormalities. Due to the fast camera motion and deformation of the colon in standard forward-viewing colonoscopies, traditional simultaneous localization and mapping (SLAM) systems work poorly for 3D reconstruction of colon surfaces and are prone to severe drift. Thus in this paper, a preoperative colon model segmented from CT scans is used together with the colonoscopic images to achieve the 3D colon reconstruction. The proposed framework includes dense depth estimation from monocular colonoscopic images using a deep neural network (DNN), visual odometry (VO) based camera motion estimation and an embedded deformation (ED) graph based non-rigid registration algorithm for deforming 3D scans to the segmented colon model. A realistic simulator is used to generate different simulation datasets with ground truth. Simulation results demonstrate the good performance of the proposed 3D colonic surface reconstruction method in terms of accuracy and robustness. In-vivo experiments are also conducted and the results show the practicality of the proposed framework for providing useful shape and texture information in colonoscopy applications.",
        "primary_area": "",
        "author": "Shuai Zhang;Liang Zhao;Shoudong Huang;Ruibin Ma;Boni Hu;Qi Hao;Shuai Zhang;Liang Zhao;Shoudong Huang;Ruibin Ma;Boni Hu;Qi Hao",
        "authorids": "/37086326556;/37857963600;/37421307400;/37088872397;/37088758545;/37403530000;/37086326556;/37857963600;/37421307400;/37088872397;/37088758545;/37403530000",
        "aff": "Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Centre for Autonomous Systems, University of Technology Sydney; Centre for Autonomous Systems, University of Technology Sydney; Department of Computer Science, University of North Carolina, Chapel Hill, United States; School of Aeronautics, Northwestern Polytechnical University, China; Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561772/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14166807750289717298&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;3;0",
        "aff_unique_norm": "Southern University of Science and Technology;University of Technology Sydney;University of North Carolina;Northwestern Polytechnical University",
        "aff_unique_dep": "Department of Computer Science and Engineering;Centre for Autonomous Systems;Department of Computer Science;School of Aeronautics",
        "aff_unique_url": "https://www.sustech.edu.cn;https://www.uts.edu.au;https://www.unc.edu;https://www.nwpu.edu.cn",
        "aff_unique_abbr": "SUSTech;UTS;UNC;NWPU",
        "aff_campus_unique_index": "0;1;1;2;0",
        "aff_campus_unique": "Shenzhen;Sydney;Chapel Hill;",
        "aff_country_unique_index": "0;1;1;2;0;0",
        "aff_country_unique": "China;Australia;United States"
    },
    {
        "id": "9561005",
        "title": "3D Surfel Map-Aided Visual Relocalization with Learned Descriptors",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce a method for visual relocalization using the geometric information from a 3D surfel map. A visual database is first built by global indices from the 3D surfel map rendering, which provides associations between image points and 3D surfels. Surfel reprojection constraints are utilized to optimize the keyframe poses and map points in the visual database. A hierarchical camera relocalization algorithm then utilizes the visual database to estimate 6-DoF camera poses. Learned descriptors are further used to improve the performance in challenging cases. We present evaluation under real-world conditions and simulation to show the effectiveness and efficiency of our method, and make the final camera poses consistently well aligned with the 3D environment.",
        "primary_area": "",
        "author": "Haoyang Ye;Huaiyang Huang;Marco Hutter;Timothy Sandy;Ming Liu;Haoyang Ye;Huaiyang Huang;Marco Hutter;Timothy Sandy;Ming Liu",
        "authorids": "/37086022108;/37087103064;/37545251000;/37085800060;/37085398677;/37086022108;/37087103064;/37545251000;/37085800060;/37085398677",
        "aff": "RAM-LAB, the Hong Kong University of Science and Technology, Kowloon, Hong Kong; RAM-LAB, the Hong Kong University of Science and Technology, Kowloon, Hong Kong; Robotic Systems Lab, ETH, Zurich, Switzerland; Robotic Systems Lab, ETH, Zurich, Switzerland; RAM-LAB, the Hong Kong University of Science and Technology, Kowloon, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561005/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7867708851341731678&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;ETH Zurich",
        "aff_unique_dep": "RAM-LAB;Robotic Systems Lab",
        "aff_unique_url": "https://www.ust.hk;https://www.ethz.ch",
        "aff_unique_abbr": "HKUST;ETHZ",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Hong Kong SAR;Zurich",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "China;Switzerland"
    },
    {
        "id": "9561503",
        "title": "3D biped locomotion control including seamless transition between walking and running via 3D ZMP manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "A novel control scheme for biped robots to manipulate the ZMP three-dimensionally apart from the actual ground profile is presented. It is shown that the linear inverted-pendulum-like dynamics with this scheme can represent a wider class of movements including variation of the body height. Moreover, this can also represent the motion in aerial phase. Based on this, the foot-guided controller proposed by the authors is enhanced to enable the robots to locomote on highly uneven terrains and also to seamlessly transition between walking and running without pre-planning the overall motion reference. The controller guarantees the capturability at landing and defines the motion by a time-variant state feedback, which is analytically derived from a model predictive optimization. It is verified through some computer simulations.",
        "primary_area": "",
        "author": "Tomomichi Sugihara;Kenta Imanishi;Takanobu Yamamoto;St\u00e9phane Caron;Tomomichi Sugihara;Kenta Imanishi;Takanobu Yamamoto;St\u00e9phane Caron",
        "authorids": "/37288884300;/37086601182;/37086303355;/37587869700;/37288884300;/37086601182;/37086303355;/37587869700",
        "aff": "Graduate School of Engineering, Osaka University, Osaka, Japan; Graduate School of Engineering, Osaka University, Osaka, Japan; Graduate School of Engineering, Osaka University, Osaka, Japan; CNRS\u2013UM LIRMM, Montpellier, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561503/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6621585177904501940&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Osaka University;CNRS-UM LIRMM",
        "aff_unique_dep": "Graduate School of Engineering;",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.lirmm.fr",
        "aff_unique_abbr": "Osaka U;",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Osaka;Montpellier",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Japan;France"
    },
    {
        "id": "9560926",
        "title": "3D3L: Deep Learned 3D Keypoint Detection and Description for LiDARs",
        "track": "main",
        "status": "Poster",
        "abstract": "With the advent of powerful, light-weight 3D LiDARs, they have become the hearth of many navigation and SLAM algorithms on various autonomous systems. Pointcloud registration methods working with unstructured pointclouds such as ICP are often computationally expensive or require a good initial guess. Furthermore, 3D feature-based registration methods have never quite reached the robustness of 2D methods in visual SLAM. With the continuously increasing resolution of LiDAR range images, these 2D methods not only become applicable but should exploit the illumination-independent modalities that come with it, such as depth and intensity. In visual SLAM, deep learned 2D features and descriptors perform exceptionally well compared to traditional methods. In this publication, we use a state-of-the-art 2D feature network as a basis for 3D3L, exploiting both intensity and depth of LiDAR range images to extract powerful 3D features. Our results show that these keypoints and descriptors extracted from LiDAR scan images outperform state-of-the-art on different benchmark metrics and allow for robust scan-to-scan alignment as well as global localization.",
        "primary_area": "",
        "author": "Dominc Streiff;Lukas Bernreiter;Florian Tschopp;Marius Fehr;Roland Siegwart;Dominc Streiff;Lukas Bernreiter;Florian Tschopp;Marius Fehr;Roland Siegwart",
        "authorids": "/37088998438;/37086451179;/37086688697;/37085807555;/37281398300;/37088998438;/37086451179;/37086688697;/37085807555;/37281398300",
        "aff": "Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Voliro Airborne Robotics, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560926/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11961668475809778978&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "ETH Zurich;Voliro Airborne Robotics",
        "aff_unique_dep": "Autonomous Systems Lab;",
        "aff_unique_url": "https://www.ethz.ch;",
        "aff_unique_abbr": "ETHZ;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561954",
        "title": "6-DoF Contrastive Grasp Proposal Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Proposing grasp poses for novel objects is an essential component for any robot manipulation task. Planning six degrees of freedom (DoF) grasps with a single camera, however, is challenging due to the complex object shape, incomplete object information, and sensor noise. In this paper, we present a 6-DoF contrastive grasp proposal network (CGPN) to infer 6-DoF grasps from a single-view depth image. First, an image encoder is used to extract the feature map from the input depth image, after which 3-DoF grasp regions are proposed from the feature map with a rotated region proposal network. Feature vectors that within the proposed grasp regions are then extracted and refined to 6-DoF grasps. The proposed model is trained offline with synthetic grasp data. To improve the robustness in reality and bridge the simulation-to-real gap, we further introduce a contrastive learning module and variant image processing techniques during the training. CGPN can locate collision-free grasps of an object using a single-view depth image within 0.5 second. Experiments on a physical robot further demonstrate the effectiveness of the algorithm. The experimental videos are available at [1].",
        "primary_area": "",
        "author": "Xinghao Zhu;Lingfeng Sun;Yongxiang Fan;Masayoshi Tomizuka;Xinghao Zhu;Lingfeng Sun;Yongxiang Fan;Masayoshi Tomizuka",
        "authorids": "/37087322158;/37087105341;/37085827034;/37281933000;/37087322158;/37087105341;/37085827034;/37281933000",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, USA; FANUC Advanced Research Laboratory, FANUC America Corporation, Union City, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561954/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7458874541325870249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;FANUC America Corporation",
        "aff_unique_dep": "Department of Mechanical Engineering;FANUC Advanced Research Laboratory",
        "aff_unique_url": "https://www.berkeley.edu;https://www.fanucamerica.com",
        "aff_unique_abbr": "UC Berkeley;FANUC",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Berkeley;Union City",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561404",
        "title": "6D Object Pose Estimation with Pairwise Compatible Geometric Features",
        "track": "main",
        "status": "Poster",
        "abstract": "This work addresses the problem of 6-DoF pose estimation under heavy occlusion. While previous work demonstrates reasonable results in unoccluded situations, robust and efficient pose estimation is still challenging in heavily occluded and low-texture scenarios which are ubiquitous in many applications. To this end, we propose a novel end-to-end deep neural network model recovering object poses from depth measurements. The proposed model enforces pairwise consistency of 3D geometric features by applying spectral convolutions on a pairwise compatibility graph. We achieve comparable accuracy as the state-of-the-art graph matching solver while being much faster. Our approach outperforms state-of-the-art 6-DoF pose estimation methods on LineMOD and Occlusion LineMOD and runs in reasonable time (~5.9 Hz). We additionally verify this method on a synthetic dataset with large affine changes.",
        "primary_area": "",
        "author": "Muyuan Lin;Varun Murali;Sertac Karaman;Muyuan Lin;Varun Murali;Sertac Karaman",
        "authorids": "/37088998422;/37086855117;/37304113000;/37088998422;/37086855117;/37304113000",
        "aff": "Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561404/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7563240333202860015&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information & Decision Systems",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561696",
        "title": "A 2-Dimensional Branch-and-Bound Algorithm for Hand-Eye Self-Calibration of SCARA Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the high positioning accuracy and relatively low prices, SCARA robots are widely used in industrial fields. The objective of this paper is to propose a hand-eye self-calibration algorithm for SCARA robots which could consider both accuracy and computational cost. The previous global optimal hand-eye calibration algorithms based on branch-and-bound (BnB) optimization is limited by their expensive computational cost. The speed of these algorithms depends on the volume of the search space to a large extent, which is the main concern in this paper. Instead of searching over the 3-dimensional parameter space corresponding to the rotation component of hand-eye pose, a new 2-dimensional search space is defined by separating and coupling some calibration parameters by means of the special structure of SCARA robots, which have 4 degrees of freedom (DoFs) including three translation DoFs and only one rotation DoF. The simulation and real experiments show the similar accuracy but much faster speed of the proposed algorithm compared with previous optimal algorithms based on BnB.",
        "primary_area": "",
        "author": "Chengyu Tao;Na Lv;Shanben Chen;Chengyu Tao;Na Lv;Shanben Chen",
        "authorids": "/37089001391;/37089407343;/37335068100;/37089001391;/37089407343;/37335068100",
        "aff": "School of Materials Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Electronic Information and Electricity Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Materials Science and Engineering, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561696/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16397172984043030894&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "School of Materials Science and Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561403",
        "title": "A 3D Printed Mechanical Model of the Knee to Detect and Avoid Total Knee Replacement Surgery Errors",
        "track": "main",
        "status": "Poster",
        "abstract": "In this article, a novel 3D printed knee model for detecting possible errors in the planning and treatment of total knee replacement surgery is presented. This method is a first step towards automation of prosthesis placement. Thanks to the mathematically computed four-bar mechanism, it is now possible to emulate the implant insertion before the operation. This model allows the surgeon to fit the prosthesis to the patient\u2019s knee and to verify if the mounted position is optimal. This process can be repeated until the ideal position is found. Exact copies of the bones are made from the CT images of the patient. These resin copies of the real bones are placed in the motion model, reproducing the real patient\u2019s knee flexion. The model shows the implantation result with respect to the operation plan and the patient\u2019s kinematics. The experiment carried out on a patient\u2019s model according to the standard implantation shows a lift-off and sliding effect of the femoral component outside the joint area. However, this phenomenon is easily resolved if the femoral component is implanted about half a centimeter lateral to the knee\u2019s coronal axis. Until now, no medical research had questioned the lateral positioning of the prosthesis. This knee model provides an understanding of the important biomechanical parameters for total knee replacement surgery. This model will have a significant contribution to secure the surgery\u2019s success, increase patient satisfaction and reduce the overall number of revisions.",
        "primary_area": "",
        "author": "Alexandra Mercader;Timon R\u00f6ttinger;Amir Bigdeli;Heinz R\u00f6ttinger;Tim C. Lueth;Alexandra Mercader;Timon R\u00f6ttinger;Amir Bigdeli;Heinz R\u00f6ttinger;Tim C. Lueth",
        "authorids": "/37086497553;/37088997820;/37089000036;/37088997550;/37389804500;/37086497553;/37088997820;/37089000036;/37088997550;/37389804500",
        "aff": "Institute of Micro Technology and Medical Device Technology, Technical University of Munich, Garching, Germany; Artemed Klinikum M\u00fcnchen S\u00fcd, Munchen, Germany; Artemed Klinikum M\u00fcnchen S\u00fcd, Munchen, Germany; Artemed Klinikum M\u00fcnchen S\u00fcd, Munchen, Germany; Institute of Micro Technology and Medical Device Technology, Technical University of Munich, Garching, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561403/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7600530114818240406&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Technical University of Munich;Artemed Klinikum M\u00fcnchen S\u00fcd",
        "aff_unique_dep": "Institute of Micro Technology and Medical Device Technology;",
        "aff_unique_url": "https://www.tum.de;",
        "aff_unique_abbr": "TUM;",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Garching;M\u00fcnchen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561476",
        "title": "A Benchmark for LiDAR-based Panoptic Segmentation based on KITTI",
        "track": "main",
        "status": "Poster",
        "abstract": "Panoptic segmentation is the recently introduced task that tackles semantic segmentation and instance segmentation jointly [18]. In this paper, we present an extension of SemanticKITTI [1], a large-scale dataset providing dense point-wise semantic labels for all sequences of the KITTI Odometry Benchmark [10]. This extension enables training and evaluation of LiDAR-based panoptic segmentation. We provide the data and discuss the processing steps needed to enrich a given semantic annotation with temporally consistent instance information, i.e., instance information that supplements the semantic labels and identifies the same instance over sequences of LiDAR point clouds. Additionally, we present two strong baselines that combine state-of-the-art LiDAR-based semantic segmentation approaches with a state-of-the-art detector enriching the segmentation with instance information and that allow other researchers to compare their approaches against. We believe that our extension of SemanticKITTI with strong baselines enables the creation of novel algorithms for LiDAR-based panoptic segmentation as much as it has for the original semantic segmentation and semantic scene completion tasks. Data, code, and an online evaluation service using a hidden test set are publicly available at http://semantic-kitti.org.",
        "primary_area": "",
        "author": "Jens Behley;Andres Milioto;Cyrill Stachniss;Jens Behley;Andres Milioto;Cyrill Stachniss",
        "authorids": "/37593243900;/37086400161;/37329668600;/37593243900;/37086400161;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561476/",
        "gs_citation": 87,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5761241076487552628&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561535",
        "title": "A Bipolar Myoelectric Sensor-Enabled Human-Machine Interface Based On Spinal Module Activations",
        "track": "main",
        "status": "Poster",
        "abstract": "The surface electromyography (sEMG) signal-based human-machine interface (HMI) has been widely used for various scenarios of physical human-robot interaction. However, current HMIs based on bipolar myoelectric sensors are hindered by the limitations of global sEMG features, which are prone to variability and delay. In this letter, we define a HMI that takes advantage of the underlying neural information of spinal module activations from bipolar sEMG signals, inspired by recent findings of neural codes. Firstly, the spinal module activations are identified by the spiking trains of the muscle synergies extracted from bipolar sEMG signals. Secondly, we extract the information encoded in both firing rates and spike timings of the spinal module activation in a population coding manner, which follows the information encoding principle of neurons. Thirdly, we map the series of spinal module activations into gait phases, locomotion modes, joint moment and human identity in order to experimentally reveal the physiological information contained in the spinal module activations. The contained information and the benefit of our design are demonstrated and experimentally explained by the presented results and comparisons with the traditionally used global sEMG features. The proposed bipolar myoelectric sensor-enabled human-machine interface could contribute to various scenarios of physical human-robot interaction.",
        "primary_area": "",
        "author": "Chunzhi Yi;Feng Jiang;Guangming Lu;Chifu Yang;Zhen Ding;Jianfei Zhu;Jie Liu;Chunzhi Yi;Feng Jiang;Guangming Lu;Chifu Yang;Zhen Ding;Jianfei Zhu;Jie Liu",
        "authorids": "/37086422331;/37414830600;/37533207200;/37537204400;/37089267794;/37088997367;/37088998205;/37086422331;/37414830600;/37533207200;/37537204400;/37089267794;/37088997367;/37088998205",
        "aff": "School of Computer Science and Technology, Harbin Institute of Technology, Harbin, Heilongjiang, China; Pengcheng Laboratory, Shenzhen, Guangdong, China; Department of Medical Imaging, Nanjing Jinling Hospital, Clinical School, Medical College, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, Heilongjiang, China; AI Research Institute, Harbin Institute of Technology, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561535/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18072738464744372482&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology;Pengcheng Laboratory;Nanjing University",
        "aff_unique_dep": "School of Computer Science and Technology;;Department of Medical Imaging",
        "aff_unique_url": "http://www.hit.edu.cn/;;http://www.nju.edu.cn",
        "aff_unique_abbr": "HIT;;Nanjing U",
        "aff_campus_unique_index": "0;1;2;0;0;0;1",
        "aff_campus_unique": "Harbin;Shenzhen;Nanjing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562090",
        "title": "A Capturability-based Control Framework for the Underactuated Bipedal Walking",
        "track": "main",
        "status": "Poster",
        "abstract": "This work considers the control of underactuated bipedal walking, and a novel capturability-based control framework is presented. Compared with traditional approaches, the presented control method does not rely on the use of the Poincar\u00e9 map, which may take significant computational cost. Firstly, a new definition of stable walking is presented, and a novel foot-placement based control method is proposed. Then, a controller design method is presented based on this control method. For the controller design, the foot placement adjustment is achieved by updating the virtual constraints using a heuristic method, and an improved virtual constraint control method is proposed to enforce the virtual constraints. Finally, the effectiveness of the presented control framework is illustrated on a five-link underactuated planar biped by numerical simulations.",
        "primary_area": "",
        "author": "Haihui Yuan;Sumian Song;Ruilong Du;Shiqiang Zhu;Jason Gu;Mingguo Zhao;Jianxin Pang;Haihui Yuan;Sumian Song;Ruilong Du;Shiqiang Zhu;Jason Gu;Mingguo Zhao;Jianxin Pang",
        "authorids": "/37089002104;/37088998939;/37089002206;/37281408900;/37276928500;/37336278300;/37088897069;/37089002104;/37088998939;/37089002206;/37281408900;/37276928500;/37336278300;/37088897069",
        "aff": "Department of Automation, Tsinghua University, Beijing, China; Zhejiang Lab, Intelligent Robot Research Center, Hangzhou, China; Department of Automation, Tsinghua University, Beijing, China; Zhejiang Lab, Intelligent Robot Research Center, Hangzhou, China; Department of Electrical Engineering, Dalhousie University, Halifax, Canada; Department of Automation, Tsinghua University, Beijing, China; Ubtech Robotics Corp., Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562090/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4861101149842349276&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;1;2;0;3",
        "aff_unique_norm": "Tsinghua University;Zhejiang Lab;Dalhousie University;UBTech Robotics Corp.",
        "aff_unique_dep": "Department of Automation;Intelligent Robot Research Center;Department of Electrical Engineering;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;;https://www.dal.ca;https://www.ubtech.com/",
        "aff_unique_abbr": "THU;;Dal;",
        "aff_campus_unique_index": "0;1;0;1;2;0",
        "aff_campus_unique": "Beijing;Hangzhou;Halifax;",
        "aff_country_unique_index": "0;0;0;0;1;0;0",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "9561935",
        "title": "A Cascaded LiDAR-Camera Fusion Network for Road Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Most of the existing road detection methods are either single-modal based, e.g., based on LiDAR or camera, or multi-modal based with LiDAR-camera fusion. The algorithms are designed for a specific data type, and cannot cope with input data changes. In addition, the LiDAR-camera based methods can only work in day time with enough light. In this paper, we develop a novel LiDAR-camera fusion strategy, which combines the LiDAR point clouds and the camera images in a cascaded way. The proposed network has two working modes, the single-modal mode with LiDAR point clouds only and the multimodal mode with both LiDAR and camera data, so it can be used in all day scenes. The whole network consists of three parts: 1) LiDAR segmentation module, which segments road points in the LiDAR\u2019s imagery view. 2) Sparse-to-dense module, which upsamples the sparse LiDAR feature maps to dense road detection results. 3) LiDAR-camera fusion module, which fuses the dense LiDAR feature maps with the dense camera images to obtain accurate road estimations. Experiments on the KITTI-Road dataset show that the proposed cascaded LiDAR-camera fusion network can obtain very competitive road detection performance, with a MaxF value of 96.38%, and achieve the state-of-the-art in the single-modal mode among all LiDAR-only methods.",
        "primary_area": "",
        "author": "Shuo Gu;Jian Yang;Hui Kong;Shuo Gu;Jian Yang;Hui Kong",
        "authorids": "/37086251612;/37280205100;/37061510500;/37086251612;/37280205100;/37061510500",
        "aff": "PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; PCA Lab, Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561935/",
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17910683338827088909&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nanjing University of Science and Technology",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "http://www.nust.edu.cn",
        "aff_unique_abbr": "NJUST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561368",
        "title": "A Comparison Between Joint Space and Task Space Mappings for Dynamic Teleoperation of an Anthropomorphic Robotic Arm in Reaction Tests",
        "track": "main",
        "status": "Poster",
        "abstract": "Teleoperation\u2014i.e., controlling a robot with human motion\u2014proves promising in enabling a humanoid robot to move as dynamically as a human. But how to map human motion to a humanoid robot matters because a human and a humanoid robot rarely have identical topologies and dimensions. This work presents an experimental study that utilizes reaction tests to compare joint space and task space mappings for dynamic teleoperation of an anthropomorphic robotic arm that possesses human-level dynamic motion capabilities. The experimental results suggest that the robot achieved similar and, in some cases, human-level dynamic performances with both mappings for the six participating human subjects. All subjects became proficient at teleoperating the robot with both mappings after practice, despite that the subjects and the robot differed in size and link length ratio and that the teleoperation required the subjects to move unintuitively. Yet, most subjects developed their teleoperation proficiencies more quickly with task space mapping than with joint space mapping after similar amounts of practice. This study also indicates the potential values of three-dimensional task space mapping, a teleoperation training simulator, and force feedback to the human pilot for intuitive and dynamic teleoperation of a humanoid robot\u2019s arms.",
        "primary_area": "",
        "author": "Sunyu Wang;Kevin Murphy;Dillan Kenney;Joao Ramos;Sunyu Wang;Kevin Murphy;Dillan Kenney;Joao Ramos",
        "authorids": "/37086931682;/37089477145;/37088997585;/37085375922;/37086931682;/37089477145;/37088997585;/37085375922",
        "aff": "Department of Mechanical Science and Engineering, the University of Illinois at Urbana-Champaign, USA; Department of Mechanical Science and Engineering, the University of Illinois at Urbana-Champaign, USA; Department of Mechanical Science and Engineering, the University of Illinois at Urbana-Champaign, USA; Department of Mechanical Science and Engineering, the University of Illinois at Urbana-Champaign, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561368/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13651701380945111021&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Mechanical Science and Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561685",
        "title": "A Confidence-Based Supervised-Autonomous Control Strategy for Robotic Vaginal Cuff Closure",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous robotic suturing has the potential to improve surgery outcomes by leveraging accuracy, repeatability, and consistency compared to manual operations. However, achieving full autonomy in complex surgical environments is not practical and human supervision is required to guarantee safety. In this paper, we develop a confidence-based supervised autonomous suturing method to perform robotic suturing tasks via both Smart Tissue Autonomous Robot (STAR) and surgeon collaboratively with the highest possible degree of autonomy. Via the proposed method, STAR performs autonomous suturing when highly confident and otherwise asks the operator for possible assistance in suture positioning adjustments. We evaluate the accuracy of our proposed control method via robotic suturing tests on synthetic vaginal cuff tissues and compare them to the results of vaginal cuff closures performed by an experienced surgeon. Our test results indicate that by using the proposed confidence-based method, STAR can predict the success of pure autonomous suture placement with an accuracy of 94.74%. Moreover, via an additional 25% human intervention, STAR can achieve a 98.1% suture placement accuracy compared to an 85.4% accuracy of completely autonomous robotic suturing. Finally, our experiment results indicate that STAR using the proposed method achieves 1.6 times better consistency in suture spacing and 1.8 times better consistency in suture bite sizes than the manual results.",
        "primary_area": "",
        "author": "Michael Kam;Hamed Saeidi;Michael H. Hsieh;J. U. Kang;Axel Krieger;Michael Kam;Hamed Saeidi;Michael H. Hsieh;J. U. Kang;Axel Krieger",
        "authorids": "/37086456157;/37085642285;/37074949000;/37273713000;/38484449800;/37086456157;/37085642285;/37074949000;/37273713000;/38484449800",
        "aff": "Dep. of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Dep. of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Dep. of Urology, Children's National Health System, Washington, DC, USA; Dep. of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Dep. of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561685/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10643192483662019564&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Johns Hopkins University;Children's National Health System",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Urology",
        "aff_unique_url": "https://www.jhu.edu;https://childrensnational.org",
        "aff_unique_abbr": "JHU;",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Baltimore;Washington, DC",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561938",
        "title": "A Continuous-Time Approach for 3D Radar-to-Camera Extrinsic Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "Reliable operation in inclement weather is essential to the deployment of safe autonomous vehicles (AVs). Robustness and reliability can be achieved by fusing data from the standard AV sensor suite (i.e., lidars, cameras) with weather robust sensors, such as millimetre-wavelength radar. Critically, accurate sensor data fusion requires knowledge of the rigidbody transform between sensor pairs, which can be determined through the process of extrinsic calibration. A number of extrinsic calibration algorithms have been designed for 2D (planar) radar sensors\u2014however, recently-developed, low-cost 3D millimetre-wavelength radars are set to displace their 2D counterparts in many applications. In this paper, we present a continuous-time 3D radar-to-camera extrinsic calibration algorithm that utilizes radar velocity measurements and, unlike the majority of existing techniques, does not require specialized radar retroreflectors to be present in the environment. We derive the observability properties of our formulation and demonstrate the efficacy of our algorithm through synthetic and real-world experiments.",
        "primary_area": "",
        "author": "Emmett Wise;Juraj Per\u0161i\u0107;Christopher Grebe;Ivan Petrovi\u0107;Jonathan Kelly;Emmett Wise;Juraj Per\u0161i\u0107;Christopher Grebe;Ivan Petrovi\u0107;Jonathan Kelly",
        "authorids": "/37088541180;/37086217528;/37089002066;/37564131900;/37085364182;/37088541180;/37086217528;/37089002066;/37564131900;/37085364182",
        "aff": "Space & Terrestrial Autonomous Robotics Systems (STARS) Laboratory, The University of Toronto Institute for Aerospace Studies, Toronto, Canada; Laboratory for Autonomous Systems and Mobile Robotics, University of Zagreb Faculty of Electrical Engineering and Computing, Croatia; Space & Terrestrial Autonomous Robotics Systems (STARS) Laboratory, The University of Toronto Institute for Aerospace Studies, Toronto, Canada; Laboratory for Autonomous Systems and Mobile Robotics, University of Zagreb Faculty of Electrical Engineering and Computing, Croatia; Space & Terrestrial Autonomous Robotics Systems (STARS) Laboratory, The University of Toronto Institute for Aerospace Studies, Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561938/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5802914859628053697&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "University of Toronto Institute for Aerospace Studies;University of Zagreb",
        "aff_unique_dep": "Space & Terrestrial Autonomous Robotics Systems (STARS) Laboratory;Faculty of Electrical Engineering and Computing",
        "aff_unique_url": "https://www.ias.uToronto.ca;https://www.fesb.hr",
        "aff_unique_abbr": "UTIAS;",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Toronto;Zagreb",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "Canada;Croatia"
    },
    {
        "id": "9560941",
        "title": "A Convex Quasistatic Time-stepping Scheme for Rigid Multibody Systems with Contact and Friction",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning for robotic manipulation makes heavy use of quasistatic models, but these same models have not yet proven useful for simulation. This is because in many multi-contact situations, the quasistatic models do not describe a unique next state for the system. A planner is able to use these models optimistically (checking only for feasibility of a motion), but simulation requires more.In this work, we enable quasistatic models to uniquely determine contact forces by modeling actuated robots as impedances instead of prescribed motions. Using this model with a well-known convex relaxation for Coulomb friction, time-stepping of quasistatic models can be formulated as a convex Quadratic Program (QP). This convex relaxation does admit mild non-physical behavior between relatively-sliding objects, but through simulations of various complexity, we show that the proposed quasistatic time-stepping scheme generates mostly physically-realistic behaviors, and scales well with the complexity of the simulated systems.",
        "primary_area": "",
        "author": "Tao Pang;Russ Tedrake;Tao Pang;Russ Tedrake",
        "authorids": "/37089309719;/37283152200;/37089309719;/37283152200",
        "aff": "Tao Pang; Russ Tedrake",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560941/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5533229956542113793&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9561827",
        "title": "A Data-Driven Approach for Contact Detection, Classification and Reaction in Physical Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers a scenario where a robot and a human operator share the same workspace, and the robot is able to both carry out autonomous tasks and physically interact with the human in order to achieve common goals. In this context, both intentional and accidental contacts between human and robot might occur due to the complexity of tasks and environment, to the uncertainty of human behavior, and to the typical lack of awareness of each other actions. Here, a two stage strategy based on Recurrent Neural Networks (RNNs) is designed to detect intentional and accidental contacts: the occurrence of a contact with the human is detected at the first stage, while the classification between intentional and accidental is performed at the second stage. An admittance control strategy or an evasive action is then performed by the robot, respectively. The approach also works in the case the robot simultaneously interacts with the human and the environment, where the interaction wrench of the latter is modeled via Gaussian Mixture Models (GMMs). Control Barrier Functions (CBFs) are included, at the control level, to guarantee the satisfaction of robot and task constraints while performing the proper interaction strategy. The approach has been validated on a real setup composed of a Kinova Jaco2 robot.",
        "primary_area": "",
        "author": "Martina Lippi;Giuseppe Gillini;Alessandro Marino;Filippo Arrichiello;Martina Lippi;Giuseppe Gillini;Alessandro Marino;Filippo Arrichiello",
        "authorids": "/37086443839;/37087103540;/37390952800;/37298259000;/37086443839;/37087103540;/37390952800;/37298259000",
        "aff": "Roma Tre University, Italy; University of Cassino and Southern Lazio, Italy; University of Cassino and Southern Lazio, Italy; University of Cassino and Southern Lazio, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561827/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=748918983396814131&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Roma Tre University;University of Cassino and Southern Lazio",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uniroma3.it;https://www.unicas.it",
        "aff_unique_abbr": "Roma Tre;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9562062",
        "title": "A Data-Driven Reinforcement Learning Solution Framework for Optimal and Adaptive Personalization of a Hip Exoskeleton",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic exoskeletons are exciting technologies for augmenting human mobility. However, designing such a device for seamless integration with the human user and to assist human movement still is a major challenge. This paper aims at developing a novel data-driven solution framework based on reinforcement learning (RL), without first modeling the human-robot dynamics, to provide optimal and adaptive personalized torque assistance for reducing human efforts during walking. Our automatic personalization solution framework includes the assistive torque profile with two control timing parameters (peak and offset timings), the least square policy iteration (LSPI) for learning the parameter tuning policy, and a cost function based on a transferred work ratio. The proposed controller was successfully validated on a healthy human subject to assist unilateral hip extension in walking. The results showed that the optimal and adaptive RL controller as a new approach was feasible for tuning assistive torque profile of the hip exoskeleton that coordinated with human actions and reduced activation level of hip extensor muscle in human.",
        "primary_area": "",
        "author": "Xikai Tu;Minhan Li;Ming Liu;Jennie Si;He Helen Huang;Xikai Tu;Minhan Li;Ming Liu;Jennie Si;He Helen Huang",
        "authorids": "/37085375520;/37086936924;/38237723700;/37308391800;/37401091200;/37085375520;/37086936924;/38237723700;/37308391800;/37401091200",
        "aff": "Department of Mechanical Engineering, Hubei University of Technology, Wuhan, China; University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Electrical, Computer, and Energy Engineering, Arizona State University, Tempe, AZ, USA; University of North Carolina at Chapel Hill, Chapel Hill, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562062/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14945161452834895057&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;1",
        "aff_unique_norm": "Hubei University of Technology;University of North Carolina at Chapel Hill;Arizona State University",
        "aff_unique_dep": "Department of Mechanical Engineering;;Department of Electrical, Computer, and Energy Engineering",
        "aff_unique_url": ";https://www.unc.edu;https://www.asu.edu",
        "aff_unique_abbr": ";UNC Chapel Hill;ASU",
        "aff_campus_unique_index": "0;1;1;2;1",
        "aff_campus_unique": "Wuhan;Chapel Hill;Tempe",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561424",
        "title": "A Direct Collocation method for optimization of EMG-driven wrist muscle musculoskeletal model",
        "track": "main",
        "status": "Poster",
        "abstract": "EMG-driven musculoskeletal model has been broadly used to detect human intention in rehabilitation robots. This approach computes muscle-tendon force and translates it to the joint kinematics. However, the muscle-tendon parameters of the musculoskeletal model are difficult to measure in vivo and varied across subjects. In this study, a direct collocation (DC) method is proposed to optimize the subject-specific parameters in a wrist musculoskeletal model. The resultant optimized parameters are used to estimate the wrist flexion/extension motion. The estimation performance is compared with the parameters optimized by the genetic algorithm. Experiment results show that the DC methods have a similar performance compared with GA, in which the mean correlation are 0.96 and 0.93 for the genetic algorithm and DC method respectively. But the direction collocation method requires less optimization time.",
        "primary_area": "",
        "author": "Yihui Zhao;Zhenhong Li;Zhiqiang Zhang;Ahmed Asker;Sheng Q. Xie;Yihui Zhao;Zhenhong Li;Zhiqiang Zhang;Ahmed Asker;Sheng Q. Xie",
        "authorids": "/37088655338;/37085726884;/37537888200;/37085539047;/37833367900;/37088655338;/37085726884;/37537888200;/37085539047;/37833367900",
        "aff": "Institute of Rehabilitation Engineering, Binzhou Medical University, Yantai, China; Institute of Rehabilitation Engineering, Binzhou Medical University, Yantai, China; Institute of Rehabilitation Engineering, Binzhou Medical University, Yantai, China; Institute of Rehabilitation Engineering, Binzhou Medical University, Yantai, China; Institute of Rehabilitation Engineering, Binzhou Medical University, Yantai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561424/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13582956322636920261&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Binzhou Medical University",
        "aff_unique_dep": "Institute of Rehabilitation Engineering",
        "aff_unique_url": "http://www.bzmu.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Yantai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561482",
        "title": "A Drive-through Recharging Strategy for a Quadrotor",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a drive-through recharging strategy for a quadrotor. First, a ground charging station is constructed with a portable charging wire, then with two conductive hooks connected to the battery, the quadrotor is flying through the station. Finally, after connecting the hooks to the charging wire, the quadrotor can be recharged without landing or stopping, similar to a drive-through. During the charging, the quadrotor is still able to accomplish local monitoring assignments. The main challenge of this work is to ensure that the hooks successfully connect to the charging wire. Though visual-based techniques appear promising to handle this problem, the detection of a thin charging wire is challenging especially during the flight. Besides, the conductive hooks underneath the quadrotor are out of the camera view, which brings more challenges to the problem. Therefore, in this paper, the aiming problem is directed into the position constraint control problem of the quadrotor. Specifically, a virtual aiming box is considered near the charging wire center, then a control design is proposed to constrain the position of the quadrotor to ensure the hooks position always within the virtual aiming box. Moreover, to enhance the system robustness against the outdoor environment, a wind disturbance estimator is proposed in the control design. Both theoretical analysis and experimental validation are carried out to demonstrate the effectiveness of the proposed strategy.",
        "primary_area": "",
        "author": "Yafeng Wang;Qinbo Sun;Tristan Berger;Weimin Qi;Yafeng Wang;Qinbo Sun;Tristan Berger;Weimin Qi",
        "authorids": "/37086960317;/37086608896;/37088998665;/37087243921;/37086960317;/37086608896;/37088998665;/37087243921",
        "aff": "Department of Mechanical Engineering, Texas Tech University, Lubbock, TX, USA; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China; Mechatronics, ENSIL-ENSCI Engineering School of Limoges, Limoges, France; School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561482/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13266744966437685096&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Texas Tech University;Chinese University of Hong Kong;ENSI-ENSCI Engineering School of Limoges",
        "aff_unique_dep": "Department of Mechanical Engineering;School of Science and Engineering;Mechatronics",
        "aff_unique_url": "https://www.ttu.edu;https://www.cuhk.edu.cn;https://www.ensil-ensci.fr",
        "aff_unique_abbr": "TTU;CUHK;",
        "aff_campus_unique_index": "0;1;2;1",
        "aff_campus_unique": "Lubbock;Shenzhen;Limoges",
        "aff_country_unique_index": "0;1;2;1",
        "aff_country_unique": "United States;China;France"
    },
    {
        "id": "9561420",
        "title": "A Dynamics Simulator for Soft Growing Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Simulating soft robots in cluttered environments remains an open problem due to the challenge of capturing complex dynamics and interactions with the environment. Furthermore, fast simulation is desired for quickly exploring robot behaviors in the context of motion planning. In this paper, we examine a particular class of inflated-beam soft growing robots called \"vine robots,\" and present a dynamics simulator that captures general behaviors, handles robot-object interactions, and runs faster than real time. The simulator framework uses a simplified multi-link, rigid-body model with contact constraints. To bridge the sim-to-real gap, we develop methods for fitting model parameters based on video data of a robot in motion and in contact with an environment. We provide examples of simulations, including several with fit parameters, to show the qualitative and quantitative agreement between simulated and real behaviors. Our work demonstrates the capabilities of this high-speed dynamics simulator and its potential for use in the control of soft robots.",
        "primary_area": "",
        "author": "Rianna Jitosho;Nathaniel Agharese;Allison Okamura;Zac Manchester;Rianna Jitosho;Nathaniel Agharese;Allison Okamura;Zac Manchester",
        "authorids": "/37086937312;/37086452967;/37276156400;/37086011525;/37086937312;/37086452967;/37276156400;/37086011525",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561420/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16254804973867410443&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Stanford University;Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering;Robotics Institute",
        "aff_unique_url": "https://www.stanford.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Stanford;CMU",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Stanford;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562067",
        "title": "A Fast and Approximate Medial Axis Sampling Technique",
        "track": "main",
        "status": "Poster",
        "abstract": "One key aspect to planning safe motions for a robot requires maintaining a minimum distance from obstacles. The medial axis, or the set of all points equidistant to two or more obstacles, is useful for planning in this context. However, it is computationally intensive to compute this structure directly. As such, prior research proposed directly sampling this structure to avoid its explicit computation. In this paper, we revisit the computational cost of these sampling-based techniques for motion planning, and we propose a novel approximation algorithm that significantly reduces the necessary collision detection invocations in generating samples near the medial axis. At its core, our technique approximates the clearance of a configuration by reasoning about the clearance of nearby configurations. Ultimately, our approach reduces the computational burden of planning on or near the medial axis.",
        "primary_area": "",
        "author": "Jory Denny;David Qin;Hanglin Zhou;Jory Denny;David Qin;Hanglin Zhou",
        "authorids": "/37947351200;/37089001096;/37086578070;/37947351200;/37089001096;/37086578070",
        "aff": "Department of Mathematics and Computer Science, SpiRoL: Spider Robotics Lab, University of Richmond, VA, USA; Department of Mathematics and Computer Science, SpiRoL: Spider Robotics Lab, University of Richmond, VA, USA; Department of Mathematics and Computer Science, SpiRoL: Spider Robotics Lab, University of Richmond, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562067/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9509430433233633291&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Richmond",
        "aff_unique_dep": "Department of Mathematics and Computer Science",
        "aff_unique_url": "https://www.richmond.edu",
        "aff_unique_abbr": "UR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Richmond",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561735",
        "title": "A Fault Tolerant Control Architecture Based on Fault Trees for an Underwater Robot Executing Transect Missions",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic systems evolving in hazardous and harsh environment are prone to mission failure or system loss in presence of faults. This paper presents a fault tolerant methodology, implemented into a control architecture of an underwater robot that executes biological monitoring missions. High level constraint violations (mission, safety, energy, time and localization) and low level faults (software and hardware faults) are considered using a method based on fault trees. These undesirable events are detected and treated by a fault tolerant module that decides to recover at low level or to give a feedback to the mission manager which selects the high level reaction. This fault tolerant architecture has been tested on real field conditions, and we illustrate our methodology on a set of selected events. We conclude about reliability improvement of low cost underwater robots for complex and long missions.",
        "primary_area": "",
        "author": "Adrien Hereau;Karen Godary-Dejean;J\u00e9r\u00e9mie Guiochet;Didier Crestani;Adrien Hereau;Karen Godary-Dejean;J\u00e9r\u00e9mie Guiochet;Didier Crestani",
        "authorids": "/37088995855;/38270047500;/37937604500;/38308041800;/37088995855;/38270047500;/37937604500;/38308041800",
        "aff": "LIRMM, University of Montpellier, CNRS, Montpellier, France; LIRMM, University of Montpellier, CNRS, Montpellier, France; LAAS-CNRS, University of Toulouse, CNRS, UPS, Toulouse, France; LIRMM, University of Montpellier, CNRS, Montpellier, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561735/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10169458965348499613&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Montpellier;LAAS-CNRS",
        "aff_unique_dep": "LIRMM;",
        "aff_unique_url": "https://www.univ-montp2.fr;https://www.laas.fr/",
        "aff_unique_abbr": "UM;LAAS-CNRS",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Montpellier;Toulouse",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561056",
        "title": "A Few Shot Adaptation of Visual Navigation Skills to New Observations using Meta-Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Target-driven visual navigation is a challenging problem that requires a robot to find the goal using only visual inputs. Many researchers have demonstrated promising results using deep reinforcement learning (deep RL) on various robotic platforms, but typical end-to-end learning is known for its poor extrapolation capability to new scenarios. Therefore, learning a navigation policy for a new robot with a new sensor configuration or a new target still remains a challenging problem. In this paper, we introduce a learning algorithm that enables rapid adaptation to new sensor configurations or target objects with a few shots. We design a policy architecture with latent features between perception and inference networks and quickly adapt the perception network via meta-learning while freezing the inference network. Our experiments show that our algorithm adapts the learned navigation policy with only three shots for unseen situations with different sensor configurations or different target colors. We also analyze the proposed algorithm by investigating various hyperparameters.",
        "primary_area": "",
        "author": "Qian Luo;Maks Sorokin;Sehoon Ha;Qian Luo;Maks Sorokin;Sehoon Ha",
        "authorids": "/37089000136;/37088996336;/37086314268;/37089000136;/37088996336;/37086314268",
        "aff": "Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Robotics at Google, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561056/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7651021683560714326&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Georgia Institute of Technology;Google",
        "aff_unique_dep": ";Robotics",
        "aff_unique_url": "https://www.gatech.edu;https://www.google.com",
        "aff_unique_abbr": "Georgia Tech;Google",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Atlanta;Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561192",
        "title": "A Finite-Gain Stable Multi-Agent Robot Control Framework with Adaptive Authority Allocation",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-agent control of a robot using multiple controllers is vital in domains like shared control and reliable control. The strategy of assigning a varying priority (authority) to each agent controller, and commanding the robot using an authority-weighted sum of the forces produced by all the agents has been exploited in prior works. In this paper, firstly, we show that this strategy results in a loss of passivity, and we identify the passivity-disrupting scaling-related terms. Secondly, we propose a model independent method to ensure finite-gain L2 stability of such a generic multi-agent robot control system with time-varying force scaling factors. Thirdly, the analysis is validated with simulations and hardware experiments.",
        "primary_area": "",
        "author": "Ribin Balachandran;Hrishik Mishra;Michael Panzirsch;Christian Ott;Ribin Balachandran;Hrishik Mishra;Michael Panzirsch;Christian Ott",
        "authorids": "/37085381760;/37086428941;/37085398040;/37282440400;/37085381760;/37086428941;/37085398040;/37282440400",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561192/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7410724218172975223&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561421",
        "title": "A Flexible Magnetic Field Mapping Model For Calibration of Magnetic Manipulation System",
        "track": "main",
        "status": "Poster",
        "abstract": "Magnetic manipulation provides a versatile, remote, noninvasive, and cost-effective strategy in a variety of applications. Till now, many different configurations of magnetic manipulation systems have been developed to address different needs on force, torque, accuracy, and accessibilities. Magnetic field mapping can help to explore the exact map of the magnetic field in the working space and guarantee the homogeneity of the magnetic field. In this paper, a flexible mapping method is employed to solve the scalar potential of the magnetic source by using the separation of variables in Cartesian coordinates. Levenberg-Marquardt Algorithm (LMA) and Whale Optimization Algorithm (WOA) are set to the solver of the model. The work is evaluated in the mapping of an eight-pole magnetic manipulation system. The result of numerical simulation shows that the coefficient of determination R2 of the model reaches99.81%, and the actual system mapping obtains R2 value of 99.57%. This technique can directly be used to calculate the magnetic flux density and gradient field in a short period (\u22481ms). Finally, the manipulation of a permanent magnet under the control magnetic field mapping and PID controller demonstrates the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Yi Xing;Yanchao Jia;Zhen Zhan;Jianjie Li;Chengzhi Hu;Yi Xing;Yanchao Jia;Zhen Zhan;Jianjie Li;Chengzhi Hu",
        "authorids": "/37089000019;/37088999036;/37089001805;/37089398918;/38025900900;/37089000019;/37088999036;/37089001805;/37089398918;/38025900900",
        "aff": "Department of Mechanical Engineering and Energy, Southern University of Science and Technology, China; Department of Mechanical Engineering and Energy, Southern University of Science and Technology, China; Department of Mechanical Engineering and Energy, Southern University of Science and Technology, China; Department of Mechanical Engineering and Energy, Southern University of Science and Technology, China; Department of Mechanical Engineering and Energy, Southern University of Science and Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561421/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3973358348686031871&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering and Energy",
        "aff_unique_url": "https://www.sustech.edu.cn",
        "aff_unique_abbr": "SUSTech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561126",
        "title": "A Flexible and Efficient Loop Closure Detection Based on Motion Knowledge",
        "track": "main",
        "status": "Poster",
        "abstract": "Loop closure detection (LCD) is an essential module for simultaneous localization and mapping (SLAM), which can correct accumulated errors after long-term explorations. The widely used bag-of-words (BoW) model can not satisfy well the requirements of both low time consumption and high accuracy for a mobile platform. In this paper, we propose a novel LCD algorithm based on motion knowledge. We give a flexible and efficient detection strategy and also give flexible and efficient combinations of a global binary feature extracted by convolutional neural network (CNN) and a hand-crafted local binary feature. We take a continuous motion model, grid-based motion statistics (GMS) and motion states as motion knowledge. Furthermore, we fuse the proposed LCD with a visual-inertial odometry (VIO) system to correct localization errors by a pose graph optimization. Comparative experiments with state-of-the-art LCD algorithms on typical datasets have been carried out, and the results demonstrate that our proposed method achieves quite high recall rates and quite high speed at 100% precision. Moreover, experimental results from VIO further validate the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Bingxi Liu;Fulin Tang;Yujie Fu;Yanqun Yang;Yihong Wu;Bingxi Liu;Fulin Tang;Yujie Fu;Yanqun Yang;Yihong Wu",
        "authorids": "/37089000347;/37086567542;/37089001494;/37088996228;/37337262300;/37089000347;/37086567542;/37089001494;/37088996228;/37337262300",
        "aff": "National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Innovation Technology Center, Shanxi Coking Coal Group Co., LTD, Taiyuan, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561126/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5828774327921308572&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Chinese Academy of Sciences;Shanxi Coking Coal Group Co., LTD",
        "aff_unique_dep": "Institute of Automation;Innovation Technology Center",
        "aff_unique_url": "http://www.ia.cas.cn;",
        "aff_unique_abbr": "CAS;",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Beijing;Taiyuan",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562068",
        "title": "A Framework for Multisensory Foresight for Embodied Agents",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting future sensory states is crucial for learning agents such as robots, drones, and autonomous vehicles. In this paper, we couple multiple sensory modalities with exploratory actions and propose a predictive neural network architecture to address this problem. Most existing approaches rely on large, manually annotated datasets, or only use visual data as a single modality. In contrast, the unsupervised method presented here uses multi-modal perceptions for predicting future visual frames. As a result, the proposed model is more comprehensive and can better capture the spatio-temporal dynamics of the environment, leading to more accurate visual frame prediction. The other novelty of our framework is the use of sub-networks dedicated to anticipating future haptic, audio, and tactile signals. The framework was tested and validated with a dataset containing 4 sensory modalities (vision, haptic, audio, and tactile) on a humanoid robot performing 9 behaviors multiple times on a large set of objects. While the visual information is the dominant modality, utilizing the additional non-visual modalities improves the accuracy of predictions.",
        "primary_area": "",
        "author": "Xiaohui Chen;Ramtin Hosseini;Karen Panetta;Jivko Sinapov;Xiaohui Chen;Ramtin Hosseini;Karen Panetta;Jivko Sinapov",
        "authorids": "/37088997952;/37087014514;/37411695500;/37546531000;/37088997952;/37087014514;/37411695500;/37546531000",
        "aff": "Tufts University, MA, USA; Tufts University, MA, USA; Tufts University, MA, USA; Tufts University, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562068/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12339883244603529448&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tufts University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tufts.edu",
        "aff_unique_abbr": "Tufts",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561392",
        "title": "A Front-End for Dense Monocular SLAM using a Learned Outlier Mask Prior",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent achievements in depth prediction from a single RGB image have powered the new research area of combining convolutional neural networks (CNNs) with classical simultaneous localization and mapping (SLAM) algorithms. The depth prediction from a CNN provides a reasonable initial point in the optimization process in the traditional SLAM algorithms, while the SLAM algorithms further improve the CNN prediction online. However, most of the current CNN-SLAM approaches have only taken advantage of the depth prediction but not yet other products from a CNN. In this work, we explore the use of the outlier mask, a by-product from unsupervised learning of depth from video, as a prior in a classical probability model for depth estimate fusion to step up the outlier-resistant tracking performance of a SLAM front-end. On the other hand, some of the previous CNN-SLAM work builds on feature-based sparse SLAM methods, wasting the per-pixel dense prediction from a CNN. In contrast to these sparse methods, we devise a dense CNN-assisted SLAM frontend that is implementable with TensorFlow and evaluate it on both indoor and outdoor datasets.",
        "primary_area": "",
        "author": "Yihao Zhang;John J. Leonard;Yihao Zhang;John J. Leonard",
        "authorids": "/37088999548;/37329387400;/37088999548;/37329387400",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561392/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17245853131620984076&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561127",
        "title": "A Fully Spiking Neural Control System Based on Cerebellar Predictive Learning for Sensor-Guided Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The cerebellum plays a distinctive role within our motor control system to achieve fine and coordinated motions. While cerebellar lesions do not lead to a complete loss of motor functions, both action and perception are severally impacted. Hence, it is assumed that the cerebellum uses an internal forward model to provide anticipatory signals by learning from the error in sensory states. In some studies, it was demonstrated that the learning process relies on the jointspace error. However, this may not exist. This work proposes a novel fully spiking neural system that relies on a forward predictive learning by means of a cellular cerebellar model. The forward model is learnt thanks to the sensory feedback in task-space and it acts as a Smith predictor. The latter predicts sensory corrections in input to a differential mapping spiking neural network during a visual servoing task of a robot arm manipulator. In this paper, we promote the developed control system to achieve more accurate target reaching actions and reduce the motion execution time for the robotic reaching tasks thanks to the cerebellar predictive capabilities.",
        "primary_area": "",
        "author": "Omar Zahra;David Navarro-Alarcon;Silvia Tolu;Omar Zahra;David Navarro-Alarcon;Silvia Tolu",
        "authorids": "/37087649475;/38271697000;/37085870566;/37087649475;/38271697000;/37085870566",
        "aff": "Department of Mechanical Engineering, The Hong Kong Polytechnic University, Kowloon, Hong Kong; Department of Mechanical Engineering, The Hong Kong Polytechnic University, Kowloon, Hong Kong; Department of Electrical Engineering, Technical University of Denmark, Copenhagen, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561127/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1124989789774375760&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Hong Kong Polytechnic University;Technical University of Denmark",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electrical Engineering",
        "aff_unique_url": "https://www.polyu.edu.hk;https://www.dtu.dk",
        "aff_unique_abbr": "PolyU;DTU",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Hong Kong SAR;Copenhagen",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;Denmark"
    },
    {
        "id": "9561841",
        "title": "A General-Purpose Anomalous Scenario Synthesizer for Rotary Equipment",
        "track": "main",
        "status": "Poster",
        "abstract": "Data synthesizing is crucial for data-driven anomaly prognostics on physical machines. We propose the first general-purpose anomalous scenario synthesizer, GPASS, for rotary equipment. More specifically, we present a design of implementing modular rotational damping, large lateral force, with high-frequency range capability as fundamental modes of physical inputs. The GPASS is a general-purpose platform that can impose inputs independently or jointly, and generate an extensive range of anomalous scenarios on the same subject. Finally, it has the capability of capturing multi-variate sensor readings on the same anomalous event. Experimental results demonstrate that the synthesizer can dynamically and accurately introduce lateral force at specified magnitudes and frequencies, proving the effectiveness of the proposed device.",
        "primary_area": "",
        "author": "Yip Fun Yeung;Ali Alshehri;Lois Wampler;Mikio Furokawa;Takayuki Hirano;Kamal Youcef-Toumi;Yip Fun Yeung;Ali Alshehri;Lois Wampler;Mikio Furokawa;Takayuki Hirano;Kamal Youcef-Toumi",
        "authorids": "/37088687204;/37089001004;/37088998565;/37086933718;/37086934581;/38271700200;/37088687204;/37089001004;/37088998565;/37086933718;/37086934581;/38271700200",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; The Japan Steel Works, LTD., Hiroshima Plant, Japan; The Japan Steel Works, LTD., Hiroshima Plant, Japan; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561841/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8080028472785191544&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Japan Steel Works, LTD.",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://web.mit.edu;https://www.jsw.co.jp",
        "aff_unique_abbr": "MIT;JSW",
        "aff_campus_unique_index": "0;0;0;1;1;0",
        "aff_campus_unique": "Cambridge;Hiroshima",
        "aff_country_unique_index": "0;0;0;1;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9561135",
        "title": "A Generalized A* Algorithm for Finding Globally Optimal Paths in Weighted Colored Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "Both geometric and semantic information of the search space are imperative for a good plan. We encode those properties in a weighted colored graph (geometric information in terms of edge weight and semantic information in terms of edge and vertex color) and propose a generalized A\u2217 to find the shortest path among the set of paths with minimal inclusion of low-ranked color edges. We prove the completeness and optimality of this Class-Ordered A\u2217 (COA\u2217 ) algorithm with respect to the hereto defined notion of optimality. The utility of COA\u2217 is numerically validated in a ternary graph with feasible, infeasible, and unknown vertices and edges for the cases of a 2D mobile robot, a 3D robotic arm, and a 5D robotic arm with limited sensing capabilities. We compare the results of COA\u2217 to that of the regular A\u2217 algorithm, the latter of which finds a shortest path regardless of the semantic information, and we show that the COA\u2217 dominates the A\u2217 solution in terms of finding less uncertain paths.",
        "primary_area": "",
        "author": "Jaein Lim;Panagiotis Tsiotras;Jaein Lim;Panagiotis Tsiotras",
        "authorids": "/37088506597;/37330609800;/37088506597;/37330609800",
        "aff": "School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Aerospace Engineering and Associate Director, Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561135/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13336405842731552687&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Aerospace Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561787",
        "title": "A Generative Model-Based Predictive Display for Robotic Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new generative model-based predictive display for robotic teleoperation over high-latency communication links. Our method is capable of rendering photo-realistic images of the scene to the human operator in real time from RGB-D images acquired by the remote robot. A preliminary exploration stage is used to build a coarse 3D map of the remote environment and to train a generative model, both of which are then used to generate photo-realistic images for the human operator based on the commanded pose of the robot. Data captured by the remote robot is used to dynamically update the 3D map, enabling teleoperation in the presence of new and relocated objects. Various experiments validate our proposed method\u2019s performance and benefits over alternative methods.",
        "primary_area": "",
        "author": "Bowen Xie;Mingjie Han;Jun Jin;Martin Barczyk;Martin J\u00e4gersand;Bowen Xie;Mingjie Han;Jun Jin;Martin Barczyk;Martin J\u00e4gersand",
        "authorids": "/37088997299;/37088998699;/37086574802;/37544927400;/37269568300;/37088997299;/37088998699;/37086574802;/37544927400;/37269568300",
        "aff": "Department of Mechanical Engineering, University of Alberta, Edmonton, Canada; Department of Mechanical Engineering, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada; Department of Mechanical Engineering, University of Alberta, Edmonton, Canada; Department of Computing Science, University of Alberta, Edmonton, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561787/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3084289085918897606&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Edmonton",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561433",
        "title": "A Geometric Folding Pattern for Robot Coverage Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Conventional coverage path planning algorithms are mainly based on the zigzag and spiral patterns or their combinations. The traversal order is limited by the linear or inside-outside manner. We propose a new set of coverage patterns induced from geometric folding operations, called the geometric folding pattern, to make coverage paths with more flexible traversal order. We study the modeling and parameterization of the geometric folding patterns. Then, a sampling operator is introduced. Based on the computational tools, we demonstrate the application of the proposed patterns in designing coverage paths. We show that the simple geometric folding patterns are flexible and controllable, which enables more choices for the coverage path planning problem.",
        "primary_area": "",
        "author": "Lifeng Zhu;Shuai Yao;Boyang Li;Aiguo Song;Yiyang Jia;Jun Mitani;Lifeng Zhu;Shuai Yao;Boyang Li;Aiguo Song;Yiyang Jia;Jun Mitani",
        "authorids": "/37086246211;/37089100655;/37089000670;/37276033000;/37088999040;/37089403802;/37086246211;/37089100655;/37089000670;/37276033000;/37088999040;/37089403802",
        "aff": "The State Key Laboratory of Bioelectronics, Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, P.R.China; China Jiliang University, China; Tsinghua University, China; The State Key Laboratory of Bioelectronics, Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, P.R.China; University of Tsukuba, Japan; University of Tsukuba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561433/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15777235538101720415&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;3;3",
        "aff_unique_norm": "Southeast University;China Jiliang University;Tsinghua University;University of Tsukuba",
        "aff_unique_dep": "School of Instrument Science and Engineering;;;",
        "aff_unique_url": "https://www.seu.edu.cn/;http://www.cjluniversity.edu.cn;https://www.tsinghua.edu.cn;https://www.tsukuba.ac.jp",
        "aff_unique_abbr": "SEU;CJLU;THU;UT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9561605",
        "title": "A Graph Attention Spatio-temporal Convolutional Network for 3D Human Pose Estimation in Video",
        "track": "main",
        "status": "Poster",
        "abstract": "Spatio-temporal information is key to resolve occlusion and depth ambiguity in 3D human pose estimation. Previous methods have focused on either temporal contexts or local-to-global architectures that embed fixed-length spatiotemporal information. To date, there have not been effective proposals to simultaneously and flexibly capture varying spatiotemporal sequences and effectively achieves real-time 3D human pose estimation. In this work, we improve the learning of kinematic constraints in the human skeleton: posture, local kinematic connections, and symmetry by modeling local and global spatial information via attention mechanisms. To adapt to single- and multi-frame estimation, the dilated temporal model is employed to process varying skeleton sequences. Also, importantly, we carefully design the interleaving of spatial semantics with temporal dependencies to achieve a synergistic effect. To this end, we propose a simple yet effective graph attention spatio-temporal convolutional network (GAST-Net) that comprises of interleaved temporal convolutional and graph attention blocks. Experiments on two challenging benchmark datasets (Human3.6M and HumanEva-I) and YouTube videos demonstrate that our approach effectively mitigates depth ambiguity and self-occlusion, generalizes to half upper body estimation, and achieves competitive performance on 2D-to-3D video pose estimation. Code, video, and supplementary information is available at: http://www.juanrojas.net/gast/",
        "primary_area": "",
        "author": "Junfa Liu;Juan Rojas;Yihui Li;Zhijun Liang;Yisheng Guan;Ning Xi;Haifei Zhu;Junfa Liu;Juan Rojas;Yihui Li;Zhijun Liang;Yisheng Guan;Ning Xi;Haifei Zhu",
        "authorids": "/37598330900;/38469295700;/37089546773;/37089000518;/37402001000;/37274126400;/37853668000;/37598330900;/38469295700;/37089546773;/37089000518;/37402001000;/37274126400;/37853668000",
        "aff": "The Biomimetic and Intelligent Robotics Lab (BIRL), School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Dept. of Mechanical and Automation Engineering, Chinese University of Hong Kong, Hong Kong, China; The Biomimetic and Intelligent Robotics Lab (BIRL), School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; The Biomimetic and Intelligent Robotics Lab (BIRL), School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; The Biomimetic and Intelligent Robotics Lab (BIRL), School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China; Dept. of Industrial and Manufacturing Systems Engineering, The University of Hong Kong, SAR, China; The Biomimetic and Intelligent Robotics Lab (BIRL), School of Electromechanical Engineering, Guangdong University of Technology, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561605/",
        "gs_citation": 123,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17501312761048545827&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;2;0",
        "aff_unique_norm": "Guangdong University of Technology;Chinese University of Hong Kong;University of Hong Kong",
        "aff_unique_dep": "School of Electromechanical Engineering;Dept. of Mechanical and Automation Engineering;Dept. of Industrial and Manufacturing Systems Engineering",
        "aff_unique_url": "http://www.gdut.edu.cn;https://www.cuhk.edu.hk;https://www.hku.hk",
        "aff_unique_abbr": ";CUHK;HKU",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Guangzhou;Hong Kong;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560765",
        "title": "A Graph-Based Method for Joint Instance Segmentation of Point Clouds and Image Sequences",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of class agnostic, joint instance segmentation of scene data. While learning-based semantic instance segmentation methods have achieved impressive progress, their use is limited in robotics applications due to reliance on expensive training data annotations and assumptions of single sensor modality or known object classes. We propose a novel graph-based instance segmentation approach that combines information from a 2D image sequence and a 3D point cloud capturing the scene. Our approach propagates information with a general graph representation to produce a segmentation taking into account both geometric and photometric information. This allows us to leverage information from complementary sensor modalities without requiring training data. Our method shows improved object recall and boundary identification over state-of-the-art RGB-D segmentation methods. We demonstrate generality by evaluating on both RGB-D data and a LiDAR+image sensor data.",
        "primary_area": "",
        "author": "Montiel Abello;Joshua G. Mangelson;Michael Kaess;Montiel Abello;Joshua G. Mangelson;Michael Kaess",
        "authorids": "/37086331118;/37086109836;/37324200400;/37086331118;/37086109836;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Electrical and Computer Engineering Department, Brigham Young University, Provo, UT, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560765/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16169076068365019811&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Brigham Young University",
        "aff_unique_dep": "Robotics Institute;Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.cmu.edu;https://www.byu.edu",
        "aff_unique_abbr": "CMU;BYU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pittsburgh;Provo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561959",
        "title": "A Haptic Mouse Design with Stiffening Muscle Layer for Simulating Guarding in Abdominal Palpation Training",
        "track": "main",
        "status": "Poster",
        "abstract": "A patient would contract surface muscles as a reaction called muscle guarding when experiencing discomfort and pain during physical palpation. This reaction carries important information about an affected location. Training physicians to regulate palpation forces to elicit just enough muscle tension is a challenge using real patients. Tunable stiffness mechanisms enabled by soft robotics can be effectively integrated into medical simulator designs for effective clinical education. In this paper, we propose a controllable stiffness muscle layer to simulate guarding for abdominal palpation training. Designs with soft, fine, and rigid granular jamming, stretchable and non-stretchable layer jamming mechanisms were tested and evaluated as methods to create controllable stiffness muscle. User studies have been carried out on 10 naive participants to differentiate the tense and relaxed abdomen with the proposed jamming mechanisms. Muscle samples made of ground coffee (fine granular jamming) and latex layers (stretchable layer jamming) show good usability in simulating abdomen with different stiffness with at least 75% of the user data exhibits more than 70% of decision accuracy for both tested palpation gestures (single finger and multiple fingers) after short pre-training.",
        "primary_area": "",
        "author": "Liang He;Florence Leong;Thilina Dulantha Lalitharatne;Simon de Lusignan;Thrishantha Nanayakkara;Liang He;Florence Leong;Thilina Dulantha Lalitharatne;Simon de Lusignan;Thrishantha Nanayakkara",
        "authorids": "/37086496884;/38187555600;/38548735500;/37991052800;/37399134000;/37086496884;/38187555600;/38548735500;/37991052800;/37399134000",
        "aff": "Oxford Robotics Institute, University of Oxford, UK; Dyson School of Design Engineering, Imperial College, London, UK; Dyson School of Design Engineering, Imperial College, London, UK; Nuffield Department of Primary Care Health Sciences, University of Oxford, UK; Dyson School of Design Engineering, Imperial College, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561959/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7711127376641982973&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "University of Oxford;Imperial College London",
        "aff_unique_dep": "Oxford Robotics Institute;Dyson School of Design Engineering",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.imperial.ac.uk",
        "aff_unique_abbr": "Oxford;ICL",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Oxford;London",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561730",
        "title": "A Hybrid Collision Model for Safety Collision Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-collision detection and avoidance are essential for reactive control, in particular for dynamics robots equipped with legs or arms. Yet, only few control methods are able to handle such constraints, and it is often necessary to rely on path planning to define a collision-free trajectory that the controller would then track. In this paper, we introduce a combination of two lightweight, conservative and smooth models to generically handle self-collisions in robot control. For pairs of bodies that are far from one another on average (e.g. segments of distinct legs), we rely on a standard forward kinematics approach, using simplified geometries for which we provide analytical derivatives. For bodies that are moving close to one another, we propose to use a data-driven approach, with datasets generated thanks to a standard collision library. We then build a simple torque-based controller that can be implemented on top of any control law to prevent unexpected self-collision. This controller is meant to be implemented as a low-level protection, directly on the robot hardware. We also provide an open-source library to generate ANSI-C code for any robot model, experimented on the real quadruped Solo.",
        "primary_area": "",
        "author": "T. No\u00ebl;T. Flayols;J. Mirabel;J. Carpentier;N. Mansard;T. No\u00ebl;T. Flayols;J. Mirabel;J. Carpentier;N. Mansard",
        "authorids": "/37088996240;/37086293347;/37086157231;/37085506841;/37542913400;/37088996240;/37086293347;/37086157231;/37085506841;/37542913400",
        "aff": "LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; Artifical and Natural Intelligence Toulouse Insitute (ANITI), Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; INRIA, Ecole Normale Superieure, CNRS, PSL Research University, Paris, France; Artifical and Natural Intelligence Toulouse Insitute (ANITI), Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561730/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=319189570927447900&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;1",
        "aff_unique_norm": "LAAS-CNRS;Artifical and Natural Intelligence Toulouse Institute;INRIA",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.laas.fr/;;https://www.inria.fr",
        "aff_unique_abbr": "LAAS-CNRS;ANITI;INRIA",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Toulouse;Paris",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561279",
        "title": "A Hybrid Position/Force Controller for Joint Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a hybrid position/force controller for operating joint robots. The hybrid controller has two goals\u2014motion tracking and force regulating. As long as these two goals are not mutually exclusive, they can be decoupled in some way. In this work, we make use of the smooth and invertible mapping from the joint space to the task space to decouple the two control goals and design controllers separately. The traditional motion controller in the task space is used for motion control, while the force controller is designed through manipulating the desired trajectory to regulate the force indirectly. Two case studies\u2014contour tracking/polishing surfaces and grabbing boxes with two robotic arms\u2014are presented to show the efficacy of the hybrid controller, and simulations with physics engines are carried out to validate the efficacy of the proposed method.",
        "primary_area": "",
        "author": "Shengwen Xie;Juan Ren;Shengwen Xie;Juan Ren",
        "authorids": "/37086431913;/37957047600;/37086431913;/37957047600",
        "aff": "Department of Mechanical Engineering, Iowa State University, Ames, IA, USA; Department of Mechanical Engineering, Iowa State University, Ames, IA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561279/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3396488494303355120&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Iowa State University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.iastate.edu",
        "aff_unique_abbr": "ISU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ames",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561994",
        "title": "A Joint Network for Grasp Detection Conditioned on Natural Language Commands",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the task of grasping a target object based on a natural language command query. Previous work primarily focused on localizing the object given the query, which requires a separate grasp detection module to grasp it. The cascaded application of two pipelines incurs errors in overlapping multi-object cases due to ambiguity in the individal outputs. This work proposes a model named Command Grasping Network (CGNet) to directly output command satisficing grasps from RGB image and textual command inputs. A dataset with ground truth (image, command, grasps) tuple is generated based on the VMRD dataset to train the proposed network. Experimental results on the generated test set show that CGNet outperforms a cascaded object-retrieval and grasp detection baseline by a large margin. Three physical experiments demonstrate the functionality and performance of CGNet.",
        "primary_area": "",
        "author": "Yiye Chen;Ruinian Xu;Yunzhi Lin;Patricio A. Vela;Yiye Chen;Ruinian Xu;Yunzhi Lin;Patricio A. Vela",
        "authorids": "/37089001985;/37086419762;/37088506366;/37329553400;/37089001985;/37086419762;/37088506366;/37329553400",
        "aff": "School of Electrical and Computer Engineering, and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA; School of Electrical and Computer Engineering, and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA; School of Electrical and Computer Engineering, and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA; School of Electrical and Computer Engineering, and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561994/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5401974350083532034&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561684",
        "title": "A Knowledge-Based Fast Motion Planning Method Through Online Environmental Feature Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The sampling-based partial motion planning algorithm has come into widespread application in dynamic mobile robot navigation due to its low calculation costs and excellent performance in avoiding obstacles. However, when confronted with complicated scenarios, the motion planning algorithms are easily caught in traps. In order to solve this problem, this paper proposes a knowledge-based fast motion planning algorithm based on Risk-RRT, which guides motion planning by constructing a topological feature tree and generating a heuristic path from the tree. Firstly, an online topological feature learning method is proposed to simultaneously extract the features during the motion of the robot by means of the dual-channel scale filter and the secondary distance fusion. The learning process is completed until the feature points can represent arbitrary obstacle-free grid points of the whole map. Secondly, the topological feature tree is constructed with environmental feature points and the heuristic motion planning can be carried out on the feature tree. For one map, once the construction of the feature tree finishes, it can be reused as a prior knowledge in the following heuristic motion planning process, which will further improve the efficiency of searching feasible paths. The experimental results demonstrate that our proposed method can remarkably reduce the time taken to find a heuristic path and enhance the success rate of navigation in trapped environments.",
        "primary_area": "",
        "author": "Yuan Yuan;Jie Liu;Jiankun Wang;Wenzheng Chi;Guodong Chen;Lining Sun;Yuan Yuan;Jie Liu;Jiankun Wang;Wenzheng Chi;Guodong Chen;Lining Sun",
        "authorids": "/37088953835;/37088952814;/37086100720;/38580627700;/37085895073;/37273265800;/37088953835;/37088952814;/37086100720;/38580627700;/37085895073;/37273265800",
        "aff": "Robotics and Microsystems Center, School of Mechanical and Electric Engineering, Soochow University, Suzhou, China; Robotics and Microsystems Center, School of Mechanical and Electric Engineering, Soochow University, Suzhou, China; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China; Robotics and Microsystems Center, School of Mechanical and Electric Engineering, Soochow University, Suzhou, China; Robotics and Microsystems Center, School of Mechanical and Electric Engineering, Soochow University, Suzhou, China; Robotics and Microsystems Center, School of Mechanical and Electric Engineering, Soochow University, Suzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561684/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18085701594709817282&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Soochow University;Southern University of Science and Technology",
        "aff_unique_dep": "School of Mechanical and Electric Engineering;Department of Electronic and Electrical Engineering",
        "aff_unique_url": "http://www.soochow.edu.cn;https://www.sustech.edu.cn",
        "aff_unique_abbr": ";SUSTech",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Suzhou;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561898",
        "title": "A Large Area Robotic Skin with Sparsely Embedded Microphones for Human-Robot Tactile Communication",
        "track": "main",
        "status": "Poster",
        "abstract": "A human can socially interact in a non-verbal manner by understanding the intention behind a tactile stimulus. Patting on one\u2019s back is one of tactile communications, which is considered as a sign of encouragement in most cultures. The majority of such tactile communication is carried out by a dynamic tactile on large passive body parts and differently interpreted by how and where on the body is touched. Thus any robotic system that physically interacts with a human requires a dynamic tactile sensor for further social interaction. This paper presents a large dynamic tactile sensor that could cover a robot\u2019s passive body parts using a few sparsely distributed microphones to cover a large area in an efficient manner. A porous structured mesh, neoprene, and loop fabric are used to form a sensor\u2019s skin that could well generate and transfer a signal to distributed microphones when a touch is introduced. TDOA source localisation algorithms are implemented to find the touch point locating in between the distributed microphones, and a simple convolutional neural network is trained to classify a type of the touch. A localising performance is qualitatively achieved in a testbed of the sensor and applied to a mannequin\u2019s back to show the applicability, which classified a touch into six classes with an accuracy of 88 %.",
        "primary_area": "",
        "author": "Min Jin Yang;Kyungseo Park;Jung Kim;Min Jin Yang;Kyungseo Park;Jung Kim",
        "authorids": "/37088997191;/37067235600;/37407273800;/37088997191;/37067235600;/37407273800",
        "aff": "Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561898/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6976571167253704151&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9562109",
        "title": "A Large-Scale Dataset for Benchmarking Elevator Button Segmentation and Character Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Human activities are hugely restricted by COVID-19, recently. Robots that can conduct inter-floor navigation attract much public attention since they can substitute human workers to conduct the service work. However, current robots either depend on human assistance or elevator retrofitting, and fully autonomous inter-floor navigation is still not available. As the very first step of inter-floor navigation, elevator button segmentation and recognition hold an important position. Therefore, we release the first large-scale publicly available elevator panel dataset in this work, containing 3,718 panel images with 35,100 button labels, to facilitate more powerful algorithms on autonomous elevator operation. Together with the dataset, a number of deep learning based implementations for button segmentation and recognition are also released to benchmark future methods in the community. The dataset is available at https://github.com/zhudelong/elevator_button_recognition",
        "primary_area": "",
        "author": "Jianbang Liu;Yuqi Fang;Delong Zhu;Nachuan Ma;Jin Pan;Max Q.-H. Meng;Jianbang Liu;Yuqi Fang;Delong Zhu;Nachuan Ma;Jin Pan;Max Q.-H. Meng",
        "authorids": "/37088998181;/37086493133;/37086137408;/37087245791;/37087244420;/37274117000;/37088998181;/37086493133;/37086137408;/37087245791;/37087244420;/37274117000",
        "aff": "Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong SAR, China; Department of Electronic Engineering, Chinese University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562109/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11430947643127923122&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electronic Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Shatin;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561173",
        "title": "A Laser-based Dual-arm System for Precise Control of Collaborative Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative robots offer increased interaction capabilities at relatively low cost but in contrast to their industrial counterparts they inevitably lack precision. Moreover, in addition to the robots' own imperfect models, day-to-day operations entail various sources of errors that despite being small rapidly accumulate. This happens as tasks change and robots are re-programmed, often requiring time-consuming calibrations. These aspects strongly limit the application of collaborative robots in tasks demanding high precision (e.g. watch-making). We address this problem by relying on a dual-arm system with laser-based sensing to measure relative poses between objects of interest and compensate for pose errors coming from robot proprioception. Our approach leverages previous knowledge of object 3D models in combination with point cloud registration to efficiently extract relevant poses and compute corrective trajectories. This results in high-precision assembly behaviors. The approach is validated in a needle threading experiment, with a 150\u03bcm thread and a 300\u03bcm hole, and a USB insertion task using two 7-axis Panda robots.",
        "primary_area": "",
        "author": "Jo\u00e3o Silv\u00e9rio;Guillaume Clivaz;Sylvain Calinon;Jo\u00e3o Silv\u00e9rio;Guillaume Clivaz;Sylvain Calinon",
        "authorids": "/37085736048;/37088900720;/37295947200;/37085736048;/37088900720;/37295947200",
        "aff": "Idiap Research Institute, Martigny, Switzerland; Idiap Research Institute, Martigny, Switzerland; Idiap Research Institute, Martigny, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561173/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3462756356955422496&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Idiap Research Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.idiap.ch",
        "aff_unique_abbr": "Idiap",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Martigny",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561018",
        "title": "A Legged Soft Robot Platform for Dynamic Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an open-source untethered quadrupedal soft robot platform for dynamic locomotion (e.g., high-speed running and backflipping). The robot is mostly soft (80 vol.%) while driven by four geared servo motors. The robot\u2019s soft body and soft legs were 3D printed with gyroid infill using a flexible material, enabling it to conform to the environment and passively stabilize during locomotion in multi-terrain environments. In addition, we simulated the robot in a real-time soft body simulation. With tuned gaits in simulation, the real robot can locomote at a speed of 0.9 m/s (2.5 body length/second), substantially faster than most untethered legged soft robots published to date. We hope this platform, along with its verified simulator, can catalyze agile soft robots' development.",
        "primary_area": "",
        "author": "Boxi Xia;Jiaming Fu;Hongbo Zhu;Zhicheng Song;Yibo Jiang;Hod Lipson;Boxi Xia;Jiaming Fu;Hongbo Zhu;Zhicheng Song;Yibo Jiang;Hod Lipson",
        "authorids": "/37087053954;/37088998835;/37089001603;/37088997483;/37089000477;/37278575000;/37087053954;/37088998835;/37089001603;/37088997483;/37089000477;/37278575000",
        "aff": "Department of Mechanical Engineering, Columbia University, New York, NY; Department of Mechanical Engineering, Columbia University, New York, NY; Department of Mechanical Engineering, Columbia University, New York, NY; Department of Mechanical Engineering, Columbia University, New York, NY; Department of Mechanical Engineering, Columbia University, New York, NY; Department of Mechanical Engineering, Columbia University, New York, NY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561018/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12762695776516808392&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561663",
        "title": "A Light-Weight Semantic Map for Visual Localization towards Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate localization is of crucial importance for autonomous driving tasks. Nowadays, we have seen a lot of sensor-rich vehicles (e.g. Robo-taxi) driving on the street autonomously, which rely on high-accurate sensors (e.g. Lidar and RTK GPS) and high-resolution map. However, low-cost production cars cannot afford such high expenses on sensors and maps. How to reduce costs? How do sensor-rich vehicles benefit low-cost cars? In this paper, we proposed a light-weight localization solution, which relies on low-cost cameras and compact visual semantic maps. The map is easily produced and updated by sensor-rich vehicles in a crowd-sourced way. Specifically, the map consists of several semantic elements, such as lane line, crosswalk, ground sign, and stop line on the road surface. We introduce the whole framework of on-vehicle mapping, on-cloud maintenance, and user-end localization. The map data is collected and preprocessed on vehicles. Then, the crowd-sourced data is uploaded to a cloud server. The mass data from multiple vehicles are merged on the cloud so that the semantic map is updated in time. Finally, the semantic map is compressed and distributed to production cars, which use this map for localization. We validate the performance of the proposed map in real-world experiments and compare it against other algorithms. The average size of the semantic map is 36 kb/km. We highlight that this framework is a reliable and practical localization solution for autonomous driving.",
        "primary_area": "",
        "author": "Tong Qin;Yuxin Zheng;Tongqing Chen;Yilun Chen;Qing Su;Tong Qin;Yuxin Zheng;Tongqing Chen;Yilun Chen;Qing Su",
        "authorids": "/37086218149;/37088996195;/37088688037;/37088689305;/37088688782;/37086218149;/37088996195;/37088688037;/37088689305;/37088688782",
        "aff": "IAS BU Smart Driving Product Dept, Huawei Technologies, Shanghai, China; IAS BU Smart Driving Product Dept, Huawei Technologies, Shanghai, China; IAS BU Smart Driving Product Dept, Huawei Technologies, Shanghai, China; IAS BU Smart Driving Product Dept, Huawei Technologies, Shanghai, China; IAS BU Smart Driving Product Dept, Huawei Technologies, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561663/",
        "gs_citation": 128,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6642321507495219825&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Smart Driving Product Dept",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561970",
        "title": "A Locally-Adaptive, Parallel-Jaw Gripper with Clamping and Rolling Capable, Soft Fingertips for Fine Manipulation of Flexible Flat Cables",
        "track": "main",
        "status": "Poster",
        "abstract": "Flexible flat cables (FFC) are very popular for connecting different components in modern electronics (e.g., mobile phones, laptops, tablets, etc.). The manipulation of FFCs typically relies on highly trained workers that spend hours performing the same repetitive processes, or on autonomous robotic systems that are equipped with simple clamping mechanisms or pneumatically driven suction cups. Such robotic systems are difficult to program and reprogram and often rely on sophisticated sensing elements and complicated control laws. Moreover, the performance and robustness of such systems is far from sufficient, hindering their mass adoption. The manipulation of FFCs is also quite challenging. A good gripper should be able to pinch the cable steadily and execute insertion tasks of the cable connector with ease. The suction cup based solution is a good approach for holding the cable, but it makes the cable connector insertion very challenging as it can only apply limited shear forces. In this paper, we propose a locally-adaptive, pneumatic, parallel-jaw robot gripper equipped with fingertips that are able to both pinch the cable with a soft clamping mechanism and roll the cable surface on the soft fingertip structure until it reaches the desired connector. The gripper base accommodates a camera that allows for the recognition and pose estimation of the flat, flexible cables and other electronic components. The gripper is of low-cost and low-complexity and it can facilitate the efficient and robust execution of FFC grasping and assembly tasks.",
        "primary_area": "",
        "author": "Jayden Chapman;Gal Gorjup;Anany Dwivedi;Saori Matsunaga;Toshisada Mariyama;Bruce MacDonald;Minas Liarokapis;Jayden Chapman;Gal Gorjup;Anany Dwivedi;Saori Matsunaga;Toshisada Mariyama;Bruce MacDonald;Minas Liarokapis",
        "authorids": "/37088482031;/37087237844;/37086133073;/37088580339;/37087323162;/37300950400;/38558084100;/37088482031;/37087237844;/37086133073;/37088580339;/37087323162;/37300950400;/38558084100",
        "aff": "Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand; Information Technology R&D Center, Mitsubishi Electric Corporation, Japan; Information Technology R&D Center, Mitsubishi Electric Corporation, Japan; Department of Electrical, Computer and Software Engineering, Centre for Automation and Robotic Engineering Science, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561970/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12863808866569398136&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;0;0",
        "aff_unique_norm": "University of Auckland;Mitsubishi Electric Corporation",
        "aff_unique_dep": "Department of Mechanical Engineering;Information Technology R&D Center",
        "aff_unique_url": "https://www.auckland.ac.nz;https://www.mitsubishielectric.com",
        "aff_unique_abbr": "UoA;MEC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;1;0;0",
        "aff_country_unique": "New Zealand;Japan"
    },
    {
        "id": "9561489",
        "title": "A Low-cost Intrinsically Safe Mechanism for Physical Distancing Between Clinicians and Patients",
        "track": "main",
        "status": "Poster",
        "abstract": "During the COVID-19 pandemic, due to the unprecedented workload and cross-infection hazard, the health-care workers\u2019 lives are under a significant threat. However, minimizing the duration and frequency of close clinician-to-patient contacts using simple technologies that enable physical distancing could reduce the risk of spreading the disease. In this context, this paper presents the conceptual design and preliminary assessment of a low-cost and intrinsically safe remote service delivery platform that can assist clinicians in doing various tasks at a safe distance from patients. This mechanism is capable of manipulating objects in three-dimensional Cartesian space and can be adapted to handling a wide variety of medical devices. Moreover, its passive weight-compensating design provides the mechanism with high maneuverability, enhanced dynamic manipulability, and better force feedback quality. The advantages and effectiveness of the proposed mechanism are demonstrated through experiments. In the experiment, an ultrasound probe is mounted at the end effector of the device to perform an imaging task from a safe distance. Due to the existence of the force feedback, the user could remotely manipulate the ultrasound probe for having a successful vertical and pivot scanning to get high-quality images with a low physical and mental demand.",
        "primary_area": "",
        "author": "Abed Soleymani;Ali Torabi;Mahdi Tavakoli;Abed Soleymani;Ali Torabi;Mahdi Tavakoli",
        "authorids": "/37089002006;/37086366170;/37282400400;/37089002006;/37086366170;/37282400400",
        "aff": "Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561489/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5201920932550983463&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Alberta",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ualberta.ca",
        "aff_unique_abbr": "UAlberta",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Edmonton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9560973",
        "title": "A Model-Free Synchronous Control of Humanoid Robot Finger",
        "track": "main",
        "status": "Poster",
        "abstract": "For a multi-fingered robot hand, the individual control over single joints cannot guarantee their fine collaboration. For achieving a high-precision synchronization, a theory of synchronous control is introduced to multi-fingered robot hands. This paper introduced a new model-free and cross-coupling control strategy. It had been tested on the humanoid robot fingers and showed high positioning performance. For realizing the mutual influence between the control of all joints, we establish the synchronization error by the differential disposal of adjacent actuator errors, then position errors and synchronization errors are incorporated into a unified control frame. Meanwhile, considering the complex dynamic formulations of the dexterous hand and the characteristics of the control system, a model-free, cross-coupled trajectory tracking method is introduced and the explicit dynamic modeling parameters is not necessary. Finally, we tested our method on a multi-fingered hand platform HIT/DLR-II. The results prove that the new method has superior performance over traditional non-synchronous approaches.",
        "primary_area": "",
        "author": "Ziqi Liu;Li Jiang;Bin Yang;Chongyang Li;Ming Cheng;Shaowei Fan;Dapeng Yang;Ziqi Liu;Li Jiang;Bin Yang;Chongyang Li;Ming Cheng;Shaowei Fan;Dapeng Yang",
        "authorids": "/37086050522;/37287953000;/37086354117;/37086345622;/37085871202;/37403817800;/37601257200;/37086050522;/37287953000;/37086354117;/37086345622;/37085871202;/37403817800;/37601257200",
        "aff": "State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560973/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16486097289917113774&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "State Key Laboratory of Robotics and System",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560980",
        "title": "A Multi-Level Network for Human Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Although multi-person human pose estimation has made great progress in recent years, the challenges such as various scales of persons, occluded keypoints, and crowded backgrounds in complex scenes are still remained to be solved. In this paper, we propose a novel multi-level pose estimation network (MLPE) to learn multi-level features that can preserve both the strong semantic clues and spatial resolution for keypoint prediction and location. More specifically, a multi-level prediction network with a feature enhancement strategy is first proposed to learn multi-level features to achieve a good trade-off between the global context information and spatial resolution. We then build a high-resolution fine network to restore high spatial resolution information based on transposed convolutions to accurately locate the keypoints. We have conducted extensive experiments on the challenging MS COCO dataset, which has proved the effectiveness of our proposed method. Code \u2020 and the experimental results are publicly online available for further research.",
        "primary_area": "",
        "author": "Zhanpeng Shao;Peng Liu;Youfu Li;Jianyu Yang;Xiaolong Zhou;Zhanpeng Shao;Peng Liu;Youfu Li;Jianyu Yang;Xiaolong Zhou",
        "authorids": "/37077906300;/37088997350;/37279884400;/38008552200;/37406424000;/37077906300;/37088997350;/37279884400;/38008552200;/37406424000",
        "aff": "College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; Department of Mechanical Engineering, City University of Hong Kong, Hong Kong; School of Rail Transportation, Soochow University, Suzhou, China; College of Electrical and Information Engineering, Quzhou University, Quzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560980/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11272708170894645836&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;3",
        "aff_unique_norm": "Zhejiang University of Technology;City University of Hong Kong;Soochow University;Quzhou University",
        "aff_unique_dep": "College of Computer Science and Technology;Department of Mechanical Engineering;School of Rail Transportation;College of Electrical and Information Engineering",
        "aff_unique_url": "https://www.zjut.edu.cn;https://www.cityu.edu.hk;http://www.soochow.edu.cn;",
        "aff_unique_abbr": "ZJUT;CityU;;",
        "aff_campus_unique_index": "0;0;1;2;3",
        "aff_campus_unique": "Hangzhou;Hong Kong SAR;Suzhou;Quzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562057",
        "title": "A Multi-UAV System for Detection and Elimination of Multiple Targets",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem of safe interception of multiple intruder UAVs by a team of cooperating autonomous aerial vehicles is addressed in this paper. The presented work is motivated by the Mohamed Bin Zayed International Robotics Challenge (MBZIRC) 2020 where this task was simplified to an interaction with a set of static and dynamic objects (balloons and a UAV), and by a real autonomous aerial interception system of Eagle.One that our team has been working on. We propose a general control, perception, and coordination system for the fast and reliable interception of targets in a 3D environment relying only on onboard sensors and processing. The proposed methods and the entire complex multi-robot system were successfully verified in demanding desert conditions, with the main focus on reliability and fast deployment. In the MBZIRC competition, the proposed approach exhibited the greatest reliability and fastest solution. It was crucial to our team in winning the entire competition and achieving the second place in the intruder UAV interception scenario.",
        "primary_area": "",
        "author": "Yurii Stasinchuk;Matou\u0161 Vrba;Mat\u011bj Petrl\u00edk;Tom\u00e1\u0161 B\u00e1\u010da;Vojt\u011bch Spurn\u00fd;Daniel Hert;David \u017daitl\u00edk;Tiago Nascimento;Martin Saska;Yurii Stasinchuk;Matou\u0161 Vrba;Mat\u011bj Petrl\u00edk;Tom\u00e1\u0161 B\u00e1\u010da;Vojt\u011bch Spurn\u00fd;Daniel Hert;David \u017daitl\u00edk;Tiago Nascimento;Martin Saska",
        "authorids": "/37088997121;/37086915990;/37086431997;/37945177400;/37085831556;/37086107524;/37088655830;/37680521100;/37298817800;/37088997121;/37086915990;/37086431997;/37945177400;/37085831556;/37086107524;/37088655830;/37680521100;/37298817800",
        "aff": "Department of Cybernetics, Czech Technical University in Prague, Prague, Czech Republic; Department of Cybernetics, Czech Technical University in Prague, Prague, Czech Republic; Department of Cybernetics, Czech Technical University in Prague, Prague, Czech Republic; Department of Cybernetics, Czech Technical University in Prague, Prague, Czech Republic; Department of Cybernetics, Czech Technical University in Prague, Prague, Czech Republic; Department of Cybernetics, Czech Technical University in Prague, Prague, Czech Republic; Department of Cybernetics, Czech Technical University in Prague, Prague, Czech Republic; Department of Cybernetics, Czech Technical University in Prague, Prague, Czech Republic; Department of Cybernetics, Czech Technical University in Prague, Prague, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562057/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5511182283457007830&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Department of Cybernetics",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "9561906",
        "title": "A Multi-spectral Dataset for Evaluating Motion Estimation Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Visible images have been widely used for motion estimation. Thermal images, in contrast, are more challenging to be used in motion estimation since they typically have lower resolution, less texture, and more noise. In this paper, a novel dataset for evaluating the performance of multi-spectral motion estimation systems is presented. All the sequences are recorded from a handheld multi-spectral device. It consists of a standard visible-light camera, a long-wave infrared camera, an RGB-D camera, and an inertial measurement unit (IMU). The multi-spectral images, including both color and thermal images in full sensor resolution (640 \u00d7 480), are obtained from a standard and a long-wave infrared camera at 32Hz with hardware-synchronization. The depth images are captured by a Microsoft Kinect2 and can have benefits for learning cross-modalities stereo matching. For trajectory evaluation, accurate ground-truth camera poses obtained from a motion capture system are provided. In addition to the sequences with bright illumination, the dataset also contains dim, varying, and complex illumination scenes. The full dataset, including raw data and calibration data with detailed data format specifications, is publicly available.",
        "primary_area": "",
        "author": "Weichen Dai;Yu Zhang;Shenzhou Chen;Donglei Sun;Da Kong;Weichen Dai;Yu Zhang;Shenzhou Chen;Donglei Sun;Da Kong",
        "authorids": "/37086568517;/37086570568;/37088999121;/37087078347;/37088921695;/37086568517;/37086570568;/37088999121;/37087078347;/37088921695",
        "aff": "State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University; Alibaba A.I. Labs; Centre for English Language Education, University of Nottingham Ningbo China; State Key Laboratory of Industrial Control Technology, College of Control Science and Engineering, Zhejiang University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561906/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14030187366609510224&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Zhejiang University;Alibaba Group;University of Nottingham Ningbo China",
        "aff_unique_dep": "College of Control Science and Engineering;Alibaba A.I. Labs;Centre for English Language Education",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.alibaba.com;https://www.nottingham.edu.cn",
        "aff_unique_abbr": "ZJU;Alibaba A.I. Labs;UNNC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Ningbo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561929",
        "title": "A New Framework for Registration of Semantic Point Clouds from Stereo and RGB-D Cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper reports on a novel nonparametric rigid point cloud registration framework, Semantic Continuous Visual Odometry (CVO), that jointly integrates geometric and semantic measurements such as color or semantic labels into the alignment process and does not require explicit data association. The point clouds are represented as nonparametric functions in a reproducible kernel Hilbert space. The alignment problem is formulated as maximizing the inner product between two functions, essentially a sum of weighted kernels, each of which exploits the local geometric and semantic features. As a result of the continuous models, analytical gradients can be computed, and a local solution can be obtained by optimization over the rigid body transformation group. Besides, we present a new point cloud alignment metric that is intrinsic to the proposed framework and takes into account geometric and semantic information. The evaluations using publicly available stereo and RGB-D datasets show that the proposed method outperforms state-of-the-art outdoor and indoor frame-to-frame registration methods. An open-source GPU implementation is also provided.",
        "primary_area": "",
        "author": "Ray Zhang;Tzu-Yuan Lin;Chien Erh Lin;Steven A. Parkison;William Clark;Jessy W. Grizzle;Ryan M. Eustice;Maani Ghaffari;Ray Zhang;Tzu-Yuan Lin;Chien Erh Lin;Steven A. Parkison;William Clark;Jessy W. Grizzle;Ryan M. Eustice;Maani Ghaffari",
        "authorids": "/37087057058;/37089000346;/37089002238;/37089406983;/37086299313;/37277141500;/37283587600;/37087056400;/37087057058;/37089000346;/37089002238;/37089406983;/37086299313;/37277141500;/37283587600;/37087056400",
        "aff": "University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; TRI; Department of Mathematics, Cornell University, Ithaca, NY; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561929/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15195821582986197065&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;2;0;0;0",
        "aff_unique_norm": "University of Michigan;TRI;Cornell University",
        "aff_unique_dep": ";;Department of Mathematics",
        "aff_unique_url": "https://www.umich.edu;;https://www.cornell.edu",
        "aff_unique_abbr": "UM;;Cornell",
        "aff_campus_unique_index": "0;0;0;2;0;0;0",
        "aff_campus_unique": "Ann Arbor;;Ithaca",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "9561413",
        "title": "A Normal Distribution Transform-Based Radar Odometry Designed For Scanning and Automotive Radars",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing radar sensors can be classified into automotive and scanning radars. While most radar odometry (RO) methods are only designed for a specific type of radar, our RO method adapts to both scanning and automotive radars. Our RO is simple yet effective, where the pipeline consists of thresholding, probabilistic submap building, and an Normal Distribution Transform-based (NDT-based) radar scan matching. The proposed RO has been tested on two public radar datasets: the Oxford Radar RobotCar dataset and the nuScenes dataset, which provide scanning and automotive radar data respectively. The results show that our approach surpasses state-of-the-art RO using either automotive or scanning radar by reducing translational error by 51% and 30%, respectively, and rotational error by 17% and 29%, respectively. Besides, we show that our RO achieves centimeter-level accuracy as lidar odometry, and automotive and scanning RO have similar accuracy.",
        "primary_area": "",
        "author": "Pou-Chun Kung;Chieh-Chih Wang;Wen-Chieh Lin;Pou-Chun Kung;Chieh-Chih Wang;Wen-Chieh Lin",
        "authorids": "/37088998469;/37088493330;/37291223500;/37088998469;/37088493330;/37291223500",
        "aff": "Graduate Degree Program of Robotics, National Chiao Tung University, Hsinchu, Taiwan; Department of Electrical and Computer Engineering, Mechanical and Mechatronics Systems Research Laboratories, Industrial Technology Research Institute, National Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science, National Chiao Tung University, Hsinchu, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561413/",
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9843597848072730040&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National Chiao Tung University",
        "aff_unique_dep": "Graduate Degree Program of Robotics",
        "aff_unique_url": "https://www.nctu.edu.tw",
        "aff_unique_abbr": "NCTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561497",
        "title": "A Novel Gait Phase Detection Algorithm for Foot Drop Correction through Optimal Hybrid FES-Orthosis Assistance",
        "track": "main",
        "status": "Poster",
        "abstract": "As a life-threatening disease, stroke can lead to long-term problems affecting the patients\u2019 daily living ability. A common problem facing post-stroke patients is foot drop. An emerging modality of interest for correcting the foot drop is to combine both actuated ankle-foot orthosis (AAFO) and functional electrical stimulation (FES). Such hybrid assistive system not only ensure effective assistance but also can avoid fast muscular fatigue due to excessive muscular stimulation. Due to the significant changes in the ankle joint\u2019s kinematics and kinetics with gait cycles, optimization control strategies for hybrid AAFO and FES systems are highly demanded. However, it is challenging to develop accurate gait phase detection algorithms to guide the control of AAFO and FES while ensuring robustness with respect to the diversity and variability of patients\u2019 gaits. In this paper, we present a novel swing sub-phase detection algorithm based on a moving average convergence divergence (MACD) indicator. The proposed detection algorithm uses only information collected from the affected leg by means of two inertia measurement units (IMU) and the AAFO. Moreover, a gait-phase based control strategy is developed to optimize the assistive effect of a hybrid AAFO and FES system. Experimental results with five healthy show the potential of the proposed approaches in ensuring both satisfactory ankle joint trajectory tracking and effective reduction in stimulation intensity, compared to the use of conventional FES assistance.",
        "primary_area": "",
        "author": "Pyeong-Gook Jung;Weiguang Huo;Huiseok Moon;Yacine Amirat;Samer Mohammed;Pyeong-Gook Jung;Weiguang Huo;Huiseok Moon;Yacine Amirat;Samer Mohammed",
        "authorids": "/38542803600;/37589154200;/37088997237;/37274109900;/38580067500;/38542803600;/37589154200;/37088997237;/37274109900;/38580067500",
        "aff": "LISSI, Univ Paris Est Creteil, Vitry, France; Department of Mechanical Engineering, Imperial College London, UK; LISSI, Univ Paris Est Creteil, Vitry, France; LISSI, Univ Paris Est Creteil, Vitry, France; LISSI, Univ Paris Est Creteil, Vitry, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561497/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14937249497318532137&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University Paris Est Cr\u00e9teil;Imperial College London",
        "aff_unique_dep": "LISSI;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.univ-Paris12.fr;https://www.imperial.ac.uk",
        "aff_unique_abbr": "UPEC;Imperial",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Vitry;London",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "France;United Kingdom"
    },
    {
        "id": "9562097",
        "title": "A Novel Hybrid Approach for Fault-Tolerant Control of UAVs based on Robust Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The control of complex autonomous systems has significantly improved in recent years and unmanned aerial vehicles (UAVs) have become popular in the research community. Although the use of UAVs is increasing, much work remains to guarantee fault- tolerant control (FTC) properties of these vehicles. Model-based controllers are the standard way to control UAVs, however obtaining models of the system and environment for every possible operating condition a UAV can experience in a real-world scenario is not feasible. Reinforcement Learning has shown promise in controlling complex systems but requires training in a simulator (requiring a model) of the system. Further, stability guarantees do not exist for learning-based controllers, which limits their large scale application in the real-world. We propose a novel hybrid FTC approach that uses a learned supervisory controller (together with low-level PID controllers) with key stability guarantees. We use a robust reinforcement learning approach to learn the supervisory control parameters and prove stability. We empirically validate our framework using trajectory-following experiments (in simulation) for a quadcopter subject to rotor faults, wind disturbances, and severe position and attitude noise.",
        "primary_area": "",
        "author": "Yves Soh\u00e8ge;Marcos Qui\u00f1ones-Grueiro;Gregory Provan;Yves Soh\u00e8ge;Marcos Qui\u00f1ones-Grueiro;Gregory Provan",
        "authorids": "/37086524631;/37085884677;/37329267000;/37086524631;/37085884677;/37329267000",
        "aff": "Insight Centre for Data Analytics, University College Cork, Cork, Ireland; ISIS, Vanderbilt University, Nashville, Tennessee, USA; Insight Centre for Data Analytics, University College Cork, Cork, Ireland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562097/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=552298688788959077&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University College Cork;Vanderbilt University",
        "aff_unique_dep": "Insight Centre for Data Analytics;",
        "aff_unique_url": "https://www.ucc.ie;https://www.vanderbilt.edu",
        "aff_unique_abbr": "UCC;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Cork;Nashville",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Ireland;United States"
    },
    {
        "id": "9561499",
        "title": "A Novel Model Predictive Control Framework Using Dynamic Model Decomposition Applied to Dynamic Legged Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic locomotion for legged robots is difficult because the system dynamics are highly nonlinear and complex, nominally underactuated and unstable, multi-input and multi-output, as well as time-variant and hybrid. One usually faces the choice between the intricate full-body dynamics which remains computationally expensive and sometimes even intractable, and the empirically simplified model which inevitably limits the locomotion capability. In this paper, we explore the legged robot dynamics from a different perspective. By decomposing the robot into the body and the legs, with interaction forces and moments connecting them, we enjoy a novel method called Dynamic Model Decomposition that involves lower-dimensional dynamics for each subsystem while their composition maintaining the equivalence to the original full-order robot model. Based on that, we further propose a corresponding model predictive control framework via quadratic programming, which con-siders linearly approximated body dynamics with constrained leg reaction forces as inputs. The overall methodology was successfully applied to a planar five-link biped robot. The simulation results show that the robot is capable of body reference tracking, push recovery, velocity tracking, and even blind locomotion on fairly rough terrain. This suggests a promising dynamic motion control scheme in the future.",
        "primary_area": "",
        "author": "Junjie Shen;Dennis Hong;Junjie Shen;Dennis Hong",
        "authorids": "/37087324771;/37575333900;/37087324771;/37575333900",
        "aff": "Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561499/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4748234347550251508&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561924",
        "title": "A Novel Robotic System for Ultrasound-guided Peripheral Vascular Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an autonomous RGB-D and 2D ultrasound-guided robotic system for collecting 3D localized volumes of peripheral vessels. This compact design, with available commercial components, lends itself to platform utility throughout the human body. The fully integrated system works with force limits for future safety in human use. We propose a PID force controller for smooth and safe robot scanning following a priori 3D trajectory generated from a surface point cloud. System calibration is implemented to determine transformations among sensors, end-effector and robot base. A vascular localization pipeline that consists of detection and tracking is proposed to find the 3D vessel positions in real-time. Precision tests are performed with both predesignated and autonomously selected areas in an arm phantom. The average variance of the autonomously collected ultrasound images (to construct 3D volumes) between repeated tests is shown to be around 0.3 mm, similar to the theoretical spatial resolution a clinical ultrasound system. This fully integrated system demonstrates the capability of autonomous collection of peripheral vessels with built-in safety measures for future human testing.",
        "primary_area": "",
        "author": "Guangshen Ma;Siobhan R. Oca;Yifan Zhu;Patrick J. Codd;Daniel M. Buckland;Guangshen Ma;Siobhan R. Oca;Yifan Zhu;Patrick J. Codd;Daniel M. Buckland",
        "authorids": "/37086933341;/37088996908;/37089394764;/37688751700;/37086865493;/37086933341;/37088996908;/37089394764;/37688751700;/37086865493",
        "aff": "Department of Mechanical Engineering and Materials Science, Duke University; Department of Mechanical Engineering and Materials Science, Duke University; Department of Computer Science, University of Illinois at Urbana-Champaign; Department of Neurosurgery, Duke University; Department of Surgery, Division of Emergency Medicine, Duke University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561924/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15416655912697487250&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Duke University;University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Mechanical Engineering and Materials Science;Department of Computer Science",
        "aff_unique_url": "https://www.duke.edu;https://illinois.edu",
        "aff_unique_abbr": "Duke;UIUC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561724",
        "title": "A Novel Tactile Feedback System with On-Line Texture Decoding and Direct-Texture-Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile perception on our fingers is a key sensory feedback that enables us to perceive and explore our world using our hands as probes, and is essential for efficient gripping and manipulation of objects. A tactile feedback system can therefore greatly improve the quality of life of individuals with partial or complete sensory loss like during stroke, or with artificial limbs after an amputation. However, most existing tactile texture feedback technologies suffer from two constraints. First, texture decoding and texture feedback have been traditionally examined separately and not as parts of the same problem, and second, texture information has been popularly fed back using sensory modality other than tactile itself. In this study, we propose a prototype on-line direct-texture decoding and feedback system in which the texture touched by a user is decoded using an accelerometer attached to the finger. The feedback is realized by rubbing the user\u2019s skin with the actual material and the speed of the user swipes. The efficacy of the proposed system was tested in two user experiments with five test materials. The results and the corresponding hints for future improvements are discussed.",
        "primary_area": "",
        "author": "Kuniharu Sakurada;Gowrishankar Ganesh;Wenwei Yu;Kuniharu Sakurada;Gowrishankar Ganesh;Wenwei Yu",
        "authorids": "/37086799529;/37274061900;/37598846600;/37086799529;/37274061900;/37598846600",
        "aff": "Graduate School of Science for Open and Environmental Systems, Center for Information and Computer Science, University of Keio, Kanagawa, Japan; UM-CNRS Laboratoire d\u2019Informatique, de Robotique et de Microelectronique de Montpellier (LIRMM), Montpellier Cedex 5, France; Frontier Medical Engineering, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561724/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8032779585150937938&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Keio;University of Montpellier;Frontier Medical Engineering",
        "aff_unique_dep": "Graduate School of Science for Open and Environmental Systems, Center for Information and Computer Science;Laboratoire d\u2019Informatique, de Robotique et de Microelectronique de Montpellier;",
        "aff_unique_url": "https://www.keio.ac.jp;https://www.lirmm.fr;",
        "aff_unique_abbr": "Keio;LIRMM;",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Kanagawa;Montpellier;Chiba",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Japan;France"
    },
    {
        "id": "9561957",
        "title": "A Novel Torsional Actuator Augmenting Twisting Skeleton and Artificial Muscle for Robots in Extreme Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Torsional actuators are a class of artificial muscle technology that generates torque and produces rotary motion in response to various stimuli. This paper presents a novel torsional actuator combining an origami-inspired twisting skeleton and an artificial muscle. The process of torsional actuator design starts from identifying a foldable twisting skeleton which is capable of achieving helical motion thereby translating linear motion to rotational motion. This is followed by the integration of an artificial muscle to drive the twisting skeleton. Kinematics of both the twisting skeleton and artificial muscle are analyzed. Following the design and kinematic analysis, a prototype is developed by bonding 3D printed polylactic acid (PLA) parts and thermoplastic polyurethane (TPU) films to form the twisting skeleton and laminating TPU membranes by using heat sealing tools to form the artificial muscle. A pneumatic control system is built to evaluate the performances of torsional actuator by testing the relationship between twisting angle, air pressure, driving force and output torque. Experimental results show that the relationship between air pressure, driving force and output torque is proportional at a given twisting angle. The novel torsional actuator augmenting an origami-inspired skeleton and soft artificial muscle leads to simplified analytical model and has potential of driving robotic systems in environment where pneumatically actuated systems are preferred over electrical machines and drives.",
        "primary_area": "",
        "author": "Zhujin Jiang;Ketao Zhang;Zhujin Jiang;Ketao Zhang",
        "authorids": "/37088996825;/38005192300;/37088996825;/38005192300",
        "aff": "Centre for Advanced Robotics (ARQ), Queen Mary University of London; Centre for Advanced Robotics (ARQ), Queen Mary University of London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561957/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9458405439039971373&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Queen Mary University of London",
        "aff_unique_dep": "Centre for Advanced Robotics (ARQ)",
        "aff_unique_url": "https://www.qmul.ac.uk",
        "aff_unique_abbr": "QMUL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561978",
        "title": "A Novel Variable Resolution Torque Sensor Based on Variable Stiffness Principle",
        "track": "main",
        "status": "Poster",
        "abstract": "High resolution and large range force/torque (F/T) measurements are usually required in many engineering tasks. However, most existing F/T sensors only have a fixed resolution over their whole ranges. The key lies in that it is difficult to well balance high resolution and large range in the sensor design. Taking the torque sensor for example, this paper presents a better compromise for this problem i.e., a novel variable resolution torque sensor based on variable stiffness principle. From the structural points of view, the sensor is constructed with multiple radial flexures to achieve a pure rotational motion with negligible parasitic center motions. Two resistive strain gauges (RSGs) are selected as the measuring units of the sensor to detect the applied external torque and meanwhile provide variable resolutions in the two different measuring ranges (each RSG for one range). Static and dynamic models of the sensor are established in details and validated through finite element analysis (FEA) to evaluate its characteristics. A principle prototype is finally fabricated and tested to verify the effectiveness of the presented design. RSGs are calibrated through a commercial six-axis F/T sensor from ATI Industrial Automation, Inc. Experimental results show that the torque sensor can provide high and low resolutions in the small and large ranges respectively and possesses the first natural frequency of 67.3 Hz. In addition, the proposed variable resolution method can also be applied to the development of multi-axis F/T sensors.",
        "primary_area": "",
        "author": "Xiantao Sun;Wenjie Chen;Jianbin Zhang;Jianhua Wang;Jun Jiang;Weihai Chen;Xiantao Sun;Wenjie Chen;Jianbin Zhang;Jianhua Wang;Jun Jiang;Weihai Chen",
        "authorids": "/37959843100;/37421822700;/37293685500;/37539004800;/37962919900;/37279188000;/37959843100;/37421822700;/37293685500;/37539004800;/37962919900;/37279188000",
        "aff": "Anhui Engineering Laboratory of Human-Machine Cooperative System and Intelligent Equipment, School of Electrical Engineering and Automation, Anhui University, Hefei, China; Anhui Engineering Laboratory of Human-Machine Cooperative System and Intelligent Equipment, School of Electrical Engineering and Automation, Anhui University, Hefei, China; School of Mechanical Engineering and Automation, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; Beijing Institute of Control Engineering, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561978/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:JTOG2_QLqlYJ:scholar.google.com/&scioq=A+Novel+Variable+Resolution+Torque+Sensor+Based+on+Variable+Stiffness+Principle&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;2;1",
        "aff_unique_norm": "Anhui University;Beihang University;Beijing Institute of Control Engineering",
        "aff_unique_dep": "School of Electrical Engineering and Automation;School of Mechanical Engineering and Automation;",
        "aff_unique_url": "http://www.ahu.edu.cn/;http://www.buaa.edu.cn;",
        "aff_unique_abbr": "AHU;Beihang;",
        "aff_campus_unique_index": "0;0;1;1;1;1",
        "aff_campus_unique": "Hefei;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561905",
        "title": "A Parallelized Iterative Algorithm for Real-Time Simulation of Long Flexible Cable Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel real-time physically-accurate simulator for long flexible cable manipulation. We first discretize the cable into multiple rigid link segments, each with complementarity-based contact model and inter-segment compliant coupling; and partition the cable into a number of subsystems, each composed with a number of consecutive links. We then formulate the inter-subsystem consistency constraint as a certain analytical condition among the inter-subsystem coupling and the contact impulses; and solve each subsystem dynamics in parallel with the contact model together with this consistency condition in an iterative manner, achieving both the speed and the accuracy of the simulation. A novel post-regulation scheme is also proposed to further speed up the simulation. Experimental validation/demonstration are also performed to show the theory.",
        "primary_area": "",
        "author": "Jeongmin Lee;Minji Lee;Jaemin Yoon;Dongjun Lee;Jeongmin Lee;Minji Lee;Jaemin Yoon;Dongjun Lee",
        "authorids": "/37088998350;/37086549787;/37085562778;/37077171500;/37088998350;/37086549787;/37085562778;/37077171500",
        "aff": "Department of Mechanical & Aerospace Engineering and IAMD, Seoul National University, Seoul, Republic of Korea; Department of Mechanical & Aerospace Engineering and IAMD, Seoul National University, Seoul, Republic of Korea; Department of Mechanical & Aerospace Engineering and IAMD, Seoul National University, Seoul, Republic of Korea; Department of Mechanical & Aerospace Engineering and IAMD, Seoul National University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561905/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4497156137075613476&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical & Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561581",
        "title": "A Passive Hydraulic Auxiliary System Designed for Increasing Legged Robot Payload and Efficiency",
        "track": "main",
        "status": "Poster",
        "abstract": "Load-carrying capability is an essential criterion in legged robots' practical application. This paper proposes an unpowered hydraulic auxiliary system to improve the legged robot's loading capability and energy efficiency. For humans, it has been widely hypothesized that intra-abdominal pressure can reduce potential injurious compressive force imposed on spinal discs when a person lifts heavy objects. Inspired by this human biomechanical phenomenon, we design a novel loading-carrying strategy using hydraulic cylinders, valves and accumulators. Different from ordinary powered hydraulic systems, this design provides continuous support force to share the load applied on knee joint actuator without consuming extra energy. The bent-leg theoretical model is constructed to validate the design and analysis. A bipedal hydraulic-assisted electric leg prototype (HyELeg) is fabricated and tested for squatting and walking gaits. The results show that with hydraulic assistance, the prototype can save energy by 45.9% for squatting with a load of 125% of its own body weight, and the walking performance is enhanced by 16.9% in energy efficiency with carrying a load of 67.5% of its own body weight.",
        "primary_area": "",
        "author": "Wu Fan;Tao Liu;Jingang Yi;Xinyan Huang;Bin Zhang;Xiufeng Zhang;Shuoyu Wang;Wu Fan;Tao Liu;Jingang Yi;Xinyan Huang;Bin Zhang;Xiufeng Zhang;Shuoyu Wang",
        "authorids": "/37088457421;/37293265800;/37277001600;/37089000882;/37085880290;/37086857698;/37406370400;/37088457421;/37293265800;/37277001600;/37089000882;/37085880290;/37086857698;/37406370400",
        "aff": "State Key Laboratory of Fluid Power & Mechatronic Systems, School of Mechanical Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Fluid Power & Mechatronic Systems, School of Mechanical Engineering, Zhejiang University, Hangzhou, China; Department of Mechanical and Aerospace Engineering, Rutgers University, Piscataway, NJ, USA; State Key Laboratory of Fluid Power & Mechatronic Systems, School of Mechanical Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Fluid Power & Mechatronic Systems, School of Mechanical Engineering, Zhejiang University, Hangzhou, China; National Research Center for Rehabilitation Technical Aids, Beijing, China; Department of Intelligent Mechanical Systems Engineering, Kochi University of Technology, Kochi, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561581/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15689366047953295359&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;2;3",
        "aff_unique_norm": "Zhejiang University;Rutgers University;National Research Center for Rehabilitation Technical Aids;Kochi University of Technology",
        "aff_unique_dep": "School of Mechanical Engineering;Department of Mechanical and Aerospace Engineering;;Department of Intelligent Mechanical Systems Engineering",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.rutgers.edu;;https://www.kochi-tech.ac.jp",
        "aff_unique_abbr": "ZJU;Rutgers;;KUT",
        "aff_campus_unique_index": "0;0;1;0;0;3",
        "aff_campus_unique": "Hangzhou;Piscataway;;Kochi",
        "aff_country_unique_index": "0;0;1;0;0;0;2",
        "aff_country_unique": "China;United States;Japan"
    },
    {
        "id": "9561377",
        "title": "A Passive Navigation Planning Algorithm for Collision-free Control of Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Path planning and collision avoidance are challenging in complex and highly variable environments due to the limited horizon of events. In literature, there are multiple model- and learning-based approaches that require significant computational resources to be effectively deployed and they may have limited generality. We propose a planning algorithm based on a globally stable passive controller that can plan smooth trajectories using limited computational resources in challenging environmental conditions. The architecture combines the recently proposed fractal impedance controller with elastic bands and regions of finite time invariance. As the method is based on an impedance controller, it can also be used directly as a force/torque controller. We validated our method in simulation to analyse the ability of interactive navigation in challenging concave domains via the issuing of via-points, and its robustness to low bandwidth feedback. A swarm simulation using 11 agents validated the scalability of the proposed method. We have performed hardware experiments on a holonomic wheeled platform validating smoothness and robustness of interaction with dynamic agents (i.e., humans and robots). The computational complexity of the proposed local planner enables deployment with low-power micro-controllers lowering the energy consumption compared to other methods that rely upon numeric optimisation.",
        "primary_area": "",
        "author": "Carlo Tiseo;Vladimir Ivan;Wolfgang Merkt;Ioannis Havoutis;Michael Mistry;Sethu Vijayakumar;Carlo Tiseo;Vladimir Ivan;Wolfgang Merkt;Ioannis Havoutis;Michael Mistry;Sethu Vijayakumar",
        "authorids": "/37085404832;/37085552022;/37086118415;/37542879900;/37542865600;/37295595500;/37085404832;/37085552022;/37086118415;/37542879900;/37542865600;/37295595500",
        "aff": "Edinburgh Centre for Robotics, Institute of Perception Action and Behaviour, School of Informatics, University of Edinburgh; Edinburgh Centre for Robotics, Institute of Perception Action and Behaviour, School of Informatics, University of Edinburgh; Oxford Robotics Institute, University of Oxford; Oxford Robotics Institute, University of Oxford; Edinburgh Centre for Robotics, Institute of Perception Action and Behaviour, School of Informatics, University of Edinburgh; Edinburgh Centre for Robotics, Institute of Perception Action and Behaviour, School of Informatics, University of Edinburgh",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561377/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8823815982329935908&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "University of Edinburgh;University of Oxford",
        "aff_unique_dep": "School of Informatics;Oxford Robotics Institute",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.ox.ac.uk",
        "aff_unique_abbr": "Edinburgh;Oxford",
        "aff_campus_unique_index": "0;0;1;1;0;0",
        "aff_campus_unique": "Edinburgh;Oxford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561370",
        "title": "A Peg-in-hole Task Strategy for Holes in Concrete",
        "track": "main",
        "status": "Poster",
        "abstract": "A method that enables an industrial robot to accomplish the peg-in-hole task for holes in concrete is proposed. The proposed method involves slightly detaching the peg from the wall, when moving between search positions, to avoid the negative influence of the concrete\u2019s high friction coefficient. It uses a deep neural network (DNN), trained via reinforcement learning, to effectively find holes with variable shape and surface finish (due to the brittle nature of concrete) without analytical modeling or control parameter tuning. The method uses displacement of the peg toward the wall surface, in addition to force and torque, as one of the inputs of the DNN. Since the displacement increases as the peg gets closer to the hole (due to the chamfered shape of holes in concrete), it is a useful parameter for inputting in the DNN. The proposed method was evaluated by training the DNN on a hole 500 times and attempting to find 12 unknown holes. The results of the evaluation show the DNN enabled a robot to find the unknown holes with average success rate of 96.1% and average execution time of 12.5 seconds. Additional evaluations with random initial positions and a different type of peg demonstrate the trained DNN can generalize well to different conditions. Analyses of the influence of the peg displacement input showed the success rate of the DNN is increased by utilizing this parameter. These results validate the proposed method in terms of its effectiveness and applicability to the construction industry.",
        "primary_area": "",
        "author": "Andr\u00e9 Yuji Yasutomi;Hiroki Mori;Tetsuya Ogata;Andr\u00e9 Yuji Yasutomi;Hiroki Mori;Tetsuya Ogata",
        "authorids": "/37086573633;/37086432927;/37273829100;/37086573633;/37086432927;/37273829100",
        "aff": "Robotics Research Department, Center for Technology Innovation, R&D Group, Hitachi, Ltd.; Department of Intermedia Art and Science, Graduate School of Fundamental Science and Engineering, Waseda University; Artificial Intelligence Research Center, AIST",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561370/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8527857965989599120&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Hitachi, Ltd.;Waseda University;Advanced Institute of Science and Technology",
        "aff_unique_dep": "Robotics Research Department;Department of Intermedia Art and Science, Graduate School of Fundamental Science and Engineering;Artificial Intelligence Research Center",
        "aff_unique_url": "https://www.hitachi.com;https://www.waseda.jp/top;https://www.aist.go.jp",
        "aff_unique_abbr": "Hitachi;Waseda;AIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561507",
        "title": "A Primitive-Based Approach to Good Seamanship Path Planning for Autonomous Surface Vessels",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper offers a multi-layer planning approach for autonomous surface vessels (ASVs) that must adhere to good seamanship practices and the International Regulations for Prevention of Collisions at Sea (COLREGS) [1]. The approach combines novel situational awareness logic with motion primitive-based planners in a receding horizon framework. Further, ship domain and ship arena concepts are used to develop risk metrics that capture COLREGS compliance and the notion of good seamanship. By relying on metrics-driven motion planning as opposed to rule-based conditions, the proposed framework scales naturally to non-trivial single-vessel and multi-vessel situations. The planner is evaluated using adaptive, simulation-based testing to statistically compare the performance to other standard methods. Finally, proof-of-concept field experiments are presented on a subscale platform.",
        "primary_area": "",
        "author": "Paul Stankiewicz;Marin Kobilarov;Paul Stankiewicz;Marin Kobilarov",
        "authorids": "/37086190885;/37546944400;/37086190885;/37546944400",
        "aff": "Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561507/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16833936752213050769&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560838",
        "title": "A Real-Time Multi-Task Framework for Guidewire Segmentation and Endpoint Localization in Endovascular Interventions",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time guidewire segmentation and endpoint localization play a pivotal role in robot-assisted minimally invasive surgery, which is helpful to reduce radiation dose and procedure time. Nevertheless, the tasks often come with the challenge of limited computational resources. For this purpose, a real-time multi-task framework with two stages is developed. In the first stage, a Fast Attention-fused Network (FAD-Net) is proposed to obtain accurate guidewire segmentation masks. In the second stage, a lightweight localization network and a post-processing algorithm are designed to robustly predict the guidewire endpoint position. Quantitative and qualitative evaluations on intraoperative X-ray sequences from 30 patients demonstrate that the developed framework outperforms the previously-published results for the tasks, achieving state-of-the-art performance. Moreover, the inference rate of the developed framework is approximately 10.6 FPS, which meets the real-time requirement of X-ray fluoroscopy. These results indicate the proposed approach has the potential to be integrated into the robotic navigation framework for endovascular interventions, enabling robotic-assisted minimally invasive surgery.",
        "primary_area": "",
        "author": "Yan-Jie Zhou;Shi-Qi Liu;Xiao-Liang Xie;Xiao-Hu Zhou;Guan-An Wang;Zeng-Guang Hou;Rui-Qi Li;Zhen-Liang Ni;Chen-Chen Fan;Yan-Jie Zhou;Shi-Qi Liu;Xiao-Liang Xie;Xiao-Hu Zhou;Guan-An Wang;Zeng-Guang Hou;Rui-Qi Li;Zhen-Liang Ni;Chen-Chen Fan",
        "authorids": "/37087016101;/37086480801;/37533295000;/37085823497;/37088996304;/37279945000;/37087030761;/37087030579;/37089268878;/37087016101;/37086480801;/37533295000;/37085823497;/37088996304;/37279945000;/37087030761;/37087030579;/37089268878",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; CASIA-MUST Joint Laboratory of Intelligence Science and Technology, Institute of Systems Engineering, Macau University of Science and Technology, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560838/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7583801682670363817&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;0;1;1;2;0;0;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences;Macau University of Science and Technology",
        "aff_unique_dep": "School of Artificial Intelligence;Institute of Automation;Institute of Systems Engineering",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.ia.cas.cn;https://www.must.edu.mo",
        "aff_unique_abbr": "UCAS;CAS;MUST",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562059",
        "title": "A Reversible Dynamic Movement Primitive formulation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, a novel Dynamic Movement Primitive (DMP) formulation is proposed which supports reversibility, i.e. backwards reproduction of a learned trajectory. Apart from sharing all favourable properties of the original DMP, decoupling the teaching of position and velocity profiles and bidirectional drivability along the encoded path are also supported. Original DMP have been extensively used for encoding and reproducing a desired motion pattern in several robotic applications. However, they lack reversibility, which is a useful and expedient property that can be leveraged in many scenarios. The proposed formulation is analyzed theoretically and its practical usefulness is showcased in an assembly by insertion experimental scenario.",
        "primary_area": "",
        "author": "Antonis Sidiropoulos;Zoe Doulgeri;Antonis Sidiropoulos;Zoe Doulgeri",
        "authorids": "/37089372642;/37274011500;/37089372642;/37274011500",
        "aff": "Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562059/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11048489842408498803&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.auth.gr",
        "aff_unique_abbr": "AUTH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Thessaloniki",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9561941",
        "title": "A Robot Walks into a Bar: Automatic Robot Joke Success Assessment",
        "track": "main",
        "status": "Poster",
        "abstract": "Effective social robots should leverage humor\u2019s unique ability to improve relationship connections and dispel stress, but current robots possess limited (if any) humorous abilities. In this paper, we aim to supplement one aspect of autonomous robots by giving robotic systems the ability to \"read the room\" to assess how their humorous statements are received by nearby people in real time. Using a dataset of the audio of crowd responses to a robotic comedian over multiple performances (first presented in past work), we establish human-labeled joke success ground truths and compare individual human rater accuracy against the outputs of lightweight Machine Learning (ML) approaches that are easy to deploy in real-time joke assessment. Our results indicate that all three ML approaches (na\u00efve Bayes, support vector machines, and single-hidden-layer feedforward neural networks) performed significantly better than the baseline approach used in our past work. In particular, support vector machines and neural network approaches are comparable to a human rater in the task of assessing if a joke failed or not in certain cases. The products of this work will inform self-assessment techniques for robots and help social robotics researchers test their own assessment methods on realistic data from human crowds.",
        "primary_area": "",
        "author": "Ajitesh Srivastava;Naomi T. Fitter;Ajitesh Srivastava;Naomi T. Fitter",
        "authorids": "/37085469114;/37077925800;/37085469114;/37077925800",
        "aff": "Ming Hsieh Department of Electrical and Computer Engineering, University of Southern California, Los Angeles, CA, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, Oregon, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561941/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11702991024612539902&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Southern California;Oregon State University",
        "aff_unique_dep": "Ming Hsieh Department of Electrical and Computer Engineering;Collaborative Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://www.usc.edu;https://oregonstate.edu",
        "aff_unique_abbr": "USC;OSU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Los Angeles;Corvallis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561265",
        "title": "A Robotic Defect Inspection System for Free-form Specular Surfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a robotic system to automatically perform defect inspection tasks over free-form specular surfaces, which the image acquisition sub-system is equipped with a 6-DOF robot manipulator to achieve flexible scanning. Given the mesh model of the workpiece, we implement K-means based region segmentation algorithm on the point cloud after preprocessing. Then, we take the smooth regions as input to plan the scanning path. A projection registration method that robustly localizes the object in the robot\u2019s frame is proposed for real-time workpiece localization. According to the optical features of the high-resolution line scan, we design an image processing pipeline to detect defects from the captured images. We report a detailed experimental study to validate the proposed methodology.",
        "primary_area": "",
        "author": "Shengzeng Huo;David Navarro-Alarcon;David TW Chik;Shengzeng Huo;David Navarro-Alarcon;David TW Chik",
        "authorids": "/37088859840;/38271697000;/37088998789;/37088859840;/38271697000;/37088998789",
        "aff": "KLN, The Hong Kong Polytechnic University, Hong Kong; KLN, The Hong Kong Polytechnic University, Hong Kong; Hong Kong Applied Science and Technology Research Institute, NT, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561265/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7578268230471711675&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Hong Kong Polytechnic University;Hong Kong Applied Science and Technology Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.polyu.edu.hk;https://www.hkastri.hk",
        "aff_unique_abbr": "PolyU;HKASTRI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560965",
        "title": "A Robotic System for Implant Modification in Single-stage Cranioplasty",
        "track": "main",
        "status": "Poster",
        "abstract": "Craniomaxillofacial reconstruction with patientspecific customized craniofacial implants (CCIs) is most commonly performed for large-sized skeletal defects. Because the exact size of skull resection may not be known prior to the surgery, in single-stage cranioplasty, an oversized CCI is prefabricated and resized intraoperatively with a manual-cutting process provided by a surgeon. The manual resizing, however, may be inaccurate and significantly add to the operating time. This paper introduces a fast and non-contact approach for intraoperatively determining the exact contour of the skull resection and automatically resizing the implant to fit the resection area. Our approach includes four steps: First, we acquire a patient\u2019s defect information using a handheld 3D scanner. Second, the scanned defect is aligned to the CCI by registering the scanned defect to the preoperative CT model. Third, a cutting toolpath is generated from the scanned defect model by extracting the resection contour. Lastly, a cutting robot resizes the oversized CCI to fit the resection area. To evaluate the resizing performance of our method, we generated six different resection shapes for the cutting experiments. We compared the performance of our method to the performance of surgeon\u2019s manual resizing and an existing technique that collects the defect contour with an optical tracking system. The results show that our proposed method improves the resizing accuracy by 56% compared to the surgeon\u2019s manual modification and 42% compared to the optical tracking method.",
        "primary_area": "",
        "author": "Shuya Liu;Wei-Lun Huang;Chad Gordon;Mehran Armand;Shuya Liu;Wei-Lun Huang;Chad Gordon;Mehran Armand",
        "authorids": "/37088918688;/37088916536;/37085760882;/37545404000;/37088918688;/37088916536;/37085760882;/37545404000",
        "aff": "Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD; Department of Computer Science, Johns Hopkins University, Baltimore, MD; Department of Plastic and Reconstructive Surgery, Section of Neuroplastic and Reconstructive Surgery, Johns Hopkins School of Medicine, Baltimore, MD; Department of Orthopaedic Surgery, Mechanical Engineering, and Computer Science, Johns Hopkins University, Baltimore, MD",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560965/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12379838867737158246&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Johns Hopkins University;Johns Hopkins School of Medicine",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Plastic and Reconstructive Surgery",
        "aff_unique_url": "https://www.jhu.edu;https://www.hopkinsmedicine.org",
        "aff_unique_abbr": "JHU;Johns Hopkins",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561195",
        "title": "A Safe Hierarchical Planning Framework for Complex Driving Scenarios based on Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles need to handle various traffic conditions and make safe and efficient decisions and maneuvers. However, on the one hand, a single optimization/sampling-based motion planner cannot efficiently generate safe trajectories in real time, particularly when there are many interactive vehicles near by. On the other hand, end-to-end learning methods cannot assure the safety of the outcomes. To address this challenge, we propose a hierarchical behavior planning framework with a set of low-level safe controllers and a high-level reinforcement learning algorithm (H-CtRL) as a coordinator for the low-level controllers. Safety is guaranteed by the low-level optimization/sampling-based controllers, while the high-level reinforcement learning algorithm makes H-CtRL an adaptive and efficient behavior planner. To train and test our proposed algorithm, we built a simulator that can reproduce traffic scenes using real-world datasets. The proposed HCtRL is proved to be effective in various realistic simulation scenarios, with satisfying performance in terms of both safety and efficiency.",
        "primary_area": "",
        "author": "Jinning Li;Liting Sun;Jianyu Chen;Masayoshi Tomizuka;Wei Zhan;Jinning Li;Liting Sun;Jianyu Chen;Masayoshi Tomizuka;Wei Zhan",
        "authorids": "/37088998708;/37085425729;/37086004703;/37281933000;/37067099600;/37088998708;/37085425729;/37086004703;/37281933000;/37067099600",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561195/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6207403136066544246&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561722",
        "title": "A Scavenger Hunt for Service Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Creating robots that can perform general-purpose service tasks in a human-populated environment has been a longstanding grand challenge for AI and Robotics research. One particularly valuable skill that is relevant to a wide variety of tasks is the ability to locate and retrieve objects upon request. This paper models this skill as a Scavenger Hunt (SH) game, which we formulate as a variation of the NP-hard stochastic traveling purchaser problem. In this problem, the goal is to find a set of objects as quickly as possible, given probability distributions of where they may be found. We investigate the performance of several solution algorithms for the SH problem, both in simulation and on a real mobile robot. We use Reinforcement Learning (RL) to train an agent to plan a minimal cost path, and show that the RL agent can outperform a range of heuristic algorithms, achieving near optimal performance. In order to stimulate research on this problem, we introduce a publicly available software stack and associated website that enable users to upload scavenger hunts which robots can download, perform, and learn from to continually improve their performance on future hunts.",
        "primary_area": "",
        "author": "Harel Yedidsion;Jennifer Suriadinata;Zifan Xu;Stefan Debruyn;Peter Stone;Harel Yedidsion;Jennifer Suriadinata;Zifan Xu;Stefan Debruyn;Peter Stone",
        "authorids": "/37086064503;/37088997885;/37089000983;/37089002040;/37269574900;/37086064503;/37088997885;/37089000983;/37089002040;/37269574900",
        "aff": "Department of Computer Science, The University of Texas at Austin; Department of Computer Science, The University of Texas at Austin; Department of Physics, The University of Texas at Austin; Department of Computer Science, The University of Texas at Austin; Sony AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561722/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7131310422919282381&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of Texas at Austin;Sony",
        "aff_unique_dep": "Department of Computer Science;Sony AI",
        "aff_unique_url": "https://www.utexas.edu;https://www.sony.com",
        "aff_unique_abbr": "UT Austin;Sony AI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9562029",
        "title": "A Self-Supervised Near-to-Far Approach for Terrain-Adaptive Off-Road Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a self-supervised method for systematically choosing traversable terrain while autonomously navigating a vehicle to a goal position in an unknown off-road environment. Leveraging the color discriminant bias of off-road terrain types, and using images from a vehicle-mounted camera, we employ a viewpoint transformation that maintains the spatial layout of the terrain to cluster terrain types by color and register corresponding traversability features to guide future navigation decisions. As it navigates, our algorithm also generates training images for use in contemporary end-to-end navigation schemes. Our test results demonstrate the advantages of our approach over classical near-to-far approaches in off-road environments with unknown traversability characteristics, and highlight its fit to supervised semantic segmentation schemes that require foreknowledge of traversability characteristics for labeling, which are limited by insufficient data and suffer pixel-level class imbalance. We detail the techniques for clustering, feature registration, path planning and navigation; and demonstrate the method. Finally, we study the effectiveness of non-discretionary self-supervised data labeling.",
        "primary_area": "",
        "author": "Orighomisan Mayuku;Brian W. Surgenor;Joshua A. Marshall;Orighomisan Mayuku;Brian W. Surgenor;Joshua A. Marshall",
        "authorids": "/37088908485;/37349192600;/37269656200;/37088908485;/37349192600;/37269656200",
        "aff": "Department of Mechanical & Materials Engineering and the Ingenuity Labs Research Institute, Queen\u2019s University, Kingston, ON; Department of Mechanical & Materials Engineering and the Ingenuity Labs Research Institute, Queen\u2019s University, Kingston, ON; Department of Electrical & Computer Engineering and the Ingenuity Labs Research Institute, Queen\u2019s University, Kingston, ON",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562029/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16252469623816479457&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queen\u2019s University",
        "aff_unique_dep": "Department of Mechanical & Materials Engineering",
        "aff_unique_url": "https://www.queensu.ca",
        "aff_unique_abbr": "Queen's U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kingston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561394",
        "title": "A Self-Training Approach-Based Traversability Analysis for Mobile Robots in Urban Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a method for LiDAR sensor-based traversability analysis for autonomous mobile robots in urban environments. Although urban environments are structured environments, a typical terrain comprises hazardous regions for mobile robots. Therefore, a reliable method for detecting traversable regions is required to prevent robots from getting stuck in the middle of the road. Conventional approaches require considerable efforts to obtain a model for traversability analysis for a specific robot or environment. In particular, learning-based methods require explicit training data. This paper introduces a method for traversability mapping based on a self-training algorithm to eliminate the hand labeling process. A neural network was applied to the underlying classifier of the self-training algorithm. With our approach, the model can be learned with even weakly labeled data obtained from robot-specific parameters and the robot\u2019s footprint. In practical experiments, the self-trained model performed better performance than the existing supervised learning method. Moreover, as the fraction of unlabeled data increased, the performance also increased. Therefore, the demonstrations in the urban environments indicate the effectiveness of the proposed method for traversability mapping.",
        "primary_area": "",
        "author": "Hyunsuk Lee;Woojin Chung;Hyunsuk Lee;Woojin Chung",
        "authorids": "/38240235000;/37280299200;/38240235000;/37280299200",
        "aff": "Department of Mechanical Engineering, Korea University, Seoul, Korea; Department of Mechanical Engineering, Korea University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561394/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5867501959239076493&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "http://www.korea.ac.kr",
        "aff_unique_abbr": "KU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561271",
        "title": "A Self-supervised Learning System for Object Detection in Videos Using Random Walks on Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new self-supervised system for learning to detect novel and previously unseen categories of objects in images. The proposed system receives as input several unlabeled videos of scenes containing various objects. The frames of the videos are segmented into objects using depth information, and the segments are tracked along each video. The system then constructs a weighted graph that connects sequences based on the similarities between the objects that they contain. The similarity between two sequences of objects is measured by using generic visual features, after automatically re-arranging the frames in the two sequences to align the viewpoints of the objects. The graph is used to sample triplets of similar and dissimilar examples by performing random walks. The triplet examples are finally used to train a siamese neural network that projects the generic visual features into a low-dimensional manifold. Experiments on three public datasets, YCB-Video, CORe50 and RGBD-Object, show that the projected low-dimensional features improve the accuracy of clustering unknown objects into novel categories, and outperform several recent unsupervised clustering techniques.",
        "primary_area": "",
        "author": "Juntao Tan;Changkyu Song;Abdeslam Boularias;Juntao Tan;Changkyu Song;Abdeslam Boularias",
        "authorids": "/37088893154;/37086556487;/37542596800;/37088893154;/37086556487;/37542596800",
        "aff": "Department of Computer Science, Rutgers University, Piscataway, New Jersey, USA; Department of Computer Science, Rutgers University, Piscataway, New Jersey, USA; Department of Computer Science, Rutgers University, Piscataway, New Jersey, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561271/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10030157158123509478&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560803",
        "title": "A Shared Control Framework for Robotic Telemanipulation Combining Electromyography Based Motion Estimation and Compliance Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Electromyography (EMG) is a wearable, noninvasive, commonly used method for measuring the human muscular activations from the surface of the skin. In this work, we present a pilot study that focuses on the formulation of a shared control framework to facilitate the simplified execution of Electromyography (EMG) based telemanipulation tasks with a robotic platform. The framework combines a Random Forests (RF) regression method with a compliance controller that relies on the force measurements collected with a force-torque sensor. The RF regression efficiently maps the myoelectric activations of the human muscles to corresponding human wrist positions. Then, a teleoperation process is used to control the robot arm end-effector\u2019s position, utilizing the human wrist position estimations. The examined application involves semi-autonomous cleaning of a whiteboard surface with the proposed framework. The compliance controller guarantees that a desired contact force will always be maintained on the whiteboard surface during task execution. This ensures that any EMG based decoding inaccuracies will not drive the robot away from the cleaning plane. Essentially, the system projects the EMG based estimation on the cleaning plane. The shared control framework offers robust performance, with minimal training and calibration required.",
        "primary_area": "",
        "author": "Anany Dwivedi;Dasha Shieff;Amber Turner;Gal Gorjup;Yongje Kwon;Minas Liarokapis;Anany Dwivedi;Dasha Shieff;Amber Turner;Gal Gorjup;Yongje Kwon;Minas Liarokapis",
        "authorids": "/37086133073;/37089000955;/37089000332;/37087237844;/37086480207;/38558084100;/37086133073;/37089000955;/37089000332;/37087237844;/37086480207;/38558084100",
        "aff": "Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand; Department of Mechanical Engineering, New Dexterity Research Group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560803/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8482627252771604497&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Auckland",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "UoA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9560939",
        "title": "A Simulation-Based Grasp Planner for Enabling Robotic Grasping during Composite Sheet Layup",
        "track": "main",
        "status": "Poster",
        "abstract": "Composites are increasingly becoming a material of choice in the aerospace and automotive industries. Currently, many composite parts are produced by manually laying up sheets on complex molds. Composite sheet layup requires executing two main tasks: (1) grasping a sheet and (2) draping it on the mold. Automating the layup process requires automation of these two tasks. This paper is focused on the automation of the grasping task using robots. This requires an automated generation of grasp plans to enable robots to hold the sheet during the draping process. We present a simulation-based approach for determining robot grasp locations on the composite sheets. We also present an intervention controller that uses a real-time sheet tracking system during plan execution and can prevent failures. We demonstrate the performance of the developed system using a large complex part.",
        "primary_area": "",
        "author": "Omey M. Manyar;Jaineel Desai;Nimish Deogaonkar;Rex Jomy Joesph;Rishi Malhan;Zachary McNulty;Bohan Wang;Jernej Barbi\u010d;Satyandra K. Gupta;Omey M. Manyar;Jaineel Desai;Nimish Deogaonkar;Rex Jomy Joesph;Rishi Malhan;Zachary McNulty;Bohan Wang;Jernej Barbi\u010d;Satyandra K. Gupta",
        "authorids": "/37088999526;/37088999014;/37088998334;/37089000672;/37086537030;/37086012577;/37088999210;/37085505798;/37878971100;/37088999526;/37088999014;/37088998334;/37089000672;/37086537030;/37086012577;/37088999210;/37085505798;/37878971100",
        "aff": "Center for Advanced Manufacturing, University of Southern California, Los Angeles, CA, USA; Center for Advanced Manufacturing, University of Southern California, Los Angeles, CA, USA; Center for Advanced Manufacturing, University of Southern California, Los Angeles, CA, USA; Center for Advanced Manufacturing, University of Southern California, Los Angeles, CA, USA; Center for Advanced Manufacturing, University of Southern California, Los Angeles, CA, USA; Center for Advanced Manufacturing, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA; Center for Advanced Manufacturing, University of Southern California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560939/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5559234658710392110&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Center for Advanced Manufacturing",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561287",
        "title": "A Soft Robotic Gripper with Anti-Freezing Ionic Hydrogel-Based Sensors for Learning-Based Object Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robotic grippers possess high structural compliance and adaptability for grasping objects with unknown and irregular shapes and sizes. To enable more dexterous manipulation, soft sensors with similar mechanical properties to common elastomer materials are desired to be integrated into soft grippers. In this paper, we develop ionic hydrogel-based strain and tactile sensors and integrate these sensors into a three-finger soft gripper for learning-based object recognition. Such hydrogel-based sensors have excellent conductivity, high stretchability and toughness, good ambient stability, and unique anti-freezing property, and can be readily attached to a soft gripper at desired locations for strain and tactile sensing. Based on a deep-learning model, we demonstrate the capability of the sensory soft gripper for object grasping and recognition at both room and freezing temperatures, and achieve high recognition accuracy close to 100% for 10 typical objects. With these abilities, our gripper can find interesting applications such as sorting food or chemicals in low temperature storage and cold chain transportation, or manipulating equipment in polar area.",
        "primary_area": "",
        "author": "Runze Zuo;Zhanfeng Zhou;Binbin Ying;Xinyu Liu;Runze Zuo;Zhanfeng Zhou;Binbin Ying;Xinyu Liu",
        "authorids": "/37088998948;/37089399456;/37088999486;/37310954100;/37088998948;/37089399456;/37088999486;/37310954100",
        "aff": "Department of Mechanical and Industrial Engineering, University of Toronto, Canada; Department of Mechanical and Industrial Engineering, University of Toronto, Canada; Department of Mechanical and Industrial Engineering, University of Toronto, Canada; Department of Mechanical and Industrial Engineering, University of Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561287/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=60430334184514864&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Department of Mechanical and Industrial Engineering",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561321",
        "title": "A Soft-Rigid Air-Propelled Pipe-Climbing Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Complex pipeline network should be inspected regularly for safety. In general, these tasks are often completed by large pipe-climbing robots or customized equipment. Most of them are not effective, and cannot work on pipes with uncertain barriers. Moreover, some pipes are mounted in constrained scenarios, so bulky robots are not applicable. This paper presents a tethered soft-rigid pipe-climbing robot to fill the gap. Two indispensable actions, i.e. embracing pipe and moving along it, are realized by a soft component and a 3D printed wheel mechanism. The latter includes two forces: thrust force from the compressed air and tractive force from wheels, to drive the robot comprehensively, and a lightweight body (only 160g) benefits agile motion. In operation, pressure exerted on the soft component enables the robot to embrace pipes of different diameters, with controllable adhesion force, and locomotion force is also regulated. Inspired from vehicle, an elastic damper is attached between the wheel structure and the robot body, which can effectively alleviate vibration when crossing barriers. In addition, theoretical models are constructed to analyse and control thrust force, and the locomotion performance is analysed by dynamics model. Experiments demonstrate that this robot can perform rapid climbing at a speed of 1.09m/s in load-free scenarios, and it can move at a maximum speed of 0.828m/s with 500g load. Reconstruction of a flexible pipe using the robot is also demonstrated.",
        "primary_area": "",
        "author": "Qingxiang Zhao;Zhiyi Jiang;Henry K. Chu;Qingxiang Zhao;Zhiyi Jiang;Henry K. Chu",
        "authorids": "/37088996834;/37088996837;/37085396213;/37088996834;/37088996837;/37085396213",
        "aff": "Department of Mechanical Engineering, Hong Kong Polytechnic University, Hong Kong, China; Department of Mechanical Engineering, Hong Kong Polytechnic University, Hong Kong, China; Department of Mechanical Engineering, Hong Kong Polytechnic University, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561321/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11287576350557343898&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hong Kong Polytechnic University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.polyu.edu.hk",
        "aff_unique_abbr": "PolyU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562112",
        "title": "A Stable Control Strategy for Industrial Robots with External Feedback Loop",
        "track": "main",
        "status": "Poster",
        "abstract": "The inner/low-level control loop of most industrial robotic manipulators is protected from any modification by a closed control architecture. The only way to specify joint inputs to them is through position or velocity commands. Furthermore, the inner controller is unknown/uncertain, as it is not revealed to the user. This makes it very difficult to determine the configuration of the inner controller, including the structure and values of the control gains. As a result, integrating external sensory feedback systems into a closed architecture system becomes a difficult task because the interaction of the external feedback loop with the inner control loop can affect the stability of the overall system. In this paper, a stable control strategy is proposed to generate the joint velocity commands for industrial robotic manipulators with uncertain closed control architecture. Based on the proposed method, external feedback controllers can be added regardless of the inner control loop configuration. The proposed external (or outer) control loop approach provides a high degree of design flexibility by enabling smooth implementation of various modern control applications on industrial robots. Unlike previous studies, the proposed control method is not limited to a particular configuration of the controller in the inner loop, nor to the structure of its control gains. The proposed controller design is validated on the UR 5e industrial manipulator.",
        "primary_area": "",
        "author": "Gulam Dastagir Khan;Huu-Thiet Nguyen;Chien Chern Cheah;Gulam Dastagir Khan;Huu-Thiet Nguyen;Chien Chern Cheah",
        "authorids": "/37088556111;/37087050111;/37282378800;/37088556111;/37087050111;/37282378800",
        "aff": "School of Electrical & Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical & Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical & Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562112/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17283013316375132363&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Electrical & Electronic Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9560967",
        "title": "A Tactile Sensing Foot for Single Robot Leg Stabilization",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile sensing on human feet is crucial for motion control, however, has not been explored in robotic counterparts. This work is dedicated to endowing tactile sensing to legged robot\u2019s feet and showing that a single-legged robot can be stabilized with only tactile sensing signals from its foot. We propose a robot leg with a novel vision-based tactile sensing foot system and implement a processing algorithm to extract contact information for feedback control in stabilizing tasks. A pipeline to convert images of the foot skin into high-level contact information using a deep learning framework is presented. The leg was quantitatively evaluated in a stabilization task on a tilting surface to show that the tactile foot was able to estimate both the surface tilting angle and the foot poses. Feasibility and effectiveness of the tactile system were investigated qualitatively in comparison with conventional single-legged robotic systems using inertia measurement units (IMU). Experiments demon-strate the capability of vision-based tactile sensors in assisting legged robots to maintain stability on unknown terrains and the potential for regulating more complex motions for humanoid robots.",
        "primary_area": "",
        "author": "Guanlan Zhang;Yipai Du;Yazhan Zhang;Michael Yu Wang;Guanlan Zhang;Yipai Du;Yazhan Zhang;Michael Yu Wang",
        "authorids": "/37088526543;/37088526419;/37086842950;/37280913900;/37088526543;/37088526419;/37086842950;/37280913900",
        "aff": "Department of Mechanical and Aerospace Engineering, Hong Kong University of Science and Technology, Hong Kong; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong; Department of Mechanical and Aerospace Engineering, Hong Kong University of Science and Technology, Hong Kong; Department of Mechanical and Aerospace Engineering and the Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560967/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18023102676519941444&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560878",
        "title": "A Tethered Quadrotor UAV\u2212Buoy System for Marine Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned aerial vehicles (UAVs) are finding their way into offshore applications. In this work, we postulate an original system that entails a marine locomotive quadrotor UAV that manipulates the velocity of a floating buoy by means of a cable. By leveraging the advantages of UAVs relative to high speed, maneuverability, ease of deployment, and wide field of vision, the proposed UAV\u2212buoy system paves the way in front of a variety of novel applications. The dynamic model that couples the buoy, UAV, cable, and water environment is presented using the Euler-Lagrange method. A stable control system design is proposed to manipulate the forward-surge speed of the buoy under two constraints: maintaining the cable in a taut state, and keeping the buoy in contact with the water surface. Polar coordinates are used in the controller design process to attain correlated effects on the tracking performance, whereby each control channel independently affects one control parameter. This results in improved performance over traditional Cartesian-based velocity controllers, as demonstrated via numerical simulations in wave-free and wavy seas.",
        "primary_area": "",
        "author": "Ahmad Kourani;Naseem Daher;Ahmad Kourani;Naseem Daher",
        "authorids": "/37086587716;/37085823601;/37086587716;/37085823601",
        "aff": "Mechanical Engineering Department, Vision and Robotics Lab, American University of Beirut, Beirut, Lebanon; Electrical & Computer Engineering Department, Vision and Robotics Lab, American University of Beirut, Beirut, Lebanon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560878/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10640720430336529784&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "American University of Beirut",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.aub.edu.lb",
        "aff_unique_abbr": "AUB",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beirut",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Lebanon"
    },
    {
        "id": "9561429",
        "title": "A Translational Parallel Continuum Robot Reinforced by Origami and Cross-Routing Tendons",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce an origami-reinforced parallel continuum robot which is capable of maintaining the orientation of the end effector regardless of the bending shape. The cross-routing tendons provide an effective actuation of the robot because the constant length of the backbones prevent the actuation of parallel arrangement of tendons. We utilise the arclength relationship of parallel curves to show that parallel backbones of equal lengths and constant spacing between the backbones enable the constant orientation of the end effector. The origami shell is introduced to increase the torsional stiffness of the continuum robot and minimise any twisting. This leads to planar and parallel bending of all backbones. Planar quintic Pythagorean Hodograph curves are utilised for shape reconstruction, which is more accurate as compared to the curves with piecewise constant curvatures. The concept of this continuum robot and the accuracy of the reconstruction are validated experimentally.",
        "primary_area": "",
        "author": "Charles Troeung;Chao Chen;Charles Troeung;Chao Chen",
        "authorids": "/37088996123;/37539314700;/37088996123;/37539314700",
        "aff": "Laboratory of Motion Generation and Analysis, Faculty of Engineering, Monash University, Clayton, VIC, Australia; Laboratory of Motion Generation and Analysis, Faculty of Engineering, Monash University, Clayton, VIC, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561429/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:wEcUVb5tdsAJ:scholar.google.com/&scioq=A+Translational+Parallel+Continuum+Robot+Reinforced+by+Origami+and+Cross-Routing+Tendons&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Monash University",
        "aff_unique_dep": "Faculty of Engineering",
        "aff_unique_url": "https://www.monash.edu",
        "aff_unique_abbr": "Monash",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Clayton",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9561618",
        "title": "A Unified Optimization Framework and New Set of Performance Metrics for Robot Leg Design",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a framework for the simultaneous optimization of motors, transmissions, and mechanisms of different joints of robotic legs with the goal of achieving an energy efficient, precisely controllable and stable locomotion in dynamic environments. This unified framework allowed us to introduce and formulate new performance metrics for the separate evaluation of the system's stabilizing ability during stance and swing. Moreover, through a case study, this design optimization framework was applied to an anthropomorphic robot leg model and the optimal actuation configurations for the leg were obtained. This case study also helped us investigate the relationships among our three objectives (energy efficiency, and stance and swing control). It was shown that while in some cases a clear trade-off exists, it is not always valid and as such, careful consideration of all three objectives is necessary.",
        "primary_area": "",
        "author": "Chathura Semasinghe;Drake Taylor;Siavash Rezazadeh;Chathura Semasinghe;Drake Taylor;Siavash Rezazadeh",
        "authorids": "/37085991251;/37088997070;/37562356200;/37085991251;/37088997070;/37562356200",
        "aff": "Department of Mechanical and Materials Engineering, University of Denver, Denver, CO, USA; Department of Mechanical and Materials Engineering, University of Denver, Denver, CO, USA; Department of Mechanical and Materials Engineering, University of Denver, Denver, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561618/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17030389987274723007&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Denver",
        "aff_unique_dep": "Department of Mechanical and Materials Engineering",
        "aff_unique_url": "https://www.du.edu",
        "aff_unique_abbr": "DU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Denver",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561224",
        "title": "A Unified Perception Benchmark for Capacitive Proximity Sensing Towards Safe Human-Robot Collaboration (HRC)",
        "track": "main",
        "status": "Poster",
        "abstract": "During the co-presence of human workers and robots, measures are required to avoid injuries from undesired contacts. Capacitive Proximity Sensors (CPSs) offer a cost-effective solution to cover the entire robot manipulator with fast close-range perception for HRC tasks, closing the perception gap between tactile detection and mid-range perception. CPSs do not suffer from occlusion and compared to pure tactile or force sensing, they react earlier and allow increasing the operating speed of Collaborative Robots (Cobots) while still maintaining safety. However, since capacitive coupling to obstacles varies with their distance, shape and material properties, the projection from capacitance to actual distances is a general problem. In this work, we propose an universal benchmark test procedure for fellow researchers to evaluate their CPSs. Considering ISO/TS 15066 for Power and Force Limiting (PFL) as a reference, we derive the requirements for the specified body regions and propose a method for determining the operation speed to comply with PFL based on a pre-defined detection threshold. Finally, the benchmark test procedure is evaluated on three different concepts of CPSs from the contributed researchers, demonstrating the general applicability.",
        "primary_area": "",
        "author": "Serkan Ergun;Yitao Ding;Hosam Alagi;Christian Sch\u00f6ffmann;Barnaba Ubezio;Gergely Soti;Michael Rathmair;Stephan M\u00fchlbacher-Karrer;Ulrike Thomas;Bj\u00f6rn Hein;Michael Hofbaur;Hubert Zangl;Serkan Ergun;Yitao Ding;Hosam Alagi;Christian Sch\u00f6ffmann;Barnaba Ubezio;Gergely Soti;Michael Rathmair;Stephan M\u00fchlbacher-Karrer;Ulrike Thomas;Bj\u00f6rn Hein;Michael Hofbaur;Hubert Zangl",
        "authorids": "/37089000883;/37086576023;/38666348400;/37088840357;/37088506657;/37089001331;/38490952600;/38353427100;/37281523200;/37604448500;/37282896000;/37273010900;/37089000883;/37086576023;/38666348400;/37088840357;/37088506657;/37089001331;/38490952600;/38353427100;/37281523200;/37604448500;/37282896000;/37273010900",
        "aff": "Institute of Smart Systems Technologies, Klagenfurt University (AAU), Klagenfurt am W\u00f6rthersee, Austria; Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology (TUC), Chemnitz, Germany; Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics Lab (IAR - IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Institute of Smart Systems Technologies, Klagenfurt University (AAU), Klagenfurt am W\u00f6rthersee, Austria; Joanneum Research Robotics (Jr), Institute of Robotics and Mechatronics, Klagenfurt am W\u00f6rthersee, Austria; Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics Lab (IAR - IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Joanneum Research Robotics (Jr), Institute of Robotics and Mechatronics, Klagenfurt am W\u00f6rthersee, Austria; Joanneum Research Robotics (Jr), Institute of Robotics and Mechatronics, Klagenfurt am W\u00f6rthersee, Austria; Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology (TUC), Chemnitz, Germany; Karlsruhe University of Applied Sciences; Joanneum Research Robotics (Jr), Institute of Robotics and Mechatronics, Klagenfurt am W\u00f6rthersee, Austria; Institute of Smart Systems Technologies, Klagenfurt University (AAU), Klagenfurt am W\u00f6rthersee, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561224/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17152379176681254699&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;1;2;0;3;2;3;3;1;4;3;0",
        "aff_unique_norm": "Klagenfurt University;Chemnitz University of Technology;Karlsruhe Institute of Technology;JOANNEUM RESEARCH;Karlsruhe University of Applied Sciences",
        "aff_unique_dep": "Institute of Smart Systems Technologies;Lab of Robotics and Human-Machine-Interaction;Institute for Anthropomatics and Robotics;Institute of Robotics and Mechatronics;",
        "aff_unique_url": "https://www.aau.at;https://www.tu-chemnitz.de;https://www.kit.edu;https://www.joanneum.at;https://www.hs-karlsruhe.de",
        "aff_unique_abbr": "AAU;TUC;KIT;Jr;HsKA",
        "aff_campus_unique_index": "0;1;2;0;0;2;0;0;1;0;0",
        "aff_campus_unique": "Klagenfurt am W\u00f6rthersee;Chemnitz;Karlsruhe;",
        "aff_country_unique_index": "0;1;1;0;0;1;0;0;1;1;0;0",
        "aff_country_unique": "Austria;Germany"
    },
    {
        "id": "9562118",
        "title": "A Variable Soft Finger Exoskeleton for Quantifying Fatigue-induced Mechanical Impedance",
        "track": "main",
        "status": "Poster",
        "abstract": "Interactive (mechanical) impedance and finger fatigues are important topics, which have not been well investigated. To tackle this problem, we developed a soft lightweight (0.25 kg) finger exoskeleton (TIE-EXO) for quantifying interactive impedance and finger fatigue. A resist-as-needed (RAN) controller was used to produce variable resistance in fingers\u2019 exercises. The TIE-EXO\u2019s feedback and RAN\u2019s parameters were applied to quantify the relationship between interactive impedance and finger fatigue. This quantification was validated in the index and middle fingers of three subjects. This validation shows that the RAN control enables the TIE-EXO to produce online resistance adaptations to different subjects and finger fatigue. Moreover, it indicates a variation and invariance in finger impedance control. We argue that the proposed method provides a novel way for investigating interactive impedance and finger fatigue.",
        "primary_area": "",
        "author": "Xiaofeng Xiong;Poramate Manoonpong;Xiaofeng Xiong;Poramate Manoonpong",
        "authorids": "/37086356526;/37295679400;/37086356526;/37295679400",
        "aff": "SDU Biorobotics, the M\u00e6rsk Mc-Kinney M\u00f8ller Institute, the University of Southern Denmark (SDU), Odense M, Denmark; Bio-Inspired Robotics and Neural Engineering Lab, the School of Information Science and Technology, Vidyasirimedhi Institute of Science and Technology, Rayong, Thailand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562118/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3129754270028102511&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Southern Denmark;Vidyasirimedhi Institute of Science and Technology",
        "aff_unique_dep": "SDU Biorobotics;School of Information Science and Technology",
        "aff_unique_url": "https://www.sdu.dk;https://www.vistech.ac.th",
        "aff_unique_abbr": "SDU;VISTEC",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Odense;Rayong",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Denmark;Thailand"
    },
    {
        "id": "9561932",
        "title": "A Variable Stiffness Actuator Based on Second-order Lever Mechanism and Its Manipulator Integration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new variable stiffness actuator based on a second-order lever mechanism which has wide stiffness regulation range. By employing a novel symmetric structure design and improving the load capacity of the stiffness regulation module, the proposed actuator also shows well performance in load capacity, stiffness regulation response, and elastic hysteresis. On this basis, a variable stiffness actuated manipulator is developed. The experimental results demonstrate that the presented manipulator possesses abilities in fast stiffness tracking, shock-absorbing and explosive movement. It is also verified that the manipulator can withstand accidental impact, which illustrates the structure stability of the proposed design.",
        "primary_area": "",
        "author": "Zhangxing Liu;Hongzhe Jin;Hui Zhang;Yubin Liu;Yilin Long;Xiufang Liu;Jie Zhao;Zhangxing Liu;Hongzhe Jin;Hui Zhang;Yubin Liu;Yilin Long;Xiufang Liu;Jie Zhao",
        "authorids": "/37085778935;/37535059400;/37086337663;/37834545900;/37088997616;/37088999698;/37279457400;/37085778935;/37535059400;/37086337663;/37834545900;/37088997616;/37088999698;/37279457400",
        "aff": "School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China; School of Mechatronics Engineering, Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561932/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16662940265095443980&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "School of Mechatronics Engineering",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560832",
        "title": "A Variational Infinite Mixture for Probabilistic Inverse Dynamics Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Probabilistic regression techniques in control and robotics applications have to fulfill different criteria of data-driven adaptability, computational efficiency, scalability to high dimensions, and the capacity to deal with different modalities in the data. Classical regressors usually fulfill only a subset of these properties. In this work, we extend seminal work on Bayesian nonparametric mixtures and derive an efficient variational Bayes inference technique for infinite mixtures of probabilistic local polynomial models with well-calibrated certainty quantification. We highlight the model\u2019s power in combining data-driven complexity adaptation, fast prediction, and the ability to deal with discontinuous functions and heteroscedastic noise. We benchmark this technique on a range of large real-world inverse dynamics datasets, showing that the infinite mixture formulation is competitive with classical Local Learning methods and regularizes model complexity by adapting the number of components based on data and without relying on heuristics. Moreover, to showcase the practicality of the approach, we use the learned models for online inverse dynamics control of a Barrett-WAM manipulator, significantly improving the trajectory tracking performance.",
        "primary_area": "",
        "author": "Hany Abdulsamad;Peter Nickl;Pascal Klink;Jan Peters;Hany Abdulsamad;Peter Nickl;Pascal Klink;Jan Peters",
        "authorids": "/37085685682;/37088996429;/37089001124;/37533077600;/37085685682;/37088996429;/37089001124;/37533077600",
        "aff": "Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt; Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt; Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt; Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560832/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16445856064274080676&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Intelligent Autonomous Systems",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561911",
        "title": "A Versatile Vision-Pheromone-Communication Platform for Swarm Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes a versatile platform for swarm robotics research. It integrates multiple pheromone communication with a dynamic visual scene along with real time data transmission and localization of multiple-robots. The platform has been built for inquiries into social insect behavior and bio-robotics. By introducing a new research scheme to coordinate olfactory and visual cues, it not only complements current swarm robotics platforms which focus only on pheromone communications by adding visual interaction, but also may fill an important gap in closing the loop from bio-robotics to neuroscience. We have built a controllable dynamic visual environment based on our previously developed ColCOS\u03a6 (a multi-pheromones platform) by enclosing the arena with LED panels and interacting with the micro mobile robots with a visual sensor. In addition, a wireless communication system has been developed to allow transmission of real-time bi-directional data between multiple micro robot agents and a PC host. A case study combining concepts from the internet of vehicles (IoV) and insect-vision inspired model has been undertaken to verify the applicability of the presented platform, and to investigate how complex scenarios can be facilitated by making use of this platform.",
        "primary_area": "",
        "author": "Tian Liu;Xuelong Sun;Cheng Hu;Qinbing Fu;Shigang Yue;Tian Liu;Xuelong Sun;Cheng Hu;Qinbing Fu;Shigang Yue",
        "authorids": "/37086288032;/37087007876;/37085455691;/37085764413;/37333835800;/37086288032;/37087007876;/37085455691;/37085764413;/37333835800",
        "aff": "Computational Intelligence Laboratory/Lincoln Center for Autonomous Systems, School of Computer Science, University of Lincoln, United Kingdom; Computational Intelligence Laboratory/Lincoln Center for Autonomous Systems, School of Computer Science, University of Lincoln, United Kingdom; Computational Intelligence Laboratory/Lincoln Center for Autonomous Systems, School of Computer Science, University of Lincoln, United Kingdom; Machine Life and Intelligence Research Center, School of Mechanical and Electrical Engineering, Guangzhou University, Guangzhou, China; Computational Intelligence Laboratory/Lincoln Center for Autonomous Systems, School of Computer Science, University of Lincoln, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561911/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8879757606377273581&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Lincoln;Guangzhou University",
        "aff_unique_dep": "School of Computer Science;School of Mechanical and Electrical Engineering",
        "aff_unique_url": "https://www.lincoln.ac.uk;http://www.gzhu.edu.cn",
        "aff_unique_abbr": "UoL;GZU",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Lincoln;Guangzhou",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9562021",
        "title": "A Visibility Roadmap Sampling Approach for a Multi-Robot Visibility-Based Pursuit-Evasion Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "Given a two-dimensional polygonal space, the multi-robot visibility-based pursuit-evasion problem tasks several pursuer robots with the goal of establishing visibility with an arbitrarily fast evader. The best known complete algorithm for this problem takes time doubly exponential in the number of robots. However, sampling-based techniques have shown promise in generating feasible solutions in these scenarios. One of the primary drawbacks to employing existing sampling-based methods is that existing algorithms have long execution times and high failure rates for complex environments. This paper addresses that limitation by proposing a new algorithm that takes an environment as its input and returns a joint motion strategy which ensures that the evader is captured by one of the pursuers. Starting with a single pursuer, we sequentially construct Sample-Generated Pursuit-Evasion Graphs to create such a joint motion strategy. This sequential graph structure ensures that our algorithm will always terminate with a solution, regardless of the complexity of the environment. We describe an implementation of this algorithm and present quantitative results that show significant improvement in comparison to the existing algorithm.",
        "primary_area": "",
        "author": "Trevor Olsen;Anne M. Tumlin;Nicholas M. Stiffler;Jason M. O\u2019Kane;Trevor Olsen;Anne M. Tumlin;Nicholas M. Stiffler;Jason M. O\u2019Kane",
        "authorids": "/37089000508;/37088998140;/37947254000;/37279835400;/37089000508;/37088998140;/37947254000;/37279835400",
        "aff": "Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562021/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12486191033461781844&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of South Carolina",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.sc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Columbia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561775",
        "title": "A Wheeled V-shaped In-Pipe Robot with Clutched Underactuated Joints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a wheeled V-shaped in-pipe robot in which the two outputs of the wheel shaft and roll joint are driven solely by a single actuator input. This underactuation is generated by a simple miter gear mechanism. Generally, to control two movements easily, one of the outputs of the underactuated mechanism is constrained by the resilience force of springs or by the friction force. However, this complicates the control of each output. In this study, a one-way clutch is installed to completely constrain one of the outputs (wheel movement). By using this clutch, the proposed mechanism enables a hemispherical wheel to switch between pitch and roll rotations by selecting the drive direction of a single motor. The one-way clutch constrains the wheels to rotate in only one direction. To take advantage of this constraint, the robot changes its direction of movement between forward and backward by using the rolling movement of the robot. After describing the configuration of the proposed robot and a roll-angle model of the robot, experiments are conducted in straight pipes, bending pipes, and an out-of-plane double elbow.",
        "primary_area": "",
        "author": "Yoshimichi Oka;Atsushi Kakogawa;Shugen Ma;Yoshimichi Oka;Atsushi Kakogawa;Shugen Ma",
        "authorids": "/37086473322;/37846134700;/37280187400;/37086473322;/37846134700;/37280187400",
        "aff": "Department of Robotics, Ritsumeikan University, Shiga, Japan; Department of Robotics, Ritsumeikan University, Shiga, Japan; Department of Robotics, Ritsumeikan University, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561775/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2036646832008086365&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ritsumeikan University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.ritsumeikan.ac.jp",
        "aff_unique_abbr": "Ritsumeikan",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shiga",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561143",
        "title": "A data-set and a method for pointing direction estimation from depth images for human-robot interaction and VR applications",
        "track": "main",
        "status": "Poster",
        "abstract": "3D pointing devices are indispensable in virtual reality (hereafter VR) and human-robot interaction scenarios. Existing devices are cumbersome or non-immersive or have a limited volume of operation. Hand gesture-based interfaces do not suffer from these problems and can be used for 3D pointing purposes. However, there is a lack of robust, accurate hand gesture-based pointing techniques which can be attributed to the non-existence of large and accurate data-set for the same. To overcome this barrier, we propose a data-set consisting of depth images with a large number (107000) of samples collected from 11 subjects, with accurate ground-truth and adequate variation in the orientation and distance of the hand w.r.t. the camera. We propose a 3D convolutional neural network based technique that works on the proposed data-set and achieves an accuracy of 94.49% for an angle error threshold of 10 degrees. The proposed data-set may be used for developing more accurate, robust, less computationally expensive methods.",
        "primary_area": "",
        "author": "Shome S Das;Shome S Das",
        "authorids": "/37086511605;/37086511605",
        "aff": "Department of Electrical Engineering, Indian Institute of Science, Bangalore, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561143/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9922293976329296595&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Indian Institute of Science",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.iisc.ac.in",
        "aff_unique_abbr": "IISc",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Bangalore",
        "aff_country_unique_index": "0",
        "aff_country_unique": "India"
    },
    {
        "id": "9561300",
        "title": "A general elimination strategy for camera motion estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Camera motion estimation, such as relative pose estimation and absolute pose estimation, are fundamental problems in computer vision and robotics. To obtain the motion parameters, classical methods rely on studying the properties of the geometric matrices, e.g., rotation matrix, essential matrix, homography matrix. The well known five-point algorithm was successfully derived using the singular constraint and trace constraints on the essential matrix. However, finding all the algebraic constraints is not always trivial for some recent problems. In this paper, we propose a simple and general technique to find complete algebraic constraints so that we can derive efficient algorithms. We show that using the quaternion to formulate the rotation matrix we can eliminate any unknowns from the original equations and obtain constraints on the rest of the unknowns based on Gr\u00f6bner basis. We demonstrate that this approach can be applied to almost all the camera motion estimation and show its improvement compared to the existing methods. Further more, based on this elimination technique, we exploit new constraints for the relative pose estimation with gravity prior, and derive a new globally optimal algorithm to this problem. We compare our algorithm with the state-of-the-art methods on both synthetic and real-world data, and show the benefits including accuracy and efficiency.",
        "primary_area": "",
        "author": "Yaqing Ding;Yingna Su;Chengzhong Xu;Jian Yang;Hui Kong;Yaqing Ding;Yingna Su;Chengzhong Xu;Jian Yang;Hui Kong",
        "authorids": "/37088220065;/37086262686;/37278305300;/37280205100;/37061510500;/37088220065;/37086262686;/37278305300;/37280205100;/37061510500",
        "aff": "Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology; Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology; Faculty of Science and Technology, University of Macau, Macau SAR, China; Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology; Key Lab of Intelligent Perception and Systems for High-Dimensional Information of Ministry of Education, and Jiangsu Key Lab of Image and Video Understanding for Social Security, School of Computer Science and Engineering, Nanjing University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561300/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17914803071069114158&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Nanjing University of Science and Technology;University of Macau",
        "aff_unique_dep": "School of Computer Science and Engineering;Faculty of Science and Technology",
        "aff_unique_url": "http://www.nust.edu.cn;https://www.um.edu.mo",
        "aff_unique_abbr": "NJUST;UM",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Macau SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561869",
        "title": "A high-voltage power electronics unit for flying insect robots that can modulate wing thrust",
        "track": "main",
        "status": "Poster",
        "abstract": "Flapping-wing insect-scale robots (<500 mg) offer enormous potential advantages over larger robots in applications such as agricultural support, environmental monitoring, and exploration of hazardous locations or extra-terrestrial space. Scaling laws that confer advantages to smaller robots, such as reduced materials cost and lower power requirements, also pose miniaturization challenges. Here we address the challenge of supplying a high voltage, oscillating signal to piezoelectric actuators that can be modulated to vary wing thrust. We present a system capable of modulating thrust for the generation of forces and torques required for control of flapping-wing insect sized robots. The power electronics unit with boost converter and two drivers is 90 mg including optional 15 mg output storage capacitor (not including 8 mg MCU). The boost converter operates at 30\u201340% efficiency at 240 V output under driver load and supplied with 7 V, and the driver produces sinusoidal wing flapping signals at typical operating output voltages of 160\u2013220 Vpp with <14% total harmonic distortion. The system can linearly modulate measured thrust over 70% of the tested amplitude range from 40\u2013200 Vpp. The thrust modulation reported here is necessary to realize controlled flight using on-board power systems, instead of externally provided signals via a wire tether.",
        "primary_area": "",
        "author": "Johannes James;Sawyer Fuller;Johannes James;Sawyer Fuller",
        "authorids": "/37086453925;/37408404900;/37086453925;/37408404900",
        "aff": "Department of Mechanical Engineering, University of Washington, Seattle, WA, USA; Department of Mechanical Engineering, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561869/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9742612472875455641&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561800",
        "title": "A novel method for computing the 3D friction cone using complimentary constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling the Coulomb Friction Cone in trajectory optimization is typically done by linearizing it along a series of vectors. Often, these vectors define the edges of polyhedral estimations of the cone. This article provides an alternate approach that samples the cone along a vector that satisfies the Maximum Dissipation Principle, which is shown to be significantly more computationally tractable. The proposed technique uses the polar representation of the relative velocity of a contact point on a surface to determine the direction of the resultant friction force and linearizes the friction cone along this vector. This study describes the development of the proposed model. Thereafter, a trajectory optimization experiment was conducted to compare the traditional four-sided polyhedral estimation of the friction cone with the novel method. Compute time and computational complexity were used as performance metrics in this study. Results from these experiments indicate that the proposed method reduced the compute time by 39.13% and a 57.00% reduction in inequality constraints when compared to the 4-sided polyhedral estimation.",
        "primary_area": "",
        "author": "Dean Pretorius;Callen Fisher;Dean Pretorius;Callen Fisher",
        "authorids": "/37088997547;/37085623300;/37088997547;/37085623300",
        "aff": "Department of Electrical and Electronic Engineering, University of Stellenbosch, Stellenbosch, South Africa; Department of Electrical and Electronic Engineering, University of Stellenbosch, Stellenbosch, South Africa",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561800/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4216811896955233474&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Stellenbosch",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.sun.ac.za",
        "aff_unique_abbr": "SUN",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stellenbosch",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Africa"
    },
    {
        "id": "9560812",
        "title": "A portable acoustofluidic device for multifunctional cell manipulation and reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "Microbubble-induced acoustic microstreaming for efficient on-chip micromanipulation is widely developed in biological applications. However, it is still challenging to simultaneously transport, trap, and rotate single cells using one device in a biocompatible manner, while expensive and bulky traditional acoustic driving system also increases its limitation. This paper presents a portable acoustofluidic device for multifunctional cell manipulation and 3D reconstruction, using acoustically oscillating bottom bubble array. Based on the Arduino-based driving system, multiple bubble-induced microvortices were generated and utilized to achieve multifunctional manipulation in a noninvasive manner. Self-propelled transportation of single or multiple cells is first accomplished by bottom bubble array; Controllable trapping, 3D rotation (in the x-y or x-z plane) of DU145 cells are further performed by every single microbubble. Through experiments, rotation direction, speed and axis can be modulated by tuning the driving frequency and voltage. Finally, 3D cell reconstruction combining imaging processing algorithm with out-of-plane rotation enables a sufficient illustration of cell structures and surface morphology, providing an efficient properties measurement function. All these aspects of this device show great potentials in bioengineering, biophysics and biomedicine.",
        "primary_area": "",
        "author": "Wei Zhang;Bin Song;Xue Bai;Jingli Guo;Lin Feng;Fumihito Arai;Wei Zhang;Bin Song;Xue Bai;Jingli Guo;Lin Feng;Fumihito Arai",
        "authorids": "/37086933988;/37086935548;/37088554994;/37089001453;/37403324400;/37274069600;/37086933988;/37086935548;/37088554994;/37089001453;/37403324400;/37274069600",
        "aff": "School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; School of Mechanical Engineering & Automation, Beihang University, Beijing, China; Beijing Advanced Innovation Center for Biomedical Engineering and School of Mechanical Engineering & Automation, Beihang University, Beijing, China; Department of Mechanical Engineering, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560812/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10462761527743608608&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "Beihang University;University of Tokyo",
        "aff_unique_dep": "School of Mechanical Engineering & Automation;Department of Mechanical Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "Beihang;UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Beijing;Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9560844",
        "title": "ACRONYM: A Large-Scale Grasp Dataset Based on Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce ACRONYM, a dataset for robot grasp planning based on physics simulation. The dataset contains 17.7M parallel-jaw grasps, spanning 8872 objects from 262 different categories, each labeled with the grasp result obtained from a physics simulator. We show the value of this large and diverse dataset by using it to train two state-of-the-art learning-based grasp planning algorithms. Grasp performance improves significantly when compared to the original smaller dataset. Data and tools can be accessed at https://sites.google.com/nvidia.com/graspdataset.",
        "primary_area": "",
        "author": "Clemens Eppner;Arsalan Mousavian;Dieter Fox;Clemens Eppner;Arsalan Mousavian;Dieter Fox",
        "authorids": "/37571607800;/37085404794;/37284329000;/37571607800;/37085404794;/37284329000",
        "aff": "NVIDIA, USA; NVIDIA, USA; Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560844/",
        "gs_citation": 228,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8368781993671899436&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "NVIDIA;University of Washington",
        "aff_unique_dep": "NVIDIA;Paul G. Allen School of Computer Science & Engineering",
        "aff_unique_url": "https://www.nvidia.com;https://www.washington.edu",
        "aff_unique_abbr": "NV;UW",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Seattle",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561564",
        "title": "ADTrack: Target-Aware Dual Filter Learning for Real-Time Anti-Dark UAV Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Prior correlation filter (CF)-based tracking methods for unmanned aerial vehicles (UAVs) have virtually focused on tracking in the daytime. However, when the night falls, the trackers will encounter more harsh scenes, which can easily lead to tracking failure. In this regard, this work proposes a novel tracker with anti-dark function (ADTrack). The proposed method integrates an efficient and effective low-light image enhancer into a CF-based tracker. Besides, a target-aware mask is simultaneously generated by virtue of image illumination variation. The target-aware mask can be applied to jointly train a target-focused filter that assists the context filter for robust tracking. Specifically, ADTrack adopts dual regression, where the context filter and the target-focused filter restrict each other for dual filter learning. Exhaustive experiments are conducted on typical dark sceneries benchmark, consisting of 37 typical night sequences from authoritative benchmarks, i.e., UAVDark, and our newly constructed benchmark UAVDark70. The results have shown that ADTrack favorably outperforms other state-of-the-art trackers and achieves a real-time speed of 34 frames/s on a single CPU, greatly extending robust UAV tracking to night scenes.",
        "primary_area": "",
        "author": "Bowen Li;Changhong Fu;Fangqiang Ding;Junjie Ye;Fuling Lin;Bowen Li;Changhong Fu;Fangqiang Ding;Junjie Ye;Fuling Lin",
        "authorids": "/37089000657;/37086797986;/37088456219;/37088917418;/37088212953;/37089000657;/37086797986;/37088456219;/37088917418;/37088212953",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561564/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15799537201735864862&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tongji University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn",
        "aff_unique_abbr": "Tongji",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561438",
        "title": "ALTRO-C: A Fast Solver for Conic Model-Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Model-predictive control (MPC) is an increasingly popular method for controlling complex robotic systems in which optimal control problems are solved on board the robot at real-time rates. However, successful application of MPC depends critically on the performance of the algorithms used to solve the underlying optimization problems. An ideal solver should both leverage the structure of the MPC problem and support efficient \"warm starting\" so that information from previous solutions can be recycled to speed convergence. We present ALTRO-C, a high-performance solver with both of these properties that utilizes an augmented Lagrangian method to handle general convex conic constraints. We demonstrate the new solver\u2019s superior performance against several existing state-of-the-art solvers on a variety of benchmark control problems formulated as both quadratic and second-order cone programs.",
        "primary_area": "",
        "author": "Brian E. Jackson;Tarun Punnoose;Daniel Neamati;Kevin Tracy;Rianna Jitosho;Zachary Manchester;Brian E. Jackson;Tarun Punnoose;Daniel Neamati;Kevin Tracy;Rianna Jitosho;Zachary Manchester",
        "authorids": "/37087323361;/37088996023;/37088999751;/37086545632;/37086937312;/37086011525;/37087323361;/37088996023;/37088999751;/37086545632;/37086937312;/37086011525",
        "aff": "Robotics Institute Carnegie Mellon University, Pittsburgh, USA; Department of Electrical Engineering, Stanford University, Stanford, USA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, USA; Robotics Institute Carnegie Mellon University, Pittsburgh, USA; Department of Mechanical Engineering, Stanford University, Stanford, USA; Robotics Institute Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561438/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15163595936561750446&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Stanford University;California Institute of Technology",
        "aff_unique_dep": "Robotics Institute;Department of Electrical Engineering;Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.stanford.edu;https://www.caltech.edu",
        "aff_unique_abbr": "CMU;Stanford;Caltech",
        "aff_campus_unique_index": "0;1;2;0;1;0",
        "aff_campus_unique": "Pittsburgh;Stanford;Pasadena",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561604",
        "title": "AM-RRT*: Informed Sampling-based Planning with Assisting Metric",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a new algorithm that extends RRT* and RT-RRT* for online path planning in complex, dynamic environments. Sampling-based approaches often perform poorly in environments with narrow passages, a feature common to many indoor applications of mobile robots as well as computer games. Our method extends RRT-based sampling methods to enable the use of an assisting distance metric to improve performance in environments with obstacles. This assisting metric, which can be any metric that has better properties than the Euclidean metric when line of sight is blocked, is used in combination with the standard Euclidean metric in such a way that the algorithm can reap benefits from the assisting metric while maintaining the desirable properties of previous RRT variants - namely probabilistic completeness in tree coverage and asymptotic optimality in path length. We also introduce a new method of targeted rewiring, aimed at shortening search times and path lengths in tasks where the goal shifts repeatedly. We demonstrate that our method offers considerable improvements over existing multi-query planners such as RT-RRT* when using diffusion distance as an assisting metric: finding near-optimal paths with a decrease in search time of several orders of magnitude. Experimental results demonstrate our method offers a reduction of 99.5% in planning times and 9.8% in path lengths over RT-RRT* in a variety of environments.",
        "primary_area": "",
        "author": "Daniel Armstrong;Andr\u00e9 Jonasson;Daniel Armstrong;Andr\u00e9 Jonasson",
        "authorids": "/37088998783;/37088999244;/37088998783;/37088999244",
        "aff": "Department of Computer Science, University of Oxford, United Kingdom; Ocado Technology 10x, Hatfield, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561604/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Oxford;Ocado Technology",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.ox.ac.uk;https://technology.ocado.com",
        "aff_unique_abbr": "Oxford;",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Oxford;Hatfield",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561311",
        "title": "APPLI: Adaptive Planner Parameter Learning From Interventions",
        "track": "main",
        "status": "Poster",
        "abstract": "While classical autonomous navigation systems can typically move robots from one point to another safely and in a collision-free manner, these systems may fail or produce suboptimal behavior in certain scenarios. The current practice in such scenarios is to manually re-tune the system\u2019s parameters, e.g. max speed, sampling rate, inflation radius, to optimize performance. This practice requires expert knowledge and may jeopardize performance in the originally good scenarios. Meanwhile, it is relatively easy for a human to identify those failure or suboptimal cases and provide a teleoperated intervention to correct the failure or suboptimal behavior. In this work, we seek to learn from those human interventions to improve navigation performance. In particular, we propose Adaptive Planner Parameter Learning from Interventions (APPLI), in which multiple sets of navigation parameters are learned during training and applied based on a confidence measure to the underlying navigation system during deployment. In our physical experiments, the robot achieves better performance compared to the planner with static default parameters, and even dynamic parameters learned from a full human demonstration. We also show APPLI\u2019s generalizability in another unseen physical test course, and a suite of 300 simulated navigation environments.",
        "primary_area": "",
        "author": "Zizhao Wang;Xuesu Xiao;Bo Liu;Garrett Warnell;Peter Stone;Zizhao Wang;Xuesu Xiao;Bo Liu;Garrett Warnell;Peter Stone",
        "authorids": "/37088943546;/37086258082;/37088429909;/37079072000;/37269574900;/37088943546;/37086258082;/37088429909;/37079072000;/37269574900",
        "aff": "Department of Electrical and Computer Engineering, University of Texas at Austin, Austin, Texas; Department of Computer Science, University of Texas at Austin, Austin, Texas; Department of Computer Science, University of Texas at Austin, Austin, Texas; Computational and Information Sciences Directorate, Army Research Laboratory, Austin, Texas; Sony AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561311/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3683245331188004897&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "University of Texas at Austin;Army Research Laboratory;Sony",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Computational and Information Sciences Directorate;Sony AI",
        "aff_unique_url": "https://www.utexas.edu;https://www.arl.army.mil;https://www.sony.com",
        "aff_unique_abbr": "UT Austin;ARL;Sony AI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9561647",
        "title": "APPLR: Adaptive Planner Parameter Learning from Reinforcement",
        "track": "main",
        "status": "Poster",
        "abstract": "Classical navigation systems typically operate using a fixed set of hand-picked parameters (e.g. maximum speed, sampling rate, inflation radius, etc.) and require heavy expert re-tuning in order to work in new environments. To mitigate this requirement, it has been proposed to learn parameters for different contexts in a new environment using human demonstrations collected via teleoperation. However, learning from human demonstration limits deployment to the training environment, and limits overall performance to that of a potentially-suboptimal demonstrator. In this paper, we introduce APPLR, Adaptive Planner Parameter Learning from Reinforcement, which allows existing navigation systems to adapt to new scenarios by using a parameter selection scheme discovered via reinforcement learning (RL) in a wide variety of simulation environments. We evaluate APPLR on a robot in both simulated and physical experiments, and show that it can outperform both a fixed set of hand-tuned parameters and also a dynamic parameter tuning scheme learned from human demonstration.",
        "primary_area": "",
        "author": "Zifan Xu;Gauraang Dhamankar;Anirudh Nair;Xuesu Xiao;Garrett Warnell;Bo Liu;Zizhao Wang;Peter Stone;Zifan Xu;Gauraang Dhamankar;Anirudh Nair;Xuesu Xiao;Garrett Warnell;Bo Liu;Zizhao Wang;Peter Stone",
        "authorids": "/37089000983;/37088999999;/37088999799;/37086258082;/37079072000;/37088429909;/37088943546;/37269574900;/37089000983;/37088999999;/37088999799;/37086258082;/37079072000;/37088429909;/37088943546;/37269574900",
        "aff": "Department of Physics, University of Texas at Austin, Austin, Texas; Department of Computer Science, University of Texas at Austin, Austin, Texas; Mathematics, University of Texas at Austin, Austin, Texas; Department of Computer Science, University of Texas at Austin, Austin, Texas; Computational and Information Sciences Directorate, Army Research Laboratory, Austin, Texas; Department of Computer Science, University of Texas at Austin, Austin, Texas; Electrical and Computer Engineering, University of Texas at Austin, Austin, Texas; Sony AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561647/",
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11672220671482267509&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;0;0;2",
        "aff_unique_norm": "University of Texas at Austin;Army Research Laboratory;Sony",
        "aff_unique_dep": "Department of Physics;Computational and Information Sciences Directorate;Sony AI",
        "aff_unique_url": "https://www.utexas.edu;https://www.arl.army.mil;https://www.sony.com",
        "aff_unique_abbr": "UT Austin;ARL;Sony AI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;1",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9561844",
        "title": "ARC-LfD: Using Augmented Reality for Interactive Long-Term Robot Skill Maintenance via Constrained Learning from Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from Demonstration (LfD) enables novice users to teach robots new skills. However, many LfD methods do not facilitate skill maintenance and adaptation. Changes in task requirements or in the environment often reveal the lack of resiliency and adaptability in the skill model. To overcome these limitations, we introduce ARC-LfD: an Augmented Reality (AR) interface for constrained Learning from Demonstration that allows users to maintain, update, and adapt learned skills. This is accomplished through in-situ visualizations of learned skills and constraint-based editing of existing skills without requiring further demonstration. We describe the existing algorithmic basis for this system as well as our Augmented Reality interface and the novel capabilities it provides. Finally, we provide three case studies that demonstrate how ARC-LfD enables users to adapt to changes in the environment or task which require a skill to be altered after initial teaching has taken place.",
        "primary_area": "",
        "author": "Matthew B. Luebbers;Connor Brooks;Carl L. Mueller;Daniel Szafir;Bradley Hayes;Matthew B. Luebbers;Connor Brooks;Carl L. Mueller;Daniel Szafir;Bradley Hayes",
        "authorids": "/37088999556;/37086576242;/37086575970;/37086231248;/38573944100;/37088999556;/37086576242;/37086575970;/37086231248;/38573944100",
        "aff": "Computer Science Department, College of Engineering and Applied Science, University of Colorado Boulder, Boulder, Colorado, USA; Computer Science Department, College of Engineering and Applied Science, University of Colorado Boulder, Boulder, Colorado, USA; Computer Science Department, College of Engineering and Applied Science, University of Colorado Boulder, Boulder, Colorado, USA; ATLAS Institute, University of Colorado Boulder, Boulder, Colorado, USA; Computer Science Department, College of Engineering and Applied Science, University of Colorado Boulder, Boulder, Colorado, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561844/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16096894090563242631&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Colorado Boulder",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU Boulder",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561144",
        "title": "ARROCH: Augmented Reality for Robots Collaborating with a Human",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot collaboration frequently requires extensive communication, e.g., using natural language and gesture. Augmented reality (AR) has provided an alternative way of bridging the communication gap between robots and people. However, most current AR-based human-robot communication methods are unidirectional, focusing on how the human adapts to robot behaviors, and are limited to single-robot domains. In this paper, we develop AR for Robots Collaborating with a Human (ARROCH), a novel algorithm and system that supports bidirectional, multi-turn, human-multi-robot communication in indoor multi-room environments. The human can see through obstacles to observe the robots\u2019 current states and intentions, and provide feedback, while the robots\u2019 behaviors are then adjusted toward human-multi-robot teamwork. Experiments have been conducted with real robots and human participants using collaborative delivery tasks. Results show that ARROCH outperformed a standard non-AR approach in both user experience and teamwork efficiency. In addition, we have developed a novel simulation environment using Unity (for AR and human simulation) and Gazebo (for robot simulation). Results in simulation demonstrate ARROCH\u2019s superiority over AR-based baselines in human-robot collaboration.",
        "primary_area": "",
        "author": "Kishan Chandan;Vidisha Kudalkar;Xiang Li;Shiqi Zhang;Kishan Chandan;Vidisha Kudalkar;Xiang Li;Shiqi Zhang",
        "authorids": "/37088997296;/37088995883;/37088583870;/37086294744;/37088997296;/37088995883;/37088583870;/37086294744",
        "aff": "SUNY Binghamton; SUNY Binghamton; OPPO US Research Center; SUNY Binghamton",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561144/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9715898801017660729&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "State University of New York at Binghamton;OPPO",
        "aff_unique_dep": ";US Research Center",
        "aff_unique_url": "https://www.binghamton.edu;https://www.oppo.com",
        "aff_unique_abbr": "SUNY Binghamton;OPPO",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Binghamton;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561815",
        "title": "ASVLite: a high-performance simulator for autonomous surface vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "The energy of ocean waves is the key distinguishing factor of marine environments compared to other aquatic environments such as lakes and rivers. Waves significantly affect the dynamics of marine vehicles; hence it is imperative to consider the dynamics of vehicles in waves when developing efficient control strategies for autonomous surface vehicles (ASVs). However, most marine simulators available open-source either exclude dynamics of vehicles in waves or use methods with high computational overhead. This paper presents ASVLite, a computationally efficient ASV simulator that uses frequency domain analysis for wave force computation. ASVLite is suitable for applications requiring low computational overhead and high run-time performance. Our tests on a Raspberry Pi 2 and a mid-range desktop computer show that the simulator has a high run-time performance to efficiently simulate irregular waves with a component wave count of up to 260 and large-scale swarms of up to 500 ASVs.",
        "primary_area": "",
        "author": "Toby Thomas;David M. Bossens;Danesh Tarapore;Toby Thomas;David M. Bossens;Danesh Tarapore",
        "authorids": "/37089001084;/37088822733;/37086275308;/37089001084;/37088822733;/37086275308",
        "aff": "School of Electronics and Computer Science, University of Southampton, Southampton, U.K.; School of Electronics and Computer Science, University of Southampton, Southampton, U.K.; School of Electronics and Computer Science, University of Southampton, Southampton, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561815/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17272584544517266067&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Southampton",
        "aff_unique_dep": "School of Electronics and Computer Science",
        "aff_unique_url": "https://www.southampton.ac.uk",
        "aff_unique_abbr": "Southampton",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Southampton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561252",
        "title": "AU-Expression Knowledge Constrained Representation Learning for Facial Expression Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Recognizing human emotion/expressions automatically is quite an expected ability for intelligent robotics, as it can promote better communication and cooperation with humans. Current deep-learning-based algorithms may achieve impressive performance in some lab-controlled environments, but they always fail to recognize the expressions accurately for the uncontrolled in-the-wild situation. Fortunately, facial action units (AU) describe subtle facial behaviors, and they can help distinguish uncertain and ambiguous expressions. In this work, we explore the correlations among the action units and facial expressions, and devise an AU-Expression Knowledge Constrained Representation Learning (AUE-CRL) framework to learn the AU representations without AU annotations and adaptively use representations to facilitate facial expression recognition. Specifically, it leverages AU-expression correlations to guide the learning of the AU classifiers, and thus it can obtain AU representations without incurring any AU annotations. Then, it introduces a knowledge-guided attention mechanism that mines useful AU representations under the constraint of AU-expression correlations. In this way, the framework can capture local discriminative and complementary features to enhance facial representation for facial expression recognition. We conduct experiments on the challenging uncontrolled datasets to demonstrate the superiority of the proposed framework over current state-of-the-art methods. Codes and trained models are available at https://github.com/HCPLab-SYSU/AUE-CRL.",
        "primary_area": "",
        "author": "Tao Pu;Tianshui Chen;Yuan Xie;Hefeng Wu;Liang Lin;Tao Pu;Tianshui Chen;Yuan Xie;Hefeng Wu;Liang Lin",
        "authorids": "/37089002130;/37085782949;/37086257390;/37898860700;/37406180600;/37089002130;/37085782949;/37086257390;/37898860700;/37406180600",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; DarkMatter AI Research, Guangzhou, China; DarkMatter AI Research, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561252/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5012870908631270444&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Sun Yat-sen University;DarkMatter AI Research",
        "aff_unique_dep": "School of Computer Science and Engineering;",
        "aff_unique_url": "http://www.sysu.edu.cn;",
        "aff_unique_abbr": "SYSU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560908",
        "title": "AVGCN: Trajectory Prediction using Graph Convolutional Networks Guided by Human Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "Pedestrian trajectory prediction is a critical yet challenging task especially for crowded scenes. We suggest that introducing an attention mechanism to infer the importance of different neighbors is critical for accurate trajectory prediction in scenes with varying crowd size. In this work, we propose a novel method, AVGCN, for trajectory prediction utilizing graph convolutional networks (GCN) based on human attention (A denotes attention, V denotes visual field constraints). First, we train an attention network that estimates the importance of neighboring pedestrians, using gaze data collected as subjects perform a bird\u2019s eye view crowd navigation task. Then, we incorporate the learned attention weights modulated by constraints on the pedestrian\u2019s visual field into a trajectory prediction network that uses a GCN to aggregate information from neighbors efficiently. AVGCN also considers the stochastic nature of pedestrian trajectories by taking advantage of variational trajectory prediction. Our approach achieves state-of-the-art performance on several trajectory prediction benchmarks, and the lowest average prediction error over all considered benchmarks.",
        "primary_area": "",
        "author": "Congcong Liu;Yuying Chen;Ming Liu;Bertram E. Shi;Congcong Liu;Yuying Chen;Ming Liu;Bertram E. Shi",
        "authorids": "/37086126145;/37086602838;/37085398677;/37275989700;/37086126145;/37086602838;/37085398677;/37275989700",
        "aff": "JD.COM; Department of Electronic and Computer Engineering, the Hong Kong University of Science and Technology; Department of Electronic and Computer Engineering, the Hong Kong University of Science and Technology; Department of Electronic and Computer Engineering, the Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560908/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=295725247232277985&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "JD.com;Hong Kong University of Science and Technology",
        "aff_unique_dep": ";Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.jd.com;https://www.ust.hk",
        "aff_unique_abbr": "JD;HKUST",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561823",
        "title": "AXLE: Computationally-efficient trajectory smoothing using factor graph chains",
        "track": "main",
        "status": "Poster",
        "abstract": "Factor graph chains\u2013 the special case of a factor graph in which there are no potentials connecting non-adjacent nodes\u2013 arise naturally in many robotics problems. Importantly, they are often part of an inner loop in trajectory optimization and estimation problems, and so applications can be very sensitive to the performance of a solver.Of course, it is well-known that factor graph chains have an O(N) solution, but an actual solution is often left as \"an exercise to the reader\"\u2026 with the inevitable consequence that few (if any) efficient solutions are readily available.In this paper, we carefully derive the solution while keeping track of the specific block structure that arises, we work through a number of practical implementation challenges, and we highlight additional optimizations that are not at first apparent. An easy-to-use and self-contained solver is provided in C, which outperforms the AprilSAM general-purpose sparse matrix factorization library by a factor of 7.3x even without specialized block operations.The name AXLE reflects the names of the key matrices involved (the approach here solves the linear problem AX = E by factoring A as LLT), while also reflecting its key application in kino-dynamic trajectory estimation of vehicles with axles.",
        "primary_area": "",
        "author": "Edwin Olson;Edwin Olson",
        "authorids": "/37413277900;/37413277900",
        "aff": "University of Michigan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561823/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:6ueFEuUiTuMJ:scholar.google.com/&scioq=AXLE:+Computationally-efficient+trajectory+smoothing+using+factor+graph+chains&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561068",
        "title": "Accelerating Probabilistic Volumetric Mapping using Ray-Tracing Graphics Hardware",
        "track": "main",
        "status": "Poster",
        "abstract": "Probabilistic volumetric mapping (PVM) represents a 3D environmental map for an autonomous robotic navigational task. A popular implementation such as Octomap is widely used in the robotics community for such a purpose. The Octomap relies on an octree to represent a PVM and its main bottleneck lies in massive ray-shooting to determine the occupancy of the underlying volumetric voxel grids.In this paper, we propose GPU-based ray shooting to drastically improve the ray shooting performance in Octomap. Our main idea is based on the use of recent ray-tracing RTX GPU, mainly designed for real-time photo-realistic computer graphics and the accompanying graphics API, known as DXR. Our ray-shooting first maps leaf-level voxels in the given octree to a set of axis-aligned bounding boxes (AABBs) and employ massively parallel ray shooting on them using GPUs to find free and occupied voxels. These are fed back into the CPU to update the voxel occupancy and restructure the octree. In our experiments, we have observed more than three-orders-of-magnitude performance improvement in terms of ray shooting using ray-tracing RTX GPU over a state-of-the-art Octomap CPU implementation, where the benchmarking environments consist of more than 77K points and 25K~34K voxel grids.",
        "primary_area": "",
        "author": "Heajung Min;Kyung Min Han;Young J. Kim;Heajung Min;Kyung Min Han;Young J. Kim",
        "authorids": "/37088997066;/37088507416;/38185529300;/37088997066;/37088507416;/38185529300",
        "aff": "Department of Computer Science and Engineering, Ewha Womans University, Korea; Department of Computer Science and Engineering, Ewha Womans University, Korea; Department of Computer Science and Engineering, Ewha Womans University, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561068/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13424735917961553425&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ewha Womans University",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "http://www.ewha.ac.kr",
        "aff_unique_abbr": "Ewha",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9562036",
        "title": "Accelerating combinatorial filter reduction through constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Reduction of combinatorial filters involves compressing state representations that robots use. Such optimization arises in automating the construction of minimalist robots. But exact combinatorial filter reduction is an NP-complete problem and all current techniques are either inexact or formalized with exponentially many constraints. This paper proposes a new formalization needing only a polynomial number of constraints, and characterizes these constraints in three different forms: nonlinear, linear, and conjunctive normal form. Empirical results show that constraints in conjunctive normal form capture the problem most effectively, leading to a method that outperforms the others. Further examination indicates that a substantial proportion of constraints remain inactive during iterative filter reduction. To leverage this observation, we introduce just-in-time generation of such constraints, which yields improvements in efficiency and has the potential to minimize large filters.",
        "primary_area": "",
        "author": "Yulin Zhang;Hazhar Rahmani;Dylan A. Shell;Jason M. O\u2019Kane;Yulin Zhang;Hazhar Rahmani;Dylan A. Shell;Jason M. O\u2019Kane",
        "authorids": "/37089453389;/37086453006;/37269198900;/37279835400;/37089453389;/37086453006;/37269198900;/37279835400",
        "aff": "Dept. of Computer Science and Engineering, Texas A&M University, College Station, TX, USA; Dept. of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA; Dept. of Computer Science and Engineering, Texas A&M University, College Station, TX, USA; Dept. of Computer Science and Engineering, University of South Carolina, Columbia, SC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562036/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2765429625001867006&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Texas A&M University;University of South Carolina",
        "aff_unique_dep": "Department of Computer Science and Engineering;Dept. of Computer Science and Engineering",
        "aff_unique_url": "https://www.tamu.edu;https://www.sc.edu",
        "aff_unique_abbr": "TAMU;USC",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "College Station;Columbia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561215",
        "title": "Accurate and Robust Scale Recovery for Monocular Visual Odometry Based on Plane Geometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Scale ambiguity is a fundamental problem in monocular visual odometry. Typical solutions include loop closure detection and environment information mining. For applications like self-driving cars, loop closure is not always available, hence mining prior knowledge from the environment becomes a more promising approach. In this paper, with the assumption of a constant height of the camera above the ground, we develop a light-weight scale recovery framework leveraging an accurate and robust estimation of the ground plane. The framework includes a ground point extraction algorithm for selecting high-quality points on the ground plane, and a ground point aggregation algorithm for joining the extracted ground points in a local sliding window. Based on the aggregated data, the scale is finally recovered by solving a least-squares problem using a RANSAC-based optimizer. Sufficient data and robust optimizer enable a highly accurate scale recovery. Experiments on the KITTI dataset show that the proposed framework can achieve state-of-the-art accuracy in terms of translation errors, while maintaining competitive performance on the rotation error. Due to the light-weight design, our framework also demonstrates a high frequency of 20 Hz on the dataset.",
        "primary_area": "",
        "author": "Rui Tian;Yunzhou Zhang;Delong Zhu;Shiwen Liang;Sonya Coleman;Dermot Kerr;Rui Tian;Yunzhou Zhang;Delong Zhu;Shiwen Liang;Sonya Coleman;Dermot Kerr",
        "authorids": "/37086594833;/37310459100;/37086137408;/37088996631;/37269140600;/37295244700;/37086594833;/37310459100;/37086137408;/37088996631;/37269140600;/37295244700",
        "aff": "College of Information Science and Engineering, Northeastern University, Shenyang, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Shatin, N.T., Hong Kong SAR, China; College of Information Science and Engineering, Northeastern University, Shenyang, China; School of Computing and Intelligent Systems, Ulster University, N. Ireland, UK; School of Computing and Intelligent Systems, Ulster University, N. Ireland, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561215/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5063534806532964714&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;2;2",
        "aff_unique_norm": "Northeastern University;Chinese University of Hong Kong;Ulster University",
        "aff_unique_dep": "College of Information Science and Engineering;Department of Electronic Engineering;School of Computing and Intelligent Systems",
        "aff_unique_url": "http://www.neu.edu.cn/;https://www.cuhk.edu.hk;https://www.ulster.ac.uk",
        "aff_unique_abbr": "NEU;CUHK;Ulster",
        "aff_campus_unique_index": "0;0;1;0;2;2",
        "aff_campus_unique": "Shenyang;Shatin;N. Ireland",
        "aff_country_unique_index": "0;0;0;0;1;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9561074",
        "title": "Accurate and Robust Stereo Direct Visual Odometry for Agricultural Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision-based localization and mapping in the agricultural environment is challenging due to the unstructured scene with unstable features, illumination variations, bumpy roads, and dynamic environmental objects. To address these challenges, we propose an accurate and robust stereo direct visual odometry system with modifications on Stereo-DSO. We firstly select some well-matched static stereo points in the latest keyframe to improve the accuracy of inverse depth calculation for tracking. The inverse depth can further distinguish close objects from background, which will avoid large and far-away scene objects in keyframe determination. To boost efficiency and accuracy at the tracking stage, we propose a point selection method to sample map points and remove outliers. Furthermore, altitude smoothness verification with a local flat ground assumption and recovery method for tracking failure on bumpy roads are proposed to improve the system\u2019s robustness. Finally, a far-away keyframe is reserved in the sliding window to alleviate the orientation drift since the agricultural robots usually move straightly following the crop row. Our system achieved new state-of-the-art results on Flourish dataset and the recently released Rosario dataset.",
        "primary_area": "",
        "author": "Tao Yu;Junwei Zhou;Liangliang Wang;Shengwu Xiong;Tao Yu;Junwei Zhou;Liangliang Wang;Shengwu Xiong",
        "authorids": "/37088998807;/37089399974;/37089001550;/37090018117;/37088998807;/37089399974;/37089001550;/37090018117",
        "aff": "Sanya Science and Education Innovation Park of Wuhan University of Technology, Sanya; School of Computer, Wuhan University of Technology, Wuhan; School of Computer, Wuhan University of Technology, Wuhan; Sanya Science and Education Innovation Park of Wuhan University of Technology, Sanya",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561074/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14246127997372582417&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Wuhan University of Technology",
        "aff_unique_dep": "Science and Education Innovation Park",
        "aff_unique_url": "http://www.wut.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Sanya;Wuhan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561390",
        "title": "Achieving Hard Real-Time Capability for 3D Human Pose Estimation Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In the industrial domain, the application of any system as a safety function has to follow strict rules and requirements, defined in safety standards such as ISO 13849 [1] and ISO 13855 [2]. Two core requirements are an extremely low rate of dangerous errors and an upper limit for the response time of the system (hard real-time requirement). Current approaches in the field of human pose estimation achieve neither of both.In our work we approach the second requirement by introducing a general procedure to achieve hard real-time capability for interchangeable 3D human pose estimation systems. We use the detections of the pose estimation to model the human as 3D volume consisting of spheres and spherical cones. To bridge the time between arriving detections, the volume is adjusted in a way that ensures coherence, continuity and, most important, conformance with necessary surcharges from safety standard ISO 13855 [2]. Low and fixed computational cost for the adaption makes the procedure real-time capable. Our modelling approach using spheres and spherical cones also allows distance calculations at low and fixed computational costs, e.g. between human and robot. We show the benefit of our approach via human-robot distance calculation experiments, outperforming a safety-certified laser scanner for most of the time.",
        "primary_area": "",
        "author": "Patrick Schlosser;Christoph Ledermann;Patrick Schlosser;Christoph Ledermann",
        "authorids": "/37088366421;/38468554800;/37088366421;/38468554800",
        "aff": "Intelligent Process Automation and Robotics Lab, Institute of Anthropomatics and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Intelligent Process Automation and Robotics Lab, Institute of Anthropomatics and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561390/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11392742704433688404&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute of Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561474",
        "title": "Achieving Multitasking Robots in Multi-Robot Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "One simplifying assumption made in the existing and well-performing multi-robot systems is that the robots are single-tasking: each robot operates on a single task at any time. While this assumption is innocent to make in situations with sufficient resources such that robots can work independently, it becomes a restriction when they must share capabilities. In this paper, we consider multitasking robots with multi-robot tasks. Given a set of tasks, each achievable by a coalition of robots, our approach allows the coalitions to overlap by exploiting task synergies based on the physical constraints required to maintain these coalitions. The key contribution is a general and flexible framework that extends the current multi-robot systems to enable multitasking. The proposed approach is inspired by the information invariant theory, which orients around the equivalence of different information requirements. We map physical constraints to information requirements in our work, thereby allowing task synergies to be identified by reasoning about the relationships between such requirements. We show that our algorithm is sound and complete. Simulation results show its effectiveness under resource-constrained situations and in handling challenging scenarios in a realistic UAV simulator.",
        "primary_area": "",
        "author": "Winston Smith;Yu Zhang;Winston Smith;Yu Zhang",
        "authorids": "/37087238182;/37086071738;/37087238182;/37086071738",
        "aff": "School of Computing, Informatics and Decision Systems Engineering, Arizona State University; School of Computing, Informatics and Decision Systems Engineering, Arizona State University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561474/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8282107887701428601&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School of Computing, Informatics and Decision Systems Engineering",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561338",
        "title": "AcinoSet: A 3D Pose Estimation Dataset and Baseline Models for Cheetahs in the Wild",
        "track": "main",
        "status": "Poster",
        "abstract": "Animals are capable of extreme agility, yet understanding their complex dynamics, which have ecological, biomechanical and evolutionary implications, remains challenging. Being able to study this incredible agility will be critical for the development of next-generation autonomous legged robots. In particular, the cheetah (acinonyx jubatus) is supremely fast and maneuverable, yet quantifying its wholebody 3D kinematic data during locomotion in the wild remains a challenge, even with new deep learning-based methods. In this work we present an extensive dataset of free-running cheetahs in the wild, called AcinoSet, that contains 119, 490 frames of multi-view synchronized high-speed video footage, camera calibration files and 7, 588 human-annotated frames. We utilize markerless animal pose estimation to provide 2D keypoints. Then, we use three methods that serve as strong baselines for 3D pose estimation tool development: traditional sparse bundle adjustment, an Extended Kalman Filter, and a trajectory optimization-based method we call Full Trajectory Estimation. The resulting 3D trajectories, human-checked 3D ground truth, and an interactive tool to inspect the data is also provided. We believe this dataset will be useful for a diverse range of fields such as ecology, neuroscience, robotics, biomechanics as well as computer vision. Code and data can be found at: https://github.com/African-Robotics-Unit/AcinoSet.",
        "primary_area": "",
        "author": "Daniel Joska;Liam Clark;Naoya Muramatsu;Ricardo Jericevich;Fred Nicolls;Alexander Mathis;Mackenzie W. Mathis;Amir Patel;Daniel Joska;Liam Clark;Naoya Muramatsu;Ricardo Jericevich;Fred Nicolls;Alexander Mathis;Mackenzie W. Mathis;Amir Patel",
        "authorids": "/37089000631;/37088997488;/37088996058;/37088995932;/38667731900;/37088887382;/37088886847;/38029333400;/37089000631;/37088997488;/37088996058;/37088995932;/38667731900;/37088887382;/37088886847;/38029333400",
        "aff": "African Robotics Unit (ARU), University of Cape Town, South Africa; African Robotics Unit (ARU), University of Cape Town, South Africa; University of Tsukuba, Japan; African Robotics Unit (ARU), University of Cape Town, South Africa; African Robotics Unit (ARU), University of Cape Town, South Africa; \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne, Switzerland; African Robotics Unit (ARU), University of Cape Town, South Africa",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561338/",
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6476588664791852629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;0;0;2;2;0",
        "aff_unique_norm": "University of Cape Town;University of Tsukuba;EPFL",
        "aff_unique_dep": "African Robotics Unit (ARU);;",
        "aff_unique_url": "https://www.ru.ac.za;https://www.tsukuba.ac.jp;https://www.epfl.ch",
        "aff_unique_abbr": "UCT;UT;EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0;2;2;0",
        "aff_country_unique": "South Africa;Japan;Switzerland"
    },
    {
        "id": "9561183",
        "title": "Acoustic Communication and Sensing for Inflatable Modular Soft Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Modular soft robots combine the strengths of two traditionally separate areas of robotics. As modular robots, they can show robustness to individual failure and reconfigurability; as soft robots, they can deform and undergo large shape changes in order to adapt to their environment, and have inherent human safety. However, for sensing and communication these robots also combine the challenges of both: they require solutions that are scalable (low cost and complexity) and efficient (low power) to enable collectives of large numbers of robots, and these solutions must also be able to interface with the high extension ratio elastic bodies of soft robots. In this work, we seek to address these challenges using acoustic signals produced by piezoelectric surface transducers that are cheap, simple, and low power, and that not only integrate with but also leverage the elastic robot skins for signal transmission. Importantly, to further increase scalability, the transducers exhibit multi-functionality made possible by a relatively flat frequency response across the audible and ultrasonic ranges. With minimal hardware, they enable directional contact-based communication, audible-range communication at a distance, and exteroceptive sensing. We demonstrate a subset of the decentralized collective behaviors that these functions make possible with multi-robot hardware implementations. The use of acoustic waves in this domain is shown to provide distinct advantages over existing solutions.",
        "primary_area": "",
        "author": "Daniel S. Drew;Matthew Devlin;Elliot Hawkes;Sean Follmer;Daniel S. Drew;Matthew Devlin;Elliot Hawkes;Sean Follmer",
        "authorids": "/37086008697;/37088687226;/37681388800;/37085667725;/37086008697;/37088687226;/37681388800;/37085667725",
        "aff": "The Department of Mechanical Engineering, Stanford University, CA, USA; Department of Mechanical Engineering, University of California Santa Barbara, CA, USA; Department of Mechanical Engineering, University of California Santa Barbara, CA, USA; The Department of Mechanical Engineering, Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561183/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13815279700141050176&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Stanford University;University of California Santa Barbara",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu;https://www.ucsb.edu",
        "aff_unique_abbr": "Stanford;UCSB",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Stanford;Santa Barbara",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561711",
        "title": "Active Bayesian Multi-class Mapping from Range and Semantic Segmentation Observations",
        "track": "main",
        "status": "Poster",
        "abstract": "Many robot applications call for autonomous exploration and mapping of unknown and unstructured environments. Information-based exploration techniques, such as Cauchy-Schwarz quadratic mutual information (CSQMI) and fast Shannon mutual information (FSMI), have successfully achieved active binary occupancy mapping with range measurements. However, as we envision robots performing complex tasks specified with semantically meaningful objects, it is necessary to capture semantic categories in the measurements, map representation, and exploration objective. This work develops a Bayesian multi-class mapping algorithm utilizing range-category measurements. We derive a closed-form efficiently computable lower bound for the Shannon mutual information between the multi-class map and the measurements. The bound allows rapid evaluation of many potential robot trajectories for autonomous exploration and mapping. We compare our method against frontier-based and FSMI exploration and apply it in a 3-D photo-realistic simulation environment.",
        "primary_area": "",
        "author": "Arash Asgharivaskasi;Nikolay Atanasov;Arash Asgharivaskasi;Nikolay Atanasov",
        "authorids": "/37088997086;/37670511000;/37088997086;/37670511000",
        "aff": "Department of Electrical and Computer Engineering, University of California, San Diego, CA, USA; Department of Electrical and Computer Engineering, University of California, San Diego, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561711/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1081429678954022020&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562009",
        "title": "Active Inference for Integrated State-Estimation, Control, and Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents an approach for control, state-estimation and learning model (hyper)parameters for robotic manipulators. It is based on the active inference framework, prominent in computational neuroscience as a theory of the brain, where behaviour arises from minimizing variational free-energy. First, we show there is a direct relationship between active inference controllers, and classic methods such as PID control. We demonstrate its application for adaptive and robust behaviour of a robotic manipulator that rivals state-of-the-art. Additionally, we show that by learning specific hyperparameters, our approach can deal with unmodeled dynamics, damps oscillations, and is robust against poor initial parameters. The approach is validated on the \u2018Franka Emika Panda\u2019 7 DoF manipulator. Finally, we highlight limitations of active inference controllers for robotic systems.",
        "primary_area": "",
        "author": "Mohamed Baioumy;Paul Duckworth;Bruno Lacerda;Nick Hawes;Mohamed Baioumy;Paul Duckworth;Bruno Lacerda;Nick Hawes",
        "authorids": "/37086937698;/37087188849;/38230417200;/37590842900;/37086937698;/37087188849;/38230417200;/37590842900",
        "aff": "Oxford Robotics Institute, University of Oxford, United Kingdom; Oxford Robotics Institute, University of Oxford, United Kingdom; Oxford Robotics Institute, University of Oxford, United Kingdom; Oxford Robotics Institute, University of Oxford, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562009/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8539928850693005049&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561479",
        "title": "Active Information Acquisition under Arbitrary Unknown Disturbances",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory optimization of sensing robots to actively gather information of targets has received much attention in the past. It is well-known that under the assumption of linear Gaussian target dynamics and sensor models the stochastic Active Information Acquisition problem is equivalent to a deterministic optimal control problem. However, the above-mentioned assumptions regarding the target dynamic model are limiting. In real-world scenarios, the target may be subject to disturbances whose models or statistical properties are hard or impossible to obtain. Typical scenarios include abrupt maneuvers, jumping disturbances due to interactions with the environment, anomalous misbehaviors due to system faults/attacks, etc. Motivated by the above considerations, in this paper we consider targets whose dynamic models are subject to arbitrary unknown inputs whose models or statistical properties are not assumed to be available. In particular, with the aid of an unknown input decoupled filter, we formulate the sensor trajectory planning problem to track evolution of the target state and analyse the resulting performance for both the state and unknown input evolution tracking. Inspired by concepts of Reduced Value Iteration, a suboptimal solution that expands a search tree via Forward Value Iteration with informativeness-based pruning is proposed. Concrete suboptimality performance guarantees for tracking both the state and the unknown input are established. Numerical simulations of a target tracking example are presented to compare the proposed solution with a greedy policy.",
        "primary_area": "",
        "author": "Jennifer Wakulicz;He Kong;Salah Sukkarieh;Jennifer Wakulicz;He Kong;Salah Sukkarieh",
        "authorids": "/37088996209;/37086935024;/37284368200;/37088996209;/37086935024;/37284368200",
        "aff": "Australian Centre for Field Robotics, The University of Sydney, NSW, Australia; Australian Centre for Field Robotics, The University of Sydney, NSW, Australia; Australian Centre for Field Robotics, The University of Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561479/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12757262093953050053&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Sydney",
        "aff_unique_dep": "Australian Centre for Field Robotics",
        "aff_unique_url": "https://www.sydney.edu.au",
        "aff_unique_abbr": "USYD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9560869",
        "title": "Active Model Learning using Informative Trajectories for Improved Closed-Loop Control on Real Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Model-based controllers on real robots require accurate knowledge of the system dynamics to perform optimally. For complex dynamics, first-principles modeling is not sufficiently precise, and data-driven approaches can be leveraged to learn a statistical model from real experiments. However, the efficient and effective data collection for such a data-driven system on real robots is still an open challenge. This paper introduces an optimization problem formulation to find an informative trajectory that allows for efficient data collection and model learning. We present a sampling-based method that computes an approximation of the trajectory that minimizes the prediction uncertainty of the dynamics model. This trajectory is then executed, collecting the data to update the learned model. We experimentally demonstrate the capabilities of our proposed framework when applied to a complex omnidirectional flying vehicle with tiltable rotors. Using our informative trajectories results in models which outperform models obtained from non-informative trajectory by 13.3% with the same amount of training data. Furthermore, we show that the model learned from informative trajectories generalizes better than the one learned from non-informative trajectories, achieving better tracking performance on different tasks.",
        "primary_area": "",
        "author": "Weixuan Zhang;Marco Tognon;Lionel Ott;Roland Siegwart;Juan Nieto;Weixuan Zhang;Marco Tognon;Lionel Ott;Roland Siegwart;Juan Nieto",
        "authorids": "/37088443145;/37085377048;/38251784400;/37281398300;/37085778635;/37088443145;/37085377048;/38251784400;/37281398300;/37085778635",
        "aff": "Autonomous Systems Lab, ETH Z\u00fcrich, Zurich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Zurich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Zurich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Zurich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560869/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=455615029997140709&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561111",
        "title": "Active Modular Environment for Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel robot-environment interaction in navigation tasks such that robots have neither a representation of their working space nor planning function, instead, an active environment takes charge of these aspects. This is realized by spatially deploying computing units, called cells, and making cells manage traffic in their respective physical region. Different from stigmegic approaches, cells interact with each other to manage environmental information and to construct instructions on how robots move.As a proof-of-concept, we present an architecture called AFADA and its prototype, consisting of modular cells and robots moving on the cells. The instructions from cells are based on a distributed routing algorithm and a reservation protocol. We demonstrate that AFADA enables a robot to move efficiently in a dynamic environment that stochastic changes its topology, comparing to self-navigation by a robot itself. This is followed by several demos, including multi-robot navigation, highlighting the power of offloading both representation and planning from robots to the environment. We expect that the concept of AFADA contributes to developing the infrastructure for multiple robots because it can engage online and lifelong planning and execution.",
        "primary_area": "",
        "author": "Shota Kameyama;Keisuke Okumura;Yasumasa Tamura;Xavier D\u00e9fago;Shota Kameyama;Keisuke Okumura;Yasumasa Tamura;Xavier D\u00e9fago",
        "authorids": "/37089000700;/37086500021;/37087281003;/37265172200;/37089000700;/37086500021;/37087281003;/37265172200",
        "aff": "School of Computing, Tokyo Institute of Technology, Japan; School of Computing, Tokyo Institute of Technology, Japan; School of Computing, Tokyo Institute of Technology, Japan; School of Computing, Tokyo Institute of Technology, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561111/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17505088594120878123&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.titech.ac.jp",
        "aff_unique_abbr": "Titech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561361",
        "title": "Active Telepresence Assistance for Supervisory Control: A User Study with a Multi-Camera Tele-Nursing Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Supervisory control of a humanoid robot in a manipulation task requires coordination of remote perception with robot action, which becomes more demanding with multiple moving cameras available for task supervision. We explore the use of autonomous camera control and selection to reduce operator workload and improve task performance in a supervisory control task. We design a novel approach to autonomous camera selection and control, and evaluate the approach in a user study which revealed that autonomous camera control does improve task performance and operator experience, but autonomous camera selection requires further investigation to benefit the operator\u2019s confidence and maintain trust in the robot autonomy.",
        "primary_area": "",
        "author": "Alexandra Valiton;Hannah Baez;Naomi Harrison;Justine Roy;Zhi Li;Alexandra Valiton;Hannah Baez;Naomi Harrison;Justine Roy;Zhi Li",
        "authorids": "/37088504878;/37089000997;/37088996358;/37089000597;/37085821311;/37088504878;/37089000997;/37088996358;/37089000597;/37085821311",
        "aff": "Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561361/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9702735499328134739&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Robotics Engineering Program",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560833",
        "title": "AdaGrasp: Learning an Adaptive Gripper-Aware Grasping Policy",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper aims to improve robots\u2019 versatility and adaptability by allowing them to use a large variety of end- effector tools and quickly adapt to new tools. We propose AdaGrasp, a method to learn a single grasping policy that generalizes to novel grippers. By training on a large collection of grippers, our algorithm is able to acquire generalizable knowledge of how different grippers should be used in various tasks. Given a visual observation of the scene and the gripper, AdaGrasp infers the possible grasp poses and their grasp scores by computing the cross convolution between the shape encodings of the gripper and scene. Intuitively, this cross convolution operation can be considered as an efficient way of exhaustively matching the scene geometry with gripper geometry under different grasp poses (i.e., translations and orientations), where a good \"match\" of 3D geometry will lead to a successful grasp. We validate our methods in both simulation and real- world environments. Our experiment shows that AdaGrasp significantly outperforms the existing multi-gripper grasping policy method, especially when handling cluttered environments and partial observations. Code and Data are available at https://adagrasp.cs.columbia.edu.",
        "primary_area": "",
        "author": "Zhenjia Xu;Beichun Qi;Shubham Agrawal;Shuran Song;Zhenjia Xu;Beichun Qi;Shubham Agrawal;Shuran Song",
        "authorids": "/37089001027;/37088997198;/37088998130;/37085613509;/37089001027;/37088997198;/37088998130;/37085613509",
        "aff": "Columbia University; Columbia University; Columbia University; Columbia University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560833/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12320717161269744876&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560960",
        "title": "Adaptation to Team Composition Changes for Heterogeneous Multi-Robot Sensor Coverage",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of multi-robot sensor coverage, which deals with deploying a multi-robot team in an environment and optimizing the sensing quality of the overall environment. As real-world environments involve a variety of sensory information, and individual robots are limited in their available number of sensors, successful multi-robot sensor coverage requires the deployment of robots in such a way that each individual team member\u2019s sensing quality is maximized. Additionally, because individual robots have varying complements of sensors and both robots and sensors can fail, robots must be able to adapt and adjust how they value each sensing capability in order to obtain the most complete view of the environment, even through changes in team composition. We introduce a novel formulation for sensor coverage by multi-robot teams with heterogeneous sensing capabilities that maximizes each robot's sensing quality, balancing the varying sensing capabilities of individual robots based on the overall team composition. We propose a solution based on regularized optimization that uses sparsity-inducing terms to ensure a robot team focuses on all possible event types, and which we show is proven to converge to the optimal solution. Through extensive simulation, we show that our approach is able to effectively deploy a multi-robot team to maximize the sensing quality of an environment, responding to failures in the multi-robot team more robustly than non-adaptive approaches.",
        "primary_area": "",
        "author": "Brian Reily;Terran Mott;Hao Zhang;Brian Reily;Terran Mott;Hao Zhang",
        "authorids": "/37088504746;/37089001905;/37085545929;/37088504746;/37089001905;/37085545929",
        "aff": "Department of Computer Science, Human-Centered Robotics Laboratory, The Colorado School of Mines, Golden, CO, USA; Department of Computer Science, Human-Centered Robotics Laboratory, The Colorado School of Mines, Golden, CO, USA; Department of Computer Science, Human-Centered Robotics Laboratory, The Colorado School of Mines, Golden, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560960/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9589755624150636935&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Colorado School of Mines",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.mines.edu",
        "aff_unique_abbr": "CSM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Golden",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561477",
        "title": "Adaptive Failure Search Using Critical States from Domain Experts",
        "track": "main",
        "status": "Poster",
        "abstract": "Uncovering potential failure cases is a crucial step in the validation of safety critical systems such as autonomous vehicles. Failure search may be done through logging substantial vehicle miles in either simulation or real world testing. Due to the sparsity of failure events, naive random search approaches require significant amounts of vehicle operation hours to find potential system weaknesses. As a result, adaptive searching techniques have been proposed to efficiently explore and uncover failure trajectories of an autonomous policy in simulation. Adaptive Stress Testing (AST) is one such method that poses the problem of failure search as a Markov decision process and uses reinforcement learning techniques to find high probability failures. However, this formulation requires a probability model for the actions of all agents in the environment. In systems where the environment actions are discrete and dependencies among agents exist, it may be infeasible to fully characterize the distribution or find a suitable proxy. This work proposes the use of a data driven approach to learn a suitable classifier that tries to model how humans identify critical states and use this to guide failure search in AST. We show that the incorporation of critical states into the AST framework generates failure scenarios with increased safety violations in an autonomous driving policy with a discrete action space.",
        "primary_area": "",
        "author": "Peter Du;Katherine Driggs-Campbell;Peter Du;Katherine Driggs-Campbell",
        "authorids": "/37088598010;/37085509519;/37088598010;/37085509519",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561477/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6577926829537655119&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois, Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561331",
        "title": "Adaptive Nonlinear Model Predictive Control for Autonomous Surface Vessels With Largely Varying Payload",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous surface vessels (ASVs) always carry payloads such as passengers and cargoes. The change in the payload can sometimes be several times the weight of the vessel. The payload can cause significant changes in the dynamics of the vessel, thereby degrading the performance of the controller. This paper proposes an adaptive nonlinear model predictive control (A-NMPC) strategy for ASV trajectory tracking, which allows real-time changes in dynamics caused by severe payload variation. First, a nonlinear dynamic model that updates with the vessel\u2019s payload is established. Then a pressure sensing method is proposed to estimate the payload of the vessel. Further, a parametric cost function that considers changing dynamics, as well as input and state constraints, is formulated in the NMPC algorithm. The tracking ability of A-NMPC is systematically studied on three different sizes of vessels in the simulation where the payload of these vessels changes eight times their inherent weight. Numerical results show that when the payload changes greatly the vessels with A-NMPC can accurately track the reference trajectory while the vessels with conventional NMPC cannot. Finally, the tracking experiments with a quarter-scale vessel in a swimming pool further verify the effectiveness of the proposed A-NMPC strategy.",
        "primary_area": "",
        "author": "Wei Wang;Niklas Hagemann;Carlo Ratti;Daniela Rus;Wei Wang;Niklas Hagemann;Carlo Ratti;Daniela Rus",
        "authorids": "/37073346500;/37089000190;/37590016800;/37279652300;/37073346500;/37089000190;/37590016800;/37279652300",
        "aff": "Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; SENSEable City Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561331/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18216885909796371999&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Lab (CSAIL)",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561319",
        "title": "Adaptive Sampling using POMDPs with Domain-Specific Considerations",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate improving Monte Carlo Tree Search based solvers for Partially Observable Markov Decision Processes (POMDPs), when applied to adaptive sampling problems. We propose improvements in rollout allocation, the action exploration algorithm, and plan commitment. The first allocates a different number of rollouts depending on how many actions the agent has taken in an episode. We find that rollouts are more valuable after some initial information is gained about the environment. Thus, a linear increase in the number of rollouts, i.e. allocating a fixed number at each step, is not appropriate for adaptive sampling tasks. The second alters which actions the agent chooses to explore when building the planning tree. We find that by using knowledge of the number of rollouts allocated, the agent can more effectively choose actions to explore. The third improvement is in determining how many actions the agent should take from one plan. Typically, an agent will plan to take the first action from the planning tree and then call the planner again from the new state. Using statistical techniques, we show that it is possible to greatly reduce the number of rollouts by increasing the number of actions taken from a single planning tree without affecting the agent\u2019s final reward. Finally, we demonstrate experimentally, on simulated and real aquatic data from an underwater robot, that these improvements can be combined, leading to better adaptive sampling. The code for this work is available at https://github.com/uscresl/AdaptiveSamplingPOMCP.",
        "primary_area": "",
        "author": "Gautam Salhotra;Christopher E. Denniston;David A. Caron;Gaurav S. Sukhatme;Gautam Salhotra;Christopher E. Denniston;David A. Caron;Gaurav S. Sukhatme",
        "authorids": "/37088996184;/37086855837;/37545524400;/37278934100;/37088996184;/37086855837;/37545524400;/37278934100",
        "aff": "University of Southern California; University of Southern California; University of Southern California; University of Southern California",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561319/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13950116623203555847&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561447",
        "title": "Adaptive Tracking Control of Soft Robots Using Integrated Sensing Skins and Recurrent Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study integrated estimation and control of soft robots. A significant challenge in deploying closed loop controllers is reliable proprioception via integrated sensing in soft robots. Despite the considerable advances accomplished in fabrication, modelling, and model-based control of soft robots, integrated sensing and estimation is still in its infancy. To that end, this paper introduces a new method of estimating the degree of curvature of a soft robot using a stretchable sensing skin. The skin is a spray-coated piezoresistive sensing layer on a latex membrane. The mapping from the strain signal to the degree of curvature is estimated by using a recurrent neural network. We investigate uni-directional bending as well as bi-directional bending of a single-segment soft robot. Moreover, an adaptive controller is developed to track the degree of curvature of the soft robot in the presence of dynamic uncertainties. Subsequently, using the integrated soft sensing skin, we experimentally demonstrate successful curvature tracking control of the soft robot.",
        "primary_area": "",
        "author": "Lasitha Weerakoon;Zepeng Ye;Rahul Subramonian Bama;Elisabeth Smela;Miao Yu;Nikhil Chopra;Lasitha Weerakoon;Zepeng Ye;Rahul Subramonian Bama;Elisabeth Smela;Miao Yu;Nikhil Chopra",
        "authorids": "/37088479686;/37089000561;/37086480732;/37270797200;/37712030100;/37283228300;/37088479686;/37089000561;/37086480732;/37270797200;/37712030100;/37283228300",
        "aff": "Department of Mechanical Engineering, University of Maryland, College Park, MD, USA; Department of Mechanical Engineering, University of Maryland, College Park, MD, USA; Department of Mechanical Engineering, University of Maryland, College Park, MD, USA; Department of Mechanical Engineering, University of Maryland, College Park, MD, USA; Department of Mechanical Engineering, University of Maryland, College Park, MD, USA; Department of Mechanical Engineering, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561447/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10453882453026959829&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561886",
        "title": "Adaptive stiffness estimation impedance control for achieving sustained contact in aerial manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a manipulator-equipped unmanned aerial vehicle (UAV) performing contact-based surface inspection. Using stereo camera information, a contact point is determined and an approach path is generated to ensure an autonomous workflow. The proposed inspection method uses an impedance controller to regulate the force applied by the end-effector to the contact surface. Due to the often adverse conditions in the real world, the aerial manipulator may fail to achieve contact after approaching the surface. Therefore, the impedance controller is coupled with an online stiffness estimation algorithm to increase the overall robustness of the inspection system and achieve stable surface contact. Finally, simulations in the Gazebo environment and experiments in the real world are performed to show the feasibility of this approach.",
        "primary_area": "",
        "author": "Lovro Markovi\u0107;Marko Car;Matko Orsag;Stjepan Bogdan;Lovro Markovi\u0107;Marko Car;Matko Orsag;Stjepan Bogdan",
        "authorids": "/37086941032;/37085654400;/37568794800;/37357209200;/37086941032;/37085654400;/37568794800;/37357209200",
        "aff": "Faculty of Electrical and Computer Engineering, University of Zagreb, Zagreb, Croatia; Faculty of Electrical and Computer Engineering, University of Zagreb, Zagreb, Croatia; Faculty of Electrical and Computer Engineering, University of Zagreb, Zagreb, Croatia; Faculty of Electrical and Computer Engineering, University of Zagreb, Zagreb, Croatia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561886/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15423874805725427105&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Zagreb",
        "aff_unique_dep": "Faculty of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.unizg.hr",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zagreb",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Croatia"
    },
    {
        "id": "9561242",
        "title": "Advanced Sensing Development to Support Robot Accuracy Assessment and Improvement",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots can perform various types of automated movements in the workspace. In recent years, robot applications have been expanded to a much wider scope, including robot machining, robot assembly, robot 3D printing, robot inspection, etc. Many of these applications require robots to have higher absolute accuracy compared with conventional robot part handling and welding. The capability to assess a robot\u2019s accuracy, and further, improve accuracy becomes important. In this paper, an advanced sensor and an accompanying methodology are developed that enable manufacturers to perform accuracy assessment to improve their robot systems. A smart target (patent pending) is developed at the National Institute of Standards and Technology (NIST). This sensor is integrated with a vision-based measurement instrument to perform high accuracy measurements of six-dimensional (6-D) information (x, y, and z position, roll, pitch, and yaw orientation) for a moving robot arm. The smart target is motorized. It can constantly rotate toward the vision-based measurement instrument to maximize its line-of-sight. A use case is presented to demonstrate the accuracy degradation assessment by using the smart target on a Universal Robot.",
        "primary_area": "",
        "author": "Guixiu Qiao;Guixiu Qiao",
        "authorids": "/37271268000;/37271268000",
        "aff": "National Institute of Standards and Technology, Gaithersburg, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561242/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8216289292138536811&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "National Institute of Standards and Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nist.gov",
        "aff_unique_abbr": "NIST",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Gaithersburg",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561817",
        "title": "Adversarial Attacks on Optimization based Planners",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory planning is a key piece in the algorithmic architecture of a robot. Trajectory planners typically use iterative optimization schemes for generating smooth trajectories that avoid collisions and are optimal for tracking given the robot\u2019s physical specifications. Starting from an initial estimate, the planners iteratively refine the solution so as to satisfy the desired constraints. In this paper, we show that such iterative optimization based planners can be vulnerable to adversarial attacks that force the planner either to fail completely, or significantly increase the time required to find a solution. The key insight here is that an adversary in the environment can directly affect the optimization cost function of a planner. We demonstrate how the adversary can adjust its own state configurations to result in poorly conditioned eigenstructure of the objective leading to failures. We apply our method against two state of the art trajectory planners and demonstrate that an adversary can consistently exploit certain weaknesses of an iterative optimization scheme.",
        "primary_area": "",
        "author": "Sai Vemprala;Ashish Kapoor;Sai Vemprala;Ashish Kapoor",
        "authorids": "/37085796013;/37397699500;/37085796013;/37397699500",
        "aff": "Microsoft Corporation, Redmond, USA; Microsoft Corporation, Redmond, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561817/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2867099531569381266&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "Microsoft Corporation",
        "aff_unique_url": "https://www.microsoft.com",
        "aff_unique_abbr": "Microsoft",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Redmond",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561205",
        "title": "Adversarial Differentiable Data Augmentation for Autonomous Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous systems often rely on neural networks to achieve high performance on planning and control problems. Unfortunately, neural networks suffer severely when input images become degraded in ways that are not reflected in the training data. This is particularly problematic for robotic systems like autonomous vehicles (AV) for which reliability is paramount. In this work, we consider robust optimization methods for hardening control systems against image corruptions and other unexpected domain shifts. Recent work on robust optimization for neural nets has been focused largely on combating adversarial attacks. In this work, we borrow ideas from the adversarial training and data augmentation literature to enhance robustness to image corruptions and domain shifts. To this end, we train networks while augmenting image data with a battery of image degradations. Unlike traditional augmentation methods, we choose the parameters for each degradation adversarially so as to maximize system performance. By formulating image degradations in a way that is differentiable with respect to degradation parameters, we enable the use of efficient optimization methods (PGD) for choosing worst-case augmentation parameters. We demonstrate the efficacy of this method on the learning to steer task for AVs. By adversarially training against image corruptions, we produce networks that are highly robust to image corruptions. We show that the proposed differentiable augmentation schemes result in higher levels of robustness and accuracy for a range of settings as compared to baseline and state-of-the-art augmentation methods.",
        "primary_area": "",
        "author": "Manli Shu;Yu Shen;Ming C. Lin;Tom Goldstein;Manli Shu;Yu Shen;Ming C. Lin;Tom Goldstein",
        "authorids": "/37088485182;/37088996267;/37278387400;/37085737041;/37088485182;/37088996267;/37278387400;/37085737041",
        "aff": "Department of Computer Science, University of Maryland, College Park, MD, U.S.A; Department of Computer Science, University of Maryland, College Park, MD, U.S.A; Maryland Robotics Center, University of Maryland, College Park, MD, U.S.A; Department of Computer Science, University of Maryland, College Park, MD, U.S.A",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561205/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14427495131135689256&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Maryland, College Park;University of Maryland",
        "aff_unique_dep": "Department of Computer Science;Maryland Robotics Center",
        "aff_unique_url": "https://www/umd.edu;https://www.umd.edu",
        "aff_unique_abbr": "UMD;UMD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561915",
        "title": "Adversarial Imitation Learning with Trajectorial Augmentation and Correction",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Imitation Learning requires a large number of expert demonstrations, which are not always easy to obtain, especially for complex tasks. A way to overcome this shortage of labels is through data augmentation. However, this cannot be easily applied to control tasks due to the sequential nature of the problem. In this work, we introduce a novel augmentation method which preserves the success of the augmented trajectories. To achieve this, we introduce a semi-supervised correction network that aims to correct distorted expert actions. To adequately test the abilities of the correction network, we develop an adversarial data augmented imitation architecture to train an imitation agent using synthetic experts. Additionally, we introduce a metric to measure diversity in trajectory datasets. Experiments show that our data augmentation strategy can improve accuracy and convergence time of adversarial imitation while preserving the diversity between the generated and real trajectories.",
        "primary_area": "",
        "author": "Dafni Antotsiou;Carlo Ciliberto;Tae-Kyun Kim;Dafni Antotsiou;Carlo Ciliberto;Tae-Kyun Kim",
        "authorids": "/37089000455;/38228801600;/37280613000;/37089000455;/38228801600;/37280613000",
        "aff": "EEE Department, Imperial College London, UK; EEE Department, Imperial College London, UK; EEE Department, Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561915/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2801066596416347902&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "EEE Department",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561379",
        "title": "Adversarial Skill Learning for Robust Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning has made significant progress in robotic manipulation tasks and it works well in the ideal disturbance-free environment. However, in a real-world environment, both internal and external disturbances are inevitable, thus the performance of the trained policy will dramatically drop. To improve the robustness of the policy, we introduce the adversarial training mechanism to the robotic manipulation tasks in this paper, and an adversarial skill learning algorithm based on soft actor-critic (SAC) is proposed for robust manipulation. Extensive experiments are conducted to demonstrate that the learned policy is robust to internal and external disturbances. Additionally, the proposed algorithm is evaluated in both the simulation environment and on the real robotic platform.",
        "primary_area": "",
        "author": "Pingcheng Jian;Chao Yang;Di Guo;Huaping Liu;Fuchun Sun;Pingcheng Jian;Chao Yang;Di Guo;Huaping Liu;Fuchun Sun",
        "authorids": "/37088996499;/37089736871;/37085360957;/37310126400;/37279269000;/37088996499;/37089736871;/37085360957;/37310126400;/37279269000",
        "aff": "the Department of Computer Science and Technology, Beijing National Research Center for Information Science and Technology, Institute for Artificial Intelligence, Tsinghua University, Beijing, China; the Department of Computer Science and Technology, Beijing National Research Center for Information Science and Technology, Institute for Artificial Intelligence, Tsinghua University, Beijing, China; the Department of Computer Science and Technology, Beijing National Research Center for Information Science and Technology, Institute for Artificial Intelligence, Tsinghua University, Beijing, China; the Department of Computer Science and Technology, Beijing National Research Center for Information Science and Technology, Institute for Artificial Intelligence, Tsinghua University, Beijing, China; the Department of Computer Science and Technology, Beijing National Research Center for Information Science and Technology, Institute for Artificial Intelligence, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561379/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15021458877616202133&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561036",
        "title": "Adversarial Training is Not Ready for Robot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Adversarial training is an effective method to train deep learning models that are resilient to norm-bounded perturbations, with the cost of nominal performance drop. While adversarial training appears to enhance the robustness and safety of a deep model deployed in open-world decision-critical applications, counterintuitively, it induces undesired behaviors in robot learning settings. In this paper, we show theoretically and experimentally that neural controllers obtained via adversarial training are subjected to three types of defects, namely transient, systematic, and conditional errors. We first generalize adversarial training to a safety-domain optimization scheme allowing for more generic specifications. We then prove that such a learning process tends to cause certain error profiles. We support our theoretical results by a thorough experimental safety analysis in a robot-learning task. Our results suggest that adversarial training is not yet ready for robot learning.",
        "primary_area": "",
        "author": "Mathias Lechner;Ramin Hasani;Radu Grosu;Daniela Rus;Thomas A. Henzinger;Mathias Lechner;Ramin Hasani;Radu Grosu;Daniela Rus;Thomas A. Henzinger",
        "authorids": "/37086937501;/37085814419;/37442339800;/37279652300;/37271213400;/37086937501;/37085814419;/37442339800;/37279652300;/37271213400",
        "aff": "Institute of Science and Technology Austria (IST Austria); Technische Universit\u00e4t Wien (TU Wien), Vienna, Austria; Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Technische Universit\u00e4t Wien (TU Wien), Vienna, Austria; Institute of Science and Technology Austria (IST Austria)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561036/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17215242907018884764&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "Institute of Science and Technology Austria;Technische Universit\u00e4t Wien;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ist.ac.at;https://www.tuwien.ac.at;https://web.mit.edu",
        "aff_unique_abbr": "IST Austria;TU Wien;MIT",
        "aff_campus_unique_index": "1;2;1",
        "aff_campus_unique": ";Vienna;Cambridge",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Austria;United States"
    },
    {
        "id": "9561632",
        "title": "Adversarially-trained Hierarchical Feature Extractor for Vehicle Re-identification",
        "track": "main",
        "status": "Poster",
        "abstract": "Vehicle Re-identification (Re-ID) aims to retrieve all instances of query vehicle images present in an image pool. However viewpoint, illumination, and occlusion variations along with subtle differences between two unique images pose a significant challenge towards achieving an effective system. In this paper, we emphasize upon enhancing the performance of visual feature based ReID system by improving feature embedding quality and propose (1) an attention-guided hierarchical feature extractor (HFE) that leverages the structure of a backbone CNN to extract coarse and fine-grained features and (2) to train the proposed network within a hard negative adversarial framework that generates samples exhibiting extreme variations, encouraging the network to extract important distinguishing features across varying scales. To demonstrate the effectiveness of the proposed framework we use VERI-Wild, VRIC and Veri-776 datasets that exhibit extreme intra-class and minute inter-class differences and achieve state-of-the-art (SoTA) performance. Codes related to this paper are publicly available at https://github.com/PS06/VReID.",
        "primary_area": "",
        "author": "Pranjay Shyam;Kuk-Jin Yoon;Kyung-Soo Kim;Pranjay Shyam;Kuk-Jin Yoon;Kyung-Soo Kim",
        "authorids": "/37088503847;/38182036400;/37292681500;/37088503847;/38182036400;/37292681500",
        "aff": "Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561632/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3051416743687786284&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561875",
        "title": "Affordable Autonomy through Cooperative Sensing and Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "It is widely anticipated that Level-44 (L4) autonomous vehicles - vehicles capable of autonomously performing all driving functions under certain conditions - will eventually become available to the public. However, these vehicles are likely to be expensive due to the additional requirements on hardware, making them potentially inaccessible to the average consumer. This paper introduces the concept of Affordable Autonomy through Cooperative Sensing and Planning (AACSP). This concept enables a vehicle equipped with lower-end sensors such as a Level-26 vehicle - vehicle capable of limited lateral and longitudinal control but requiring a driver to stay engaged - to enter into an autonomous mode whenever it is in proximity with a Level-4 vehicle traveling along the same route. The paper describes the system along with the technical components of cooperative planning & state coordination in detail while giving an overview of the cooperative perception and localization modules that are required to implement the AACSP concept. The paper also presents results from simulation and real vehicles.",
        "primary_area": "",
        "author": "Paritosh Kelkar;Parth Chopra;Savio Pereira;Dan DeLano;Aaron Miller;Kyungzun Rim;Samer Rajab;Jonathan Butzke;Maxim Likhachev;Paritosh Kelkar;Parth Chopra;Savio Pereira;Dan DeLano;Aaron Miller;Kyungzun Rim;Samer Rajab;Jonathan Butzke;Maxim Likhachev",
        "authorids": "/37085628697;/37086875710;/37088999604;/37089001728;/37088505682;/37088506236;/37089045683;/38228824500;/37309318800;/37085628697;/37086875710;/37088999604;/37089001728;/37088505682;/37088506236;/37089045683;/38228824500;/37309318800",
        "aff": "Honda R&D Americas, LLC; Honda R&D Americas, LLC; Robotwits LLC, Pittsburgh, PA; Robotwits LLC, Pittsburgh, PA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Honda R&D Americas, LLC; Robotwits LLC, Pittsburgh, PA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561875/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2974697287898566005&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;1;2;2;0;1;2",
        "aff_unique_norm": "Honda R&D Americas;Robotwits LLC;Carnegie Mellon University",
        "aff_unique_dep": "R&D;;The Robotics Institute",
        "aff_unique_url": "https://www.honda.com;;https://www.cmu.edu",
        "aff_unique_abbr": "HRDA;;CMU",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561770",
        "title": "Aggregating Long-Term Context for Learning Laparoscopic and Robot-Assisted Surgical Workflows",
        "track": "main",
        "status": "Poster",
        "abstract": "Analyzing surgical workflow is crucial for surgical assistance robots to understand surgeries. With the understanding of the complete surgical workflow, the robots are able to assist the surgeons in intra-operative events, such as by giving a warning when the surgeon is entering specific keys or high-risk phases. Deep learning techniques have recently been widely applied to recognizing surgical workflows. Many of the existing temporal neural network models are limited in their capability to handle long-term dependencies in the data, instead, relying upon the strong performance of the underlying per-frame visual models. We propose a new temporal network structure that leverages task-specific network representation to collect long-term sufficient statistics that are propagated by a sufficient statistics model (SSM). We implement our approach within an LSTM backbone for the task of surgical phase recognition and explore several choices for propagated statistics. We demonstrate superior results over existing and novel state-of-the-art segmentation techniques on two laparoscopic cholecystectomy datasets: the publicly available Cholec80 dataset and MGH100, a novel dataset with more challenging and clinically meaningful segment labels.",
        "primary_area": "",
        "author": "Yutong Ban;Guy Rosman;Thomas Ward;Daniel Hashimoto;Taisei Kondo;Hidekazu Iwaki;Ozanan Meireles;Daniela Rus;Yutong Ban;Guy Rosman;Thomas Ward;Daniel Hashimoto;Taisei Kondo;Hidekazu Iwaki;Ozanan Meireles;Daniela Rus",
        "authorids": "/37086284172;/37393688300;/37088999591;/445988338893945;/37088999129;/37699924100;/37086164472;/37279652300;/37086284172;/37393688300;/37088999591;/445988338893945;/37088999129;/37699924100;/37086164472;/37279652300",
        "aff": "Department of Surgery, SAIIL, Massachusetts General Hospital, Boston, MA, US; Toyota Research Institute, Cambridge, MA, US; Department of Surgery, SAIIL, Massachusetts General Hospital, Boston, MA, US; Department of Surgery, SAIIL, Massachusetts General Hospital, Boston, MA, US; Olympus Corporation, Tokyo, Japan; Olympus Corporation, Tokyo, Japan; Department of Surgery, SAIIL, Massachusetts General Hospital, Boston, MA, US; Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, US",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561770/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12219193084315770941&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;2;2;0;3",
        "aff_unique_norm": "Massachusetts General Hospital;Toyota Research Institute;Olympus Corporation;Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Surgery;;;Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.massgeneral.org;https://www.tri.global;https://www.olympus.com;https://www.csail.mit.edu",
        "aff_unique_abbr": "MGH;TRI;;CSAIL",
        "aff_campus_unique_index": "0;1;0;0;2;2;0;1",
        "aff_campus_unique": "Boston;Cambridge;Tokyo",
        "aff_country_unique_index": "0;0;0;0;1;1;0;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9561239",
        "title": "Agile Actions with a Centaur-Type Humanoid: A Decoupled Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "The kinematic features of a centaur-type humanoid platform, combined with a powerful actuation, enable the experimentation of a variety of agile and dynamic motions. However, the higher number of degrees-of-freedom and the increased weight of the system, compared to the bipedal and quadrupedal counterparts, pose significant research challenges in terms of computational load and real implementation. To this end, this work presents a control architecture to perform agile actions, conceived for torque-controlled platforms, which decouples for computational purposes offline optimal control planning of lower-body primitives, based on a template kinematic model, and online control of the upper-body motion to maintain balance. Three stabilizing strategies are presented, whose performance is compared in two types of simulated jumps, while experimental validation is performed on a half-squat jump using the CENTAURO robot.",
        "primary_area": "",
        "author": "Matteo Parigi Polverini;Enrico Mingo Hoffman;Arturo Laurenzi;Nikos G. Tsagarakis;Matteo Parigi Polverini;Enrico Mingo Hoffman;Arturo Laurenzi;Nikos G. Tsagarakis",
        "authorids": "/37085589882;/37085377101;/37086141170;/37295830800;/37085589882;/37085377101;/37086141170;/37295830800",
        "aff": "Humanoids & Human Centered Mechatronics Research Line (HHCM), Istituto Italiano di Tecnologia (IIT), Genova, Italy; Humanoids & Human Centered Mechatronics Research Line (HHCM), Istituto Italiano di Tecnologia (IIT), Genova, Italy; Humanoids & Human Centered Mechatronics Research Line (HHCM), Istituto Italiano di Tecnologia (IIT), Genova, Italy; Humanoids & Human Centered Mechatronics Research Line (HHCM), Istituto Italiano di Tecnologia (IIT), Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561239/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13057568540477376291&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Humanoids & Human Centered Mechatronics Research Line (HHCM)",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genova",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9562117",
        "title": "Agile Robot Navigation through Hallucinated Learning and Sober Deployment",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from Hallucination (LfH) is a recent machine learning paradigm for autonomous navigation, which uses training data collected in completely safe environments and adds numerous imaginary obstacles to make the environment densely constrained, to learn navigation planners that produce feasible navigation even in highly constrained (more dangerous) spaces. However, LfH requires hallucinating the robot perception during deployment to match with the hallucinated training data, which creates a need for sometimes-infeasible prior knowledge and tends to generate very conservative planning. In this work, we propose a new LfH paradigm that does not require runtime hallucination\u2014a feature we call \"sober deployment\"\u2014and can therefore adapt to more realistic navigation scenarios. This novel Hallucinated Learning and Sober Deployment (HLSD) paradigm is tested in a benchmark testbed of 300 simulated navigation environments with a wide range of difficulty levels, and in the real-world. In most cases, HLSD outperforms both the original LfH method and a classical navigation planner.",
        "primary_area": "",
        "author": "Xuesu Xiao;Bo Liu;Peter Stone;Xuesu Xiao;Bo Liu;Peter Stone",
        "authorids": "/37086258082;/37088429909;/37269574900;/37086258082;/37088429909;/37269574900",
        "aff": "Department of Computer Science, University of Texas at Austin, Austin, TX; Department of Computer Science, University of Texas at Austin, Austin, TX; Sony AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562117/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7810693501502911045&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Texas at Austin;Sony",
        "aff_unique_dep": "Department of Computer Science;Sony AI",
        "aff_unique_url": "https://www.utexas.edu;https://www.sony.com",
        "aff_unique_abbr": "UT Austin;Sony AI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9561907",
        "title": "Airflow-Inertial Odometry for Resilient State Estimation on Multirotors",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a dead reckoning strategy for increased resilience to position estimation failures on multirotors, using only data from a low-cost IMU and novel, bio-inspired airflow sensors. The goal is challenging, since low-cost IMUs are subject to large noise and drift, while 3D airflow sensing is made difficult by the interference caused by the propellers and by the wind. Our approach relies on a deep-learning strategy to interpret the measurements of the bio-inspired sensors, a map of the wind speed to compensate for position-dependent wind, and a filter to fuse the information and generate a pose and velocity estimate. Our results show that the approach reduces the drift with respect to IMU-only dead reckoning by up to an order of magnitude over 30 seconds after a position sensor failure in non-windy environments, and it can compensate for the challenging effects of turbulent, and spatially varying wind.",
        "primary_area": "",
        "author": "Andrea Tagliabue;Jonathan P. How;Andrea Tagliabue;Jonathan P. How",
        "authorids": "/37086131568;/37276347700;/37086131568;/37276347700",
        "aff": "Department of Aeronautics and Astronautics, Massachusetts Institute of Technology; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561907/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15365533654049142815&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561563",
        "title": "Alternative Paths Planner (APP) for Provably Fixed-time Manipulation Planning in Semi-structured Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In many applications, including logistics and manufacturing, robot manipulators operate in semi-structured environments alongside humans or other robots. These environments are largely static, but they may contain some movable obstacles that the robot must avoid. Manipulation tasks in these applications are often highly repetitive, but require fast and reliable motion planning capabilities, often under strict time constraints. Existing preprocessing-based approaches are beneficial when the environments are highly-structured, but their performance degrades in the presence of movable obstacles, since these are not modelled a priori. We propose a novel preprocessing-based method called Alternative Paths Planner (APP) that provides provably fixed-time planning guarantees in semi-structured environments. APP plans a set of alternative paths offline such that, for any configuration of the movable obstacles, at least one of the paths from this set is collision-free. During online execution, a collision-free path can be looked up efficiently within a few microseconds. We evaluate APP on a 7 DoF robot arm in semi-structured domains of varying complexity and demonstrate that APP is several orders of magnitude faster than state-of-the-art motion planners for each domain. We further validate this approach with real-time experiments on a robotic manipulator.",
        "primary_area": "",
        "author": "Fahad Islam;Chris Paxton;Clemens Eppner;Bryan Peele;Maxim Likhachev;Dieter Fox;Fahad Islam;Chris Paxton;Clemens Eppner;Bryan Peele;Maxim Likhachev;Dieter Fox",
        "authorids": "/37085429028;/37085403975;/37571607800;/37088997596;/37309318800;/37284329000;/37085429028;/37085403975;/37571607800;/37088997596;/37309318800;/37284329000",
        "aff": "Carnegie Mellon University; NVIDIA; NVIDIA; NVIDIA; Carnegie Mellon University; University of Washington",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561563/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1847226525860393964&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;0;2",
        "aff_unique_norm": "Carnegie Mellon University;NVIDIA;University of Washington",
        "aff_unique_dep": ";NVIDIA Corporation;",
        "aff_unique_url": "https://www.cmu.edu;https://www.nvidia.com;https://www.washington.edu",
        "aff_unique_abbr": "CMU;NVIDIA;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560777",
        "title": "Amortized Q-learning with Model-based Action Proposals for Autonomous Driving on Highways",
        "track": "main",
        "status": "Poster",
        "abstract": "Well-established optimization-based methods can guarantee an optimal trajectory for a short optimization horizon, typically no longer than a few seconds. As a result, choosing the optimal trajectory for this short horizon may still result in a sub-optimal long-term solution. At the same time, the resulting short-term trajectories allow for effective, comfortable and provable safe maneuvers in a dynamic traffic environment. In this work, we address the question of how to ensure an optimal long-term driving strategy, while keeping the benefits of classical trajectory planning. We introduce a Reinforcement Learning based approach that coupled with a trajectory planner, learns an optimal long-term decision-making strategy for driving on highways. By online generating locally optimal maneuvers as actions, we balance between the infinite low-level continuous action space, and the limited flexibility of a fixed number of predefined standard lane-change actions. We evaluated our method on realistic scenarios in the open-source traffic simulator SUMO and were able to achieve better performance than the 4 benchmark approaches we compared against, including a random action selecting agent, greedy agent, high-level, discrete actions agent and an IDM-based SUMO-controlled agent.",
        "primary_area": "",
        "author": "Branka Mirchevska;Maria H\u00fcgle;Gabriel Kalweit;Moritz Werling;Joschka Boedecker;Branka Mirchevska;Maria H\u00fcgle;Gabriel Kalweit;Moritz Werling;Joschka Boedecker",
        "authorids": "/37086546750;/37086480992;/37087323482;/37542759200;/37888921900;/37086546750;/37086480992;/37087323482;/37542759200;/37888921900",
        "aff": "BMW Group, Unterschleissheim, Germany; Dept. of Computer Science, University of Freiburg, Germany; Dept. of Computer Science, University of Freiburg, Germany; BMW Group, Unterschleissheim, Germany; Cluster of Excellence BrainLinks-BrainTools, Freiburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560777/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15000791348483731754&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "BMW Group;University of Freiburg",
        "aff_unique_dep": ";Dept. of Computer Science",
        "aff_unique_url": "https://www.bmwgroup.com;https://www.uni-freiburg.de",
        "aff_unique_abbr": "BMW;Uni Freiburg",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Freiburg",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561415",
        "title": "Amplifying Laminar Jamming for Soft Robots by Geometry-Induced Rigidity",
        "track": "main",
        "status": "Poster",
        "abstract": "Variable stiffness technology is an extensively discussed topic in soft robotics, which can bridge the traditional fast, precise and high-force rigid robots with compliant, agile, and safe soft robots. In this paper, we introduce the concept of geometry-induced rigidity and propose a variable curvature jamming (VCJ) mechanism for amplifying the laminar jamming structures which are fast, efficient, low cost, easy control, and very versatile in stiffness modulation applications. By adjusting the cross sectional curvature of the laminar jamming structures, and coupling with the vacuum jamming, the initial compliant laminar structures can stiffen notably. The bidirectional stiffness behaviors of the VCJ actuators with different design parameters are experimentally studied and analyzed. The results show that the transverse curvature can remarkably enhance the stiffness and load capacity of the actuators, about 3 folds in stiffness change than the laminar jamming mechanism. The VCJ actuator can even bear 10.85-kg weight which is about 1700 times of its own weight at its rigid state. And it can be operated in three stiffening modes with different degrees of variable stiffness performance. Moreover, the proposed VCJ mechanism is compatible with all existing laminar jamming designs, which provide an effective design method for building soft actuators and soft robots with excellent variable stiffness performance and load capacity.",
        "primary_area": "",
        "author": "Wen-Bo Li;Xin-Yu Guo;Fu-Yi Fang;Wen-Ming Zhang;Wen-Bo Li;Xin-Yu Guo;Fu-Yi Fang;Wen-Ming Zhang",
        "authorids": "/37086008498;/37088803441;/37088999355;/37309473800;/37086008498;/37088803441;/37088999355;/37309473800",
        "aff": "State Key Laboratory of Mechanical System and Vibration, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561415/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8890820970213400580&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562049",
        "title": "An Active Palm Enhances Dexterity of Soft Robotic In-Hand Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "In-hand manipulation is challenging for soft robotic hands, especially in the real world where robots encounter a variety of object sizes and shapes. As such, the role of the palm is crucial, providing stabilizing contact to objects during grasping and manipulation, and controlling the position of objects with respect to the fingertips. We demonstrate an actuated palm capable of enhancing the in-hand manipulation capabilities of a soft hand by better-utilizing limited finger dexterity. With a combination of physical and virtual experiments, we explore the effects of palm diameter and height on in-hand manipulation performance over a variety of object shapes and sizes, and three key manipulation primitive motions. The results of these experiments show that maintaining manipulation capabilities over a large range of object sizes requires the palm\u2019s diameter to decrease as a function of its height to prevent interference between the fingers and palm. Based on these insights, we design an actuated palm mechanism that achieves the desired relationship between palm height and diameter using one actuated degree of freedom. Finally, we show that this adjustable palm enables the hand to manipulate a larger range of object sizes and aspect ratios, and its utility is demonstrated in a mid-air shelving in-hand manipulation task.",
        "primary_area": "",
        "author": "Clark B. Teeple;Grace R. Kim;Moritz A. Graule;Robert J. Wood;Clark B. Teeple;Grace R. Kim;Moritz A. Graule;Robert J. Wood",
        "authorids": "/37086131116;/37088996387;/37085771962;/37326227400;/37086131116;/37088996387;/37085771962;/37326227400",
        "aff": "John A. Paulson School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562049/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2354238308924638685&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "John A. Paulson School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561204",
        "title": "An Adaptive Fuzzy Reinforcement Learning Cooperative Approach for the Autonomous Control of Flock Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "The flock-guidance problem enjoys a challenging structure where multiple optimization objectives are solved simultaneously. This usually necessitates different control approaches to tackle various objectives, such as guidance, collision avoidance, and cohesion. The guidance schemes, in particular, have long suffered from complex tracking-error dynamics. Furthermore, techniques that are based on linear feedback strategies obtained at equilibrium conditions either may not hold or degrade when applied to uncertain dynamic environments. Pre-tuned fuzzy inference architectures lack robustness under such unmodeled conditions. This work introduces an adaptive distributed technique for the autonomous control of flock systems. Its relatively flexible structure is based on online fuzzy reinforcement learning schemes which simultaneously target a number of objectives; namely, following a leader, avoiding collision, and reaching a flock velocity consensus. In addition to its resilience in the face of dynamic disturbances, the algorithm does not require more than the agent position as a feedback signal. The effectiveness of the proposed method is validated with two simulation scenarios and benchmarked against a similar technique from the literature.",
        "primary_area": "",
        "author": "Shuzheng Qu;Mohammed Abouheaf;Wail Gueaieb;Davide Spinello;Shuzheng Qu;Mohammed Abouheaf;Wail Gueaieb;Davide Spinello",
        "authorids": "/37088837623;/37071245400;/37294232300;/37300354700;/37088837623;/37071245400;/37294232300;/37300354700",
        "aff": "School of Electrical Engineering & Computer Science, University of Ottawa, Ottawa, Canada; School of Electrical Engineering & Computer Science, University of Ottawa, Ottawa, Canada; School of Electrical Engineering & Computer Science, University of Ottawa, Ottawa, Canada; Department of Mechanical Engineering, University of Ottawa, Ottawa, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561204/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7747228579426694856&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Ottawa",
        "aff_unique_dep": "School of Electrical Engineering & Computer Science",
        "aff_unique_url": "https://www.uottawa.ca",
        "aff_unique_abbr": "U Ottawa",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ottawa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561229",
        "title": "An Anytime Algorithm for Chance Constrained Stochastic Shortest Path Problems and Its Application to Aircraft Routing",
        "track": "main",
        "status": "Poster",
        "abstract": "Aircraft routing problem is a crucial component for flight automation. Despite recent successes, challenges still remain when the environment is dynamic and uncertain. In this paper, we tackle the following two challenges. First, when the environment is uncertain, it is much safer if the route planner can guarantee a specified level of safety. Second, when the environment is dynamic, the planner needs to adapt to the changes in the environment quickly. To address these challenges, we present three contributions. First, we propose formulating the aircraft routing problem under a dynamic and uncertain environment as a chance constrained stochastic shortest path (CC-SSP) problem. Second, we introduce an anytime algorithm for the CC-SSP problem, which is effective in a dynamic environment with limited planning time. To be more specific, we present two versions of the algorithm and compare their performances. Third, we show that the algorithm can be generalized to solve a larger class of problems called chance constrained partially observable Markov decision process (CC-POMDP).",
        "primary_area": "",
        "author": "Sungkweon Hong;Sang Uk Lee;Xin Huang;Majid Khonji;Rashid Alyassi;Brian C. Williams;Sungkweon Hong;Sang Uk Lee;Xin Huang;Majid Khonji;Rashid Alyassi;Brian C. Williams",
        "authorids": "/37088997042;/37085778048;/37086595235;/37085584255;/37088601052;/37274902300;/37088997042;/37085778048;/37086595235;/37085584255;/37088601052;/37274902300",
        "aff": "Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology, Cambridge, MA, USA; Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE; Electrical Engineering and Computer Science, Khalifa University, Abu Dhabi, UAE; Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561229/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13135922100600594039&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Khalifa University",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Lab;Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.mit.edu;https://www.khalifa.edu",
        "aff_unique_abbr": "MIT;KU",
        "aff_campus_unique_index": "0;0;0;1;1;0",
        "aff_campus_unique": "Cambridge;Abu Dhabi",
        "aff_country_unique_index": "0;0;0;1;1;0",
        "aff_country_unique": "United States;United Arab Emirates"
    },
    {
        "id": "9561042",
        "title": "An Approximation Algorithm for an Assisted Shortest Path Problem",
        "track": "main",
        "status": "Poster",
        "abstract": "In this article, we introduce a cooperative path planning algorithm for a cardinal and a support robot where the cardinal robot is unable to traverse a subset of edges in a network until the support robot has first traversed them. This subset of edges represent paths in an environment that are initially unavailable to the cardinal robot and require the assistance of the support robot. A (2 + \u03b1)-approximation algorithm (where \u03b1 is the supremum of the ratio of the travel time of the support robot versus the travel time of the cardinal robot) is presented for this problem and is applied to various types of networks in order to examine the quality of the solutions it produces. We then conclude by discussing some potential future work concerning variations of this problem.",
        "primary_area": "",
        "author": "Christopher Montez;Sivakumar Rathinam;Swaroop Darbha;David Casbeer;Satyanarayana Gupta Manyam;Christopher Montez;Sivakumar Rathinam;Swaroop Darbha;David Casbeer;Satyanarayana Gupta Manyam",
        "authorids": "/37088996637;/37268809800;/37282703100;/37273056100;/37088997716;/37088996637;/37268809800;/37282703100;/37273056100;/37088997716",
        "aff": "Christopher Montez; Sivakumar Rathinam; Swaroop Darbha; David Casbeer; Satyanarayana Gupta Manyam",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561042/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=349984154706435757&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9562113",
        "title": "An Artin Braid Group Representation of Knitting Machine State with Applications to Validation and Optimization of Fabrication Plans",
        "track": "main",
        "status": "Poster",
        "abstract": "Industrial knitting machines create fabric by manipulating loops held on hundreds of needles. A core problem in pattern making for these machines is transfer planning \u2013 coming up with a sequence of low-level operations that move loops to the appropriate needles so that knitting through those loops produces the correct final structure. Since each loop is connected to the larger piece in progress, transfer plans must account for not only loop position, but the way strands of yarn tangle around each other.We present the first complete, discrete representation of the machine\u2019s loop-tangling process. Our representation combines a braid from the Artin Braid Group with an array of explicit loop positions to fully capture loop crossings. By storing braids in the Symmetric Normal Form, states can be quickly compared and updated incrementally with machine operations. This representation can be used to verify the equivalence of transfer operations, providing an important tool in optimizing knit manufacturing.We improve on prior work in transfer planning algorithms, which can only solve certain subclasses of problems and are frequently suboptimal in terms of fabrication time, by introducing a novel A* search heuristic and state-collapsing mechanism, which we show finds optimal transfer plans for a large benchmark set of small transfer planning problems.",
        "primary_area": "",
        "author": "Jenny Lin;James McCann;Jenny Lin;James McCann",
        "authorids": "/37088997267;/37088910733;/37088997267;/37088910733",
        "aff": "Carnegie Mellon University, Pittsburgh, PA; Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562113/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12638398206501767077&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561651",
        "title": "An Autonomous Robotic Flexible Endoscope System with a DNA-inspired Continuum Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we proposed an autonomous robotic flexible endoscope system for the laparoscopic bariatric surgery (LBS). This system comprises a UR5 robot and a flexible endoscope equipped with a novel continuum joint, named reinforced double helix continuum mechanism. Compared with the simple helix structure, the compressional and torsional stiffness of the proposed joint are improved significantly. To automate the robotic flexible endoscope, image-based visual servoing technique is employed. A deep learning algorithm named TernausNet-16 is improved and incorporated into the control framework to detect surgical instruments inside the camera view. The experimental studies verified the effectiveness and feasibility of the robotic flexible endoscope system for the visual serviong control scheme assisted by deep learning methods.",
        "primary_area": "",
        "author": "Xue Zhang;Weibing Li;Wing Yin Ng;Yisen Huang;Yitian Xian;Philip Wai Yan Chiu;Zheng Li;Xue Zhang;Weibing Li;Wing Yin Ng;Yisen Huang;Yitian Xian;Philip Wai Yan Chiu;Zheng Li",
        "authorids": "/37087468458;/37087238169;/37088833121;/37088832156;/37088998568;/37086577711;/38469473900;/37087468458;/37087238169;/37088833121;/37088832156;/37088998568;/37086577711;/38469473900",
        "aff": "Department of Surgery, The Chinese University of Hong Kong, Hong Kong; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; Chow Yuk Ho Technology Centre for Innovative Medicine, The Chinese University of Hong Kong, Hong Kong; Department of Surgery, The Chinese University of Hong Kong, Hong Kong; Chow Yuk Ho Technology Centre for Innovative Medicine, The Chinese University of Hong Kong, Hong Kong; Department of Surgery, Chow Yuk Ho Technology Centre for Innovative Medicine, and Multi-Scale Medical Robotics Centre Ltd., The Chinese University of Hong Kong, Hong Kong; Department of Surgery, Chow Yuk Ho Technology Centre for Innovative Medicine, Li Ka Shing Institute of Health Sciences, and Multi-Scale Medical Robotics Centre Ltd., The Chinese University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561651/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16305193571105245517&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Sun Yat-sen University",
        "aff_unique_dep": "Department of Surgery;School of Computer Science and Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;http://www.sysu.edu.cn",
        "aff_unique_abbr": "CUHK;SYSU",
        "aff_campus_unique_index": "0;1;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR;Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561004",
        "title": "An Autonomous Vault-Building Robot System for Creating Spanning Structures",
        "track": "main",
        "status": "Poster",
        "abstract": "Research in autonomous robots for construction has largely focused on ground-based robots whose reach constrains the size of what they can build, or on climbing or aerial robots that build solid or unroofed structures. Autonomous construction of larger, multistory buildings, or bridges spanning unsupported distances, would require robots that build sturdy structures supporting their own weight. In this paper, we present VaultBot, a system of autonomous robots that build a load-bearing spanning vault using identical modular blocks. The custom blocks employ mechanical and other features to facilitate robotic manipulation and locomotion, and can be removed from and replaced in an assembled structure as a way of repairing damage. We characterize the system's performance and failure modes, and demonstrate reliable autonomous assembly for a structure composed of 46 blocks. Blocks can be made collapsible and deployable as a way of reducing mass and volume that must be transported to a construction site. Such a system could be used to help enable construction of protective shelters in challenging environments, such as disaster relief scenarios, arctic settings, or extraterrestrial habitats.",
        "primary_area": "",
        "author": "Nathan Melenbrink;Ariel Wang;Justin Werfel;Nathan Melenbrink;Ariel Wang;Justin Werfel",
        "authorids": "/37086291970;/37088999539;/37266345300;/37086291970;/37088999539;/37266345300",
        "aff": "Wyss Institute for Biologically Inspired Engineering, Harvard University, Boston, MA, USA; Harvard College, Cambridge, MA, USA; Wyss Institute for Biologically Inspired Engineering, Harvard University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561004/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3328305550090521084&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "Wyss Institute for Biologically Inspired Engineering",
        "aff_unique_url": "https://wyss.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Boston;Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561426",
        "title": "An Efficient Closed-Form Method for Optimal Hybrid Force-Velocity Control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper derives a closed-form method for computing hybrid force-velocity control. The key idea is to maximize the kinematic conditioning of the mechanical system, which includes a robot, free objects, a rigid environment and contact constraints. The method is complete, in that it always produces an optimal/near optimal solution when a solution exists. It is efficient, since it is in closed form, avoiding the iterative search of our previous work. We test the method on 78,000 randomly generated test cases. The method outperforms our previous search-based technique by being from 7 to 40 times faster, while consistently producing better solutions in the sense of robustness to kinematic singularity. We also test the method in several representative manipulation experiments.",
        "primary_area": "",
        "author": "Yifan Hou;Matthew T. Mason;Yifan Hou;Matthew T. Mason",
        "authorids": "/37086454260;/37273994200;/37086454260;/37273994200",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561426/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2776139031488465889&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560863",
        "title": "An Efficient Parallel Self-assembly Planning Algorithm for Modular Robots in Environments with Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-assembly has attracted growing interests in modular robotics during past decades. Recent work accelerates the assembly process by parallelizing the docking actions among robots. However, these methods can only apply to ideal environments without obstacles. Otherwise, robots will get trapped during the assembly process, due to the complex scenes with obstacles. This paper presents an efficient parallel assembly planning algorithm for modular robots by taking the surrounding obstacles into consideration. By this algorithm, the docking actions are able to avoid immovable obstacles, and therefore parallel self-assembly of robots can adapt to complex environments. To validate the efficacy and generality, the authors have implemented this algorithm in a grid-world simulation environment with 25 distinct maps. The simulation results show a much higher success rate (more than 80%) of our proposed algorithm compared with the existing parallel self-assembly planning algorithms. Finally, the feasibility of the algorithm is affirmed by a self-assembly experiment on the automated guided vehicles (AGVs).",
        "primary_area": "",
        "author": "Lianxin Zhang;Zhang-Hua Fu;Hengli Liu;Qingquan Liu;Xiaoqiang Ji;Huihuan Qian;Lianxin Zhang;Zhang-Hua Fu;Hengli Liu;Qingquan Liu;Xiaoqiang Ji;Huihuan Qian",
        "authorids": "/37086801017;/37089407143;/37086607474;/37089000031;/37088954362;/37549401900;/37086801017;/37089407143;/37086607474;/37089000031;/37088954362;/37549401900",
        "aff": "The Chinese University of Hong Kong, Shenzhen; The Chinese University of Hong Kong, Shenzhen; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society; The Chinese University of Hong Kong, Shenzhen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560863/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11169891268148544988&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cuhk.edu.cn;http://www.siarfs.org/",
        "aff_unique_abbr": "CUHK;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560805",
        "title": "An Encoder-Free Joint Velocity Estimation Method for Serial Manipulators Using Inertial Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper focuses on developing a real-time and flexible velocity estimation approach for serial revolute manipulator using only one inertial measurement unit (IMU) mounted on each link side of the manipulator. Particularly, the proposed approach has no requirement for the installation position and orientation of the IMU, which improves the flexibility of the implementation procedure. A joint velocity model is established based on the proposed principle of constructing coordinate system according to the robotic geometric information. The general solutions are derived in detail, thereby the proposed algorithm can be generalized into any other robots with the same geometric configuration. With the method, the joint rotational velocity measurements of static and dynamic robotic motion are provided compared to encoders. Experimental results based on the six degrees of freedom (DOF) collaborative manipulator have validated the feasibility and effectiveness of the proposed approach. The proposed method has the benefits of low cost and flexibility, which could work as a redundant velocity monitor criterion to provide assistant joint velocity measurements.",
        "primary_area": "",
        "author": "Xiaolong Xu;Yujie Sun;Xincheng Tian;Lelai Zhou;Yibin Li;Xiaolong Xu;Yujie Sun;Xincheng Tian;Lelai Zhou;Yibin Li",
        "authorids": "/37086267051;/37086308487;/37086265655;/37089259985;/37279897500;/37086267051;/37086308487;/37086265655;/37089259985;/37279897500",
        "aff": "Engineering Research Center of Intelligent Unmanned System, Ministry of Education, Jinan, China; Engineering Research Center of Intelligent Unmanned System, Ministry of Education, Jinan, China; Engineering Research Center of Intelligent Unmanned System, Ministry of Education, Jinan, China; Engineering Research Center of Intelligent Unmanned System, Ministry of Education, Jinan, China; Engineering Research Center of Intelligent Unmanned System, Ministry of Education, Jinan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560805/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2809756704774884562&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Engineering Research Center of Intelligent Unmanned System",
        "aff_unique_dep": "Ministry of Education",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561769",
        "title": "An Equivariant Filter for Visual Inertial Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual Inertial Odometry (VIO) is of great interest due the ubiquity of devices equipped with both a monocular camera and Inertial Measurement Unit (IMU). Methods based on the extended Kalman Filter remain popular in VIO due to their low memory requirements, CPU usage, and processing time when compared to optimisation-based methods. In this paper, we analyse the VIO problem from a geometric perspective and propose a novel formulation on a smooth quotient manifold where the equivalence relationship is the well-known invariance of VIO to choice of reference frame. We propose a novel Lie group that acts transitively on this manifold and is compatible with the visual measurements. This structure allows for the application of Equivariant Filter (EqF) design leading to a novel filter for the VIO problem. Combined with a very simple vision processing front-end, the proposed filter demonstrates state-of-the-art performance on the EuRoC dataset compared to other EKF-based VIO algorithms.",
        "primary_area": "",
        "author": "Pieter van Goor;Robert Mahony;Pieter van Goor;Robert Mahony",
        "authorids": "/37088339154;/37283743600;/37088339154;/37283743600",
        "aff": "Systems Theory and Robotics group and the Australian Centre for Robotic Vision, Australian National University; Systems Theory and Robotics group and the Australian Centre for Robotic Vision, Australian National University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561769/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11965639251804909527&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Australian National University",
        "aff_unique_dep": "Systems Theory and Robotics group",
        "aff_unique_url": "https://www.anu.edu.au",
        "aff_unique_abbr": "ANU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9561741",
        "title": "An Event-based Vision Dataset for Visual Navigation Tasks in Agricultural Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "a new generation of computer vision, namely event-based or neuromorphic vision, provides a new paradigm for capturing visual data and the way such data is processed. Due to a highly novel type of visual sensors used in event-based vision, only a few datasets aimed at visual navigation tasks are publicly available.In this paper, we present and describe the first event-based vision dataset intended to cover visual navigation tasks for mobile robots navigating in different types of agricultural environment. The dataset might open new opportunities for the evaluation of existing and creation of new event-based visual navigation methods for use in agricultural scenes that contain a lot of vegetation, animals, and patterned objects.The new dataset was created using our own custom-designed Sensor Bundle, which was installed on a mobile robot platform. During data acquisition sessions, the platform was manually controlled. The Sensor Bundle consists of a dynamic vision sensor, a LIDAR, an RGB-D camera, and environmental sensors.In total, 21 data sequences in 12 different scenarios for the autumn season are publicly available. Each data sequence is accompanied by a video demonstrating its content and a detailed description, including known issues. The new dataset is mostly designed for Visual Odometry tasks; however, it also includes loop-closures for applying event-based visual SLAM methods.",
        "primary_area": "",
        "author": "Andrejs Zujevs;Mihails Pudzs;Vitalijs Osadcuks;Arturs Ardavs;Maris Galauskis;Janis Grundspenkis;Andrejs Zujevs;Mihails Pudzs;Vitalijs Osadcuks;Arturs Ardavs;Maris Galauskis;Janis Grundspenkis",
        "authorids": "/37088505117;/37567477300;/37085994987;/37088504357;/37089000846;/38054637200;/37088505117;/37567477300;/37085994987;/37088504357;/37089000846;/38054637200",
        "aff": "Faculty of Computer Science and Information Technology, Riga Technical University, Latvia; Faculty of Computer Science and Information Technology, Riga Technical University, Latvia; Faculty of Engineering, Latvia University of Life Sciences and Technologies, Latvia; Faculty of Computer Science and Information Technology, Riga Technical University, Latvia; Faculty of Computer Science and Information Technology, Riga Technical University, Latvia; Faculty of Computer Science and Information Technology, Riga Technical University, Latvia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561741/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12943461893865946114&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Riga Technical University;Latvia University of Life Sciences and Technologies",
        "aff_unique_dep": "Faculty of Computer Science and Information Technology;Faculty of Engineering",
        "aff_unique_url": "https://www.rtu.lv;https://www.luta.lv",
        "aff_unique_abbr": "RTU;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Latvia"
    },
    {
        "id": "9561316",
        "title": "An Improved Magnetic Spot Navigation for Replacing the Barcode Navigation in Automated Guided Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "The barcode navigation based on QR (quick response) codes is widely employed in industrial logistics due to its accurate localization and flexible movement paths. However, the regular repair of damaged barcodes and robot speed control when approaching the barcodes are required. In this study, we presented an improved magnetic spot navigation approach to replace the barcode navigation for automated guided vehicles (AGVs). The fusion of the high-precision magnetic tracking method and odometer based on AGV encoders can overcome the disadvantages of barcode navigation. The magnetic tracking approach provides the AGV pose relative to the nearest magnet spot, instead of the low-precision longitudinal and lateral measurement via a magnetic ruler. Besides, with the benefit of the adaptive weighted fusion algorithm, the distance between the adjacent barcode can be set from 500 to 1000 mm via magnetic spots. Experimental results show that the mean path accuracy and mean magnet spot localization accuracy of the improved magnetic spot navigation were 110 \u00b1 30 mm and 14.5 \u00b1 0.87 mm, respectively. The proposed approach provides a novel possibility for large-area and high-precision navigation in AGVs-based industrial logistics, especially for large outdoor scenarios.",
        "primary_area": "",
        "author": "Houde Dai;Pengfei Guo;Hongyu Chen;Silin Zhao;Penghua Liu;Guijuan Lin;Houde Dai;Pengfei Guo;Hongyu Chen;Silin Zhao;Penghua Liu;Guijuan Lin",
        "authorids": "/37085718591;/37088997316;/37088996823;/37089001486;/37088997331;/37088999756;/37085718591;/37088997316;/37088996823;/37089001486;/37088997331;/37088999756",
        "aff": "Quanzhou Institute of Equipment Manufacturing, Haixi Institutes, Chinese Academy of Sciences, Jinjiang, China; Fujian College, University of Chinese Academy of Sciences, Fuzhou, China; Xiamen University of Technology, Xiamen, China; Xiamen University of Technology, Xiamen, China; Xiamen University of Technology, Xiamen, China; Xiamen University of Technology, Xiamen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561316/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8611674089872307599&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;2;2",
        "aff_unique_norm": "Chinese Academy of Sciences;University of Chinese Academy of Sciences;Xiamen University of Technology",
        "aff_unique_dep": "Institute of Equipment Manufacturing;Fujian College;",
        "aff_unique_url": "http://www.cas.cn;http://www.ucas.ac.cn;http://www.xmut.edu.cn",
        "aff_unique_abbr": "CAS;UCAS;",
        "aff_campus_unique_index": "0;1;2;2;2;2",
        "aff_campus_unique": "Jinjiang;Fuzhou;Xiamen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562040",
        "title": "An Integrated High-dexterity Cooperative Robotic Assistant for Intraocular Micromanipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Makoto Jinno;Gang Li;Niravkumar Patel;Iulian Iordachita;Makoto Jinno;Gang Li;Niravkumar Patel;Iulian Iordachita",
        "authorids": "/37088649257;/37085576110;/37086366528;/37330620500;/37088649257;/37085576110;/37086366528;/37330620500",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562040/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8699053654081030961&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9561798",
        "title": "An Intention Guided Hierarchical Framework for Trajectory-based Teleoperation of Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "In human-in-the-loop navigation, the operator\u2019s intention is to locally avoid obstacles while planning long-horizon paths in order to complete the navigation task. We propose a hierarchical teleoperation framework that captures these characteristics of intention, and generates trajectories that are locally safe and follow the operator\u2019s global plan. The hierarchical teleoperation framework consists of 1) a global path which encapsulates the intended direction of the operator, 2) local trajectories that circumvent obstacles near the vehicle\u2019s vicinity while following the global path, and 3) safety monitoring to avoid possible imminent collisions. By removing the operator from providing dynamic-level control inputs and instead having inputs inform trajectory generation, we show a significant reduction of the operator\u2019s engagement while maintaining smooth performance.We showcase hierarchical teleoperation in navigation tasks in a random forest environment and a high-clutter warehouse characterized by narrow gaps and dense obstacles. With our method, we maintain consistent high speed throughout the task with smooth jerk profiles, decreased time to completion, and significantly reduced operator engagement.",
        "primary_area": "",
        "author": "Xuning Yang;Jasmine Cheng;Nathan Michael;Xuning Yang;Jasmine Cheng;Nathan Michael",
        "authorids": "/37086010950;/37089001660;/37302499000;/37086010950;/37089001660;/37302499000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561798/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9136826103269546532&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561227",
        "title": "An MR Safe Rotary Encoder Based on Eccentric Sheave and FBG Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "MRI-guided robotic systems are emerging platforms for minimally invasive intervention because of high positioning accuracy and excellent tissue contrast. MR safe encoders are critical components for closed-loop robotic control. This paper develops an MR safe absolute rotary encoder based on eccentric sheave and FBG sensors. The eccentric sheave transforms the rotational motion of the shaft to the bending deflection of the beam on which FBG sensors are integrated. A model is built by establishing the relationship of the kinematics of the sheave, the mechanical properties of the beam with unknown length, and the strain model of two Fiber Bragg Grating (FBG) sensors. A Pseudo-Rigid Body (PRB) 3R model is used to solve a set of constrained equations for accurate rotary encoding. A prototype is built to calibrate the parameters and validate the accuracy of the encoder and its MR compatibility. Results show that the maximum angular error is 1.6\u00b0, and the RMS error is 0.46\u00b0. MRI shows that no noticeable artifacts are observed, and the Signal to Noise Ratio (SNR) is not affected. The results demonstrate the potential of the proposed method for it to be integrated with MR safe robots with easy fabrication, compact structures, and continuous measurement.",
        "primary_area": "",
        "author": "Shaoping Huang;Anzhu Gao;Zicong Wu;Chuqian Lou;Yanjun Wang;Guang-Zhong Yang;Shaoping Huang;Anzhu Gao;Zicong Wu;Chuqian Lou;Yanjun Wang;Guang-Zhong Yang",
        "authorids": "/37086543846;/38027228000;/37088406835;/37089002000;/37089001396;/37276270800;/37086543846;/38027228000;/37088406835;/37089002000;/37089001396;/37276270800",
        "aff": "The Institute of Medical Robotics and School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China; Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai, China; The Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; The Imperial College London and Empa-Swiss Federal Laboratories for Materials Science and Technology; The Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; The Institute of Medical Robotics and School of Biomedical Engineering, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561227/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13480044230730521827&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Shanghai Engineering Research Center of Intelligent Control and Management;Imperial College London",
        "aff_unique_dep": "School of Biomedical Engineering;;",
        "aff_unique_url": "https://www.sjtu.edu.cn;;https://www.imperial.ac.uk",
        "aff_unique_abbr": "SJTU;;Imperial College",
        "aff_campus_unique_index": "0;0;2;0;0",
        "aff_campus_unique": "Shanghai;;London",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9560943",
        "title": "An On-Line POMDP Solver for Continuous Observation Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning under partial obervability is essential for autonomous robots. A principled way to address such planning problems is the Partially Observable Markov Decision Process (POMDP). Although solving POMDPs is computationally intractable, substantial advancements have been achieved in developing approximate POMDP solvers in the past two decades. However, computing robust solutions for problems with continuous observation spaces remains challenging. Most on-line solvers rely on discretising the observation space or artificially limiting the number of observations that are considered during planning to compute tractable policies. In this paper we propose a new on-line POMDP solver, called Lazy Belief Extraction for Continuous Observation POMDPs (LABECOP), that combines methods from Monte-Carlo-Tree-Search and particle filtering to construct a policy reprentation which doesn't require discretised observation spaces and avoids limiting the number of observations considered during planning. Experiments on three different problems involving continuous observation spaces indicate that LABECOP performs similar or better than state- of-the-art POMDP solvers.",
        "primary_area": "",
        "author": "Marcus Hoerger;Hanna Kurniawati;Marcus Hoerger;Hanna Kurniawati",
        "authorids": "/37086163111;/37565882700;/37086163111;/37565882700",
        "aff": "College of Engineering & Computer Science, The Australian National University, Canberra, Australia; College of Engineering & Computer Science, The Australian National University, Canberra, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560943/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13200202509049405223&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Australian National University",
        "aff_unique_dep": "College of Engineering & Computer Science",
        "aff_unique_url": "https://www.anu.edu.au",
        "aff_unique_abbr": "ANU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Canberra",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9561977",
        "title": "An Open-Source Mechanical Design of ALARIS Hand: A 6-DOF Anthropomorphic Robotic Hand",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new open-source mechanical design of a 6-DOF anthropomorphic ALARIS robotic hand that can serve as a low-cost design platform for further customization and utilization for research and educational purposes. The presented hand design employs linkage-based three-phalange finger and two-phalange adaptive thumb designs with non-backdrivable worm-and-rack transmission mechanisms. Combination of design improvements and solutions, discussed in the paper, are implemented in a functional robotic hand prototype with powerful grasping capabilities, which utilizes off-the-shelf inexpensive components and 3D printing technology ensuring the hand low manufacturing cost and replicability. The open-source mechanical design of the presented ALARIS robotic hand is freely available for downloading from the authors\u2019 research lab web-site https://www.alaris.kz and https://github.com/alarisnu/alaris_hand.",
        "primary_area": "",
        "author": "Ayaulym Nurpeissova;Talgat Tursynbekov;Almas Shintemirov;Ayaulym Nurpeissova;Talgat Tursynbekov;Almas Shintemirov",
        "authorids": "/37088996395;/37088997652;/37078561500;/37088996395;/37088997652;/37078561500",
        "aff": "School of Engineering and Digital Sciences, Nazarbayev University, Nur-Sultan (Astana), Kazakhstan; School of Engineering and Digital Sciences, Nazarbayev University, Nur-Sultan (Astana), Kazakhstan; School of Engineering and Digital Sciences, Nazarbayev University, Nur-Sultan (Astana), Kazakhstan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561977/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12206716958661841083&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nazarbayev University",
        "aff_unique_dep": "School of Engineering and Digital Sciences",
        "aff_unique_url": "https://www.nu.edu.kz",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nur-Sultan (Astana)",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Kazakhstan"
    },
    {
        "id": "9561098",
        "title": "An Optimization Approach for a Robust and Flexible Control in Collaborative Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "In Human-Robot Collaboration, the robot operates in a highly dynamic environment. Thus, it is pivotal to guarantee the robust stability of the system during the interaction but also a high flexibility of the robot behavior in order to ensure safety and reactivity to the variable conditions of the collaborative scenario.In this paper we propose a control architecture capable of maximizing the flexibility of the robot while guaranteeing a stable behavior when physically interacting with the environment. This is achieved by combining an energy tank based variable admittance architecture with control barrier functions. The proposed architecture is experimentally validated on a collaborative robot.",
        "primary_area": "",
        "author": "Federico Benzi;Cristian Secchi;Federico Benzi;Cristian Secchi",
        "authorids": "/37088995970;/37300905500;/37088995970;/37300905500",
        "aff": "Department of Sciences and Methods of Engineering, University of Modena and Reggio Emilia, Italy; Department of Sciences and Methods of Engineering, University of Modena and Reggio Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561098/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15312482811581387954&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia",
        "aff_unique_dep": "Department of Sciences and Methods of Engineering",
        "aff_unique_url": "https://www.unimore.it",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9561542",
        "title": "An Optimized Two-Layer Approach for Efficient and Robustly Stable Bilateral Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel bilateral teleoperation architecture that allows to optimally render the remote interaction force at the local side while guaranteeing a robustly stable behaviour. Stability is guaranteed by ensuring a proper energy exchange between the local and the remote sides. Desired performance is obtained by optimizing the way energy is exploited for generating the behaviour at each side. The effectiveness of the proposed architecture is experimentally validated on a torque-controlled manipulator and in a surgical scenario, using the da Vinci\u00ae Research Kit (dVRK).",
        "primary_area": "",
        "author": "Filippo Loschi;Nicola Piccinelli;Diego Dall\u2019Alba;Riccardo Muradore;Paolo Fiorini;Cristian Secchi;Filippo Loschi;Nicola Piccinelli;Diego Dall\u2019Alba;Riccardo Muradore;Paolo Fiorini;Cristian Secchi",
        "authorids": "/37088999199;/37086529418;/38540860700;/37299825000;/37279139000;/37300905500;/37088999199;/37086529418;/38540860700;/37299825000;/37279139000;/37300905500",
        "aff": "Department of Computer Science, Altair Lab, University of Verona, Italy; Department of Computer Science, Altair Lab, University of Verona, Italy; Department of Computer Science, Altair Lab, University of Verona, Italy; Department of Computer Science, Altair Lab, University of Verona, Italy; Department of Computer Science, Altair Lab, University of Verona, Italy; Department of Science and Methods for Engineering, University of Modena and Reggio Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561542/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6974109438495767048&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "University of Verona;University of Modena and Reggio Emilia",
        "aff_unique_dep": "Department of Computer Science;Department of Science and Methods for Engineering",
        "aff_unique_url": "https://www.univr.it;https://www.unimore.it",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9561829",
        "title": "An Overconstrained Robotic Leg with Coaxial Quasi-direct Drives for Omni-directional Ground Mobility",
        "track": "main",
        "status": "Poster",
        "abstract": "Planar mechanisms dominate modern designs of legged robots with remote actuator placement for robust agility in ground mobility. This paper presents a novel design of robotic leg modules using the Bennett linkage, driven by two coaxially arranged quasi-direct actuators capable of omnidirectional ground locomotion. The Bennett linkage belongs to a family of overconstrained linkages with three-dimensional spatial motion and unparalleled joint axes. We present the first work regarding the design, modeling, and optimization of the Bennett leg module, enabling lateral locomotion, like the crabs, that was not capable with robotic legs designed with common planar mechanisms. We further explored the concept of overconstrained robots, which is a class of advanced robots based on the design reconfiguration of the Bennett leg modules, serving as a potential direction for future research.",
        "primary_area": "",
        "author": "Shihao Feng;Yuping Gu;Weijie Guo;Yuqin Guo;Fang Wan;Jia Pan;Chaoyang Song;Shihao Feng;Yuping Gu;Weijie Guo;Yuqin Guo;Fang Wan;Jia Pan;Chaoyang Song",
        "authorids": "/37088853309;/37089001719;/37088823083;/37089000250;/37086101569;/37535628800;/37086009346;/37088853309;/37089001719;/37088823083;/37089000250;/37086101569;/37535628800;/37086009346",
        "aff": "Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; University of Hong Kong, Pokfulam, Hong Kong; Visiting Scholar With the Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China; Department of Computer Science, University of Hong Kong, Pokfulam, Hong Kong; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, Guangdong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561829/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10602349645460885700&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;1;0",
        "aff_unique_norm": "Southern University of Science and Technology;University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Energy Engineering;",
        "aff_unique_url": "https://www.sustech.edu.cn;https://www.hku.hk",
        "aff_unique_abbr": "SUSTech;HKU",
        "aff_campus_unique_index": "0;0;0;1;0;1;0",
        "aff_campus_unique": "Shenzhen;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561725",
        "title": "An Underactuated Gripper based on Car Differentials for Self-Adaptive Grasping with Passive Disturbance Rejection",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce an underactuated differential-based robot gripper able to perform self-adaptive grasping with passive disturbance rejection. The gripper utilises three car differential systems to achieve self-adaptiveness with a single actuator: a base differential for distributing power from the motor to the fingers, and two independent finger differentials for controlling the proximal and distal joints. Linear and torsional springs are cleverly added to these differentials to allow the return of the fingers and the gripper-object system to equilibrium, thus enabling the gripper rejecting unexpected external forces applied to the fingers after securing a grasp. This novel design provides passive disturbance rejection without implementing complicated control systems and is the main contribution of this paper. Moreover, the differentials allow the gripper to perform not only self-adaptive power grasp but also precision grasp, provide it with a large force transmission efficiency, and facilitate the prediction of grasping position. We analyse the static model of the introduced differential system and evaluate the gripper design via four sets of experiments. Numerical and empirical results clearly demonstrate the viability of the proposed grasper.",
        "primary_area": "",
        "author": "Qiujie Lu;Jinhong Wang;Zhuang Zhang;Genliang Chen;Hao Wang;Nicolas Rojas;Qiujie Lu;Jinhong Wang;Zhuang Zhang;Genliang Chen;Hao Wang;Nicolas Rojas",
        "authorids": "/37086808828;/37089001553;/37088364196;/37085416387;/37085421631;/37990657400;/37086808828;/37089001553;/37088364196;/37085416387;/37085421631;/37990657400",
        "aff": "REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK; REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK; State Key Laboratory of Mechanical Systems and Vibration and the Shanghai Key Laboratory of Digital Manufacture for Thin Walled Structures, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical Systems and Vibration and the Shanghai Key Laboratory of Digital Manufacture for Thin Walled Structures, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical Systems and Vibration and the Shanghai Key Laboratory of Digital Manufacture for Thin Walled Structures, Shanghai Jiao Tong University, Shanghai, China; REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561725/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12673332862129612469&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;0",
        "aff_unique_norm": "Imperial College London;Shanghai Jiao Tong University",
        "aff_unique_dep": "Dyson School of Design Engineering;State Key Laboratory of Mechanical Systems and Vibration",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "ICL;SJTU",
        "aff_campus_unique_index": "0;0;1;1;1;0",
        "aff_campus_unique": "London;Shanghai",
        "aff_country_unique_index": "0;0;1;1;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9560822",
        "title": "An Upper Confidence Bound for Simultaneous Exploration and Exploitation in Heterogeneous Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Heterogeneous multi-robot systems are advantageous for operations in unknown environments because functionally specialised robots can gather environmental information, while others perform tasks. We de ne this decomposition as the scout\u2013task robot architecture and show how it avoids the need to explicitly balance exploration and exploitation by permitting the system to do both simultaneously. The challenge is to guide exploration in a way that improves overall performance for time-limited tasks. We derive a novel upper confidence bound for simultaneous exploration and exploitation based on mutual information and present a general solution for scout\u2013task coordination using decentralised Monte Carlo tree search. We evaluate the performance of our algorithms in a multi-drone surveillance scenario in which scout robots are equipped with low-resolution, long-range sensors and task robots capture detailed information using short-range sensors. The results address a new class of coordination problem for heterogeneous teams that has many practical applications.",
        "primary_area": "",
        "author": "Ki Myung Brian Lee;Felix Kong;Ricardo Cannizzaro;Jennifer L. Palmer;David Johnson;Chanyeol Yoo;Robert Fitch;Ki Myung Brian Lee;Felix Kong;Ricardo Cannizzaro;Jennifer L. Palmer;David Johnson;Chanyeol Yoo;Robert Fitch",
        "authorids": "/37088506983;/37088545936;/37086453725;/37085998803;/37088999378;/37086933786;/38466367800;/37088506983;/37088545936;/37086453725;/37085998803;/37088999378;/37086933786;/38466367800",
        "aff": "University of Technology Sydney, Ultimo, NSW, Australia; University of Technology Sydney, Ultimo, NSW, Australia; Department of Defence, Defence Science and Technology Group, Australia; Department of Defence, Defence Science and Technology Group, Australia; Mission Systems Pty. Ltd., Sydney, Australia; University of Technology Sydney, Ultimo, NSW, Australia; University of Technology Sydney, Ultimo, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560822/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15854600601134407316&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;1;2;0;0",
        "aff_unique_norm": "University of Technology Sydney;Defence Science and Technology Group;Mission Systems Pty. Ltd.",
        "aff_unique_dep": ";Department of Defence;",
        "aff_unique_url": "https://www.uts.edu.au;https://www.dstgroup.com.au;",
        "aff_unique_abbr": "UTS;DST Group;",
        "aff_campus_unique_index": "0;0;2;0;0",
        "aff_campus_unique": "Ultimo;;Sydney",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9561578",
        "title": "An analytical diabolo model for robotic learning and control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a diabolo model that can be used for training agents in simulation to play diabolo, as well as running it on a real dual robot arm system. We first derive an analytical model of the diabolo-string system and compare its accuracy using data recorded via motion capture, which we release as a public dataset of skilled play with diabolos of different dynamics. We show that our model outperforms a deep-learning-based predictor, both in terms of precision and physically consistent behavior. Next, we describe a method based on optimal control to generate robot trajectories that produce the desired diabolo trajectory, as well as a system to transform higher-level actions into robot motions. Finally, we test our method on a real robot system playing the diabolo, and throw it to and catch it from a human player.",
        "primary_area": "",
        "author": "Felix von Drigalski;Devwrat Joshi;Takayuki Murooka;Kazutoshi Tanaka;Masashi Hamaya;Yoshihisa Ijiri;Felix von Drigalski;Devwrat Joshi;Takayuki Murooka;Kazutoshi Tanaka;Masashi Hamaya;Yoshihisa Ijiri",
        "authorids": "/37086063905;/37087323475;/37088341446;/37088507484;/37085532024;/37085621887;/37086063905;/37087323475;/37088341446;/37088507484;/37085532024;/37085621887",
        "aff": "OMRON SINIC X Corporation, Tokyo, Japan; Hosoda Laboratory, The University of Osaka; JSK Laboratory, The University of Tokyo; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON Corporation, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561578/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9720463060738801041&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;0;3",
        "aff_unique_norm": "OMRON SINIC X Corporation;University of Osaka;University of Tokyo;OMRON Corporation",
        "aff_unique_dep": ";Hosoda Laboratory;JSK Laboratory;",
        "aff_unique_url": ";https://www.osaka-u.ac.jp;https://www.u-tokyo.ac.jp;https://www.omron.com",
        "aff_unique_abbr": ";;UTokyo;OMRON",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9560919",
        "title": "An efficient approach to closed-loop shape control of deformable objects using finite element models",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots are nowadays faced with the challenge of handling deformable objects in industrial operations. In particular, the problem of shape control, which aims at giving a specific deformation state to an object, has gained interest recently in the research community. Among the proposed solutions, approaches based on finite elements proved accurate and reliable but also complex and computationally-intensiveIn order to mitigate these drawbacks, we propose a scheme for shape control that does not require to run a real-time simulation or to solve an implicit optimization problem for computing the control outputs. It is based on a partition of the nodal coordinates that allows deriving a control law directly from tangent stiffness matrices. This formulation is also coupled with the introduction of reduced finite element models. Simulation and experimental results in the context of linear deformable object manipulation demonstrate the interest of the proposed approach.",
        "primary_area": "",
        "author": "A. Koessler;N. Roca Filella;B.C. Bouzgarrou;L. Lequi\u00e8vre;J.-A. Corrales Ramon;A. Koessler;N. Roca Filella;B.C. Bouzgarrou;L. Lequi\u00e8vre;J.-A. Corrales Ramon",
        "authorids": "/37086180046;/37088998534;/37078602100;/37586981400;/37353717200;/37086180046;/37088998534;/37078602100;/37586981400;/37353717200",
        "aff": "Clermont Auvergne INP, CNRS, Institut Pascal, Universit\u00e9 Clermont Auvergne, France; Clermont Auvergne INP, CNRS, Institut Pascal, Universit\u00e9 Clermont Auvergne, France; Clermont Auvergne INP, CNRS, Institut Pascal, Universit\u00e9 Clermont Auvergne, France; Clermont Auvergne INP, CNRS, Institut Pascal, Universit\u00e9 Clermont Auvergne, France; Centro Singular de Investigaci\u00f3n en Tecnolox\u00edas Intelixentes (CiTIUS), Universidade de Santiago de Compostela, Santiago de Compostela, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560919/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4213779436073835433&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Universit\u00e9 Clermont Auvergne;Universidade de Santiago de Compostela",
        "aff_unique_dep": ";Centro Singular de Investigaci\u00f3n en Tecnolox\u00edas Intelixentes (CiTIUS)",
        "aff_unique_url": "https://www.uca.fr;https://www.usc.es",
        "aff_unique_abbr": "UCA;USC",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Santiago de Compostela",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "France;Spain"
    },
    {
        "id": "9561282",
        "title": "An integrated approach for determining objects to be relocated and their goal positions inside clutter for object retrieval",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of rearranging objects in a cluttered and confined space using a robotic manipulator. The goal is to retrieve a target object from the clutter where the target is occluded by other objects. In situations where overhand grasps are not allowed, the robot needs to remove some objects to make the target accessible. In the course of removing the objects, the robot also needs to determine the locations to place the removed objects. If the robot can access enough empty spaces around or inside the clutter, the placement of the objects is trivially simple. If empty spaces are scarce, placing objects should be done in a principled way as an incorrect placement would deplete the empty spaces quickly.In this work, we propose a method that solves the problems of what and where to relocate objects inside the clutter to retrieve the target. Previously, there have been several efficient methods proposed that deal with each of the what and where to relocate problems separately. We solve the problems together using a graph structure constructed from an object configuration. Also, the method runs fast so scalable in the number of objects. Compared to a state-of-the-art method, our method reduces task and motion planning time up to 74.9% (at least 56.7%) and has a higher success rate under a short time limit for planning, which is 3 minutes.",
        "primary_area": "",
        "author": "Jeeho Ahn;Jaeho Lee;Sang Hun Cheong;ChangHwan Kim;Changjoo Nam;Jeeho Ahn;Jaeho Lee;Sang Hun Cheong;ChangHwan Kim;Changjoo Nam",
        "authorids": "/37088999970;/37088998428;/37087069759;/37292328800;/37086294341;/37088999970;/37088998428;/37087069759;/37292328800;/37086294341",
        "aff": "Korea Institute of Science and Technology; Korea Institute of Science and Technology; SK Telecom; Korea Institute of Science and Technology; Inha University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561282/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4202390213334131853&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "Korea Institute of Science and Technology;SK Telecom;Inha University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.kist.re.kr;https://www.sktelecom.com;https://www.inha.edu/",
        "aff_unique_abbr": "KIST;SKT;Inha",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561065",
        "title": "Analysis of Open-Loop Grasping From Piles",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper offers an explanation of why humans can effortlessly grasp objects from a pile. We identified a regularity in objects\u2019 motion when pushed, namely, an object separates and stabilizes in front of the pusher. We devise an open-loop grasping strategy leveraging this regularity in piles of nearly identical objects. Our real robot robustly grasps round objects beside a wall with success rates between 95% and 100% without visual or tactile feedback. We analyze our grasping strategy extensively both in real-world and simulated experiments. We observe that object roundness improves grasping and the motion pattern also manifests in small piles beside a wall. Our qualitative simulation can approximate the real robot\u2019s grasping behavior, and we apply open-loop grasping in an warehouse pick-and-place application.",
        "primary_area": "",
        "author": "El\u0151d P\u00e1ll;Oliver Brock;El\u0151d P\u00e1ll;Oliver Brock",
        "authorids": "/37085546046;/37279727100;/37085546046;/37279727100",
        "aff": "Robotics and Biology Laboratory, Technische Universit\u00e4t Berlin, Germany; Robotics and Biology Laboratory, Technische Universit\u00e4t Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561065/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5715705664465462068&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Berlin",
        "aff_unique_dep": "Robotics and Biology Laboratory",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561652",
        "title": "Analyzing Human Models that Adapt Online",
        "track": "main",
        "status": "Poster",
        "abstract": "Predictive human models often need to adapt their parameters online from human data. This raises previously ignored safety-related questions for robots relying on these models such as what the model could learn online and how quickly could it learn it. For instance, when will the robot have a confident estimate in a nearby human\u2019s goal? Or, what parameter initializations guarantee that the robot can learn the human\u2019s preferences in a finite number of observations? To answer such analysis questions, our key idea is to model the robot\u2019s learning algorithm as a dynamical system where the state is the current model parameter estimate and the control is the human data the robot observes. This enables us to leverage tools from reachability analysis and optimal control to compute the set of hypotheses the robot could learn in finite time, as well as the worst and best-case time it takes to learn them. We demonstrate the utility of our analysis tool in four human-robot domains, including autonomous driving and indoor navigation.",
        "primary_area": "",
        "author": "Andrea Bajcsy;Anand Siththaranjan;Claire J. Tomlin;Anca D. Dragan;Andrea Bajcsy;Anand Siththaranjan;Claire J. Tomlin;Anca D. Dragan",
        "authorids": "/37086934087;/37089000224;/37271692600;/37960625200;/37086934087;/37089000224;/37271692600;/37960625200",
        "aff": "UC Berkeley EECS; UC Berkeley EECS; UC Berkeley EECS; UC Berkeley EECS",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561652/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5281501127681871114&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561373",
        "title": "Analyzing Neural Jacobian Methods in Applications of Visual Servoing and Kinematic Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing adaptable control laws that can transfer between different robots is a challenge because of kinematic and dynamic differences, as well as in scenarios where external sensors are used. In this work, we empirically investigate a neural networks ability to approximate the Jacobian matrix for an application in Cartesian control schemes. Specifically, we are interested in approximating the kinematic Jacobian, which arises from kinematic equations mapping a manipulator\u2019s joint angles to the end-effector\u2019s location. We propose two different approaches to learn the kinematic Jacobian. The first method arises from visual servoing where we learn the kinematic Jacobian as an approximate linear system of equations from the k-nearest neighbors for a desired joint configuration. The second, motivated by forward models in machine learning, learns the kinematic behavior directly and calculates the Jacobian by differentiating the learned neural kinematics model. Simulation experimental results show that both methods achieve better performance than alternative data-driven methods for control, provide closer approximations to the proper kinematics Jacobian matrix, and on average produce better-conditioned Jacobian matrices. Real-world experiments were conducted on a Kinova Gen-3 lightweight robotic manipulator, which includes an uncalibrated visual servoing experiment, a practical application of our methods, as well as a 7-DOF point-to-point task highlighting that our methods are applicable on real robotic manipulators.",
        "primary_area": "",
        "author": "Michael Przystupa;Masood Dehghan;Martin Jagersand;A. Rupam Mahmood;Michael Przystupa;Masood Dehghan;Martin Jagersand;A. Rupam Mahmood",
        "authorids": "/37088998333;/37951137300;/37269568300;/37408373700;/37088998333;/37951137300;/37269568300;/37408373700",
        "aff": "Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada; Department of Computing Science, University of Alberta, Edmonton, AB, Canada; CIFAR AI Chair, Alberta Machine Intelligence Institute (Amii)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561373/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6323229998912295735&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Alberta;Alberta Machine Intelligence Institute",
        "aff_unique_dep": "Department of Computing Science;AI Chair",
        "aff_unique_url": "https://www.ualberta.ca;https://www.amii.ca",
        "aff_unique_abbr": "UAlberta;Amii",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Edmonton;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561022",
        "title": "Anticipatory Navigation in Crowds by Probabilistic Prediction of Pedestrian Future Movements",
        "track": "main",
        "status": "Poster",
        "abstract": "Critical for the coexistence of humans and robots in dynamic environments is the capability for agents to understand each other\u2019s actions, and anticipate their movements. This paper presents Stochastic Process Anticipatory Navigation (SPAN), a framework that enables nonholonomic robots to navigate in environments with crowds, while anticipating and accounting for the motion patterns of pedestrians. To this end, we learn a predictive model to predict continuous-time stochastic processes to model future movement of pedestrians. Anticipated pedestrian positions are used to conduct chance constrained collision-checking, and are incorporated into a time-to-collision control problem. An occupancy map is also integrated to allow for probabilistic collision-checking with static obstacles. We demonstrate the capability of SPAN in crowded simulation environments, as well as with a real-world pedestrian dataset.",
        "primary_area": "",
        "author": "Weiming Zhi;Tin Lai;Lionel Ott;Fabio Ramos;Weiming Zhi;Tin Lai;Lionel Ott;Fabio Ramos",
        "authorids": "/37086936558;/37086935412;/38251784400;/37285364500;/37086936558;/37086935412;/38251784400;/37285364500",
        "aff": "School of Computer Science, The University of Sydney, Australia; School of Computer Science, The University of Sydney, Australia; School of Computer Science, The University of Sydney, Australia; NVIDIA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561022/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5475706262980737615&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Sydney;NVIDIA",
        "aff_unique_dep": "School of Computer Science;NVIDIA",
        "aff_unique_url": "https://www.sydney.edu.au;https://www.nvidia.com",
        "aff_unique_abbr": "USYD;NV",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "9560952",
        "title": "Anticipatory Path Planning for Continuum Arms in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Continuum arms are more adaptable to their environments and inherently human-friendly compared to their rigid counterparts. Path planning of continuum arms is an active research area with many challenges. The hyper-redundancy of continuum arms, which renders them highly versatile, is their curse in path planning. This problem becomes even more challenging in dynamic environments in the presence of mobile obstacles. In this paper, we propose an anticipatory path planning approach for continuum arms in dynamic environments. Our approach is based on obstacle prediction coupled with temporal graphs to model the dynamic environment. We evaluate the proposed approach\u2019s performance and compare it to prevailing path planning approaches for continuum arms in dynamic environments.",
        "primary_area": "",
        "author": "Brandon H. Meng;Dimuthu D. K. Arachchige;Jiahao Deng;Isuru S. Godage;Iyad Kanj;Brandon H. Meng;Dimuthu D. K. Arachchige;Jiahao Deng;Isuru S. Godage;Iyad Kanj",
        "authorids": "/37086843091;/37088945620;/37086841664;/37946220700;/37284504800;/37086843091;/37088945620;/37086841664;/37946220700;/37284504800",
        "aff": "School of Computing, DePaul University, Chicago, IL, USA; School of Computing, DePaul University, Chicago, IL, USA; School of Computing, DePaul University, Chicago, IL, USA; School of Computing, DePaul University, Chicago, IL, USA; School of Computing, DePaul University, Chicago, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560952/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2407025706790344536&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "DePaul University",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.depaul.edu",
        "aff_unique_abbr": "DePaul",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562070",
        "title": "Anticipatory Planning and Dynamic Lost Person Models for Human-Robot Search and Rescue",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we consider the problem of planning paths for a team of autonomous unmanned aerial vehicles (UAVs) to assist search and rescue practitioners. To address the problem, we develop a fully integrated framework that includes information from all aspects of the search environment. We take into consideration lost person motion via a behavior-based predictive model, anticipated human searcher trajectories, as well as measurements from fixed field of view sensors on board UAVs. We use a metric of posterior risk as the optimization target as it is an indicator of improved situational awareness and the effectiveness of continuing search efforts. Monte Carlo simulations are presented to demonstrate the effectiveness of the proposed framework.",
        "primary_area": "",
        "author": "Larkin Heintzman;Amanda Hashimoto;Nicole Abaid;Ryan K. Williams;Larkin Heintzman;Amanda Hashimoto;Nicole Abaid;Ryan K. Williams",
        "authorids": "/37086596250;/37089000520;/37545444400;/38238005300;/37086596250;/37089000520;/37545444400;/38238005300",
        "aff": "Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; Engineering Mechanics Program, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; Department of Mathematics, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA; Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562070/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18443762738103697113&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Virginia Polytechnic Institute and State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561944",
        "title": "Anytime Fault-tolerant Adaptive Routing for Multi-Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "The Correlated Team Orienteering Problem (CTOP) is a routing problem where the objective is to determine a set of routes that maximizes the summation of collected rewards in the environment while respecting the vehicles\u2019 budget. However, solutions to this problem usually consider static instances and may produce poor results in dynamic real-world scenarios. In this paper, we propose an approach to deal with the execution of missions planned as a CTOP instance, especially when vehicles of the team are prone to failure and may not complete their routes. The main contribution of this paper is a novel anytime heuristic that iteratively adapts the initial set of routes, allowing to increase the overall robustness of the mission and still collect the most profitable rewards. The methodology was thoroughly evaluated considering different scenarios and in all the cases was able to achieve comparable or better results in terms of reward than planning a new set of routes, however, spending considerably less time.",
        "primary_area": "",
        "author": "Ronaldo F. dos Santos;Erickson R. Nascimento;Douglas G. Macharet;Ronaldo F. dos Santos;Erickson R. Nascimento;Douglas G. Macharet",
        "authorids": "/37088997841;/38099290700;/37590114800;/37088997841;/38099290700;/37590114800",
        "aff": "Tres Lagoas Campus, Universidade\u02c6 Federal de Mato Grosso do Sul, MS, Brazil; Department of Computer Science, Computer Vision and Robotics Laboratory (VeRLab), Universidade Federal de Minas Gerais, MG, Brazil; Department of Computer Science, Computer Vision and Robotics Laboratory (VeRLab), Universidade Federal de Minas Gerais, MG, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561944/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9802189230994991381&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Universidade Federal de Mato Grosso do Sul;Universidade Federal de Minas Gerais",
        "aff_unique_dep": ";Department of Computer Science",
        "aff_unique_url": ";http://www.ufmg.br",
        "aff_unique_abbr": ";UFMG",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Tres Lagoas;MG",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Brazil"
    },
    {
        "id": "9561463",
        "title": "Anytime Game-Theoretic Planning with Active Reasoning About Humans\u2019 Latent States for Human-Centered Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "A human-centered robot needs to reason about the cognitive limitation and potential irrationality of its human partner to achieve seamless interactions. This paper proposes an anytime game-theoretic planner that integrates iterative reasoning models, a partially observable Markov decision process, and chance-constrained Monte-Carlo belief tree search for robot behavioral planning. Our planner enables a robot to safely and actively reason about its human partner\u2019s latent cognitive states (bounded intelligence and irrationality) in real-time to maximize its utility better. We validate our approach in an autonomous driving domain where our behavioral planner and a low-level motion controller hierarchically control an autonomous car to negotiate traffic merges. Simulations and user studies are conducted to show our planner\u2019s effectiveness.",
        "primary_area": "",
        "author": "Ran Tian;Liting Sun;Masayoshi Tomizuka;David Isele;Ran Tian;Liting Sun;Masayoshi Tomizuka;David Isele",
        "authorids": "/37085997198;/37085425729;/37281933000;/37086124264;/37085997198;/37085425729;/37281933000;/37086124264",
        "aff": "UC Berkeley; UC Berkeley; UC Berkeley; Honda Research Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561463/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8118450198740216530&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of California, Berkeley;Honda Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.honda-ri.com",
        "aff_unique_abbr": "UC Berkeley;HRI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9561704",
        "title": "Appearance-based Loop Closure Detection via Bidirectional Manifold Representation Consensus",
        "track": "main",
        "status": "Poster",
        "abstract": "Loop closure detection (LCD), which aims to deal with the drift emerging when robots travel around the route, plays a key role in a simultaneous localization and mapping system. Unlike most current methods which focus on seeking an appropriate representation of images, we propose a novel two-stage pipeline dominated by the estimation of spatial geometric relationship. When a query image occurs, we select candidates on-line according to the similarity of global semantic features in the first stage, and then conduct robust geometric confirmation to verify true loop-closing pairs in the second stage. To this end, a robust feature matching algorithm, termed as bidirectional manifold representation consensus (BMRC), is proposed. In particular, we utilize manifold representation to construct local neighborhood structures of feature points and formulate the matching problem into an optimization model, enabling linearithmic time complexity via a closed-form solution. Furthermore, we propose a dynamic place partition strategy based on BMRC to segment image streams with similar content into a place, which can mine more valid candidate frames, improving the recall rate of the whole system. Extensive experiments on several publicly available datasets reveal that BMRC has a good performance in the general feature matching task and the proposed pipeline outperforms the current state-of-the-art approaches in the LCD task.",
        "primary_area": "",
        "author": "Kaining Zhang;Zizhuo Li;Jiayi Ma;Kaining Zhang;Zizhuo Li;Jiayi Ma",
        "authorids": "/37089000357;/37089000926;/37966025300;/37089000357;/37089000926;/37966025300",
        "aff": "Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China; Electronic Information School, Wuhan University, Wuhan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561704/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14963943970880643818&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Wuhan University",
        "aff_unique_dep": "Electronic Information School",
        "aff_unique_url": "http://www.whu.edu.cn/",
        "aff_unique_abbr": "WHU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Wuhan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561453",
        "title": "Applications: Twisted String Actuation-based Compact Automatic Transmission",
        "track": "main",
        "status": "Poster",
        "abstract": "Input-output transmission ratio shifting mechanisms provide a variable transmission ratio, which effectively expands a speed-force operating range of actuators. Although it is the most effective solution to increase the performance of robotic systems, its application to compact robotic systems still remains a challenging issue due to its complexity and massive structure. In this paper, we introduce a twisted string actuation-based transmission module for compact robotic systems. The twisted string mechanism provides a simplified transmission design and a compact form factor of the transmission module. An automatic transmission shifting algorithm is proposed for effective and autonomous control strategies. The developed prototype is integrated into a robotic gripper/hand, and its performance is verified with grasping demonstrations.",
        "primary_area": "",
        "author": "Seokhwan Jeong;Yeongseok Lee;Kyung-Soo Kim;Seokhwan Jeong;Yeongseok Lee;Kyung-Soo Kim",
        "authorids": "/37087324027;/37088924577;/37292681500;/37087324027;/37088924577;/37292681500",
        "aff": "Department of Mechanical Engineering, Sogang University, Seoul, South Korea; Mechanical Engineering Department, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Mechanical Engineering Department, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561453/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12134174555114740157&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Sogang University;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering;Mechanical Engineering Department",
        "aff_unique_url": "http://www.sogang.ac.kr;https://www.kaist.ac.kr",
        "aff_unique_abbr": "Sogang;KAIST",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Seoul;Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9560916",
        "title": "Approximate Inverse Reinforcement Learning from Vision-based Imitation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a method for obtaining an implicit objective function for vision-based navigation. The proposed methodology relies on Imitation Learning, Model Predictive Control (MPC), and an interpretation technique used in Deep Neural Networks. We use Imitation Learning as a means to do Inverse Reinforcement Learning in order to create an approximate cost function generator for a visual navigation challenge. The resulting cost function, the costmap, is used in conjunction with MPC for real-time control and outperforms other state-of-the-art costmap generators in novel environments. The proposed process allows for simple training and robustness to out-of-sample data. We apply our method to the task of vision-based autonomous driving in multiple real and simulated environments and show its generalizability. Supplementary video: https://youtu.be/WyJfT5lc0aQ",
        "primary_area": "",
        "author": "Keuntaek Lee;Bogdan Vlahov;Jason Gibson;James M. Rehg;Evangelos A. Theodorou;Keuntaek Lee;Bogdan Vlahov;Jason Gibson;James M. Rehg;Evangelos A. Theodorou",
        "authorids": "/37086938143;/37086612248;/37087413994;/37272058600;/37546007800;/37086938143;/37086612248;/37087413994;/37272058600;/37546007800",
        "aff": "Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA; Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560916/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5932443014814057314&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561655",
        "title": "Approximate Solutions to a Class of Reachability Games",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a method for finding approximate Nash equilibria in a broad class of reachability games. These games are often used to formulate both collision avoidance and goal satisfaction. Our method is computationally efficient, running in real-time for scenarios involving multiple players and more than ten state dimensions. The proposed approach forms a family of increasingly exact approximations to the original game. Our results characterize the quality of these approximations and show operation in a receding horizon, minimally-invasive control context. Additionally, as a special case, our method reduces to local gradient-based optimization in the single-player (optimal control) setting, for which a wide variety of efficient algorithms exist.",
        "primary_area": "",
        "author": "David Fridovich-Keil;Claire J. Tomlin;David Fridovich-Keil;Claire J. Tomlin",
        "authorids": "/37086041251;/37271692600;/37086041251;/37271692600",
        "aff": "Department of Aeronautics & Astronautics, Stanford University; Department of Electrical Engineering & Computer Sciences, UC, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561655/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12845693577501155545&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Stanford University;University of California, Berkeley",
        "aff_unique_dep": "Department of Aeronautics & Astronautics;Department of Electrical Engineering & Computer Sciences",
        "aff_unique_url": "https://www.stanford.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "Stanford;UC Berkeley",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Stanford;Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561456",
        "title": "Approximating Constraint Manifolds Using Generative Models for Sampling-Based Constrained Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Sampling-based motion planning under task constraints is challenging because the null-measure constraint manifold in the configuration space makes rejection sampling extremely inefficient, if not impossible. This paper presents a learning-based sampling strategy for constrained motion planning problems. We investigate the use of two well-known deep generative models, the Conditional Variational Autoencoder (CVAE) and the Conditional Generative Adversarial Net (CGAN), to generate constraint-satisfying sample configurations. Instead of precomputed graphs, we use generative models conditioned on constraint parameters for approximating the constraint manifold. This approach allows for the efficient drawing of constraint-satisfying samples online without any need for modification of available sampling-based motion planning algorithms. We evaluate the efficiency of these two generative models in terms of their sampling accuracy and coverage of sampling distribution. Simulations and experiments are also conducted for different constraint tasks on two robotic platforms.",
        "primary_area": "",
        "author": "Cihan Acar;Keng Peng Tee;Cihan Acar;Keng Peng Tee",
        "authorids": "/37088854551;/37275857100;/37088854551;/37275857100",
        "aff": "Institute for Infocomm Research (I2R), A*STAR, Singapore; Institute for Infocomm Research (I2R), A*STAR, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561456/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5259571535828483850&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Institute for Infocomm Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.i2r.a-star.edu.sg",
        "aff_unique_abbr": "I2R",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9561414",
        "title": "Arm-Hand Systems As Hybrid Parallel-Serial Systems: A Novel Inverse Kinematics Solution",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we aim to solve inverse kinematics of the integrated robotic arm-hand systems to achieve precision grasping, provided the desired grasp configuration (contact points + contact normals). The key insights of our approach are three-fold. First, we propose a human-inspired thumb-first strategy and consider one finger of the robotic hand as the \"thumb\" to narrow down the search space and increase the success rate of the algorithm. Second, we formulate the arm-thumb serial chain as a closed chain while other fingers are still as serial chains such that the entire arm-hand system is controlled as a hybrid parallel-serial system. The closed-chain formulation truncates and simplifies the task hierarchy of the entire arm-hand system. Third, we attach a virtual revolute joint to the thumb\u2019s tip with its rotation axis aligning with the thumb\u2019s contact normal to allow this virtual joint to act as the embodiment of the thumb\u2019s functional redundancy. By selecting the thumb\u2019s joints including the virtual revolute joint as the active joints of the arm-thumb closed chain, the arm-thumb system\u2019s self-motion (i.e., the palm pose) and the thumb\u2019s functional redundancy can be directly controlled without using the null space projection. This provides a new possibility to control the self-motion of robot manipulators. Simulation results will demonstrate the advantages and superb performance of the proposed approach for solving the problem of inverse kinematics of achieving precision grasps compared to other classical approaches based on the Damped Least-Squares method [1] in terms of the average success rate (96% v.s. 12%).",
        "primary_area": "",
        "author": "Shuwei Qiu;Mehrdad R. Kermani;Shuwei Qiu;Mehrdad R. Kermani",
        "authorids": "/37088462355;/37266294100;/37088462355;/37266294100",
        "aff": "Department of Electrical and Computer Engineering, Western University, London, Ontario, Canada; Department of Electrical and Computer Engineering, Western University, London, Ontario, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561414/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18115151711934980696&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Western University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.uwo.ca",
        "aff_unique_abbr": "Western",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561246",
        "title": "Artificial Neural Networks to Solve Forward Kinematics of a Wearable Parallel Robot with Semi-rigid Links",
        "track": "main",
        "status": "Poster",
        "abstract": "Wearable robots are designed to provide physical assistance and rehabilitation training. Light-weight designs are desirable for human usage and parallel robots are quite suitable due to low moving inertia. One of the challenges of using wearable parallel robots is to compute the end-effector position/orientation from joint angle measurements, as the forward kinematics problem is computationally difficult. It becomes even more challenging if the kinematic model changes from the nominal model due to deflection of the mechanical members, manufacturing tolerances, or misalignments of the joints between the machine and the user.Artificial neural networks have been used to provide solution of the forward kinematics problem for parallel robots. However, their efficacy has not yet been studied in wearable applications where the linkages of the robots are not fully rigid. In this paper, we conducted a case study to investigate the performance of using neural network models to compute forward kinematics of a wearable robot. Our results show that the performance of neural networks is superior to numerical approaches and produces reasonable solutions even at the boundary of the robot workspace.",
        "primary_area": "",
        "author": "Antonio Prado;Haohan Zhang;Sunil K. Agrawal;Antonio Prado;Haohan Zhang;Sunil K. Agrawal",
        "authorids": "/37086063498;/37086027856;/37281455400;/37086063498;/37086027856;/37281455400",
        "aff": "Department of Mechanical Engineering, Robotics and Rehabilitation Laboratory, Columbia University, New York, NY, USA; Department of Mechanical Engineering, Robotics and Rehabilitation Laboratory, Columbia University, New York, NY, USA; Department of Rehabilitation and Regenerative Medicine, Columbia University Medical Center, New York, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561246/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1980788238526002903&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Columbia University;Columbia University Medical Center",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Rehabilitation and Regenerative Medicine",
        "aff_unique_url": "https://www.columbia.edu;https://www.columbia.edu",
        "aff_unique_abbr": "Columbia;CUMC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561925",
        "title": "Assembly Sequences Based on Multiple Criteria Against Products with Deformable Parts",
        "track": "main",
        "status": "Poster",
        "abstract": "To generate assembly sequences that robots can easily handle, this study tackled assembly sequence generation (ASG) by considering two tradeoff objectives: (1) insertion conditions and (2) degrees of the constraints affecting the assembled parts. We propose a multi-objective genetic algorithm to balance these two objectives. Furthermore, we extend our previously proposed 3D computer-aided design (CAD)-based method for extracting three types of two-part relationship matrices from 3D models that include deformable parts. The interference between deformable and other parts can be determined using scaled part shapes. Our proposed ASG can produce Pareto-optimal sequences for multi-component models with deformable parts such as rubber bands, rubber belts, and roller chains. We further discuss the limitation and applicability of the generated sequences to robotic assembly.",
        "primary_area": "",
        "author": "Takuya Kiyokawa;Jun Takamatsu;Tsukasa Ogasawara;Takuya Kiyokawa;Jun Takamatsu;Tsukasa Ogasawara",
        "authorids": "/37086694759;/37324010500;/37269488400;/37086694759;/37324010500;/37269488400",
        "aff": "Division of Information Science, Robotics Laboratory, Nara Institute of Science and Technology (NAIST), Japan; Division of Information Science, Robotics Laboratory, Nara Institute of Science and Technology (NAIST), Japan; Division of Information Science, Robotics Laboratory, Nara Institute of Science and Technology (NAIST), Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561925/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1528646872811725903&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nara Institute of Science and Technology",
        "aff_unique_dep": "Division of Information Science, Robotics Laboratory",
        "aff_unique_url": "https://www.naist.jp",
        "aff_unique_abbr": "NAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9560949",
        "title": "Assistive supernumerary grasping with the back of the hand",
        "track": "main",
        "status": "Poster",
        "abstract": "The Dorsal Grasper, an assistive wearable grasping device, incorporates supernumerary fingers and an artificial palm with the forearm and back of the hand, respectively. It enables power wrap grasping and adduction pinching with its V-shaped soft fingers. Designed with C6/C7 spinal cord injury in mind, it takes advantage of active wrist extension that remains in this population after injury. We propose that allowing the operator to actively participate in applying grasp forces on the object, using the back of the hand, enables intuitive, fast and reliable grasping relevant for the execution of activities of daily living. Functional grasping is tested in three normative subjects and a person with C6 SCI using the Grasp and Release Test. Results indicate that this device provides promising performance on a subset of objects that complements the existing compensatory strategies used by people with C6/C7 SCI. We find that the addition of the artificial palm is important for increasing maximum grip strength, by increasing contact friction and protecting the opisthenar.",
        "primary_area": "",
        "author": "Jungpyo Lee;Licheng Yu;Lucie Derbier;Hannah S. Stuart;Jungpyo Lee;Licheng Yu;Lucie Derbier;Hannah S. Stuart",
        "authorids": "/37088998357;/37089000958;/37088997159;/37085437460;/37088998357;/37089000958;/37088997159;/37085437460",
        "aff": "Dept. of Mechanical Engineering, University of California at Berkeley, Berkeley, CA, USA; Dept. of Mechanical Engineering, University of California at Berkeley, Berkeley, CA, USA; Delta V Biomechanics, Inc, Palo Alto, CA, USA; Dept. of Mechanical Engineering, University of California at Berkeley, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560949/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2818193939286886130&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;Delta V Biomechanics, Inc",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.berkeley.edu;",
        "aff_unique_abbr": "UC Berkeley;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Berkeley;Palo Alto",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561671",
        "title": "Assumption Monitoring Using Runtime Verification for UAV Temporal Task Plan Executions",
        "track": "main",
        "status": "Poster",
        "abstract": "Temporal task planning guarantees a robot will succeed in its task as long as certain explicit and implicit assumptions about the robot\u2019s operating environment, sensors, and capabilities hold. A robot executing a plan can silently fail to fulfill the task if the assumptions are violated at runtime. Monitoring assumption violations at runtime can flag silent failures and also provide mitigation and remediation opportunities. However, this requires means for describing assumptions combining temporal and quantitative data, automatic construction of correct monitors and ensuring a correct interplay between the planning execution and monitors. In this paper we propose combining temporal planning with stream runtime verification, which offers a high-level language to describe monitors together with guarantees on execution time and memory usage. We demonstrate our approach both in real and simulated flights for some typical mission scenarios.",
        "primary_area": "",
        "author": "Sebasti\u00e1n Zudaire;Felipe Gorostiaga;C\u00e9sar S\u00e1nchez;Gerardo Schneider;Sebasti\u00e1n Uchitel;Sebasti\u00e1n Zudaire;Felipe Gorostiaga;C\u00e9sar S\u00e1nchez;Gerardo Schneider;Sebasti\u00e1n Uchitel",
        "authorids": "/37088506523;/37086462724;/37086461584;/37086417679;/37283369600;/37088506523;/37086462724;/37086461584;/37086417679;/37283369600",
        "aff": "Instituto Balseiro - Univ. Nacional de Cuyo, Argentina; CIFASIS, Argentina; IMDEA Software Institute, Spain; Univ. of Gothenburg, Sweden; Imperial College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561671/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5156823960963288638&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "Univ. Nacional de Cuyo;CIFASIS;IMDEA Software Institute;University of Gothenburg;Imperial College London",
        "aff_unique_dep": "Instituto Balseiro;;;;",
        "aff_unique_url": "https://www.uncuyo.edu.ar;;https://www.imdea.org/;https://www.gu.se;https://www.imperial.ac.uk",
        "aff_unique_abbr": "UNCuyo;;IMDEA;GU;ICL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;2;3",
        "aff_country_unique": "Argentina;Spain;Sweden;United Kingdom"
    },
    {
        "id": "9560836",
        "title": "Asymptotically Optimal Kinodynamic Planning Using Bundles of Edges",
        "track": "main",
        "status": "Poster",
        "abstract": "Using sampling to estimate the connectivity of high-dimensional configuration spaces has been the theoretical underpinning for effective sampling-based motion planners. Typical strategies either build a roadmap, or a tree as the underlying search structure that connects sampled configurations, with a focus on guaranteeing completeness and optimality as the number of samples tends to infinity. Roadmap-based planners allow preprocessing the space, and can solve multiple kinematic motion planning problems, but need a steering function to connect pairwise-states. Such steering functions are difficult to define for kinodynamic systems, and limit the applicability of roadmaps to motion planning problems with dynamical systems. Recent advances in the analysis of single-query tree-based planners has shown that forward search trees based on random propagations are asymptotically optimal. The current work leverages these recent results and proposes a multi-query framework for kinodynamic planning. Bundles of kinodynamic edges can be sampled to cover the state space before the query arrives. Then, given a motion planning query, the connectivity of the state space reachable from the start can be recovered from a forward search tree reasoning about a local neighborhood of the edge bundle from each tree node. The work demonstrates theoretically that considering any constant radial neighborhood during this process is sufficient to guarantee asymptotic optimality. Experimental validation in five and twelve dimensional simulated systems also highlights the ability of the proposed edge bundles to express high-quality kinodynamic solutions. Our approach consistently finds higher quality solutions compared to SST, and RRT, often with faster initial solution times. The strategy of sampling kinodynamic edges is demonstrated to be a promising new paradigm.",
        "primary_area": "",
        "author": "Rahul Shome;Lydia E. Kavraki;Rahul Shome;Lydia E. Kavraki",
        "authorids": "/37085557993;/37279015600;/37085557993;/37279015600",
        "aff": "Dept. of Computer Science, Rice University; Dept. of Computer Science, Rice University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560836/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13886634919355767539&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Dept. of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561481",
        "title": "Asynchronous Multi-View SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing multi-camera SLAM systems assume synchronized shutters for all cameras, which is often not the case in practice. In this work, we propose a generalized multi-camera SLAM formulation which accounts for asynchronous sensor observations. Our framework integrates a continuous-time motion model to relate information across asynchronous multi-frames during tracking, local mapping, and loop closing. For evaluation, we collected AMV-Bench, a challenging new SLAM dataset covering 482 km of driving recorded using our asynchronous multi-camera robotic platform. AMV-Bench is over an order of magnitude larger than previous multi-view HD outdoor SLAM datasets, and covers diverse and challenging motions and environments. Our experiments emphasize the necessity of asynchronous sensor modeling, and show that the use of multiple cameras is critical towards robust and accurate SLAM in challenging outdoor scenes. The supplementary material is located at: https://www.cs.toronto.edu/~ajyang/amv-slam",
        "primary_area": "",
        "author": "Anqi Joyce Yang;Can Cui;Ioan Andrei B\u00e2rsan;Raquel Urtasun;Shenlong Wang;Anqi Joyce Yang;Can Cui;Ioan Andrei B\u00e2rsan;Raquel Urtasun;Shenlong Wang",
        "authorids": "/37088997061;/37088999367;/37086454262;/37269502900;/37085699650;/37088997061;/37088999367;/37086454262;/37269502900;/37085699650",
        "aff": "University of Toronto; University of Waterloo; University of Toronto; University of Toronto; University of Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561481/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4947858065766583176&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University of Toronto;University of Waterloo",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utoronto.ca;https://uwaterloo.ca",
        "aff_unique_abbr": "U of T;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9560770",
        "title": "Asynchronous Reliability-Aware Multi-UAV Coverage Path Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Graceful degradation is a potential advantage of Multi-Robot Systems over Single-Robot Systems. In aerial robotics applications, such as infrastructure inspection, this trait is desirable as it would improve mission reliability despite the use of failure-prone low-cost drones. The Reliability-Aware Multi-Agent Coverage Path Planning (RA-MCPP) problem finds path plans for each robot to maximise the probability of mission completion by a given deadline. This paper proposes a path planner for RA-MCPP formulated in continuous time, enabling more complex realistic environments to be considered. The proposed method (i) extends a reliability evaluation framework to evaluate the Probability of Completion metric on asynchronous strategies on non-unit lattice graph environments, and (ii) introduces a greedy-genetic meta-heuristic optimisation method as a scalable and accurate RA-MCPP solver. This method is shown to provide plans with higher reliability when compared with existing approaches in three real inspection scenarios.",
        "primary_area": "",
        "author": "Mickey Li;Arthur Richards;Mahesh Sooriyabandara;Mickey Li;Arthur Richards;Mahesh Sooriyabandara",
        "authorids": "/37088998842;/37299756300;/37330935600;/37088998842;/37299756300;/37330935600",
        "aff": "Bristol Robotics Laboratory, University of Bristol, Bristol, UK; Bristol Robotics Laboratory, University of Bristol, Bristol, UK; Bristol Research and Innovation Laboratory, Toshiba Research Europe Ltd, Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560770/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5195229587849947743&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Bristol;Toshiba Research Europe Ltd",
        "aff_unique_dep": "Bristol Robotics Laboratory;Bristol Research and Innovation Laboratory",
        "aff_unique_url": "https://www.bristol.ac.uk;https://www.toshiba.eu/research/",
        "aff_unique_abbr": "UoB;TREL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bristol",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561154",
        "title": "Attention-Based Probabilistic Planning with Active Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Attention control is a key cognitive ability for humans to select information relevant to the current task. This paper develops a computational model of attention and an algorithm for attention-based probabilistic planning in Markov decision processes. In attention-based planning, the robot decides to be in different attention modes. An attention mode corresponds to a subset of state variables monitored by the robot. By switching between different attention modes, the robot actively perceives task-relevant information to reduce the cost of information acquisition and processing, while achieving near-optimal task performance. Though planning with attention-based active perception inevitably introduces partial observations, a partially observable MDP formulation makes the problem computational expensive to solve. Instead, our proposed method employs a hierarchical planning framework in which the robot determines what to pay attention to and for how long the attention should be sustained before shifting to other information sources. During the attention sustaining phase, the robot carries out a sub-policy, computed from an abstraction of the original MDP given the current attention. We use an example where a robot is tasked to capture a set of intruders in a stochastic gridworld. The experimental results show that the proposed method enables information- and computation-efficient optimal planning in stochastic environments.",
        "primary_area": "",
        "author": "Haoxiang Ma;Jie Fu;Haoxiang Ma;Jie Fu",
        "authorids": "/37088998794;/37085509060;/37088998794;/37085509060",
        "aff": "Department of Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561154/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=965833797239192149&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Department of Robotics Engineering",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561347",
        "title": "Attentional Learn-able Pooling for Human Activity Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Human activity/behaviour monitoring and recognition is a key for facilitating humans robot interaction, and allows robots for a better scheduling of future operations. It is challenging and often addressed at different levels, such as human activity classification, future activity prediction and monitoring of the on-going activities. The paper proposes a novel attention-based learn-able pooling mechanism for human activity classification from RGB videos. Recently, most of the best performing human activity recognition approaches are based on 3D skeleton positions. The 3D skeleton positions are not always available in videos captured using RGB cameras, which are widely used in robotics applications. RGB videos contain rich spatio-temporal information and processing them semantically is a difficult task. Moreover, accurately capturing spatial information and long-term temporal dependencies is the key to achieving high recognition accuracy. We use an existing Convolutional Neural Network for image recognition to extract video features which are then processed using our innovative application of attention mechanism to focus the network on features that are more important for discrimination. Afterwards, we use a novel learn-able pooling mechanism to extract activity-aware spatio-temporal cues for efficient activity recognition. The proposed pooling mechanism learns the structural information from hidden states of a bidirectional Long Short-Term Memory network via Fisher Vectors.",
        "primary_area": "",
        "author": "Bappaditya Debnath;Mary O\u2019Brien;Swagat Kumar;Ardhendu Behera;Bappaditya Debnath;Mary O\u2019Brien;Swagat Kumar;Ardhendu Behera",
        "authorids": "/37086637895;/37087228081;/37535549500;/37085623279;/37086637895;/37087228081;/37535549500;/37085623279",
        "aff": "Department of Computer Science, Edge Hill University, Ormskirk, United Kingdom; Department of Health Social Care and Medicine, Edge Hill University, Ormskirk, United Kingdom; Department of Computer Science, Edge Hill University, Ormskirk, United Kingdom; Department of Computer Science, Edge Hill University, Ormskirk, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561347/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16153490388134081145&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Edge Hill University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.edgehill.ac.uk",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ormskirk",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561480",
        "title": "Attentional-GCNN: Adaptive Pedestrian Trajectory Prediction towards Generic Autonomous Vehicle Use Cases",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicle navigation in shared pedestrian environments requires the ability to predict future crowd motion both accurately and with minimal delay. Understanding the uncertainty of the prediction is also crucial. Most existing approaches however can only estimate uncertainty through repeated sampling of generative models. Additionally, most current predictive models are trained on datasets that assume complete observability of the crowd using an aerial view. These are generally not representative of real-world usage from a vehicle perspective, and can lead to the underestimation of uncertainty bounds when the on-board sensors are occluded. Inspired by prior work in motion prediction using spatio-temporal graphs, we propose a novel Graph Convolutional Neural Network (GCNN)-based approach, Attentional-GCNN, which aggregates information of implicit interaction between pedestrians in a crowd by assigning attention weight in edges of the graph. Our model can either output a probabilistic distribution or faster deterministic prediction, demonstrating applicability to autonomous vehicle use cases where either speed or accuracy with uncertainty bounds are required. To further improve the training of predictive models, we propose an automatically labelled pedestrian dataset collected from an intelligent vehicle platform representative of real-world use. Through experiments on a number of datasets, we show our proposed method achieves an improvement over the state of the art by 10% on Average Displacement Error (ADE) and 12% on Final Displacement Error (FDE) with fast inference speeds.",
        "primary_area": "",
        "author": "Kunming Li;Stuart Eiffert;Mao Shan;Francisco Gomez-Donoso;Stewart Worrall;Eduardo Nebot;Kunming Li;Stuart Eiffert;Mao Shan;Francisco Gomez-Donoso;Stewart Worrall;Eduardo Nebot",
        "authorids": "/37088436006;/37088438040;/38242373300;/37085895630;/37606436900;/37273559500;/37088436006;/37088438040;/38242373300;/37085895630;/37606436900;/37273559500",
        "aff": "Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW, Australia; Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW, Australia; Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW, Australia; University Institute for Computer Research, Universidad de Alicante, Spain; Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW, Australia; Australian Centre for Field Robotics, The University of Sydney, Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561480/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5505415423443464770&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "University of Sydney;Universidad de Alicante",
        "aff_unique_dep": "Australian Centre for Field Robotics;University Institute for Computer Research",
        "aff_unique_url": "https://www.sydney.edu.au;https://www.ua.es",
        "aff_unique_abbr": "USYD;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "Australia;Spain"
    },
    {
        "id": "9561139",
        "title": "Attribute-Based Robotic Grasping with One-Grasp Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic grasping is one of the most fundamental robotic manipulation tasks and has been actively studied. However, how to quickly teach a robot to grasp a novel target object in clutter remains challenging. This paper attempts to tackle the challenge by leveraging object attributes that facilitate recognition, grasping, and quick adaptation. In this work, we introduce an end-to-end learning method of attribute-based robotic grasping with one-grasp adaptation capability. Our approach fuses the embeddings of a workspace image and a query text using a gated-attention mechanism and learns to predict instance grasping affordances. Besides, we utilize object persistence before and after grasping to learn a joint metric space of visual and textual attributes. Our model is self-supervised in a simulation that only uses basic objects of various colors and shapes but generalizes to novel objects and real-world scenes. We further demonstrate that our model is capable of adapting to novel objects with only one grasp data and improving instance grasping performance significantly. Experimental results in both simulation and the real world demonstrate that our approach achieves over 80% instance grasping success rate on unknown objects, which outperforms several baselines by large margins. Supplementary material is available at https://sites.google.com/umn.edu/attributes-grasping.",
        "primary_area": "",
        "author": "Yang Yang;Yuanhao Liu;Hengyue Liang;Xibai Lou;Changhyun Choi;Yang Yang;Yuanhao Liu;Hengyue Liang;Xibai Lou;Changhyun Choi",
        "authorids": "/37088070512;/37088998753;/37088072759;/37088504165;/37085811337;/37088070512;/37088998753;/37088072759;/37088504165;/37085811337",
        "aff": "University of Minnesota, Minneapolis, USA; University of Minnesota, Minneapolis, USA; University of Minnesota, Minneapolis, USA; University of Minnesota, Minneapolis, USA; University of Minnesota, Minneapolis, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561139/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5811444449061667950&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.minnesota.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561506",
        "title": "Augmented Hierarchical Quadratic Programming for Adaptive Compliance Robot Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Today\u2019s robots are expected to fulfill different requirements originated from executing complex tasks in uncertain environments, often in collaboration with humans. To deal with this type of multi-objective control problem, hierarchical least-square optimization techniques are often employed, defining multiple tasks as objective functions, listed in hierarchical manner. The solution to the Inverse Kinematics problem requires to plan and constantly update the Cartesian trajectories. However, we propose an extension to the classical Hierarchical Quadratic Programming formulation, that allows to optimally generate these trajectories at control level. This is achieved by augmenting the optimization variable, to include the Cartesian reference and allow for the formulation of an adaptive compliance controller, which retains an impedancelike behaviour under external disturbances, while switching to an admittance-like behavior when collaborating with a human. The effectiveness of this approach is tested using a 7-DoF Franka Emika Panda manipulator in three different collaborative scenarios.",
        "primary_area": "",
        "author": "Francesco Tassi;Elena De Momi;Arash Ajoudani;Francesco Tassi;Elena De Momi;Arash Ajoudani",
        "authorids": "/37086861229;/37947344300;/37945239900;/37086861229;/37947344300;/37945239900",
        "aff": "Department of Electronics Information and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Electronics Information and Bioengineering, Politecnico di Milano, Milan, Italy; Dept. of Advanced Robotics, HRI2 Lab, Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561506/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8465420295088547092&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Politecnico di Milano;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Electronics Information and Bioengineering;Dept. of Advanced Robotics",
        "aff_unique_url": "https://www.polimi.it;https://www.iit.it",
        "aff_unique_abbr": "Politecnico di Milano;IIT",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Milan;Genova",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9562091",
        "title": "Auto-Tuned Sim-to-Real Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Policies trained in simulation often fail when transferred to the real world due to the \u2018reality gap\u2019 where the simulator is unable to accurately capture the dynamics and visual properties of the real world. Current approaches to tackle this problem, such as domain randomization, require prior knowledge and engineering to determine how much to randomize system parameters in order to learn a policy that is robust to sim-to-real transfer while also not being too conservative. We propose a method for automatically tuning simulator system parameters to match the real world using only raw RGB images of the real world without the need to define rewards or estimate state. Our key insight is to reframe the auto-tuning of parameters as a search problem where we iteratively shift the simulation system parameters to approach the real world system parameters. We propose a Search Param Model (SPM) that, given a sequence of observations and actions and a set of system parameters, predicts whether the given parameters are higher or lower than the true parameters used to generate the observations. We evaluate our method on multiple robotic control tasks in both sim-to-sim and sim-to-real transfer, demonstrating significant improvement over naive domain randomization. Project videos at https://yuqingd.github.io/autotuned-sim2real/.",
        "primary_area": "",
        "author": "Yuqing Du;Olivia Watkins;Trevor Darrell;Pieter Abbeel;Deepak Pathak;Yuqing Du;Olivia Watkins;Trevor Darrell;Pieter Abbeel;Deepak Pathak",
        "authorids": "/37088999884;/37088998559;/37282910600;/37542877900;/37085372144;/37088999884;/37088998559;/37282910600;/37542877900;/37085372144",
        "aff": "UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562091/",
        "gs_citation": 98,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12964173176086500372&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of California, Berkeley;Carnegie Mellon University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UC Berkeley;CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561909",
        "title": "Auto-calibration Method Using Stop Signs for Urban Autonomous Driving Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Calibration of sensors is fundamental to robust performance for intelligent vehicles. In natural environments, disturbances can easily challenge calibration. One possibility is to use natural objects of known shape to recalibrate sensors. An approach based on recognition of traffic signs, such as stop signs, and use of them for recalibration of cameras is presented. The approach is based on detection, geometry estimation, calibration, and recursive updating. Results from natural environments are presented that clearly show convergence and improved performance.",
        "primary_area": "",
        "author": "Yunhai Han;Yuhan Liu;David Paz;Henrik Christensen;Yunhai Han;Yuhan Liu;David Paz;Henrik Christensen",
        "authorids": "/37088996153;/37088999574;/37088688508;/37281307400;/37088996153;/37088999574;/37088688508;/37281307400",
        "aff": "Contextual Robotics Institute, University of California, CA; Contextual Robotics Institute, University of California, CA; Contextual Robotics Institute, University of California, CA; Contextual Robotics Institute, University of California, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561909/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9165211059167846986&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Santa Barbara",
        "aff_unique_dep": "Contextual Robotics Institute",
        "aff_unique_url": "https://www.ucsb.edu",
        "aff_unique_abbr": "UCSB",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Santa Barbara",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561002",
        "title": "Automated Behavior Tree Error Recovery Framework for Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Reacting to unexpected conditions and recovering from errors is crucial for robots to perform their missions continuously in dynamic environments. This paper introduces a novel framework aiming to handle errors impairing the quality of robot services concerning on-line management of error recovery. The framework is a combination of an execution generation tool, a learning module, and a recovery pipeline for error detection, diagnosis, and recovery in robotic systems. The execution generation tool generates control flow instructions and parameter files, then extracts necessary skills from the skill library based on application descriptions or recovery solution recipes. In the learning module, a Bayesian Network (BN) decision model is interactively and continually trained, incorporating application information structured according to the Failure Mode and Effects Analysis (FMEA) method. The recovery pipeline implements a decision model inferring the cause of an error and choosing recovery solutions. We will provide an experimental evaluation of our framework on a pick-and-place application performed by a robot arm in the physical world.",
        "primary_area": "",
        "author": "Ruichao Wu;Sitar Kortik;Christoph Hellmann Santos;Ruichao Wu;Sitar Kortik;Christoph Hellmann Santos",
        "authorids": "/37088996486;/37085419348;/37088997276;/37088996486;/37085419348;/37088997276",
        "aff": "Fraunhofer IPA, Stuttgart, Germany; Fraunhofer IPA, Stuttgart, Germany; Fraunhofer IPA, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561002/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14831663067030635932&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ipa.fraunhofer.de/",
        "aff_unique_abbr": "Fraunhofer IPA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561791",
        "title": "Automated End-Effector Alignment for Robotic Cell Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Cell manipulation is a key technology in many biomedical and clinical applications, in which end-effector alignment is a critical procedure. Presently, end-effector alignment is performed manually and suffers from large misalignment error and inconsistency. Manual alignment often undesirably moves the end-effector (e.g., a glass micropipette) out of the limited field of view under microscopy and risks breaking the fragile end-effector. This paper presents automated end-effector alignment for robotic cell manipulation. A rotational degree of freedom was added to a micromanipulator with translational degrees of freedom. The kinematic model of end-effector\u2019s rotation was established, and the unknown model parameters were calibrated and updated via quadratic optimization. A controller was designed based on the kinematics modeling and parameter optimization to compensate for rotation-induced translation and achieve end-effector alignment. Experimental results demonstrate that the robotic alignment technique achieved an accuracy of 0.6\u00b10.3\u00b0 and a time cost of 18.5 \u00b1 10.2 s, both significantly less than manual alignment. The developed controller cost significantly less time for micropipette alignment than the PID controller. A glass micropipette was used as the end-effector for human sperm immobilization, a critical procedure in clinical cell surgery. The success rate of sperm immobilization was 97% by robotic micropipette alignment, higher than the success rate of 90% by manual alignment due to the higher accuracy of robotic alignment.",
        "primary_area": "",
        "author": "Changsheng Dai;Songlin Zhuang;Zhuoran Zhang;Guanqiao Shan;Yu Sun;Changsheng Dai;Songlin Zhuang;Zhuoran Zhang;Guanqiao Shan;Yu Sun",
        "authorids": "/37086292072;/37085492095;/37085810781;/37086937807;/37309639100;/37086292072;/37085492095;/37085810781;/37086937807;/37309639100",
        "aff": "Advanced Micro and Nanosystems Laboratory, University of Toronto, Canada; Advanced Micro and Nanosystems Laboratory, University of Toronto, Canada; Advanced Micro and Nanosystems Laboratory, University of Toronto, Canada; Advanced Micro and Nanosystems Laboratory, University of Toronto, Canada; Advanced Micro and Nanosystems Laboratory, University of Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561791/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10760920264803739334&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Advanced Micro and Nanosystems Laboratory",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561997",
        "title": "Automated Environment Reduction for Debugging Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Complex environments can cause robots to fail. Identifying the key elements of the environment associated with such failures is critical for faster fault isolation and, ultimately, debugging those failures. In this work we present the first automated approach for reducing the environment in which a robot failed. Similar to software debugging techniques, our approach systematically performs a partition of the environment space causing a failure, executes the robot in each partition containing a reduced environment, and further partitions reduced environments that still lead to a failure. The technique is novel in the spatial-temporal partition strategies it employs, and in how it manages the potential different robot behaviors occurring under the same environments. Our study of a ground robot on three failure scenarios finds that environment reductions of over 95% are achievable within a 2-hour window.",
        "primary_area": "",
        "author": "Meriel von Stein;Sebastian Elbaum;Meriel von Stein;Sebastian Elbaum",
        "authorids": "/37088997804;/37272376100;/37088997804;/37272376100",
        "aff": "University of Virginia, USA; University of Virginia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561997/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4661075403173929103&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561175",
        "title": "Automated Extrinsic Calibration for 3D LiDARs with Range Offset Correction using an Arbitrary Planar Board",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an automatic and accuracy- enhanced extrinsic calibration method for 3D LiDARs with a range offset correction, which needs only an arbitrarily-shaped single planar board. One of the most exhaustive parts of existing LiDAR calibration procedures is to manually find target objects from massive point clouds. To obviate user interventions, we propose an automated planar board detection from LiDAR range images. To extract a target completely, we suppress outliers and restore rejected inliers of the target board by introducing a target completion method. We empirically find that range measurements of various LiDARs are mainly skewed by constant offset values. To compensate for this, we suggest a range offset model for each laser channel in calibration procedures. The relative pose between LiDARs and range offsets are jointly estimated by minimizing bi-directional point- to-board distances within the iterative re-weighted least squares (IRLS) framework. To verify the suggested range offset model, we obtain and analyze extensive real-world measurements. By conducting experiments using the various sensor configurations and shapes of boards, we quantitatively and qualitatively confirm accuracy and versatility of the proposed method by comparing with the state-of-the-art LiDAR calibration methods. All the source code and data used in the paper are available at : https://github.com/JunhaAgu/AutoL2LCalib.",
        "primary_area": "",
        "author": "Junha Kim;Changhyeon Kim;Youngsoo Han;H. Jin Kim;Junha Kim;Changhyeon Kim;Youngsoo Han;H. Jin Kim",
        "authorids": "/37087404753;/37086041943;/37088568838;/37599626400;/37087404753;/37086041943;/37088568838;/37599626400",
        "aff": "Department of Mechanical and Aerospace Engineering, Seoul National University and Automation and Systems Research Institute (ASRI), Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University and Automation and Systems Research Institute (ASRI), Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University and Automation and Systems Research Institute (ASRI), Seoul, South Korea; Department of Mechanical and Aerospace Engineering, Seoul National University and Automation and Systems Research Institute (ASRI), Seoul, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561175/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=57395922842409571&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561465",
        "title": "Automated Generation of Robot Trajectories for Assembly Processes Requiring Only Sparse Manual Input",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a new method for offline programming part assembly operations with tight fittings is presented. More specifically, an assembly process trajectory generator with self programming capabilities is developed where the user needs to provide only very sparse and intuitive input. The presented system is added to the existing skill based robot software package VEROSIM. In VEROSIM, the trajectory generator is applied to an industrial test platform for assembling insulin injection devices at the Danish pharmaceutical company Novo Nordisk, where it is shown that the trajectories as expected are executable. Hence, the method is a strong alternative to online approaches such as programming by demonstration.",
        "primary_area": "",
        "author": "Steffen Madsen;Milad Jami;Henrik G. Petersen;Steffen Madsen;Milad Jami;Henrik G. Petersen",
        "authorids": "/37088235185;/37088997643;/37562505800;/37088235185;/37088997643;/37562505800",
        "aff": "SDU Robotics, University of Southern Denmark, Odense M, Denmark; Novo Nordisk A/S, Bagsvaerd, Denmark; SDU Robotics, University of Southern Denmark, Odense M, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561465/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2541914784231570865&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Southern Denmark;Novo Nordisk A/S",
        "aff_unique_dep": "SDU Robotics;",
        "aff_unique_url": "https://www.sdu.dk;https://www.novonordisk.com",
        "aff_unique_abbr": "SDU;NN",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Odense;Bagsvaerd",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9560959",
        "title": "Automated Mosquito Salivary Gland Extractor for PfSPZ-based Malaria Vaccine Production",
        "track": "main",
        "status": "Poster",
        "abstract": "Malaria is a worldwide scourge, and the broad deployment of an effective vaccine would improve the lives of millions of people. A vaccine based on Plasmodium falciparum (PfSPZ) sporozoites extracted from the salivary glands of infected mosquitoes shows significant promise. However, the large-scale industrial production of PfSPZ-based vaccines will benefit from automation of the key step of extracting sporozoites from mosquito salivary glands that is currently performed by manual microdissection. In this work, we demonstrate a robotic system prototype for extracting salivary glands from mosquitoes to streamline vaccine production and reduce the need for operators. In the proposed system, mosquitoes are decapitated in an automated robotic pick-place-decapitate process, then a squeezer apparatus extracts mosquito salivary glands from the body. Mosquito detection and body part localization are performed by computer vision methods. The software allows system operation in simulation and on the robotic hardware, which facilitates subsystem development and integration. Experiments show encouraging results with success rates of 93% in robotic mosquito manipulation and 87.1% in salivary gland extraction. The system has the potential to improve the efficiency of PfSPZ vaccine production with significant gains in throughput and reduction in training times for a highly deskilled initial manual step. Further, this system is expected to pave the way for a more mature future system.",
        "primary_area": "",
        "author": "Wanze Li;Zhuohong He;Parth Vora;Yanzhou Wang;Balazs Vagvolgyi;Simon Leonard;Anna Goodridge;Iulian Iordachita;Stephen L. Hoffman;Sumana Chakravarty;Russell H. Taylor;Wanze Li;Zhuohong He;Parth Vora;Yanzhou Wang;Balazs Vagvolgyi;Simon Leonard;Anna Goodridge;Iulian Iordachita;Stephen L. Hoffman;Sumana Chakravarty;Russell H. Taylor",
        "authorids": "/37088980931;/37088981043;/37088981341;/37089395453;/37568674700;/37269567400;/37088986893;/37330620500;/37088644231;/37087012292;/37277162900;/37088980931;/37088981043;/37088981341;/37089395453;/37568674700;/37269567400;/37088986893;/37330620500;/37088644231;/37087012292;/37277162900",
        "aff": "Laboratory for Computational Sensing and Robotics, The Johns Hopkins University; Laboratory for Computational Sensing and Robotics, The Johns Hopkins University; Laboratory for Computational Sensing and Robotics, The Johns Hopkins University; Laboratory for Computational Sensing and Robotics, The Johns Hopkins University; Laboratory for Computational Sensing and Robotics, The Johns Hopkins University; Laboratory for Computational Sensing and Robotics, The Johns Hopkins University; Laboratory for Computational Sensing and Robotics, The Johns Hopkins University; Laboratory for Computational Sensing and Robotics, The Johns Hopkins University; Sanaria, Inc; Sanaria, Inc; Laboratory for Computational Sensing and Robotics, The Johns Hopkins University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560959/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4945275737433012754&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;1;1;0",
        "aff_unique_norm": "Johns Hopkins University;Sanaria, Inc",
        "aff_unique_dep": "Laboratory for Computational Sensing and Robotics;",
        "aff_unique_url": "https://www.jhu.edu;https://www.sanaria.com",
        "aff_unique_abbr": "JHU;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561831",
        "title": "Automated Planning of Workcell Layouts Considering Task Sequences",
        "track": "main",
        "status": "Poster",
        "abstract": "The initial design of a robotic workcell layout has a large impact on the feasibility and performance of the intended robotic tasks. We define this layout design as a constrained nonlinear optimization problem that aims to optimize the placement of workcell components by minimizing the distance traveled between task sequences while maximizing the robot\u2019s manipulability. Suitable constraints guarantee the reachability as well as the absence of collisions. We solve this optimization problem via a genetic algorithm, and demonstrate it in three scenarios for a dual-arm robotic system that assembles product variants out of aluminum profiles.",
        "primary_area": "",
        "author": "Timo Bachmann;Korbinian Nottensteiner;M\u00e1ximo A. Roa;Timo Bachmann;Korbinian Nottensteiner;M\u00e1ximo A. Roa",
        "authorids": "/37089000086;/37085782023;/37628512100;/37089000086;/37085782023;/37628512100",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561831/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10806833296757551200&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Wessling",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9562016",
        "title": "Automated acquisition of structured, semantic models of manipulation activities from human VR demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a system capable of collecting and annotating, human performed, robot understandable, everyday activities from virtual environments. The human movements are mapped in the simulated world using off-the-shelf virtual reality devices with full body, and eye tracking capabilities. All the interactions in the virtual world are physically simulated, thus movements and their effects are closely relatable to the real world. During the activity execution, a subsymbolic data logger is recording the environment and the human gaze on a per-frame basis, enabling offline scene reproduction and replays. Coupled with the physics engine, online monitors (symbolic data loggers) are parsing (using various grammars) and recording events, actions, and their effects in the simulated world.",
        "primary_area": "",
        "author": "Andrei Haidu;Michael Beetz;Andrei Haidu;Michael Beetz",
        "authorids": "/37085583787;/37279125900;/37085583787;/37279125900",
        "aff": "Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562016/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4048254844718662700&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bremen",
        "aff_unique_dep": "Institute for Artificial Intelligence",
        "aff_unique_url": "https://www.uni-bremen.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561485",
        "title": "Automated design of underactuated monolithic soft robotics structures with multiple predefined end poses",
        "track": "main",
        "status": "Poster",
        "abstract": "The increasing frequency of robot interactions with humans and complex environments motivates the design and control of soft robotic systems made of compliant structures. Additive manufacturing processes enable the creation of new robotic systems and mechanisms that gain their compliance extrinsically through their design, rather than simply their material. With the ability to rapidly and affordably manufacture such mechanisms, the interest in producing custom task-specific underactuated mechanisms has grown. These mechanisms may be useful for highly repetitive tasks or complex situations where the simplicity of control outweighs the versatility of a more traditional robotic system. In the course of this work, new underactuated monolithic soft robotic mechanisms are presented along with automated design processes. The structures can reach multiple arbitrary end effector poses and are controlled with as few actuators as possible. Two methods for the automated design of such structures via inverse kinematics and two concepts for the mechanical realization are presented. Several functional models were created to illustrate possible application scenarios and validate the mechanical concepts. A novel contact surface was also developed and shown to improve the accuracy performance of these structures. These automated design methods contribute toward the general accessibility and usability of multi-pose underactuated extrinsically soft mechanisms.",
        "primary_area": "",
        "author": "Simon Schiele;Henry Phalen;Julian Kulozik;Yannick S. Krieger;Tim C. Lueth;Simon Schiele;Henry Phalen;Julian Kulozik;Yannick S. Krieger;Tim C. Lueth",
        "authorids": "/37086933976;/37087012679;/37088996989;/37073292900;/37389804500;/37086933976;/37087012679;/37088996989;/37073292900;/37389804500",
        "aff": "Institute of Micro Technology and Medical Device Technology (MIMED), Technical University of Munich, Munich, Germany; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA; Institute of Micro Technology and Medical Device Technology (MIMED), Technical University of Munich, Munich, Germany; Institute of Micro Technology and Medical Device Technology (MIMED), Technical University of Munich, Munich, Germany; Institute of Micro Technology and Medical Device Technology (MIMED), Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561485/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4797017316157255903&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Technical University of Munich;Johns Hopkins University",
        "aff_unique_dep": "Institute of Micro Technology and Medical Device Technology (MIMED);Laboratory for Computational Sensing and Robotics",
        "aff_unique_url": "https://www.tum.de;https://www.jhu.edu",
        "aff_unique_abbr": "TUM;JHU",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Munich;Baltimore",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9561484",
        "title": "Automatic Hanging Point Learning from Random Shape Generation and Physical Function Validation",
        "track": "main",
        "status": "Poster",
        "abstract": "The purpose of this paper is the robotic hanging manipulation of an object of various shapes that is not limited to a specific category. To achieve this, we propose a method that allows the estimator to learn many different shapes with hanging points without any manual annotation. A random shape generator using GAN solves the limitation of the number of 3D models and can handle objects of various shapes. In addition, hanging is repeated in the dynamics simulation, and hanging points are automatically generated. A large amount of training data is generated by rendering random-textured objects with hanging points in the random simulation environment. A deep neural network trained with these data was able to estimate hanging points of an unknown category object in the real world and achieved hanging manipulation by a robot.",
        "primary_area": "",
        "author": "Kosuke Takeuchi;Iori Yanokura;Yohei Kakiuchi;Kei Okada;Masayuki Inaba;Kosuke Takeuchi;Iori Yanokura;Yohei Kakiuchi;Kei Okada;Masayuki Inaba",
        "authorids": "/37088996846;/37086105883;/38242437800;/37280639000;/37286658200;/37088996846;/37086105883;/38242437800;/37280639000;/37286658200",
        "aff": "JSK Laboratory, The University of Tokyo, Japan; JSK Laboratory, The University of Tokyo, Japan; JSK Laboratory, The University of Tokyo, Japan; JSK Laboratory, The University of Tokyo, Japan; JSK Laboratory, The University of Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561484/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11249347345074009461&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "JSK Laboratory",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561789",
        "title": "Automatic Hyper-Parameter Tuning for Black-box LiDAR Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR odometry algorithms are complex and involve a number of hyper-parameters. The choice of hyper-parameters can substantively affect the performance of odometry estimation, and it is necessary to carefully fine-tune the hyper-parameters depending on the sensor, environment, and algorithm to achieve the best estimation results. While odometry estimation algorithms are often tuned manually, this is time-consuming and may also result in a sub-optimal parameter set. This paper presents an automatic hyper-parameter tuning approach for LiDAR odometry estimation. By taking advantage of the sequential model-based optimization (SMBO) approach, we automatically optimize the hyper-parameter set of a black-box odometry estimation algorithm without detailed knowledge of the algorithm. In addition, a LiDAR data augmentation approach is also proposed to prevent overfitting. Through evaluation, we show that the combination of SMBO-based parameter exploration and data augmentation enables us to efficiently and robustly optimize the hyper-parameter set for several different odometry estimation algorithms. We also demonstrate that the optimized parameter set exhibits superior performance with respect to KITTI dataset and in a real use scenario.",
        "primary_area": "",
        "author": "Kenji Koide;Masashi Yokozuka;Shuji Oishi;Atsuhiko Banno;Kenji Koide;Masashi Yokozuka;Shuji Oishi;Atsuhiko Banno",
        "authorids": "/37086179385;/38230409400;/37085895378;/37391486400;/37086179385;/38230409400;/37085895378;/37391486400",
        "aff": "Department of Information Technology and Human Factors, the National Institute of Advanced Industrial Science and Technology, Tsukuba, Japan; Department of Information Technology and Human Factors, the National Institute of Advanced Industrial Science and Technology, Tsukuba, Japan; Department of Information Technology and Human Factors, the National Institute of Advanced Industrial Science and Technology, Tsukuba, Japan; Department of Information Technology and Human Factors, the National Institute of Advanced Industrial Science and Technology, Tsukuba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561789/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8274179965851201937&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Department of Information Technology and Human Factors",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tsukuba",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561432",
        "title": "Automatic Mapping of Tailored Landmark Representations for Automated Driving and Map Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "While the automatic creation of maps for localization is a widely tackled problem, the automatic inference of higher layers of HD maps is not. Additionally, approaches that learn from maps require richer and more precise landmarks than currently available.In this work, we fuse semantic detections from a monocular camera with depth and orientation estimation from lidar to automatically detect, track and map parametric, semantic map elements. We propose the use of tailored representations that are minimal in the number of parameters, making the map compact and the estimation robust and precise enough to enable map inference even from single frame detections. As examples, we map traffic signs, traffic lights and poles using upright rectangles and cylinders.After robust multi-view optimization, traffic lights and signs have a mean absolute position error of below 10 cm, extent estimates are below 5 cm and orientation MAE is below 6\u25e6. This proves the suitability as automatically generated, pixel-accurate ground truth, reducing the task of ground truth generation from tedious 3D annotation to a post-processing of misdetections.",
        "primary_area": "",
        "author": "Jan-Hendrik Pauls;Benjamin Schmidt;Christoph Stiller;Jan-Hendrik Pauls;Benjamin Schmidt;Christoph Stiller",
        "authorids": "/37086547128;/37088997240;/37284652100;/37086547128;/37088997240;/37284652100",
        "aff": "Institute of Measurement and Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Institute of Measurement and Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Institute of Measurement and Control Systems, Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561432/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16313263677458202348&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute of Measurement and Control Systems",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9562025",
        "title": "Automatic Tuning for Data-driven Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Model predictive control (MPC) is a powerful feedback technique that is often used in data-driven robotics. The performance of data-driven MPC depends on the accuracy of the model, which often requires careful tuning. Furthermore, specifying the task with an objective function and synthesizing a feedback policy are not straightforward and typically lead to suboptimal solutions driven by trial and error. To address these challenges, we present a method to jointly optimize the data-driven system identification, task specification, and control synthesis of unknown dynamical systems. We use our method to develop AutoMPC3, a software package designed to automate and optimize data-driven MPC. Empirical evaluation on the pendulum swing-up, cart-pole swing-up, and half-cheetah running demonstrates that our method finds data-driven control policies that outperform offline reinforcement learning, without any hand-tuning.",
        "primary_area": "",
        "author": "William Edwards;Gao Tang;Giorgos Mamakoukas;Todd Murphey;Kris Hauser;William Edwards;Gao Tang;Giorgos Mamakoukas;Todd Murphey;Kris Hauser",
        "authorids": "/37089000004;/37086290360;/37085871347;/37329499800;/37543748800;/37089000004;/37086290360;/37085871347;/37329499800;/37543748800",
        "aff": "Department of Computer Science, University of Illinois at Urbana-Champaign; Department of Computer Science, University of Illinois at Urbana-Champaign; Department of Mechanical Engineering, Northwestern University; Department of Mechanical Engineering, Northwestern University; Department of Computer Science, University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562025/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12264151842517598631&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Northwestern University",
        "aff_unique_dep": "Department of Computer Science;Department of Mechanical Engineering",
        "aff_unique_url": "https://illinois.edu;https://www.northwestern.edu",
        "aff_unique_abbr": "UIUC;NU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Urbana-Champaign;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560755",
        "title": "Automating Behavior Selection for Affective Telepresence Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "The tabletop robot Haru, used for affective telepresence research, enables a teleoperator to communicate affects from a distance. The robot\u2019s expressiveness offers myriad ways of communicating affects through the execution of emotive routines. The teleoperator reacts to input modalities such as the user\u2019s facial expression, gestures and speech-based intent as perceived by the robot\u2019s perception system. However, due to the sheer number of routines to select from, the task of choosing the appropriate or the most preferred routine is becoming cumbersome. In this paper, we propose a human-in-the-loop reinforcement learning mechanism in which an agent learns the teleoperator\u2019s selection preference as a function of the input modalities and aids the routine selection process by narrowing it to n-best optimal choices. Our experimental results show that with only a few number of interactions from the teleoperator, the system can learn to recommend optimal routine behaviors for all perceived modalities, which greatly reduces the workload of the teleoperator.",
        "primary_area": "",
        "author": "Yurii Vasylkiv;Zhen Ma;Guangliang Li;Eleanor Sandry;Heike Brock;Keisuke Nakamura;Irani Pourang;Randy Gomez;Yurii Vasylkiv;Zhen Ma;Guangliang Li;Eleanor Sandry;Heike Brock;Keisuke Nakamura;Irani Pourang;Randy Gomez",
        "authorids": "/37085884941;/37088438862;/37086047680;/37088997706;/37086009097;/37534198900;/37088947020;/37979526500;/37085884941;/37088438862;/37086047680;/37088997706;/37086009097;/37534198900;/37088947020;/37979526500",
        "aff": "University of Manitoba; Ocean University of China; Ocean University of China; Curtin University; Honda Research Institute Japan Co., Ltd.; Honda Research Institute Japan Co., Ltd.; University of Manitoba; Honda Research Institute Japan Co., Ltd.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560755/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7808153296595522485&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;2;3;3;0;3",
        "aff_unique_norm": "University of Manitoba;Ocean University of China;Curtin University;Honda Research Institute Japan Co., Ltd.",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://umanitoba.ca;http://www.ouc.edu.cn;https://www.curtin.edu.au;https://www.honda-ri.jp/english/",
        "aff_unique_abbr": "U of M;OUC;Curtin;HRI-JP",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;2;3;3;0;3",
        "aff_country_unique": "Canada;China;Australia;Japan"
    },
    {
        "id": "9561284",
        "title": "Autonomous Aerial Swarming in GNSS-denied Environments with High Obstacle Density",
        "track": "main",
        "status": "Poster",
        "abstract": "The compact flocking of relatively localized Un-manned Aerial Vehicles (UAVs) in high obstacle density areas is discussed in this paper. The presented work tackles realistic scenarios in which the environment map is not known apriori and the use of a global localization system and communication infrastructure is difficult due to the presence of obstacles. To achieve flocking in such a constrained environment, we propose a fully decentralized, bio-inspired control law that uses only onboard sensor data for safe flocking through the environment without any communication with other agents. In the proposed approach, each UAV agent uses onboard sensors to self-localize and estimate the relative position of other agents in its local reference frame. The usability and performance of the proposed approach were verified and evaluated using various experiments in a realistic robotic simulator and a natural forest. The presented experiments also validate the utility of onboard relative localization for autonomous multi-UAV applications in the absence of global localization information and communication.",
        "primary_area": "",
        "author": "Afzal Ahmad;Viktor Walter;Pavel Petr\u00e1\u010dek;Mat\u011bj Petrl\u00edk;Tom\u00e1\u0161 B\u00e1\u010da;David \u017daitl\u00edk;Martin Saska;Afzal Ahmad;Viktor Walter;Pavel Petr\u00e1\u010dek;Mat\u011bj Petrl\u00edk;Tom\u00e1\u0161 B\u00e1\u010da;David \u017daitl\u00edk;Martin Saska",
        "authorids": "/37088525145;/37086448499;/37087995299;/37086431997;/37945177400;/37088655830;/37298817800;/37088525145;/37086448499;/37087995299;/37086431997;/37945177400;/37088655830;/37298817800",
        "aff": "Faculty of Electrical Engineering, Czech Technical University in Prague, Prague; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague; Faculty of Electrical Engineering, Czech Technical University in Prague, Prague",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561284/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15594942155247655836&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Czech Technical University in Prague",
        "aff_unique_dep": "Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "9561767",
        "title": "Autonomous Cooperative Visual Navigation for Planetary Exploration Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Planetary robotics navigation has attracted the great attention of many researchers in recent years. Localization is one of the most important problems for robots on another planet in the lack of GPS. The robots need to be able to know their location and the surrounding map in the environment concurrently, to work and communicate together on another planet. In the current work, a novel algorithm is designed to cooperatively localize a team of robots on another planet. Consequently, a robust algorithm is developed for cooperative Visual Odometry (VO) to localize each robot in a planetary environment while detecting both intra-loop closure and inter-loop closures using previously observed area by the robot and shared area from other robots, respectively. To validate the proposed algorithm, a comparison is provided between the proposed cooperative VO and the single version of VO. Accordingly, a planetary analogue real dataset is employed to investigate the accuracy of the proposed algorithm. The results promise the concept of cooperative VO to significantly increase the accuracy of localization.",
        "primary_area": "",
        "author": "Masoud S. Bahraini;Abdelhafid Zenati;Nabil Aouf;Masoud S. Bahraini;Abdelhafid Zenati;Nabil Aouf",
        "authorids": "/37088998036;/37086430997;/37327854800;/37088998036;/37086430997;/37327854800",
        "aff": "Department of Mechanical Engineering, Sirjan University of Technology, Sirjan, Iran; Department of Electrical and Electronic Engineering, City University of London, London, UK; Department of Electrical and Electronic Engineering, City University of London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561767/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10396905985337900709&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Sirjan University of Technology;City University of London",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electrical and Electronic Engineering",
        "aff_unique_url": ";https://www.city.ac.uk",
        "aff_unique_abbr": ";City, University of London",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Sirjan;London",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Iran;United Kingdom"
    },
    {
        "id": "9561987",
        "title": "Autonomous Decentralized Shape-Based Navigation for Snake Robots in Dense Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we focus on the autonomous navigation of snake robots in densely-cluttered environments, where collisions between the robot and obstacles are frequent, which could happen often in disaster scenarios, underground caves, or grassland/forest environments. This work takes the view that obstacles are not to be avoided, but rather exploited to support and direct the motion of the snake robot. We build upon a decentralized state-of-the-art compliant controller for serpenoid locomotion, and develop a bi-stable dynamical system that relies on inertial feedback to continuously steer the robot toward a desired direction. We experimentally show that this controller allows the robot to autonomously navigate dense environments by consistently locomoting along a given, global direction of travel in the world, which could be selected by a human operator or a higher level planner. We further equip the robot with an onboard vision system, allowing the robot to autonomously select its own direction of travel, based on the obstacle distribution ahead of its position (i.e., enacting feedforward control). In those additional experiments on hardware, we show how such an exteroceptive sensor can allow the robot to steer before hitting obstacles and to preemptively avoid challenging regions where proprioception-only (i.e., torque and inertial) feedback control would not suffice.",
        "primary_area": "",
        "author": "Guillaume Sartoretti;Tianyu Wang;Gabriel Chuang;Qingyang Li;Howie Choset;Guillaume Sartoretti;Tianyu Wang;Gabriel Chuang;Qingyang Li;Howie Choset",
        "authorids": "/37085791757;/37088483378;/37088998466;/37089001663;/37281322200;/37085791757;/37088483378;/37088998466;/37089001663;/37281322200",
        "aff": "Department of Mechanical Engineering, National University of Singapore, Singapore; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561987/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10277312694233723371&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "National University of Singapore;Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering;Robotics Institute",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.cmu.edu",
        "aff_unique_abbr": "NUS;CMU",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Pittsburgh",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "9561922",
        "title": "Autonomous Distributed 3D Radiation Field Estimation for Nuclear Environment Characterization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper contributes a method designed to enable autonomous distributed 3D nuclear radiation field mapping. The algorithm uses a single radiation sensor and a sequence of spatially distributed and robotically acquired radiation measurements across a discretized 3D grid to derive a radiation gradient. The derived gradient is probabilistically propagated to unknown components of the map to further guide a curiosity-driven path planner by identifying the next most radiologically informative point given available information. To demonstrate the method, we develop a resilient micro flying robot capable of autonomous GPS-denied navigation that integrates a Thallium\u2013doped Cesium Iodide (CsI(Tl)) scintillator and Silicon Photomultiplier (SiPm) combined with custom\u2013built pulse counting circuitry. A set of experimental studies is presented inside an indoor facility within which actual radioactive uranium ore sources have been distributed.",
        "primary_area": "",
        "author": "Frank Mascarich;Paolo De Petris;Huan Nguyen;Nikhil Khedekar;Kostas Alexis;Frank Mascarich;Paolo De Petris;Huan Nguyen;Nikhil Khedekar;Kostas Alexis",
        "authorids": "/37086409687;/37089002113;/37088471319;/37086935230;/37546514600;/37086409687;/37089002113;/37088471319;/37086935230;/37546514600",
        "aff": "University of Nevada, Reno, NV, USA; NTNU, Trondheim, Norway; NTNU, Trondheim, Norway; University of Nevada, Reno, NV, USA; NTNU, Trondheim, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561922/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13015218867515591608&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "University of Nevada, Reno;Norwegian University of Science and Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.unr.edu;https://www.ntnu.no",
        "aff_unique_abbr": "UNR;NTNU",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Reno;Trondheim",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "United States;Norway"
    },
    {
        "id": "9560789",
        "title": "Autonomous Flying into Buildings in a Firefighting Scenario",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an approach enabling an Unmanned Aerial Vehicle (UAV) to autonomously enter a target building through an open window. We use a fusion of depth camera and 2D Light Detection and Ranging (LiDAR) data for window detection and continuous estimation of its position, orientation, and size. The proposed algorithms are capable of running both with and without available a priori information. The obtained detections are utilized for planning collision-free trajectories through the target window. We use a sensor fusion algorithm for robust altitude estimation from laser rangefinder data while flying over ground with inconsistent elevation. Particular focus is given to the transition between outdoor and indoor environments and vice-versa to achieve the required reliability of UAV state estimation. The proposed approach has been verified in multiple real-world experiments, where the UAV was able to successfully enter and leave the target building both under normal conditions and under decreased visibility conditions in a smoke-filled environment.",
        "primary_area": "",
        "author": "Vaclav Pritzl;Petr Stepan;Martin Saska;Vaclav Pritzl;Petr Stepan;Martin Saska",
        "authorids": "/37088348638;/37726750300;/37298817800;/37088348638;/37726750300;/37298817800",
        "aff": "Department of Cybernetics, Faculty of Electrical Engineering, Multi-Robot Systems Group, Czech Technical University, Prague, Czech Republic; Department of Cybernetics, Faculty of Electrical Engineering, Multi-Robot Systems Group, Czech Technical University, Prague, Czech Republic; Department of Cybernetics, Faculty of Electrical Engineering, Multi-Robot Systems Group, Czech Technical University, Prague, Czech Republic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560789/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12781962364740533088&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Czech Technical University",
        "aff_unique_dep": "Department of Cybernetics",
        "aff_unique_url": "https://www.cvut.cz",
        "aff_unique_abbr": "CTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Prague",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Czech Republic"
    },
    {
        "id": "9561631",
        "title": "Autonomous Multi-View Navigation via Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel deep reinforcement learning (DRL) system for the autonomous navigation of mobile robots that consists of three modules: map navigation, multi-view perception and multi-branch control. Our DRL system takes as the input a routed map provided by a global planner and three RGB images captured by a multi-camera setup to gather global and local information, respectively. In particular, we present a multi-view perception module based on an attention mechanism to filter out redundant information caused by multi-camera sensing. We also replace raw RGB images with low-dimensional representations via a specifically designed network, which benefits a more robust sim2real transfer learning. Extensive experiments in both simulated and real-world scenarios demonstrate that our system outperforms state-of-the-art approaches.",
        "primary_area": "",
        "author": "Xueqin Huang;Wei Chen;Wei Zhang;Ran Song;Jiyu Cheng;Yibin Li;Xueqin Huang;Wei Chen;Wei Zhang;Ran Song;Jiyu Cheng;Yibin Li",
        "authorids": "/37088842394;/37089397739;/37085379581;/37546859100;/37086026328;/37279897500;/37088842394;/37089397739;/37085379581;/37546859100;/37086026328;/37279897500",
        "aff": "School of Control Science and Engineering, Shandong University, China; School of Control Science and Engineering, Shandong University, China; Institute of Brain and Brain-Inspired Science, Shandong University, China; Institute of Brain and Brain-Inspired Science, Shandong University, China; School of Control Science and Engineering, Shandong University, China; School of Control Science and Engineering, Shandong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561631/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4269581968371535161&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Shandong University",
        "aff_unique_dep": "School of Control Science and Engineering",
        "aff_unique_url": "http://www.sdu.edu.cn",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561419",
        "title": "Autonomous Navigation for Adaptive Unmanned Underwater Vehicles Using Fiducial Markers",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an integrated methodology and experimental validation of an autonomous framework for unmanned underwater vehicles (UUVs) merely equipped with a conventional monocular camera and a pressure sensor to accomplish high-performance autonomy. Optimal pose of the UUV is solved iteratively by Levenburg-Marquardt optimization for the Perspective-n-Point (PnP) problem. To guarantee a consistent localization system, a properly-tuned EKF with extra outlier removal approaches including applying Chi-square tests of innovations adequately removes measurement noises, mean-while provides unknown navigation state estimations. A classic adaptive controller is developed to enable autonomous mobility. Real-time experiments are designed to demonstrate underwater autonomous performance with a miniature commercial UUV, BlueROV2 Heavy.",
        "primary_area": "",
        "author": "Juan Chen;Caiming Sun;Aidong Zhang;Juan Chen;Caiming Sun;Aidong Zhang",
        "authorids": "/37088999140;/37086270576;/37086269590;/37088999140;/37086270576;/37086269590",
        "aff": "Robotics Research Center, Peng Cheng Laboratory (PCL), Shenzhen, China; Institute of Robotics and Intelligent Manufacturing (IRIM), The Chinese University of Hong Kong (CUHK), Shenzhen, China; Institute of Robotics and Intelligent Manufacturing (IRIM), The Chinese University of Hong Kong (CUHK), Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561419/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12003663185317419707&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Pengcheng Laboratory;Chinese University of Hong Kong",
        "aff_unique_dep": "Robotics Research Center;Institute of Robotics and Intelligent Manufacturing",
        "aff_unique_url": ";https://www.cuhk.edu.hk",
        "aff_unique_abbr": "PCL;CUHK",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561965",
        "title": "Autonomous Navigation in Dynamic Environments with Multi-Modal Perception Uncertainties",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the safe path planning problem for autonomous mobility with multi-modal perception uncertainties. Specifically, we assume that different sensor inputs lead to different Gaussian process regulated perception uncertainties (named as multi-modal perception uncertainties). We implement a Bayesian inference algorithm, which merges the multi-modal GP-regulated uncertainties into a unified one and translates the unified uncertainty into a dynamic risk map. With the safe path planner taking the risk map as input, we are able to plan a safe path for the autonomous vehicle to follow. Experimental results on an autonomous golf cart testbed validate the applicability and efficiency of the proposed algorithm.",
        "primary_area": "",
        "author": "Hongliang Guo;Zefan Huang;Qiheng Ho;Marcelo Ang;Daniela Rus;Hongliang Guo;Zefan Huang;Qiheng Ho;Marcelo Ang;Daniela Rus",
        "authorids": "/37085490043;/37087323099;/37087321977;/37279138700;/37279652300;/37085490043;/37087323099;/37087321977;/37279138700;/37279652300",
        "aff": "Singapore-MIT Alliance for Research and Technology, Singapore; Singapore-MIT Alliance for Research and Technology, Singapore; Singapore-MIT Alliance for Research and Technology, Singapore; National University of Singapore, Singapore; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561965/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9623610436683351853&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "Singapore-MIT Alliance for Research and Technology;National University of Singapore;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": ";https://www.nus.edu.sg;https://www.mit.edu",
        "aff_unique_abbr": "SMART;NUS;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "9561295",
        "title": "Autonomous Navigation of an Ultrasound Probe Towards Standard Scan Planes with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous ultrasound (US) acquisition is an important yet challenging task, as it involves interpretation of the highly complex and variable images and their spatial relationships. In this work, we propose a deep reinforcement learning framework to autonomously control the 6-D pose of a virtual US probe based on real-time image feedback to navigate towards the standard scan planes under the restrictions in real-world US scans. Furthermore, we propose a confidence-based approach to encode the optimization of image quality in the learning process. We validate our method in a simulation environment built with real-world data collected in the US imaging of the spine. Experimental results demonstrate that our method can perform reproducible US probe navigation towards the standard scan plane with an accuracy of 4.91mm/4.65\u00b0 in the intra-patient setting, and accomplish the task in the intra- and inter-patient settings with a success rate of 92% and 46%, respectively. The results also show that the introduction of image quality optimization in our method can effectively improve the navigation performance.",
        "primary_area": "",
        "author": "Keyu Li;Jian Wang;Yangxin Xu;Hao Qin;Dongsheng Liu;Li Liu;Max Q.-H. Meng;Keyu Li;Jian Wang;Yangxin Xu;Hao Qin;Dongsheng Liu;Li Liu;Max Q.-H. Meng",
        "authorids": "/37087244178;/37089001664;/37086799174;/37088999648;/37088996849;/37086313226;/37274117000;/37087244178;/37089001664;/37086799174;/37088999648;/37088996849;/37086313226;/37274117000",
        "aff": "Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong, China; School of Biomedical Engineering, Shenzhen University, Shenzhen, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong, China; Sonoscape Medical Corp, Shenzhen, China; Department of Pain, Peking University Shenzhen Hospital, Shenzhen, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Electronic and Electrical Engineering of the Southern University of Science and Technology in Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561295/",
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10045802491169329098&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;3;0;4",
        "aff_unique_norm": "Chinese University of Hong Kong;Shenzhen University;Sonoscape Medical Corp;Peking University Shenzhen Hospital;Southern University of Science and Technology",
        "aff_unique_dep": "Department of Electronic Engineering;School of Biomedical Engineering;;Department of Pain;Department of Electronic and Electrical Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.szu.edu.cn;;http://www.puhshenzhen.com/;https://www.sustech.edu.cn",
        "aff_unique_abbr": "CUHK;SZU;;;SUSTech",
        "aff_campus_unique_index": "0;1;0;1;0;1",
        "aff_campus_unique": "Hong Kong;Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561049",
        "title": "Autonomous Overtaking in Gran Turismo Sport Using Curriculum Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Professional race-car drivers can execute extreme overtaking maneuvers. However, existing algorithms for autonomous overtaking either rely on simplified assumptions about the vehicle dynamics or try to solve expensive trajectory-optimization problems online. When the vehicle approaches its physical limits, existing model-based controllers struggle to handle highly nonlinear dynamics, and cannot leverage the large volume of data generated by simulation or real-world driving. To circumvent these limitations, we propose a new learning-based method to tackle the autonomous overtaking problem. We evaluate our approach in the popular car racing game Gran Turismo Sport, which is known for its detailed modeling of various cars and tracks. By leveraging curriculum learning, our approach leads to faster convergence as well as increased performance compared to vanilla reinforcement learning. As a result, the trained controller outperforms the built-in model-based game AI and achieves comparable over-taking performance with an experienced human driver.",
        "primary_area": "",
        "author": "Yunlong Song;HaoChih Lin;Elia Kaufmann;Peter D\u00fcrr;Davide Scaramuzza;Yunlong Song;HaoChih Lin;Elia Kaufmann;Peter D\u00fcrr;Davide Scaramuzza",
        "authorids": "/37088688858;/37088997754;/37086293209;/37089049740;/37397688400;/37088688858;/37088997754;/37086293209;/37089049740;/37397688400",
        "aff": "Dep. of Neuroinformatics, University of Zurich and ETH, Zurich, Switzerland; Sony AI Zurich; Dep. of Neuroinformatics, University of Zurich and ETH, Zurich, Switzerland; Sony AI Zurich; Dep. of Neuroinformatics, University of Zurich and ETH, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561049/",
        "gs_citation": 104,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10103547978418648747&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "University of Zurich;Sony AI",
        "aff_unique_dep": "Department of Neuroinformatics;",
        "aff_unique_url": "https://www.unizh.ch;https://www.sony.ai",
        "aff_unique_abbr": "UZH;Sony AI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561469",
        "title": "Autonomous Robotic Escort Incorporating Motion Prediction and Human Intention",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a technique that allows a robot to escort a human to their destination. Unlike tracking where the robot follows the human from behind, the proposed technique locates the robot in front of the human by incorporating human intention in addition to conventional motion prediction. Human head pose is used as an effective past-proven implicit indicator of intention. A particle filter allows accurate estimation and prediction of the non-Gaussian human trajectory. The predicted pose from both the human motion and intention determines the robot control action which leads to efficient autonomous escorting. Experimental analysis shows that the incorporation of the proposed human intention model reduces human position prediction error by approximately 40% when turning. Experimental validation with an omnidirectional mobile robotic platform shows successful and effective escorting compared to the conventional techniques.",
        "primary_area": "",
        "author": "Dean Conte;Tomonari Furukawa;Dean Conte;Tomonari Furukawa",
        "authorids": "/37088602114;/37280186200;/37088602114;/37280186200",
        "aff": "Department of Mechanical Engineering, Virginia Tech, Blacksburg, VA, USA; Department of Mechanical and Aerospace Engineering, University of Virginia, Charlottesville, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561469/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12015496341584427931&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Virginia Tech;University of Virginia",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.vt.edu;https://www.virginia.edu",
        "aff_unique_abbr": "VT;UVA",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Blacksburg;Charlottesville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560830",
        "title": "Autonomous UAV Safety by Visual Human Crowd Detection Using Multi-Task Deep Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Camera-equipped UAVs, or drones, are increasingly employed in a wide range of applications. Thus, ensuring their safe flight in areas containing people is a top priority. In this paper, a deep neural network-based method is proposed for the task of visual human crowd detection from UAV footage, allowing a drone to rapidly extract semantic segmentation maps from captured video frames during flight. These maps can be exploited (e.g., by a path planner) to define no-fly zones over, or near human crowds and, hence, enhance UAV flight safety. To this end, a novel neural architecture for binary (crowd/non- crowd) semantic segmentation from single RGB images is proposed, based on Convolutional Neural Networks (CNNs). It consists of a semantic segmentation and an image-to-image translation (I2I) neural branch. The overall network is trained using a novel multi-task loss function that addresses both tasks by processing the output of the corresponding branch. During inference, information flows across branches through additional skip synapses to further assist the crowd detection task. In order to evaluate the proposed method, we introduce a real and a synthetic human crowd RGB image dataset. The proposed method outperforms previous aerial crowd detection methods by a large margin and without any post-processing. Moreover, it demonstrates increased generalization ability, while running at real-time and near-real-time speeds on a ground computer and on embedded AI hardware, respectively.",
        "primary_area": "",
        "author": "Christos Papaioannidis;Ioannis Mademlis;Ioannis Pitas;Christos Papaioannidis;Ioannis Mademlis;Ioannis Pitas",
        "authorids": "/37087243479;/37085450633;/37276557400;/37087243479;/37085450633;/37276557400",
        "aff": "Department of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Informatics, Aristotle University of Thessaloniki, Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560830/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3228012369440556066&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki",
        "aff_unique_dep": "Department of Informatics",
        "aff_unique_url": "https://www.auth.gr",
        "aff_unique_abbr": "AUTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Thessaloniki",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9560867",
        "title": "Autonomous Vehicle Motion Planning via Recurrent Spline Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory planning in dynamic environments can be decomposed into two sub-problems: 1) planning a path to avoid static obstacles, 2) then planning a speed profile to avoid dynamic obstacles. This is also called path-speed decomposition. In this work, we present a novel approach to solve the first sub-problem, motion planning with static obstacles. From an optimization perspective, motion planning for autonomous vehicles can be viewed as non-convex constrained nonlinear optimization, which requires a good enough initial guess to start and is often sensitive to algorithm parameters. We formulate motion planning as convex spline optimization. The convexity of the formulated problem makes it able to be solved fast and reliably, while guaranteeing a global optimum. We then reorganize the constrained spline optimization into a recurrent formulation, which further reduces the computational time to be linear in the optimization horizon size. The proposed method can be applied to both trajectory generation and motion planning problems. Its effectiveness is demonstrated in challenging scenarios such as tight lane changes and sharp turns.",
        "primary_area": "",
        "author": "Wenda Xu;Qian Wang;John M. Dolan;Wenda Xu;Qian Wang;John M. Dolan",
        "authorids": "/37085555642;/37085864517;/37283756800;/37085555642;/37085864517;/37283756800",
        "aff": "ECE, Carnegie Mellon University, Pittsburgh, PA; Applied Dynamics & Control Group, International Center for Automotive Research (CU-ICAR), Clemson University, Greenville, SC; Faculty of the Robotics Institute, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560867/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1474688369465044798&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Clemson University",
        "aff_unique_dep": "Electrical and Computer Engineering;Applied Dynamics & Control Group",
        "aff_unique_url": "https://www.cmu.edu;https://www.clemson.edu",
        "aff_unique_abbr": "CMU;Clemson",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pittsburgh;Greenville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560974",
        "title": "Avoidance Critical Probabilistic Roadmaps for Motion Planning in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning among dynamic obstacles is an essential capability towards navigation in the real-world. Sampling-based motion planning algorithms find solutions by approximating the robot\u2019s configuration space through a graph representation, predicting or computing obstacles\u2019 trajectories, and finding feasible paths via a pathfinding algorithm. In this work, we seek to improve the performance of these subproblems by identifying regions critical to dynamic environment navigation and leveraging them to construct sparse probabilistic roadmaps. Motion planning and pathfinding algorithms should allow robots to prevent encounters with obstacles, irrespective of their trajectories, by being conscious of spatial context cues such as the location of chokepoints (e.g., doorways). Thus, we propose a self-supervised methodology for learning to identify regions frequently used for obstacle avoidance from local environment features. As an application of this concept, we leverage a neural network to generate hierarchical probabilistic roadmaps termed Avoidance Critical Probabilistic Roadmaps (ACPRM). These roadmaps contain motion structures that enable efficient obstacle avoidance, reduce the search and planning space, and increase a roadmap\u2019s reusability and coverage. ACPRMs are demonstrated to achieve up to five orders of magnitude improvement over grid-sampling in the multi-agent setting and up to ten orders of magnitude over a competitive baseline in the multi-query setting.",
        "primary_area": "",
        "author": "Felipe Felix Arias;Brian Ichter;Aleksandra Faust;Nancy M. Amato;Felipe Felix Arias;Brian Ichter;Aleksandra Faust;Nancy M. Amato",
        "authorids": "/37088999294;/37086034185;/37077144300;/37277222500;/37088999294;/37086034185;/37077144300;/37277222500",
        "aff": "Department of Computer Science, Parasol Lab, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Google Research, Mountain View, CA, USA; Google Research, Mountain View, CA, USA; Department of Computer Science, Parasol Lab, University of Illinois at Urbana-Champaign, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560974/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4287805442641672682&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Google",
        "aff_unique_dep": "Department of Computer Science;Google Research",
        "aff_unique_url": "https://illinois.edu;https://research.google",
        "aff_unique_abbr": "UIUC;Google",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Urbana;Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560911",
        "title": "Avoiding Degeneracy for Monocular Visual SLAM with Point and Line Features",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a degeneracy avoidance method for a point and line based visual SLAM algorithm is proposed. Visual SLAM predominantly uses point features. However, point features lack robustness in low texture and illuminance variant environments. Therefore, line features are used to compensate the weaknesses of point features. In addition, point features are poor in representing discernable features for the naked eye, meaning mapped point features cannot be recognized. To overcome the limitations above, line features were actively employed in previous studies. However, since degeneracy arises in the process of using line features, this paper attempts to solve this problem. First, a simple method to identify degenerate lines is presented. In addition, a novel structural constraint is proposed to avoid the degeneracy problem. At last, a point and line based monocular SLAM system using a robust optical-flow based lien tracking method is implemented. The results are verified using experiments with the EuRoC dataset and compared with other state-of-the-art algorithms. It is proven that our method yields more accurate localization as well as mapping results.",
        "primary_area": "",
        "author": "Hyunjun Lim;Yeeun Kim;Kwangik Jung;Sumin Hu;Hyun Myung;Hyunjun Lim;Yeeun Kim;Kwangik Jung;Sumin Hu;Hyun Myung",
        "authorids": "/37086920575;/37086349774;/37085618149;/37088446287;/37424926900;/37086920575;/37086349774;/37085618149;/37088446287;/37424926900",
        "aff": "School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Civil and Environmental Engineering, KAIST, Daejeon, Republic of Korea; School of Electrical Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; KI-AI, and KI-R, School of Electrical Engineering, KAIST, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560911/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2212616433861572368&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;KAIST",
        "aff_unique_dep": "School of Electrical Engineering;Department of Civil and Environmental Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST;KAIST",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561131",
        "title": "B-splines for Purely Vision-based Localization and Mapping on Non-holonomic Ground Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Purely vision-based localization and mapping is a cost-effective and thus attractive solution to localization and mapping on smart ground vehicles. However, the accuracy and especially robustness of vision-only solutions remain rivalled by more expensive, lidar-based multi-sensor alternatives. We show that a significant increase in robustness can be achieved if taking non-holonomic kinematic constraints on the vehicle motion into account. Rather than using approximate planar motion models or simple, pair-wise regularization terms, we demonstrate the use of B-splines for an exact imposition of smooth, non-holonomic trajectories inside the 6 DoF bundle adjustment. We introduce both hard and soft formulations and compare their computational efficiency and accuracy against traditional solutions. Through results on both simulated and real data, we demonstrate a significant improvement in robustness and accuracy in degrading visual conditions.",
        "primary_area": "",
        "author": "Kun Huang;Yifu Wang;Laurent Kneip;Kun Huang;Yifu Wang;Laurent Kneip",
        "authorids": "/37089501622;/37086160259;/37569040300;/37089501622;/37086160259;/37569040300",
        "aff": "Shanghai Engineering Research Center of Intelligent Vision and Imaging, ShanghaiTech University; Australian National University; Shanghai Engineering Research Center of Intelligent Vision and Imaging, ShanghaiTech University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561131/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5422280815118143703&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "ShanghaiTech University;Australian National University",
        "aff_unique_dep": "Shanghai Engineering Research Center of Intelligent Vision and Imaging;",
        "aff_unique_url": "https://www.shanghaitech.edu.cn;https://www.anu.edu.au",
        "aff_unique_abbr": "ShanghaiTech;ANU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Shanghai;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;Australia"
    },
    {
        "id": "9561367",
        "title": "Backstepping and Sliding Mode Control for AUVs Aided with Bioinspired Neurodynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Research on tracking control has been on-going for many years. The accuracy and the practicality of the tracking control method has always been one of the most important aspects when designing the control strategy. Autonomous Underwater Vehicles are becoming increasingly important in the applications of ocean surveillance and military, etc. Therefore, this paper aims to develop a control method for autonomous underwater vehicles based on bioinspired neural dynamics. The proposed method practically solves the speed jump and chattering issues that are respectively in conventional backstepping and sliding mode controls with the aid of the bioinspired neural dynamics. In addition, the proposed control method also takes the dynamic uncertainties for the autonomous underwater vehicle into the consideration. The combined tracking method has relatively good overall performance for autonomous underwater vehicle against model uncertainties and disturbances.",
        "primary_area": "",
        "author": "Zhe Xu;Simon X. Yang;S. Andrew Gadsden;Junfei Li;Danjie Zhu;Zhe Xu;Simon X. Yang;S. Andrew Gadsden;Junfei Li;Danjie Zhu",
        "authorids": "/37087246964;/37279517900;/37847767200;/37087244581;/37088997387;/37087246964;/37279517900;/37847767200;/37087244581;/37088997387",
        "aff": "School of Engineering, University of Guelph, Guelph, Canada; School of Engineering, University of Guelph, Guelph, Canada; School of Engineering, University of Guelph, Guelph, Canada; School of Engineering, University of Guelph, Guelph, Canada; School of Engineering, University of Guelph, Guelph, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561367/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2150691760104377383&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Guelph",
        "aff_unique_dep": "School of Engineering",
        "aff_unique_url": "https://www.uoguelph.ca",
        "aff_unique_abbr": "U of G",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Guelph",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561579",
        "title": "Balance Control of a Novel Wheel-legged Robot: Design and Experiments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a balance control technique for a novel wheel-legged robot. We first derive a dynamic model of the robot and then apply a linear feedback controller based on output regulation and linear quadratic regulator (LQR) methods to maintain the standing of the robot on the ground without moving backward and forward mightily. To take into account nonlinearities of the model and obtain a large domain of stability, a nonlinear controller based on the interconnection and damping assignment - passivity-based control (IDA-PBC) method is exploited to control the robot in more general scenarios. Physical experiments are performed with various control tasks. Experimental results demonstrate that the proposed linear output regulator can maintain the standing of the robot, while the proposed nonlinear controller can balance the robot under an initial starting angle far away from the equilibrium point, or under a changing robot height.",
        "primary_area": "",
        "author": "Shuai Wang;Leilei Cui;Jingfan Zhang;Jie Lai;Dongsheng Zhang;Ke Chen;Yu Zheng;Zhengyou Zhang;Zhong-Ping Jiang;Shuai Wang;Leilei Cui;Jingfan Zhang;Jie Lai;Dongsheng Zhang;Ke Chen;Yu Zheng;Zhengyou Zhang;Zhong-Ping Jiang",
        "authorids": "/37088687660;/37088689192;/37086386519;/37088688811;/37088939687;/37089001085;/37086993722;/37088690693;/37279935100;/37088687660;/37088689192;/37086386519;/37088688811;/37088939687;/37089001085;/37086993722;/37088690693;/37279935100",
        "aff": "Tencent Robotics X, Tencent Holdings, Shenzhen, China; Department of Electrical and Computer Engineering, Control and Networks Lab, Tandon School of Engineering, New York University, Brooklyn, NY, USA; Department of Electrical & Electronic Engineering, School of Engineering, University of Manchester, UK; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Tencent Robotics X, Tencent Holdings, Shenzhen, China; Department of Electrical and Computer Engineering, Control and Networks Lab, Tandon School of Engineering, New York University, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561579/",
        "gs_citation": 94,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15405450621549397468&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;2;0;0;0;0;0;1",
        "aff_unique_norm": "Tencent;New York University;University of Manchester",
        "aff_unique_dep": "Tencent Robotics X;Department of Electrical and Computer Engineering;Department of Electrical & Electronic Engineering",
        "aff_unique_url": "https://www.tencent.com;https://www.nyu.edu;https://www.manchester.ac.uk",
        "aff_unique_abbr": "Tencent;NYU;UoM",
        "aff_campus_unique_index": "0;1;2;0;0;0;0;0;1",
        "aff_campus_unique": "Shenzhen;Brooklyn;Manchester",
        "aff_country_unique_index": "0;1;2;0;0;0;0;0;1",
        "aff_country_unique": "China;United States;United Kingdom"
    },
    {
        "id": "9561615",
        "title": "Balancing on a Springy Leg",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a simulation study of the problem of balancing a planar double pendulum in which the lower body (the leg) has been modified to include a spring-loaded passive prismatic joint. Robots of this kind can travel by hopping, and can also stand and balance on a single point. The purpose of this study is to investigate the degree to which a balance controller can cope with the large and rapidly changing forces from the spring. It is shown that good performance can be achieved using an existing balance controller if the spring-loaded joint is instrumented so that its position and velocity can be taken into account when calculating the state variables needed by the balance controller.",
        "primary_area": "",
        "author": "Juan D. Gamba;Roy Featherstone;Juan D. Gamba;Roy Featherstone",
        "authorids": "/37088990443;/37449492400;/37088990443;/37449492400",
        "aff": "Dept. Informatics, Bioengineering, Robotics and Systems Engineering (Dibris), University of Genoa, Italy; Dept. Advanced Robotics, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561615/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16991804100690262037&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Genoa;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Dept. Informatics, Bioengineering, Robotics and Systems Engineering (Dibris);Dept. Advanced Robotics",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it",
        "aff_unique_abbr": "UniGe;IIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Genoa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9560745",
        "title": "Batteries, camera, action! Learning a semantic control space for expressive robot cinematography",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial vehicles are revolutionizing the way filmmakers can capture shots of actors by composing novel aerial and dynamic viewpoints. However, despite great advancements in autonomous flight technology, generating expressive camera behaviors is still a challenge and requires non-technical users to edit a large number of unintuitive control parameters. In this work, we develop a data-driven framework that enables editing of these complex camera positioning parameters in a semantic space (e.g. calm, enjoyable, establishing). First, we generate a database of video clips with a diverse range of shots in a photo-realistic simulator, and use hundreds of participants in a crowd-sourcing framework to obtain scores for a set of semantic descriptors for each clip. Next, we analyze correlations between descriptors and build a semantic control space based on cinematography guidelines and human perception studies. Finally, we learn a generative model that can map a set of desired semantic video descriptors into low-level camera trajectory parameters. We evaluate our system by demonstrating that our model successfully generates shots that are rated by participants as having the expected degrees of expression for each descriptor. We also show that our models generalize to different scenes in both simulation and real-world experiments. Data and video found at: https://sites.google.com/view/robotcam.",
        "primary_area": "",
        "author": "Rogerio Bonatti;Arthur Bucker;Sebastian Scherer;Mustafa Mukadam;Jessica Hodgins;Rogerio Bonatti;Arthur Bucker;Sebastian Scherer;Mustafa Mukadam;Jessica Hodgins",
        "authorids": "/37086934741;/37089000770;/37584159000;/37085562050;/37285071200;/37086934741;/37089000770;/37584159000;/37085562050;/37285071200",
        "aff": "Carnegie Mellon University; University of S\u00e3o Paulo; Carnegie Mellon University; Facebook AI Research; Facebook AI Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560745/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17341687120763867220&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;2",
        "aff_unique_norm": "Carnegie Mellon University;University of S\u00e3o Paulo;Meta",
        "aff_unique_dep": ";;Facebook AI Research",
        "aff_unique_url": "https://www.cmu.edu;https://www.usp.br;https://research.facebook.com",
        "aff_unique_abbr": "CMU;USP;FAIR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;Brazil"
    },
    {
        "id": "9561573",
        "title": "Bayesian Disturbance Injection: Robust Imitation Learning of Flexible Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "Scenarios requiring humans to choose from multiple seemingly optimal actions are commonplace, however standard imitation learning often fails to capture this behavior. Instead, an over-reliance on replicating expert actions induces inflexible and unstable policies, leading to poor generalizability in an application. To address the problem, this paper presents the first imitation learning framework that incorporates Bayesian variational inference for learning flexible nonparametric multi-action policies, while simultaneously robustifying the policies against sources of error, by introducing and optimizing disturbances to create a richer demonstration dataset. This combinatorial approach forces the policy to adapt to challenging situations, enabling stable multi-action policies to be learned efficiently. The effectiveness of our proposed method is evaluated through simulations and real-robot experiments for a table-sweep task using the UR3 6-DOF robotic arm. Results show that, through improved flexibility and robustness, the learning performance and control safety are better than comparison methods.",
        "primary_area": "",
        "author": "Hanbit Oh;Hikaru Sasaki;Brendan Michael;Takamitsu Matsubara;Hanbit Oh;Hikaru Sasaki;Brendan Michael;Takamitsu Matsubara",
        "authorids": "/37088999484;/37086937467;/37085555241;/37533262700;/37088999484;/37086937467;/37085555241;/37533262700",
        "aff": "Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology (NAIST), Japan; Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology (NAIST), Japan; Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology (NAIST), Japan; Division of Information Science, Graduate School of Science and Technology, Nara Institute of Science and Technology (NAIST), Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561573/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6172606938960608723&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nara Institute of Science and Technology",
        "aff_unique_dep": "Division of Information Science, Graduate School of Science and Technology",
        "aff_unique_url": "https://www.naist.edu/",
        "aff_unique_abbr": "NAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9560950",
        "title": "Beelines: Motion Prediction Metrics for Self-Driving Safety and Comfort",
        "track": "main",
        "status": "Poster",
        "abstract": "The commonly used metrics for motion prediction do not correlate well with a self-driving vehicle\u2019s system-level performance. The most common metrics are average displacement error (ADE) and final displacement error (FDE), which omit many features, making them poor self-driving performance indicators. Since high-fidelity simulations and track testing can be resource-intensive, the use of prediction metrics better correlated with full-system behavior allows for swifter iteration cycles. In this paper, we offer a conceptual framework for prediction evaluation highly specific to self-driving. We propose two complementary metrics that quantify the effects of motion prediction on safety (related to recall) and comfort (related to precision). Using a simulator, we demonstrate that our safety metric has a significantly better signal-to-noise ratio than displacement error in identifying unsafe events.",
        "primary_area": "",
        "author": "Skanda Shridhar;Yuhang Ma;Tara Stentz;Zhengdi Shen;Galen Clark Haynes;Neil Traft;Skanda Shridhar;Yuhang Ma;Tara Stentz;Zhengdi Shen;Galen Clark Haynes;Neil Traft",
        "authorids": "/37088997442;/37088998530;/37088996950;/37089002015;/37089406900;/37086106200;/37088997442;/37088998530;/37088996950;/37089002015;/37089406900;/37086106200",
        "aff": "Uber Advanced Technologies Group, PA, USA; Uber Advanced Technologies Group, PA, USA; Uber Advanced Technologies Group, PA, USA; Uber Advanced Technologies Group, PA, USA; Uber Advanced Technologies Group, PA, USA; Uber Advanced Technologies Group, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560950/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8416089101639687500&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Uber Advanced Technologies Group",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uber.com",
        "aff_unique_abbr": "Uber ATG",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561095",
        "title": "Behavior Planning at Urban Intersections through Hierarchical Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "For autonomous vehicles, effective behavior planning is crucial to ensure safety of the ego car. In many urban scenarios, it is hard to create sufficiently general heuristic rules, especially for challenging scenarios that some new human drivers find difficult. In this work, we propose a behavior planning structure based on reinforcement learning (RL) which is capable of performing autonomous vehicle behavior planning with a hierarchical structure in simulated urban environments. Application of the hierarchical structure [1] allows the various layers of the behavior planning system to be satisfied. Our algorithms can perform better than heuristic-rule-based methods for elective decisions such as when to turn left between vehicles approaching from the opposite direction or possible lane-change when approaching an intersection due to lane blockage or delay in front of the ego car. Such behavior is hard to evaluate as correct or incorrect, but some aggressive expert human drivers handle such scenarios effectively and quickly. On the other hand, compared to traditional RL methods, our algorithm is more sample-efficient, due to the use of a hybrid reward mechanism and heuristic exploration during the training process. The results also show that the proposed method converges to an optimal policy faster than traditional RL methods.",
        "primary_area": "",
        "author": "Zhiqian Qiao;Jeff Schneider;John M. Dolan;Zhiqian Qiao;Jeff Schneider;John M. Dolan",
        "authorids": "/37086488404;/37281084800;/37283756800;/37086488404;/37281084800;/37283756800",
        "aff": "Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, USA; The Robotics Institute, Carnegie Mellon University; The Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561095/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4827597599071283581&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Electrical and Computer Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561027",
        "title": "Behavior Tree Learning for Robotic Task Planning through Monte Carlo DAG Search over a Formal Grammar",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an algorithm for learning behavior trees for robotic task planning, which alleviates the need for time-intensive or infeasible manual design of control architectures. Our method involves representing the search space of behavior trees as a formal grammar and searching over this grammar by means of a new generalization of Monte Carlo tree search (MCTS) for directed acyclic graphs (DAGs), named MCDAGS. Additionally, our method employs simulated annealing to expedite the aggregation of the most functional subtrees. We present simulated experiments for a marine target search and response scenario, and an abstract task selection problem. Our results demonstrate that the learned behavior trees compare favorably with a manually-designed tree, and outperform baseline learning methods. Overall, these results show that our method is a viable technique for the automatic design of behavior trees for robotic task planning.",
        "primary_area": "",
        "author": "Emily Scheide;Graeme Best;Geoffrey A. Hollinger;Emily Scheide;Graeme Best;Geoffrey A. Hollinger",
        "authorids": "/37088999480;/37085672100;/37543482700;/37088999480;/37085672100;/37543482700",
        "aff": "Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561027/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6945861813049995140&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561608",
        "title": "Behavior-Tree-Based Person Search for Symbiotic Autonomous Mobile Robot Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of people search by a mobile social robot in case of a situation that cannot be solved by the robot alone. Examples are physically opening a closed door or operating an elevator. Based on the Behavior Tree framework, we create a modular and easily extendable action sequence with the goal of finding a person to assist the robot. By decomposing the Behavior Tree as a Discrete Time Markov Chain, we obtain an estimate of the probability and rate of success of the options for action, especially where the robot should wait or search for people. In a real-world experiment, the presented method is compared with other common approaches in a total of 588 test runs over the course of one week, starting at two different locations in a university building. We show our method to be superior to other approaches in terms of success rate and duration until a finding person and returning to the start location.",
        "primary_area": "",
        "author": "Marvin Stuede;Timo Lerche;Martin Alexander Petersen;Svenja Spindeldreier;Marvin Stuede;Timo Lerche;Martin Alexander Petersen;Svenja Spindeldreier",
        "authorids": "/37086937070;/37088996263;/37089001804;/37088940377;/37086937070;/37088996263;/37089001804;/37088940377",
        "aff": "Institute of Mechatronic Systems, Leibniz University Hannover, Garbsen, Germany; Institute of Mechatronic Systems, Leibniz University Hannover, Garbsen, Germany; Institute of Mechatronic Systems, Leibniz University Hannover, Garbsen, Germany; Institute of Mechatronic Systems, Leibniz University Hannover, Garbsen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561608/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2003695123525508603&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Leibniz University Hannover",
        "aff_unique_dep": "Institute of Mechatronic Systems",
        "aff_unique_url": "https://www.leibniz.uni-hannover.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Garbsen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561121",
        "title": "Belief Space Partitioning for Symbolic Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a memory-constrained partition-based method to extract symbolic representations of the belief state and its dynamics in order to solve planning problems in a partially observable Markov decision process (POMDP). Our K-means partitioning strategy uses a fixed number of symbols to represent the partitions of the belief space and ensures the parameterization of the belief dynamics does not grow exponentially as the system dimension increases. By casting our problem as a partitioning of the POMDP, we can then solve planning problems using traditional symbolic planning solvers (such as HTN or A* solvers). Our work is motivated by an autonomous underwater vehicle navigation problem where the vehicle is affected by uncertain flow conditions and receives severely limited position observations. Simulation experiments are provided to validate the performance of the proposed algorithms.",
        "primary_area": "",
        "author": "Mengxue Hou;Tony X. Lin;Haomin Zhou;Wei Zhang;Catherine R. Edwards;Fumin Zhang;Mengxue Hou;Tony X. Lin;Haomin Zhou;Wei Zhang;Catherine R. Edwards;Fumin Zhang",
        "authorids": "/37086538614;/37088439582;/37834718900;/37089656248;/37085893403;/37406187900;/37086538614;/37088439582;/37834718900;/37089656248;/37085893403;/37406187900",
        "aff": "School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia, USA; School of Mathematics, Georgia Institute of Technology, Atlanta, Georgia, USA; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Skidaway Institute of Oceanography, University of Georgia, Savannah, Georgia, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, Georgia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561121/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1459658556674510673&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "Georgia Institute of Technology;Southern University of Science and Technology;University of Georgia",
        "aff_unique_dep": "School of Electrical and Computer Engineering;Department of Mechanical and Energy Engineering;Skidaway Institute of Oceanography",
        "aff_unique_url": "https://www.gatech.edu;https://www.sustech.edu.cn;https://www.uga.edu",
        "aff_unique_abbr": "Georgia Tech;SUSTech;UGA",
        "aff_campus_unique_index": "0;0;0;1;2;0",
        "aff_campus_unique": "Atlanta;Shenzhen;Savannah",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9561134",
        "title": "Benchmarking Domain Randomisation for Visual Sim-to-Real Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Domain randomisation is a very popular method for visual sim-to-real transfer in robotics, due to its simplicity and ability to achieve transfer without any real-world images at all. Nonetheless, a number of design choices must be made to achieve optimal transfer. In this paper, we perform a comprehensive benchmarking study on these different choices, with two key experiments evaluated on a real-world object pose estimation task. First, we study the rendering quality, and nd that a small number of high-quality images is superior to a large number of low-quality images. Second, we study the type of randomisation, and nd that both distractors and textures are important for generalisation to novel environments.",
        "primary_area": "",
        "author": "Raghad Alghonaim;Edward Johns;Raghad Alghonaim;Edward Johns",
        "authorids": "/37089000835;/37602799000;/37089000835;/37602799000",
        "aff": "The Robot Learning Lab, Imperial College London; The Robot Learning Lab, Imperial College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561134/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9346120468962205996&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "The Robot Learning Lab",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561026",
        "title": "Benchmarking Real-Time Capabilities of ROS 2 and OROCOS for Robotics Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Numerous robotic and control applications have strict real-time requirements, which, when violated, result in reduced quality of service or, in case of safety critical applications, might even have catastrophic consequences. To ensure that certain real-time constraints are satisfied, roboticists have relied on real-time safe frameworks, environments and middleware. With the introduction of ROS 2, alongside kernel patches such as PREEMPT_RT, there is an abundance of solutions to pick from. This paper compares OROCOS and ROS 2 over PREEMPT_RT and vanilla Linux kernels in a variety of benchmarks and draws conclusions on their performance in real-time critical applications. The outcome of the benchmark shows comparable performances under normal conditions. However, when the system is under stress both frameworks suffer in different fashions. Furthermore, the results show an accumulating error which over time violates the real-time requirements in both frameworks. These findings are paramount in conducting real world application with real-time constraints.",
        "primary_area": "",
        "author": "Sinan Barut;Marco Boneberger;Pouya Mohammadi;Jochen J. Steil;Sinan Barut;Marco Boneberger;Pouya Mohammadi;Jochen J. Steil",
        "authorids": "/37088998540;/37089000313;/37085482974;/37328304300;/37088998540;/37089000313;/37085482974;/37328304300",
        "aff": "The Institute of Robotics and Process Control, Technische Universit\u00e4t Braunschweig, Braunschweig, Germany; The Institute of Robotics and Process Control, Technische Universit\u00e4t Braunschweig, Braunschweig, Germany; The Institute of Robotics and Process Control, Technische Universit\u00e4t Braunschweig, Braunschweig, Germany; The Institute of Robotics and Process Control, Technische Universit\u00e4t Braunschweig, Braunschweig, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561026/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=288860074692782391&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Braunschweig",
        "aff_unique_dep": "Institute of Robotics and Process Control",
        "aff_unique_url": "https://www.tu-braunschweig.de",
        "aff_unique_abbr": "TU Braunschweig",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Braunschweig",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561006",
        "title": "Beyond ANN: Exploiting Structural Knowledge for Efficient Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual place recognition is the task of recognizing same places of query images in a set of database images. It is important for loop closure detection in SLAM and candidate selection for global localization. Many approaches in the literature perform computationally inefficient full image comparisons between queries and all database images. There is still a lack of suited methods for efficient place recognition that allow a fast, sparse comparison of only the most promising image pairs without any loss in performance. While this is partially given by approximate nearest neighbor (ANN) based methods, they trade speed for precision and additional memory consumption, and many cannot find arbitrary numbers of matching database images in case of loops in the database. In this paper, we propose a novel fast sequence-based method for efficient place recognition that can be applied online. It uses relocalization to recover from sequence losses, and exploits usually available but often unused intra-database similarities for a potential detection of all matching database images for each query in case of loops or stops in the database. We performed extensive experimental evaluations over five datasets and 21 sequence combinations, and show that our method outperforms two state-of-the-art approaches and even full image comparisons in many cases, while providing a good tradeoff between performance and percentage of evaluated image pairs. Code is available 1.",
        "primary_area": "",
        "author": "Stefan Schubert;Peer Neubert;Peter Protzel;Stefan Schubert;Peer Neubert;Peter Protzel",
        "authorids": "/37086245725;/37600009900;/37330206000;/37086245725;/37600009900;/37330206000",
        "aff": "Faculty of Electrical Engineering and Automation Technology, Chemnitz University of Technology, Chemnitz, Germany; Faculty of Electrical Engineering and Automation Technology, Chemnitz University of Technology, Chemnitz, Germany; Faculty of Electrical Engineering and Automation Technology, Chemnitz University of Technology, Chemnitz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561006/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10108127031903741492&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chemnitz University of Technology",
        "aff_unique_dep": "Faculty of Electrical Engineering and Automation Technology",
        "aff_unique_url": "https://www.tu-chemnitz.de",
        "aff_unique_abbr": "TUC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chemnitz",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561455",
        "title": "Bias Compensated UWB Anchor Initialization using Information-Theoretic Supported Triangulation Points",
        "track": "main",
        "status": "Poster",
        "abstract": "For Ultra-Wide-Band (UWB) based navigation, an accurate initialization of the anchors in a reference coordinate system is crucial for precise subsequent UWB-inertial based pose estimation. This paper presents a strategy based on information theory to initialize such UWB anchors using raw distance measurements from tag to anchor(s) and aerial vehicle poses. We include a linear distance-dependent bias term and an offset in our estimation process in order to achieve unprecedented accuracy in the 3D position estimates of the anchors (error reduction by a factor of about 3.5 compared to current approaches) without the need of prior knowledge. After an initial coarse position triangulation of the anchors using random vehicle positions, a bounding volume is created in the vicinity of the roughly estimated anchor position. In this volume, we calculate points which provide the maximal triangulation related information based on the Fisher Information Theory. Using these information theoretic optimal points, a fine triangulation is done including bias term estimation. We evaluate our approach in simulations with realistic sensor noise as well as with real world experiments. We also fly an aerial vehicle with UWB-inertial based closed loop control demonstrating that precise anchor initialization does improve navigation precision. Our initialization approach is compared to state-of-the-art as well as to an initialization without the simultaneous bias estimation.",
        "primary_area": "",
        "author": "Julian Blueml;Alessandro Fornasier;Stephan Weiss;Julian Blueml;Alessandro Fornasier;Stephan Weiss",
        "authorids": "/37088999142;/37088685957;/37535323400;/37088999142;/37088685957;/37535323400",
        "aff": "Control of Networked Systems Group, University of Klagenfurt, Austria; Control of Networked Systems Group, University of Klagenfurt, Austria; Control of Networked Systems Group, University of Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561455/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4230601659849002979&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Klagenfurt",
        "aff_unique_dep": "Control of Networked Systems Group",
        "aff_unique_url": "https://www.uni-klagenfurt.at",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9560885",
        "title": "Bidirectional Attention Network for Monocular Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a Bidirectional Attention Network (BANet), an end-to-end framework for monocular depth estimation (MDE) that addresses the limitation of effectively integrating local and global information in convolutional neural networks. The structure of this mechanism derives from a strong conceptual foundation of neural machine translation, and presents a light-weight mechanism for adaptive control of computation similar to the dynamic nature of recurrent neural networks. We introduce bidirectional attention modules that utilize the feed-forward feature maps and incorporate the global context to filter out ambiguity. Extensive experiments reveal the high degree of capability of this bidirectional attention model over feed-forward baselines and other state-of-the-art methods for monocular depth estimation on two challenging datasets - KITTI and DIODE. We show that our proposed approach either outperforms or performs at least on a par with the state-of-the-art monocular depth estimation methods with less memory and computational complexity.",
        "primary_area": "",
        "author": "Shubhra Aich;Jean Marie Uwabeza Vianney;Md Amirul Islam;Mannat Kaur Bingbing Liu;Shubhra Aich;Jean Marie Uwabeza Vianney;Md Amirul Islam;Mannat Kaur Bingbing Liu",
        "authorids": "/37085387003;/37087103547;/37088999107;/37089002151;/37085387003;/37087103547;/37088999107;/37089002151",
        "aff": "Noah\u2019s Ark Laboratory, Huawei Technologies, Markham, ON, Canada; Noah\u2019s Ark Laboratory, Huawei Technologies, Markham, ON, Canada; Noah\u2019s Ark Laboratory, Huawei Technologies, Markham, ON, Canada; Noah\u2019s Ark Laboratory, Huawei Technologies, Markham, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560885/",
        "gs_citation": 105,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7407217712191423021&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Noah\u2019s Ark Laboratory",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Markham",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561673",
        "title": "Bimanual Regrasping for Suture Needles using Reinforcement Learning for Rapid Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Regrasping a suture needle is an important yet time-consuming process in suturing. To bring efficiency into regrasping, prior work either designs a task-specific mechanism or guides the gripper toward some specific pick-up point for proper grasping of a needle. Yet, these methods are usually not deployable when the working space is changed. Therefore, in this work, we present rapid trajectory generation for bimanual needle regrasping via reinforcement learning (RL). Demonstrations from a sampling-based motion planning algorithm is incorporated to speed up the learning. In addition, we propose the ego-centric state and action spaces for this bimanual planning problem, where the reference frames are on the end-effectors instead of some fixed frame. Thus, the learned policy can be directly applied to any feasible robot configuration. Our experiments in simulation show that the success rate of a single pass is 97%, and the planning time is 0.0212s on average, which outperforms other widely used motion planning algorithms. For the real-world experiments, the success rate is 73.3% if the needle pose is reconstructed from an RGB image, with a planning time of 0.0846s and a run time of 5.1454s. If the needle pose is known beforehand, the success rate becomes 90.5%, with a planning time of 0.0807s and a run time of 2.8801s.",
        "primary_area": "",
        "author": "Zih-Yun Chiu;Florian Richter;Emily K. Funk;Ryan K. Orosco;Michael C. Yip;Zih-Yun Chiu;Florian Richter;Emily K. Funk;Ryan K. Orosco;Michael C. Yip",
        "authorids": "/37086357053;/37086936752;/37088073811;/38580551800;/37085382768;/37086357053;/37086936752;/37088073811;/38580551800;/37085382768",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Surgery - Division of Head and Neck Surgery, University of California San Diego, La Jolla, CA, USA; Department of Surgery - Division of Head and Neck Surgery, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561673/",
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15278790538251941291&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561045",
        "title": "Binary-LoRAX: Low-Latency Runtime Adaptable XNOR Classifier for Semi-Autonomous Grasping with Prosthetic Hands",
        "track": "main",
        "status": "Poster",
        "abstract": "Intelligent, semi-autonomous prostheses take ad-vantage of combining autonomous functions and traditional myoelectric control. With the help of visual and environment sensors, intelligent prostheses achieve a level of autonomy which relieves the user from generating elaborate electromyographic (EMG) signals for grasp type and trajectory. To achieve the desired functionality, the semi-autonomous prosthesis must efficiently process the incoming environmental data at a high rate, with low power and high accuracy. In this paper, we propose Binary-LoRAX, a low-latency runtime adaptable classifier for the semi-autonomous grasping task of prosthetic hands. We offload the classification task to an efficient binary neural network accelerator which performs high-throughput XNOR operations on digital signal processing (DSP) blocks. To tailor the classifier\u2019s performance to the current application scenario, we propose a frequency scaling approach which dynamically switches between two modes of operation, high-performance and power-saving. At high-performance, classifications are performed with a low latency of 0.45ms, high-throughput of 4999 FPS and power consumption of \u223c 2.15 W. This enables functions such as object localization and batch classification. Switching to power-saving mode, a latency of 80 ms is maintained, with up to 19% improved classifier battery-life. Our prototypes achieve a high accuracy of up to 99.82% on a 25 class problem from the YCB graspable object dataset.",
        "primary_area": "",
        "author": "Nael Fasfous;Manoj-Rohit Vemparala;Alexander Frickenstein;Mohamed Badawy;Felix Hundhausen;Julian H\u00f6fer;Naveen-Shankar Nagaraja;Christian Unger;Hans-J\u00f6rg V\u00f6gel;J\u00fcrgen Becker;Tamim Asfour;Walter Stechele;Nael Fasfous;Manoj-Rohit Vemparala;Alexander Frickenstein;Mohamed Badawy;Felix Hundhausen;Julian H\u00f6fer;Naveen-Shankar Nagaraja;Christian Unger;Hans-J\u00f6rg V\u00f6gel;J\u00fcrgen Becker;Tamim Asfour;Walter Stechele",
        "authorids": "/37088489057;/37085862632;/37086928555;/37089946350;/37086581259;/37089341628;/37085648406;/38236678900;/37086372121;/37270020100;/37295529100;/37295611800;/37088489057;/37085862632;/37086928555;/37089946350;/37086581259;/37089341628;/37085648406;/38236678900;/37086372121;/37270020100;/37295529100;/37295611800",
        "aff": "Technical University of Munich; BMW Group; BMW Group; Technical University of Munich; Karlsruhe Institute of Technology; Karlsruhe Institute of Technology; BMW Group; BMW Group; BMW Group; Karlsruhe Institute of Technology; Karlsruhe Institute of Technology; Technical University of Munich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561045/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12173848318916555163&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;1;1;0;2;2;1;1;1;2;2;0",
        "aff_unique_norm": "Technical University of Munich;BMW Group;Karlsruhe Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.tum.de;https://www.bmwgroup.com;https://www.kit.edu",
        "aff_unique_abbr": "TUM;BMW;KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561288",
        "title": "Biomimetic Control of Myoelectric Prosthetic Hand Based on a Lambda-type Muscle Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Myoelectric prosthetic hands are intended to re-place the function of the amputee\u2019s lost arm. Therefore, developing robotic prosthetics that can mimic not only the appearance and functionality of humans but also characteristics unique to human movements is paramount. This paper proposes a novel biomimetic control method for myoelectric prosthetic hands integrating the impedance model with the concept of the \u03bb-type muscle model. According to the state of the muscle, the proposed method can dynamically control the joint equilibrium position, and can maintain the joint angle naturally during muscle relaxation. The experimental results, based on comparison with the actual human joint angles, suggest that the proposed method has a better correlation with the actual human motion than the conventional methods. Additionally, the control experiments showed that the proposed method could achieve a natural prosthetic hand movement similar to that of a human, thereby allowing voluntary hand movements.",
        "primary_area": "",
        "author": "Akira Furui;Kosuke Nakagaki;Toshio Tsuji;Akira Furui;Kosuke Nakagaki;Toshio Tsuji",
        "authorids": "/37086130517;/37088997210;/37271914700;/37086130517;/37088997210;/37271914700",
        "aff": "Graduate School of Advanced Science and Engineering, Hiroshima University, Higashi-Hiroshima, Japan; Graduate School of Engineering, Hiroshima University, Higashi-Hiroshima, Japan; Graduate School of Advanced Science and Engineering, Hiroshima University, Higashi-Hiroshima, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561288/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1165366939475347622&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Hiroshima University",
        "aff_unique_dep": "Graduate School of Advanced Science and Engineering",
        "aff_unique_url": "https://www.hiroshima-u.ac.jp",
        "aff_unique_abbr": "Hiroshima U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Higashi-Hiroshima",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561919",
        "title": "Biomimetic Operational Space Control for Musculoskeletal Humanoid Optimizing Across Muscle Activation and Joint Nullspace",
        "track": "main",
        "status": "Poster",
        "abstract": "We have implemented a force-based operational space controller on a physical musculoskeletal humanoid robot arm. The controller calculates muscle activations based on a biomimetic Hill-type muscle model. We propose a method to include the joint torque nullspace in the optimization process, which enables the robot to exploit the nullspace to gradually lower its overall muscle activation. We have verified in experiments that it can react compliantly to external disturbances while retaining its operational space task.",
        "primary_area": "",
        "author": "Yasunori Toshimitsu;Kento Kawaharazuka;Manabu Nishiura;Yuya Koga;Yusuke Omura;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba;Yasunori Toshimitsu;Kento Kawaharazuka;Manabu Nishiura;Yuya Koga;Yusuke Omura;Yuki Asano;Kei Okada;Koji Kawasaki;Masayuki Inaba",
        "authorids": "/37086842924;/37086101930;/37088690295;/37088339856;/37088340210;/38238750500;/37280639000;/37085684621;/37286658200;/37086842924;/37086101930;/37088690295;/37088339856;/37088340210;/38238750500;/37280639000;/37085684621;/37286658200",
        "aff": "Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan; TOYOTA MOTOR CORPORATION; Department of Mechano-Informatics, Graduate School of Information Science and Technology, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561919/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3001396781111082771&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "University of Tokyo;Toyota Motor Corporation",
        "aff_unique_dep": "Department of Mechano-Informatics;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.toyota-global.com",
        "aff_unique_abbr": "UTokyo;Toyota",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9562082",
        "title": "Bringing WALL-E out of the Silver Screen: Understanding How Transformative Robot Sound Affects Human Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Lovable robots in movies regularly beep, chirp, and whirr, yet robots in the real world rarely deploy such sounds. Despite preliminary work supporting the perceptual and objective benefits of intentionally-produced robot sound, relatively little research is ongoing in this area. In this paper, we systematically evaluate transformative robot sound across multiple robot archetypes and behaviors. We conducted a series of five online video-based surveys, each with N\u2248 100 participants, to better understand the effects of musician-designed transformative sounds on perceptions of personal, service, and industrial robots. Participants rated robot videos with transformative sound as significantly happier, warmer, and more competent in all five studies, as more energetic in four studies, and as less discomforting in one study. Overall, results confirmed that transformative sounds consistently improve subjective ratings but may convey affect contrary to the intent of affective robot behaviors. In future work, we will investigate the repeatability of these results through in-person studies and develop methods to automatically generate transformative robot sound. This work may benefit researchers and designers who aim to make robots more favorable to human users.",
        "primary_area": "",
        "author": "Brian J. Zhang;Nick Stargu;Samuel Brimhall;Lilian Chan;Jason Fick;Naomi T. Fitter;Brian J. Zhang;Nick Stargu;Samuel Brimhall;Lilian Chan;Jason Fick;Naomi T. Fitter",
        "authorids": "/37088691065;/37089000621;/37088997521;/37088945572;/37088997291;/37077925800;/37088691065;/37089000621;/37088997521;/37088945572;/37088997291;/37077925800",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Unaffiliated Performing Artist; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Music Department, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562082/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6906010354820875409&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Oregon State University;Unaffiliated Performing Artist",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute;",
        "aff_unique_url": "https://oregonstate.edu;",
        "aff_unique_abbr": "OSU;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Corvallis;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "9560977",
        "title": "CABiNet: Efficient Context Aggregation Network for Low-Latency Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "With the increasing demand of autonomous machines, pixel-wise semantic segmentation for visual scene understanding needs to be not only accurate but also efficient for any potential real-time applications. In this paper, we propose CABiNet (Context Aggregated Bi-lateral Network), a dual branch convolutional neural network (CNN), with significantly lower computational costs as compared to the state-of-the-art, while maintaining a competitive prediction accuracy. Building upon the existing multi-branch architectures for high-speed semantic segmentation, we design a cheap high resolution branch for effective spatial detailing and a context branch with light-weight versions of global aggregation and local distribution blocks, potent to capture both long-range and local contextual dependencies required for accurate semantic segmentation, with low computational overheads. Specifically, we achieve 76.6% and 75.9% mIOU on Cityscapes validation and test sets respectively, at 76 FPS on an NVIDIA RTX 2080Ti and 8 FPS on a Jetson Xavier NX.",
        "primary_area": "",
        "author": "Saumya Kumaar;Ye Lyu;Francesco Nex;Michael Ying Yang;Saumya Kumaar;Ye Lyu;Francesco Nex;Michael Ying Yang",
        "authorids": "/37086360433;/37087091991;/37541648900;/37086073066;/37086360433;/37087091991;/37541648900;/37086073066",
        "aff": "University of Twente, The Netherlands; University of Twente, The Netherlands; University of Twente, The Netherlands; University of Twente, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560977/",
        "gs_citation": 74,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10208960908179299395&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Twente",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utwente.nl",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9561190",
        "title": "CAROM - Vehicle Localization and Traffic Scene Reconstruction from Monocular Cameras on Road Infrastructures",
        "track": "main",
        "status": "Poster",
        "abstract": "Traffic monitoring cameras are powerful tools for traffic management and essential components of intelligent road infrastructure systems. In this paper, we present a vehicle localization and traffic scene reconstruction framework using these cameras, dubbed as CAROM, i.e., \"CARs On the Map\". CAROM processes traffic monitoring videos and converts them to anonymous data structures of vehicle type, 3D shape, position, and velocity for traffic scene reconstruction and replay. Through collaborating with a local department of transportation in the United States, we constructed a benchmarking dataset containing GPS data, roadside camera videos, and drone videos to validate the vehicle tracking results. On average, the localization error is approximately 0.8 m and 1.7 m within the range of 50 m and 120 m from the cameras, respectively.",
        "primary_area": "",
        "author": "Duo Lu;Varun C Jammula;Steven Como;Jeffrey Wishart;Yan Chen;Yezhou Yang;Duo Lu;Varun C Jammula;Steven Como;Jeffrey Wishart;Yan Chen;Yezhou Yang",
        "authorids": "/37086105021;/37088508837;/37088999441;/37086206905;/37086037127;/37086004333;/37086105021;/37088508837;/37088999441;/37086206905;/37086037127;/37086004333",
        "aff": "Arizona State University, Tempe, AZ, USA; Arizona State University, Tempe, AZ, USA; Arizona State University, Tempe, AZ, USA; Exponent, Tempe, AZ, USA; Arizona State University, Tempe, AZ, USA; Arizona State University, Tempe, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561190/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17709264214729150278&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Arizona State University;Exponent",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.asu.edu;",
        "aff_unique_abbr": "ASU;",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561069",
        "title": "CLIPPER: A Graph-Theoretic Framework for Robust Data Association",
        "track": "main",
        "status": "Poster",
        "abstract": "We present CLIPPER (Consistent LInking, Pruning, and Pairwise Error Rectification), a framework for robust data association in the presence of noise and outliers. We formulate the problem in a graph-theoretic framework using the notion of geometric consistency. State-of-the-art techniques that use this framework utilize either combinatorial optimization techniques that do not scale well to large-sized problems, or use heuristic approximations that yield low accuracy in high-noise, high-outlier regimes. In contrast, CLIPPER uses a relaxation of the combinatorial problem and returns solutions that are guaranteed to correspond to the optima of the original problem. Low time complexity is achieved with an efficient projected gradient ascent approach. Experiments indicate that CLIPPER maintains a consistently low runtime of 15 ms where exact methods can require up to 24 s at their peak, even on small-sized problems with 200 associations. When evaluated on noisy point cloud registration problems, CLIPPER achieves 100% precision and 98% recall in 90% outlier regimes while competing algorithms begin degrading by 70% outliers. In an instance of associating noisy points of the Stanford Bunny with 990 outlier associations and only 10 inlier associations, CLIPPER successfully returns 8 inlier associations with 100% precision in 138 ms. Code is available at https://mit-acl.github.io/clipper.",
        "primary_area": "",
        "author": "Parker C. Lusk;Kaveh Fathian;Jonathan P. How;Parker C. Lusk;Kaveh Fathian;Jonathan P. How",
        "authorids": "/37088441763;/37085866524;/37276347700;/37088441763;/37085866524;/37276347700",
        "aff": "Department of Aeronautics and Astronautics, Massachusetts Institute of Technology; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561069/",
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17462897492198194090&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561714",
        "title": "CNN-based Ego-Motion Estimation for Fast MAV Maneuvers",
        "track": "main",
        "status": "Poster",
        "abstract": "In the field of visual ego-motion estimation for Micro Air Vehicles (MAVs), fast maneuvers stay challenging mainly because of the big visual disparity and motion blur. In the pursuit of higher robustness, we study convolutional neural networks (CNNs) that predict the relative pose between subsequent images from a fast-moving monocular camera facing a planar scene. Aided by the Inertial Measurement Unit (IMU), we mainly focus on translational motion. The networks we study have similar small model sizes (around 1.35MB) and high inference speeds (around 10 milliseconds on a mobile GPU). Images for training and testing have realistic motion blur. Departing from a network framework that iteratively warps the first image to match the second with cascaded network blocks, we study different network architectures and training strategies. Simulated datasets and a self-collected MAV flight dataset are used for evaluation. The proposed setup shows better accuracy over existing networks and traditional feature-point-based methods during fast maneuvers. Moreover, self-supervised learning outperforms supervised learning. Videos and open-sourced code are available at https://github. com/tudelft/PoseNet_Planar",
        "primary_area": "",
        "author": "Yingfu Xu;Guido C. H. E. de Croon;Yingfu Xu;Guido C. H. E. de Croon",
        "authorids": "/37089001042;/37698062600;/37089001042;/37698062600",
        "aff": "Micro Air Vehicle Laboratory, Faculty of Aerospace Engineering, Delft University of Technology, The Netherlands; Micro Air Vehicle Laboratory, Faculty of Aerospace Engineering, Delft University of Technology, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561714/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17730037266550590008&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Faculty of Aerospace Engineering",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9560909",
        "title": "COLREGs-Informed RRT* for Collision Avoidance of Marine Crafts",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper proposes novel sampling strategies to compute the optimal path alteration of a surface vessel sailing in close quarters. Such strategy directly encodes the rules for safe navigation at sea, by exploiting the concept of minimal ship domain to determine the compliant region where the path deviation is to be generated. The sampling strategy is integrated within the optimal rapidly-exploring random tree algorithm, which minimizes the length of the path deviation. Further, the feasibility of the path with respect to the steering characteristics of own ship is verified by ensuring that the position of the new waypoints respects the minimum turning radius of the vessel. The proposed sampling strategy brings a significant performance improvement both in terms of optimal cost, computational speed and convergence rate.",
        "primary_area": "",
        "author": "Thomas Thuesen Enevoldsen;Christopher Reinartz;Roberto Galeazzi;Thomas Thuesen Enevoldsen;Christopher Reinartz;Roberto Galeazzi",
        "authorids": "/37086448170;/37088996682;/38548724800;/37086448170;/37088996682;/38548724800",
        "aff": "Department of Electrical Engineering, Automation and Control Group, Technical University of Denmark, Lyngby, Denmark; Department of Electrical Engineering, Automation and Control Group, Technical University of Denmark, Lyngby, Denmark; Department of Electrical Engineering, Automation and Control Group, Technical University of Denmark, Lyngby, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560909/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11276585375041097419&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Denmark",
        "aff_unique_dep": "Department of Electrical Engineering, Automation and Control Group",
        "aff_unique_url": "https://www.tu.dk",
        "aff_unique_abbr": "DTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lyngby",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9561528",
        "title": "CSM: Contact Sensitivity Maps for Benchmarking Robot Collision Handling Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In physical human-robot interaction (pHRI), robots need to detect and react to intended and unintended contacts in a safe manner. Proprioceptive sensing capabilities and collision detection and identification techniques differ among commercially available robots, which means that also their sensitivity to detect dynamic collisions with the environment or the human co-worker differ. Up to now, there exists no standardized procedure for assessing the contact sensitivity of a robotic system. In this paper, we propose the concept of contact sensitivity maps (CSM), a relationship between the robot's dynamic impact properties and the reliability of its collision handling. The CSM allows the robot user to determine for which robot workspace areas and dynamic collision parameters (mass, velocity) reliable contact detection and reaction can be expected. We propose a standardized benchmarking procedure and test setup for deriving CSMs. Finally, we analyze and compare the experimental results of the Universal Robots UR10e, UR5e, and Franka Emika Panda, where we observe significant differences in contact sensitivity.",
        "primary_area": "",
        "author": "Robin Jeanne Kirschner;Jo\u00e3o Jantalia;Nico Mansfeld;Saeed Abdolshah;Sami Haddadin;Robin Jeanne Kirschner;Jo\u00e3o Jantalia;Nico Mansfeld;Saeed Abdolshah;Sami Haddadin",
        "authorids": "/37088861072;/37088998326;/38541896600;/37086148547;/37542865300;/37088861072;/37088998326;/38541896600;/37086148547;/37542865300",
        "aff": "Institute for Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Institute for Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Institute for Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Institute for Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Institute for Robotics and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561528/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13016743046663315153&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Institute for Robotics and Systems Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561658",
        "title": "CVaR-based Flight Energy Risk Assessment for Multirotor UAVs using a Deep Energy Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Energy management is a critical aspect of risk assessment for Uncrewed Aerial Vehicle (UAV) flights, as a depleted battery during a flight brings almost guaranteed vehicle damage and a high risk of human injuries or property damage. Predicting the amount of energy a flight will consume is challenging as routing, weather, obstacles, and other factors affect the overall consumption. We develop a deep energy model for a UAV that uses Temporal Convolutional Networks to capture the time varying features while incorporating static contextual information. Our energy model is trained on a real world dataset and does not require segregating flights into regimes. We illustrate an improvement in power predictions by 29% on test flights when compared to a state-of-the-art analytical method. Using the energy model, we can predict the energy usage for a given trajectory and evaluate the risk of running out of battery during flight. We propose using Conditional Value-at-Risk (CVaR) as a metric for quantifying this risk. We show that CVaR captures the risk associated with worst-case energy consumption on a nominal path by transforming the output distribution of Monte Carlo forward simulations into a risk space. Computing the CVaR on the risk-space distribution provides a metric that can evaluate the overall risk of a flight before take-off. Our energy model and risk evaluation method can improve flight safety and evaluate the coverage area from a proposed takeoff location. The video and codebase are available at: [Video]a | [Code]b",
        "primary_area": "",
        "author": "Arnav Choudhry;Brady Moon;Jay Patrikar;Constantine Samaras;Sebastian Scherer;Arnav Choudhry;Brady Moon;Jay Patrikar;Constantine Samaras;Sebastian Scherer",
        "authorids": "/37088996144;/37086448648;/37086449345;/37540663000;/37584159000;/37088996144;/37086448648;/37086449345;/37540663000;/37584159000",
        "aff": "Department of Civil and Environmental Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Civil and Environmental Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561658/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=638106956880751143&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Civil and Environmental Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561149",
        "title": "CamVox: A Low-cost and Accurate Lidar-assisted Visual SLAM System",
        "track": "main",
        "status": "Poster",
        "abstract": "Combining lidar in camera-based simultaneous localization and mapping (SLAM) is an effective method in improving overall accuracy, especially at outdoor large scale scenes. Recent development of low-cost lidars (e.g. Livox lidar) enable us to explore such SLAM systems with lower budget and higher performance. In this paper we propose CamVox by adapting Livox lidars into visual SLAM (ORB-SLAM2) by exploring the lidars\u2019 unique features. Based on the unique scan pattern of Livox lidars, we propose an automatic lidar-camera calibration method that will work in uncontrolled scenes. The long depth detection range also benefit a more accurate mapping. Comparison of CamVox with visual SLAM (VINS-mono) and lidar SLAM (LOAM) are evaluated on the same dataset to demonstrate the performance. We open sourced our hardware, code and dataset on GitHub1.",
        "primary_area": "",
        "author": "Yuewen Zhu;Chunran Zheng;Chongjian Yuan;Xu Huang;Xiaoping Hong;Yuewen Zhu;Chunran Zheng;Chongjian Yuan;Xu Huang;Xiaoping Hong",
        "authorids": "/37088998674;/37088928114;/37088939463;/37089000881;/37088942003;/37088998674;/37088928114;/37088939463;/37089000881;/37088942003",
        "aff": "School of System Design and Intelligent Manufacturing, Southern University of Science and Technology, China; School of System Design and Intelligent Manufacturing, Southern University of Science and Technology, China; School of System Design and Intelligent Manufacturing, Southern University of Science and Technology, China; School of System Design and Intelligent Manufacturing, Southern University of Science and Technology, China; School of System Design and Intelligent Manufacturing, Southern University of Science and Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561149/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology",
        "aff_unique_dep": "School of System Design and Intelligent Manufacturing",
        "aff_unique_url": "https://www.sustech.edu.cn",
        "aff_unique_abbr": "SUSTech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561289",
        "title": "Camera Relocalization using Deep Point Cloud Generation and Hand-crafted Feature Refinement",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual localization plays an indispensable role in robotics. Both learning and hand-crafted feature based methods for relocalization process keep their effectiveness and weakness. However, current algorithms seldom consider these two kinds of features under one framework. In this paper, focusing on this task, we propose a novel relocalization framework for RGB or RGB-D data source, which is composed of coarse localization process by learning features and pose refinement by hand-crafted features. In particular, coarse stage contains deep point cloud generation and registration. In this stage, instead of regressing camera pose directly, the paper novelly designs a neural network called PGNet to construct sparse point cloud with RGB or RGB-D as inputs. Further more, by means of training set, hand-crafted feature space is established. Based on the obtained camera pose in coarse stage, accurate point-to-point correspondences are set up through searching the space. Then accurate camera pose is obtained by applying RANSAC to correspondences or solving PnP. Finally, experiments on both outdoor and indoor benchmark datasets demonstrate state-of-the-art performance over other existing methods.",
        "primary_area": "",
        "author": "Wang Junyi;Qi Yue;Wang Junyi;Qi Yue",
        "authorids": "/37428528900;/37531291200;/37428528900;/37531291200",
        "aff": "Peng Cheng Laboratory, ShenZhen, China; Qingdao Research Institute of Beihang University, Qingdao, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561289/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12516175159656491515&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Pengcheng Laboratory;Beihang University",
        "aff_unique_dep": "Peng Cheng Laboratory;Qingdao Research Institute",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "ShenZhen;Qingdao",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561633",
        "title": "Can Non-Humanoid Social Robots Reduce Workload of Special Educators : An Online and In-Premises Field Study",
        "track": "main",
        "status": "Poster",
        "abstract": "Although Socially Assistive Robotics have been used in Autism Spectrum Disorder (ASD) interventions, such studies often exclude Special Educators (SEs) and often use expensive humanoid robots. In this paper, we investigate whether non-humanoid toy robots can act as teaching aids in ASD Education, in particular, can they reduce the workload of SEs. We target two most common yet divergent problems from Individualized Education Plans (IEPs) of ASD children - communication and gross motor skills. We present results from three studies a) toy robot Cozmo assists SEs in verbal lessons in school premises, b) mini drone Tello helps SEs in exercise lessons in school premises, and c) Cozmo, SEs, and ASD children connect remotely, as mandated due to the Covid-19 pandemic, for verbal lessons. All three studies showed improvement in learning outcomes and reduction in prompts from the SEs, denoting reduced workload. The effect of a robot's virtual presence in online ASD interventions has not been studied before. However, our results show that children spent more time on lessons in online intervention with Cozmo, suggesting that using robots should also be considered when designing online interventions. Furthermore, the roles of Cozmo were analyzed, and we found children showed increased spontaneous interaction when Cozmo acts as a Co-Instructor. Thus, preliminary results indicate toy robots, as opposed to expensive humanoids, may have significant potential in aiding SEs in Autism education.",
        "primary_area": "",
        "author": "Nabanita Paul;Siddharth Ramesh;Chiranjib Bhattacharya;Jayashree Ramesh;Priya Vijayan;Nabanita Paul;Siddharth Ramesh;Chiranjib Bhattacharya;Jayashree Ramesh;Priya Vijayan",
        "authorids": "/37089001825;/37088997343;/37391325600;/37086236930;/37088422488;/37089001825;/37088997343;/37391325600;/37086236930;/37088422488",
        "aff": "Department of Computer Science and Automation, Indian Institute Of Science, Bengaluru, India; Department of Computer Science and Automation, Indian Institute Of Science, Bengaluru, India; Department of Computer Science and Automation, Indian Institute Of Science, Bengaluru, India; Academy for Severe Handicaps and Autism(ASHA); Academy for Severe Handicaps and Autism(ASHA)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561633/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12427132172154775958&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "Indian Institute of Science;Academy for Severe Handicaps and Autism",
        "aff_unique_dep": "Department of Computer Science and Automation;",
        "aff_unique_url": "https://www.iisc.ac.in;",
        "aff_unique_abbr": "IISc;ASHA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bengaluru;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India;"
    },
    {
        "id": "9561112",
        "title": "Can Therapists Design Robot-Mediated Interventions and Teleoperate Robots Using VR to Deliver Interventions for ASD?",
        "track": "main",
        "status": "Poster",
        "abstract": "Socially Assistive Robots (SARs) have demonstrated success in the delivery of interventions to individuals with Autism Spectrum Disorder (ASD). To date, these robot-mediated interventions have primarily been designed and implemented by robotics researchers. It remains unclear whether therapists could independently utilize robots to deliver therapies in clinical settings. In this paper, we conducted a study to investigate whether therapists could design and implement robot-mediated interventions for children with ASD. Furthermore, we compared therapists\u2019 performance, efficiency, and perceptions towards using a Virtual Reality (VR) and kinesthetic-based interface for delivering robot-mediated interventions. Overall, our results demonstrated therapists could independently design and implement interventions with a SAR. They were faster at designing a new intervention using VR than a kinesthetic interface. Therapists also had similar performance to delivering inperson interventions when utilizing VR to deliver interventions with the robot. Therapists reported moderate workload using the VR interface and perceived VR to be usable.",
        "primary_area": "",
        "author": "Roman Kulikovskiy;Megan Sochanski;Ala\u2019aldin Hijaz;Matteson Eaton;Jessica Korneder;Wing-Yue Geoffrey Louie;Roman Kulikovskiy;Megan Sochanski;Ala\u2019aldin Hijaz;Matteson Eaton;Jessica Korneder;Wing-Yue Geoffrey Louie",
        "authorids": "/37088996798;/37088945448;/37087237346;/37088997688;/37088946177;/37088998176;/37088996798;/37088945448;/37087237346;/37088997688;/37088946177;/37088998176",
        "aff": "Intelligent Robotics Laboratory, Oakland University, Michigan, USA; Intelligent Robotics Laboratory, Oakland University, Michigan, USA; Intelligent Robotics Laboratory, Oakland University, Michigan, USA; Applied Behavior Analysis Clinic, Oakland University, Michigan, USA; Applied Behavior Analysis Clinic, Oakland University, Michigan, USA; Intelligent Robotics Laboratory, Oakland University, Michigan, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561112/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9077316218021833335&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Oakland University",
        "aff_unique_dep": "Intelligent Robotics Laboratory",
        "aff_unique_url": "https://www.oakland.edu",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Michigan",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561983",
        "title": "Can a Robot Trust You? : A DRL-Based Approach to Trust-Driven Human-Guided Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans are known to construct cognitive maps of their everyday surroundings using a variety of perceptual inputs. As such, when a human is asked for directions to a particular location, their wayfinding capability in converting this cognitive map into directional instructions is challenged. Owing to spatial anxiety, the language used in the spoken instructions can be vague and often unclear. To account for this unreliability in navigational guidance, we propose a novel Deep Reinforcement Learning (DRL) based trust-driven robot navigation algorithm that learns humans\u2019 trustworthiness to perform a language guided navigation task.Our approach seeks to answer the question as to whether a robot can trust a human\u2019s navigational guidance or not. To this end, we look at training a policy that learns to navigate towards a goal location using only trustworthy human guidance, driven by its own robot trust metric. We look at quantifying various affective features from language-based instructions and incorporate them into our policy\u2019s observation space in the form of a human trust metric. We utilize both these trust metrics into an optimal cognitive reasoning scheme that decides when and when not to trust the given guidance. Our results show that the learned policy can navigate the environment in an optimal, time-efficient manner as opposed to an explorative approach that performs the same task. We showcase the efficacy of our results both in simulation and a real world environment.",
        "primary_area": "",
        "author": "Vishnu Sashank Dorbala;Arjun Srinivasan;Aniket Bera;Vishnu Sashank Dorbala;Arjun Srinivasan;Aniket Bera",
        "authorids": "/37086951195;/37086239144;/37085393882;/37086951195;/37086239144;/37085393882",
        "aff": "University of Maryland, College Park, USA; University of Maryland, College Park, USA; University of Maryland, College Park, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561983/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14322248075586511534&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561439",
        "title": "Causal Reasoning in Simulation for Structure and Transfer Learning of Robot Manipulation Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "We present CREST, an approach for causal reasoning in simulation to learn the relevant state space for a robot manipulation policy. Our approach conducts interventions using internal models, which are simulations with approximate dynamics and simplified assumptions. These interventions elicit the structure between the state and action spaces, enabling construction of neural network policies with only relevant states as input. These policies are pretrained using the internal model with domain randomization over the relevant states. The policy network weights are then transferred to the target domain (e.g., the real world) for fine tuning. We perform extensive policy transfer experiments in simulation for two representative manipulation tasks: block stacking and crate opening. Our policies are shown to be more robust to domain shifts, more sample efficient to learn, and scale to more complex settings with larger state spaces. We also show improved zero-shot sim- to-real transfer of our policies for the block stacking task.",
        "primary_area": "",
        "author": "Tabitha E. Lee;Jialiang Alan Zhao;Amrita S. Sawhney;Siddharth Girdhar;Oliver Kroemer;Tabitha E. Lee;Jialiang Alan Zhao;Amrita S. Sawhney;Siddharth Girdhar;Oliver Kroemer",
        "authorids": "/37089274027;/37088998086;/37089000940;/37088998555;/37593222300;/37089274027;/37088998086;/37089000940;/37088998555;/37593222300",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561439/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9056769536387504298&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561276",
        "title": "Chance Constrained Simultaneous Path Planning and Task Assignment with Bottleneck Objective",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel algorithm for combined task assignment and path planning on a roadmap with stochastic costs. In this problem, the initially unassigned robots and tasks are located at known positions in a roadmap. We want to assign a unique task to each robot and compute a path for the robot to go to the task location. Given the means and variances of travel cost, our goal is to develop algorithms that guarantee that for each robot, with high probability, the total travel cost is below a minimum value in any realization of the stochastic travel costs. We prove that the solution can be obtained by solving (a) a chance-constrained shortest path problems for all robot-task pairs and (b) a linear bottleneck assignment problem in which the cost of an assignment is equal to the optimal objective value of the former problem. We propose algorithms for solving the chance-constrained shortest path problem either optimally or approximately by solving a number of deterministic shortest path problems that minimize some linear combination of means and variances of edge costs. We present simulation results on randomly generated networks and data to demonstrate that our algorithm is scalable with the number of robots (or tasks) and the size of the network.",
        "primary_area": "",
        "author": "Fan Yang;Nilanjan Chakraborty;Fan Yang;Nilanjan Chakraborty",
        "authorids": "/37086018699;/37314871600;/37086018699;/37314871600",
        "aff": "The Mechanical Engineering Department, Stony Brook University; The Mechanical Engineering Department, Stony Brook University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561276/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17251033653008322839&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stony Brook University",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.stonybrook.edu",
        "aff_unique_abbr": "SBU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stony Brook",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561945",
        "title": "Chip-Less Wireless Sensing of Kirigami Structural Morphing Under Various Mechanical Stimuli Using Home-Based Ink-Jet Printable Materials",
        "track": "main",
        "status": "Poster",
        "abstract": "The feasibility of using chip-based RFID designs as wireless sensor tags open a wide range of application possibilities in the field of robotics. However, multi-step lithography manufacturing and/or MEMS techniques are often required for the industrial-grade fabrication of such sensors. In this paper, we present a simple, home-based, two-step fabrication process to produce chipless RF-based wireless sensors. We use an office-based inkjet printer to produce the antenna traces using silver conductive ink. Kirigami-inspired designs are used to produce four sensors responsive to various mechanical stimuli commonly used for DIY robotic projects (contact, compression, extension, and bend). We demonstrate sensing and wireless transmission of the detected mechanical stimuli through the proposed chipless sensor tags with reliable consistency. The tags can be replicated quickly with the inkjet-printing method. This paper also contains analyses on the effects of varying the dimensions and electrical parameters of the tags. The developed antennas in this work can be used as wireless mechano-responsive sensors for robotic applications.",
        "primary_area": "",
        "author": "Godwin Ponraj;Wei Le Yeo;Kirthika Senthil Kumar;Manivannan Sivaperuman Kalairaj;Catherine Jiayi Cai;Hongliang Ren;Godwin Ponraj;Wei Le Yeo;Kirthika Senthil Kumar;Manivannan Sivaperuman Kalairaj;Catherine Jiayi Cai;Hongliang Ren",
        "authorids": "/37085496318;/37089001184;/37088384453;/37088918427;/37086246365;/37287561300;/37085496318;/37089001184;/37088384453;/37088918427;/37086246365;/37287561300",
        "aff": "Department of Biomedical Engineering, National University of Singapore, Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore, Singapore; Department of Electronic Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561945/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11252580013269614784&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "National University of Singapore;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Biomedical Engineering;Department of Electronic Engineering",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "NUS;CUHK",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9561926",
        "title": "Circus ANYmal: A Quadruped Learning Dexterous Manipulation with Its Limbs",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadrupedal robots are skillful at locomotion tasks while lacking manipulation skills, not to mention dexterous manipulation abilities. Inspired by the animal behavior and the duality between multi-legged locomotion and multi-fingered manipulation, we showcase a circus ball challenge on a quadrupedal robot, ANYmal. We employ a model-free reinforcement learning approach to train a deep policy that enables the robot to balance and manipulate a light-weight ball robustly using its limbs without any contact measurement sensor. The policy is trained in the simulation, in which we randomize many physical properties with additive noise and inject random disturbance force during manipulation, and achieves zero-shot deployment on the real robot without any adjustment. In the hardware experiments, dynamic performance is achieved with a maximum rotation speed of 15 \u00b0/s, and robust recovery is showcased under external poking. To our best knowledge, it is the first work that demonstrates the dexterous dynamic manipulation on a real quadrupedal robot.",
        "primary_area": "",
        "author": "Fan Shi;Timon Homberger;Joonho Lee;Takahiro Miki;Moju Zhao;Farbod Farshidian;Kei Okada;Masayuki Inaba;Marco Hutter;Fan Shi;Timon Homberger;Joonho Lee;Takahiro Miki;Moju Zhao;Farbod Farshidian;Kei Okada;Masayuki Inaba;Marco Hutter",
        "authorids": "/37086162286;/37085994390;/37086264321;/37086454028;/37085684946;/37085428006;/37280639000;/37286658200;/37545251000;/37086162286;/37085994390;/37086264321;/37086454028;/37085684946;/37085428006;/37280639000;/37286658200;/37545251000",
        "aff": "Department of Creative-Infomatics, JSK Lab, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Robotics Systems Lab, ETH Z\u00fcrich, Zurich; Robotics Systems Lab, ETH Z\u00fcrich, Zurich; Robotics Systems Lab, ETH Z\u00fcrich, Zurich; Department of Creative-Infomatics, JSK Lab, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Robotics Systems Lab, ETH Z\u00fcrich, Zurich; Department of Creative-Infomatics, JSK Lab, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Department of Creative-Infomatics, JSK Lab, The University of Tokyo, Bunkyo-ku, Tokyo, Japan; Robotics Systems Lab, ETH Z\u00fcrich, Zurich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561926/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9774736545409110798&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;0;1;0;0;1",
        "aff_unique_norm": "University of Tokyo;ETH Zurich",
        "aff_unique_dep": "Department of Creative-Infomatics;Robotics Systems Lab",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.ethz.ch",
        "aff_unique_abbr": "UTokyo;ETHZ",
        "aff_campus_unique_index": "0;1;1;1;0;1;0;0;1",
        "aff_campus_unique": "Bunkyo-ku, Tokyo;Zurich",
        "aff_country_unique_index": "0;1;1;1;0;1;0;0;1",
        "aff_country_unique": "Japan;Switzerland"
    },
    {
        "id": "9561267",
        "title": "Cirrus: A Long-range Bi-pattern LiDAR Dataset",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce Cirrus, a new long-range bi-pattern LiDAR public dataset for autonomous driving tasks such as 3D object detection, critical to highway driving and timely decision making. Our platform is equipped with a high-resolution video camera and a pair of LiDAR sensors with a 250-meter effective range, which is significantly longer than existing public datasets. We record paired point clouds simultaneously using both Gaussian and uniform scanning patterns. Point density varies significantly across such a long range, and different scanning patterns further diversify object representation in LiDAR. In Cirrus, eight categories of objects are exhaustively annotated in the LiDAR point clouds for the entire effective range. To illustrate the kind of studies supported by this new dataset, we introduce LiDAR model adaptation across different ranges, scanning patterns, and sensor devices. Promising results show the great potential of this new dataset to the robotics and computer vision communities.",
        "primary_area": "",
        "author": "Ze Wang;Sihao Ding;Ying Li;Jonas Fenn;Sohini Roychowdhury;Andreas Wallin;Lane Martin;Scott Ryvola;Guillermo Sapiro;Qiang Qiu;Ze Wang;Sihao Ding;Ying Li;Jonas Fenn;Sohini Roychowdhury;Andreas Wallin;Lane Martin;Scott Ryvola;Guillermo Sapiro;Qiang Qiu",
        "authorids": "/37279247400;/37072775400;/37086505809;/37088997712;/38580454400;/37086479698;/37088996086;/37088997449;/37274814000;/37085427467;/37279247400;/37072775400;/37086505809;/37088997712;/38580454400;/37086479698;/37088996086;/37088997449;/37274814000;/37085427467",
        "aff": "Purdue University, USA; Volvo Cars Technology, USA; Volvo Cars Technology, USA; Volvo Cars Technology, USA; Volvo Cars Technology, USA; Volvo Cars Technology, USA; Luminar Technologies, Inc., USA; Luminar Technologies, Inc., USA; Duke University, USA; Purdue University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561267/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5991362547092489007&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;1;1;1;1;2;2;3;0",
        "aff_unique_norm": "Purdue University;Volvo Cars Technology;Luminar Technologies;Duke University",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.purdue.edu;https://www.volvocars.com;https://www.luminartechnologies.com;https://www.duke.edu",
        "aff_unique_abbr": "Purdue;;;Duke",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561855",
        "title": "City-scale Scene Change Detection using Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a method for detecting structural changes in a city using images captured from vehicular mounted cameras over traversals at two different times. We first generate 3D point clouds for each traversal from the images and approximate GNSS/INS readings using Structure-from-Motion (SfM). A direct comparison of the two point clouds for change detection is not ideal due to inaccurate geo-location information and possible drifts in the SfM. To circumvent this problem, we propose a deep learning-based non-rigid registration on the point clouds which allows us to compare the point clouds for structural change detection in the scene. Furthermore, we introduce a dual thresholding check and post-processing step to enhance the robustness of our method. We collect two datasets for the evaluation of our approach. Experiments show that our method is able to detect scene changes effectively, even in the presence of viewpoint and illumination differences.",
        "primary_area": "",
        "author": "Zi Jian Yew;Gim Hee Lee;Zi Jian Yew;Gim Hee Lee",
        "authorids": "/37087233050;/37088505845;/37087233050;/37088505845",
        "aff": "Department of Computer Science, National University of Singapore; Department of Computer Science, National University of Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561855/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15005988247153814081&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9561475",
        "title": "CloudAAE: Learning 6D Object Pose Regression with On-line Data Synthesis on Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "It is often desired to train 6D pose estimation systems on synthetic data because manual annotation is expensive. However, due to the large domain gap between the synthetic and real images, synthesizing color images is expensive. In contrast, this domain gap is considerably smaller and easier to fill for depth information. In this work, we present a system that regresses 6D object pose from depth information represented by point clouds, and a lightweight data synthesis pipeline that creates synthetic point cloud segments for training. We use an augmented autoencoder (AAE) for learning a latent code that encodes 6D object pose information for pose regression. The data synthesis pipeline only requires texture-less 3D object models and desired viewpoints, and it is cheap in terms of both time and hardware storage. Our data synthesis process is up to three orders of magnitude faster than commonly applied approaches that render RGB image data. We show the effectiveness of our system on the LineMOD, LineMOD Occlusion, and YCB Video datasets. The implementation of our system is available at: https://github.com/GeeeG/CloudAAE.",
        "primary_area": "",
        "author": "Ge Gao;Mikko Lauri;Xiaolin Hu;Jianwei Zhang;Simone Frintrop;Ge Gao;Mikko Lauri;Xiaolin Hu;Jianwei Zhang;Simone Frintrop",
        "authorids": "/37086315473;/37857377500;/37085492703;/37281460600;/37402784100;/37086315473;/37857377500;/37085492703;/37281460600;/37402784100",
        "aff": "Department of Informatics, University of Hamburg, Germany; Department of Informatics, University of Hamburg, Germany; Department of Computer Science and Technology, State Key Laboratory of Intelligent Technology and Systems, Tsinghua University, China; Department of Informatics, University of Hamburg, Germany; Department of Informatics, University of Hamburg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561475/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2193664500551252894&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Hamburg;Tsinghua University",
        "aff_unique_dep": "Department of Informatics;Department of Computer Science and Technology",
        "aff_unique_url": "https://www.uni-hamburg.de;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": ";Tsinghua",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Germany;China"
    },
    {
        "id": "9561256",
        "title": "Co-Optimizing Robot, Environment, and Tool Design via Joint Manipulation Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing work on sequential manipulation planning and trajectory optimization typically assumes the robot, environment and tools to be given. However, in particular in industrial applications, it is highly interesting to ask, what would be an optimal robot design, tool shape, or robot station geometry for a particular ensemble of manipulation tasks. To tackle this problem we propose a formulation to jointly optimize over static design parameters and the sequential manipulation trajectory. We can include optimization objectives such as penalizing velocities (path length) and joint torques. Our evaluations show that design optimization can significantly improve on such metrics. For instance, in a wrench tool demonstration scenario we show that the shape of the wrench tool as well as design of the robot can be optimized to allow for exerting a necessary external torque with minimal effort.",
        "primary_area": "",
        "author": "Marc Toussaint;Jung-Su Ha;Ozgur S. Oguz;Marc Toussaint;Jung-Su Ha;Ozgur S. Oguz",
        "authorids": "/37528418600;/38543013300;/37085638620;/37528418600;/38543013300;/37085638620",
        "aff": "Max Planck Institute for Intelligent Systems, Germany; Learning & Intelligent Systems Lab, TU Berlin, Germany; Max Planck Institute for Intelligent Systems, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561256/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7559672738595549446&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;Technische Universit\u00e4t Berlin",
        "aff_unique_dep": ";Learning & Intelligent Systems Lab",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.tu-berlin.de",
        "aff_unique_abbr": "MPI-IS;TU Berlin",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berlin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9560942",
        "title": "Coarse-to-Fine Imitation Learning: Robot Manipulation from a Single Demonstration",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a simple new method for visual imitation learning, which allows a novel robot manipulation task to be learned from a single human demonstration, without requiring any prior knowledge of the object being interacted with. Our method models imitation learning as a state estimation problem, with the state defined as the end-effector\u2019s pose at the point where object interaction begins, as observed from the demonstration. By modelling a manipulation task as a coarse, approach trajectory followed by a fine, interaction trajectory, this state estimator can be trained in a self-supervised manner, by automatically moving the end-effector\u2019s camera around the object. At test time, the end-effector is moved to the estimated state through a linear path, at which point the demonstration\u2019s end-effector velocities are simply repeated, enabling convenient acquisition of a complex interaction trajectory without actually needing to explicitly learn a policy. Real-world experiments on 8 everyday tasks show that our method can learn a diverse range of skills from just a single human demonstration, whilst also yielding a stable and interpretable controller. Videos at: www.robot-learning.uk/coarse-to-fine-imitation-learning.",
        "primary_area": "",
        "author": "Edward Johns;Edward Johns",
        "authorids": "/37602799000;/37602799000",
        "aff": "Robot Learning Lab, Imperial College London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560942/",
        "gs_citation": 147,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4798806516821996780&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "Robot Learning Lab",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "ICL",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9560792",
        "title": "CodeVIO: Visual-Inertial Odometry with Learned Optimizable Dense Depth",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a lightweight, tightly-coupled deep depth network and visual-inertial odometry (VIO) system, which can provide accurate state estimates and dense depth maps of the immediate surroundings. Leveraging the proposed lightweight Conditional Variational Autoencoder (CVAE) for depth inference and encoding, we provide the network with previously marginalized sparse features from VIO to increase the accuracy of initial depth prediction and generalization capability. The compact representation of dense depth, termed depth code, can be updated jointly with navigation states in a sliding window estimator in order to provide the dense local scene geometry. We additionally propose a novel method to obtain the CVAE\u2019s Jacobian which is shown to be more than an order of magnitude faster than previous works, and we additionally leverage First-Estimate Jacobian (FEJ) to avoid recalculation. As opposed to previous works that rely on completely dense residuals, we propose to only provide sparse measurements to update the depth code and show through careful experimentation that our choice of sparse measurements and FEJs can still significantly improve the estimated depth maps. Our full system also exhibits state-of-the-art pose estimation accuracy, and we show that it can run in real-time with single-thread execution while utilizing GPU acceleration only for the network and code Jacobian.",
        "primary_area": "",
        "author": "Xingxing Zuo;Nathaniel Merrill;Wei Li;Yong Liu;Marc Pollefeys;Guoquan Huang;Xingxing Zuo;Nathaniel Merrill;Wei Li;Yong Liu;Marc Pollefeys;Guoquan Huang",
        "authorids": "/37086314032;/37087322112;/37089000271;/37066946100;/37271138500;/37077670600;/37086314032;/37087322112;/37089000271;/37066946100;/37271138500;/37077670600",
        "aff": "Institute of Cyber-System and Control, Zhejiang University; Robot Perception and Navigation Group, University of Delaware; Inceptio Technology, Shanghi, China; Institute of Cyber-System and Control, Zhejiang University; Microsoft Mixed Reality and Artificial Intelligence Lab, Z\u00fcrich; Robot Perception and Navigation Group, University of Delaware",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560792/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8030686004771200481&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;3;1",
        "aff_unique_norm": "Zhejiang University;University of Delaware;Inceptio Technology;Microsoft",
        "aff_unique_dep": "Institute of Cyber-System and Control;Robot Perception and Navigation Group;;Mixed Reality and Artificial Intelligence Lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.udel.edu;;https://www.microsoft.com",
        "aff_unique_abbr": "ZJU;;;Microsoft",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Z\u00fcrich",
        "aff_country_unique_index": "0;1;0;0;2;1",
        "aff_country_unique": "China;United States;Switzerland"
    },
    {
        "id": "9561645",
        "title": "Coding for Distributed Multi-Agent Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper aims to mitigate straggler effects in synchronous distributed learning for multi-agent reinforcement learning (MARL) problems. Stragglers arise frequently in a distributed learning system, due to the existence of various system disturbances such as slow-downs or failures of compute nodes and communication bottlenecks. To resolve this issue, we propose a coded distributed learning framework, which speeds up the training of MARL algorithms in the presence of stragglers, while maintaining the same accuracy as the centralized approach. As an illustration, a coded distributed version of the multi-agent deep deterministic policy gradient (MADDPG) algorithm is developed and evaluated. Different coding schemes, including maximum distance separable (MDS) code, random sparse code, replication-based code, and regular low density parity check (LDPC) code are also investigated. Simulations in several multi-robot problems demonstrate the promising performance of the proposed framework.",
        "primary_area": "",
        "author": "Baoqian Wang;Junfei Xie;Nikolay Atanasov;Baoqian Wang;Junfei Xie;Nikolay Atanasov",
        "authorids": "/37086377335;/37085354420;/37670511000;/37086377335;/37085354420;/37670511000",
        "aff": "San Diego State University, La Jolla, CA; Department of Electrical and Computer Engineering, San Diego State University, San Diego, CA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561645/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16740303634366203257&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "San Diego State University;University of California, San Diego",
        "aff_unique_dep": ";Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.sdsu.edu;https://www.ucsd.edu",
        "aff_unique_abbr": "SDSU;UCSD",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "La Jolla;San Diego",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561323",
        "title": "Collaborative Fall Detection using a Wearable Device and a Companion Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Older adults who age in place face many health problems and need to be taken care of. Fall is a serious problem among elderly people. In this paper, we present the design and implementation of collaborative fall detection using a wearable device and a companion robot. First, we developed a wearable device by integrating a camera, an accelerometer and a microphone. Second, a companion robot communicates with the wearable device to conduct collaborative fall detection. The robot is also able to contact caregivers in case of emergency. The collaborative fall detection method consists of motion data based preliminary detection on the wearable device and video-based final detection on the companion robot. Both convolutional neural network (CNN) and long short-term memory (LSTM) are used for video-based fall detection. The experimental results show that the overall accuracy of video-based algorithm is 84%. We also investigated the relation between the accuracy and the number of image frames. Our method improves the accuracy of fall detection while maximizing the battery life of the wearable device. In addition, our method significantly increases the sensing range of the companion robot.",
        "primary_area": "",
        "author": "Fei Liang;Ricardo Hernandez;Jiaxing Lu;Brandon Ong;Matthew Jackson Moore;Weihua Sheng;Senlin Zhang;Fei Liang;Ricardo Hernandez;Jiaxing Lu;Brandon Ong;Matthew Jackson Moore;Weihua Sheng;Senlin Zhang",
        "authorids": "/37088810517;/37089000487;/37088690371;/37089001840;/37088999791;/37276312200;/37535987900;/37088810517;/37089000487;/37088690371;/37089001840;/37088999791;/37276312200;/37535987900",
        "aff": "School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK, USA; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK, USA; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK, USA; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK, USA; School of Mechanical and Aerospace Engineering, Oklahoma State University, Stillwater, OK, USA; School of Electrical and Computer Engineering, Oklahoma State University, Stillwater, OK, USA; State Key Laboratory of Industrial Control Technology, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561323/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9347488899931600991&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;1",
        "aff_unique_norm": "Oklahoma State University;Zhejiang University",
        "aff_unique_dep": "School of Electrical and Computer Engineering;State Key Laboratory of Industrial Control Technology",
        "aff_unique_url": "https://www.okstate.edu;http://www.zju.edu.cn",
        "aff_unique_abbr": "OSU;ZJU",
        "aff_campus_unique_index": "0;0;0;0;0;0;1",
        "aff_campus_unique": "Stillwater;Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9561681",
        "title": "Collaborative Learning of Multiple-Discontinuous-Image Saliency Prediction for Drone Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "Most of the existing saliency prediction research focuses on either single images or videos (or more precisely multiple images in sequence). However, to apply saliency prediction to drone exploration that has to consider multiple images from different view angles or localizations to determine the direction to explore, saliency prediction over multiple discontinuous images is required. In this paper, we propose a deep relative saliency model (MS-Net) for such an application. MS-Net starts with a single-image saliency feature extraction network for each image separately and then integrate these images by using a GCN-based mechanism called multi-image saliency fusion that learns relative saliency information among all the images. Finally, it predicts the saliency of each image by considering the relative information. Because there are no existing saliency prediction datasets with such multiple discontinuous images, we randomly cropped a large number of sub-images from 360\u00b0 images of the existing 360\u00b0 image saliency datasets to build our own dataset for both training and evaluation. Experimental results showed that the proposed MSNet considerably outperformed both single-image and video saliency prediction methods and could achieve comparative performance to that of 360\u00b0 image saliency prediction even with only limited field-of-views, i.e., five sub-images, considered.",
        "primary_area": "",
        "author": "Ting-Tsan Chu;Po-Heng Chen;Pin-Jie Huang;Kuan-Wen Chen;Ting-Tsan Chu;Po-Heng Chen;Pin-Jie Huang;Kuan-Wen Chen",
        "authorids": "/37088996198;/37088434052;/37088999229;/37557502900;/37088996198;/37088434052;/37088999229;/37557502900",
        "aff": "Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan; Department of Computer Science, National Yang Ming Chiao Tung University, Hsinchu, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561681/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7624540934212640588&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Yang Ming Chiao Tung University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nctu.edu.tw",
        "aff_unique_abbr": "NYCU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561946",
        "title": "Collaborative Visual Inertial SLAM for Multiple Smart Phones",
        "track": "main",
        "status": "Poster",
        "abstract": "The efficiency and accuracy of mapping are crucial in a large scene and long-term AR applications. Multi-agent cooperative SLAM is the precondition of multi-user AR interaction. The cooperation of multiple smart phones has the potential to improve efficiency and robustness of task completion and can complete tasks that a single agent cannot do. However, it depends on robust communication, efficient location detection, robust mapping, and efficient information sharing among agents. We propose a multi-intelligence collaborative monocular visual-inertial SLAM deployed on multiple ios mobile devices with a centralized architecture. Each agent can independently explore the environment, run a visual-inertial odometry module online, and then send all the measurement information to a central server with higher computing resources. The server manages all the information received, detects overlapping areas, merges and optimizes the map, and shares information with the agents when needed. We have verified the performance of the system in public datasets and real environments. The accuracy of mapping and fusion of the proposed system is comparable to VINS-Mono which requires higher computing resources.",
        "primary_area": "",
        "author": "Jialing Liu;Ruyu Liu;Kaiqi Chen;Jianhua Zhang;Dongyan Guo;Jialing Liu;Ruyu Liu;Kaiqi Chen;Jianhua Zhang;Dongyan Guo",
        "authorids": "/37088570563;/37086354166;/37088570441;/37678556700;/37088454745;/37088570563;/37086354166;/37088570441;/37678556700;/37088454745",
        "aff": "College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China; School of Computer Science and Engineering, Tianjin University of Technology, Tianjin, China; College of Computer Science and Technology, Zhejiang University of Technology, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561946/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=900129652528895688&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Zhejiang University of Technology;Tianjin University of Technology",
        "aff_unique_dep": "College of Computer Science and Technology;School of Computer Science and Engineering",
        "aff_unique_url": "https://www.zjut.edu.cn;http://www.tjut.edu.cn",
        "aff_unique_abbr": "ZJUT;TUT",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Hangzhou;Tianjin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561186",
        "title": "Collective Transport of Unconstrained Objects via Implicit Coordination and Adaptive Compliance",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a decentralized control algorithm for robots to aid in carrying an unknown load. Coordination occurs solely through sensing of the forces on or movement of the shared load. Robots prevent undesired motion of the load while permitting movement in the task-relevant subspace, and stabilize against unexpected events by a transient decrease in compliance. The algorithm requires no direct communication between agents, and minimal knowledge of the system or task. We demonstrate the approach in simulation using a commercially available compliant robotic platform.",
        "primary_area": "",
        "author": "Nicole E. Carey;Justin Werfel;Nicole E. Carey;Justin Werfel",
        "authorids": "/37086162723;/37266345300;/37086162723;/37266345300",
        "aff": "Autodesk Robotics Laboratory, San Francisco, CA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561186/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14140958896517933096&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Autodesk;Harvard University",
        "aff_unique_dep": "Robotics Laboratory;John A. Paulson School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.autodesk.com;https://www.harvard.edu",
        "aff_unique_abbr": "Autodesk;Harvard",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "San Francisco;Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561417",
        "title": "Collision Avoidance in Tightly-Constrained Environments without Coordination: a Hierarchical Control Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a hierarchical control approach for maneuvering an autonomous vehicle (AV) in tightly-constrained environments where other moving AVs and/or human driven vehicles are present. A two-level hierarchy is proposed: a high-level data-driven strategy predictor and a lower-level model-based feedback controller. The strategy predictor maps an encoding of a dynamic environment to a set of high-level strategies via a neural network. Depending on the selected strategy, a set of time-varying hyperplanes in the AV\u2019s position space is generated online and the corresponding halfspace constraints are included in a lower-level model-based receding horizon controller. These strategy-dependent constraints drive the vehicle towards areas where it is likely to remain feasible. Moreover, the predicted strategy also informs switching between a discrete set of policies, which allows for more conservative behavior when prediction confidence is low. We demonstrate the effectiveness of the proposed data-driven hierarchical control framework in a two-car collision avoidance scenario through simulations and experiments on a 1/10 scale autonomous car platform where the strategy-guided approach outperforms a model predictive control baseline in both cases.",
        "primary_area": "",
        "author": "Xu Shen;Edward L. Zhu;Yvonne R. St\u00fcrz;Francesco Borrelli;Xu Shen;Edward L. Zhu;Yvonne R. St\u00fcrz;Francesco Borrelli",
        "authorids": "/37088488320;/37088645903;/37085870626;/37299856800;/37088488320;/37088645903;/37085870626;/37299856800",
        "aff": "Department of Mechanical Engineering, University of California at Berkeley, Berkeley, CA, USA; Department of Mechanical Engineering, University of California at Berkeley, Berkeley, CA, USA; Department of Mechanical Engineering, University of California at Berkeley, Berkeley, CA, USA; Department of Mechanical Engineering, University of California at Berkeley, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561417/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=853725731094803631&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561677",
        "title": "Collision Detection, Identification, and Localization on the DLR SARA Robot with Sensing Redundancy",
        "track": "main",
        "status": "Poster",
        "abstract": "Physical human-robot interaction is known to be a crucial aspect in modern lightweight robotics. Herein, the estimation of external interactions is essential for the effective and safe collaboration. In this work, an extended momentum-based disturbance observer is presented which includes the sensing redundancy related to additional force-torque measurements. The observer eliminates the need for acceleration measurements/estimates and it is able to accurately reconstruct multiple simultaneous contact locations. Moreover, it provides uncoupled, configuration-independent, and singularity-free estimates of the external forces. The performance of the approach is experimentally validated on the SARA robot, the new generation of DLR lightweight robots, involving high resolution force-torque sensors in a redundant arrangement.",
        "primary_area": "",
        "author": "Maged Iskandar;Oliver Eiberger;Alin Albu-Sch\u00e4ffer;Alessandro De Luca;Alexander Dietrich;Maged Iskandar;Oliver Eiberger;Alin Albu-Sch\u00e4ffer;Alessandro De Luca;Alexander Dietrich",
        "authorids": "/37086454969;/37295473300;/38270361100;/37269180600;/37970388100;/37086454969;/37295473300;/38270361100;/37269180600;/37970388100",
        "aff": "German Aerospace Center (DLR); German Aerospace Center (DLR); German Aerospace Center (DLR); Sapienza Universita di Roma, Italy; German Aerospace Center (DLR)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561677/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14401547050008813828&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "German Aerospace Center;Sapienza University of Rome",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.dlr.de;https://www.uniroma1.it",
        "aff_unique_abbr": "DLR;Sapienza",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Germany;Italy"
    },
    {
        "id": "9560859",
        "title": "Collision Risk Assessment and Obstacle Avoidance Control for Autonomous Sailing Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Obstacle avoidance is crucial for autonomous surface vehicles (ASVs) in the sea because rescue is extremely difficult there. OceanVoy, a sailboat toward long range energy-saving voyage, has to overcome the dual challenges, i.e. from the environmental interference and its low mobility preventing from precise obstacle avoidance. We propose a control scheme based on real-time collision risk assessment and a hybrid propulsion system to enhance safety of OceanVoy. A novel sailboat safety zone (SSZ) has been designed to warn the potential collision during its sailing. Both intrinsic characteristics of OceanVoy and environmental factors have been considered in SSZ. We use lateral and axial thrusters to provide emergency propulsion. A collision avoidance algorithm is executed to coordinate motors in rudder, sail and thrusters based on SSZ. Both simulation and experiments have been conducted and the results have validated our system and collision avoidance scheme.",
        "primary_area": "",
        "author": "Weimin Qi;Qinbo Sun;Chongfeng Liu;Xiaoqiang Ji;Zhongzhong Cao;Yiwen Liang;Huihuan Qian;Weimin Qi;Qinbo Sun;Chongfeng Liu;Xiaoqiang Ji;Zhongzhong Cao;Yiwen Liang;Huihuan Qian",
        "authorids": "/37087243921;/37086608896;/37087049736;/37088954362;/37088997687;/37088996115;/37549401900;/37087243921;/37086608896;/37087049736;/37088954362;/37088997687;/37088996115;/37549401900",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong, Shenzhen, China; Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), The Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560859/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8747526407447978302&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS)",
        "aff_unique_url": "https://www.cuhk.edu.cn",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561473",
        "title": "Collision-Aware Target-Driven Object Grasping in Constrained Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping a novel target object in constrained environments (e.g., walls, bins, and shelves) requires intensive reasoning about grasp pose reachability to avoid collisions with the surrounding structures. Typical 6-DoF robotic grasping systems rely on the prior knowledge about the environment and intensive planning computation, which is ungeneralizable and inefficient. In contrast, we propose a novel Collision-Aware Reachability Predictor (CARP) for 6-DoF grasping systems. The CARP learns to estimate the collision-free probabilities for grasp poses and significantly improves grasping in challenging environments. The deep neural networks in our approach are trained fully by self-supervision in simulation. The experiments in both simulation and the real world show that our approach achieves more than 75% grasping rate on novel objects in various surrounding structures. The ablation study demonstrates the effectiveness of the CARP, which improves the 6-DoF grasping rate by 95.7%.",
        "primary_area": "",
        "author": "Xibai Lou;Yang Yang;Changhyun Choi;Xibai Lou;Yang Yang;Changhyun Choi",
        "authorids": "/37088504165;/37088070512;/37085811337;/37088504165;/37088070512;/37085811337",
        "aff": "Department of Electrical and Computer Engineering, Univ. of Minnesota, Minneapolis, USA; Department of Computer Science and Engineering, Univ. of Minnesota, Minneapolis, USA; Department of Electrical and Computer Engineering, Univ. of Minnesota, Minneapolis, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561473/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=404026155629503726&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561326",
        "title": "Collision-Free MPC for Legged Robots in Static and Dynamic Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a model predictive controller (MPC) that automatically discovers collision-free locomotion while simultaneously taking into account the system dynamics, friction constraints, and kinematic limitations. A relaxed barrier function is added to the optimization\u2019s cost function, leading to collision avoidance behavior without increasing the problem\u2019s computational complexity. Our holistic approach does not require any heuristics and enables legged robots to find whole-body motions in the presence of static and dynamic obstacles. We use a dynamically generated euclidean signed distance field for static collision checking. Collision checking for dynamic obstacles is modeled with moving cylinders, increasing the responsiveness to fast-moving agents. Furthermore, we include a Kalman filter motion prediction for moving obstacles into our receding horizon planning, enabling the robot to anticipate possible future collisions. Our experiments1 demonstrate collision-free motions on a quadrupedal robot in challenging indoor environments. The robot handles complex scenes like overhanging obstacles and dynamic agents by exploring motions at the robot\u2019s dynamic and kinematic limits.",
        "primary_area": "",
        "author": "Magnus Gaertner;Marko Bjelonic;Farbod Farshidian;Marco Hutter;Magnus Gaertner;Marko Bjelonic;Farbod Farshidian;Marco Hutter",
        "authorids": "/37089000713;/37085993346;/37085428006;/37545251000;/37089000713;/37085993346;/37085428006;/37545251000",
        "aff": "Robotic Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561326/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13791332651225898883&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9560850",
        "title": "Collision-free vector field guidance and MPC for a fixed-wing UAV",
        "track": "main",
        "status": "Poster",
        "abstract": "The present work focuses on the development of an efficient path controller to guide a fixed-wing UAV (Unmanned Aerial Vehicle) to follow a closed curve and avoid unknown dynamic obstacles. Our strategy is composed of two layers: a top level layer responsible for guidance and a lower level layer responsible for tracking the references given by the top level. To solve the guidance problem, we propose a vector field strategy that switches between two forms: a vector field to converge and circulate the target curve and a vector field to avoid obstacles by circulating the closest one. To make the fixed-wing UAV follow the velocity provided by the guidance vector field we consider a Model Predictive Control scheme. The feedback linearization allows efficient computation of control commands as a linear MPC controller can be employed. Our results are validated in simulations that take into account the 6DOF (Degrees of Freedom) model with constraints of the aircraft, wind disturbance and uncertainties on the measurements.",
        "primary_area": "",
        "author": "Leonardo A. A. Pereira;Arthur H. D. Nunes;Adriano M. C. Rezende;Vinicius M. Gon\u00e7alves;Guilherme V. Raffo;Luciano C. A. Pimenta;Leonardo A. A. Pereira;Arthur H. D. Nunes;Adriano M. C. Rezende;Vinicius M. Gon\u00e7alves;Guilherme V. Raffo;Luciano C. A. Pimenta",
        "authorids": "/37086520128;/37088504019;/37086580165;/37533873500;/37590643600;/37297110600;/37086520128;/37088504019;/37086580165;/37533873500;/37590643600;/37297110600",
        "aff": "Graduate Program in Electrical Engineering, Universidade Federal de Minas Gerais, Belo Horizonte, MG, Brazil; Graduate Program in Electrical Engineering, Universidade Federal de Minas Gerais, Belo Horizonte, MG, Brazil; Graduate Program in Electrical Engineering, Universidade Federal de Minas Gerais, Belo Horizonte, MG, Brazil; Graduate Program in Electrical Engineering, Universidade Federal de Minas Gerais, Belo Horizonte, MG, Brazil; Graduate Program in Electrical Engineering, Universidade Federal de Minas Gerais, Belo Horizonte, MG, Brazil; Graduate Program in Electrical Engineering, Universidade Federal de Minas Gerais, Belo Horizonte, MG, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560850/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2360578481334424937&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Universidade Federal de Minas Gerais",
        "aff_unique_dep": "Graduate Program in Electrical Engineering",
        "aff_unique_url": "https://www.ufmg.br",
        "aff_unique_abbr": "UFMG",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Belo Horizonte",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Brazil"
    },
    {
        "id": "9561505",
        "title": "CollisionIK: A Per-Instant Pose Optimization Method for Generating Robot Motions with Environment Collision Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a per-instant pose optimization method that can generate configurations that achieve specified pose or motion objectives as best as possible over a sequence of solutions, while also simultaneously avoiding collisions with static or dynamic obstacles in the environment. We cast our method as a weighted sum non-linear constrained optimization-based IK problem where each term in the objective function encodes a particular pose objective. We demonstrate how to effectively incorporate environment collision avoidance as a single term in this multi-objective, optimization-based IK structure, and provide solutions for how to spatially represent and organize external environments such that data can be efficiently passed to a real-time, performance-critical optimization loop. We demonstrate the effectiveness of our method by comparing it to various state-of-the-art methods in a testbed of simulation experiments and discuss the implications of our work based on our results.",
        "primary_area": "",
        "author": "Daniel Rakita;Haochen Shi;Bilge Mutlu;Michael Gleicher;Daniel Rakita;Haochen Shi;Bilge Mutlu;Michael Gleicher",
        "authorids": "/37085893032;/37088999457;/38569363200;/37282585700;/37085893032;/37088999457;/38569363200;/37282585700",
        "aff": "Department of Computer Sciences, University of Wisconsin\u2013Madison, Madison, USA; Department of Computer Sciences, University of Wisconsin\u2013Madison, Madison, USA; Department of Computer Sciences, University of Wisconsin\u2013Madison, Madison, USA; Department of Computer Sciences, University of Wisconsin\u2013Madison, Madison, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561505/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17381694186504302669&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Wisconsin\u2013Madison",
        "aff_unique_dep": "Department of Computer Sciences",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW\u2013Madison",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560731",
        "title": "Combined Sampling and Optimization Based Planning for Legged-Wheeled Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning for legged-wheeled machines is typically done using trajectory optimization because of many degrees of freedom, thus rendering legged-wheeled planners prone to falling prey to bad local minima. We present a combined sampling and optimization-based planning approach that can cope with challenging terrain. The sampling-based stage computes whole-body configurations and contact schedule, which speeds up the optimization convergence. The optimization-based stage ensures that all the system constraints, such as non-holonomic rolling constraints, are satisfied. The evaluations show the importance of good initial guesses for optimization. Furthermore, they suggest that terrain/collision (avoidance) constraints are more challenging than the robot model\u2019s constraints. Lastly, we extend the optimization to handle general terrain representations in the form of elevation maps.",
        "primary_area": "",
        "author": "Edo Jelavic;Farbod Farshidian;Marco Hutter;Edo Jelavic;Farbod Farshidian;Marco Hutter",
        "authorids": "/37086273999;/37085428006;/37545251000;/37086273999;/37085428006;/37545251000",
        "aff": "Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560731/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6134567823403220594&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561850",
        "title": "Combined System Identification and State Estimation for a Quadrotor UAV",
        "track": "main",
        "status": "Poster",
        "abstract": "Precise system identification is an important aspect of adequate control design and parameter definition to allow for accurate and reliable navigation. While this is well known in robotics, the community working with small rotorcraft Unmanned Aerial Vehicles (UAVs) has yet to discover the benefits. In contrast to existing work, which often performs offline or deterministic (i.e. closed-form) system identification, we present a probabilistic approach to the online estimation of system identification parameters and self-calibration states. Instead of decoupling system identification and state estimation for vehicle control, we merge the entire process into a holistic probabilistic framework to allow self-awareness and self-healing. Our observability analysis shows that most of the system identification parameters are observable and converge quickly to the optimal value using a combination of inertial cues, dynamic modeling, and an additional exteroceptive sensor. We support our theoretical findings with extensive tests simulating realistic data in Gazebo.",
        "primary_area": "",
        "author": "Christoph B\u00f6hm;Christian Brommer;Alexander Hardt-Stremayr;Stephan Weiss;Christoph B\u00f6hm;Christian Brommer;Alexander Hardt-Stremayr;Stephan Weiss",
        "authorids": "/37088521138;/37086574162;/37086579419;/37535323400;/37088521138;/37086574162;/37086579419;/37535323400",
        "aff": "Control of Networked Systems Group, University of Klagenfurt, Austria; Control of Networked Systems Group, University of Klagenfurt, Austria; Control of Networked Systems Group, University of Klagenfurt, Austria; Control of Networked Systems Group, University of Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561850/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9790026376696739659&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Klagenfurt",
        "aff_unique_dep": "Control of Networked Systems Group",
        "aff_unique_url": "https://www.uni-klagenfurt.at",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9560861",
        "title": "Combining Multi-Robot Motion Planning and Goal Allocation using Roadmaps",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of automating fleets of robots with non-holonomic dynamics. Previously studied methods either specialize in facets of this problem, that is, one or a combination of multi-robot goal allocation, motion planning, and coordination, and typically acrifice optimality and completeness for scalability. We propose an approach that constructs an abstract multi-robot roadmap in a reduced configuration space, where we account for environment connectivity and interference cost between robots occupying the same polygons. Querying the road-map results in a robot-goal assignment and abstract multi-robot trajectory. This is then exploited to de-compose the original problem into smaller problems, each of which is solved with a multi-robot motion planner that accounts for kinodynamic constraints. We validate the approach experimentally to demonstrate the advantage of considering task assignment and motion planning holistically, and explore some methods for balancing solution quality and computational efficiency.",
        "primary_area": "",
        "author": "Jo\u00e3o Salvado;Masoumeh Mansouri;Federico Pecora;Jo\u00e3o Salvado;Masoumeh Mansouri;Federico Pecora",
        "authorids": "/37086201112;/37085453076;/37564376200;/37086201112;/37085453076;/37564376200",
        "aff": "AASS Research Centre, \u00d6rebro University; School of Computer Science, University of Birmingham; AASS Research Centre, \u00d6rebro University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560861/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17925393937900010095&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "\u00d6rebro University;University of Birmingham",
        "aff_unique_dep": "AASS Research Centre;School of Computer Science",
        "aff_unique_url": "https://www.oru.se;https://www.birmingham.ac.uk",
        "aff_unique_abbr": ";UoB",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Birmingham",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Sweden;United Kingdom"
    },
    {
        "id": "9561648",
        "title": "Comfortable and Safe Decelerations for a Self-Driving Transit Bus",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a combination of Model Predictive Control and Lexicographic Programming to address complex scenarios with conflicting goals related to various aspects of comfort and safety of passengers in a transit bus, generating different deceleration profiles depending on the speed of the bus and distance to obstacles, validated in experiments with a standard transit bus equipped with self-driving capabilities.",
        "primary_area": "",
        "author": "Alexis Mifsud;Matteo Ciocca;Pierre-Brice Wieber;Alexis Mifsud;Matteo Ciocca;Pierre-Brice Wieber",
        "authorids": "/37085375719;/37086171985;/37295495700;/37085375719;/37086171985;/37295495700",
        "aff": "Univ. Grenoble Alpes, Inria, Grenoble, France; Univ. Grenoble Alpes, Inria, Grenoble, France; Univ. Grenoble Alpes, Inria, Grenoble, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561648/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7237714268205383063&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universite Grenoble Alpes",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.univ-grenoble-alpes.fr",
        "aff_unique_abbr": "UGA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Grenoble",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561879",
        "title": "Command Filtered Tracking Control for High-order Systems with Limited Transmission Bandwidth",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates the tracking control problem of a class of high-order distributed systems subjected to limited communication bandwidth. An event-triggered control method is proposed, where the controller is triggered only when specific events happen. Moreover, the computational complexity is reduced by introducing command filters for virtual control signals. Specifically, the backstepping scheme is adopted as the main design framework, by which the n-th order nonlinear system is divided into n command-cascaded first order subsystems. And virtual control commands are sent through a second-order low-pass filter, by which the time derivatives of the virtual commands can be obtained directly. The theoretical analysis shows the stability of the proposed method. The tracking performance is illustrated by a simulation example.",
        "primary_area": "",
        "author": "Jialei Bao;Peter Xiaoping Liu;Huanqing Wang;Minhua Zheng;Ying Zhao;Jialei Bao;Peter Xiaoping Liu;Huanqing Wang;Minhua Zheng;Ying Zhao",
        "authorids": "/37088224060;/37276301100;/38466729800;/37086229425;/37088996421;/37088224060;/37276301100;/38466729800;/37086229425;/37088996421",
        "aff": "School of Mechanical, Electronic and Control Engineering, Beijing Jiaotong University, Beijing, China; Department of Systems and Computer Engineering, Carleton University, Ottawa, ON, Canada; School of Mathematics, Bohai University, Jinzhou, China; School of Mechanical, Electronic and Control Engineering, Beijing Jiaotong University, Beijing, China; School of Mechanical, Electronic and Control Engineering, Beijing Jiaotong University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561879/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8390131239722504859&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;0",
        "aff_unique_norm": "Beijing Jiao Tong University;Carleton University;Bohai University",
        "aff_unique_dep": "School of Mechanical, Electronic and Control Engineering;Department of Systems and Computer Engineering;School of Mathematics",
        "aff_unique_url": "http://www.bjtu.edu.cn;https://carleton.ca;http://www.bhu.edu.cn",
        "aff_unique_abbr": "BJTU;Carleton;",
        "aff_campus_unique_index": "0;1;2;0;0",
        "aff_campus_unique": "Beijing;Ottawa;Jinzhou",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "9561880",
        "title": "Communication Strategy for Efficient Guidance Providing : Domain-structure Awareness, Performance Trade-offs, and Value of Future Observations",
        "track": "main",
        "status": "Poster",
        "abstract": "Service robots are gaining capabilities to be deployed in public environments for human assistance. While robot actively providing guidance has shown great success in field study, the communication strategy (the strategy to decide whom to initiate the service for and when), and hence the performance evaluation, has been based on behavioral-based qualitative analysis. We attribute this to the challenge of accessing large-scale field data with condition control, and approach the problem with simulation from the agent-based modeling literature, to simulate pedestrian behavior in unfamiliar environments and estimate travel cost. We contribute a planning approach that uses the pedestrian behavior prediction from the model, to decide whom to initiate guidance and when for performance maximization. The results suggest that our approach is more efficient based on the measure of saved pedestrian travel time, compared to the behavioral-based strategy and a baseline that maximizes service counts.",
        "primary_area": "",
        "author": "Shih-Yun Lo;Andrea L. Thomaz;Shih-Yun Lo;Andrea L. Thomaz",
        "authorids": "/37087323268;/37296354000;/37087323268;/37296354000",
        "aff": "The University of Texas at Austin; The University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561880/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:TFWoZXgK4aAJ:scholar.google.com/&scioq=Communication+Strategy+for+Efficient+Guidance+Providing+:+Domain-structure+Awareness,+Performance+Trade-offs,+and+Value+of+Future+Observations&hl=en&as_sdt=0,5",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561041",
        "title": "Communication-Aware Multi-robot Coordination with Submodular Maximization",
        "track": "main",
        "status": "Poster",
        "abstract": "Submodular maximization has been widely used in many multi-robot task planning problems including information gathering, exploration, and target tracking. However, the interplay between submodular maximization and communication is rarely explored in the multi-robot setting. In many cases, maximizing the submodular objective may drive the robots in a way so as to disconnect the communication network. Driven by such observations, in this paper, we consider the problem of maximizing submodular function with connectivity constraints. Specifically, we propose a problem called Communication-aware Submodular Maximization (CSM), in which communication maintenance and submodular maximization are jointly considered in the decision-making process. One heuristic algorithm that consists of two stages, i.e. topology generation and deviation minimization is proposed. We validate the formulation and algorithm through numerical simulation. We find that our algorithm on average suffers only slightly performance decrease compared to the pure greedy strategy.",
        "primary_area": "",
        "author": "Guangyao Shi;Ishat E Rabban;Lifeng Zhou;Pratap Tokekar;Guangyao Shi;Ishat E Rabban;Lifeng Zhou;Pratap Tokekar",
        "authorids": "/37089000733;/37085352321;/37086092920;/37546532700;/37089000733;/37085352321;/37086092920;/37546532700",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561041/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=567551448371312175&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9560976",
        "title": "Comparison of predictive controllers for locomotion and balance recovery of quadruped robots",
        "track": "main",
        "status": "Poster",
        "abstract": "As locomotion decisions must be taken by considering the future, most existing quadruped controllers are based on a model predictive controller (MPC) with a reduced model of the dynamics to generate the motion and a whole- body controller to execute it. Yet the simplifying assumptions of the MPC are often chosen ad-hoc or by intuition. In this article, we focus on a set of MPCs and analyze the effect of chosen model reductions on the behavior of the robot. Based on existing formulations, we present additional controllers to better understand the influence of model reductions on the controller capabilities. Finally, we propose a robust predictive controller capable of optimizing the foot placements, gait period, center- of-mass trajectory and ground reaction forces. The behavior of these controllers is statistically evaluated in simulation. This empirical study aims to assess the relative importance of the components of the optimal control problem (variables, costs, dynamics) to be able to take reasoned decisions instead of arbitrarily emphasizing or neglecting some of them. We also provide a qualitative study in simulation and on the real robot Solo-12.",
        "primary_area": "",
        "author": "Thomas Corb\u00e8res;Thomas Flayols;Pierre-Alexandre L\u00e9ziart;Rohan Budhiraja;Philippe Sou\u00e8res;Guilhem Saurel;Nicolas Mansard;Thomas Corb\u00e8res;Thomas Flayols;Pierre-Alexandre L\u00e9ziart;Rohan Budhiraja;Philippe Sou\u00e8res;Guilhem Saurel;Nicolas Mansard",
        "authorids": "/37088997400;/37086293347;/37087901433;/37086291965;/37377500300;/37085810875;/37542913400;/37088997400;/37086293347;/37087901433;/37086291965;/37377500300;/37085810875;/37542913400",
        "aff": "LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; Artificial and Natural Intelligence Toulouse Institute, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; Artificial and Natural Intelligence Toulouse Institute, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560976/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10120921649958815619&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;0;1",
        "aff_unique_norm": "LAAS-CNRS;Artificial and Natural Intelligence Toulouse Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.laas.fr/;",
        "aff_unique_abbr": "LAAS-CNRS;ANITI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Toulouse;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9562080",
        "title": "Compartmentalized Covariance Intersection: A Novel Filter Architecture for Distributed Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces the Compartmentalized Covariance Intersection (CCI) algorithm, a consistent technique to fuse measurements in cooperative navigation networks. The algorithm reduces the excess conservatism of standard Covariance Intersection (CI) by assuming that correlation is only present within each measurement stream and not across the different sources. This assumption allows the sources to be compartmentalized and fused with the Kalman equations rather than the CI method, resulting in tighter convergence. The CCI algorithm is applied to a cooperative localization application and is demonstrated to substantially outperform CI, with a covariance that approaches the performance of an ideal centralized estimator in simulations of linear, Gaussian systems. This approach is also demonstrated to be consistent using Monte Carlo simulations. Finally, CCI was used in a laboratory demonstration to perform distributed localization with real-world range measurements between a team of six agents.",
        "primary_area": "",
        "author": "Adam Wiktor;Stephen Rock;Adam Wiktor;Stephen Rock",
        "authorids": "/37085578962;/37267840600;/37085578962;/37267840600",
        "aff": "Department of Aeronautics & Astronautics, Stanford University, Stanford, CA; Department of Aeronautics & Astronautics, Stanford University, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562080/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2763160375922097307&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Aeronautics & Astronautics",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562104",
        "title": "Compensating for Unmodeled Forces using Neural Networks in Soft Manipulator Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft manipulators made of deformable materials have great promise in applications that require additional flexibility and compliance; however, these characteristics also make them difficult to simulate accurately and quickly. The lack of a fast and accurate simulator prevents motion planners from generating feasible plans, which would enable soft robots to achieve more complex tasks, such as manipulation. In this work, we propose combining a simplified quasistatic model with a neural network that learns to compensate for unmodeled forces, such as friction and loads, in order to create a fast forward model for soft manipulators with multiple segments. We show that the resulting neural network model reduces average end effector position error by 62% compared to the quasistatic model, while still being fast enough for motion planning. We also incorporate this model into an RRT*-based planner and demonstrate that the plans generated using our model are more likely to be feasible when executed on hardware than plans generated with a simulator using the quasistatic model.",
        "primary_area": "",
        "author": "Scott Chow;Gina Olson;Geoffrey A. Hollinger;Scott Chow;Gina Olson;Geoffrey A. Hollinger",
        "authorids": "/37088999309;/37085437507;/37543482700;/37088999309;/37085437507;/37543482700",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562104/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13214518436590488170&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Oregon State University;Carnegie Mellon University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute;Department of Mechanical Engineering",
        "aff_unique_url": "https://oregonstate.edu;https://www.cmu.edu",
        "aff_unique_abbr": "OSU;CMU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Corvallis;Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561784",
        "title": "Complete Path Planning That Simultaneously Optimizes Length and Clearance",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers a fundamental, optimal path planning problem that requires simultaneously minimizing path length and maximizing obstacle clearance. We show that in even simple planar settings with point and disc obstacles, the set of alternative solutions such that no one is clearly better than another (the set of Pareto-optimal solutions) is uncountably infinite. In spite of this difficulty, we introduce a complete, efficient algorithm that computes the Pareto front and a data structure that finitely represents the complete set of all Pareto- optimal paths. Particular optimal paths can then be selected from the computed data structure during execution, based on any additional conditions or considerations.",
        "primary_area": "",
        "author": "Basak Sakcak;Steven M. LaValle;Basak Sakcak;Steven M. LaValle",
        "authorids": "/37086497815;/37280522300;/37086497815;/37280522300",
        "aff": "Faculty of Information Technology and Electrical Engineering, Center of Ubiquitous Computing, University of Oulu, Finland; Faculty of Information Technology and Electrical Engineering, Center of Ubiquitous Computing, University of Oulu, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561784/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10486213591438873584&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Oulu",
        "aff_unique_dep": "Faculty of Information Technology and Electrical Engineering",
        "aff_unique_url": "https://www.oulu.fi",
        "aff_unique_abbr": "UOulu",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "9561320",
        "title": "Composable Geometric Motion Policies using Multi-Task Pullback Bundle Dynamical Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite decades of work in fast reactive planning and control, challenges remain in developing reactive motion policies on non-Euclidean manifolds and enforcing constraints while avoiding undesirable potential function local minima. This work presents a principled method for designing and fusing desired robot task behaviors into a stable robot motion policy, leveraging the geometric structure of non-Euclidean manifolds, which are prevalent in robot configuration and task spaces. Our Pullback Bundle Dynamical Systems (PBDS) framework drives desired task behaviors and prioritizes tasks using separate position-dependent and position/velocity-dependent Riemannian metrics, respectively, thus simplifying individual task design and modular composition of tasks. For enforcing constraints, we provide a class of metric-based tasks, eliminating local minima by imposing non-conflicting potential functions only for goal region attraction. We also provide a geometric optimization problem for combining tasks inspired by Riemannian Motion Policies (RMPs) that reduces to a simple least-squares problem, and we show that our approach is geometrically well-defined. We demonstrate the PBDS framework on the sphere S2 and at 300-500 Hz on a manipulator arm, and we provide task design guidance and an open-source Julia library implementation. Overall, this work presents a fast, easy-to-use framework for generating motion policies without unwanted potential function local minima on general manifolds.",
        "primary_area": "",
        "author": "Andrew Bylard;Riccardo Bonalli;Marco Pavone;Andrew Bylard;Riccardo Bonalli;Marco Pavone",
        "authorids": "/37085786338;/37086102018;/37307912900;/37085786338;/37086102018;/37307912900",
        "aff": "Department of Aeronautics and Astronautics, Stanford University, Stanford, CA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561320/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5916963051408202657&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560992",
        "title": "Composing HARMONI: An Open-source Tool for Human and Robot Modular OpeN Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "The research and development of socially interactive robots is a complex challenge because of the wide variety of capabilities needed for effective social human-robot interactions (HRI). Many of these capabilities, including perception, dialog, and control, have state of the art methods and solutions, but combining those into a comprehensive and seamless interaction is still an open challenge. We describe HARMONI, a multi-modal, open-source tool for rapid social HRI development and deployment. HARMONI is centered around a ROS package for interaction development, including decision management and node orchestration. HARMONI systematically integrates with disparate functionalities needed to conduct a meaningful social human-robot interaction such as external cloud services, AI models, and modules for sensing, planning, and acting on a variety of platforms. HARMONI was applied to the QT robot platform and usability tests were conducted to evaluate the ease and speed of development and deployment. This paper describes the architecture and design of HARMONI and reports the results of a pilot study with novice users.",
        "primary_area": "",
        "author": "Micol Spitale;Chris Birmingham;R. Michael Swan;Maja J Matari\u0107;Micol Spitale;Chris Birmingham;R. Michael Swan;Maja J Matari\u0107",
        "authorids": "/37087228730;/37088505872;/37088997333;/38300930600;/37087228730;/37088505872;/37088997333;/38300930600",
        "aff": "CS Department, Interaction Lab, University of Southern California, Los Angeles, CA, The United States; CS Department, Interaction Lab, University of Southern California, Los Angeles, CA, The United States; CS Department, Interaction Lab, University of Southern California, Los Angeles, CA, The United States; Interaction Lab, University of Southern California",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560992/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9398005603077065073&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "CS Department, Interaction Lab",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561697",
        "title": "Compositional and Scalable Object SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a fast, scalable, and accurate Simultaneous Localization and Mapping (SLAM) system that represents indoor scenes as a graph of objects. Leveraging the observation that artificial environments are structured and occupied by recognizable objects, we show that a compositional and scalable object mapping formulation is amenable to a robust SLAM solution for drift-free large-scale indoor reconstruction. To achieve this, we propose a novel semantically assisted data association strategy that results in unambiguous persistent object landmarks and a 2.5D compositional rendering method that enables reliable frame-to-model RGB-D tracking. Consequently, we deliver an optimized online implementation that can run at near frame rate with a single graphics card, and provide a comprehensive evaluation against state-of-the-art baselines. An open-source implementation will be provided at https://github.com/rpl-cmu/object-slam.",
        "primary_area": "",
        "author": "Akash Sharma;Wei Dong;Michael Kaess;Akash Sharma;Wei Dong;Michael Kaess",
        "authorids": "/37088997026;/37086933483;/37324200400;/37088997026;/37086933483;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561697/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16612322163605048604&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562020",
        "title": "Computational Design and Fabrication of Corrugated Mechanisms from Behavioral Specifications",
        "track": "main",
        "status": "Poster",
        "abstract": "Orthogonally assembled double-layered corrugated (OADLC) mechanisms are a class of foldable structures that harness origami-inspired methods to enhance the structural stiffness of resulting devices; these mechanisms have extensive applications due to their lightweight, compact nature as well as their high strength-to-weight ratio. However, the design of these mechanisms remains challenging. Here, we propose an efficient method to rapidly design OADLC mechanisms from desired behavioral specifications, i.e. in-plane stiffness and out-of-plane stiffness. Based on an equivalent plate model, we develop and validate analytical formulas for the behavioral specifications of OADLC mechanisms; the analytical formulas can be described as expressions of design parameters. On the basis of the analytical expressions, we formulate the design of OADLC mechanisms from behavioral specifications into an optimization problem that minimizes the weight with given design constraints. The 2D folding patterns of the optimized OADLC mechanisms can be generated automatically and directly delivered for fabrication. Our rapid design method is demonstrated by developing stiffness-enhanced mechanisms with a desired out-of-plane stiffness for a foldable gripper that enables a blimp to perch steadily under air disturbance and weight limit.",
        "primary_area": "",
        "author": "Chang Liu;Wenzhong Yan;Ankur Mehta;Chang Liu;Wenzhong Yan;Ankur Mehta",
        "authorids": "/37086303084;/37087323423;/37086302574;/37086303084;/37087323423;/37086302574",
        "aff": "Samueli School of Engineering, Electrical and Computer Engineering, University of California, Los Angeles, CA, USA; Samueli School of Engineering, Mechanical and Aerospace Engineering, University of California, Los Angeles, USA; Samueli School of Engineering, Electrical and Computer Engineering, University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562020/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9771011508676403216&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560988",
        "title": "Computational design of energy-efficient legged robots: Optimizing for size and actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a computational framework for the design of high-performance legged robotic systems. The framework relies on the concurrent optimization of hardware parameters and control trajectories to find the best robot design for a given task. In particular, we focus on energy efficiency, presenting novel electro-mechanical models to account for the losses of the actuators due to friction and Joule effects. Thanks to a bi-level optimization scheme, featuring a genetic algorithm in the outer loop, our framework can also optimize for the duration of the motion, the actuators, and the size of the robot. We present a novel approach to scale both the actuators and the robot structure in a way that ensures structural integrity by maintaining constant the normalized deflection of the links. We validated our approach by designing a two-joint monoped robot to execute a jumping task. Our simulation results show that our framework can lead to remarkable energy savings (up to 60%) thanks to the concurrent optimization of robot size, motion duration, and actuators.",
        "primary_area": "",
        "author": "G. Fadini;T. Flayols;A. Del Prete;N. Mansard;P. Sou\u00e8res;G. Fadini;T. Flayols;A. Del Prete;N. Mansard;P. Sou\u00e8res",
        "authorids": "/37089509475;/37086293347;/37085422921;/37542913400;/37377500300;/37089509475;/37086293347;/37085422921;/37542913400;/37377500300",
        "aff": "LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; Industrial Engineering Department, University of Trento; Artifical and Natural Intelligence Toulouse Insitute (ANITI); LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560988/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12336361888483523085&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "LAAS-CNRS;University of Trento;Artificial and Natural Intelligence Toulouse Institute",
        "aff_unique_dep": ";Industrial Engineering Department;",
        "aff_unique_url": "https://www.laas.fr/;https://www.unitn.it;https://www.aniti.fr",
        "aff_unique_abbr": "LAAS-CNRS;;ANITI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toulouse;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "France;Italy"
    },
    {
        "id": "9561653",
        "title": "Computationally-Efficient Roadmap-based Inspection Planning via Incremental Lazy Search",
        "track": "main",
        "status": "Poster",
        "abstract": "The inspection-planning problem calls for computing motions for a robot that allow it to inspect a set of points of interest (POIs) while considering plan quality (e.g., plan length). This problem has applications across many domains where robots can help with inspection, including infrastructure maintenance, construction, and surgery. Incremental Random Inspection-roadmap Search (IRIS) is an asymptotically-optimal inspection planner that was shown to compute higher-quality inspection plans orders of magnitudes faster than the prior state-of-the-art method. In this paper, we significantly accelerate the performance of IRIS to broaden its applicability to more challenging real-world applications. A key computational challenge that IRIS faces is effectively searching roadmaps for inspection plans\u2014a procedure that dominates its running time. In this work, we show how to incorporate lazy edge-evaluation techniques into IRIS\u2019s search algorithm and how to reuse search efforts when a roadmap undergoes local changes. These enhancements, which do not compromise IRIS\u2019s asymptotic optimality, enable us to compute inspection plans much faster than the original IRIS. We apply IRIS with the enhancements to simulated bridge inspection and surgical inspection tasks and show that our new algorithm for some scenarios can compute similar-quality inspection plans 570\u00d7 faster than prior work.",
        "primary_area": "",
        "author": "Mengyu Fu;Oren Salzman;Ron Alterovitz;Mengyu Fu;Oren Salzman;Ron Alterovitz",
        "authorids": "/37086578786;/37077497700;/37320259800;/37086578786;/37077497700;/37320259800",
        "aff": "Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Computer Science Department, Technion - Israel Institute of Technology, Israel; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561653/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13252343731327533772&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of North Carolina at Chapel Hill;Technion - Israel Institute of Technology",
        "aff_unique_dep": "Department of Computer Science;Computer Science Department",
        "aff_unique_url": "https://www.unc.edu;https://www.technion.ac.il",
        "aff_unique_abbr": "UNC Chapel Hill;Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chapel Hill;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "9561303",
        "title": "Computing All Solutions to a Discretization-Invariant Formulation for Optimal Mechanism Design",
        "track": "main",
        "status": "Poster",
        "abstract": "Kinematics is the first consideration in designing the mechanical structures that comprise robots. Of the many subcategories that exist under this umbrella, an often early design goal is to achieve some desired workspace. This goal applies to both single and multi-degree-of-freedom systems. Previous literature has applied the diversity of extant optimization techniques for achieving such design goals. A conceptually simple approach to single-objective optimization is to symbolically derive a gradient vector, then find all of its zeroes. This approach is easier said than done since the resulting system is nonlinear. For this reason, sophisticated optimization heuristics are more commonly employed. In this paper, we revitalize the former approach, offering a route to efficiently find all of the gradient zeroes, including the global minimum. Our approach is facilitated by homotopy continuation. We connect the theoretical results to practical problems by demonstrating the design of a mechanism for a humanoid walking gait and the finger of a robotic hand.",
        "primary_area": "",
        "author": "Aravind Baskar;Mark Plecnik;Aravind Baskar;Mark Plecnik",
        "authorids": "/37088998829;/37085786438;/37088998829;/37085786438",
        "aff": "Department of Aerospace & Mechanical Engineering, University of Notre Dame; Department of Aerospace & Mechanical Engineering, University of Notre Dame",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561303/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3320588144586097270&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Notre Dame",
        "aff_unique_dep": "Department of Aerospace & Mechanical Engineering",
        "aff_unique_url": "https://www.nd.edu",
        "aff_unique_abbr": "Notre Dame",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561613",
        "title": "Computing the positioning error of an upper-arm robotic prosthesis from the observation of its wearer\u2019s posture",
        "track": "main",
        "status": "Poster",
        "abstract": "When the arm prosthesis worn by an amputated Human being is not adequately configured with respect to the end-effector task, body compensations are often observed. Namely, to compensate for a wrong joint positioning on the robotic distal side, a subject trying to reach a desired position/orientation of his/her hand mobilizes his/her proximal joints, thus exploiting the redundancy of the human+robot kinematic chain.In this paper, we explore the possibility of exploiting this well-known behavior to reverse the causality: if we observe the posture of an amputated subject wearing a prosthesis during a hand positioning task, to what extent can we infer the positioning error of the prosthesis?To answer this question, we make the assumption that the adequate, or natural posture for a given task is one that optimizes a postural score. The proposed approach then consists in i) measuring the joint posture of the subject fitted with the prosthesis; ii) search for an alternative posture that optimizes a postural score within the null space of the human+robot kinematic chain and iii) compute the position error for the robot joints between the initial and the optimized posture.An experimental evaluation is provided with non amputated subjects who emulate erratic positioning of their distal joints during hand positioning tasks. Results show that joint errors are estimated with a precision that seems compatible with the implementation of a real time control algorithm.",
        "primary_area": "",
        "author": "Alexis Poignant;Mathilde Legrand;Nathana\u00ebl Jarrass\u00e9;Guillaume Morel;Alexis Poignant;Mathilde Legrand;Nathana\u00ebl Jarrass\u00e9;Guillaume Morel",
        "authorids": "/37089000783;/37088398051;/38324251300;/37274022000;/37089000783;/37088398051;/38324251300;/37274022000",
        "aff": "CNRS, INSERM, Institute for Intelligent Systems and Robotics (ISIR), Sorbonne Universit\u00e9, Paris, France; CNRS, INSERM, Institute for Intelligent Systems and Robotics (ISIR), Sorbonne Universit\u00e9, Paris, France; CNRS, INSERM, Institute for Intelligent Systems and Robotics (ISIR), Sorbonne Universit\u00e9, Paris, France; CNRS, INSERM, Institute for Intelligent Systems and Robotics (ISIR), Sorbonne Universit\u00e9, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561613/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16938617173946912227&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Sorbonne Universit\u00e9",
        "aff_unique_dep": "Institute for Intelligent Systems and Robotics (ISIR)",
        "aff_unique_url": "https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "Sorbonne U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561751",
        "title": "Conditional StyleGAN for Grasp Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an approach based on conditional generative adversarial networks (GANs) to generate grasps directly and in a feed-forward manner from a raw depth image input. Building on the recently introduced StyleGAN architecture we extend results from an earlier proof-of-concept paper [1] and demonstrate successful sim2real transfer of grasp outputs for a robot arm with a Shadow Dexterous Hand. We find that the GAN model, which was only trained on a limited set of primitive objects, was able to generalize to a range of everyday real-world objects that differed significantly from the primitive objects used in simulation training. In contrast to discriminative models, the approach learns a latent representation in the set of feasible grasps that can be used for navigation in grasp space and thus allows smooth integration with other motion planning tools.",
        "primary_area": "",
        "author": "Florian Patzelt;Robert Haschke;Helge Ritter;Florian Patzelt;Robert Haschke;Helge Ritter",
        "authorids": "/37088998609;/37565751900;/37266153900;/37088998609;/37565751900;/37266153900",
        "aff": "Center of Excellence Cognitive Interaction Technology (CITEC), Neuroinformatics Group, Bielefeld University, Germany; Center of Excellence Cognitive Interaction Technology (CITEC), Neuroinformatics Group, Bielefeld University, Germany; Center of Excellence Cognitive Interaction Technology (CITEC), Neuroinformatics Group, Bielefeld University, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561751/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12712575667005895297&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Bielefeld University",
        "aff_unique_dep": "Neuroinformatics Group",
        "aff_unique_url": "https://www.uni-bielefeld.de",
        "aff_unique_abbr": "Uni Bielefeld",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9562095",
        "title": "Conditioning Style on Substance: Plans for Narrative Observation",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider a robot tasked with observing its environment and later selectively summarizing what it saw as a vivid, structured narrative. The robot interacts with an uncertain environment, modelled as a stochastic process, and must decide what events to pay attention to (substance), and how to best make its recording (style) for later compilation of its summary. If carrying a video camera, for example, it must decide where to be, what to aim the camera at, and which stylistic selections, like the focus and level of zoom, are most suitable. This paper examines planning algorithms that help the robot predict events that (1)will likely occur; (2)would be useful in telling a tale; and (3)may be hewed to cohere stylistically. The third factor, a time-extended requirement, is entirely neglected in earlier, simpler work. With formulations based on underlying Markov Decision Processes, we compare two algorithms: a monolithic planner that jointly plans over events and style pairs and a decoupled approach that prescribes style conditioned on events. The decoupled approach is seen to be effective and much faster to compute, suggesting that computational expediency justifies the separation of substance from style. Finally, we also report on our hardware implementation.",
        "primary_area": "",
        "author": "Diptanil Chaudhuri;Rhema Ike;Hazhar Rahmani;Dylan A. Shell;Aaron T. Becker;Jason M. O\u2019Kane;Diptanil Chaudhuri;Rhema Ike;Hazhar Rahmani;Dylan A. Shell;Aaron T. Becker;Jason M. O\u2019Kane",
        "authorids": "/37088998497;/37088995937;/37086453006;/37269198900;/37588897100;/37279835400;/37088998497;/37088995937;/37086453006;/37269198900;/37588897100;/37279835400",
        "aff": "Dept. of Computer Science and Engineering, Texas A&M University; Dept. of Electrical and Computer Engineering, University of Houston; Dept. of Computer Science and Engineering, University of South Carolina; Dept. of Computer Science and Engineering, Texas A&M University; Dept. of Electrical and Computer Engineering, University of Houston; Dept. of Computer Science and Engineering, University of South Carolina",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562095/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13266772811477991757&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;1;2",
        "aff_unique_norm": "Texas A&M University;University of Houston;University of South Carolina",
        "aff_unique_dep": "Department of Computer Science and Engineering;Dept. of Electrical and Computer Engineering;Dept. of Computer Science and Engineering",
        "aff_unique_url": "https://www.tamu.edu;https://www.uh.edu;https://www.sc.edu",
        "aff_unique_abbr": "TAMU;UH;USC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560781",
        "title": "Configuration Transformation of the Wheel-Legged Robot Using Inverse Dynamics Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, the configuration transformation of Wheel-Legged Robot (WLR) is studied, which can enable the robot to change its multilinks configuration on Inverted Equilibrium Manifold (IEM), while keeping balance with a small location drift on the floor. First of all, the general form of dynamics equation of planar Articulated Wheeled Inverted Pendulum (AWIP) with a wheel and n \u2212 1 rigid links, is derived. The Partial Feedback Linearization (PFL) combined with a Sliding Mode Control (SMC) is used to design the inverse dynamics controller of AWIP, while considering full dynamics terms. The well-known WLR model is used as a simple example of AWIP to accomplish the configuration transformation task. An optimization based configuration transformation algorithm is proposed to realize a comprehensive optimization of the shortest path in joint space and the minimum location drift of WLR on the floor. Finally, the effectiveness of the proposed algorithm is demonstrated through simulation to implement the configuration transformation task.",
        "primary_area": "",
        "author": "Haitao Zhou;Haoyang Yu;Xu Li;Haibo Feng;Songyuan Zhang;Yili Fu;Haitao Zhou;Haoyang Yu;Xu Li;Haibo Feng;Songyuan Zhang;Yili Fu",
        "authorids": "/37086149626;/37088996543;/37086152356;/37085664239;/38468925500;/37286601800;/37086149626;/37088996543;/37086152356;/37085664239;/38468925500;/37286601800",
        "aff": "State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560781/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2143617923114209185&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "State Key Laboratory of Robotics and System",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560994",
        "title": "Congestion-aware Multi-agent Trajectory Prediction for Collision Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting agents\u2019 future trajectories plays a crucial role in modern AI systems, yet it is challenging due to intricate interactions exhibited in multi-agent systems, especially when it comes to collision avoidance. To address this challenge, we propose to learn congestion patterns as contextual cues explicitly and devise a novel \"Sense\u2013Learn\u2013Reason\u2013Predict\" framework by exploiting advantages of three different doctrines of thought, which yields the following desirable benefits: (i) Representing congestion as contextual cues via latent factors subsumes the concept of social force commonly used in physics- based approaches and implicitly encodes the distance as a cost, similar to the way a planning-based method models the environment. (ii) By decomposing the learning phases into two stages, a \"student\" can learn contextual cues from a \"teacher\" while generating collision-free trajectories. To make the framework computationally tractable, we formulate it as an optimization problem and derive an upper bound by leveraging the variational parametrization. In experiments, we demonstrate that the proposed model is able to generate collision- free trajectory predictions in a synthetic dataset designed for collision avoidance evaluation and remains competitive on the commonly used NGSIM US-101 highway dataset. Source code and dataset tools can be accessed via Github.",
        "primary_area": "",
        "author": "Xu Xie;Chi Zhang;Yixin Zhu;Ying Nian Wu;Song-Chun Zhu;Xu Xie;Chi Zhang;Yixin Zhu;Ying Nian Wu;Song-Chun Zhu",
        "authorids": "/37086273323;/37087232818;/37086172463;/37736182700;/37281407500;/37086273323;/37087232818;/37086172463;/37736182700;/37281407500",
        "aff": "Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560994/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16800112779183093688&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Statistics Department",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561129",
        "title": "Connecting Semantic Building Information Models and Robotics: An application to 2D LiDAR-based localization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a method to integrate the rich semantic data-set provided by Building Information Modeling (BIM) with robotics world models, taking as use case indoor semantic localization in a large university building. We convert a subset of semantic entities with associated geometry present in BIM models and represented in the Industry Foundation Classes (IFC) data format to a robot-specific world model representation. This representation is then stored in a spatial database from which the robot can query semantic objects in its immediate surroundings. The contribution of this work is that, from this query, the robot\u2019s feature detectors are configured and used to make explicit data associations with semantic structural objects from the BIM model that are located near the robot\u2019s current position. A graph-based approach is then used to localize the robot, incorporating the explicit map-feature associations for localization. We show that this explainable model-based approach allows a robot equipped with a 2D LiDAR and odometry to track its pose in a large indoor environment for which a BIM model is available.",
        "primary_area": "",
        "author": "R. W. M. Hendrikx;P. Pauwels;E. Torta;H.P. J. Bruyninckx;M. J. G. van de Molengraft;R. W. M. Hendrikx;P. Pauwels;E. Torta;H.P. J. Bruyninckx;M. J. G. van de Molengraft",
        "authorids": "/37089401889;/37704703100;/38489917800;/37278642900;/37326459000;/37089401889;/37704703100;/38489917800;/37278642900;/37326459000",
        "aff": "Faculty of Mechanical Engineering, Eindhoven University of Technology, The Netherlands; Faculty of Built Environment, Eindhoven University of Technology, The Netherlands; Faculty of Mechanical Engineering, Eindhoven University of Technology, The Netherlands; Faculty of Mechanical Engineering, KU Leuven, Belgium; Faculty of Mechanical Engineering, Eindhoven University of Technology, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561129/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9294072687741199628&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Eindhoven University of Technology;KU Leuven",
        "aff_unique_dep": "Faculty of Mechanical Engineering;Faculty of Mechanical Engineering",
        "aff_unique_url": "https://www.tue.nl;https://www.kuleuven.be",
        "aff_unique_abbr": "TU/e;KU Leuven",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Eindhoven;",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Netherlands;Belgium"
    },
    {
        "id": "9560744",
        "title": "Conquering Textureless with RF-referenced Monocular Vision for MAV State Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "The versatile nature of agile micro aerial vehicles (MAVs) poses fundamental challenges to the design of robust state estimation in various complex environments. Achieving high-quality performance in textureless scenes is one of the missing pieces in the puzzle. Previously proposed solutions either seek a remedy with visual loop closure or leverage RF localizability with inferior accuracy. None of them support accurate MAV state estimation in textureless scenes. This paper presents RFSift, a new state estimator that conquers the textureless challenge with RF-referenced monocular vision, achieving centimeter-level accuracy in textureless scenes. Our key observation is that RF and visual measurements are tied up with pose constraints. Mapping RF to feature quality and sift well-matched ones significantly improves accuracy. RFSift consists of 1) an RF-sifting algorithm that maps 3D UWB measurements to 2D visual features for sifting the best features; 2) an RF-visual-inertial sensor fusion algorithm that enables robust state estimation by leveraging multiple sensors with complementary advantages. We implement the prototype with off-the-shelf products and conduct large-scale experiments. The results demonstrate that RFSift is robust in textureless scenes, 10x more accurate than the state-of-the-art monocular vision system. The code of RFSift is available at https://github.com/weisgroup/RFSift.",
        "primary_area": "",
        "author": "Shengkai Zhang;Sheyang Tang;Wei Wang;Tao Jiang;Qian Zhang;Shengkai Zhang;Sheyang Tang;Wei Wang;Tao Jiang;Qian Zhang",
        "authorids": "/37088219113;/37088211989;/37538912600;/37279307300;/37289940400;/37088219113;/37088211989;/37538912600;/37279307300;/37289940400",
        "aff": "School of Electronic Information and Communications, HUST, Wuhan, China; School of Electronic Information and Communications, HUST, Wuhan, China; School of Electronic Information and Communications, HUST, Wuhan, China; School of Electronic Information and Communications, HUST, Wuhan, China; Department of Computer Science and Engineering, HKUST, Hong Kong, SAR China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560744/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1816535164719120756&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Huazhong University of Science and Technology;Hong Kong University of Science and Technology",
        "aff_unique_dep": "School of Electronic Information and Communications;Department of Computer Science and Engineering",
        "aff_unique_url": "http://www.hust.edu.cn;https://www.hkust.edu.hk",
        "aff_unique_abbr": "HUST;HKUST",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Wuhan;Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561971",
        "title": "Consensus-Based Control Barrier Function for Swarm",
        "track": "main",
        "status": "Poster",
        "abstract": "In swarm control, many robots coordinate their actions in a distributed and decentralized way. We propose a consensus-based control barrier function (CCBF) for a swarm. CCBF restricts the states of the whole distributed system, not just those of the individual robots. The barrier function is approximated by a consensus filter. We prove that CCBF constrains the control inputs for holding the forward invariance of the safety set. Moreover, we applied CCBF to a practical problem and conducted an experiment with actual robots. The results showed that CCBF restricted the states of multiple robots to the safety set. To the best of our knowledge, this is the first CBF that can restrict the state of the whole distributed system with only local communication. CCBF has various applications such as monitoring with a swarm and maintaining the network between a swarm and a base station.",
        "primary_area": "",
        "author": "Manao Machida;Masumi Ichien;Manao Machida;Masumi Ichien",
        "authorids": "/37089001389;/37297994600;/37089001389;/37297994600",
        "aff": "Data Science Research Laboratories, NEC Corporation, Kawasaki, Kanagawa, Japan; Data Science Research Laboratories, NEC Corporation, Kawasaki, Kanagawa, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561971/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14069383577170290310&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "NEC Corporation",
        "aff_unique_dep": "Data Science Research Laboratories",
        "aff_unique_url": "https://www.nec.com",
        "aff_unique_abbr": "NEC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kawasaki",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561837",
        "title": "Consistent State Estimation on Manifolds for Autonomous Metal Structure Inspection",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents the Manifold Invariant Extended Kalman Filter, a novel approach for better consistency and accuracy in state estimation on manifolds. The robustness of this filter allows for techniques with high noise potential like ultra-wideband localization to be used for a wider variety of applications like autonomous metal structure inspection. The filter is derived and its performance is evaluated by testing it on two different manifolds: a cylindrical one and a bivariate b-spline representation of a real vessel surface, showing its flexibility to being used on different types of surfaces. Its comparison with a standard EKF that uses virtual, noise-free measurements as manifold constraints proves that it outperforms standard approaches in consistency and accuracy. Further, an experiment using a real magnetic crawler robot on a curved metal surface with ultra-wideband localization shows that the proposed approach is viable in the real world application of autonomous metal structure inspection.",
        "primary_area": "",
        "author": "Bryan Starbuck;Alessandro Fornasier;Stephan Weiss;C\u00e9dric Pradalier;Bryan Starbuck;Alessandro Fornasier;Stephan Weiss;C\u00e9dric Pradalier",
        "authorids": "/37088996725;/37088685957;/37535323400;/37279005400;/37088996725;/37088685957;/37535323400;/37279005400",
        "aff": "Georgia Tech Lorraine - CNRS UMI; Control of Networked Systems Group, University of Klagenfurt, Austria; Control of Networked Systems Group, University of Klagenfurt, Austria; Georgia Tech Lorraine - CNRS UMI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561837/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5049186098483148496&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Georgia Tech Lorraine;University of Klagenfurt",
        "aff_unique_dep": ";Control of Networked Systems Group",
        "aff_unique_url": "https://gtl.gatech.edu;https://www.uni-klagenfurt.at",
        "aff_unique_abbr": "GT Lorraine;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Lorraine;",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "France;Austria"
    },
    {
        "id": "9561530",
        "title": "Constrained Differential Dynamic Programming Revisited",
        "track": "main",
        "status": "Poster",
        "abstract": "Differential Dynamic Programming (DDP) has become a well established method for unconstrained trajectory optimization. Despite its several applications in robotics and controls, however, a widely successful constrained version of the algorithm has yet to be developed. This paper builds upon penalty methods and active-set approaches towards designing a Dynamic Programming-based methodology for constrained optimal control. Regarding the former, our derivation employs a constrained version of Bellman\u2019s principle of optimality, by introducing a set of auxiliary slack variables in the backward pass. In parallel, we show how Augmented Lagrangian methods can be naturally incorporated within DDP, by utilizing a particular set of penalty-Lagrangian functions that preserve second-order differentiability. We demonstrate experimentally that our extensions (individually and combinations thereof) enhance significantly the convergence properties of the algorithm, and outperform previous approaches on a large number of simulated scenarios.",
        "primary_area": "",
        "author": "Yuichiro Aoyama;George Boutselis;Akash Patel;Evangelos A. Theodorou;Yuichiro Aoyama;George Boutselis;Akash Patel;Evangelos A. Theodorou",
        "authorids": "/37088997423;/37085870461;/37088687165;/37546007800;/37088997423;/37085870461;/37088687165;/37546007800",
        "aff": "Komatsu Ltd., Tokyo, Japan; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561530/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9903897381120667264&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Komatsu Ltd.;Georgia Institute of Technology",
        "aff_unique_dep": ";School of Aerospace Engineering",
        "aff_unique_url": "https://www.komatsu.com;https://www.gatech.edu",
        "aff_unique_abbr": "Komatsu;Georgia Tech",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Atlanta",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Japan;United States"
    },
    {
        "id": "9560983",
        "title": "Constrained Image-Based Visual Servoing using Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel constrained image-based visual servoing (IBVS) approach that guarantees target features to remain within the camera field of view (FOV) for the duration of the task. Barrier function (BF) is used to transform the feature dynamics on the image plane into equivalent dynamics with full state constraints. An IBVS controller is designed for the full state constrained system that regulates the original system. A stability analysis is provided to prove the local asymptotic convergence of the state error in the sense of Lyapunov. Simulation and robot implementation results show the efficiency of the proposed method to reach the desired features from any initial configuration while the visibility constraints of the feature points are being realized.",
        "primary_area": "",
        "author": "Iman Salehi;Ghananeel Rotithor;Ryan Saltus;Ashwin P. Dani;Iman Salehi;Ghananeel Rotithor;Ryan Saltus;Ashwin P. Dani",
        "authorids": "/37086429379;/37086959793;/37086960783;/37531596100;/37086429379;/37086959793;/37086960783;/37531596100",
        "aff": "Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT; Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT; Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT; Department of Electrical and Computer Engineering, University of Connecticut, Storrs, CT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560983/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17868290505344435436&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Connecticut",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.uconn.edu",
        "aff_unique_abbr": "UConn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Storrs",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560868",
        "title": "Constrained Path Planning and Guidance in General Wind Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an optimal planning/guidance approach for a UAV point-to-point navigation in 2D, under wind influence, with the imposition of a general desired airspeed profile. A cost function weighting the travel time and the control effort is minimized through the Pontryagin\u2019s Minimum Principle. An analytical expression for the optimal heading to assure minimum-time flight is also derived. A general wind case in constrained path navigation is solved through an iterative procedure, using artificial potential fields.",
        "primary_area": "",
        "author": "Ely Carneiro de Paiva;Mariana Costa Perazzo;Rafael de Angelis Cordeiro;Ely Carneiro de Paiva;Mariana Costa Perazzo;Rafael de Angelis Cordeiro",
        "authorids": "/37328648300;/37088998239;/37088996399;/37328648300;/37088998239;/37088996399",
        "aff": "School of Mech. Engineering (FEM), University of Campinas (Unicamp), Campinas, SP, Brazil; School of Mech. Engineering (FEM), University of Campinas (Unicamp), Campinas, SP, Brazil; School of Mech. Engineering (FEM), University of Campinas (Unicamp), Campinas, SP, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560868/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:Rn62rJoyvHEJ:scholar.google.com/&scioq=Constrained+Path+Planning+and+Guidance+in+General+Wind+Fields&hl=en&as_sdt=0,14",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Campinas",
        "aff_unique_dep": "School of Mech. Engineering (FEM)",
        "aff_unique_url": "https://www.unicamp.br",
        "aff_unique_abbr": "Unicamp",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Campinas",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Brazil"
    },
    {
        "id": "9560795",
        "title": "Constraint Handling in Continuous-Time DDP-Based Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "The Sequential Linear Quadratic (SLQ) algorithm is a continuous-time version of the well-known Differential Dynamic Programming (DDP) technique with a Gauss-Newton Hessian approximation. This family of methods has gained popularity in the robotics community due to its efficiency in solving complex trajectory optimization problems. However, one major drawback of DDP-based formulations is their inability to properly incorporate path constraints. In this paper, we address this issue by devising a constrained SLQ algorithm that handles a mixture of constraints with a previously implemented projection technique and a new augmented-Lagrangian approach. By providing an appropriate multiplier update law, and by solving a single inner and outer loop iteration, we are able to retrieve suboptimal solutions at rates suitable for real-time model-predictive control applications. We particularly focus on the inequality-constrained case, where three augmented-Lagrangian penalty functions are introduced, along with their corresponding multiplier update rules. These are then benchmarked against a relaxed log-barrier formulation in a cart-pole swing up example, an obstacle-avoidance task, and an object-pushing task with a quadrupedal mobile manipulator.",
        "primary_area": "",
        "author": "Jean-Pierre Sleiman;Farbod Farshidian;Marco Hutter;Jean-Pierre Sleiman;Farbod Farshidian;Marco Hutter",
        "authorids": "/37087322472;/37085428006;/37545251000;/37087322472;/37085428006;/37545251000",
        "aff": "The Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; The Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; The Robotic Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560795/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10539569759984919873&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561037",
        "title": "Contact Forces Preintegration for Estimation in Legged Robotics using Factor Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "State estimation, in particular estimation of the base position, orientation and velocity, plays a big role in the efficiency of legged robot stabilization. The estimation of the base state is particularly important because of its strong correlation with the underactuated dynamics, i.e. the evolution of center of mass and angular momentum. Yet this estimation is typically done in two phases, first estimating the base state, then reconstructing the center of mass from the robot model. The underactuated dynamics is indeed not properly observed, and any bias in the model would not be corrected from the sensors. While it has already been observed that force measurements make such a bias observable, these are often only used for a binary estimation of the contact state. In this paper, we propose to simultaneously estimate the base and the underactuation state by exploiting all measurements simultaneously. To this end, we propose several contributions to implement a complete state estimator using factor graphs. Contact forces altering the underactuated dynamics are pre-integrated using a novel adaptation of the IMU pre-integration method, which constitutes the principal contribution. IMU pre-integration is also used to estimate the positional motion of the base. Encoder measurements then participate to the estimation in two ways: by providing leg odometry displacements which contributes to the observability of IMU biases; and by relating the positional and centroidal states, thus connecting the whole graph and producing a tightly-coupled whole-body estimator. The validity of the approach is demonstrated on real data captured by the Solo12 quadruped robot.",
        "primary_area": "",
        "author": "M\u00e9d\u00e9ric Fourmy;Thomas Flayols;Pierre-Alexandre L\u00e9ziart;Nicolas Mansard;Joan Sol\u00e0;M\u00e9d\u00e9ric Fourmy;Thomas Flayols;Pierre-Alexandre L\u00e9ziart;Nicolas Mansard;Joan Sol\u00e0",
        "authorids": "/37088340075;/37086293347;/37087901433;/37542913400;/37407733200;/37088340075;/37086293347;/37087901433;/37542913400;/37407733200",
        "aff": "LAAS-CNRS, Universit\u00e9 de Toulouse, France; Artificial and Natural Intelligence Toulouse Institute, Toulouse, France; LAAS-CNRS, Universit\u00e9 de Toulouse, France; Artificial and Natural Intelligence Toulouse Institute, Toulouse, France; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, Barcelona",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561037/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7788623760400600923&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;2",
        "aff_unique_norm": "Universit\u00e9 de Toulouse;Artificial and Natural Intelligence Toulouse Institute;Institut de Rob\u00f2tica i Inform\u00e0tica Industrial",
        "aff_unique_dep": "LAAS-CNRS;;",
        "aff_unique_url": "https://www.univ-toulouse.fr;;https://www.iri.upc.edu/",
        "aff_unique_abbr": "UT;ANITI;IRI",
        "aff_campus_unique_index": "1;1;2",
        "aff_campus_unique": ";Toulouse;Barcelona",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "France;Spain"
    },
    {
        "id": "9562058",
        "title": "Contact Localization for Robot Arms in Motion without Torque Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Detecting and localizing contacts is essential for robot manipulators to perform contact-rich tasks in unstructured environments. While robot skins can localize contacts on the surface of robot arms, these sensors are not yet robust or easily accessible. As such, prior works have explored using proprioceptive observations, such as joint velocities and torques, to perform contact localization. Many past approaches assume the robot is static during contact incident, a single contact is made at a time, or having access to accurate dynamics models and joint torque sensing. In this work, we relax these assumptions and propose using Domain Randomization to train a neural network to localize contacts of robot arms in motion without joint torque observations. Our method uses a novel cylindrical projection encoding of the robot arm surface, which allows the network to use convolution layers to process input features and transposed convolution layers to predict contacts. The trained network achieves a contact detection accuracy of 91.5% and a mean contact localization error of 3.0cm. We further demonstrate an application of the contact localization model in an obstacle mapping task, evaluated in both simulation and the real world.",
        "primary_area": "",
        "author": "Jacky Liang;Oliver Kroemer;Jacky Liang;Oliver Kroemer",
        "authorids": "/37088504798;/37593222300;/37088504798;/37593222300",
        "aff": "Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562058/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11046811371907453546&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560766",
        "title": "Contact Mode Guided Sampling-Based Planning for Quasistatic Dexterous Manipulation in 2D",
        "track": "main",
        "status": "Poster",
        "abstract": "The discontinuities and multi-modality introduced by contacts make manipulation planning challenging. Many previous works avoid this problem by pre-designing a set of high-level motion primitives like grasping and pushing. However, such motion primitives are often not adequate to describe dexterous manipulation motions. In this work, we propose a method for dexterous manipulation planning at a more primitive level. The key idea is to use contact modes to guide the search in a sampling-based planning framework. Our method can automatically generate contact transitions and motion trajectories under the quasistatic assumption. In the experiments, this method sometimes generates motions that are often pre-designed as motion primitives, as well as dexterous motions that are more task-specific 1.",
        "primary_area": "",
        "author": "Xianyi Cheng;Eric Huang;Yifan Hou;Matthew T. Mason;Xianyi Cheng;Eric Huang;Yifan Hou;Matthew T. Mason",
        "authorids": "/37086574792;/37086066878;/37086454260;/37273994200;/37086574792;/37086066878;/37086454260;/37273994200",
        "aff": "Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560766/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17665456849926559461&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561877",
        "title": "Contact-GraspNet: Efficient 6-DoF Grasp Generation in Cluttered Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping unseen objects in unconstrained, cluttered environments is an essential skill for autonomous robotic manipulation. Despite recent progress in full 6-DoF grasp learning, existing approaches often consist of complex sequential pipelines that possess several potential failure points and run-times unsuitable for closed-loop grasping. Therefore, we propose an end-to-end network that efficiently generates a distribution of 6-DoF parallel-jaw grasps directly from a depth recording of a scene. Our novel grasp representation treats 3D points of the recorded point cloud as potential grasp contacts. By rooting the full 6-DoF grasp pose and width in the observed point cloud, we can reduce the dimensionality of our grasp representation to 4-DoF which greatly facilitates the learning process. Our class-agnostic approach is trained on 17 million simulated grasps and generalizes well to real world sensor data. In a robotic grasping study of unseen objects in structured clutter we achieve over 90% success rate, cutting the failure rate in half compared to a recent state-of-the-art method. Video of the real world experiments and code are available at https://research.nvidia.com/publication/2021-03_Contact-GraspNet%3A--Efficient.",
        "primary_area": "",
        "author": "Martin Sundermeyer;Arsalan Mousavian;Rudolph Triebel;Dieter Fox;Martin Sundermeyer;Arsalan Mousavian;Rudolph Triebel;Dieter Fox",
        "authorids": "/37089406746;/37085404794;/37542908700;/37284329000;/37089406746;/37085404794;/37542908700;/37284329000",
        "aff": "Technical University of Munich (TUM); NVIDIA; Technical University of Munich (TUM); University of Washington",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561877/",
        "gs_citation": 424,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7435707566181754125&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Technical University of Munich;NVIDIA;University of Washington",
        "aff_unique_dep": ";NVIDIA Corporation;",
        "aff_unique_url": "https://www.tum.de;https://www.nvidia.com;https://www.washington.edu",
        "aff_unique_abbr": "TUM;NVIDIA;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9561521",
        "title": "Contact-Implicit Trajectory Optimization With Learned Deformable Contacts Using Bilevel Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a bilevel, contact-implicit trajectory optimization (TO) formulation that searches for robot trajectories with learned soft contact models. On the lower-level, contact forces are solved via a quadratic program (QP) with the maximum dissipation principle (MDP), based on which the dynamics constraints are formulated in the upper-level TO problem that uses direct transcription. Our method uses a contact model for granular media that is learned from physical experiments, but is general to any contact model that is stick-slip, convex, and smooth. We employ a primal interior-point method with a pre-specified duality gap to solve the lower-level problem, which provides robust gradient information to the upper-level problem. We evaluate our method by optimizing locomotion trajectories of a quadruped robot on various granular terrains offline, and show that we can obtain long-horizon walking gaits of high qualities.",
        "primary_area": "",
        "author": "Yifan Zhu;Zherong Pan;Kris Hauser;Yifan Zhu;Zherong Pan;Kris Hauser",
        "authorids": "/37088507100;/37086067204;/37543748800;/37088507100;/37086067204;/37543748800",
        "aff": "Department of Computer Science, University of Illinois at Urbana-Champaign, IL, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, IL, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561521/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17346033518837276684&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561593",
        "title": "Context-Aware Safe Reinforcement Learning for Non-Stationary Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety is a critical concern when deploying reinforcement learning agents for realistic tasks. Recently, safe reinforcement learning algorithms have been developed to optimize the agent\u2019s performance while avoiding violations of safety constraints. However, few studies have addressed the nonstationary disturbances in the environments, which may cause catastrophic outcomes. In this paper, we propose the context-aware safe reinforcement learning (CASRL) method, a metal-earning framework to realize safe adaptation in non-stationary environments. We use a probabilistic latent variable model to achieve fast inference of the posterior environment transition distribution given the context data. Safety constraints are then evaluated with uncertainty-aware trajectory sampling. Prior safety constraints are formulated with domain knowledge to improve safety during exploration. The algorithm is evaluated in realistic safety-critical environments with non-stationary disturbances. Results show that the proposed algorithm significantly outperforms existing baselines in terms of safety and robustness.",
        "primary_area": "",
        "author": "Baiming Chen;Zuxin Liu;Jiacheng Zhu;Mengdi Xu;Wenhao Ding;Liang Li;Ding Zhao;Baiming Chen;Zuxin Liu;Jiacheng Zhu;Mengdi Xu;Wenhao Ding;Liang Li;Ding Zhao",
        "authorids": "/37088689832;/37086936718;/37086544946;/37088505867;/37088505922;/37835892200;/37085680141;/37088689832;/37086936718;/37086544946;/37088505867;/37088505922;/37835892200;/37085680141",
        "aff": "State Key Laboratory of Automotive Safety and Energy, Tsinghua University, Beijing, China; Department of Mechanical Engineering, Carnegie Mellon University, USA; Department of Mechanical Engineering, Carnegie Mellon University, USA; Department of Mechanical Engineering, Carnegie Mellon University, USA; Department of Mechanical Engineering, Carnegie Mellon University, USA; State Key Laboratory of Automotive Safety and Energy, Tsinghua University, Beijing, China; Department of Mechanical Engineering, Carnegie Mellon University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561593/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2585544954690118709&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;0;1",
        "aff_unique_norm": "Tsinghua University;Carnegie Mellon University",
        "aff_unique_dep": "State Key Laboratory of Automotive Safety and Energy;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.cmu.edu",
        "aff_unique_abbr": "THU;CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;1;1;1;1;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9562043",
        "title": "Context-Dependent Anomaly Detection for Low Altitude Traffic Surveillance",
        "track": "main",
        "status": "Poster",
        "abstract": "The detection of contextual anomalies is a challenging task for surveillance since an observation can be considered anomalous or normal in a specific environmental context. An unmanned aerial vehicle (UAV) can utilize its aerial monitoring capability and employ multiple sensors to gather contextual information about the environment and perform contextual anomaly detection. In this work, we introduce a deep neural network-based method (CADNet) to find point anomalies (i.e., single instance anomalous data) and contextual anomalies (i.e., context-specific abnormality) in an environment using a UAV. The method is based on a variational autoencoder (VAE) with a context sub-network. The context sub-network extracts contextual information regarding the environment using GPS and time data, then feeds it to the VAE to predict anomalies conditioned on the context. To the best of our knowledge, our method is the first contextual anomaly detection method for UAV-assisted aerial surveillance. We evaluate our method on the AU-AIR dataset in a traffic surveillance scenario. Quantitative comparisons against several baselines demonstrate the superiority of our approach in the anomaly detection tasks. The codes and data will be available at https://bozcani.github.io/cadnet.",
        "primary_area": "",
        "author": "Ilker Bozcan;Erdal Kayacan;Ilker Bozcan;Erdal Kayacan",
        "authorids": "/37086455563;/37595300900;/37086455563;/37595300900",
        "aff": "Department of Electrical and Computer Engineering, Artificial Intelligence in Robotics Laboratory (Air Lab), Aarhus University, Aarhus C, Denmark; Department of Electrical and Computer Engineering, Artificial Intelligence in Robotics Laboratory (Air Lab), Aarhus University, Aarhus C, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562043/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11540546039893337223&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Aarhus University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.au.dk",
        "aff_unique_abbr": "AU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Aarhus",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9561870",
        "title": "Contextual Latent-Movements Off-Policy Optimization for Robotic Manipulation Skills",
        "track": "main",
        "status": "Poster",
        "abstract": "Parameterized movement primitives have been extensively used for imitation learning of robotic tasks. However, the high-dimensionality of the parameter space hinders the improvement of such primitives in the reinforcement learning (RL) setting, especially for learning with physical robots. In this paper we propose a novel view on handling the demonstrated trajectories for acquiring low-dimensional, non-linear latent dynamics, using mixtures of probabilistic principal component analyzers (MPPCA) on the movements\u2019 parameter space. Moreover, we introduce a new contextual off-policy RL algorithm, named LAtent-Movements Policy Optimization (LAMPO). LAMPO can provide gradient estimates from previous experience using self-normalized importance sampling, hence, making full use of samples collected in previous learning iterations. These advantages combined provide a complete framework for sample-efficient off-policy optimization of movement primitives for robot learning of high-dimensional manipulation skills. Our experimental results conducted both in simulation and on a real robot show that LAMPO provides sample-efficient policies against common approaches in literature. Code available at https://github.com/SamuelePolimi/lampo.",
        "primary_area": "",
        "author": "Samuele Tosatto;Georgia Chalvatzaki;Jan Peters;Samuele Tosatto;Georgia Chalvatzaki;Jan Peters",
        "authorids": "/37086325207;/37085353493;/37533077600;/37086325207;/37085353493;/37533077600",
        "aff": "Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561870/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6278794220439974288&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Intelligent Autonomous Systems",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Darmstadt",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561683",
        "title": "Contingencies from Observations: Tractable Contingency Planning with Learned Behavior Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans have a remarkable ability to accurately reason about future events, including the behaviors and states of mind of other agents. Consider driving a car through a busy intersection: it is necessary to reason about the physics of the vehicle, the intentions of other drivers, and their beliefs about your own intentions. For example, if you signal a turn, another driver might yield to you; or if you enter the passing lane, another driver might decelerate to give you room to merge in front. Competent drivers must plan how they can safely react to a variety of potential future behaviors of other agents before they make their next move. This requires contingency planning: explicitly planning a set of conditional actions that depend on the stochastic outcome of future events. In this work, we develop a general-purpose contingency planner that is learned end-to-end using high-dimensional scene observations and low-dimensional behavioral observations. We use a conditional autoregressive flow model for contingency planning. We show how this model can tractably learn contingencies from behavioral observations. We developed a closed-loop control benchmark of realistic multi-agent scenarios in a driving simulator (CARLA), on which we compare our method to various noncontingent methods that reason about multi-agent future behavior, and find that our contingency planning method achieves qualitatively and quantitatively superior performance.",
        "primary_area": "",
        "author": "Nicholas Rhinehart;Jeff He;Charles Packer;Matthew A. Wright;Rowan McAllister;Joseph E. Gonzalez;Sergey Levine;Nicholas Rhinehart;Jeff He;Charles Packer;Matthew A. Wright;Rowan McAllister;Joseph E. Gonzalez;Sergey Levine",
        "authorids": "/37085401789;/37089000364;/37086111776;/37085897886;/38540418600;/37086566024;/37085481973;/37085401789;/37089000364;/37086111776;/37085897886;/38540418600;/37086566024;/37085481973",
        "aff": "UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561683/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7613827299684116880&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560793",
        "title": "Continual Model-Based Reinforcement Learning with Hypernetworks",
        "track": "main",
        "status": "Poster",
        "abstract": "Effective planning in model-based reinforcement learning (MBRL) and model-predictive control (MPC) relies on the accuracy of the learned dynamics model. In many instances of MBRL and MPC, this model is assumed to be stationary and is periodically re-trained from scratch on state transition experience collected from the beginning of environment interactions. This implies that the time required to train the dynamics model - and the pause required between plan executions - grows linearly with the size of the collected experience. We argue that this is too slow for lifelong robot learning and propose HyperCRL, a method that continually learns the encountered dynamics in a sequence of tasks using task-conditional hypernetworks. Our method has three main attributes: first, it includes dynamics learning sessions that do not revisit training data from previous tasks, so it only needs to store the most recent fixed-size portion of the state transition experience; second, it uses fixed-capacity hypernetworks to represent non-stationary and task-aware dynamics; third, it outperforms existing continual learning alternatives that rely on fixed-capacity networks, and does competitively with baselines that remember an ever increasing coreset of past experience. We show that HyperCRL is effective in continual model-based reinforcement learning in robot locomotion and manipulation scenarios, such as tasks involving pushing and door opening. Our project website with videos is at this link http://rvl.cs.toronto.edu/blog/2020/hypercrl/",
        "primary_area": "",
        "author": "Yizhou Huang;Kevin Xie;Homanga Bharadhwaj;Florian Shkurti;Yizhou Huang;Kevin Xie;Homanga Bharadhwaj;Florian Shkurti",
        "authorids": "/37088995990;/37088998841;/37086638775;/37706697200;/37088995990;/37088998841;/37086638775;/37706697200",
        "aff": "Division of Engineering Science, University of Toronto, Canada; Department of Computer Science, University of Toronto, Canada; Department of Computer Science, University of Toronto, Canada; Department of Computer Science, University of Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560793/",
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9742474038673437752&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Division of Engineering Science",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561209",
        "title": "Continuous Optimization-Based Task and Motion Planning with Signal Temporal Logic Specifications for Sequential Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new optimization-based task and motion planning (TAMP) with signal temporal logic (STL) specifications for robotic sequential manipulation such as pick-and-place tasks. Given a high-level task specification, the TAMP problem is to plan a trajectory that satisfies the specification. This is, however, a challenging problem due to the difficulty of combining continuous motion planning and discrete task specifications. The optimization-based TAMP with temporal logic specifications is a promising method, but existing works use mixed integer problems (MIP) and do not scale well. To address this issue, in our approach, a new hybrid system model without discrete variables is introduced and combined with smooth approximation methods for STL. This allows the TAMP to be formulated as a nonlinear programming problem whose computational cost is significantly less than that of MIP. Furthermore, it is also possible to deal with nonlinear dynamics and geometric constraints represented by nonlinear functions. The effectiveness of the proposed method is demonstrated with both numerical experiments and a real robot.",
        "primary_area": "",
        "author": "Rin Takano;Hiroyuki Oyama;Masaki Yamakita;Rin Takano;Hiroyuki Oyama;Masaki Yamakita",
        "authorids": "/37086014041;/37085392095;/37279385100;/37086014041;/37085392095;/37279385100",
        "aff": "Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan; Data Science Research Laboratories, NEC Corporation, Kanagawa, Japan; Department of Systems and Control Engineering, Tokyo Institute of Technology, Meguro, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561209/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=319654059991659460&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "NEC Corporation;Tokyo Institute of Technology",
        "aff_unique_dep": "Data Science Research Laboratories;Department of Systems and Control Engineering",
        "aff_unique_url": "https://www.nec.com;https://www.titech.ac.jp",
        "aff_unique_abbr": "NEC;Titech",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Meguro",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9560981",
        "title": "Continuous Shortest Path Vector Field Navigation on 3D Triangular Meshes for Mobile Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a highly efficient approach to compute continuous shortest path vector fields on arbitrarily shaped 3D triangular meshes for robot navigation in complex real-world outdoor environments. The continuity of the vector field allows to query the shortest distance, direction and geodesic path to the goal at any point within the mesh triangles, resulting in accurate paths. In order to avoid impassable areas, our wavefront propagation method runs on a modular extendable multilayer map architecture taking different geometric cost layers into account. We describe the mathematical foundation of the geodesic distances and continuous vector field computation and demonstrate the performance in real-world and multilevel environments on our campus with a tunnel, ramps and stair- cases, and in a difficult, steep forest area with a stone quarry. For reproducibility, we provide a ready-to-use ROS software stack as well as Gazebo simulations.",
        "primary_area": "",
        "author": "Sebastian P\u00fctz;Thomas Wiemann;Malte Kleine Piening;Joachim Hertzberg;Sebastian P\u00fctz;Thomas Wiemann;Malte Kleine Piening;Joachim Hertzberg",
        "authorids": "/37086573829;/37945726600;/37087014153;/37273307000;/37086573829;/37945726600;/37087014153;/37273307000",
        "aff": "Plan-Based Robot Control, German Research Center for Artificial Intelligence, DFKI; Plan-Based Robot Control, German Research Center for Artificial Intelligence, DFKI; Plan-Based Robot Control, German Research Center for Artificial Intelligence, DFKI; Plan-Based Robot Control, German Research Center for Artificial Intelligence, DFKI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560981/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4059311157746762970&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "German Research Center for Artificial Intelligence",
        "aff_unique_dep": "Plan-Based Robot Control",
        "aff_unique_url": "https://www.dfki.de",
        "aff_unique_abbr": "DFKI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561137",
        "title": "Continuous Transition: Improving Sample Efficiency for Continuous Control Problems via MixUp",
        "track": "main",
        "status": "Poster",
        "abstract": "Although deep reinforcement learning (RL) has been successfully applied to a variety of robotic control tasks, it\u2019s still challenging to apply it to real-world tasks, due to the poor sample efficiency. Attempting to overcome this shortcoming, several works focus on reusing the collected trajectory data during the training by decomposing them into a set of policy-irrelevant discrete transitions. However, their improvements are somewhat marginal since i) the amount of the transitions is usually small, and ii) the value assignment only happens in the joint states. To address these issues, this paper introduces a concise yet powerful method to construct Continuous Transition, which exploits the trajectory information by exploiting the potential transitions along the trajectory. Specifically, we propose to synthesize new transitions for training by linearly interpolating the consecutive transitions. To keep the constructed transitions authentic, we also develop a discriminator to guide the construction process automatically. Extensive experiments demonstrate that our proposed method achieves a significant improvement in sample efficiency on various complex continuous robotic control problems in MuJoCo and outperforms the advanced model-based / model-free RL methods. The source code is available1.",
        "primary_area": "",
        "author": "Junfan Lin;Zhongzhan Huang;Keze Wang;Xiaodan Liang;Weiwei Chen;Liang Lin;Junfan Lin;Zhongzhan Huang;Keze Wang;Xiaodan Liang;Weiwei Chen;Liang Lin",
        "authorids": "/37088997253;/37088997941;/37075653600;/37085465293;/37088996152;/37406180600;/37088997253;/37088997941;/37075653600;/37085465293;/37088996152;/37406180600",
        "aff": "Sun Yat-sen University, Guangzhou, China; Dark Matter AI Inc.; University of California, Los Angeles; Dark Matter AI Inc.; Dark Matter AI Inc.; Dark Matter AI Inc.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561137/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8061614000851998606&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;1;1;1",
        "aff_unique_norm": "Sun Yat-sen University;Dark Matter AI Inc.;University of California, Los Angeles",
        "aff_unique_dep": ";;",
        "aff_unique_url": "http://www.sysu.edu.cn/;;https://www.ucla.edu",
        "aff_unique_abbr": "SYSU;;UCLA",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Guangzhou;;Los Angeles",
        "aff_country_unique_index": "0;1;1;1;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561318",
        "title": "Continuous-time State & Dynamics Estimation using a Pseudo-Spectral Parameterization",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel continuous time trajectory representation based on a Chebyshev polynomial basis, which when governed by known dynamics models, allows for full trajectory and robot dynamics estimation, particularly useful for high-performance robotics applications such as unmanned aerial vehicles. We show that we can gracefully incorporate model dynamics to our trajectory representation, within a factor-graph based framework, and leverage ideas from pseudo- spectral optimal control to parameterize the state and the control trajectories as interpolating polynomials. This allows us to perform efficient optimization at specifically chosen points derived from the theory, while recovering full trajectory estimates. Through simulated experiments we demonstrate the applicability of our representation for accurate flight dynamics estimation for multirotor aerial vehicles. The representation framework is general and can thus be applied to a multitude of high-performance applications beyond multirotor platforms.",
        "primary_area": "",
        "author": "Varun Agrawal;Frank Dellaert;Varun Agrawal;Frank Dellaert",
        "authorids": "/37086571187;/37282902200;/37086571187;/37282902200",
        "aff": "Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561318/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12942984786031495473&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Institute for Robotics and Intelligent Machines",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561168",
        "title": "Contour Primitive of Interest Extraction Network Based on One-Shot Learning for Object-Agnostic Vision Measurement",
        "track": "main",
        "status": "Poster",
        "abstract": "Image contour based vision measurement is widely applied in robot manipulation and industrial automation. It is appealing to realize object-agnostic vision system, which can be conveniently reused for various types of objects. We propose the contour primitive of interest extraction network (CPieNet) based on the one-shot learning framework. First, CPieNet is featured by that its contour primitive of interest (CPI) output, a designated regular contour part lying on a specified object, provides the essential geometric information for vision measurement. Second, CPieNet has the one-shot learning ability, utilizing a support sample to assist the perception of the novel object. To realize lower-cost training, we generate support-query sample pairs from unpaired online public images, which cover a wide range of object categories. To obtain single-pixel wide contour for precise measurement, the Gabor-filters based non-maximum suppression is designed to thin the raw contour. For the novel CPI extraction task, we built the Object Contour Primitives dataset using online public images, and the Robotic Object Contour Measurement dataset using a camera mounted on a robot. The effectiveness of the proposed methods is validated by a series of experiments.",
        "primary_area": "",
        "author": "Fangbo Qin;Jie Qin;Siyu Huang;De Xu;Fangbo Qin;Jie Qin;Siyu Huang;De Xu",
        "authorids": "/37085793636;/37088998155;/37089399405;/37291415100;/37085793636;/37088998155;/37089399405;/37291415100",
        "aff": "Research Center of Precision Sensing and Control, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Research Center of Precision Sensing and Control, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Research Center of Precision Sensing and Control, Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561168/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11145551050480133968&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Chinese Academy of Sciences;Tsinghua University",
        "aff_unique_dep": "Institute of Automation;Department of Automation",
        "aff_unique_url": "http://www.ia.cas.cn;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "CAS;THU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560910",
        "title": "Control of a Transfemoral Prosthesis on Sloped Terrain using Continuous and Nonlinear Impedance Parameters",
        "track": "main",
        "status": "Poster",
        "abstract": "The design of impedance controllers for sloped walking with a transfemoral prosthesis is a complex control problem that generally results in numerous tuning parameters. This study proposes an easy-to-tune sloped walking control scheme. While the ankle is controlled using impedance control, the knee is controlled using a hybrid strategy of impedance control and trajectory tracking. This study derived continuous, nonlinear impedance functions for the ankle and knee joints using optimization. Principal component analysis of the impedance functions revealed trends that can be used to design impedance controllers for any given slope angle. Said trends were further used to establish a tuning regime which was subsequently tested on a transfemoral prosthesis in an emulator study. The generated gait kinematics and kinetics were found to follow the trends of healthy sloped walking data.",
        "primary_area": "",
        "author": "Namita Anil Kumar;Woolim Hong;Pilwon Hur;Namita Anil Kumar;Woolim Hong;Pilwon Hur",
        "authorids": "/37086047809;/37086200267;/38317004800;/37086047809;/37086200267;/38317004800",
        "aff": "Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA; Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA; Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560910/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1462381363422602721&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560827",
        "title": "Control of an Aerial Manipulator Using a Quadrotor with a Replaceable Robotic Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "Control of an aerial manipulator is challenging due to the decentralized dynamics of the aerial vehicle and the robotic arm. It is generally complex to adjust the controller of the aerial manipulator when replacing a different robotic arm. This paper presents a flexible control scheme for a quadrotor-based aerial manipulator equipped with a replaceable robotic arm. To analyze the dynamic characteristics during grasping, the model of the aerial manipulator is decentralized including the models of a quadrotor and the centroid of an n-DOF robotic arm. The interaction effect of a moving robotic arm on the quadrotor is considered by analyzing the varying centroid of the robotic arm. Based on the modeling of the aerial manipulator, a control scheme integrating a linear model predictive control (LMPC) and a feedforward controller is presented to accurately control the motion of the aerial platform. The LMPC controls the aerial vehicle to follow the desired trajectory, and a feedforward controller keeps the aerial platform hovering stably during grasping. Practical experiments with two different robotic arms are performed. Experimental results show that the proposed modeling and control scheme provides a flexible and effective approach for an aerial manipulator with a replaceable robotic arm.",
        "primary_area": "",
        "author": "Zizhen Ouyang;Ruidong Mei;Zisen Liu;Mingxin Wei;Zida Zhou;Hui Cheng;Zizhen Ouyang;Ruidong Mei;Zisen Liu;Mingxin Wei;Zida Zhou;Hui Cheng",
        "authorids": "/37088998025;/37088996408;/37088998666;/37088996060;/37088999699;/38008557800;/37088998025;/37088996408;/37088998666;/37088996060;/37088999699;/38008557800",
        "aff": "School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Electronics and Information Technology, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560827/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9854685938823803902&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Sun Yat-sen University",
        "aff_unique_dep": "School of Computer Science and Engineering",
        "aff_unique_url": "http://www.sysu.edu.cn",
        "aff_unique_abbr": "SYSU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561664",
        "title": "Control-Tree Optimization: an approach to MPC under discrete Partial Observability",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a new approach to Model Predictive Control for environments where essential, discrete variables are partially observed. Under this assumption, the belief state is a probability distribution over a finite number of states. We optimize a control-tree where each branch assumes a given state-hypothesis. The control-tree optimization uses the probabilistic belief state information. This leads to policies more optimized with respect to likely states than unlikely ones, while still guaranteeing robust constraint satisfaction at all times. We apply the method to both linear and non-linear MPC with constraints. The optimization of the control-tree is decomposed into optimization subproblems that are solved in parallel leading to good scalability for high number of state-hypotheses. We demonstrate the real-time feasibility of the algorithm on two examples and show the benefits compared to a classical MPC scheme optimizing w.r.t. one single hypothesis.",
        "primary_area": "",
        "author": "Camille Phiquepal;Marc Toussaint;Camille Phiquepal;Marc Toussaint",
        "authorids": "/37086934298;/37528418600;/37086934298;/37528418600",
        "aff": "Machine Learning & Robotic Lab, University of Stuttgart, Germany; Learning and Intelligent Systems Lab, TU Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561664/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=87611962103494308&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Stuttgart;Technische Universit\u00e4t Berlin",
        "aff_unique_dep": "Machine Learning & Robotic Lab;Learning and Intelligent Systems Lab",
        "aff_unique_url": "https://www.uni-stuttgart.de;https://www.tu-berlin.de",
        "aff_unique_abbr": ";TU Berlin",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Berlin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9560771",
        "title": "Conv1D Energy-Aware Path Planner for Mobile Robots in Unstructured Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Driving energy consumption plays a major role in the navigation of mobile robots in challenging environments, especially if they are left to operate unattended under limited on-board power. This paper reports on first results of an energy-aware path planner, which can provide estimates of the driving energy consumption and energy recovery of a robot traversing complex uneven terrains. Energy is estimated over trajectories making use of a self-supervised learning approach, in which the robot autonomously learns how to correlate perceived terrain point clouds to energy consumption and recovery. A novel feature of the method is the use of 1D convolutional neural network to analyse the terrain sequentially in the same temporal order as it would be experienced by the robot when moving. The performance of the proposed approach is assessed in simulation over several digital terrain models collected from real natural scenarios, and is compared with a heuristic inclination-based energy model. We show evidence of the benefit of our method to increase the overall prediction r2 score by 66.8% and to reduce the driving energy consumption over planned paths by 5.5%.",
        "primary_area": "",
        "author": "Marco Visca;Arthur Bouton;Roger Powell;Yang Gao;Saber Fallah;Marco Visca;Arthur Bouton;Roger Powell;Yang Gao;Saber Fallah",
        "authorids": "/37088999318;/37085781027;/37088997540;/37069689900;/38667400500;/37088999318;/37085781027;/37088997540;/37069689900;/38667400500",
        "aff": "Connected and Autonomous Vehicles Lab (CAV Lab), University of Surrey, Guildford, UK; Surrey Space Centre, Space Technology for Autonomous and Robotic Laboratory (STAR LAB), University of Surrey, Guildford, UK; Remote Applications in Challenging Environments, Cybernetics Group, UK Atomic Energy Authority, Culham Science Centre; Surrey Space Centre, Space Technology for Autonomous and Robotic Laboratory (STAR LAB), University of Surrey, Guildford, UK; Connected and Autonomous Vehicles Lab (CAV Lab), University of Surrey, Guildford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560771/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8965634789345348366&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Surrey;UK Atomic Energy Authority",
        "aff_unique_dep": "Connected and Autonomous Vehicles Lab (CAV Lab);Cybernetics Group",
        "aff_unique_url": "https://www.surrey.ac.uk;https://www.ukaea.ukri.org",
        "aff_unique_abbr": "Surrey;UKAEA",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Guildford;Culham Science Centre",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561674",
        "title": "Cooperative Visual-Inertial Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the problem of multi-robot cooperative visual-inertial localization where each robot is equipped with only a single camera and IMU. We develop two cooperative visual-inertial odometry (C-VIO) algorithms within the multi-state constraint Kalman filter (MSCKF) framework, in which each robot utilizes not only its own measurements but constraints of common features co-observed with its neighbors within the current sliding window in order to improve the localization accuracy. The first centralized-equivalent algorithm tracks the robot-to-robot cross correlations and prioritizes the pose accuracy while requiring full capacity communication among all the robots during update. The second distributed algorithm ignores the robot-to-robot cross correlations to obtain a scalable, robust and efficient fully distributed structure where each robot only keeps its own states and communicates with its neighbors, while a covariance intersection (CI)-based update strategy is leveraged to guarantee consistency. The proposed algorithms are validated extensively in both Monte-Carlo simulations and real-world datasets, and shown to be able to achieve better accuracy with competitive efficiency.",
        "primary_area": "",
        "author": "Pengxiang Zhu;Yulin Yang;Wei Ren;Guoquan Huang;Pengxiang Zhu;Yulin Yang;Wei Ren;Guoquan Huang",
        "authorids": "/37086958473;/37085990232;/37271980400;/37077670600;/37086958473;/37085990232;/37271980400;/37077670600",
        "aff": "Department of Electrical and Computer Engineering, University of California, Riverside, CA, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Department of Electrical and Computer Engineering, University of California, Riverside, CA, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561674/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9150581603097211399&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of California, Riverside;University of Delaware",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Robot Perception and Navigation Group",
        "aff_unique_url": "https://www.ucr.edu;https://www.udel.edu",
        "aff_unique_abbr": "UCR;UD",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Riverside;Newark",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561672",
        "title": "Cost-to-Go Function Generating Networks for High Dimensional Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents c2g-HOF networks which learn to generate cost-to-go functions for manipulator motion planning. The c2g-HOF architecture consists of a cost-to-go function over the configuration space represented as a neural network (c2g-network) as well as a Higher Order Function (HOF) network which outputs the weights of the c2g-network for a given input workspace. Both networks are trained end-to-end in a supervised fashion using costs computed from traditional motion planners. Once trained, c2g-HOF can generate a smooth and continuous cost-to-go function directly from workspace sensor inputs (represented as a point cloud in 3D or an image in 2D). At inference time, the weights of the c2g-network are computed very efficiently and near-optimal trajectories are generated by simply following the gradient of the cost-to-go function.We compare c2g-HOF with traditional planning algorithms for various robots and planning scenarios. The experimental results indicate that planning with c2g-HOF is significantly faster than other motion planning algorithms, resulting in orders of magnitude improvement when including collision checking. Furthermore, despite being trained from sparsely sampled trajectories in configuration space, c2g-HOF generalizes to generate smoother, and often lower cost, trajectories. We demonstrate cost-to-go based planning on a 7 DoF manipulator arm where motion planning in a complex workspace requires only 0.13 seconds for the entire trajectory.",
        "primary_area": "",
        "author": "Jinwook Huh;Volkan Isler;Daniel D. Lee;Jinwook Huh;Volkan Isler;Daniel D. Lee",
        "authorids": "/37085775953;/37298487800;/37280609600;/37085775953;/37298487800;/37280609600",
        "aff": "Samsung AI Center NY, New York, New York; Samsung AI Center NY, New York, New York; Samsung AI Center NY, New York, New York",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561672/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8206053438738107374&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "SAC NY",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561821",
        "title": "Coupled Mobile Manipulation via Trajectory Optimization with Free Space Decomposition",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a real-time method for whole-body trajectory optimization of mobile manipulators in simplified dynamic and unstructured environments. Current trajectory optimization methods typically use decoupling of the mobile base and the robotic arm, which reduces flexibility in motion, does not scale to unstructured environments, and does not consider the future evolution of the environment, which is crucial to avoid dynamic obstacles. Given a goal configuration, such as waypoints generated by a global path planner, we formulate a receding horizon trajectory optimization minimizing the distance-to-target while avoiding collisions with static and dynamic obstacles. The presented method unifies the control of a robotic arm and a non-holonomic base to allow coupled trajectory planning. For collision avoidance, we propose to compute three convex regions englobing the robot's major body parts (i.e., base, shoulder-link and wrist-link) and thus reducing and limiting the number of inequality constraints, regardless of the number of obstacles in the environment. Moreover, our approach incorporates predicted trajectory information to smoothly, and in advance, avoid dynamic obstacles. The presented results show that trajectory optimization for the coupled system can reduce the total execution time by 48% and that applying the convex region generation for individual links allows keeping the computational costs low, even for complex scenarios, enabling onboard implementation.",
        "primary_area": "",
        "author": "Max Spahn;Bruno Brito;Javier Alonso-Mora;Max Spahn;Bruno Brito;Javier Alonso-Mora",
        "authorids": "/37088998268;/37086963867;/38271697300;/37088998268;/37086963867;/38271697300",
        "aff": "Department of Cognitive Robotics, Delft University of Technology, CD, Delft, The Netherlands; Department of Cognitive Robotics, Delft University of Technology, CD, Delft, The Netherlands; Department of Cognitive Robotics, Delft University of Technology, CD, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561821/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2056153353845023804&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Department of Cognitive Robotics",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TUDelft",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9561826",
        "title": "Covariance Self-Attention Dual Path UNet for Rectal Tumor Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning algorithms are recognized as the most effective method for rectal tumor segmentation. However, since the multi-scale detailed feature information of rectal tumor cannot be fully extracted and applied, the segmentation and identification results of most algorithms are not always perfect. In this work, we introduce a Covariance Self-Attention Dual Path UNet (CSA-DPUNet), that is modified on the basis of UNet network and self-attention mechanism to improve network performance in feature processing and representation. The proposed network mainly makes two improvements. First, the UNet structure with single path is extended to dual paths (DPUNet). By broadening the network connections, our network is able to learn more local features with multiple contextual scales from CT images. Second, an improved criss-cross self-attention module is incorporated into DPUNet(CSA-DPUNet), instead of correlation method, we adopt covariance operation to calculate the attention weight map of self-attention mechanism, which can adaptively enhance feature combination and characterization ability. Experiments illustrate that our network called CSA-DPUNet can obviously improves the segmentation accuracy of rectal tumors, which brings 15.31%, 7.2%, 11.8%, and 9.5% improvement in Dice coefficient, P, R, F1, respectively compared with state-of-the-art. The above characteristics make the proposed CSA-DPUNet suitable for segmenting rectal tumor in practice.",
        "primary_area": "",
        "author": "Haijun Gao;Xiangyin Zeng;Dazhi Pan;Bochuan Zheng;Haijun Gao;Xiangyin Zeng;Dazhi Pan;Bochuan Zheng",
        "authorids": "/37088997756;/37088997354;/37088996680;/37089000584;/37088997756;/37088997354;/37088996680;/37089000584",
        "aff": "School of Mathematics & Information, China West Normal University Nanchong Sichuan, China; School of Computer Science, China West Normal University, Nanchong Sichuan, China; Institute of Computing Method and Application Software, China West Normal University, Nanchong Sichuan, China; Institute of Computing Method and Application Software, China West Normal University, Nanchong Sichuan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561826/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13714548281741584708&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "China West Normal University",
        "aff_unique_dep": "School of Mathematics & Information",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Nanchong",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561992",
        "title": "Crawling Support Using Wearable SuperLimbs: Human-Robot Synchronization and Metabolic Cost Assessment",
        "track": "main",
        "status": "Poster",
        "abstract": "A pair of Supernumerary Robotic Limbs (Super-Limbs) can brace the wearer\u2019s upper body while they work at floor level, and support them during crawling. The SuperLimbs\u2019 motion is synchronized with the operator to mimic natural human crawling. This synchronization relies on experimental data from the operator\u2019s observed crawl. A method for predicting the phase difference between the SuperLimbs\u2019 hand placement and the operators desired hand placement is developed and used to coordinate the SuperLimbs\u2019 motion with the operator\u2019s. The experimental data is also used to design the structure of the SuperLimbs to minimize their energy consumption during crawling and regulate their actuator\u2019s temperatures.The SuperLimbs are designed to mimic the operator\u2019s arms while they crawl, however factors such as their limited number of degrees of freedom (DoF), compared to natural limbs, and the compliance of the connection between the SuperLimbs and the operator means that the SuperLimbs\u2019s may dynamically interact with the wearer differently from how their natural limbs do. A simple dynamic model is constructed to assess the energy consumed by the operator as they crawl with the SuperLimbs under different coordination patterns. An optimal coordination pattern is obtained from this assessment.",
        "primary_area": "",
        "author": "Phillip Daniel;H. Harry Asada;Phillip Daniel;H. Harry Asada",
        "authorids": "/38667464200;/37085790203;/38667464200;/37085790203",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561992/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15926400267339847474&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561694",
        "title": "Crowd against the machine: A simulation-based benchmark tool to evaluate and compare robot capabilities to navigate a human crowd",
        "track": "main",
        "status": "Poster",
        "abstract": "The evaluation of robot capabilities to navigate human crowds is essential to conceive new robots intended to operate in public spaces. This paper initiates the development of a benchmark tool to evaluate such capabilities; our long term vision is to provide the community with a simulation tool that generates virtual crowded environment to test robots, to establish standard scenarios and metrics to evaluate navigation techniques in terms of safety and efficiency, and thus, to install new methods to benchmarking robots\u2019 crowd navigation capabilities. This paper presents the architecture of the simulation tools, introduces first scenarios and evaluation metrics, as well as early results to demonstrate that our solution is relevant to be used as a benchmark tool.",
        "primary_area": "",
        "author": "Fabien Grzeskowiak;David Gonon;Daniel Dugas;Diego Paez-Granados;Jen Jen Chung;Juan Nieto;Roland Siegwart;Aude Billard;Marie Babel;Julien Pettr\u00e9;Fabien Grzeskowiak;David Gonon;Daniel Dugas;Diego Paez-Granados;Jen Jen Chung;Juan Nieto;Roland Siegwart;Aude Billard;Marie Babel;Julien Pettr\u00e9",
        "authorids": "/37087526060;/37088839883;/37086030360;/37085669907;/37085668354;/37085778635;/37281398300;/37273980800;/37563684500;/37330553700;/37087526060;/37088839883;/37086030360;/37085669907;/37085668354;/37085778635;/37281398300;/37273980800;/37563684500;/37330553700",
        "aff": "Univ Rennes Inria CNRS IRISA, Rennes, France; EPFL, Lausanne, Switzerland; ETH, Z\u00fcrich, Switzerland; EPFL, Lausanne, Switzerland; ETH, Z\u00fcrich, Switzerland; ETH, Z\u00fcrich, Switzerland; ETH, Z\u00fcrich, Switzerland; EPFL, Lausanne, Switzerland; Univ Rennes Inria CNRS IRISA, Rennes, France; Univ Rennes Inria CNRS IRISA, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561694/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13157866643111183133&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;2;1;2;2;2;1;0;0",
        "aff_unique_norm": "University of Rennes;EPFL;ETH Zurich",
        "aff_unique_dep": "Inria, CNRS, IRISA;;",
        "aff_unique_url": "https://www.univ-rennes1.fr;https://www.epfl.ch;https://www.ethz.ch",
        "aff_unique_abbr": "Univ Rennes;EPFL;ETH",
        "aff_campus_unique_index": "0;1;2;1;2;2;2;1;0;0",
        "aff_campus_unique": "Rennes;Lausanne;Z\u00fcrich",
        "aff_country_unique_index": "0;1;1;1;1;1;1;1;0;0",
        "aff_country_unique": "France;Switzerland"
    },
    {
        "id": "9560854",
        "title": "Cubic B\u00e9zier Local Path Planner for Non-holonomic Feasible and Comfortable Path Generation",
        "track": "main",
        "status": "Poster",
        "abstract": "In the case of non-holonomic robot navigation, path planning algorithms such as Rapidly-exploring Random Tree (RRT) rarely provide feasible and smooth paths without the need of additional processing. Furthermore, in a transport context like power wheelchair navigation, passenger comfort should be a priority and influence path planning strategy. In this paper, we propose a local path planner which guarantees bounded curvature value and continuous Cubic B\u00e9zier piecewise curves connection. To simulate and test this Cubic B\u00e9zier local path planner, we developed a new RRT version (CBB-RRT*) which generates on-the fly comfortable path adapted to non-holonomic constraints.",
        "primary_area": "",
        "author": "Guillaume Vailland;Val\u00e9rie Gouranton;Marie Babel;Guillaume Vailland;Val\u00e9rie Gouranton;Marie Babel",
        "authorids": "/37086917565;/38056908800;/37563684500;/37086917565;/38056908800;/37563684500",
        "aff": "INSA Rennes, Inria, CNRS, Irisa, Univ Rennes, Rennes, France; INSA Rennes, Inria, CNRS, Irisa, Univ Rennes, Rennes, France; INSA Rennes, Inria, CNRS, Irisa, Univ Rennes, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560854/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11815812177673399750&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "INSA Rennes",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.insa-rennes.fr",
        "aff_unique_abbr": "INSA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Rennes",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561096",
        "title": "Customized Handling of Unintended Interface Operation In Assistive Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an assistance system that reasons about a human\u2019s intended actions during robot teleoperation in order to provide appropriate modifications on unintended behavior. Existing methods typically treat the human and control interface as a black box and assume the measured user input is noise-free, and use this signal to infer task-level human intent. We recognize that the signal measured through the interface is masked by the physical limitations of the user and the interface they are required to use. With this key insight, we model the human\u2019s physical interaction with a control interface during robot teleoperation, and distinguish between interface-level intended and measured physical actions explicitly. By reasoning over the unobserved intentions using model-based inference techniques, our assistive system provides customized modifications on a user\u2019s issued commands. We validate our algorithm both in simulation and with a 10-person human subject study in which we evaluate the performance of the proposed assistance paradigms. Our results show that the assistance paradigms helped to significantly reduce task completion time, number of mode switches, cognitive workload, and user frustration, and improve overall user satisfaction.",
        "primary_area": "",
        "author": "Deepak Gopinath;Mahdieh Nejati Javaremi;Brenna Argall;Deepak Gopinath;Mahdieh Nejati Javaremi;Brenna Argall",
        "authorids": "/37085852666;/37086919826;/37568669000;/37085852666;/37086919826;/37568669000",
        "aff": "Shirley Ryan AbilityLab, Chicago, IL, USA; Shirley Ryan AbilityLab, Chicago, IL, USA; Shirley Ryan AbilityLab, Chicago, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561096/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17137643917981016642&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shirley Ryan AbilityLab",
        "aff_unique_dep": "",
        "aff_unique_url": "https://abilitylab.org",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561427",
        "title": "Cutting Depth Compensation Based on Milling Acoustic Signal for Robotic-Assisted Laminectomy",
        "track": "main",
        "status": "Poster",
        "abstract": "To optimize the cutting depth in robotic-assisted laminectomy, we present a real-time method to adjust the preoperatively planned feed rate in the depth direction of the robot cutting trajectory. Not only the linearity between the harmonic amplitude of the milling acoustic signal and the cutting depth is discussed by analyzing the milling dynamic model, but its influencing variables are analyzed. The amplitude of the harmonic components whose frequency are integer multiples of the spindle frequency of the surgical power tool is extracted by FFT (Fast Fourier transform). A digital PD (Proportional-Differential) controller with a dead zone generates the speed compensation amount according to the deviation of the harmonic amplitude from the expected value. In artificial bone sensitivity test experiments, the cutting depth can be estimated with a resolution of 0.15mm within the cutting depth range of 0-1.2mm by the harmonic amplitude signal. Furthermore, the safety of the proposed method under different bone deformations is verified by cutting depth control experiments.",
        "primary_area": "",
        "author": "Guangming Xia;Bin Yao;Yu Dai;Jianxun Zhang;Guangming Xia;Bin Yao;Yu Dai;Jianxun Zhang",
        "authorids": "/37088749835;/37089609686;/37085562045;/37281461800;/37088749835;/37089609686;/37085562045;/37281461800",
        "aff": "College of Artificial Intelligence, Nankai University, Tianjin, China; College of Artificial Intelligence, Nankai University, Tianjin, China; College of Artificial Intelligence, Nankai University, Tianjin, China; College of Artificial Intelligence, Nankai University, Tianjin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561427/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5789817085085620842&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nankai University",
        "aff_unique_dep": "College of Artificial Intelligence",
        "aff_unique_url": "http://www.nankai.edu.cn",
        "aff_unique_abbr": "Nankai",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tianjin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561021",
        "title": "D-ACC: Dynamic Adaptive Cruise Control for Highways with Ramps Based on Deep Q-Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "An Adaptive Cruise Control (ACC) system allows vehicles to maintain a desired headway distance to a preceding vehicle automatically. It is increasingly adopted by commercial vehicles. Recent research demonstrates that the effective use of ACC can improve the traffic flow through the adaptation of the headway distance in response to the current traffic conditions. In this paper, we demonstrate that a state-of-the- art intelligent ACC system performs poorly on highways with ramps due to the limitation of the model-based approaches that do not take into account appropriately the traffic dynamics on ramps in determining the optimal headway distance. We then propose a dynamic adaptive cruise control system (D- ACC) based on deep reinforcement learning that adapts the headway distance effectively according to dynamically changing traffic conditions for both the main road and ramp to optimize the traffic flow. Extensive simulations are performed with a combination of a traffic simulator (SUMO) and vehicle-to- everything communication (V2X) network simulator (Veins) under numerous traffic scenarios. We demonstrate that D-ACC improves the traffic flow by up to 70% compared with a state- of-the-art intelligent ACC system in a highway segment with a ramp.",
        "primary_area": "",
        "author": "Lokesh Das;Myounggyu Won;Lokesh Das;Myounggyu Won",
        "authorids": "/37088997956;/37400163000;/37088997956;/37400163000",
        "aff": "Department of Computer Science, University of Memphis, Memphis, TN, United States; Department of Computer Science, University of Memphis, Memphis, TN, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561021/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14482451606796272437&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Memphis",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.memphis.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Memphis",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561399",
        "title": "DESERTS: DElay-tolerant SEmi-autonomous Robot Teleoperation for Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Telesurgery can be hindered by high-latency and low-bandwidth communication networks, often found in austere settings. Even delays of less than one second are known to negatively impact surgeries. To tackle the effects of connectivity associated with telerobotic surgeries, we propose the DESERTS framework. DESERTS provides a novel simulator interface where the surgeon can operate directly on a virtualized reality simulation and the activities are mirrored in a remote robot, almost simultaneously. Thus, the surgeon can perform the surgery uninterrupted, while high-level commands are extracted from his motions and are sent to a remote robotic agent. The simulated setup mirrors the remote environment, including an alpha-blended view of the remote scene. The framework abstracts the actions into atomic surgical maneuvers (surgemes) which eliminate the need to transmit compressed video information. This system uses a deep learning based architecture to perform live recognition of the surgemes executed by the operator. The robot then executes the received surgemes, thereby achieving semi-autonomy. The framework\u2019s performance was tested on a peg transfer task. We evaluated the accuracy of the recognition and execution module independently as well as during live execution. Furthermore, we assessed the framework\u2019s performance in the presence of increasing delays. Notably, the system maintained a task success rate of 87% from no-delays to 5 seconds of delay.",
        "primary_area": "",
        "author": "Glebys Gonzalez;Mridul Agarwal;Mythra V. Balakuntala;Md Masudur Rahman;Upinder Kaur;Richard M. Voyles;Vaneet Aggarwal;Yexiang Xue;Juan Wachs;Glebys Gonzalez;Mridul Agarwal;Mythra V. Balakuntala;Md Masudur Rahman;Upinder Kaur;Richard M. Voyles;Vaneet Aggarwal;Yexiang Xue;Juan Wachs",
        "authorids": "/37087236532;/37087236791;/37087236032;/874937453303135;/37938211700;/37283531400;/37302263100;/37086866298;/37327560600;/37087236532;/37087236791;/37087236032;/874937453303135;/37938211700;/37283531400;/37302263100;/37086866298;/37327560600",
        "aff": "School of Industrial Engineering, Purdue University, West Lafayette, IN, USA; School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; School of Engineering Technology, Purdue University, West Lafayette, IN, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA; School of Engineering Technology, Purdue University, West Lafayette, IN, USA; School of Engineering Technology, Purdue University, West Lafayette, IN, USA; School of Electrical and Computer Engineering, Purdue University, West Lafayette, IN, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA; School of Industrial Engineering, Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561399/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15505892994958187070&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Purdue University",
        "aff_unique_dep": "School of Industrial Engineering",
        "aff_unique_url": "https://www.purdue.edu",
        "aff_unique_abbr": "Purdue",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "West Lafayette",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561248",
        "title": "DILIGENT-KIO: A Proprioceptive Base Estimator for Humanoid Robots using Extended Kalman Filtering on Matrix Lie Groups",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a contact-aided inertial-kinematic floating base estimation for humanoid robots considering an evolution of the state and observations over matrix Lie groups. This is achieved through the application of a geometrically meaningful estimator which is characterized by concentrated Gaussian distributions. The configuration of a floating base system like a humanoid robot usually requires the knowledge of an additional six degrees of freedom which describes its base position-and-orientation. This quantity usually cannot be measured and needs to be estimated. A matrix Lie group, encapsulating the position-and-orientation and linear velocity of the base link, feet positions-and-orientations and Inertial Measurement Units\u2019 biases, is used to represent the state while relative positions-and-orientations of contact feet from forward kinematics are used as observations. The proposed estimator exhibits fast convergence for large initialization errors owing to choice of uncertainty parametrization. An experimental validation is done on the iCub humanoid platform.",
        "primary_area": "",
        "author": "Prashanth Ramadoss;Giulio Romualdi;Stefano Dafarra;Francisco Javier Andrade Chavez;Silvio Traversaro;Daniele Pucci;Prashanth Ramadoss;Giulio Romualdi;Stefano Dafarra;Francisco Javier Andrade Chavez;Silvio Traversaro;Daniele Pucci",
        "authorids": "/37087983620;/37086598289;/37086168241;/37088996116;/37085503650;/37706167200;/37087983620;/37086598289;/37086168241;/37088996116;/37085503650;/37706167200",
        "aff": "DIBRIS, University of Genoa, Genoa, Italy; DIBRIS, University of Genoa, Genoa, Italy; Dynamic Interaction Control, Italian Institute of Technology, Genoa, Italy; Human Centered Robotics and Machine Intelligence, University of Waterloo, Ontario, Canada; iCub Tech, Italian Institute of Technology, Genoa, Italy; Dynamic Interaction Control, Italian Institute of Technology, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561248/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11748586023710745516&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;2;1;1",
        "aff_unique_norm": "University of Genoa;Italian Institute of Technology;University of Waterloo",
        "aff_unique_dep": "DIBRIS;Dynamic Interaction Control;Human Centered Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it;https://uwaterloo.ca",
        "aff_unique_abbr": ";IIT;UW",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Genoa;Waterloo",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "Italy;Canada"
    },
    {
        "id": "9561740",
        "title": "DIMSAN: Fast Exploration with the Synergy between Density-based Intrinsic Motivation and Self-adaptive Action Noise",
        "track": "main",
        "status": "Poster",
        "abstract": "Exploration in environments with sparse rewards remains a challenging problem in Deep Reinforcement Learning (DRL). For the off-policy method, it usually needs a large number of training samples. With the growing dimensions of state and action space, this method becomes more and more sample-inefficient. In this paper, we propose a novel fast exploration method for off-policy reinforcement learning, called Density-based Intrinsic Motivation and Self-adaptive Action Noise (DIMSAN). Our main contribution is twofold: (1) We propose a Density-based Intrinsic Motivation (DIM) method. It introduces a new intrinsic-reward generation mechanism based on samples\u2019 density estimation during experience replay and encourages the agent to seek novel and unfamiliar states. (2) We propose a Self-adaptive Action Noise (SAN) to deal with the exploration-exploitation tradeoffs, which could automatically change the exploration step through adding adaptive action space noise. The synergy between DIM and SAN could guide the agent to search the state and action space with high efficiency. We evaluate our method on the benchmark manipulation tasks and the designed challenging ones. Empirical results show that our method outperforms the existing methods in terms of convergence speed and sample efficiency, especially in challenging tasks.",
        "primary_area": "",
        "author": "Jiayi Li;Boyao Li;Tao Lu;Ning Lu;Yinghao Cai;Shuo Wang;Jiayi Li;Boyao Li;Tao Lu;Ning Lu;Yinghao Cai;Shuo Wang",
        "authorids": "/37087244449;/37087008702;/37855750400;/37087245311;/37654083400;/37280458600;/37087244449;/37087008702;/37855750400;/37087245311;/37654083400;/37280458600",
        "aff": "State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Research and Development Department, China Academy of Launch Vehicle Technology, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561740/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:FUjBgZm-ZNkJ:scholar.google.com/&scioq=DIMSAN:+Fast+Exploration+with+the+Synergy+between+Density-based+Intrinsic+Motivation+and+Self-adaptive+Action+Noise&hl=en&as_sdt=0,33",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Chinese Academy of Sciences;China Academy of Launch Vehicle Technology",
        "aff_unique_dep": "Institute of Automation;Research and Development Department",
        "aff_unique_url": "http://www.ia.cas.cn;",
        "aff_unique_abbr": "CAS;",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Beijing;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561073",
        "title": "DIPN: Deep Interaction Prediction Network with Application to Clutter Removal",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a Deep Interaction Prediction Network (DIPN) for learning to predict complex interactions that ensue as a robot end-effector pushes multiple objects, whose physical properties, including size, shape, mass, and friction coefficients may be unknown a priori. DIPN \"imagines\" the effect of a push action and generates an accurate synthetic image of the predicted outcome. DIPN is shown to be sample efficient when trained in simulation or with a real robotic system. The high accuracy of DIPN allows direct integration with a grasp network, yielding a robotic manipulation system capable of executing challenging clutter removal tasks while being trained in a fully self-supervised manner. The overall network demonstrates intelligent behavior in selecting proper actions between push and grasp for completing clutter removal tasks and significantly outperforms the previous state-of-the-art. Remarkably, DIPN achieves even better performance on the real robotic hardware system than in simulation.",
        "primary_area": "",
        "author": "Baichuan Huang;Shuai D. Han;Abdeslam Boularias;Jingjin Yu;Baichuan Huang;Shuai D. Han;Abdeslam Boularias;Jingjin Yu",
        "authorids": "/37088981654;/37086094452;/37542596800;/37536570700;/37088981654;/37086094452;/37542596800;/37536570700",
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561073/",
        "gs_citation": 77,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8735980419400617835&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561452",
        "title": "DOT: Dynamic Object Tracking for Visual SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present DOT (Dynamic Object Tracking), a front-end that added to existing SLAM systems can significantly improve their robustness and accuracy in highly dynamic environments. DOT combines instance segmentation and multi-view geometry to generate masks for dynamic objects in order to allow SLAM systems based on rigid scene models to avoid such image areas in their optimizations.To determine which objects are actually moving, DOT segments first instances of potentially dynamic objects and then, with the estimated camera motion, tracks such objects by minimizing the photometric reprojection error. This short-term tracking improves the accuracy of the segmentation with respect to other approaches. In the end, only actually dynamicmasks are generated.We have evaluated DOT with ORB-SLAM 2 [1] in three public datasets. Our results show that our approach improves significantly the accuracy and robustness of ORB-SLAM2, especially in highly dynamic scenes.",
        "primary_area": "",
        "author": "Irene Ballester;Alejandro Font\u00e1n;Javier Civera;Klaus H. Strobl;Rudolph Triebel;Irene Ballester;Alejandro Font\u00e1n;Javier Civera;Klaus H. Strobl;Rudolph Triebel",
        "authorids": "/37089002042;/37088459245;/37579561700;/37273199100;/37542908700;/37089002042;/37088459245;/37579561700;/37273199100;/37542908700",
        "aff": "Technical University of Vienna; University of Zaragoza; University of Zaragoza; German Aerospace Center (DLR); Technical University of Munich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561452/",
        "gs_citation": 91,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11385393485828980392&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;3",
        "aff_unique_norm": "Technical University of Vienna;University of Zaragoza;German Aerospace Center;Technical University of Munich",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.tu.wien.ac.at/;https://www.unizar.es;https://www.dlr.de;https://www.tum.de",
        "aff_unique_abbr": "TU Vienna;UniZar;DLR;TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;2;2",
        "aff_country_unique": "Austria;Spain;Germany"
    },
    {
        "id": "9561100",
        "title": "DRACO: Weakly Supervised Dense Reconstruction And Canonicalization of Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "We present DRACO, a method for Dense Reconstruction And Canonicalization of Object shape from one or more RGB images. Canonical shape reconstruction\u2014 estimating 3D object shape in a coordinate space canonicalized for scale, rotation, and translation parameters\u2014is an emerging paradigm that holds promise for a multitude of robotic applications. Prior approaches either rely on painstakingly gathered dense 3D supervision, or produce only sparse canonical representations, limiting real-world applicability. DRACO performs dense canonicalization using only weak supervision in the form of camera poses and semantic keypoints at train time. During inference, DRACO predicts dense object-centric depth maps in a canonical coordinate-space, solely using one or more RGB images of an object. Extensive experiments on canonical shape reconstruction and pose estimation show that DRACO is competitive or superior to fully-supervised methods.",
        "primary_area": "",
        "author": "Rahul Sajnani;AadilMehdi Sanchawala;Krishna Murthy Jatavallabhula;Srinath Sridhar;K. Madhava Krishna;Rahul Sajnani;AadilMehdi Sanchawala;Krishna Murthy Jatavallabhula;Srinath Sridhar;K. Madhava Krishna",
        "authorids": "/37088535763;/37088538330;/37085828293;/37085473189;/38201465600;/37088535763;/37088538330;/37085828293;/37085473189;/38201465600",
        "aff": "Robotics Research Center, KCIS, IIIT, Hyderabad, India; Robotics Research Center, KCIS, IIIT, Hyderabad, India; Mila, Universite de Montreal, Canada; Brown University, USA; Robotics Research Center, KCIS, IIIT, Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561100/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5921794024635450773&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "International Institute of Information Technology, Hyderabad;Universite de Montreal;Brown University",
        "aff_unique_dep": "Robotics Research Center;Mila;",
        "aff_unique_url": "https://iiit Hyderabad.ac.in;https://www.mila.quebec;https://www.brown.edu",
        "aff_unique_abbr": "IIIT Hyderabad;UM;Brown",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Hyderabad;Montreal;",
        "aff_country_unique_index": "0;0;1;2;0",
        "aff_country_unique": "India;Canada;United States"
    },
    {
        "id": "9561462",
        "title": "DWA-RL: Dynamically Feasible Deep Reinforcement Learning Policy for Robot Navigation among Mobile Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel Deep Reinforcement Learning (DRL) based policy to compute dynamically feasible and spatially aware velocities for a robot navigating among mobile obstacles. Our approach combines the benefits of the Dynamic Window Approach (DWA) in terms of satisfying the robot\u2019s dynamics constraints with state-of-the-art DRL-based navigation methods that can handle moving obstacles and pedestrians well. Our formulation achieves these goals by embedding the environmental obstacles\u2019 motions in a novel low-dimensional observation space. It also uses a novel reward function to positively reinforce velocities that move the robot away from the obstacle\u2019s heading direction leading to significantly lower number of collisions. We evaluate our method in realistic 3-D simulated environments and on a real differential drive robot in challenging dense indoor scenarios with several walking pedestrians. We compare our method with state-of-the-art collision avoidance methods and observe significant improvements in terms of success rate (up to 33% increase), number of dynamics constraint violations (up to 61% decrease), and smoothness. We also conduct ablation studies to highlight the advantages of our observation space formulation, and reward structure.",
        "primary_area": "",
        "author": "Utsav Patel;Nithish K Sanjeev Kumar;Adarsh Jagan Sathyamoorthy;Dinesh Manocha;Utsav Patel;Nithish K Sanjeev Kumar;Adarsh Jagan Sathyamoorthy;Dinesh Manocha",
        "authorids": "/37088415023;/37088996485;/37086924122;/37267825600;/37088415023;/37088996485;/37086924122;/37267825600",
        "aff": "Dept. of Computer Science, University of Maryland, College Park, MD, USA; Dept. of Computer Science, University of Maryland, College Park, MD, USA; Dept. of Electrical and Computer Engineering, University of Maryland, College Park, MD, USA; Dept. of Computer Science, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561462/",
        "gs_citation": 88,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10966936625611837717&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Maryland;University of Maryland, College Park",
        "aff_unique_dep": "Department of Computer Science;Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "https://www/umd.edu;https://www/umd.edu",
        "aff_unique_abbr": "UMD;UMD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561158",
        "title": "Dark Reciprocal-Rank: Teacher-to-student Knowledge Transfer from Self-localization Model to Graph-convolutional Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "In visual robot self-localization, graph-based scene representation and matching have recently attracted research interest as robust and discriminative methods for self-localization. Although effective, their computational and storage costs do not scale well to large-size environments. To alleviate this problem, we formulate self-localization as a graph classification problem and attempt to use the graph convolutional neural network (GCN) as a graph classification engine. A straightforward approach is to use visual feature descriptors that are employed by state-of-the-art self-localization systems, directly as graph node features. However, their superior performance in the original self-localization system may not necessarily be replicated in GCN-based self-localization. To address this issue, we introduce a novel teacher-to-student knowledge-transfer scheme based on rank matching, in which the reciprocal-rank vector output by an off-the-shelf state-of-the-art teacher self-localization model is used as the dark knowledge to transfer. Experiments indicate that the proposed graph-convolutional self-localization network (GCLN) can significantly outperform state-of-the-art self-localization systems, as well as the teacher classifier. The code and dataset are available at https://github.com/KojiTakeda00/Reciprocal_rank_KT_GCN.",
        "primary_area": "",
        "author": "Takeda Koji;Tanaka Kanji;Takeda Koji;Tanaka Kanji",
        "authorids": "/37086886630;/37845876800;/37086886630;/37845876800",
        "aff": "Graduate School of Engineering, University of Fukui, Japan; Faculty of Engineering, University of Fukui, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561158/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5863152280822939599&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Fukui",
        "aff_unique_dep": "Graduate School of Engineering",
        "aff_unique_url": "https://www.u-fukui.ac.jp",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9560857",
        "title": "Data-Driven Adaptive Task Allocation for Heterogeneous Multi-Robot Teams Using Robust Control Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-robot task allocation is a ubiquitous problem in robotics due to its applicability in a variety of scenarios. Adaptive task-allocation algorithms account for unknown disturbances and unpredicted phenomena in the environment where robots are deployed to execute tasks. However, this adaptivity typically comes at the cost of requiring precise knowledge of robot models in order to evaluate the allocation effectiveness and to adjust the task assignment online. As such, environmental disturbances can significantly degrade the accuracy of the models which in turn negatively affects the quality of the task allocation. In this paper, we leverage Gaussian processes, differential inclusions, and robust control barrier functions to learn environmental disturbances in order to guarantee robust task execution. We show the implementation and the effectiveness of the proposed framework on a real multi-robot system.",
        "primary_area": "",
        "author": "Yousef Emam;Gennaro Notomista;Paul Glotfelter;Magnus Egerstedt;Yousef Emam;Gennaro Notomista;Paul Glotfelter;Magnus Egerstedt",
        "authorids": "/37086695386;/37085607644;/37086021223;/37269707500;/37086695386;/37085607644;/37086021223;/37269707500",
        "aff": "Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Optimus Ride, Massachusetts, USA; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560857/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3271565340210489999&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Optimus Ride",
        "aff_unique_dep": "Institute for Robotics and Intelligent Machines;",
        "aff_unique_url": "https://www.gatech.edu;",
        "aff_unique_abbr": "Georgia Tech;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Atlanta;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561001",
        "title": "Data-based Control of Partially-Observed Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a data-based approach to control robotic systems with partially-observed feedback. First, an open-loop optimization problem is solved to generate the nominal trajectory and then a linear time-varying Autoregressive\u2013Moving-Average (ARMA) model of the system is calculated along the trajectory from the output measurement data. The system is then described in information state, which contains input-output information of the past few steps. Finally, a feedback gain which is calculated by solving a specific LQG problem along the nominal trajectory. The separate design of the open-loop and the closed-loop problem is used following the Decoupled Data-based Control (D2C) approach. Simulation results are also shown for complex models with fluid-structure interaction in the presence of both process and measurement noise.",
        "primary_area": "",
        "author": "Ran Wang;Raman Goyal;Suman Chakravorty;Robert E. Skelton;Ran Wang;Raman Goyal;Suman Chakravorty;Robert E. Skelton",
        "authorids": "/37088372183;/37086314049;/37301575800;/37299678000;/37088372183;/37086314049;/37301575800;/37299678000",
        "aff": "Department of Aerospace Engineering, Texas A&M University, Texas, USA; Department of Aerospace Engineering, Texas A&M University, Texas, USA; Department of Aerospace Engineering, Texas A&M University, Texas, USA; Department of Aerospace Engineering, Texas A&M University, Texas, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561001/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17044447404147540439&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Department of Aerospace Engineering",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Texas",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561050",
        "title": "Data-driven Actuator Selection for Artificial Muscle-Powered Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Even though artificial muscles have gained popularity due to their compliant, flexible and compact properties, there currently does not exist an easy way of making informed decisions on the appropriate actuation strategy when designing a muscle-powered robot; thus limiting the transition of such technologies into broader applications. What\u2019s more, when a new muscle actuation technology is developed, it is difficult to compare it against existing robot muscles. To accelerate the development of artificial muscle applications, we propose a data-driven approach for robot muscle actuator selection using Support Vector Machines (SVM). This first-of-its-kind method gives users insight into which actuators fit their specific needs and actuation performance criteria, making it possible for researchers and engineers with little to no prior knowledge of artificial muscles to focus on application design. It also provides a platform to benchmark existing, new or yet-to-be discovered artificial muscle technologies. We test our method on unseen existing robot muscle designs to prove its usability on real-world applications. We provide an open-access, web-searchable interface for easy access to our models that will additionally allow for the continuous contribution of new actuator data from groups around the world to enhance and expand these models.",
        "primary_area": "",
        "author": "Taylor West Henderson;Yuheng Zhi;Angela Liu;Michael C. Yip;Taylor West Henderson;Yuheng Zhi;Angela Liu;Michael C. Yip",
        "authorids": "/37086339549;/37086937002;/37088999780;/37085382768;/37086339549;/37086937002;/37088999780;/37085382768",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561050/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15614841394488098506&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562083",
        "title": "Data-driven Holistic Framework for Automated Laparoscope Optimal View Control with Learning-based Depth Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "Laparoscopic Field of View (FOV) control is one of the most fundamental and important components in Minimally Invasive Surgery (MIS), nevertheless the traditional manual holding paradigm may easily bring fatigue to surgical assistants, and misunderstanding between surgeons also hinders assistants to provide a high-quality FOV. Targeting this problem, we here present a data-driven framework to realize an automated laparoscopic optimal FOV control. To achieve this goal, we offline learn a motion strategy of laparoscope relative to the surgeon\u2019s hand-held surgical tool from our in-house surgical videos, developing our control domain knowledge and an optimal view generator. To adjust the laparoscope online, we first adopt a learning-based method to segment the two-dimensional (2D) position of the surgical tool, and further leverage this outcome to obtain its scale-aware depth from dense depth estimation results calculated by our novel unsupervised RoboDepth model only with the monocular camera feedback, hence in return fusing the above real-time 3D position into our control loop. To eliminate the misorientation of FOV caused by Remote Center of Motion (RCM) constraints when moving the laparoscope, we propose a novel rotation constraint using an affine map to minimize the visual warping problem, and a null-space controller is also embedded into the framework to optimize all types of errors in a unified and decoupled manner. Experiments are conducted using Universal Robot (UR) and Karl Storz Laparoscope/Instruments, which prove the feasibility of our domain knowledge and learning enabled framework for automated camera control.",
        "primary_area": "",
        "author": "Bin Li;Bo Lu;Yiang Lu;Qi Dou;Yun-Hui Liu;Bin Li;Bo Lu;Yiang Lu;Qi Dou;Yun-Hui Liu",
        "authorids": "/37089266122;/37085991083;/37086614250;/37085465414;/37279412600;/37089266122;/37085991083;/37086614250;/37085465414;/37279412600",
        "aff": "The Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong; The Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong; The Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong; Department of Computer Science and Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong; The Department of Mechanical and Automation Engineering, T Stone Robotics Institute, The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562083/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6913569655982640025&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561261",
        "title": "Data-driven sea state estimation for vessels using multi-domain features from motion responses",
        "track": "main",
        "status": "Poster",
        "abstract": "Situation awareness is of great importance for autonomous ships. One key aspect is to estimate the sea state in a real-time manner. Considering the ship as a large wave buoy, the sea state can be estimated from motion responses without extra sensors installed. However, it is difficult to associate waves with ship motion through an explicit model since the hydrodynamic effect is hard to model. In this paper, a data-driven model is developed to estimate the sea state based on ship motion data. The ship motion response is analyzed through statistical, temporal, spectral, and wavelet analysis. Features from multi-domain are constructed and an ensemble machine learning model is established. Real-world data is collected from a research vessel operating on the west coast of Norway. Through the validation with the real-world data, the model shows promising performance in terms of significant wave height and peak period.",
        "primary_area": "",
        "author": "Peihua Han;Guoyuan Li;Stian Skjong;Baiheng Wu;Houxiang Zhang;Peihua Han;Guoyuan Li;Stian Skjong;Baiheng Wu;Houxiang Zhang",
        "authorids": "/37088506262;/37085769271;/37086025356;/37088549414;/37085775728;/37088506262;/37085769271;/37086025356;/37088549414;/37085775728",
        "aff": "Department of Ocean Operations and Civil Engineering, Norweigian University of Science and Technology, Aalesund, Norway; Department of Ocean Operations and Civil Engineering, Norweigian University of Science and Technology, Aalesund, Norway; SINTEF Ocean, Trondheim, Norway; Department of Ocean Operations and Civil Engineering, Norweigian University of Science and Technology, Aalesund, Norway; Department of Ocean Operations and Civil Engineering, Norweigian University of Science and Technology, Aalesund, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561261/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13337042908982783567&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Norwegian University of Science and Technology;SINTEF Ocean",
        "aff_unique_dep": "Department of Ocean Operations and Civil Engineering;",
        "aff_unique_url": "https://www.ntnu.edu;https://www.sintef.no/projectweb/sintef-ocean/",
        "aff_unique_abbr": "NTNU;",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Aalesund;Trondheim",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Norway"
    },
    {
        "id": "9562019",
        "title": "Decentralized Circle Formation Control for Fish-like Robots in the Real-world via Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, the circle formation control problem is addressed for a group of cooperative underactuated fish-like robots involving unknown nonlinear dynamics and disturbances. Based on the reinforcement learning and cognitive consistency theory, we propose a decentralized controller without the knowledge of the dynamics of the fish-like robots. The proposed controller can be transferred from simulation to reality. It is only trained in our established simulation environment, and the trained controller can be deployed to real robots without any manual tuning. Simulation results confirm that the proposed model-free robust formation control method is scalable with respect to the group size of the robots and outperforms other representative RL algorithms. Several experiments in the real world verify the effectiveness of our RL-based approach for circle formation control.",
        "primary_area": "",
        "author": "Tianhao Zhang;Yueheng Li;Shuai Li;Qiwei Ye;Chen Wang;Guangming Xie;Tianhao Zhang;Yueheng Li;Shuai Li;Qiwei Ye;Chen Wang;Guangming Xie",
        "authorids": "/37088958998;/37088996546;/37087051054;/37089001307;/37578426800;/37270592800;/37088958998;/37088996546;/37087051054;/37089001307;/37578426800;/37270592800",
        "aff": "The State Key Laboratory of Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China; The State Key Laboratory of Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China; The State Key Laboratory of Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China; Microsoft Research Asia, Beijing, China; National Engineering Research Center of Software Engineering, Peking University, Beijing, China; The State Key Laboratory of Turbulence and Complex Systems, Intelligent Biomimetic Design Lab, College of Engineering, Peking University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562019/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10672929088800738671&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Peking University;Microsoft",
        "aff_unique_dep": "College of Engineering;Research",
        "aff_unique_url": "http://www.pku.edu.cn;https://www.microsoft.com/en-us/research/group/asia",
        "aff_unique_abbr": "PKU;MSRA",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561066",
        "title": "Decentralized Connectivity Maintenance with Time Delays using Control Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Connectivity maintenance is crucial for the real world deployment of multi-robot systems, as it ultimately allows the robots to communicate, coordinate and perform tasks in a collaborative way. A connectivity maintenance controller must keep the multi-robot system connected independently from the system\u2019s mission and in the presence of undesired real world effects such as communication delays, model errors, and computational time delays, among others. In this paper we present the implementation, on a real robotic setup, of a connectivity maintenance control strategy based on Control Barrier Functions. During experimentation, we found that the presence of communication delays has a significant impact on the performance of the controlled system, with respect to the ideal case. We propose a heuristic to counteract the effects of communication delays, and we verify its efficacy both in simulation and with physical robot experiments.",
        "primary_area": "",
        "author": "Beatrice Capelli;Hassan Fouad;Giovanni Beltrame;Lorenzo Sabattini;Beatrice Capelli;Hassan Fouad;Giovanni Beltrame;Lorenzo Sabattini",
        "authorids": "/37086348616;/37089051363;/37295768000;/37594737400;/37086348616;/37089051363;/37295768000;/37594737400",
        "aff": "Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy; Department of Computer and Software Engineering, \u00c9cole Polytechnique de Montr\u00e9al, Qu\u00e9bec, Canada; Department of Computer and Software Engineering, \u00c9cole Polytechnique de Montr\u00e9al, Qu\u00e9bec, Canada; Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561066/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7201789572537245258&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia;\u00c9cole Polytechnique de Montr\u00e9al",
        "aff_unique_dep": "Department of Sciences and Methods for Engineering (DISMI);Department of Computer and Software Engineering",
        "aff_unique_url": "https://www.unimore.it;https://www.polymtl.ca",
        "aff_unique_abbr": ";Polytechnique Montr\u00e9al",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Montr\u00e9al",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Italy;Canada"
    },
    {
        "id": "9561566",
        "title": "Decentralized Nested Gaussian Processes for Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose two decentralized approximate algorithms for nested Gaussian processes in multi-robot systems. The distributed implementation is achieved with iterative and consensus methods that facilitate local computations at the expense of inter-robot communications. Moreover, we propose a covariance-based nearest neighbor robot selection strategy that enables a subset of agents to perform predictions. In addition, both algorithms are proved to be consistent. Empirical evaluations with real data illustrate the efficiency of the proposed algorithms.",
        "primary_area": "",
        "author": "George P. Kontoudis;Daniel J. Stilwell;George P. Kontoudis;Daniel J. Stilwell",
        "authorids": "/37085624593;/37283170000;/37085624593;/37283170000",
        "aff": "Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561566/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2883818691750287257&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "Bradley Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561595",
        "title": "Decentralized Structural-RNN for Robot Crowd Navigation with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Safe and efficient navigation through human crowds is an essential capability for mobile robots. Previous work on robot crowd navigation assumes that the dynamics of all agents are known and well-defined. In addition, the performance of previous methods deteriorates in partially observable environments and environments with dense crowds. To tackle these problems, we propose decentralized structural-Recurrent Neural Network (DS-RNN), a novel network that reasons about spatial and temporal relationships for robot decision making in crowd navigation. We train our network with model-free deep reinforcement learning without any expert supervision. We demonstrate that our model outperforms previous methods in challenging crowd navigation scenarios. We successfully transfer the policy learned in the simulator to a real-world TurtleBot 2i.",
        "primary_area": "",
        "author": "Shuijing Liu;Peixin Chang;Weihang Liang;Neeloy Chakraborty;Katherine Driggs-Campbell;Shuijing Liu;Peixin Chang;Weihang Liang;Neeloy Chakraborty;Katherine Driggs-Campbell",
        "authorids": "/37088687174;/37088688639;/37089001263;/37088996927;/37085509519;/37088687174;/37088688639;/37089001263;/37088996927;/37085509519",
        "aff": "Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign; Department of Electrical and Computer Engineering, University of Illinois, Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561595/",
        "gs_citation": 140,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8635948421764642804&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Illinois, Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560907",
        "title": "Decision Making for Autonomous Driving via Augmented Adversarial Inverse Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Making decisions in complex driving environments is a challenging task for autonomous agents. Imitation learning methods have great potentials for achieving such a goal. Adversarial Inverse Reinforcement Learning (AIRL) is one of the state-of-art imitation learning methods that can learn both a behavioral policy and a reward function simultaneously, yet it is only demonstrated in simple and static environments where no interactions are introduced. In this paper, we improve and stabilize AIRL\u2019s performance by augmenting it with semantic rewards in the learning framework. Additionally, we adapt the augmented AIRL to a more practical and challenging decision-making task in a highly interactive environment in autonomous driving. The proposed method is compared with four baselines and evaluated by four performance metrics. Simulation results show that the augmented AIRL outperforms all the baseline methods, and its performance is comparable with that of the experts on all of the four metrics.",
        "primary_area": "",
        "author": "Pin Wang;Dapeng Liu;Jiayu Chen;Hanhan Li;Ching-Yao Chan;Pin Wang;Dapeng Liu;Jiayu Chen;Hanhan Li;Ching-Yao Chan",
        "authorids": "/37086349924;/37087103304;/37086562831;/37086964505;/37280785000;/37086349924;/37087103304;/37086562831;/37086964505;/37280785000",
        "aff": "University of California, Berkeley; Zenseact, Chalmers University of Technology; Peking University; Google Research; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560907/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10405349678824177168&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "University of California, Berkeley;Chalmers University of Technology;Peking University;Google",
        "aff_unique_dep": ";;;Google Research",
        "aff_unique_url": "https://www.berkeley.edu;https://www.chalmers.se;http://www.pku.edu.cn;https://research.google",
        "aff_unique_abbr": "UC Berkeley;Chalmers;Peking U;Google Research",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Berkeley;;Mountain View",
        "aff_country_unique_index": "0;1;2;0;0",
        "aff_country_unique": "United States;Sweden;China"
    },
    {
        "id": "9560782",
        "title": "Decision Making in Joint Push-Grasp Action Space for Large-Scale Object Sorting",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a planner for large-scale (un)labeled object sorting tasks, which uses two types of manipulation actions: overhead grasping and planar pushing. The grasping action offers completeness guarantee under mild assumptions, and the planar pushing is an acceleration strategy that moves multiple objects at once. We make two main contributions: (1) We propose a bilevel planning algorithm. Our high-level planner makes efficient, near-optimal choices between pushing and grasping actions based on a cost model. Our low-level planner computes one-step greedy pushing or grasping actions. (2) We propose a novel low-level push planner that can find one-step greedy pushing actions in a semi-discrete search space. The structure of the search space allows us to efficiently make decisions. We show that, for sorting up to 200 objects, our planner can find near-optimal actions within 10 seconds of computation on a desktop PC.",
        "primary_area": "",
        "author": "Zherong Pan;Kris Hauser;Zherong Pan;Kris Hauser",
        "authorids": "/37086067204;/37543748800;/37086067204;/37543748800",
        "aff": "Department of Computer Science, University of Illinois, Urbana-Champaign; Department of Computer Science, University of Illinois, Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560782/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7716608072904157025&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois, Urbana-Champaign",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561416",
        "title": "Deep 6-DoF Tracking of Unknown Objects for Reactive Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic manipulation of unknown objects is an important field of research. Practical applications occur in many real-world settings where robots need to interact with an unknown environment. We tackle the problem of reactive grasping by proposing a method for unknown object tracking, grasp point sampling and dynamic trajectory planning. Our object tracking method combines Siamese Networks with an Iterative Closest Point approach for pointcloud registration into a method for 6-DoF unknown object tracking. The method does not require further training and is robust to noise and occlusion. We propose a robotic manipulation system, which is able to grasp a wide variety of formerly unseen objects and is robust against object perturbations and inferior grasping points.",
        "primary_area": "",
        "author": "Marc Tuscher;Julian H\u00f6rz;Danny Driess;Marc Toussaint;Marc Tuscher;Julian H\u00f6rz;Danny Driess;Marc Toussaint",
        "authorids": "/37088233804;/37088996954;/37085994159;/37528418600;/37088233804;/37088996954;/37085994159;/37528418600",
        "aff": "Machine Learning and Robotics Lab, University of Stuttgart; Machine Learning and Robotics Lab, University of Stuttgart; Max-Planck Institute for Intelligent Systems, Stuttgart; Learning and Intelligent Systems, TU Berlin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561416/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11580575064923084366&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "University of Stuttgart;Max-Planck Institute for Intelligent Systems;Technische Universit\u00e4t Berlin",
        "aff_unique_dep": "Machine Learning and Robotics Lab;;Learning and Intelligent Systems",
        "aff_unique_url": "https://www.uni-stuttgart.de;https://www.mpi-is.mpg.de;https://www.tu-berlin.de",
        "aff_unique_abbr": ";MPI-IS;TU Berlin",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Stuttgart;Berlin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9560841",
        "title": "Deep Affordance Foresight: Planning Through What Can Be Done in the Future",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning in realistic environments requires searching in large planning spaces. Affordances are a powerful concept to simplify this search, because they model what actions can be successful in a given situation. However, the classical notion of affordance is not suitable for long horizon planning because it only informs the robot about the immediate outcome of actions instead of what actions are best for achieving a long-term goal. In this paper, we introduce a new affordance representation that enables the robot to reason about the longterm effects of actions through modeling what actions are afforded in the future. Based on the new representation, we develop a learning-to-plan method, Deep Affordance Foresight (DAF), that learns partial environment models of affordances of parameterized motor skills through trial-and-error. We evaluate DAF on two challenging manipulation domains and show that it can effectively learn to carry out multi-step tasks, share learned affordance representations among different tasks, and learn to plan with high-dimensional image inputs.",
        "primary_area": "",
        "author": "Danfei Xu;Ajay Mandlekar;Roberto Mart\u00edn-Mart\u00edn;Yuke Zhu;Silvio Savarese;Li Fei-Fei;Danfei Xu;Ajay Mandlekar;Roberto Mart\u00edn-Mart\u00edn;Yuke Zhu;Silvio Savarese;Li Fei-Fei",
        "authorids": "/37086228189;/37086331393;/37085788640;/37086080772;/37298502600;/38273560700;/37086228189;/37086331393;/37085788640;/37086080772;/37298502600;/38273560700",
        "aff": "Stanford Vision and Learning Lab; Stanford Vision and Learning Lab; Stanford Vision and Learning Lab; The University of Texas, Austin; Stanford Vision and Learning Lab; Stanford Vision and Learning Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560841/",
        "gs_citation": 94,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7050616374739011539&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Stanford University;University of Texas at Austin",
        "aff_unique_dep": "Vision and Learning Lab;",
        "aff_unique_url": "https://vision.stanford.edu;https://www.utexas.edu",
        "aff_unique_abbr": "Stanford V&L;UT Austin",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Stanford;Austin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561155",
        "title": "Deep Balanced Learning for Long-tailed Facial Expressions Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "The analysis of facial expression is a very complex and challenging problem. Most researches for automated Facial Expression Recognition (FER) are mainly based on deep learning networks, rarely considering data imbalance. This paper commits to addressing the long-tail distribution problems among large-scale datasets in wild. Inspired by the continual learning method, we reconstruct multi-subsets first by randomly selecting from head classes and up-sampling tail classes. A pre-trained backbone is then introduced to learn general weights in a repeatedly train-prune fashion. Hereafter, our approach creatively trains a new classifier based on union parameters previously preserved and achieves an outperformance without extra parameters added in, using the gradual-prune technique. The results show that the independent training of classifiers has been a contributing factor. We successfully conduct this experiment with several classic networks, prove its effectiveness in training a deep network on imbalanced dataset. In the face of the poor performance in current FER, we find that domain knowledge is somehow affecting the accuracy of recognition by further exploring the obstacles from the image itself.Code available at https://github.com/Epicghx/FER",
        "primary_area": "",
        "author": "Hongxiang Gao;Shan An;Jianqing Li;Chengyu Liu;Hongxiang Gao;Shan An;Jianqing Li;Chengyu Liu",
        "authorids": "/37088645179;/37089656523;/37279858500;/37578863900;/37088645179;/37089656523;/37279858500;/37578863900",
        "aff": "Tech & Data Center, JD.COM Inc., Beijing, China; Tech & Data Center, JD.COM Inc., Beijing, China; School of Biomedical Engineering and Informatics, Nanjing Medical University, Nanjing, China; State Key Laboratory of Bioelectronics, School of Instrument Science and Engineering, Southeast University, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561155/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=797716987305920060&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "JD.com Inc.;Nanjing Medical University;Southeast University",
        "aff_unique_dep": "Tech & Data Center;School of Biomedical Engineering and Informatics;School of Instrument Science and Engineering",
        "aff_unique_url": "https://www.jd.com;http://www.njmu.edu.cn;https://www.seu.edu.cn/",
        "aff_unique_abbr": "JD;NJMU;SEU",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Beijing;Nanjing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561307",
        "title": "Deep Hierarchical Rotation Invariance Learning with Exact Geometry Feature Representation for Point Cloud Classification",
        "track": "main",
        "status": "Poster",
        "abstract": "Rotation invariance is a crucial property for 3D object classification, which is still a challenging task. State-of-the-art deep learning-based works require a massive amount of data augmentation to tackle this problem. This is however inefficient and classification accuracy suffers a sharp drop in experiments with arbitrary rotations. We introduce a new descriptor that can globally and locally capture the surface geometry properties and is based on a combination of spherical harmonics energy and point feature representation. The proposed descriptor is proven to fulfill the rotation-invariant property. A limited bandwidth spherical harmonics energy descriptor globally describes a 3D shape and its rotation-invariant property is proven by utilizing the properties of a Wigner D-matrix, while the point feature representation captures the local features with a KNN to build the connection to its neighborhood. We propose a new network structure by extending PointNet++ with several adaptations that can hierarchically and efficiently exploit local rotation-invariant features. Extensive experimental results show that our proposed method dramatically outperforms most state-of-the-art approaches on standard rotation-augmented 3D object classification benchmarks as well as in robustness experiments on point perturbation, point density, and partial point clouds.",
        "primary_area": "",
        "author": "Jianjie Lin;Markus Rickert;Alois Knoll;Jianjie Lin;Markus Rickert;Alois Knoll",
        "authorids": "/37088691130;/37681876600;/37276234100;/37088691130;/37681876600;/37276234100",
        "aff": "Department of Informatics, Robotics, Artificial Intelligence and Real-Time Systems, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Department of Informatics, Robotics, Artificial Intelligence and Real-Time Systems, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany; Department of Informatics, Robotics, Artificial Intelligence and Real-Time Systems, Technische Universit\u00e4t M\u00fcnchen, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561307/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13992802148579750776&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen",
        "aff_unique_dep": "Department of Informatics, Robotics, Artificial Intelligence and Real-Time Systems",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561220",
        "title": "Deep Imitation Learning for Autonomous Navigation in Dynamic Pedestrian Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigation through dynamic pedestrian environments in a socially compliant manner is still a challenging task for autonomous vehicles. Classical methods usually lead to unnatural vehicle behaviours for pedestrian navigation due to the difficulty in modeling social conventions mathematically. This paper presents an end-to-end path planning system that achieves autonomous navigation in dynamic environments through imitation learning. The proposed system is based on a fully convolutional neural network that maps the raw sensory data into a confidence map for path extraction. Additionally, a classification network is introduced to reduce the unnecessary re-plannings and ensures that the vehicle goes back to the global path when re-planning is not needed. The imitation learning based path planner is implemented on an autonomous wheelchair and tested in a new real-world dynamic pedestrian environment. Experimental results show that the proposed system is able to generate paths for different driving tasks, such as pedestrian following, static and dynamic obstacles avoidance, etc. In comparison to the state-of-the-art method, our system is superior in terms of generating human-like trajectories.",
        "primary_area": "",
        "author": "Lei Qin;Zefan Huang;Chen Zhang;Hongliang Guo;Marcelo Ang;Daniela Rus;Lei Qin;Zefan Huang;Chen Zhang;Hongliang Guo;Marcelo Ang;Daniela Rus",
        "authorids": "/37088997571;/37087323099;/37089403978;/37085490043;/37279138700;/37279652300;/37088997571;/37087323099;/37089403978;/37085490043;/37279138700;/37279652300",
        "aff": "Singapore-MIT Alliance for Research and Technology, Singapore; Singapore-MIT Alliance for Research and Technology, Singapore; National University of Singapore, Singapore; Singapore-MIT Alliance for Research and Technology, Singapore; National University of Singapore, Singapore; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561220/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9528708257172762164&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;1;2",
        "aff_unique_norm": "Singapore-MIT Alliance for Research and Technology;National University of Singapore;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": ";https://www.nus.edu.sg;https://www.mit.edu",
        "aff_unique_abbr": "SMART;NUS;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "9560887",
        "title": "Deep Learning and Mixed Reality to Autocomplete Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "Teleoperation of robots can be challenging, especially for novice users with little to no experience at such tasks. The difficulty is largely due to the numerous degrees of freedom users must control and their limited perception bandwidth. To help mitigate these challenges, we propose in this paper a solution which relies on artificial intelligence to understand user intended motion and then on mixed reality to communicate the estimated trajectories to the users in an intuitive manner. User intended motion is estimated using a deep learning network trained on a dataset of motion primitives. During teleoperation, the estimated motions are augmented onto a first-person live video feed from the robot. Finally, if a suggested motion is accepted by the user, the robot is driven along that trajectory in an autonomous manner. We validate our proposed mixed reality teleoperation scheme with simulation experiments on a drone and demonstrate, through subjective and objective evaluation, its advantages over other teleoperation methods.",
        "primary_area": "",
        "author": "Mohammad Kassem Zein;Majd Al Aawar;Daniel Asmar;Imad H. Elhajj;Mohammad Kassem Zein;Majd Al Aawar;Daniel Asmar;Imad H. Elhajj",
        "authorids": "/37086934778;/37088997011;/37424435700;/37281934400;/37086934778;/37088997011;/37424435700;/37281934400",
        "aff": "Vision and Robotics Lab, American University of Beirut, Beirut, Lebanon; Vision and Robotics Lab, American University of Beirut, Beirut, Lebanon; Vision and Robotics Lab, American University of Beirut, Beirut, Lebanon; Vision and Robotics Lab, American University of Beirut, Beirut, Lebanon",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560887/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7620032678269330474&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "American University of Beirut",
        "aff_unique_dep": "Vision and Robotics Lab",
        "aff_unique_url": "https://www.aub.edu.lb",
        "aff_unique_abbr": "AUB",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beirut",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Lebanon"
    },
    {
        "id": "9561106",
        "title": "Deep Learning on 3D Object Detection for Automatic Plug-in Charging Using a Mobile Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Increasing research attention has been attracted to automatic plug-in charging in an unmanned and dangerous environment. In this work, we develop an object detection solution based on deep learning on 3D point clouds using a mobile robot manipulator to provide mobility and manipulation. In this solution, the 3D point cloud technology is adopted to measure the shapes and depth information for plugin charging. Then the deep learning is employed to deal with the uncertainty in 3D detection, such as inconsistent light conditions, irregular distribution, and structural ambiguity of point clouds. We utilize a mobile robot manipulator carrying a 3D camera and a gripper to detect the targeted objects and automate plug-in charging operations. The proposed 3D object detection principle and procedure for the automatic plug-in charging are presented in detail. The automatic plug-in charging testing is conducted to validate the developed 3D object detection algorithm using a mobile robot manipulator.",
        "primary_area": "",
        "author": "Zhengxue Zhou;Leihui Li;Riwei Wang;Xuping Zhang;Zhengxue Zhou;Leihui Li;Riwei Wang;Xuping Zhang",
        "authorids": "/37088572103;/37088575412;/37086957691;/37085664403;/37088572103;/37088575412;/37086957691;/37085664403",
        "aff": "Department of Mechanical and Production Engineering, Aarhus University; School of Computer Science and Engineering, Tianjin University of Technology; Wenzhou University Oujiang College; Department of Mechanical and Production Engineering, Aarhus University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561106/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14602207143105136589&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Aarhus University;Tianjin University of Technology;Wenzhou University",
        "aff_unique_dep": "Department of Mechanical and Production Engineering;School of Computer Science and Engineering;College",
        "aff_unique_url": "https://www.au.dk;http://www.tjut.edu.cn;http://www.wzu.edu.cn",
        "aff_unique_abbr": "AU;;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Oujiang",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Denmark;China"
    },
    {
        "id": "9561369",
        "title": "Deep Learning-Based Photoacoustic Visual Servoing: Using Outputs from Raw Sensor Data as Inputs to a Robot Controller",
        "track": "main",
        "status": "Poster",
        "abstract": "Tool tip visualization is an essential component of multiple robotic surgical and interventional procedures. In this paper, we introduce a real-time photoacoustic visual servoing system that processes information directly from raw acoustic sensor data, without requiring image formation or segmentation in order to make robot path planning decisions to track and maintain visualization of tool tips. The performance of this novel deep learning-based visual servoing system is compared to that of a visual servoing system which relies on image formation followed by segmentation to make and execute robot path planning decisions. Experiments were conducted with a plastisol phantom, ex vivo tissue, and a needle as the interventional tool. Needle tip tracking performance with the deep learning-based approach outperformed that of the image-based segmentation approach by 67.7% and 55.3% in phantom and ex vivo tissue, respectively. In addition, the deep learning-based system operated within the frame-rate-limiting 10 Hz laser pulse repetition frequency rate, with mean execution times of 75.2 ms and 73.9 ms per acquisition frame with phantom and ex vivo tissue, respectively. These results highlight the benefits of our new approach to integrate deep learning with robotic systems for improved automation and visual servoing of tool tips.",
        "primary_area": "",
        "author": "Mardava R. Gubbi;Muyinatu A. Lediju Bell;Mardava R. Gubbi;Muyinatu A. Lediju Bell",
        "authorids": "/37086558746;/37085388441;/37086558746;/37085388441",
        "aff": "Department of Electrical and Computer Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Electrical and Computer Engineering, the Department of Biomedical Engineering, and the Department of Computer Science, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561369/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5941641201290057734&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560873",
        "title": "Deep Multi-view Depth Estimation with Predicted Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the problem of estimating dense depth from a sequence of images using deep neural networks. Specifically, we employ a dense-optical-flow network to compute correspondences and then triangulate the point cloud to obtain an initial depth map. Parts of the point cloud, however, may be less accurate than others due to lack of common observations or small parallax. To further increase the triangulation accuracy, we introduce a depth-refinement network (DRN) that optimizes the initial depth map based on the image\u2019s contextual cues. In particular, the DRN contains an iterative refinement module (IRM) that improves the depth accuracy over iterations by refining the deep features. Lastly, the DRN also predicts the uncertainty in the refined depths, which is desirable in applications such as measurement selection for scene reconstruction. We show experimentally that our algorithm outperforms state-of-the-art approaches in terms of depth accuracy, and verify that our predicted uncertainty is highly correlated to the actual depth error.",
        "primary_area": "",
        "author": "Tong Ke;Tien Do;Khiem Vuong;Kourosh Sartipi;Stergios I. Roumeliotis;Tong Ke;Tien Do;Khiem Vuong;Kourosh Sartipi;Stergios I. Roumeliotis",
        "authorids": "/37087323518;/37088690498;/37088686343;/37085803736;/37274078800;/37087323518;/37088690498;/37088686343;/37085803736;/37274078800",
        "aff": "Tong Ke; Tien Do; Khiem Vuong; Kourosh Sartipi; University of Minnesota, Minneapolis, MN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560873/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3127978151517603903&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;2",
        "aff_unique_norm": "Tong Ke;;University of Minnesota",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";;https://www.minnesota.edu",
        "aff_unique_abbr": ";;UMN",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Minneapolis",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "9561729",
        "title": "Deep Neuromorphic Controller with Dynamic Topology for Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Current aerial robots are increasingly adaptive; they can morph to enable operation in changing conditions to complete diverse missions. Each mission may require the robot to conduct a different task. A conventional learning approach can handle these variations when the system is trained for similar tasks in a representative environment. However, it may result in overfitting to the new data stream or the failure to adapt, leading to degradation or a potential crash. These problems can be mitigated with an excessive amount of data and embedded model, but the computational power and the memory of the aerial robots are limited. In order to address the variations in the model, environment as well as the tasks within onboard computation limitations, we propose a deep neuromorphic controller approach with variable topologies to handle each different condition and the data stream with a feasible computation and memory allocation. The proposed approach is based on a deep neuromorphic (multi and variable layered neural network) controller with dynamic depth and progressive layer adaptation for each new data stream. This adaptive structure is combined with a switching function to form a sliding mode controller. The network parameter update rule guarantees the stability of the closed loop system by the convergence of the error dynamics to the sliding surface. Being the first implementation on an aerial robot in this context, the results illustrate the adaptation capability, stability, computational efficiency as well as the real-time validation.",
        "primary_area": "",
        "author": "Basaran Bahadir Kocer;Mohamad Abdul Hady;Harikumar Kandath;Mahardhika Pratama;Mirko Kovac;Basaran Bahadir Kocer;Mohamad Abdul Hady;Harikumar Kandath;Mahardhika Pratama;Mirko Kovac",
        "authorids": "/37072753900;/37087043390;/37086562310;/38233985400;/37085542534;/37072753900;/37087043390;/37086562310;/38233985400;/37085542534",
        "aff": "Aerial Robotics Laboratory, Imperial College London, London, UK; Electrical Engineering Department, Sepuluh Nopember Institute of Technology, Surabaya, Indonesia; Robotics Research Center, International Institute of Information Technology, Hyderabad, India; School of Computer Science and Engineering, Nanyang Technological University, Singapore; Materials and Technology Center of Robotics, Swiss Federal Laboratories for Materials Science and Technology, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561729/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17488407367566227926&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;4",
        "aff_unique_norm": "Imperial College London;Sepuluh Nopember Institute of Technology;International Institute of Information Technology;Nanyang Technological University;Swiss Federal Laboratories for Materials Science and Technology",
        "aff_unique_dep": "Aerial Robotics Laboratory;Electrical Engineering Department;Robotics Research Center;School of Computer Science and Engineering;Materials and Technology Center of Robotics",
        "aff_unique_url": "https://www.imperial.ac.uk;;https://iiit Hyderabad.ac.in;https://www.ntu.edu.sg;https://www.empa.ch",
        "aff_unique_abbr": "ICL;;IIIT Hyderabad;NTU;EMPA",
        "aff_campus_unique_index": "0;1;2;3",
        "aff_campus_unique": "London;Surabaya;Hyderabad;Singapore;",
        "aff_country_unique_index": "0;1;2;3;4",
        "aff_country_unique": "United Kingdom;Indonesia;India;Singapore;Switzerland"
    },
    {
        "id": "9561642",
        "title": "Deep Online Correction for Monocular Visual Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a novel deep online correction (DOC) framework for monocular visual odometry. The whole pipeline has two stages: First, depth maps and initial poses are obtained from convolutional neural networks (CNNs) trained in self-supervised manners. Second, the poses predicted by CNNs are further improved by minimizing photometric errors via gradient updates of poses during inference phases. The benefits of our proposed method are twofold: 1) Different from online-learning methods, DOC does not need to calculate gradient propagation for parameters of CNNs. Thus, it saves more computation resources during inference phases. 2) Unlike hybrid methods that combine CNNs with traditional methods, DOC fully relies on deep learning (DL) frameworks. Though without complex back-end optimization modules, our method achieves outstanding performance with relative transform error (RTE) = 2.0% on KITTI Odometry benchmark for Seq. 09, which outperforms traditional monocular VO frameworks and is comparable to hybrid methods.",
        "primary_area": "",
        "author": "Jiaxin Zhang;Wei Sui;Xinggang Wang;Wenming Meng;Hongmei Zhu;Qian Zhang;Jiaxin Zhang;Wei Sui;Xinggang Wang;Wenming Meng;Hongmei Zhu;Qian Zhang",
        "authorids": "/37089263075;/37085497549;/37407488400;/37088997060;/37089001572;/37087230852;/37089263075;/37085497549;/37407488400;/37088997060;/37089001572;/37087230852",
        "aff": "Horizon Robotics; Horizon Robotics; School of EIC, Huazhong University of Science and Technology; Horizon Robotics; Horizon Robotics; Horizon Robotics",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561642/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2200616729646155051&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Horizon Robotics;Huazhong University of Science and Technology",
        "aff_unique_dep": ";School of EIC",
        "aff_unique_url": "https://www.horizon-robotics.com/;http://www.hust.edu.cn",
        "aff_unique_abbr": "Horizon Robotics;HUST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561145",
        "title": "Deep Reinforcement Learning Framework for Underwater Locomotion of Soft Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robotics is an emerging technology with excellent application prospects. However, due to the inherent compliance of the materials used to build soft robots, it is extremely complicated to control soft robots accurately. In this paper, we introduce a data-based control framework for solving the soft robot underwater locomotion problem using deep reinforcement learning (DRL). We first built a soft robot that can swim based on the dielectric elastomer actuator (DEA). We then modeled it in a simulation for the purpose of training the neural network and tested the performance of the control framework through real experiments on the robot. The framework includes the following: a simulation method for the soft robot that can be used to collect data for training the neural network, the neural network controller of the swimming robot trained in the simulation environment, and the computer vision method to collect the observation space from the real robot using a camera. We confirmed the effectiveness of the learning method for the soft swimming robot in the simulation environment by allowing the robot to learn how to move from a random initial state to a specific direction. After obtaining the trained neural network through the simulation, we deployed it on the real robot and tested the performance of the control framework. The soft robot successfully achieved the goal of moving in a straight line in disturbed water. The experimental results suggest the potential of using deep reinforcement learning to improve the locomotion ability of mobile soft robots.",
        "primary_area": "",
        "author": "Guanda Li;Jun Shintake;Mitsuhiro Hayashibe;Guanda Li;Jun Shintake;Mitsuhiro Hayashibe",
        "authorids": "/37088997568;/37590896900;/37586645600;/37088997568;/37590896900;/37586645600",
        "aff": "Department of Robotics, Graduate School of Engineering, Neuro-Robotics Lab, Tohoku University, Sendai, Japan; Department of Mechanical and Intelligent Systems Engineering, University of Electro-Communications, Tokyo, Japan; Department of Robotics, Graduate School of Engineering, Neuro-Robotics Lab, Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561145/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12431045939359274908&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Tohoku University;University of Electro-Communications",
        "aff_unique_dep": "Department of Robotics;Department of Mechanical and Intelligent Systems Engineering",
        "aff_unique_url": "https://www.tohoku.ac.jp;https://www.uec.ac.jp",
        "aff_unique_abbr": "Tohoku U;UEC",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Sendai;Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561258",
        "title": "Deep Reinforcement Learning for Active Target Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "We solve active target tracking, one of the essential tasks in autonomous systems, using a deep reinforcement learning (RL) approach. In this problem, an autonomous agent is tasked with acquiring information about targets of interests using its on-board sensors. The classical challenges in this problem are system model dependence and the difficulty of computing information-theoretic cost functions for a long planning horizon. RL provides solutions for these challenges as the length of its effective planning horizon does not affect the computational complexity, and it drops the strong dependency of an algorithm on system models. In particular, we introduce Active Tracking Target Network (ATTN), a unified deep RL policy that is capable of solving major sub-tasks of active target tracking \u2013 in-sight tracking, navigation, and exploration. The policy shows robust behavior for tracking agile and anomalous targets with a partially known target model. Additionally, the same policy is able to navigate in obstacle environments to reach distant targets as well as explore the environment when targets are positioned in unexpected locations.",
        "primary_area": "",
        "author": "Heejin Jeong;Hamed Hassani;Manfred Morari;Daniel D. Lee;George J. Pappas;Heejin Jeong;Hamed Hassani;Manfred Morari;Daniel D. Lee;George J. Pappas",
        "authorids": "/37087322449;/37086178545;/37282929500;/37280609600;/37281547100;/37087322449;/37086178545;/37282929500;/37280609600;/37281547100",
        "aff": "Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA; Department of Electrical and Computer Engineering, Cornell University, Ithaca, NY, USA; Electrical and Systems Engineering, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561258/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16569652992012734627&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Pennsylvania;Cornell University",
        "aff_unique_dep": "Electrical and Systems Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.upenn.edu;https://www.cornell.edu",
        "aff_unique_abbr": "UPenn;Cornell",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Philadelphia;Ithaca",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561620",
        "title": "Deep Reinforcement Learning for Concentric Tube Robot Control with a Goal-Based Curriculum",
        "track": "main",
        "status": "Poster",
        "abstract": "Concentric Tube Robots (CTRs), a type of continuum robot, are a collection of concentric, pre-curved tubes composed of super elastic nickel titanium alloy. CTRs can bend and twist from the interactions between neighboring tubes causing the kinematics and therefore control of the end-effector to be very challenging to model. In this paper, we develop a control scheme for a CTR end-effector in Cartesian space with no prior kinematic model using a deep reinforcement learning (DRL) approach with a goal-based curriculum reward strategy. We explore the use of curricula by changing the goal tolerance through training with constant, linear and exponential decay functions. Also, relative and absolute joint representations as a way of improving training convergence are explored. Quantitative comparisons for combinations of curricula and joint representations are performed and the exponential decay relative approach is used for training a robust policy in a noise-induced simulation environment. Compared to a previous DRL approach, our new method reduces training time and employs a more complex simulation environment. We report mean Cartesian errors of 1.29 mm and a success rate of 0.93 with a relative decay curriculum. In path following, we report mean errors of 1.37 mm in a noise-induced path following task. Albeit in simulation, these results indicate the promise of using DRL in model free control of continuum robots and CTRs in particular.",
        "primary_area": "",
        "author": "Keshav Iyengar;Danail Stoyanov;Keshav Iyengar;Danail Stoyanov",
        "authorids": "/37088997858;/37563622300;/37088997858;/37563622300",
        "aff": "Wellcome/ EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, London, UK; Wellcome/ EPSRC Centre for Interventional and Surgical Sciences (WEISS), University College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561620/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16903513084674258891&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University College London",
        "aff_unique_dep": "Wellcome/ EPSRC Centre for Interventional and Surgical Sciences (WEISS)",
        "aff_unique_url": "https://www.ucl.ac.uk",
        "aff_unique_abbr": "UCL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561188",
        "title": "Deep Reinforcement Learning for Mapless Navigation of a Hybrid Aerial Underwater Vehicle with Medium Transition",
        "track": "main",
        "status": "Poster",
        "abstract": "Since the application of Deep Q-Learning to the continuous action domain in Atari-like games, Deep Reinforcement Learning (Deep-RL) techniques for motion control have been qualitatively enhanced. Nowadays, modern Deep-RL can be successfully applied to solve a wide range of complex decision-making tasks for many types of vehicles. Based on this context, in this paper, we propose the use of Deep-RL to perform autonomous mapless navigation for Hybrid Unmanned Aerial Underwater Vehicles (HUAUVs), robots that can operate in both, air or water media. We developed two approaches, one deterministic and the other stochastic. Our system uses the relative localization of the vehicle and simple sparse range data to train the network. We compared our approaches with an adapted version of the BUG2 algorithm for mapless navigation of aerial vehicles. Based on experimental results, we can conclude that Deep-RL-based approaches can be successfully used to perform mapless navigation and obstacle avoidance for HUAUVs. Our vehicle accomplished the navigation in two scenarios, being capable to achieve the desired target through both environments, and even outperforming the behavior-based algorithm on the obstacle-avoidance capability.",
        "primary_area": "",
        "author": "Ricardo B. Grando;Junior C. de Jesus;Victor A. Kich;Alisson H. Kolling;Nicolas P. Bortoluzzi;Pedro M. Pinheiro;Armando A. Neto;Paulo L. J. Drews;Ricardo B. Grando;Junior C. de Jesus;Victor A. Kich;Alisson H. Kolling;Nicolas P. Bortoluzzi;Pedro M. Pinheiro;Armando A. Neto;Paulo L. J. Drews",
        "authorids": "/37088755051;/37088754453;/37088996004;/37089001470;/37088755739;/37087466419;/37576889700;/38520902100;/37088755051;/37088754453;/37088996004;/37089001470;/37088755739;/37087466419;/37576889700;/38520902100",
        "aff": "NAUTEC, Centro de Ciencias Computacionais, Univ. Fed. do Rio Grande - FURG, RS, Brazil; NAUTEC, Centro de Ciencias Computacionais, Univ. Fed. do Rio Grande - FURG, RS, Brazil; Universidade Federal de Santa Maria - UFSM, RS, Brazil; Universidade Federal de Santa Maria - UFSM, RS, Brazil; NAUTEC, Centro de Ciencias Computacionais, Univ. Fed. do Rio Grande - FURG, RS, Brazil; NAUTEC, Centro de Ciencias Computacionais, Univ. Fed. do Rio Grande - FURG, RS, Brazil; Electronic Engineering Dep, Univ. Fed. de Minas Gerais, MG, Brazil; NAUTEC, Centro de Ciencias Computacionais, Univ. Fed. do Rio Grande - FURG, RS, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561188/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5452096579898242571&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;1;0;0;2;0",
        "aff_unique_norm": "Universidade Federal do Rio Grande;Universidade Federal de Santa Maria;Universidade Federal de Minas Gerais",
        "aff_unique_dep": "Centro de Ciencias Computacionais;;Department of Electronic Engineering",
        "aff_unique_url": ";https://www.ufsm.br;https://www.ufmg.br",
        "aff_unique_abbr": "FURG;UFSM;UFMG",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Santa Maria",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Brazil"
    },
    {
        "id": "9561123",
        "title": "Deep Structured Reactive Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "An intelligent agent operating in the real-world must balance achieving its goal with maintaining the safety and comfort of not only itself, but also other participants within the surrounding scene. This requires jointly reasoning about the behavior of other actors while deciding its own actions as these two processes are inherently intertwined \u2013 a vehicle will yield to us if we decide to proceed first at the intersection but will proceed first if we decide to yield. However, this is not captured in most self-driving pipelines, where planning follows prediction. In this paper we propose a novel data-driven, reactive planning objective which allows a self-driving vehicle to jointly reason about its own plans as well as how other actors will react to them. We formulate the problem as an energy-based deep structured model that is learned from observational data and encodes both the planning and prediction problems. Through simulations based on both real-world driving and synthetically generated dense traffic, we demonstrate that our reactive model outperforms a non-reactive variant in successfully completing highly complex maneuvers (lane merges/turns in traffic) faster, without trading off collision rate. Please see our supplementary document https://tinyurl.com/3nukpn5b for all additional details.",
        "primary_area": "",
        "author": "Jerry Liu;Wenyuan Zeng;Raquel Urtasun;Ersin Yumer;Jerry Liu;Wenyuan Zeng;Raquel Urtasun;Ersin Yumer",
        "authorids": "/37088998046;/37087234351;/37269502900;/37086161237;/37088998046;/37087234351;/37269502900;/37086161237",
        "aff": "Uber ATG; University of Toronto; University of Toronto; Uber ATG",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561123/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13491087056250670253&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Uber;University of Toronto",
        "aff_unique_dep": "Advanced Technologies Group;",
        "aff_unique_url": "https://www.uber.com;https://www.utoronto.ca",
        "aff_unique_abbr": "Uber ATG;U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9561274",
        "title": "Deep reinforcement learning of event-triggered communication and control for multi-agent cooperative transport",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we explore a multi-agent reinforcement learning approach to address the design problem of communication and control strategies for multi-agent cooperative transport. Typical end-to-end deep neural network policies may be insufficient for covering communication and control; these methods cannot decide the timing of communication and can only work with fixed-rate communications. Therefore, our framework exploits event-triggered architecture, namely, a feedback controller that computes the communication input and a triggering mechanism that determines when the input has to be updated again. Such event-triggered control policies are efficiently optimized using a multi-agent deep deterministic policy gradient. We confirmed that our approach could balance the transport performance and communication savings through numerical simulations.",
        "primary_area": "",
        "author": "Kazuki Shibata;Tomohiko Jimbo;Takamitsu Matsubara;Kazuki Shibata;Tomohiko Jimbo;Takamitsu Matsubara",
        "authorids": "/37086310035;/37569079000;/37533262700;/37086310035;/37569079000;/37533262700",
        "aff": "Graduate School of Science and Technology, Division of Information Science, Nara Institute of Science and Technology, Nara, Japan; Autonomous Distributed Cooperative Control Program, Data Analytics Research-Domain, Toyota Central R&D Labs., Inc., Japan; Graduate School of Science and Technology, Division of Information Science, Nara Institute of Science and Technology, Nara, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561274/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4204268807497224707&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Nara Institute of Science and Technology;Toyota Central R&D Labs., Inc.",
        "aff_unique_dep": "Division of Information Science;Data Analytics Research-Domain",
        "aff_unique_url": "https://www.nist.go.jp;https://www.toyota-global.com/company/profile",
        "aff_unique_abbr": "NIST;Toyota CRDL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nara;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561732",
        "title": "Deep3DRanker: A Novel Framework for Learning to Rank 3D Models with Self-Attention in Robotic Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "Research on generating or processing point clouds has become an increasingly popular domain in robotic research due to its extensive applications, such as robotic grasping, augmented reality and autonomous vehicle navigation. In this paper, we explore a new research area on point clouds - Learning to rank 3D models captured from a single depth image. In the Learning To Rank (LTR) task, we aim at optimizing the order of a list of 3D models according to the given query. Inspired by the recent advances in Natural Language Processing (NLP), we propose a novel framework, namely Deep3DRanker, for ranking 3D models by leveraging graph-based encoding and self-attention mechanisms. Comprehensive experiments are conducted to validate our methods on publicly available YCB synthetic and YCB video datasets. The promising results have shown that our proposed framework is generic enough to be applicable with any combinations of randomly positioned, oriented, and unseen object items with accuracy ranging from 59.2% to 94.9%, which shows great potentials of the proposed framework for robotic applications, in particular, for making decisions under different circumstances.",
        "primary_area": "",
        "author": "Frank Po Wen Lo;Yao Guo;Yingnan Sun;Jianing Qiu;Benny Lo;Frank Po Wen Lo;Yao Guo;Yingnan Sun;Jianing Qiu;Benny Lo",
        "authorids": "/37088999335;/37086919325;/37086007834;/37086922591;/38183567000;/37088999335;/37086919325;/37086007834;/37086922591;/38183567000",
        "aff": "Hamlyn Centre, Imperial College London, London, United Kingdom; Institute of Medical Robotics and School of Biomedical Engineering, Shanghai Jiaotong University, Shanghai, China; Hamlyn Centre, Imperial College London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom; Hamlyn Centre, Imperial College London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561732/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7984617701005399460&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Imperial College London;Shanghai Jiao Tong University",
        "aff_unique_dep": "Hamlyn Centre;Institute of Medical Robotics and School of Biomedical Engineering",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.sjtu.edu.cn",
        "aff_unique_abbr": "Imperial College;SJTU",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "London;Shanghai",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9562093",
        "title": "DeepQ Stepper: A framework for reactive dynamic walking on uneven terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "Reactive stepping and push recovery for biped robots is often restricted to flat terrains because of the difficulty in computing capture regions for nonlinear dynamic models. In this paper, we address this limitation by proposing a novel 3D reactive stepper, the DeepQ stepper, that can approximately learn the 3D capture regions of both simplified and full robot dynamic models using reinforcement learning, which can then be used to find optimal steps. The stepper can take into account the entire dynamics of the robot, ignored in most reactive steppers, leading to a significant improvement in performance. The DeepQ stepper can handle nonconvex terrain with obstacles, walk on restricted surfaces like stepping stones while tracking different velocities, and recover from external disturbances for a constant low computational cost.",
        "primary_area": "",
        "author": "Avadesh Meduri;Majid Khadiv;Ludovic Righetti;Avadesh Meduri;Majid Khadiv;Ludovic Righetti",
        "authorids": "/37088355351;/38667118200;/37295828600;/37088355351;/38667118200;/37295828600",
        "aff": "Tandon School of Engineering, New York University (NYU), USA; Max-Planck Institute for Intelligent Systems, Tuebingen, Germany; Max-Planck Institute for Intelligent Systems, Tuebingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562093/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14397944648695718243&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "New York University;Max-Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Tandon School of Engineering;",
        "aff_unique_url": "https://www.nyu.edu;https://www.mpituebingen.mpg.de",
        "aff_unique_abbr": "NYU;MPI-IS",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "New York;Tuebingen",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "9561949",
        "title": "DeepReach: A Deep Learning Approach to High-Dimensional Reachability",
        "track": "main",
        "status": "Poster",
        "abstract": "Hamilton-Jacobi (HJ) reachability analysis is an important formal verification method for guaranteeing performance and safety properties of dynamical control systems. Its advantages include compatibility with general nonlinear system dynamics, formal treatment of bounded disturbances, and the ability to deal with state and input constraints. However, it involves solving a PDE, whose computational and memory complexity scales exponentially with respect to the number of state variables, limiting its direct use to small-scale systems. We propose DeepReach, a method that leverages new developments in sinusoidal networks to develop a neural PDE solver for high-dimensional reachability problems. The computational requirements of DeepReach do not scale directly with the state dimension, but rather with the complexity of the underlying reachable tube. DeepReach achieves comparable results to the state-of-the-art reachability methods, does not require any explicit supervision for the PDE solution, can easily handle external disturbances, adversarial inputs, and system constraints, and also provides a safety controller for the system. We demonstrate DeepReach on a 9D multi-vehicle collision problem, and a 10D narrow passage problem, motivated by autonomous driving applications.",
        "primary_area": "",
        "author": "Somil Bansal;Claire J. Tomlin;Somil Bansal;Claire J. Tomlin",
        "authorids": "/37085404900;/37271692600;/37085404900;/37271692600",
        "aff": "ECE, University of Southern California; EECS, UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561949/",
        "gs_citation": 183,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17558452345636711178&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Southern California;University of California, Berkeley",
        "aff_unique_dep": "Electrical and Computer Engineering;Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.usc.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "USC;UC Berkeley",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Los Angeles;Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561717",
        "title": "DeepWalk: Omnidirectional Bipedal Gait by Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Bipedal walking is one of the most difficult but exciting challenges in robotics. The difficulties arise from the complexity of high-dimensional dynamics, sensing and actuation limitations combined with real-time and computational constraints. Deep Reinforcement Learning (DRL) holds the promise to address these issues by fully exploiting the robot dynamics with minimal craftsmanship. In this paper, we propose a novel DRL approach that enables an agent to learn omnidirectional locomotion for humanoid (bipedal) robots. Notably, the locomotion behaviors are accomplished by a single control policy (a single neural network). We achieve this by introducing a new curriculum learning method that gradually increases the task difficulty by scheduling target velocities. In addition, our method does not require reference motions which facilities its application to robots with different kinematics, and reduces the overall complexity. Finally, different strategies for sim-to-real transfer are presented which allow us to transfer the learned policy to a real humanoid robot.",
        "primary_area": "",
        "author": "Diego Rodriguez;Sven Behnke;Diego Rodriguez;Sven Behnke",
        "authorids": "/37086373727;/37295987100;/37086373727;/37295987100",
        "aff": "Autonomous Intelligent Systems (AIS) Group, Computer Science Institute VI, University of Bonn, Germany; Autonomous Intelligent Systems (AIS) Group, Computer Science Institute VI, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561717/",
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4576377975840778198&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Computer Science Institute VI",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "Uni Bonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9560955",
        "title": "Deformable Linear Object Prediction Using Locally Linear Latent Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a framework for deformable linear object prediction. Prediction of deformable objects (e.g., rope) is challenging due to their non-linear dynamics and infinite-dimensional configuration spaces. By mapping the dynamics from a non-linear space to a linear space, we can use the good properties of linear dynamics for easier learning and more efficient prediction. We learn a locally linear, action-conditioned dynamics model that can be used to predict future latent states. Then, we decode the predicted latent state into the predicted state. We also apply a sampling-based optimization algorithm to select the optimal control action. We empirically demonstrate that our approach can predict the rope state accurately up to ten steps into the future and that our algorithm can find the optimal action given an initial state and a goal state.",
        "primary_area": "",
        "author": "Wenbo Zhang;Karl Schmeckpeper;Pratik Chaudhari;Kostas Daniilidis;Wenbo Zhang;Karl Schmeckpeper;Pratik Chaudhari;Kostas Daniilidis",
        "authorids": "/37089000641;/37086802970;/38113795600;/37270623200;/37089000641;/37086802970;/38113795600;/37270623200",
        "aff": "GRASP Lab, University of Pennsylvania, USA; GRASP Lab, University of Pennsylvania, USA; GRASP Lab, University of Pennsylvania, USA; GRASP Lab, University of Pennsylvania, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560955/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12348902400277275896&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Lab",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561342",
        "title": "Design Considerations for a Steerable Needle Robot to Maximize Reachable Lung Volume",
        "track": "main",
        "status": "Poster",
        "abstract": "Steerable needles that are able to follow curvilinear trajectories and steer around anatomical obstacles are a promising solution for many interventional procedures. In the lung, these needles can be deployed from the tip of a conventional bronchoscope to reach lung lesions for diagnosis. The reach of such a device depends on several design parameters including the bronchoscope diameter, the angle of the piercing device relative to the medial axis of the airway, and the needle\u2019s minimum radius of curvature while steering. Assessing the effect of these parameters on the overall system\u2019s clinical utility is important in informing future design choices and understanding the capabilities and limitations of the system. In this paper, we analyze the effect of various settings for these three robot parameters on the percentage of the lung that the robot can reach. We combine Monte Carlo random sampling of piercing configurations with a Rapidly-exploring Random Trees based steerable needle motion planner in simulated human lung environments to asymptotically accurately estimate the volume of sites in the lung reachable by the robot. We highlight the importance of each parameter on the overall system\u2019s reachable workspace in an effort to motivate future device innovation and highlight design trade-offs.",
        "primary_area": "",
        "author": "Inbar Fried;Janine Hoelscher;Mengyu Fu;Maxwell Emerson;Tayfun Efe Ertop;Margaret Rox;Josephine Granna;Alan Kuntz;Jason A. Akulian;Robert J. Webster;Ron Alterovitz;Inbar Fried;Janine Hoelscher;Mengyu Fu;Maxwell Emerson;Tayfun Efe Ertop;Margaret Rox;Josephine Granna;Alan Kuntz;Jason A. Akulian;Robert J. Webster;Ron Alterovitz",
        "authorids": "/37088528690;/37085664639;/37086578786;/37088529868;/37085883000;/37088422020;/37085438897;/37085508764;/37088531510;/37325029200;/37320259800;/37088528690;/37085664639;/37086578786;/37088529868;/37085883000;/37088422020;/37085438897;/37085508764;/37088531510;/37325029200;/37320259800",
        "aff": "University of North Carolina School of Medicine, Chapel Hill, NC, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; School of Computing and the Robotics Center, University of Utah, Salt Lake City, UT, USA; Division of Pulmonary Diseases and Critical Care Medicine, University of North Carolina School of Medicine, Chapel Hill, NC, USA; Department of Mechanical Engineering, Vanderbilt University, Nashville, TN, USA; Department of Computer Science, University of North Carolina at Chapel Hill, Chapel Hill, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561342/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7346881361363023233&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;1;1;2;2;2;2;3;4;2;1",
        "aff_unique_norm": "University of North Carolina;University of North Carolina at Chapel Hill;Vanderbilt University;University of Utah;University of North Carolina School of Medicine",
        "aff_unique_dep": "School of Medicine;Department of Computer Science;Department of Mechanical Engineering;School of Computing and the Robotics Center;Division of Pulmonary Diseases and Critical Care Medicine",
        "aff_unique_url": "https://www.med.unc.edu;https://www.unc.edu;https://www.vanderbilt.edu;https://www.utah.edu;https://www.med.unc.edu",
        "aff_unique_abbr": "UNC;UNC Chapel Hill;Vanderbilt;U of U;UNC School of Medicine",
        "aff_campus_unique_index": "0;0;0;1;1;1;1;2;0;1;0",
        "aff_campus_unique": "Chapel Hill;Nashville;Salt Lake City",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561832",
        "title": "Design Paradigms Based on Spring Agonists for Underactuated Robot Hands: Concepts and Application",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we focus on a rarely used paradigm in the design of underactuated robot hands: the use of springs as agonists and tendons as antagonists. We formalize this approach in a design matrix also considering its interplay with the underactuation method used (one tendon for multiple joints vs. multiple tendons on one motor shaft). We then show how different cells in this design matrix can be combined in order to facilitate the implementation of desired postural synergies with a single motor. Furthermore, we show that when agonist and antagonist tendons are combined on the same motor shaft, the resulting spring force cancellation can be leveraged to produce multiple desirable behaviors, which we demonstrate in a physical prototype.",
        "primary_area": "",
        "author": "Tianjian Chen;Tianyi Zhang;Matei Ciocarlie;Tianjian Chen;Tianyi Zhang;Matei Ciocarlie",
        "authorids": "/37085566730;/37088686437;/37297485500;/37085566730;/37088686437;/37297485500",
        "aff": "Department of Mechanical Engineering, Columbia University, New York, NY, USA; Department of Mechanical Engineering, Columbia University, New York, NY, USA; Department of Mechanical Engineering, Columbia University, New York, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561832/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15630611418085738276&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561811",
        "title": "Design and Analysis of a Novel Lightweight, Versatile Soft-rigid Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots are compliant to wrap large objects and adaptive to unstructured environments, while rigid robots can bend discretely at joints and pinch small objects easily. In this paper, we aim to create a novel robot that can behave like a rigid or soft robot adaptively, without additional stiffness-tunable mechanism. This approach makes the robot lightweight and practical. First, we present the fabricating process of the soft-rigid robot developed in the work. A steel flexure is especially optimized and embedded in the flexible body of the robot, which enhances the bending stiffness in the axial direction dramatically while keeping the body in other directions flexible and adaptive. Second, the kinematic model and analysis are developed to characterize the different configurations of the soft-rigid robot influenced by various parameters. Third, experiments are conducted to evaluate the performance of the flexible body and validate the accuracy of the kinematic model. Finally, a two-fingered gripper is built based on the soft-rigid robots, and grasping experiments are conducted to demonstrate how the soft-rigid robots could enhance the capability of the gripper in real-word.",
        "primary_area": "",
        "author": "Yongyao Li;Ming Congr;Dong Liu;Yu Du;Yongyao Li;Ming Congr;Dong Liu;Yu Du",
        "authorids": "/37085731239;/37088999942;/37085417732;/37085405893;/37085731239;/37088999942;/37085417732;/37085405893",
        "aff": "School of Mechanical Engineering, Dalian University of Technology, Dalian, China; School of Mechanical Engineering, Dalian University of Technology, Dalian, China; School of Mechanical Engineering, Dalian University of Technology, Dalian, China; School of Mechanical Engineering, Dalian University of Technology, Dalian, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561811/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9786084529252515077&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Dalian University of Technology",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "http://www.dlut.edu.cn",
        "aff_unique_abbr": "DUT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Dalian",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561146",
        "title": "Design and Control of 5-DoF Robotically Steerable Catheter for the Delivery of the Mitral Valve Implant",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the mechanism and design of a robotically steerable catheter system for percutaneous and minimally invasive treatment of mitral regurgitation. One of the main causes of mitral regurgitation is an impaired mitral valve topology, that results in severe heart-related diseases. Repair or replacement of the mitral valve through open-heart surgery such as traditional sternotomy has been conducted as a treatment. However, at least 50 % of patients with severe mitral regurgitation are not candidates for this surgery due to their age or comorbidities. Recently, minimally invasive or transcatheter approaches for mitral valve repair/replacement have been gaining attention to minimize the surgery's risk and several catheter mechanisms have been proposed in early phase clinical trials. Although dexterity and manipulability are essential functions in the transcatheter procedure, a direct torsional capability has not been implemented in the systems. We present a design of a 5-DoF robotically steerable catheter having two bending joints, two torsion joints having a direct torquing design, and a mitral implant delivery module to provide dexterous manipulation of the tip of the catheter. Designs and kinematic models of each joint module are presented and their performance is verified with experiments. Lastly, a mitral clip implanting procedure is demonstrated in a phantom heart model.",
        "primary_area": "",
        "author": "Namrata Nayar;Seokhwan Jeong;Jaydev P. Desai;Namrata Nayar;Seokhwan Jeong;Jaydev P. Desai",
        "authorids": "/37088640098;/37087324027;/37282117700;/37088640098;/37087324027;/37282117700",
        "aff": "Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA; Department of Mechanical Engineering, Sogang University, Seoul, South Korea; Wallace H. Coulter Department of Biomedical Engineering, Medical Robotics and Automation (RoboMed) Laboratory, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561146/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2295787086794520530&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Sogang University",
        "aff_unique_dep": "Wallace H. Coulter Department of Biomedical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.gatech.edu;http://www.sogang.ac.kr",
        "aff_unique_abbr": "Georgia Tech;Sogang",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Atlanta;Seoul",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "9561200",
        "title": "Design and Control of Fully Handheld Microsurgical Robot for Active Tremor Cancellation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design and control of a fully handheld robot for robot-assisted microsurgery. The handheld robot incorporates a miniature 6-PUS parallel micromanipulator that can impose a remote center of motion (RCM) at the incision point of entry during microsurgery. An optimization framework is formulated to determine the geometric parameters of the micromanipulator. The optimization aims to minimize force applied on actuation modules by lateral load at the RCM. The optimization yields a base diameter of 16 mm, a top diameter of 12.6 mm, and a connecting link of 9.4 mm, which offers a cylindrical workspace 4-mm wide and 3-mm high with a 5-mm travel in linear actuation. An order of magnitude higher force capability is attained in the smaller form factor compared to the latest handheld micromanipulator. We built the fully handheld version of the microsurgical robot by incorporating embedded electronics and an EM tracker for sensing the 6-DOF pose of hand motion. The real-time control framework of the handheld robot is also presented, including motion filter for active tremor cancellation. As a result, the handheld robot can tolerate side loads up to 5.0 N for a lateral load applied at the RCM without significant degradation in control. Finally, the robot-aided operation with the active tremor cancellation shows a significant peak-force reduction compared to unaided operation during the task of maintaining contact force.",
        "primary_area": "",
        "author": "Eunchan Kim;Ingu Choi;Sungwook Yang;Eunchan Kim;Ingu Choi;Sungwook Yang",
        "authorids": "/37088446015;/37088446916;/38667581800;/37088446015;/37088446916;/38667581800",
        "aff": "Department of Mechanical Convergence Engineering, Hanyang University, Seoul, Korea; Electrical Engineering Department, Korea University, Seoul, Korea; S. Center for Intelligent and Interactive Robotics, Korea Institute of Science & Technology, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561200/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3295560530633461713&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Hanyang University;Korea University;Korea Institute of Science & Technology",
        "aff_unique_dep": "Department of Mechanical Convergence Engineering;Electrical Engineering Department;Center for Intelligent and Interactive Robotics",
        "aff_unique_url": "http://www.hanyang.ac.kr;http://www.korea.ac.kr;https://www.kist.re.kr",
        "aff_unique_abbr": "HYU;KU;KIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9560728",
        "title": "Design and Development of a Robotic Bioreactor for In Vitro Tissue Engineering",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, a novel robotic bioreactor is presented with capabilities of closed-loop control of force and displacement applied to a tissue scaffold and tissue scaffold stiffness calculation. These characteristics bring the potential of a robotic bioreactor that can optimize the mechanical properties of tissue constructs in order for them to match those of native tissues. Custom position and force control signals are designed to maintain a steady tensioning of the tissue scaffold while the latter one\u2019s mechanical properties evolve in time. We propose a simple model to support the hypothesis that the stiffness of a cell-seeded scaffold increases over time, and thus force control signals need to be adjusted accordingly. The robotic bioreactor is able to measure the stiffness of a scaffold sample relatively accurately, with an average standard deviation of 0.2N/mm. The combination of accurate stiffness measurements and a closed-loop control system equips the robotic bioreactor with the fundamental requirements to achieve stiffness based force control in future in vitro experiments, and thus to a tissue-scaffold responsive technology for advanced tissue engineering.",
        "primary_area": "",
        "author": "Abigail F. Smith;Jeerawan Thanarak;Marco Pontin;Nicola H. Green;Dana D. Damian;Abigail F. Smith;Jeerawan Thanarak;Marco Pontin;Nicola H. Green;Dana D. Damian",
        "authorids": "/37088999772;/37086589663;/37088561551;/37086587378;/37587456200;/37088999772;/37086589663;/37088561551;/37086587378;/37587456200",
        "aff": "Department of Automatic Control and Systems Engineering, University of Sheffield, United Kingdom; Department of Material Science and Engineering, University of Sheffield, United Kingdom; Department of Automatic Control and Systems Engineering, University of Sheffield, United Kingdom; INSIGNEO Institute for In Silico Medicine, The Pam Liversidge Building, Sir Robert Hadfield Building, Sheffield, UK; Department of Automatic Control and Systems Engineering, University of Sheffield, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560728/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9002444297919013884&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Sheffield;Insigneo Institute for in Silico Medicine",
        "aff_unique_dep": "Department of Automatic Control and Systems Engineering;",
        "aff_unique_url": "https://www.sheffield.ac.uk;",
        "aff_unique_abbr": "Sheffield;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Sheffield",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9560729",
        "title": "Design and Experiment of a Pneumatic Soft Climbing Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper designed a pneumatic soft climbing robot by utilizing the high flexibility of soft materials. Capabilities of climbing and creeping through small spaces would rarely possible with a method based only on rigid links. At first, according to the drive mode of pneumatic networks, a model for soft climbing robots with different section having their independent stiffness was designed; afterwards, the analysis of visco-mechanical properties of robots at the contact surface were provided by using the method of minimum potential energy; on the basis, finite element analysis and experiment are given to analyze the climbing behaviors of the robot; finally, by employing 3-d printing and layer-by-layer casting, a prototype soft climbing robot was prepared to perform climbing experiments. The research is expected to provide a new method for monitoring complex unstructured environments.",
        "primary_area": "",
        "author": "Fengyu Xu;Yuxuan Lu;Zhenjiang Jiang;Guoping Jiang;Fengyu Xu;Yuxuan Lu;Zhenjiang Jiang;Guoping Jiang",
        "authorids": "/37652815100;/37087500672;/37088984337;/37275167900;/37652815100;/37087500672;/37088984337;/37275167900",
        "aff": "Jiangsu Engineering Lab for IOT Intelligent Robots (IOTRobot), College of Automation, Nanjing University of Posts and Telecommunications, Nanjing, China; Nanjing Nanyou Institute of Information Technovation, Co., Ltd; Jiangsu Engineering Lab for IOT Intelligent Robots (IOTRobot), College of Automation, Nanjing University of Posts and Telecommunications, Nanjing, China; Jiangsu Engineering Lab for IOT Intelligent Robots (IOTRobot), College of Automation, Nanjing University of Posts and Telecommunications, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560729/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:BB1z8WdaZ4MJ:scholar.google.com/&scioq=Design+and+Experiment+of+a+Pneumatic+Soft+Climbing+Robot&hl=en&as_sdt=0,33",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Nanjing University of Posts and Telecommunications;Nanjing Nanyou Institute of Information Technovation",
        "aff_unique_dep": "College of Automation;Information Technovation",
        "aff_unique_url": "http://www.njupt.edu.cn;",
        "aff_unique_abbr": "NUPT;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nanjing;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560847",
        "title": "Design and Experimental Validation of a Robotic System for Reactor Core Detector Removal",
        "track": "main",
        "status": "Poster",
        "abstract": "The reactor power and the coolant level in the nuclear plant are monitored via the reactor core detectors. Every 4 to 5 years, the detectors with high-level radiation need to be removed, which is time-consuming and hazardous for workers. To address this issue, this paper introduces a novel robotic system and its strategy for the removal of the detectors. The modular mechanisms are designed to achieve diverse actions such as positioning, extracting, transporting, cutting, and coiling. The detector with different radiation doses is physically classified and minimized in volume. The experiments to simulate the removal process are conducted. The results demonstrate that the time for the robotic removal of one detector is reduced from more than 1 hour to 31.2\u00b15.3 min compared with the manual mode. The radiation exposure time for workers is reduced to 0 under normal working conditions, which significantly reduces the radiation dose compared with the traditional methods.",
        "primary_area": "",
        "author": "Zhe Han;Huanyu Tian;Fansheng Meng;Hao Wen;Rui Ma;Xingguang Duan;Yilin Zhang;Chenghua Liu;Zhe Han;Huanyu Tian;Fansheng Meng;Hao Wen;Rui Ma;Xingguang Duan;Yilin Zhang;Chenghua Liu",
        "authorids": "/37088370143;/37086813324;/37087047067;/37087228157;/37089266711;/37276797500;/37088600074;/37088599750;/37088370143;/37086813324;/37087047067;/37087228157;/37089266711;/37276797500;/37088600074;/37088599750",
        "aff": "Institute of Engineering Medicine, Beijing Institute of Technology, Beijing, China; School of Mechatronical Engineering & the Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, Beijing, China; School of Mechatronical Engineering & the Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, Beijing, China; School of Mechatronical Engineering & the Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, Beijing, China; School of Mechatronical Engineering & the Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, Beijing, China; School of Mechatronical Engineering & the Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, Beijing, China; Device Research and Development Center, China Nuclear Power Technology Research Institute Co., Ltd., Shenzhen; Device Research and Development Center, China Nuclear Power Technology Research Institute Co., Ltd., Shenzhen",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560847/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5255398208921428322&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;1;1",
        "aff_unique_norm": "Beijing Institute of Technology;China Nuclear Power Technology Research Institute Co., Ltd.",
        "aff_unique_dep": "Institute of Engineering Medicine;Device Research and Development Center",
        "aff_unique_url": "http://www.bit.edu.cn;",
        "aff_unique_abbr": "BIT;",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561470",
        "title": "Design and Implementation of a Novel, Intrinsically Safe Rigid-Flexible Coupling Manipulator for COVID-19 Oropharyngeal Swab Sampling",
        "track": "main",
        "status": "Poster",
        "abstract": "Driven by the SARS-CoV-2 pandemic, demand for oropharyngeal swab sampling (OP-swabs) is surging. However, medical staff can easily become infected by the virus during the sampling process. In an effort to combat this, we developed a novel, intrinsically safe rigid- flexible coupling (RFC) manipulator to improve the safety and reliability of OP-swab sampling to test for COVID-19, which is presented herein. Suitable sampling areas and the necessary contact force for OP-swab sampling tasks are carefully investigated, and three typical sampling paths outlined that could be performed by a robotic system. This is followed by a detailed description of an intrinsically safe bionic micro-pneumatic actuator (MPA) that was designed and fabricated as the main component of the RFC manipulator. The developed RFC manipulator\u2019s kinematic modeling, motion planning, and force control capacities were designed for OP-swab sampling scenarios. The system was then validated using both an oral cavity phantom and human volunteers, with comparative experiments on the swab quality of the OP-swab sampling approach conducted in both robotic and manual modes. The results indicate that fully-automated sampling based on this design would be feasible.",
        "primary_area": "",
        "author": "Heng Zhang;Qiwen Wang;Chuliang Chi;Yongquan Chen;Zonggao Mu;Zheng Li;Yuanmin Lan;Aidong Zhang;Heng Zhang;Qiwen Wang;Chuliang Chi;Yongquan Chen;Zonggao Mu;Zheng Li;Yuanmin Lan;Aidong Zhang",
        "authorids": "/37086798405;/37088998322;/37088998945;/37086798722;/37085472784;/38469473900;/37088999985;/37089401927;/37086798405;/37088998322;/37088998945;/37086798722;/37085472784;/38469473900;/37088999985;/37089401927",
        "aff": "Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong, Shenzhen, China; Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong, Shenzhen, China; Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong, Shenzhen, China; Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong, Shenzhen, China; School of Mechanical Engineering, Shandong University of Technology, China; Department of Surgery, and Chow Yuk Ho Technology Centre for Innovative Medicine, The Chinese University of Hong Kong, Hong Kong; Longgang District People\u2019s Hospital of Shenzhen, China; Institute of Robotics and Intelligent Manufacturing, The Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561470/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13607381759608736132&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;0;2;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Shandong University of Technology;Longgang District People\u2019s Hospital",
        "aff_unique_dep": "Institute of Robotics and Intelligent Manufacturing;School of Mechanical Engineering;",
        "aff_unique_url": "https://www.cuhk.edu.cn;;",
        "aff_unique_abbr": "CUHK;;",
        "aff_campus_unique_index": "0;0;0;0;2;0",
        "aff_campus_unique": "Shenzhen;;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560778",
        "title": "Design and Modeling of a Biomimetic Gastropod-like Soft Robot with Wet Adhesive Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Crawling through various terrains has been a long research interest. In recent years, quite a number of soft crawling robots have been developed. However, locomoting in an elastic, humid, and slippery environment remains a challenge. In nature, gastropods, such as snails, live in humid environment and could crawl through all kinds of surface conditions by using wet adhesion. In the wet adhesive locomotion, the mucus is crucial in adhering the gastropod while allowing forward motion. Previously, we presented one snail-like soft robot that mimics the gastropods. In this work, we propose a second version and present a theoretical model of the mucus simulant. In addition, the dynamic model of the soft robot\u2019s wet adhesive locomotion is developed for the first time. Results show that the speed of the current version is 5 times than that of the previous one through the optimization of design. Also shown by the results that the mucus helps to speed up the robot by at least 2.7 times.",
        "primary_area": "",
        "author": "Wenci Xin;Flippy Tianle Pan;Yehui Li;Philip Wai Yan Chiu;Zheng Li;Wenci Xin;Flippy Tianle Pan;Yehui Li;Philip Wai Yan Chiu;Zheng Li",
        "authorids": "/37088533289;/37088998591;/37088535100;/37088831941;/38469473900;/37088533289;/37088998591;/37088535100;/37088831941;/38469473900",
        "aff": "Department of Surgery, The Chinese University of Hong Kong, Hong Kong; Department of Biomedical Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Surgery, The Chinese University of Hong Kong, Hong Kong; Department of Surgery and the Chow Yuk Ho Technology Centre for Innovative Medicine, The Chinese University of Hong Kong, Hong Kong; Department of Surgery, Chow Yuk Ho Technology Centre for Innovative Medicine, Li Ka Shing Institute of Health Science, and Multi-scale Medical Robotics Center Ltd,. The Chinese University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560778/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1733387282451664848&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Surgery",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560966",
        "title": "Design and Modeling of a Variable-Stiffness Spring Mechanism for Impedance Modulation in Physical Human\u2013Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Our goal is to investigate different approaches to modulate stiffness and apply them to human-robot interaction. Here we report on our effort employing the concept of adjustable unsupported-length cantilever leaf spring, which has been previously applied to different designs of variable stiffness actuators. By transmitting the interaction force through the elastic component directly to the supporting structure instead of the actuation unit, this type of actuator requires low power to adjust and to maintain a desired stiffness. In the design of a 1-translational degree of freedom body weight support system of a rehabilitation robot, we used a leaf spring mechanism for stiffness modulation relying only on the spring deflection in combination with a non-backdrivable actuator for adjusting the vertical equilibrium position. This paper describes our approach in determining the spring parameters to attain a desired range of stiffness with a short traveling distance of the adjuster. To model the spring stiffness under deflection, the ideal cantilever support model cannot be assumed for a conventional design of dual roller-pairs slider, especially with a soft spring. A beam deflection model considering the non-zero slopes at the contact points between the rollers and the spring is presented, along with the validation experiments using different spring thicknesses on our prototype.",
        "primary_area": "",
        "author": "Ronnapee Chaichaowarat;Satoshi Nishimura;Hermano Igo Krebs;Ronnapee Chaichaowarat;Satoshi Nishimura;Hermano Igo Krebs",
        "authorids": "/37086298859;/37088534539;/37299435200;/37086298859;/37088534539;/37299435200",
        "aff": "International School of Engineering, Faculty of Engineering, Chulalongkorn University, Bangkok, Thailand; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560966/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17974787108150390689&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Chulalongkorn University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Faculty of Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "http://www.chula.ac.th;https://web.mit.edu",
        "aff_unique_abbr": "Chula;MIT",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Bangkok;Cambridge",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Thailand;United States"
    },
    {
        "id": "9561583",
        "title": "Design and Testing of a Damped Piezo-Driven Decoupled XYZ Stage",
        "track": "main",
        "status": "Poster",
        "abstract": "Lightly-damped dynamics of a flexure-based mechanism will tend to largely deteriorate the broadband control performance if its hysteresis nonlinearity has been compensated. This paper developed a novel damped piezo-driven decoupled XYZ nanopositioning stage, which consists of three orthogonal parallel kinematic subchains, in which each subchain has a translational pair using a bridge-type piezo-driven actuator and two Cardan joints using two orthogonal- axis flexure hinges. Especially, we add damped inserts into each Cardan joint, as their shearing damping effects can enhance joint damping. Kinematic coupling is theoretically modeled and the decoupled dynamic model of the stage is built up. The frequency response functions with no-damping and damping scenarios are obtained by finite element transient analysis and experimental modal analysis respectively. The results indicate that the damping inserts embedded in the flexure hinges can enhance the stiffness and damping simultaneously, which will benefit broadband motion control of the nanopositioning stage.",
        "primary_area": "",
        "author": "Zhong Chen;Junjie Shi;Songwei Zhu;Xineng Zhong;Xianmin Zhang;Zhong Chen;Junjie Shi;Songwei Zhu;Xineng Zhong;Xianmin Zhang",
        "authorids": "/38564915200;/37088649608;/37088999185;/37089001170;/37405034900;/38564915200;/37088649608;/37088999185;/37089001170;/37405034900",
        "aff": "Guangdong Province Key Laboratory of Precision Equipment and Manufacturing Technology, School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; Guangdong Province Key Laboratory of Precision Equipment and Manufacturing Technology, School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; Guangdong Province Key Laboratory of Precision Equipment and Manufacturing Technology, School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; Guangdong Province Key Laboratory of Precision Equipment and Manufacturing Technology, School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China; Guangdong Province Key Laboratory of Precision Equipment and Manufacturing Technology, School of Mechanical and Automotive Engineering, South China University of Technology, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561583/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17328326088864751971&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "South China University of Technology",
        "aff_unique_dep": "School of Mechanical and Automotive Engineering",
        "aff_unique_url": "http://www.scut.edu.cn",
        "aff_unique_abbr": "SCUT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561744",
        "title": "Design and Validation of a Novel Exoskeleton Hand Interface: The Eminence Grip",
        "track": "main",
        "status": "Poster",
        "abstract": "How best to attach exoskeletons to human limbs is an open and understudied problem. In the case of upperbody exoskeletons, cylindrical handles are commonly used attachments due to ease of use and cost effectiveness. However, handles require active grip strength from the user and may result in undesirable flexion synergy stimulation, thus limiting the robot\u2019s effectiveness. This paper presents a new design, the Eminence Grip, for attaching an exoskeleton to the hand while avoiding the undesirable consequences of using a handle. The ergonomic design uses inverse impedance matching and does not require active effort from the user to remain interfaced with the exoskeleton. We compare the performance of the Eminence Grip to the handle design in a healthy subject target reaching experiment. The results show that the Eminence Grip achieves similar performance to a handle in terms of relative motion between the user and the exoskeleton while eliminating the requirement of grip force to transfer loads to/from the exoskeleton and avoiding stimulation of the flexion synergy. Taken together, the kinematic equivalence and improvement in ergonomics suggest that the Eminence Grip is a promising exoskeleton-hand attachment interface supporting further experiments with impaired populations.",
        "primary_area": "",
        "author": "Keya Ghonasgi;Chad G. Rose;Ana C. De Oliveira;Rohit John Varghese;Ashish D. Deshpande;Keya Ghonasgi;Chad G. Rose;Ana C. De Oliveira;Rohit John Varghese;Ashish D. Deshpande",
        "authorids": "/37086480491;/37085505859;/37086396993;/37086479738;/37405479700;/37086480491;/37085505859;/37086396993;/37086479738;/37405479700",
        "aff": "Dept. of Mechanical Engineering, Rehabilitation and Neuromuscular Robotics (ReNeu) Lab, The University of Texas, Austin; Dept. of Mechanical Engineering, Wearable and BioRobotics (WeBR) Lab, Auburn University, Auburn, AL, 36849; Dept. of Mechanical Engineering, Rehabilitation and Neuromuscular Robotics (ReNeu) Lab, The University of Texas, Austin; Dept. of Mechanical Engineering, Rehabilitation and Neuromuscular Robotics (ReNeu) Lab, The University of Texas, Austin; Dept. of Mechanical Engineering, Rehabilitation and Neuromuscular Robotics (ReNeu) Lab, The University of Texas, Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561744/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17161134880568081940&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University of Texas at Austin;Auburn University",
        "aff_unique_dep": "Department of Mechanical Engineering;Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.utexas.edu;https://www.auburn.edu",
        "aff_unique_abbr": "UT Austin;Auburn",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Austin;Auburn",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560984",
        "title": "Design and soft-landing control of a six-legged mobile repetitive lander for lunar exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "The autonomous robots consisting of an immovable lander and a rover are widely deployed to explore extraterrestrial planets. However, these robots have two main limitations: (1) the separate design for lander and rover respectively results in heavy mass and big volume of the whole system, which increases the launching cost sharply; (2) the rover\u2019s detection area has to be restricted to the vicinity of the immovable lander. To overcome these problems, we designed a novel six-legged mobile repetitive lander called \"HexaMRL\", which integrates the functions of both lander and rover, including folding, deploying, repetitive soft-landing, and walking. A hybrid compliant mechanism taking advantages of both active and passive compliances was adopted on its leg. An integrated drive unit (IDU) was utilized to imitate the dynamics of a spring and a damper to absorb the landing impact energy, while the structure remains intact. Moreover, a control method based on state machine for soft-landing on the Moon was proposed. HexaMRL achieved repetitive soft-landing on a 5-DoF lunar gravity testing platform (5-DoF-LGTP) with a vertical landing velocity of 1.9 m/s and a payload of 140 kg. The drive torque safety margin is improved by 23.4%p based on the hybrid compliant leg comparing with the standalone active compliant leg.",
        "primary_area": "",
        "author": "Ke Yin;Feng Gao;Qiao Sun;Jimu Liu;Tao Xiao;Jianzhong Yang;Shuiqing Jiang;Xianbao Chen;Jing Sun;Renqiang Liu;Chenkun Qi;Ke Yin;Feng Gao;Qiao Sun;Jimu Liu;Tao Xiao;Jianzhong Yang;Shuiqing Jiang;Xianbao Chen;Jing Sun;Renqiang Liu;Chenkun Qi",
        "authorids": "/37088995872;/37400836800;/37085565719;/37088997906;/37089000453;/37088998792;/37086798280;/37085460058;/37088999866;/37087936950;/37529382400;/37088995872;/37400836800;/37085565719;/37088997906;/37089000453;/37088998792;/37086798280;/37085460058;/37088999866;/37087936950;/37529382400",
        "aff": "Department of Mechanical Engineering, State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; Department of Mechanical Engineering, State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; Department of Mechanical Engineering, State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; Department of Mechanical Engineering, State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; General Department, Fifth Aerospace Academy, Beijing, China; General Department, Fifth Aerospace Academy, Beijing, China; General Department, Fifth Aerospace Academy, Beijing, China; Department of Mechanical Engineering, State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; Department of Mechanical Engineering, State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; Department of Mechanical Engineering, State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; Department of Mechanical Engineering, State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560984/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14217217587670621613&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;1;1;1;0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Fifth Aerospace Academy",
        "aff_unique_dep": "Department of Mechanical Engineering;General Department",
        "aff_unique_url": "https://www.sjtu.edu.cn;",
        "aff_unique_abbr": "SJTU;",
        "aff_campus_unique_index": "0;0;0;0;1;1;1;0;0;0;0",
        "aff_campus_unique": "Shanghai;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560817",
        "title": "Design of Soft Sensor for Feedback Control of Bio-actuator Powered by Skeletal Muscle",
        "track": "main",
        "status": "Poster",
        "abstract": "In spite of recent high attention of the biohybrid robot system, the previous researches focused on actuation system depend on simple on/off control without feedback control. To solve this problem, we proposed a soft sensor for feedback control of a bio-actuator driven by skeletal muscle. The proposed soft sensor can measure contraction forces of the proposed bio-actuator [1]. The bio-actuator was constructed with tendon structure and culture template made by polydimethylsiloxane (PDMS). It generated contraction forces at 0.3 mN when applying electrical stimulation. To measure that kind of small amount of contraction forces (0.3 mN), we fabricated a soft sensor using liquid metal, Galinstan, and HTV-2000. At first, we measured the Young\u2019s modulus of the bioactuator and sensor and then fabricated the soft sensor having 68.52 kPa of Young\u2019s modulus that is similar the bioactuator (45.8 kPa). Next, we simulated the sensor to estimate the resistance change according to the applied force. Since the resistance change is too small, we design the circuit to amplify the signal. Then, we detect very small resistance at milli-ohm. In addition, we analyzed time response to detect signal of actuator faster than 200 ms. As a result, the proposed sensor can measure the force of bioactuator without time delay.",
        "primary_area": "",
        "author": "Eunhye Kim;Masaru Takeuchi;Ryosuke Ohira;Takuto Nomura;Yasuhisa Hasegawa;Qiang Huang;Toshio Fukuda;Eunhye Kim;Masaru Takeuchi;Ryosuke Ohira;Takuto Nomura;Yasuhisa Hasegawa;Qiang Huang;Toshio Fukuda",
        "authorids": "/37086347339;/37573622500;/37089000245;/37086346854;/37272575600;/37279982900;/37279174500;/37086347339;/37573622500;/37089000245;/37086346854;/37272575600;/37279982900;/37279174500",
        "aff": "Department of Mechatronics Engineering, Meijo University, Nagoya, Japan; Department of Micro-Nano Systems Engineering, Nagoya University, Nagoya, Japan; Department of Mechatronics Engineering, Meijo University, Nagoya, Japan; Department of Micro-Nano Systems Engineering, Nagoya University, Nagoya, Japan; Department of Micro-Nano Systems Engineering, Nagoya University, Nagoya, Japan; Beijing Institute of Technology, Beijing, China; Nagoya University and Beijing Institute of Technology, Meijo University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560817/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15704163280190367269&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;1;1;2;1",
        "aff_unique_norm": "Meijo University;Nagoya University;Beijing Institute of Technology",
        "aff_unique_dep": "Department of Mechatronics Engineering;Department of Micro-Nano Systems Engineering;",
        "aff_unique_url": "https://www.meijo-u.ac.jp;https://www.nagoya-u.ac.jp;http://www.bit.edu.cn/",
        "aff_unique_abbr": "Meijo;Nagoya U;BIT",
        "aff_campus_unique_index": "0;0;0;0;0;1",
        "aff_campus_unique": "Nagoya;Beijing;",
        "aff_country_unique_index": "0;0;0;0;0;1;0",
        "aff_country_unique": "Japan;China"
    },
    {
        "id": "9561270",
        "title": "Design of a 3-DOF Coupled Tendon-Driven Waist Joint",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a coupled tendon-driven waist joint for humanoid robots. The waist joint was designed as a 3 degrees of freedom (DOF) structure to simulate the motion of a human waist. The power transmission was designed by adopting a 3-motor 3-DOF (3M3D) coupled tendon-driven mechanism, so that the torque on the joints was multiplied. We derived the torque transmission formula and the rotation angle formula of the 3M3D tendon-driven structures and designed the waist joint by adopting an appropriate structure according to their features. To evaluate the accuracy and load capacity of the waist joint, we performed a rotational accuracy experiment and a maximum torque experiment. The experiment results showed that the maximum error of joint rotation was below 1\u00b0, and the maximum torque of the pitch, roll, and yaw rotations were 87[Nm], 53[Nm], and 22.2[Nm], respectively.",
        "primary_area": "",
        "author": "Yiwei Wang;Wenyang Li;Shunta Togo;Hiroshi Yokoi;Yinlai Jiang;Yiwei Wang;Wenyang Li;Shunta Togo;Hiroshi Yokoi;Yinlai Jiang",
        "authorids": "/37088700349;/37086518839;/37086184599;/37285419100;/37085406020;/37088700349;/37086518839;/37086184599;/37285419100;/37085406020",
        "aff": "Department of Mechanical Engineering and Intelligent Systems, University of Electro-Communications, Tokyo, Japan; Department of Mechanical Engineering and Intelligent Systems, University of Electro-Communications, Tokyo, Japan; Department of Mechanical Engineering and Intelligent Systems, University of Electro-Communications, Tokyo, Japan; Department of Mechanical Engineering and Intelligent Systems, University of Electro-Communications, Tokyo, Japan; Center for Neuroscience and Biomedical Engineering, University of Electro-Communications, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561270/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4178990001743855118&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Electro-Communications",
        "aff_unique_dep": "Department of Mechanical Engineering and Intelligent Systems",
        "aff_unique_url": "https://www.uec.ac.jp",
        "aff_unique_abbr": "UEC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561345",
        "title": "Design of a deployable underwater robot for the recovery of autonomous underwater vehicles based on origami technique",
        "track": "main",
        "status": "Poster",
        "abstract": "The recovery of autonomous underwater vehicles (AUVs) has been a challenging mission due to the limited localization accuracy and movement capability of the AUVs. To overcome these limitations, we propose a novel design of a deployable underwater robot (DUR) for the recovery mission. Utilizing the origami structure, the DUR can transform between open and closed states to maximize the performance at different recovery stages. At the approaching stage, the DUR will remain closed state to reduce the drag force. While at the capturing state, the DUR will deploy to form a much larger opening to improve the success rate of docking. Meanwhile, the thrusters\u2019 configuration also changes with the transformation of the robot body. The DUR can achieve a high driven force in the forward direction with the closed state which leads to a fast-approaching speed. While with the open state, the DUR can achieve more balanced force and torque maneuverability to prepare for agile position adjustment for the docking. CFD simulation has been used to analyze the drag forces and identify the hydrodynamic coefficients. A prototype of the robot has been fabricated and tested in an indoor water pool. Both simulation and experiment results validate the feasibility of the proposed design.",
        "primary_area": "",
        "author": "Jisen Li;Yuliang Yang;Yumei Zhang;Hua Zhu;Yongqi Li;Qiujun Huang;Haibo Lu;Shan He;Shengquan Li;Wei Zhang;Tao Mei;Feng Wu;Aidong Zhang;Jisen Li;Yuliang Yang;Yumei Zhang;Hua Zhu;Yongqi Li;Qiujun Huang;Haibo Lu;Shan He;Shengquan Li;Wei Zhang;Tao Mei;Feng Wu;Aidong Zhang",
        "authorids": "/37088836514;/37088996349;/37088998399;/37088656643;/37088996845;/37089002089;/37088883052;/37088999032;/37088837347;/37089656248;/37087244315;/37272892600;/37086269590;/37088836514;/37088996349;/37088998399;/37088656643;/37088996845;/37089002089;/37088883052;/37088999032;/37088837347;/37089656248;/37087244315;/37272892600;/37086269590",
        "aff": "Robotics Research Center, Peng Cheng Lab, Shenzhen, China; Robotics Research Center, Peng Cheng Lab, Shenzhen, China; Robotics Research Center, Peng Cheng Lab, Shenzhen, China; Robotics Research Center, Peng Cheng Lab, Shenzhen, China; Robotics Research Center, Peng Cheng Lab, Shenzhen, China; Robotics Research Center, Peng Cheng Lab, Shenzhen, China; Robotics Research Center, Peng Cheng Lab, Shenzhen, China; Robotics Research Center, Peng Cheng Lab, Shenzhen, China; Robotics Research Center, Peng Cheng Lab, Shenzhen, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, Shenzhen, China; Robotics Research Center, Peng Cheng Lab, Shenzhen, China; Department of Electronic Engineering and Information Science, University of Science and Technology of China, Anhui, China; Robotics Research Center, Peng Cheng Lab, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561345/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:fKlZxwva40sJ:scholar.google.com/&scioq=Design+of+a+deployable+underwater+robot+for+the+recovery+of+autonomous+underwater+vehicles+based+on+origami+technique&hl=en&as_sdt=0,14",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 26,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;1;0;2;0",
        "aff_unique_norm": "Pengcheng Laboratory;Southern University of Science and Technology;University of Science and Technology of China",
        "aff_unique_dep": "Robotics Research Center;Department of Mechanical and Energy Engineering;Department of Electronic Engineering and Information Science",
        "aff_unique_url": ";https://www.sustech.edu.cn;http://www.ustc.edu.cn",
        "aff_unique_abbr": ";SUSTech;USTC",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0;1;0",
        "aff_campus_unique": "Shenzhen;Anhui",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561142",
        "title": "Design of a magnetic actuation system for a microbiota-collection ingestible capsule",
        "track": "main",
        "status": "Poster",
        "abstract": "Minimally invasive wireless devices, allowing the sampling of gut\u2019s bacteria, are needed for a longitudinal understanding of the role of the microbiota on the human health. Herein, we present a novel magnetic actuation system fitting inside a 11.5 \u00d7 30.5 mm wireless ingestible capsule. Lacking any electronic components, the capsule robot is designed for the collection of microbiota\u2019s samples through mechanical brushing. Wireless activation and in situ sampling are enabled by an external permanent magnetic source. This component, when approaching the capsule, progressively allows: (1) the adhesion of the device to the mucosa, (2 the exposure of the brushes, and (3) the sampling by multiple rotations. Numerical and analytical models were developed for dimensioning the system, and were validated by benchtop experiments.",
        "primary_area": "",
        "author": "Martina Finocchiaro;Cristina Giosu\u00e8;Gaspare Drago;Fabio Cibella;Arianna Menciassi;Mario Sprovieri;Gastone Ciuti;Martina Finocchiaro;Cristina Giosu\u00e8;Gaspare Drago;Fabio Cibella;Arianna Menciassi;Mario Sprovieri;Gastone Ciuti",
        "authorids": "/37089001267;/37088995899;/37088998771;/37089001386;/37280284800;/37088678646;/37394078700;/37089001267;/37088995899;/37088998771;/37089001386;/37280284800;/37088678646;/37394078700",
        "aff": "Center of Research in Biomedical Engineering of Universitat Polit\u00e8cnica de Catalunya, Spain; National Research Council (CNR), Institute of Anthropic Impacts and Sustainability in the Marine Environment (IAS), Italy; National Research Council (CNR), Institute for Biomedical Research and Innovation (IRIB), Italy; National Research Council (CNR), Institute for Biomedical Research and Innovation (IRIB), Italy; Department of Excellence in Robotics & AI, Scuola Superiore Sant'Anna, Italy; National Research Council (CNR), Institute of Anthropic Impacts and Sustainability in the Marine Environment (IAS), Italy; Department of Excellence in Robotics & AI, Scuola Superiore Sant'Anna, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561142/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14155337944805725438&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;2;3;1;3",
        "aff_unique_norm": "Universitat Polit\u00e8cnica de Catalunya;National Research Council;National Research Council (CNR);Scuola Superiore Sant'Anna",
        "aff_unique_dep": "Center of Research in Biomedical Engineering;Institute of Anthropic Impacts and Sustainability in the Marine Environment;Institute for Biomedical Research and Innovation (IRIB);Department of Excellence in Robotics & AI",
        "aff_unique_url": "https://www.upc.edu;https://www.cnr.it;https://www.cnr.it;https://www.sssup.it",
        "aff_unique_abbr": "UPC;CNR;CNR;SSSA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1;1;1;1",
        "aff_country_unique": "Spain;Italy"
    },
    {
        "id": "9560796",
        "title": "Design, Development and Validation of a Dynamic Fall Prediction System for Excavators",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety can be listed as one of the most important aspects of every working environment, from the low risky to the most dangerous one. Construction sites can be clearly identified among the riskiest working fields, mainly because several complex and fast maneuvers are executed in a very crowded, dynamic and uncertain scenario. Specifically referring to construction machines, typical operations such as digging, earthmoving, heavy weights loading/unloading, etc. become incredibly risky if the machine stability is not guaranteed by the operator. To this purpose, this paper proposes a practical implementation of a dynamic fall prediction system for excavators based on the concept of the Zero Moment Point (ZMP). A commercially available excavator has been dynamically modelled and equipped with a set of sensors to reconstruct the state of the machine. When the proposed system is running, an alarm rings if a critical condition is reached, thus allowing the operator to avoid risky and potentially harmful situations.",
        "primary_area": "",
        "author": "Alfredo Argiolas;Simona Casini;Kazuhiro Fujio;Toshifumi Hiramatsu;Satoshi Morita;Matteo Ragaglia;Hisashi Sugiura;Marta Niccolini;Alfredo Argiolas;Simona Casini;Kazuhiro Fujio;Toshifumi Hiramatsu;Satoshi Morita;Matteo Ragaglia;Hisashi Sugiura;Marta Niccolini",
        "authorids": "/37086066315;/37085663929;/37088998662;/37086478457;/37086476952;/37085406143;/37088997767;/37542828000;/37086066315;/37085663929;/37088998662;/37086478457;/37086476952;/37085406143;/37088997767;/37542828000",
        "aff": "YANMAR R&D Europe, Firenze, Italy; YANMAR R&D Europe, Firenze, Italy; Department of Development, YANMAR Construction Equipment Co., Ltd., Fukuoka, Japan; Department of Innovation & Technology, YANMAR Holdings Co., Ltd., Shiga, Japan; Department of Innovation & Technology, YANMAR Holdings Co., Ltd., Shiga, Japan; YANMAR R&D Europe, Firenze, Italy; Department of Innovation & Technology, YANMAR Holdings Co., Ltd., Shiga, Japan; YANMAR R&D Europe, Firenze, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560796/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5670782753371515845&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;1;2;2;0;2;0",
        "aff_unique_norm": "YANMAR R&D Europe;YANMAR Construction Equipment Co., Ltd.;YANMAR Holdings Co., Ltd.",
        "aff_unique_dep": ";Department of Development;Department of Innovation & Technology",
        "aff_unique_url": ";;https://www.yanmar.com",
        "aff_unique_abbr": ";;YANMAR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;1;1;0;1;0",
        "aff_country_unique": "Italy;Japan"
    },
    {
        "id": "9561418",
        "title": "Designing Multi-Stage Coupled Convex Programming with Data-Driven McCormick Envelope Relaxations for Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "For multi-limbed robots, motion planning with posture and force constraints tends to be a difficult optimization problem due to nonlinearities, which also present extended solve times. We propose a multi-stage optimization framework with data-driven inter-stage coupling constraints to address the nonlinearity. Both clustering and evolutionary approaches to find the McCormick envelope relaxations are used to find the problem-specific parameters. The learned constraints are then used in the prior stages, which provides advanced knowledge of the following stages. This leads to improved solve times and interpretability of the results. The planner is validated through multiple walking and climbing tasks on a 10 kg hexapod robot.",
        "primary_area": "",
        "author": "Xuan Lin;Min Sung Ahn;Dennis Hong;Xuan Lin;Min Sung Ahn;Dennis Hong",
        "authorids": "/37085891795;/37086574435;/37575333900;/37085891795;/37086574435;/37575333900",
        "aff": "Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory, University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561418/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15206513510302384195&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561847",
        "title": "Detect, Reject, Correct: Crossmodal Compensation of Corrupted Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "Using sensor data from multiple modalities presents an opportunity to encode redundant and complementary features that can be useful when one modality is corrupted or noisy. Humans do this everyday, relying on touch and proprioceptive feedback in visually-challenging environments. However, robots might not always know when their sensors are corrupted, as even broken sensors can return valid values. In this work, we introduce the Crossmodal Compensation Model (CCM), which can detect corrupted sensor modalities and compensate for them. CMM is a representation model learned with self-supervision that leverages unimodal reconstruction loss for corruption detection. CCM then discards the corrupted modality and compensates for it with information from the remaining sensors. We show that CCM learns rich state representations that can be used for manipulation policies learned with reinforcement learning, even when input modalities are corrupted during policy rollout in ways not seen during training.",
        "primary_area": "",
        "author": "Michelle A. Lee;Matthew Tan;Yuke Zhu;Jeannette Bohg;Michelle A. Lee;Matthew Tan;Yuke Zhu;Jeannette Bohg",
        "authorids": "/37086935666;/37088415848;/37086080772;/37591153900;/37086935666;/37088415848;/37086080772;/37591153900",
        "aff": "Stanford University; Stanford University; The University of Texas, Austin; Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561847/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5951037749127834247&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Stanford University;University of Texas at Austin",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://www.utexas.edu",
        "aff_unique_abbr": "Stanford;UT Austin",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Stanford;Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561268",
        "title": "Detecting and Counting Oysters",
        "track": "main",
        "status": "Poster",
        "abstract": "Oysters are an essential species in the Chesapeake Bay living ecosystem. Oysters are filter feeders and considered the vacuum cleaners of the Chesapeake Bay that can considerably improve the Bay's water quality. Many oyster restoration programs have been initiated in the past decades and continued to date. Advancements in robotics and artificial intelligence have opened new opportunities for aquaculture. Drone-like ROVs with high maneuverability are getting more affordable and, if equipped with proper sensory devices, can monitor the oysters. This work presents our efforts for videography of the Chesapeake bay bottom using an ROV, constructing a database of oysters, implementing Mask R-CNN for detecting oysters, and counting their number in a video by tracking them.",
        "primary_area": "",
        "author": "Behzad Sadrfaridpour;Yiannis Aloimonos;Miao Yu;Yang Tao;Donald Webster;Behzad Sadrfaridpour;Yiannis Aloimonos;Miao Yu;Yang Tao;Donald Webster",
        "authorids": "/37085901057;/37282631400;/37712030100;/37088570242;/37089000222;/37085901057;/37282631400;/37712030100;/37088570242;/37089000222",
        "aff": "University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD; University of Maryland Institute for Advanced Computer Studies, University of Maryland, College Park, MD; Department of Mechanical Engineering and Institute for Systems Research, University of Maryland, College Park, MD; Fischell Department of Bioengineering, University of Maryland, College Park, MD; Wye Research and Education Center, University of Maryland, College Park, MD",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561268/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3691450421084046747&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "Institute for Advanced Computer Studies",
        "aff_unique_url": "https://www.umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562056",
        "title": "Detecting and Mapping Trees in Unstructured Environments with a Stereo Camera and Pseudo-Lidar",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for detecting and mapping trees in noisy stereo camera point clouds, using a learned 3D object detector. Inspired by recent advancements in 3-D object detection using a pseudo-lidar representation for stereo data, we train a PointRCNN detector to recognize trees in forest-like environments. We generate detector training data with a novel automatic labeling process that clusters a fused global point cloud. This process annotates large stereo point cloud training data sets with minimal user supervision, and unlike previous pseudo-lidar detection pipelines, requires no 3D ground truth from other sensors such as lidar. Our mapping system additionally uses a Kalman filter to associate detections and consistently estimate the positions and sizes of trees. We collect a data set for tree detection consisting of 8680 stereo point clouds, and validate our method on an outdoors test sequence. Our results demonstrate robust tree recognition in noisy stereo data at ranges of up to 7 meters, on 720p resolution images from a Stereolabs ZED 2 camera. Code and data are available at https://github.com/brian-h-wang/pseudolidar-tree-detection.",
        "primary_area": "",
        "author": "Brian H. Wang;Carlos Diaz-Ruiz;Jacopo Banfi;Mark Campbell;Brian H. Wang;Carlos Diaz-Ruiz;Jacopo Banfi;Mark Campbell",
        "authorids": "/37086875155;/37087012336;/37085491416;/37272971700;/37086875155;/37087012336;/37085491416;/37272971700",
        "aff": "Sibley School of Mechanical & Aerospace Engineering, Cornell University, Ithaca, NY, USA; Sibley School of Mechanical & Aerospace Engineering, Cornell University, Ithaca, NY, USA; Sibley School of Mechanical & Aerospace Engineering, Cornell University, Ithaca, NY, USA; Sibley School of Mechanical & Aerospace Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562056/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10001577747166558710&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "Sibley School of Mechanical & Aerospace Engineering",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ithaca",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561966",
        "title": "Detecting blindspots in colonoscopy by modelling curvature",
        "track": "main",
        "status": "Poster",
        "abstract": "Optical colonoscopy is the gold standard for colorectal cancer screening, however even under optimal conditions only 81% of the internal tissue is inspected, in part causing up to 22% of early adenomas to be missed. Blindspots commonly occur at acute bends where the camera\u2019s view is blocked. 3D reconstruction alone is insufficient to assess screening completeness as predictions of both the seen and unseen mucosa are required. Existing works in blindspot detection nevertheless use a highly detailed 3D reconstruction as the first step, the complexity of which degrades processing speed and reliability. We demonstrate that this complexity is not needed to predict whether acute bends have been adequately inspected. We propose a parametric model of the colon with only 2 variables: radius and curvature. By incorporating curvature, our method can predict the occlusion which acute bends cause. We use CT scans from 12 patients which on average contain 20 bends. We use a custom colonoscopy simulator and, assuming known geometry, show that a curved model reliably predicts these blindspots while a non-curved model always misses them. From our frame-by-frame predictions we build a panoramic map of the tissue inspected over the procedure. We show that this correctly identifies all 10 blindspots during 3 minutes of colonoscopy. We envisage that by alerting clinicians to mucosa which they have missed in real time, they can revisit these areas, improving the detection of polyps and cancers.",
        "primary_area": "",
        "author": "George Abrahams;Anthony Herv\u00e9;Julius E. Bernth;Marc Yvon;Bu Hayee;Hongbin Liu;George Abrahams;Anthony Herv\u00e9;Julius E. Bernth;Marc Yvon;Bu Hayee;Hongbin Liu",
        "authorids": "/37086938051;/37088999004;/37086175848;/37088995953;/37086933514;/37537718900;/37086938051;/37088999004;/37086175848;/37088995953;/37086933514;/37537718900",
        "aff": "HaMMeR Lab, King\u2019s College, London; Human Centric Innovation Center, IBM Europe; HaMMeR Lab, King\u2019s College, London; Human Centric Innovation Center, IBM Europe; Gastroenterology, King\u2019s College Hospital; HaMMeR Lab, King\u2019s College, London",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561966/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=310507791236500333&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;2;0",
        "aff_unique_norm": "King\u2019s College London;IBM;King\u2019s College Hospital",
        "aff_unique_dep": "HaMMeR Lab;Human Centric Innovation Center;Gastroenterology",
        "aff_unique_url": "https://www.kcl.ac.uk;https://www.ibm.com/europe;https://www.kch.nhs.uk",
        "aff_unique_abbr": "KCL;IBM;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;1;0;1;0;0",
        "aff_country_unique": "United Kingdom;Unknown"
    },
    {
        "id": "9560753",
        "title": "Developing of A Rigid-Compliant Finger Joint Exoskeleton Using Topology Optimization Method",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic hand exoskeletons can provide assistance to people who suffer from hand functional disability or spinal cord injury (SCI). However, the current hand exoskeletons remain challenging with respect to having a user-friendly design that satisfies human motion with a lightweight structure. Here we propose a method of using topology optimization in the design of finger exoskeletons, which is a lightweight and integrate manufactured exoskeleton. The exoskeleton is designed by generating the topology configuration according to the bending state of the finger. The objective function in the optimization is set to be the maximization of output displacement of the design domain. After obtaining the topology configuration, a conjugate surface flexure hinge is developed as an elastic joint to replace the compliant part of the topologies. Finally, a rigid-compliant parallel exoskeleton is fabricated by a 3D printer and the performance of the mechanism is verified.",
        "primary_area": "",
        "author": "Renghao Liang;Guanghua Xu;Bo He;Min Li;Zhicheng Teng;Sicong Zhang;Renghao Liang;Guanghua Xu;Bo He;Min Li;Zhicheng Teng;Sicong Zhang",
        "authorids": "/37086243516;/37287646000;/37086388964;/37089399239;/37086593329;/37085895725;/37086243516;/37287646000;/37086388964;/37089399239;/37086593329;/37085895725",
        "aff": "School of Mechanical Engineering, Xi\u2019an Jiaotong University, Xi\u2019an, China; State Key Laboratory for Manufacturing Systems Engineering, Xi\u2019an, China; State Key Laboratory for Manufacturing Systems Engineering, Xi\u2019an, China; State Key Laboratory for Manufacturing Systems Engineering, Xi\u2019an, China; State Key Laboratory for Manufacturing Systems Engineering, Xi\u2019an, China; State Key Laboratory for Manufacturing Systems Engineering, Xi\u2019an, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560753/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13023207502324569895&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;1",
        "aff_unique_norm": "Xi'an Jiao Tong University;State Key Laboratory for Manufacturing Systems Engineering",
        "aff_unique_dep": "School of Mechanical Engineering;",
        "aff_unique_url": "http://www.xjtu.edu.cn;",
        "aff_unique_abbr": "XJTU;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Xi'an;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561656",
        "title": "Development of Flapping Robot with Self-Takeoff from The Ground Capability",
        "track": "main",
        "status": "Poster",
        "abstract": "Birds are agile in locomotion and able to move quickly and easily from one place to another. When a bird is on the ground, and a threat approaches, the bird will fly away and escape. An ornithopter robot provides advantages in energy saving, maneuverability, and crash safety. Most flapping robots require an operator or assistance to take off. The goal of this study is to enable self-takeoff from the ground. The developed robot can generate thrust to its body by exceeding its own weight using a simple flapping mechanism and lightweight design. The result of the takeoff experiment showed that the ornithopter robot was able to self-takeoff from the ground without assistance.",
        "primary_area": "",
        "author": "Muhammad Labiyb Afakh;Terukazu Sato;Hidaka Sato;Naoyuki Takesue;Muhammad Labiyb Afakh;Terukazu Sato;Hidaka Sato;Naoyuki Takesue",
        "authorids": "/37086513543;/37087245269;/37086959255;/37295990600;/37086513543;/37087245269;/37086959255;/37295990600",
        "aff": "Department of Mechanical Systems Engineering, Tokyo Metropolitan University, Hino, Tokyo, Japan; Department of Mechanical Systems Engineering, Tokyo Metropolitan University, Hino, Tokyo, Japan; Department of Mechanical Systems Engineering, Tokyo Metropolitan University, Hino, Tokyo, Japan; Department of Mechanical Systems Engineering, Tokyo Metropolitan University, Hino, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561656/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5693420429887604597&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tokyo Metropolitan University",
        "aff_unique_dep": "Department of Mechanical Systems Engineering",
        "aff_unique_url": "https://www.tmuc.ac.jp",
        "aff_unique_abbr": "TMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hino",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561275",
        "title": "Development of a Perception System for an Autonomous Surface Vehicle using Monocular Camera, LIDAR, and Marine RADAR",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes a set of software modules and algorithms for maritime object detection and tracking. The approach described here is designed to work in conjunction with various sensors from a maritime surface vessel (e.g. marine RADAR, LIDAR, camera). The described system identifies obstacles from the input sensors, estimates their state, and fuses the obstacle data into a consolidated report. The system is verified using experiments conducted on a live system and successfully demonstrates the ability to detect and track obstacles up to 450m away while operating at 7 fps. The software is open source and available at https://github.com/uml-marine-robotics/asv_perception.",
        "primary_area": "",
        "author": "Thomas Clunie;Michael DeFilippo;Michael Sacarny;Paul Robinette;Thomas Clunie;Michael DeFilippo;Michael Sacarny;Paul Robinette",
        "authorids": "/37088997484;/37086814887;/37087043159;/37681695200;/37088997484;/37086814887;/37087043159;/37681695200",
        "aff": "University of Massachusetts at Lowell, Lowell, MA, USA; Autonomous Underwater Vehicles Laboratory, MIT Sea Grant, Cambridge, MA, USA; Autonomous Underwater Vehicles Laboratory, MIT Sea Grant, Cambridge, MA, USA; University of Massachusetts at Lowell, Lowell, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561275/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7570782399575991726&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Massachusetts Lowell;Massachusetts Institute of Technology",
        "aff_unique_dep": ";Autonomous Underwater Vehicles Laboratory",
        "aff_unique_url": "https://www.uml.edu;https://web.mit.edu",
        "aff_unique_abbr": "UMass Lowell;MIT",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Lowell;Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560891",
        "title": "Development of a Series Elastic Elbow Neurological Exam Training Simulator for Lead-pipe Rigidity",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes the development of a 1-DOF kinesthetic force display device in the form of an arm training simulator that replicates the haptic feeling of lead-pipe rigidity in the elbow joint. Patients with lead-pipe rigidity have uniformly elevated muscle tone throughout the range of motion, which is an important clinical sign for diagnosing Parkinson\u2019s disease during a neurological examination. The simulator could provide training opportunities for healthcare trainees to learn and practice the assessment technique for lead-pipe rigidity. The simulator was driven by a series elastic actuator in order to have more accurate joint torque control in a safe and cost-effective manner for rendering abnormal muscle resistance. A mathematical model of lead-pipe rigidity based on hyperbolic tangent was proposed to recreate the elevated muscle resistance at different Unified Parkinson\u2019s Disease Rating Scale (UPDRS) 0-3. Performance of the simulator was evaluated through benchtop tests and rigidity simulation tests. Preliminary results suggested the simulator had good torque control accuracy (an average RMSE < 0.27 Nm) and good fidelity in mimicking clinically-measured lead-pipe rigidity at UPDRS 0-3.",
        "primary_area": "",
        "author": "Kevin G. Gim;Maxine He;Mahshid Mansouri;Yinan Pei;Evan Ripperger;Christopher M. Zallek;Elizabeth T. Hsiao-Wecksler;Kevin G. Gim;Maxine He;Mahshid Mansouri;Yinan Pei;Evan Ripperger;Christopher M. Zallek;Elizabeth T. Hsiao-Wecksler",
        "authorids": "/37086454794;/37088996893;/37089000765;/37088820726;/37088999958;/37088822727;/38275333200;/37086454794;/37088996893;/37089000765;/37088820726;/37088999958;/37088822727;/38275333200",
        "aff": "Department of Mechanical Science and Engineering, Neuroscience Program, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Mechanical Science and Engineering, Neuroscience Program, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Mechanical Science and Engineering, Neuroscience Program, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Mechanical Science and Engineering, Neuroscience Program, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Mechanical Science and Engineering, Neuroscience Program, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Neurology, OSF HealthCare Illinois Neurological Institute, Peoria, IL, USA; Department of Mechanical Science and Engineering, Neuroscience Program, University of Illinois at Urbana-Champaign, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560891/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10835835819887029586&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;1;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;OSF HealthCare Illinois Neurological Institute",
        "aff_unique_dep": "Department of Mechanical Science and Engineering;Department of Neurology",
        "aff_unique_url": "https://illinois.edu;",
        "aff_unique_abbr": "UIUC;",
        "aff_campus_unique_index": "0;0;0;0;0;1;0",
        "aff_campus_unique": "Urbana;Peoria",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561953",
        "title": "Device Design and System Integration of a Two-Axis Water-immersible Micro Scanning Mirror (WIMSM) to Enable Dual-modal Optical and Acoustic Communication and Ranging for Underwater Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "To address the communication and ranging challenges caused by underwater environment, we design dual modal devices for autonomous underwater vehicles (AUVs). The dual-modal design builds upon a co-axial ultrasonic and green laser beams which leverage different signal diverging patterns and different responses in the underwater environment by each modality to achieve robust adaptability. Here we report our recent progress in improving scanning and aiming capabilities for dual-modal beam steering. The core part is our Two-Axis Water-immersible Micro Scanning Mirror (WIMSM). We improve hinge design of WIMSM for larger scanning range. We incorporate high speed Hall effect sensor-based pose feedback channel to enable closed-loop scanning and aiming control. We design ultrasonic-assisted laser handshaking method to help AUVs to acquire optical underwater communication. We have prototyped our devices and tested them in a water tank. The initial results are promising.",
        "primary_area": "",
        "author": "Xiaoyu Duan;Di Wang;Dezhen Song;Jun Zou;Xiaoyu Duan;Di Wang;Dezhen Song;Jun Zou",
        "authorids": "/37086934509;/37086453325;/37275586600;/37576103200;/37086934509;/37086453325;/37275586600;/37576103200",
        "aff": "Electrical and Computer Engineering Department, Texas A&M University, College Station, TX, USA; Computer Science and Engineering Department, Texas A&M University, College Station, TX, USA; Computer Science and Engineering Department, Texas A&M University, College Station, TX, USA; Electrical and Computer Engineering Department, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561953/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5582951421857632836&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562061",
        "title": "Dexterous Manoeuvre through Touch in a Cluttered Scene",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulation in a densely cluttered environment creates complex challenges in perception to close the control loop, many of which are due to the sophisticated physical interaction between the environment and the manipulator. Drawing from biological sensory-motor control, to handle the task in such a scenario, tactile sensing can be used to provide an additional dimension of the rich contact information from the interaction for decision making and action selection to manoeuvre towards a target. In this paper, a new tactile-based motion planning and control framework based on bioinspiration is proposed and developed for a robot manipulator to manoeuvre in a cluttered environment. An iterative two-stage machine learning approach is used in this framework: an autoencoder is used to extract important cues from tactile sensory readings while a reinforcement learning technique is used to generate optimal motion sequence to efficiently reach the given target. The framework is implemented on a KUKA LBR iiwa robot mounted with a SynTouch BioTac tactile sensor and tested with real-life experiments. The results show that the system is able to move the end-effector through the cluttered environment to reach the target effectively.",
        "primary_area": "",
        "author": "Wenyu Liang;Qinyuan Ren;Xiaoqiao Chen;Junli Gao;Yan Wu;Wenyu Liang;Qinyuan Ren;Xiaoqiao Chen;Junli Gao;Yan Wu",
        "authorids": "/37598507800;/38264350700;/37090017405;/37088686660;/37085344977;/37598507800;/38264350700;/37090017405;/37088686660;/37085344977",
        "aff": "Institute for Infocomm Research (I2R), A*STAR, Singapore; College of Control Science and Engineering, Zhejiang University, Hangzhou, China; College of Control Science and Engineering, Zhejiang University, Hangzhou, China; School of Automation, Guangdong University of Technology, Guangzhou, China; Institute for Infocomm Research (I2R), A*STAR, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562061/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8753331187609864595&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;0",
        "aff_unique_norm": "Institute for Infocomm Research;Zhejiang University;Guangdong University of Technology",
        "aff_unique_dep": ";College of Control Science and Engineering;School of Automation",
        "aff_unique_url": "https://www.i2r.a-star.edu.sg;http://www.zju.edu.cn;",
        "aff_unique_abbr": "I2R;ZJU;",
        "aff_campus_unique_index": "1;1;2",
        "aff_campus_unique": ";Hangzhou;Guangzhou",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9561805",
        "title": "Differentiable Physics Models for Real-world Offline Model-based Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "A limitation of model-based reinforcement learning (MBRL) is the exploitation of errors in the learned models. Blackbox models can fit complex dynamics with high fidelity, but their behavior is undefined outside of the data distribution. Physics-based models are better at extrapolating, due to the general validity of their informed structure, but underfit in the real world due to the presence of unmodeled phenomena. In this work, we demonstrate experimentally that for the offline model-based reinforcement learning setting, physics-based models can be beneficial compared to high-capacity function approximators if the mechanical structure is known. Physics-based models can learn to perform the ball in a cup (BiC) task on a physical manipulator using only 4 minutes of sampled data using offline MBRL. We find that black-box models consistently produce unviable policies for BiC as all predicted trajectories diverge to physically impossible state, despite having access to more data than the physics-based model. In addition, we generalize the approach of physics parameter identification from modeling holonomic multi-body systems to systems with nonholonomic dynamics using end-to-end automatic differentiation.Videos: https://sites.google.com/view/ball-in-a-cup-in-4-minutes/",
        "primary_area": "",
        "author": "Michael Lutter;Johannes Silberbauer;Joe Watson;Jan Peters;Michael Lutter;Johannes Silberbauer;Joe Watson;Jan Peters",
        "authorids": "/37086598847;/37088998478;/37088919632;/37533077600;/37086598847;/37088998478;/37088919632;/37533077600",
        "aff": "Computer Science Department, Technical University of Darmstadt; Computer Science Department, Technical University of Darmstadt; Computer Science Department, Technical University of Darmstadt; Computer Science Department, Technical University of Darmstadt",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561805/",
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8980572163434643911&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Technical University of Darmstadt",
        "aff_unique_dep": "Computer Science Department",
        "aff_unique_url": "https://www.tu-darmstadt.de",
        "aff_unique_abbr": "TUD",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9560754",
        "title": "Differential Information Aided 3-D Registration for Accurate Navigation and Scene Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "A novel 3-dimensional (3-D) alignment method for point-cloud registration is proposed where the time-differential information of the measured points is employed. The new problem turns out to be a novel multi-dimensional optimization. Analytical solution to this optimization is then obtained, which sets the ground of further correspondence matching using k-D trees. Finally, via many examples, we show that the new method owns better registration accuracy in real-world experiments.",
        "primary_area": "",
        "author": "Jin Wu;Shuyang Zhang;Yilong Zhu;Ruoyu Geng;Zhongtao Fu;Fulong Ma;Ming Liu;Jin Wu;Shuyang Zhang;Yilong Zhu;Ruoyu Geng;Zhongtao Fu;Fulong Ma;Ming Liu",
        "authorids": "/37085846883;/37088507304;/37086964447;/37089001275;/37088397858;/37086959093;/37085398677;/37085846883;/37088507304;/37086964447;/37089001275;/37088397858;/37086959093;/37085398677",
        "aff": "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; School of Mechanical and Electronic Engineering, Wuhan Institute of Technology, Wuhan, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560754/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8120441309310531788&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Wuhan Institute of Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;School of Mechanical and Electronic Engineering",
        "aff_unique_url": "https://www.ust.hk;http://www.wit.edu.cn/",
        "aff_unique_abbr": "HKUST;WIT",
        "aff_campus_unique_index": "0;0;0;0;1;0;0",
        "aff_campus_unique": "Hong Kong SAR;Wuhan",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561801",
        "title": "Diffuser: Multi-View 2D-to-3D Label Diffusion for Semantic Scene Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic 3D scene understanding is a fundamental problem in computer vision and robotics. Despite recent advances in deep learning, its application to multi-domain 3D semantic segmentation typically suffers from the lack of extensive enough annotated 3D datasets. On the contrary, 2D neural networks benefit from existing large amounts of training data and can be applied to a wider variety of environments, sometimes even without need for retraining. In this paper, we present \u2018Diffuser\u2019, a novel and efficient multi-view fusion framework that leverages 2D semantic segmentation of multiple image views of a scene to produce a consistent and refined 3D segmentation. We formulate the 3D segmentation task as a transductive label diffusion problem on a graph, where multi-view and 3D geometric properties are used to propagate semantic labels from the 2D image space to the 3D map. Experiments conducted on indoor and outdoor challenging datasets demonstrate the versatility of our approach, as well as its effectiveness for both global 3D scene labeling and single RGB-D frame segmentation. Furthermore, we show a significant increase in 3D segmentation accuracy compared to probabilistic fusion methods employed in several state-of-the-art multi-view approaches, with little computational overhead.",
        "primary_area": "",
        "author": "Ruben Mascaro;Lucas Teixeira;Margarita Chli;Ruben Mascaro;Lucas Teixeira;Margarita Chli",
        "authorids": "/37086455262;/37086010655;/37546501900;/37086455262;/37086010655;/37546501900",
        "aff": "Vision For Robotics Lab, ETH, Zurich, Switzerland; Vision For Robotics Lab, ETH, Zurich, Switzerland; Vision For Robotics Lab, ETH, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561801/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8246817868003249540&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Vision For Robotics Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561990",
        "title": "Direct Force and Pose NMPC with Multiple Interaction Modes for Aerial Push-and-Slide Operations",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a model predictive controller for a fully actuated aerial manipulator to track a hybrid force and pose trajectory at the end-effector in an aerial interaction task. A force sensor at the end-effector is used to detect contact and to directly control the interaction force. We propose an approach for automatic transition between three operation modes which reflect the state of contact constraints, including free flight and two modes for force control based on static or dynamic friction at the end-effector. This division into three modes allows for different mode-specific controller tunings to optimize the desired performance throughout an interaction task. Results from flight experiments which combine force, position, and attitude tracking, show the performance of the controller in terms of accuracy and precision. The performance is further benchmarked against a hybrid force/impedance controller.",
        "primary_area": "",
        "author": "Lazar Peric;Maximilian Brunner;Karen Bodie;Marco Tognon;Roland Siegwart;Lazar Peric;Maximilian Brunner;Karen Bodie;Marco Tognon;Roland Siegwart",
        "authorids": "/37088996664;/37086325079;/37086205816;/37085377048;/37281398300;/37088996664;/37086325079;/37086205816;/37085377048;/37281398300",
        "aff": "Autonomous Systems Lab, ETH Z\u00fcrich, Zurich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Zurich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Zurich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Zurich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561990/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17911977580951484595&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561410",
        "title": "Direct Sparse Stereo Visual-Inertial Global Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust and accurate localization plays a key role in autonomous driving and robot applications. To utilize the complementary properties of different sensors, we present a novel tightly-coupled approach to combine the local (stereo cameras, IMU) and global sensors (magnetometer, GNSS). We jointly optimize all the model parameters through one active window. The visual part integrates constraints from static stereo into the photometric bundle adjustment pipeline of dynamic multiview stereo. Accumulating IMU information between keyframes, magnetometer and GNSS measurements are all inserted into the active window as additional constrains among all the keyframes. Through these, our method can realize globally drift-free and locally accurate state estimation. We evaluate the effectiveness of our system on public datasets under with real-world experiments.",
        "primary_area": "",
        "author": "Ziqiang Wang;Mei Li;Dingkun Zhou;Ziqiang Zheng;Ziqiang Wang;Mei Li;Dingkun Zhou;Ziqiang Zheng",
        "authorids": "/37088999663;/37088998745;/37089001159;/37089000055;/37088999663;/37088998745;/37089001159;/37089000055",
        "aff": "UISEE (Shanghai) Automotive Technologies LTD, Shanghai, China; UISEE (Shanghai) Automotive Technologies LTD, Shanghai, China; UISEE (Shanghai) Automotive Technologies LTD, Shanghai, China; UISEE (Shanghai) Automotive Technologies LTD, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561410/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11049109764277635017&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "UISEE Automotive Technologies",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "UISEE",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561540",
        "title": "Directed Acyclic Graph Neural Network for Human Motion Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Human motion prediction is essential in human-robot interaction. Current research mostly considers the joint dependencies but ignores the bone dependencies and their relationship in the human skeleton, thus limiting the prediction accuracy. To address this issue, we represent the human skeleton as a directed acyclic graph with joints as vertexes and bones as directed edges. Then, we propose a novel directed acyclic graph neural network (DA-GNN) that follows the encoder-decoder structure. The encoder is stacked by multiple encoder blocks, each of which includes a directed acyclic graph computational operator (DA-GCO) to update joint and bone attributes based on the relationship between joint and bone dependencies in the observed human states, and a temporal update operator (TUO) to update the temporal dynamics of joints and bones in the same observation. After progressively implementing the above update process, the encoder outputs the final update result, fed into the decoder. The decoder includes a directed acyclic graph-based gated recurrent unit (DAG-GRU) and a multi-layered perceptron (MLP) to predict future human states sequentially. To the best of our knowledge, this is the first time to introduce the relationship between bone and joint dependencies in human motion prediction. Our experimental evaluations on two datasets, CMU Mocap and Human 3.6m, prove that DA-GNN outperforms current models. Finally, we showcase the efficacy of DA-GNN in a realistic HRI scenario.",
        "primary_area": "",
        "author": "Qin Li;Georgia Chalvatzaki;Jan Peters;Yong Wang;Qin Li;Georgia Chalvatzaki;Jan Peters;Yong Wang",
        "authorids": "/37089001673;/37085353493;/37533077600;/37407534600;/37089001673;/37085353493;/37533077600;/37407534600",
        "aff": "School of Automation, Central South University, Changsha, China; Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; Intelligent Autonomous Systems, Technische Universit\u00e4t Darmstadt, Darmstadt, Germany; School of Automation, Central South University, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561540/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8584814014353639470&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Central South University;Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "School of Automation;Intelligent Autonomous Systems",
        "aff_unique_url": "http://www.csu.edu.cn;https://www.tu-darmstadt.de",
        "aff_unique_abbr": ";TUD",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Changsha;Darmstadt",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "9561402",
        "title": "DisCo RL: Distribution-Conditioned Reinforcement Learning for General-Purpose Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "Can we use reinforcement learning to learn general-purpose policies that can perform a wide range of different tasks, resulting in flexible and reusable skills? Contextual policies provide this capability in principle, but the representation of the context determines the degree of generalization and expressivity. Categorical contexts preclude generalization to entirely new tasks. Goal-conditioned policies may enable some generalization, but cannot capture all tasks that might be desired. In this paper, we propose goal distributions as a general and broadly applicable task representation suitable for contextual policies. Goal distributions are general in the sense that they can represent any state-based reward function when equipped with an appropriate distribution class, while the particular choice of distribution class allows us to trade off expressivity and learnability. We develop an off-policy algorithm called distribution-conditioned reinforcement learning (DisCo RL) to efficiently learn these policies. We evaluate DisCo RL on a variety of robot manipulation tasks and find that it significantly outperforms prior methods on tasks that require generalization to new goal distributions.",
        "primary_area": "",
        "author": "Soroush Nasiriany;Vitchyr H. Pong;Ashvin Nair;Alexander Khazatsky;Glen Berseth;Sergey Levine;Soroush Nasiriany;Vitchyr H. Pong;Ashvin Nair;Alexander Khazatsky;Glen Berseth;Sergey Levine",
        "authorids": "/37089001338;/37085815171;/37086106243;/37088999311;/37085864638;/37085481973;/37089001338;/37085815171;/37086106243;/37088999311;/37085864638;/37085481973",
        "aff": "University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561402/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11728554771001772728&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561010",
        "title": "Discrete Time Delay Feedback Control of Stewart Platform with Intelligent Optimizer Weight Tuner",
        "track": "main",
        "status": "Poster",
        "abstract": "In the presence of complicated kinematic and dynamic, we present a generalizable robust control technique for the 6-Degree of Freedom (6DoF) Stewart integrated platform with revolving, time-delayed torque control actuators to achieve faster, and reliable efficiency for parallel control manipulators. The suggested optimal solution involves the construction of a time-delay Linear Quadratic Integral (LQI) controller integrated with an on-line Artificial Neural Network (ANN) as the cost function gain tuner. The controller is formulated to robustly mitigate the nonlinear system\u2019s real-time tracking error with large time-delay, which is implemented via ADAMS software. The method is validated through simulation experiments to demonstrate that the developed methodology is practical, optimum, and zero-error convergence.",
        "primary_area": "",
        "author": "Farzam Tajdari;Mahsa Tajdari;Amin Rezaei;Farzam Tajdari;Mahsa Tajdari;Amin Rezaei",
        "authorids": "/37085724718;/37088999823;/37085415280;/37085724718;/37088999823;/37085415280",
        "aff": "Mechatronic Design Engineering, Faculty of Industrial Design Engineering, Delft University of Technology, Delft, Netherlands; Department of Mechanical Engineering, Northwestern University, Evanston, IL, USA; Department of Computer Engineering and Computer Science, California State University Long Beach, Long Beach, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561010/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=127059602423782888&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Delft University of Technology;Northwestern University;California State University Long Beach",
        "aff_unique_dep": "Faculty of Industrial Design Engineering;Department of Mechanical Engineering;Department of Computer Engineering and Computer Science",
        "aff_unique_url": "https://www.tudelft.nl;https://www.northwestern.edu;https://www.csulb.edu",
        "aff_unique_abbr": "TU Delft;NU;CSULB",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Delft;Evanston;Long Beach",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Netherlands;United States"
    },
    {
        "id": "9562078",
        "title": "Discriminative Asymmetric Learning for Efficient Surgical Instrument Parsing",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic segmentation of surgical instruments provides essential priors for autonomous surgery. This task is however challenging since the fine-structure of surgical instruments requires the accurate segmentation of detailed regions in images. As the visual guidance for autonomous surgery, the algorithm should also be real-time and friendly to embedded systems. In this paper, a discriminative asymmetric learning framework is proposed to balance the efficiency and effectiveness of surgical instrument segmentation. Two convolutional neural networks with specific designs are deployed to extract the detail and semantic features of instruments. To reduce the redundancy of visual representation, the aggregator-discriminator mechanism is proposed to distinguish the features learned from different levels. Experiments demonstrate that the proposed method contributes to competitive segmentation accuracy and a higher efficiency compared to existing methods.",
        "primary_area": "",
        "author": "Jiaqi Liu;Yu Qiao;Jie Yang;Guang-Zhong Yang;Yun Gu;Jiaqi Liu;Yu Qiao;Jie Yang;Guang-Zhong Yang;Yun Gu",
        "authorids": "/37085463993;/38551616200;/37280203600;/37276270800;/37085529079;/37085463993;/38551616200;/37280203600;/37276270800;/37085529079",
        "aff": "Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, Shanghai, China; Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, Shanghai, China; Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, Shanghai, China; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China; Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562078/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:V4xCBg3W54MJ:scholar.google.com/&scioq=Discriminative+Asymmetric+Learning+for+Efficient+Surgical+Instrument+Parsing&hl=en&as_sdt=0,14",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Institute of Image Processing and Pattern Recognition",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561840",
        "title": "Dispersion-Minimizing Motion Primitives for Search-Based Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Search-based planning with motion primitives is a powerful motion planning technique that can provide dynamic feasibility, optimality, and real-time computation times on size, weight, and power-constrained platforms in unstructured environments. However, optimal design of the motion planning graph, while crucial to the performance of the planner, has not been a main focus of prior work. This paper proposes to address this by introducing a method of choosing vertices and edges in a motion primitive graph that is grounded in sampling theory and leads to theoretical guarantees on planner completeness. By minimizing dispersion of the graph vertices in the metric space induced by trajectory cost, we optimally cover the space of feasible trajectories with our motion primitive graph. In comparison with baseline motion primitives defined by uniform input space sampling, our motion primitive graphs have lower dispersion, find a plan with fewer iterations of the graph search, and have only one parameter to tune.",
        "primary_area": "",
        "author": "Laura Jarin-Lipschitz;James Paulos;Raymond Bjorkman;Vijay Kumar;Laura Jarin-Lipschitz;James Paulos;Raymond Bjorkman;Vijay Kumar",
        "authorids": "/37087015656;/37085335548;/37088996114;/37280341400;/37087015656;/37085335548;/37088996114;/37280341400",
        "aff": "GRASP Laboratory, University of Pennsylvania, PA, USA; GRASP Laboratory, University of Pennsylvania, PA, USA; GRASP Laboratory, University of Pennsylvania, PA, USA; GRASP Laboratory, University of Pennsylvania, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561840/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4111953496650560371&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561017",
        "title": "Distilling a Hierarchical Policy for Planning and Control via Representation and Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a hierarchical planning and control framework that enables an agent to perform various tasks and adapt to a new task flexibly. Rather than learning an individual policy for each particular task, the proposed framework, DISH, distills a hierarchical policy from a set of tasks by representation and reinforcement learning. The framework is based on the idea of latent variable models that represent high-dimensional observations using low-dimensional latent variables. The resulting policy consists of two levels of hierarchy: (i) a planning module that reasons a sequence of latent intentions that would lead to an optimistic future and (ii) a feedback control policy, shared across the tasks, that executes the inferred intention. Because the planning is performed in low-dimensional latent space, the learned policy can immediately be used to solve or adapt to new tasks without additional training. We demonstrate the proposed framework can learn compact representations (3- and 1-dimensional latent states and commands for a humanoid with 197- and 36-dimensional state features and actions) while solving a small number of imitation tasks, and the resulting policy is directly applicable to other types of tasks, i.e., navigation in cluttered environments.",
        "primary_area": "",
        "author": "Jung-Su Ha;Young-Jin Park;Hyeok-Joo Chae;Soon-Seo Park;Han-Lim Choi;Jung-Su Ha;Young-Jin Park;Hyeok-Joo Chae;Soon-Seo Park;Han-Lim Choi",
        "authorids": "/38543013300;/37293567900;/37085589352;/37086550050;/37308867500;/38543013300;/37293567900;/37085589352;/37086550050;/37308867500",
        "aff": "MPI for Intelligent Systems; NAVER CLOVA, NAVER Corp.; KAIST; KAIST; KAIST",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561017/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4904272575845140738&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;2",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;NAVER Corp.;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": ";NAVER CLOVA;",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.naver.com;https://www.kaist.ac.kr",
        "aff_unique_abbr": "MPI-IS;NAVER;KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Germany;South Korea"
    },
    {
        "id": "9561638",
        "title": "Distributed Client-Server Optimization for SLAM with Limited On-Device Resources",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous localization and mapping (SLAM) is a crucial functionality for exploration robots and virtual/augmented reality (VR/AR) devices. However, some of such devices with limited resources cannot afford the computational or memory cost to run full SLAM algorithms. We propose a general client-server SLAM optimization framework that achieves accurate real-time state estimation on the device with low requirements of on-board resources. The resource-limited device (the client) only works on a small part of the map, and the rest of the map is processed by the server. By sending the summarized information of the rest of map to the client, the on-device state estimation is more accurate. Further improvement of accuracy is achieved in the presence of on-device early loop closures, which enables reloading useful variables from the server to the client. Experimental results from both synthetic and real-world datasets demonstrate that the proposed optimization framework achieves accurate estimation in real-time with limited computation and memory budget of the device.",
        "primary_area": "",
        "author": "Yetong Zhang;Ming Hsiao;Yipu Zhao;Jing Dong;Jakob J. Engel;Yetong Zhang;Ming Hsiao;Yipu Zhao;Jing Dong;Jakob J. Engel",
        "authorids": "/37088998216;/37089397066;/37085797326;/37088451595;/38541523200;/37088998216;/37089397066;/37085797326;/37088451595;/38541523200",
        "aff": "College of Computing, Georgia Institute of Technology, Atlanta, USA; Facebook Reality Labs Research, Redmond, USA; Facebook Reality Labs Research, Redmond, USA; Facebook Reality Labs Research, Redmond, USA; Facebook Reality Labs Research, Redmond, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561638/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12845608623945646464&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Georgia Institute of Technology;Meta",
        "aff_unique_dep": "College of Computing;Research",
        "aff_unique_url": "https://www.gatech.edu;https://www.facebook.com/realitylabs",
        "aff_unique_abbr": "Georgia Tech;FRL",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Atlanta;Redmond",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561612",
        "title": "Distributed Dynamic Map Fusion via Federated Learning for Intelligent Networked Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "The technology of dynamic map fusion among networked vehicles has been developed to enlarge sensing ranges and improve sensing accuracies for individual vehicles. This paper proposes a federated learning (FL) based dynamic map fusion framework to achieve high map quality despite unknown numbers of objects in fields of view (FoVs), various sensing and model uncertainties, and missing data labels for online learning. The novelty of this work is threefold: (1) developing a three-stage fusion scheme to predict the number of objects effectively and to fuse multiple local maps with fidelity scores; (2) developing an FL algorithm which fine-tunes feature models (i.e., representation learning networks for feature extraction) distributively by aggregating model parameters; (3) developing a knowledge distillation method to generate FL training labels when data labels are unavailable. The proposed framework is implemented in the CARLA simulation platform. Extensive experimental results are provided to verify the superior performance and robustness of the developed map fusion and FL schemes.",
        "primary_area": "",
        "author": "Zijian Zhang;Shuai Wang;Yuncong Hong;Liangkai Zhou;Qi Hao;Zijian Zhang;Shuai Wang;Yuncong Hong;Liangkai Zhou;Qi Hao",
        "authorids": "/37088996269;/37090019250;/37088692025;/37087885545;/37403530000;/37088996269;/37090019250;/37088692025;/37087885545;/37403530000",
        "aff": "Harbin Institute of Technology, Harbin, China; Sifakis Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology, Shenzhen, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China; Pazhou Lab, Guangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561612/",
        "gs_citation": 87,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5088025601740463578&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;2",
        "aff_unique_norm": "Harbin Institute of Technology;Southern University of Science and Technology;Pazhou Lab",
        "aff_unique_dep": ";Sifakis Research Institute of Trustworthy Autonomous Systems;",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.sustech.edu.cn;",
        "aff_unique_abbr": "HIT;;",
        "aff_campus_unique_index": "0;1;1;1;2",
        "aff_campus_unique": "Harbin;Shenzhen;Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561551",
        "title": "Distributed Full-Consensus Control of Multi-Robot Systems with Range and Field-of-View Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we solve the full-consensus problem for multiple nonholonomic vehicles interacting over a directed leader-follower topology and subject to sensing constraints in the form of limited range and limited field-of-view. Remarkably, based on a polar-coordinates model transformation, the designed controller is time-invariant and smooth (in the domain of definition). Moreover, the control laws rely only on local measurements, making it well suited for implementation. The asymptotic convergence to the consensus manifold as well as the respect of the constraints is established using Lyapunov\u2019s first method and cascaded systems theory. Realistic simulations in the Gazebo-ROS environment, which illustrate the effectiveness of our theoretical contributions, are shown in an accompanying video.",
        "primary_area": "",
        "author": "Esteban Restrepo;Antonio Lor\u00eda;Ioannis Sarras;Julien Marzat;Esteban Restrepo;Antonio Lor\u00eda;Ioannis Sarras;Julien Marzat",
        "authorids": "/37088444894;/37273792000;/37398662500;/37857075800;/37088444894;/37273792000;/37398662500;/37857075800",
        "aff": "L2S-CentraleSup\u00e9lec, Universit\u00e9 Paris-Saclay, Saclay, France; L2S-CentraleSup\u00e9lec, Universit\u00e9 Paris-Saclay, Saclay, France; DTIS, ONERA, Universit\u00e9 Paris-Saclay, Palaiseau, France; DTIS, ONERA, Universit\u00e9 Paris-Saclay, Palaiseau, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561551/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7915645036316558875&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "CentraleSup\u00e9lec;ONERA",
        "aff_unique_dep": "L2S;DTIS",
        "aff_unique_url": "https://www.centrale-supelec.fr;https://www.onera.fr",
        "aff_unique_abbr": "L2S;ONERA",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Saclay;Palaiseau",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9560748",
        "title": "Distributed Heuristic Multi-Agent Path Finding with Communication",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-Agent Path Finding (MAPF) is essential to large-scale robotic systems. Recent methods have applied reinforcement learning (RL) to learn decentralized polices in partially observable environments. A fundamental challenge of obtaining collision-free policy is that agents need to learn co-operation to handle congested situations. This paper combines communication with deep Q-learning to provide a novel learning based method for MAPF, where agents achieve cooperation via graph convolution. To guide RL algorithm on long-horizon goal-oriented tasks, we embed the potential choices of shortest paths from single source as heuristic guidance instead of using a specific path as in most existing works. Our method treats each agent independently and trains the model from a single agent\u2019s perspective. The final trained policy is applied to each agent for decentralized execution. The whole system is distributed during training and is trained under a curriculum learning strategy. Empirical evaluation in obstacle-rich environment indicates the high success rate with low average step of our method.",
        "primary_area": "",
        "author": "Ziyuan Ma;Yudong Luo;Hang Ma;Ziyuan Ma;Yudong Luo;Hang Ma",
        "authorids": "/37087231574;/37089000890;/37088998793;/37087231574;/37089000890;/37088998793",
        "aff": "School of Computing Science, Simon Fraser University, Canada; School of Computing Science, Simon Fraser University, Canada; School of Computing Science, Simon Fraser University, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560748/",
        "gs_citation": 111,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14749746278908328117&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Simon Fraser University",
        "aff_unique_dep": "School of Computing Science",
        "aff_unique_url": "https://www.sfu.ca",
        "aff_unique_abbr": "SFU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561637",
        "title": "Distributed Motion Coordination Using Convex Feasible Set Based Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "The implementation of optimization-based motion coordination approaches in real world multi-agent systems remains challenging due to their high computational complexity and potential deadlocks. This paper presents a distributed model predictive control (MPC) approach based on convex feasible set (CFS) algorithm for multi-vehicle motion coordination in autonomous driving. By using CFS to convexify the collision avoidance constraints, collision-free trajectories can be computed in real time. We analyze the potential deadlocks and show that a deadlock can be resolved by changing vehicles\u2019 desired speeds. The MPC structure ensures that our algorithm is robust to low-level tracking errors. The proposed distributed method has been tested in multiple challenging multi-vehicle environments, including unstructured road, intersection, crossing, platoon formation, merging, and overtaking scenarios. The numerical results and comparison with other approaches (including a centralized MPC and reciprocal velocity obstacles) show that the proposed method is computationally efficient and robust, and avoids deadlocks.",
        "primary_area": "",
        "author": "Hongyu Zhou;Changliu Liu;Hongyu Zhou;Changliu Liu",
        "authorids": "/37089001983;/37085543217;/37089001983;/37085543217",
        "aff": "Department of Marine Technology, Noweigian University of Science and Technology, Trondheim, Norway; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561637/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7301339117694455840&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Norwegian University of Science and Technology;Carnegie Mellon University",
        "aff_unique_dep": "Department of Marine Technology;The Robotics Institute",
        "aff_unique_url": "https://www.ntnu.edu;https://www.cmu.edu",
        "aff_unique_abbr": "NTNU;CMU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Trondheim;Pittsburgh",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Norway;United States"
    },
    {
        "id": "9561888",
        "title": "Distributed Multi-Target Tracking for Heterogeneous Mobile Sensing Networks with Limited Field of Views",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces the normalized unused sensing capacity to measure the amount of information that a sensor is currently gathering relative to its theoretical maximum. This quantity can be computed using entirely local information and works for arbitrary sensor models, unlike previous literature on the subject. This is then used to develop a distributed coverage control strategy for a team of heterogeneous sensors that automatically balances the load based on the current unused capacity of each team member. This algorithm is validated in a multi-target tracking scenario, yielding superior results to standard approaches that do not account for heterogeneity or current usage rates.",
        "primary_area": "",
        "author": "Jun Chen;Philip Dames;Jun Chen;Philip Dames",
        "authorids": "/37088479962;/38547257300;/37088479962;/38547257300",
        "aff": "Department of Mechanical Engineering, Temple University, Philadelphia, PA, USA; Department of Mechanical Engineering, Temple University, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561888/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=139575304679048246&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Temple University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.temple.edu",
        "aff_unique_abbr": "Temple",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562055",
        "title": "Distributed Multi-Target Tracking in Camera Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Most recent works on multi-target tracking with multiple cameras focus on centralized systems. In contrast, this paper presents a multi-target tracking approach implemented in a distributed camera network. The advantages of distributed systems lie in lighter communication management, greater robustness to failures and local decision making. On the other hand, data association and information fusion are more challenging than in a centralized setup, mostly due to the lack of global and complete information. The proposed algorithm boosts the benefits of the Distributed-Consensus Kalman Filter with the support of a re-identification network and a distributed tracker manager module to facilitate consistent information. These techniques complement each other and facilitate the cross-camera data association in a simple and effective manner. We evaluate the whole system with known public data sets under different conditions demonstrating the advantages of combining all the modules. In addition, we compare our algorithm to some existing centralized tracking methods, outperforming their behavior in terms of accuracy and bandwidth usage.",
        "primary_area": "",
        "author": "Sara Casao;Abel Naya;Ana C. Murillo;Eduardo Montijano;Sara Casao;Abel Naya;Ana C. Murillo;Eduardo Montijano",
        "authorids": "/37088996416;/37089000703;/37393616700;/37681715400;/37088996416;/37089000703;/37393616700;/37681715400",
        "aff": "RoPeRt group, at DIIS - I3A, Universidad de Zaragoza, Spain; RoPeRt group, at DIIS - I3A, Universidad de Zaragoza, Spain; RoPeRt group, at DIIS - I3A, Universidad de Zaragoza, Spain; RoPeRt group, at DIIS - I3A, Universidad de Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562055/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3872021521216506328&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Universidad de Zaragoza",
        "aff_unique_dep": "DIIS - I3A",
        "aff_unique_url": "https://www.unizar.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9561194",
        "title": "Distributed Rendezvous Control of Networked Uncertain Robotic Systems with Bearing Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, the distributed rendezvous control problem of networked uncertain robotic systems with bearing measurements is investigated. The network topology of the multi-robot systems is described by an undirected graph. The dynamics of robots is modeled by Euler-Lagrange equation with unknown inertial parameters, which is more general than simple kinematics considered in existing works on rendezvous problem of multi-robot systems. To achieve rendezvous, a distributed adaptive force/torque control law is developed for each robot, which uses bearings with respect to its neighbors instead of relative displacements or distances. It is shown that the resulting closed-loop multi-robot systems are globally asymptotically stable. Then, the rendezvous control problem of multiple wheeled mobile robots is further solved by the proposed approach. Finally, on-site experiment on networked TurtleBot3 Burger mobile robots is conducted and the results demonstrate effectiveness of the proposed approach.",
        "primary_area": "",
        "author": "Jianing Zhao;Hanjiang Hu;Keyi Zhu;Xiao Yu;Hesheng Wang;Jianing Zhao;Hanjiang Hu;Keyi Zhu;Xiao Yu;Hesheng Wang",
        "authorids": "/37088425490;/37087321985;/37088997733;/37086354985;/37292567100;/37088425490;/37087321985;/37088997733;/37086354985;/37292567100",
        "aff": "Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai, China; Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai, China; Key Laboratory of System Control and Information Processing, Ministry of Education of China, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561194/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:P3udmwd7HKUJ:scholar.google.com/&scioq=Distributed+Rendezvous+Control+of+Networked+Uncertain+Robotic+Systems+with+Bearing+Measurements&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Key Laboratory of System Control and Information Processing;Shanghai Jiao Tong University",
        "aff_unique_dep": "Ministry of Education of China;School of Mechanical Engineering",
        "aff_unique_url": ";https://www.sjtu.edu.cn",
        "aff_unique_abbr": ";SJTU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561721",
        "title": "Distributed Topology Correction for Flexible Connectivity Maintenance in Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-robot systems can perform task-related collaborative behaviors while maintaining connectivity within the system. However, some robots may fail to execute tasks or converge relatively slowly due to connectivity constraints. We consider the case that some robots may not have tasks assigned at a certain time frame, and they may help the task robots to achieve their goals by forming a connectivity graph with flexible topology. Therefore, we introduce a topology correction controller to provide flexibility for the task robots to perform task behaviors by modifying the topology of the connectivity graph for a faster convergence rate. We propose a distributed approach of blending weighted rendezvous and weighted flocking to form the correction controller. We prove that this scheme can guarantee a faster convergence rate and provide flexible connectivity graph topology. We then present our result of a system of up to thirty robots in various cluttered environments and show that our approach of behavior combination is robust and scalable.",
        "primary_area": "",
        "author": "Sha Yi;Wenhao Luo;Katia Sycara;Sha Yi;Wenhao Luo;Katia Sycara",
        "authorids": "/37088506867;/37085748889;/37268476900;/37088506867;/37085748889;/37268476900",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561721/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11207956469961103417&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560944",
        "title": "Distributed Variable-Baseline Stereo SLAM from two UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual-Inertial Odometry (VIO) has been widely used and researched to control and aid the automation of navigation of robots especially in the absence of absolute position measurements, such as GPS. However, when the observable landmarks in the scene lie far away, as in high-altitude flights for example, the fidelity of the metric scale estimate in VIO greatly degrades. Aiming to tackle this issue, in this work, we utilize the virtual stereo setup formed by two Unmanned Aerial Vehicles (UAVs), equipped with one camera and one Inertial Measurement Unit (IMU) each, exploiting their view overlap and relative distance measurements between them using onboard Ultra-Wideband (UWB) modules to enable collaborative VIO. In particular, we propose a decentralized collaborative estimation scheme, where each agent holds its own local map, achieving a low pose estimation latency, while ensuring consistency of each agents\u2019 estimates via consensus-based optimization. Following a thorough evaluation in photorealistic simulations, we demonstrate the effectiveness of the approach at high-altitude flights of up to 160m, going significantly beyond the capabilities of state-of-the-art VIO methods. Finally, we show the advantage of actively adjusting the baseline on-the-fly over a fixed, target baseline, resulting in a significant reduction of the estimation error.",
        "primary_area": "",
        "author": "Marco Karrer;Margarita Chli;Marco Karrer;Margarita Chli",
        "authorids": "/37086206672;/37546501900;/37086206672;/37546501900",
        "aff": "Vision for Robotics Lab, ETH Zurich, Switzerland; Vision for Robotics Lab, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560944/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17849097558843413361&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Vision for Robotics Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9560845",
        "title": "Distributed coordinated path following using guiding vector fields",
        "track": "main",
        "status": "Poster",
        "abstract": "It is essential in many applications to impose a scalable coordinated motion control on a large group of mobile robots, which is efficient in tasks requiring repetitive execution, such as environmental monitoring. In this paper, we design a guiding vector field to guide multiple robots to follow possibly different desired paths while coordinating their motions. The vector field uses a path parameter as a virtual coordinate that is communicated among neighboring robots. Then, the virtual coordinate is utilized to control the relative parametric displacement between robots along the paths. This enables us to design a saturated control algorithm for a Dubins-car-like model. The algorithm is distributed, scalable, and applicable for any smooth paths in an n-dimensional configuration space, and global convergence is guaranteed. Simulations with up to fifty robots and outdoor experiments with fixed-wing aircraft validate the theoretical results.",
        "primary_area": "",
        "author": "Weijia Yao;Hector Garcia de Marina;Zhiyong Sun;Ming Cao;Weijia Yao;Hector Garcia de Marina;Zhiyong Sun;Ming Cao",
        "authorids": "/37085671673;/37085561510;/37085395704;/37293296100;/37085671673;/37085561510;/37085395704;/37293296100",
        "aff": "University of Groningen, the Netherlands; Universidad Complutense de Madrid, Spain; Eindhoven University of Technology, the Netherlands; University of Groningen, the Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560845/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3369110124314247735&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Groningen;Universidad Complutense de Madrid;Eindhoven University of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.rug.nl;https://www.ucm.es;https://www.tue.nl/",
        "aff_unique_abbr": "RUG;UCM;TU/e",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Netherlands;Spain"
    },
    {
        "id": "9561086",
        "title": "Do You See What I See? Coordinating Multiple Aerial Cameras for Robot Cinematography",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial cinematography is significantly expanding the capabilities of film-makers. Recent progress in autonomous unmanned aerial vehicles (UAVs) has further increased the potential impact of aerial cameras, with systems that can safely track actors in unstructured cluttered environments. Professional productions, however, require the use of multiple cameras simultaneously to record different viewpoints of the same scene, which are edited into the final footage either in real time or in post-production. Such extreme motion coordination is particularly hard for unscripted action scenes, which are a common use case of aerial cameras. In this work we develop a real-time multi-UAV coordination system that is capable of recording dynamic targets while maximizing shot diversity and avoiding collisions and mutual visibility between cameras. We validate our approach in multiple cluttered environments of a photo-realistic simulator, and deploy the system using two UAVs in real-world experiments. We show that our coordination scheme has low computational cost and takes only 1.17 ms on average to plan for a team of 3 UAVs over a 10 s time horizon. Supplementary video: https://youtu.be/m2R3anv2ADE",
        "primary_area": "",
        "author": "Arthur Bucker;Rogerio Bonatti;Sebastian Scherer;Arthur Bucker;Rogerio Bonatti;Sebastian Scherer",
        "authorids": "/37089000770;/37086934741;/37584159000;/37089000770;/37086934741;/37584159000",
        "aff": "University of S\u00e3o Paulo, Brazil; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561086/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17436499860700921044&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of S\u00e3o Paulo;Carnegie Mellon University",
        "aff_unique_dep": ";The Robotics Institute",
        "aff_unique_url": "https://www.usp.br;https://www.cmu.edu",
        "aff_unique_abbr": "USP;CMU",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Pittsburgh",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Brazil;United States"
    },
    {
        "id": "9562033",
        "title": "Docking and Undocking a Modular Underactuated Oscillating Swimming Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "We describe a docking mechanism and strategy to allow modular self-assembly for the Modboat: an inexpensive, underactuated, oscillating, surface-swimming robot powered by a single motor. Because propulsion is achieved through oscillation, orientation can be controlled only in the average; this complicates docking, which requires precise position and orientation control. Given these challenges, we present a docking strategy and a motion primitive for controlling orientation, and show that this strategy allows successful docking in multiple configurations. Moreover, we demonstrate that the Modboat is also capable of undocking and changing its dock configuration, all without any additional actuation. This is unique among similar modular robotic systems.",
        "primary_area": "",
        "author": "Gedaliah Knizhnik;Mark Yim;Gedaliah Knizhnik;Mark Yim",
        "authorids": "/37086285239;/37274063600;/37086285239;/37274063600",
        "aff": "GRASP Laboratory, University of Pensylvannia, Philadelphia, PA; GRASP Laboratory, University of Pensylvannia, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562033/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8613332226852800809&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562116",
        "title": "Don\u2019t Blindly Trust Your CNN: Towards Competency-Aware Object Detection by Evaluating Novelty in Open-Ended Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-world missions require robots to detect objects in complex and changing environments. While deep learning methods for object detection are able to achieve a high level of performance, they can be unreliable when operating in environments that deviate from training conditions. However, by applying novelty detection techniques, we aim to build an architecture aware of when it cannot make reliable classifications, as well as identifying novel features/data. In this work, we have proposed and evaluated a system that assesses the competence of trained Convolutional Neural Networks (CNNs). This is achieved using three complementary introspection methods: (1) a Convolutional Variational Auto-Encoder (VAE), (2) a latent space Density-adjusted Distance Measure (DDM), and (3) a Spearman\u2019s Rank Correlation (SRC) based approach. Finally these approaches are combined through a weighted sum, with weightings derived by maximising the correct attribution of novelty in an adversarial \u2018meta-game\u2019. Our experiments were conducted on real-world data from three datasets spread across two different domains: a planetary and an industrial setting. Results show that the proposed introspection methods are able to detect misclassifications and unknown classes indicative of novel features/data in both domains with up to 67% precision. Meanwhile classification results were either maintained or improved as a result.",
        "primary_area": "",
        "author": "Rhys Howard;Sam Barrett;Lars Kunze;Rhys Howard;Sam Barrett;Lars Kunze",
        "authorids": "/37088998864;/37089041848;/37947285100;/37088998864;/37089041848;/37947285100",
        "aff": "Department of Engineering Science, Oxford Robotics Institute, University of Oxford, Oxford, UK; Department of Engineering Science, Oxford Robotics Institute, University of Oxford, Oxford, UK; Department of Engineering Science, Oxford Robotics Institute, University of Oxford, Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562116/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8713233839598007364&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Engineering Science",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561219",
        "title": "Double Meta-Learning for Data Efficient Policy Optimization in Non-Stationary Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We are interested in learning models of non-stationary environments, which can be framed as a multitask learning problem. Model-free reinforcement learning algorithms can achieve good asymptotic performance in multitask learning at a cost of extensive sampling, due to their approach, which requires learning from scratch. While model-based approaches are among the most data efficient learning algorithms, they still struggle with complex tasks and model uncertainties. Meta-reinforcement learning addresses the efficiency and generalization challenges on multi task learning by quickly leveraging the meta-prior policy for a new task. In this paper, we propose a meta-reinforcement learning approach to learn the dynamic model of a non-stationary environment to be used for meta-policy optimization later. Due to the sample efficiency of model-based learning methods, we are able to simultaneously train both the meta-model of the non-stationary environment and the meta-policy until dynamic model convergence. Then, the meta-learned dynamic model of the environment will generate simulated data for meta-policy optimization. Our experiment demonstrates that our proposed method can meta-learn the policy in a non-stationary environment with the data efficiency of model-based learning approaches while achieving the high asymptotic performance of model-free meta-reinforcement learning.",
        "primary_area": "",
        "author": "Elahe Aghapour;Nora Ayanian;Elahe Aghapour;Nora Ayanian",
        "authorids": "/37085857187;/37546534600;/37085857187;/37546534600",
        "aff": "Department of Computer Science, University of Southern California, USA; Department of Computer Science, University of Southern California, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561219/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15436271200969457279&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561940",
        "title": "Double-Prong ConvLSTM for Spatiotemporal Occupancy Prediction in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting the future occupancy state of an environment is important to enable informed decisions for autonomous vehicles. Common challenges in occupancy prediction include vanishing dynamic objects and blurred predictions, especially for long prediction horizons. In this work, we propose a double-prong neural network architecture to predict the spatiotemporal evolution of the occupancy state. One prong is dedicated to predicting how the static environment will be observed by the moving ego vehicle. The other prong predicts how the dynamic objects in the environment will move. Experiments conducted on the real-world Waymo Open Dataset indicate that the fused output of the two prongs is capable of retaining dynamic objects and reducing blurriness in the predictions for longer time horizons than baseline models.",
        "primary_area": "",
        "author": "Maneekwan Toyungyernsub;Masha Itkina;Ransalu Senanayake;Mykel J. Kochenderfer;Maneekwan Toyungyernsub;Masha Itkina;Ransalu Senanayake;Mykel J. Kochenderfer",
        "authorids": "/37088596307;/37087102957;/38490726500;/37596929200;/37088596307;/37087102957;/38490726500;/37596929200",
        "aff": "Stanford University, CA, USA; Stanford University, CA, USA; Stanford University, CA, USA; Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561940/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11414632074488400155&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "California",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560734",
        "title": "Dreaming: Model-based Reinforcement Learning by Latent Imagination without Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "In the present paper, we propose a decoder-free extension of Dreamer, a leading model-based reinforcement learning (MBRL) method from pixels. Dreamer is a sample- and cost-efficient solution to robot learning, as it is used to train latent state-space models based on a variational autoencoder and to conduct policy optimization by latent trajectory imagination. However, this autoencoding based approach often causes object vanishing, in which the autoencoder fails to perceives key objects for solving control tasks, and thus significantly limiting Dreamer's potential. This work aims to relieve this Dreamer's bottleneck and enhance its performance by means of removing the decoder. For this purpose, we firstly derive a likelihood- free and InfoMax objective of contrastive learning from the evidence lower bound of Dreamer. Secondly, we incorporate two components, (i) independent linear dynamics and (ii) the random crop data augmentation, to the learning scheme so as to improve the training performance. In comparison to Dreamer and other recent model-free reinforcement learning methods, our newly devised Dreamer with InfoMax and without generative decoder (Dreaming) achieves the best scores on 5 difficult simulated robotics tasks, in which Dreamer suffers from object vanishing.",
        "primary_area": "",
        "author": "Masashi Okada;Tadahiro Taniguchi;Masashi Okada;Tadahiro Taniguchi",
        "authorids": "/37086454122;/37273806600;/37086454122;/37273806600",
        "aff": "Digitan & AI Technology Center, Technology Division, Panasonic Corporation, Japan; College of Information Science and Engineering, Ritsumeikan University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560734/",
        "gs_citation": 88,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14964622532886171129&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Panasonic Corporation;Ritsumeikan University",
        "aff_unique_dep": "Technology Division;College of Information Science and Engineering",
        "aff_unique_url": "https://www.panasonic.com;https://www.ritsumei.ac.jp",
        "aff_unique_abbr": "Panasonic;Ritsumeikan",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561943",
        "title": "Drumming Arm: an Upper-limb Prosthetic System to Restore Grip Control for a Transradial Amputee Drummer",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes a quasi-passive transradial prosthesis designed to restore drumstick grip control for amputee drummers. A compact motor with low rotor resistance driven by Electromyography (EMG) is implemented in the prosthesis to support real-time drum performances. A variety of grip profiles are achieved by adjusting the stiffness and damping of an impedance controller based on machine learning predictions from EMG data. In addition to the prosthetic design, the paper presents a dynamic model that simulates the drumstick trajectories and estimates the control gains for various natural bouncing patterns. We evaluate the effectiveness of the design through human experiments under real-time performing scenarios for two common drumming grip techniques. The results demonstrate that the prosthetic model can support similar bouncing patterns to the drummer\u2019s healthy hand for single, double, and triple-stroke rolling techniques. The results also show that the system supports usable real-time periodic grip change from single to double-stroke, successfully simulating the common paradiddle drumming technique.",
        "primary_area": "",
        "author": "Ning Yang;Ruizhi Sha;Raghavasimhan Sankaranarayanan;Qianyi Sun;Gil Weinberg;Ning Yang;Ruizhi Sha;Raghavasimhan Sankaranarayanan;Qianyi Sun;Gil Weinberg",
        "authorids": "/37088998270;/37088996392;/37088996731;/37089001703;/37540868300;/37088998270;/37088996392;/37088996731;/37089001703;/37540868300",
        "aff": "Georgia Tech Center for Music Technology (GTCMT), Georgia Institute of Technology, Atlanta, GA, USA; State Key Laboratory for Manufacturing Systems Engineering, Systems Engineering Institute, Faculty of Electronic and Information Engineering, Xi\u2019an Jiaotong University, Xi\u2019an, China; Georgia Tech Center for Music Technology (GTCMT), Georgia Institute of Technology, Atlanta, GA, USA; Georgia Tech Center for Music Technology (GTCMT), Georgia Institute of Technology, Atlanta, GA, USA; Georgia Tech Center for Music Technology (GTCMT), Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561943/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16381133034480701046&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology;Xi'an Jiao Tong University",
        "aff_unique_dep": "Center for Music Technology;Faculty of Electronic and Information Engineering",
        "aff_unique_url": "https://www.gatech.edu;http://www.xjtu.edu.cn",
        "aff_unique_abbr": "Georgia Tech;XJTU",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Atlanta;Xi'an",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9562054",
        "title": "Dual-Arm Needle Manipulation with the da Vinci\u00ae Surgical Robot Under Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a path correction method for surgical robotic systems performing needle handoff manipulations as part of autonomous execution of surgical suturing. During handoff motions, the position and orientation of the needle is subject to perturbations from the idealized planned pose due to uncertainties in camera-robot calibration and needle localization. If, after a perturbation, the system needs to perform subsequent needle regrasp(s), but the robot still follows the originally planned trajectory out of the path planner [1], it has a lower chance of gripping the needle properly. In order to accommodate these unpredictable needle pose perturbations, the proposed path correction method works locally to direct the needle from the wrong pose to the original pose by partial replanning of the robot motion. The reliability of the proposed method is evaluated with three sets of experiments in a simulation environment.",
        "primary_area": "",
        "author": "Su Lu;Thomas Shkurti;M. Cenk \u00c7avu\u0219o\u011flu;Su Lu;Thomas Shkurti;M. Cenk \u00c7avu\u0219o\u011flu",
        "authorids": "/37088650666;/37086455629;/37373298800;/37088650666;/37086455629;/37373298800",
        "aff": "Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH, USA; Department of Computer and Data Sciences, Case Western Reserve University, Cleveland, OH, USA; Department of Electrical, Computer, and Systems Engineering, Case Western Reserve University, Cleveland, OH, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562054/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8175508660970933209&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Case Western Reserve University",
        "aff_unique_dep": "Department of Electrical, Computer, and Systems Engineering",
        "aff_unique_url": "https://www.case.edu",
        "aff_unique_abbr": "CWRU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cleveland",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560866",
        "title": "Dynamic Compensation in Throwing Motion with High-Speed Robot Hand-Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, research and development have been carried out on manipulators equipped with multi-fingered robot hands as end-effectors to perform delicate and dexterous tasks. In high-speed movement of such multi-fingered hand-arms, the weight of the multi-fingered hands slows down the response of the arms. To solve this problem, we propose a control method in which a high-response hand is used to compensate for the delay in a low-response arm in the task of throwing a ball. In particular, the accuracy of the pitching motion is improved by predicting tracking errors based on the arm dynamics and using nonlinear model predictive control to compensate for arm tracking errors by using the hand motion. Experimental results of ball throwing are shown.",
        "primary_area": "",
        "author": "Akira Takahashi;Masaki Sato;Akio Namiki;Akira Takahashi;Masaki Sato;Akio Namiki",
        "authorids": "/37088686818;/37088686192;/37273962400;/37088686818;/37088686192;/37273962400",
        "aff": "Graduate School of Science and Engineering, Chiba University, Chiba, Japan; Graduate School of Science and Engineering, Chiba University, Chiba, Japan; Graduate School of Science and Engineering, Chiba University, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560866/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11378647316996256149&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chiba University",
        "aff_unique_dep": "Graduate School of Science and Engineering",
        "aff_unique_url": "https://www.chiba-u.ac.jp",
        "aff_unique_abbr": "Chiba U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chiba",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561120",
        "title": "Dynamic Movement Primitive based Motion Retargeting for Dual-Arm Sign Language Motions",
        "track": "main",
        "status": "Poster",
        "abstract": "We aim to develop an efficient programming method for equipping service robots with the skill of performing sign language motions. This paper addresses the problem of transferring complex dual-arm sign language motions characterized by the coordination among arms and hands from human to robot, which is seldom considered in previous studies of motion retargeting techniques. In this paper, we propose a novel motion retargeting method that leverages graph optimization and Dynamic Movement Primitives (DMPs) for this problem. We employ DMPs in a leader-follower manner to parameterize the original trajectories while preserving motion rhythm and relative movements between human body parts, and adopt a three-step optimization procedure to find deformed trajectories for robot motion planning while ensuring feasibility for robot execution. Experimental results of several Chinese Sign Language (CSL) motions have been successfully performed on ABB\u2019s YuMi dual-arm collaborative robot (14-DOF) with two 6-DOF Inspire-Robotics\u2019 multi-fingered hands, a system with 26 DOFs in total.",
        "primary_area": "",
        "author": "Yuwei Liang;Weijie Li;Yue Wang;Rong Xiong;Yichao Mao;Jiafan Zhang;Yuwei Liang;Weijie Li;Yue Wang;Rong Xiong;Yichao Mao;Jiafan Zhang",
        "authorids": "/37087246486;/37089000146;/37072299700;/37271511300;/37086602471;/37407593200;/37087246486;/37089000146;/37072299700;/37271511300;/37086602471;/37407593200",
        "aff": "Robotics Laboratory, Institute of Cyber-Systems and Control, Zhejiang University, China; Robotics Laboratory, Institute of Cyber-Systems and Control, Zhejiang University, China; Robotics Laboratory, Institute of Cyber-Systems and Control, Zhejiang University, China; Robotics Laboratory, Institute of Cyber-Systems and Control, Zhejiang University, China; ABB Corporate Research Center, China; ABB Corporate Research Center, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561120/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12664707063015962404&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;1",
        "aff_unique_norm": "Zhejiang University;ABB Corporate Research Center",
        "aff_unique_dep": "Institute of Cyber-Systems and Control;",
        "aff_unique_url": "http://www.zju.edu.cn;https://new.abb.com/research",
        "aff_unique_abbr": "ZJU;ABB CRC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560730",
        "title": "Dynamic Object Aware LiDAR SLAM based on Automatic Generation of Training Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Highly dynamic environments, with moving objects such as cars or humans, can pose a performance challenge for LiDAR SLAM systems that assume largely static scenes. To overcome this challenge and support the deployment of robots in real world scenarios, we propose a complete solution for a dynamic object aware LiDAR SLAM algorithm. This is achieved by leveraging a real-time capable neural network that can detect dynamic objects, thus allowing our system to deal with them explicitly. To efficiently generate the necessary training data which is key to our approach, we present a novel end-to-end occupancy grid based pipeline that can automatically label a wide variety of arbitrary dynamic objects. Our solution can thus generalize to different environments without the need for expensive manual labeling and at the same time avoids assumptions about the presence of a predefined set of known objects in the scene. Using this technique, we automatically label over 12000 LiDAR scans collected in an urban environment with a large amount of pedestrians and use this data to train a neural network, achieving an average segmentation IoU of 0.82. We show that explicitly dealing with dynamic objects can improve the LiDAR SLAM odometry performance by 39.6% while yielding maps which better represent the environments. A supplementary video1 as well as our test data2 are available online.",
        "primary_area": "",
        "author": "Patrick Pfreundschuh;Hubertus F.C. Hendrikx;Victor Reijgwart;Renaud Dub\u00e9;Roland Siegwart;Andrei Cramariuc;Patrick Pfreundschuh;Hubertus F.C. Hendrikx;Victor Reijgwart;Renaud Dub\u00e9;Roland Siegwart;Andrei Cramariuc",
        "authorids": "/37088687507;/37086454135;/37086454863;/37085782572;/37281398300;/37085840497;/37088687507;/37086454135;/37086454863;/37085782572;/37281398300;/37085840497",
        "aff": "Sevensense Robotics AG; Sevensense Robotics AG; Autonomous Systems Lab, ETH Z\u00fcrich; Sevensense Robotics AG; Autonomous Systems Lab, ETH Z\u00fcrich; Autonomous Systems Lab, ETH Z\u00fcrich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560730/",
        "gs_citation": 99,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17620674298178884634&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;1;1",
        "aff_unique_norm": "Sevensense Robotics;ETH Zurich",
        "aff_unique_dep": ";Autonomous Systems Lab",
        "aff_unique_url": "https://www.sevensense.io;https://www.ethz.ch",
        "aff_unique_abbr": "Sevensense;ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561375",
        "title": "Dynamic Occupancy Grid Mapping with Recurrent Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling and understanding the environment is an essential task for autonomous driving. In addition to the detection of objects, in complex traffic scenarios the motion of other road participants is of special interest. Therefore, we propose to use a recurrent neural network to predict a dynamic occupancy grid map, which divides the vehicle surrounding in cells, each containing the occupancy probability and a velocity estimate. During training, our network is fed with sequences of measurement grid maps, which encode the lidar measurements of a single time step. Due to the combination of convolutional and recurrent layers, our approach is capable to use spatial and temporal information for the robust detection of static and dynamic environment. In order to apply our approach with measurements from a moving ego-vehicle, we propose a method for ego-motion compensation that is applicable in neural network architectures with recurrent layers working on different resolutions. In our evaluations, we compare our approach with a state-of-the-art particle-based algorithm on a large publicly available dataset to demonstrate the improved accuracy of velocity estimates and the more robust separation of the environment in static and dynamic area. Additionally, we show that our proposed method for ego-motion compensation leads to comparable results in scenarios with stationary and with moving ego-vehicle.",
        "primary_area": "",
        "author": "Marcel Schreiber;Vasileios Belagiannis;Claudius Gl\u00e4ser;Klaus Dietmayer;Marcel Schreiber;Vasileios Belagiannis;Claudius Gl\u00e4ser;Klaus Dietmayer",
        "authorids": "/37086935692;/37085391038;/37699244900;/37283417900;/37086935692;/37085391038;/37699244900;/37283417900",
        "aff": "Institute of Measurement, Control, and Microtechnology, Ulm University, Germany; Institute of Measurement, Control, and Microtechnology, Ulm University, Germany; Robert Bosch GmbH, Corporate Research, Renningen, Germany; Institute of Measurement, Control, and Microtechnology, Ulm University, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561375/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17403803664177210036&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Ulm University;Robert Bosch GmbH",
        "aff_unique_dep": "Institute of Measurement, Control, and Microtechnology;Corporate Research",
        "aff_unique_url": "https://www.uni-ulm.de;https://www.bosch.com",
        "aff_unique_abbr": ";Bosch",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Renningen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561352",
        "title": "Dynamic Primitives and Optimal Feedback Control for the Manipulation of Complex Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern computer algorithms easily beat world champions in chess or Go, but state-of-the-art robots are still outperformed by two-year-old\u2019s in manipulating the pieces, let alone interacting with more complex objects. This work studied human behavior when moving an underactuated object, a cup with a ball rolling inside creating internal dynamics like sloshing coffee in a cup. The objective was to develop a control model that could replicate human behavior. Human movement data were collected for transporting this cup-and-ball system, both with and without external perturbations. The existing models in the human control literature, including maximum smoothness, optimal feedback control with minimum effort, and dynamic primitives with impedance were revisited for this challenging task. As these control models were primarily developed for unconstrained reaching movements, they could replicate human trajectories when transporting a rigid object. However, they fell short when the object introduced complex interaction forces due to its internal dynamics. Therefore, this study extended the framework of dynamic primitives and used an optimal controller to generate a maximally smooth zero-force trajectory for the impedance operator when interacting with perturbations from the object or the environment. Given the challenges that robot control still faces when interacting with complex objects, these findings may inform the development of bio-inspired controllers for robotic manipulation.",
        "primary_area": "",
        "author": "Reza Sharif Razavian;Salah Bazzi;Rashida Nayeem;Mohsen Sadeghi;Dagmar Sternad;Reza Sharif Razavian;Salah Bazzi;Rashida Nayeem;Mohsen Sadeghi;Dagmar Sternad",
        "authorids": "/38488619200;/37085815476;/37088507565;/37088998986;/38469397700;/38488619200;/37085815476;/37088507565;/37088998986;/38469397700",
        "aff": "Departments of Biology, Electrical and Computer Engineering,and Physics, Northeastern University, Boston, MA, USA; Departments of Biology, Electrical and Computer Engineering,and Physics, Northeastern University, Boston, MA, USA; Departments of Biology, Electrical and Computer Engineering,and Physics, Northeastern University, Boston, MA, USA; Departments of Biology, Electrical and Computer Engineering,and Physics, Northeastern University, Boston, MA, USA; Departments of Biology, Electrical and Computer Engineering,and Physics, Northeastern University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561352/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4562220528849621755&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Departments of Biology, Electrical and Computer Engineering, and Physics",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561726",
        "title": "Dynamic Projection of Human Motion for Safe and Efficient Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "In the modern manufacturing process, novel technologies enable the collaboration between humans and robots, which increases productivity while keeping flexibility. However, these technologies also lead to new challenges, e.g., maximization of Human-Robot Collaboration (HRC) performance while ensuring safety for the human being in fenceless robot applications. In this paper, an approach of the dynamic human motion projection is proposed for typical assembly tasks. The human upper body is simplified as a five-degree-of-freedom (5DOF) rigid-body model. A control-oriented projection model is proposed, and its parameters are estimated from the test data of human capability. Combined with a human-state estimator and a collision estimator, the \"worst-case\" collision motion is projected in the HRC scenario. The dynamic projection method is feasible online. Finally, the estimated collision time is adopted to increase the robot\u2019s speed limit, which validates the improvement of HRC\u2019s efficiency.",
        "primary_area": "",
        "author": "Xuming Meng;Roman Weitschat;Xuming Meng;Roman Weitschat",
        "authorids": "/37088998717;/38540468900;/37088998717;/38540468900",
        "aff": "Institute of Robotics and Mechatronics Center (RMC), German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics Center (RMC), German Aerospace Center (DLR), Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561726/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8561673199416617295&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Institute of Robotics and Mechatronics Center (RMC)",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Wessling",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561703",
        "title": "Dynamic Window Approach with Human Imitating Collision Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "The autonomous navigation in the crowded environment is a challenging task due to the sensor occlusion and the complex nature of the abstract social interactions. And yet, humans are capable of navigating in such complex environment. In this paper, we propose an effective navigation method that combines the learning-based and model-based methods in a way that a cost function that includes human imitation factor learned via deep learning is integrated into the dynamic window approach (DWA) [1]. The experiments conducted on simulations show that by training the robot to imitate the human trajectory, our navigation method is safer and more efficient than the state-of-the-art methods. Additionally, we successfully deployed a physical robot in an actual environment, and we validate that our navigation quality shares similar tendency with human in the path length, travel time, and the collision avoidance.",
        "primary_area": "",
        "author": "Sango Matsuzaki;Shinta Aonuma;Yuji Hasegawa;Sango Matsuzaki;Shinta Aonuma;Yuji Hasegawa",
        "authorids": "/37089001443;/37088999356;/37088997609;/37089001443;/37088999356;/37088997609",
        "aff": "Honda R&D Co., LTD.; Honda R&D Co., LTD.; Honda R&D Co., LTD.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561703/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17844449517231266339&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Honda R&D Co., Ltd.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.honda.com/",
        "aff_unique_abbr": "Honda R&D",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561854",
        "title": "Dynamic tracking for microrobot with active magnetic sensor array",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate position feedback in a wide range is critical for medical microrobotics and robot-assisted examinations, such as colonoscopy, bronchoscopy and capsule endoscopy examination. Among the many modalities of positioning feedback, magnetic tracking is a preferable method due to the unique advantages of free line of sight, free energy storage and untethered connection. However, the field strength of the magnetic source decreases with the third power of the distance, limiting the effectiveness of position feedback at long distances. In order to maintain a consistently high tracking accuracy in a broad area, this paper presents a new dynamic tracking solution by applying a movable sensor array. In this new solution, the tracking accuracy of the magnet is first determined and optimized within a short range. When the target microrobot carrying the magnet exceeds this optimized range, the sensor array is relocated by an external robotic arm to keep the target in the effective tracking range. Moreover, we also propose a multi-point locating algorithm to minimize the varying background noise. Experimental results show that the proposed method increases the range of magnetic tracking and achieves a satisfactory level of tracking accuracy, which demonstrates significant potentials to improve the position feedback of microrobots in medical applications.",
        "primary_area": "",
        "author": "Min Wang;Kwan Yi Leung;Rui Liu;Shuang Song;Yixuan Yuan;Jianqin Yin;Max Q.-H. Meng;Jun Liu;Min Wang;Kwan Yi Leung;Rui Liu;Shuang Song;Yixuan Yuan;Jianqin Yin;Max Q.-H. Meng;Jun Liu",
        "authorids": "/37087237694;/37088997207;/37088996359;/37400326000;/37075918800;/37086285976;/37274117000;/37086847579;/37087237694;/37088997207;/37088996359;/37400326000;/37075918800;/37086285976;/37274117000;/37086847579",
        "aff": "Department of Mechanical Engineering, City University of Hong Kong, Hong Kong SAR, China; Department of Mechanical Engineering, City University of Hong Kong, Hong Kong SAR, China; Department of Mechanical Engineering, City University of Hong Kong, Hong Kong SAR, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; Department of Electrical Engineering, City University of Hong Kong, Hong Kong SAR, China; School of Automation, Beijing University of Posts and Telecommunication, Beijing, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Mechanical Engineering, City University of Hong Kong, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561854/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4055793785210298842&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;0;2;3;0",
        "aff_unique_norm": "City University of Hong Kong;Harbin Institute of Technology;Beijing University of Posts and Telecommunications;Southern University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering;School of Mechanical Engineering and Automation;School of Automation;Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.cityu.edu.hk;http://www.hit.edu.cn/;http://www.bupt.edu.cn/;https://www.sustech.edu.cn",
        "aff_unique_abbr": "CityU;HIT;BUPT;SUSTech",
        "aff_campus_unique_index": "0;0;0;1;0;2;1;0",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560933",
        "title": "Dynamic-Aware Autonomous Exploration in Populated Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous exploration allows mobile robots to navigate in initially unknown territories in order to build complete representations of the environments. In many real-life applications, environments often contain dynamic obstacles which can compromise the exploration process by temporarily blocking passages, narrow paths, exits or entrances to other areas yet to be explored. In this work, we formulate a novel exploration strategy capable of explicitly handling dynamic obstacles, thus leading to complete and reliable exploration outcomes in populated environments. We introduce the concept of dynamic frontiers to represent unknown regions at the boundaries with dynamic obstacles together with a cost function which allows the robot to make informed decisions about when to revisit such frontiers. We evaluate the proposed strategy in challenging simulated environments and show that it outperforms a state-of-the-art baseline in these populated scenarios.",
        "primary_area": "",
        "author": "Valentina Cavinato;Thomas Eppenberger;Dina Youakim;Roland Siegwart;Renaud Dub\u00e9;Valentina Cavinato;Thomas Eppenberger;Dina Youakim;Roland Siegwart;Renaud Dub\u00e9",
        "authorids": "/37089000618;/37086124401;/37086196856;/37281398300;/37085782572;/37089000618;/37086124401;/37086196856;/37281398300;/37085782572",
        "aff": "Autonomous Systems Lab (ASL), ETH Zurich, Switzerland; Sevensense Robotics AG, Zurich, Switzerland; Sevensense Robotics AG, Zurich, Switzerland; Autonomous Systems Lab (ASL), ETH Zurich, Switzerland; Sevensense Robotics AG, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560933/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3381972135902002294&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "ETH Zurich;Sevensense Robotics AG",
        "aff_unique_dep": "Autonomous Systems Lab (ASL);",
        "aff_unique_url": "https://www.ethz.ch;https://www.sevensense.io",
        "aff_unique_abbr": "ETHZ;",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561430",
        "title": "Dynamically Switching Human Prediction Models for Efficient Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "As environments involving both robots and humans become increasingly common, so does the need to account for people during planning. To plan effectively, robots must be able to respond to and sometimes influence what humans do. This requires a human model which predicts future human actions. A simple model may assume the human will continue what they did previously; a more complex one might predict that the human will act optimally, disregarding the robot; whereas an even more complex one might capture the robot\u2019s ability to influence the human. These models make different trade-offs between computational time and performance of the resulting robot plan. Using only one model of the human either wastes computational resources or is unable to handle critical situations. In this work, we give the robot access to a suite of human models and enable it to assess the performance-computation trade-off online. By estimating how an alternate model could improve human prediction and how that may translate to performance gain, the robot can dynamically switch human models whenever the additional computation is justified. Our experiments in a driving simulator showcase how the robot can achieve performance comparable to always using the best human model, but with greatly reduced computation.",
        "primary_area": "",
        "author": "Arjun Sripathy;Andreea Bobu;Daniel S. Brown;Anca D. Dragan;Arjun Sripathy;Andreea Bobu;Daniel S. Brown;Anca D. Dragan",
        "authorids": "/37088999177;/37088414876;/38478370100;/37960625200;/37088999177;/37088414876;/38478370100;/37960625200",
        "aff": "EECS, UC Berkeley; EECS, UC Berkeley; EECS, UC Berkeley; EECS, UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561430/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11197193878292707133&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560837",
        "title": "Dynamics Randomization Revisited: A Case Study for Quadrupedal Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Understanding the gap between simulation and reality is critical for reinforcement learning with legged robots, which are largely trained in simulation. However, recent work has resulted in sometimes conflicting conclusions with regard to which factors are important for success, including the role of dynamics randomization. In this paper, we aim to provide clarity and understanding on the role of dynamics randomization in learning robust locomotion policies for the Laikago quadruped robot. Surprisingly, in contrast to prior work with the same robot model, we find that direct sim-to-real transfer is possible without dynamics randomization or on-robot adaptation schemes. We conduct extensive ablation studies in a sim-to-sim setting to understand the key issues underlying successful policy transfer, including other design decisions that can impact policy robustness. We further ground our conclusions via sim-to-real experiments with various gaits, speeds, and stepping frequencies. Additional Details: pair.toronto.edu/understanding-dr/",
        "primary_area": "",
        "author": "Zhaoming Xie;Xingye Da;Michiel van de Panne;Buck Babich;Animesh Garg;Zhaoming Xie;Xingye Da;Michiel van de Panne;Buck Babich;Animesh Garg",
        "authorids": "/37086574317;/37085791506;/37283212000;/37089002120;/37086330576;/37086574317;/37085791506;/37283212000;/37089002120;/37086330576",
        "aff": "University of British Columbia; NVIDIA; University of British Columbia; NVIDIA; Vector Institute, University of Toronto",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560837/",
        "gs_citation": 88,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4145301945764944381&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;2",
        "aff_unique_norm": "University of British Columbia;NVIDIA;University of Toronto",
        "aff_unique_dep": ";NVIDIA Corporation;Vector Institute",
        "aff_unique_url": "https://www.ubc.ca;https://www.nvidia.com;https://www.vectorinstitute.ai",
        "aff_unique_abbr": "UBC;NVIDIA;Vector Institute",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Toronto",
        "aff_country_unique_index": "0;1;0;1;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9561038",
        "title": "ECNNs: Ensemble Learning Methods for Improving Planar Grasp Quality Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an ensemble learning methodology that combines multiple existing robotic grasp synthesis algorithms and obtain a success rate that is significantly better than the individual algorithms. The methodology treats the grasping algorithms as \"experts\" providing grasp \"opinions\". An Ensemble Convolutional Neural Network (ECNN) is trained using a Mixture of Experts (MOE) model that integrates these opinions and determines the final grasping decision. The ECNN introduces minimal computational cost overhead, and the network can virtually run as fast as the slowest expert. We test this architecture using open-source algorithms in the literature by adopting GQCNN 4.0, GGCNN and a custom variation of GGCNN as experts and obtained a 6% increase in the grasp success on the Cornell Dataset compared to the best-performing individual algorithm. The performance of the method is also demonstrated using a Franka Emika Panda arm.",
        "primary_area": "",
        "author": "Fadi Alladkani;James Akl;Berk Calli;Fadi Alladkani;James Akl;Berk Calli",
        "authorids": "/37087234782;/37088982474;/37681653300;/37087234782;/37088982474;/37681653300",
        "aff": "Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, USA; Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, USA; Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561038/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16516312018251815322&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Robotics Engineering Program",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561902",
        "title": "EGO-Swarm: A Fully Autonomous and Decentralized Quadrotor Swarm System in Cluttered Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a decentralized and asynchronous systematic solution for multi-robot autonomous navigation in unknown obstacle-rich scenes using merely onboard resources. The planning system is formulated under gradient-based local planning framework, where collision avoidance is achieved by formulating the collision risk as a penalty of a nonlinear optimization problem. In order to improve robustness and escape local minima, we incorporate a lightweight topological trajectory generation method. Then agents generate safe, smooth, and dynamically feasible trajectories in only several milliseconds using an unreliable trajectory sharing network. Relative localization drift among agents is corrected by using agent detection in depth images. Our method is demonstrated in both simulation and real-world experiments. The source code is released for the reference of the community.",
        "primary_area": "",
        "author": "Xin Zhou;Jiangchao Zhu;Hongyu Zhou;Chao Xu;Fei Gao;Xin Zhou;Jiangchao Zhu;Hongyu Zhou;Chao Xu;Fei Gao",
        "authorids": "/37088432733;/37088997365;/37089001961;/37404060100;/37086045143;/37088432733;/37088997365;/37089001961;/37404060100;/37086045143",
        "aff": "National Engineering Research Center for Industrial Automation (Ningbo Institute), Ningbo, China; National Engineering Research Center for Industrial Automation (Ningbo Institute), Ningbo, China; National Engineering Research Center for Industrial Automation (Ningbo Institute), Ningbo, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561902/",
        "gs_citation": 197,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4434410485386465732&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "National Engineering Research Center for Industrial Automation;Zhejiang University",
        "aff_unique_dep": ";Huzhou Institute",
        "aff_unique_url": ";https://www.zju.edu.cn",
        "aff_unique_abbr": "NERC-IA;ZJU",
        "aff_campus_unique_index": "0;0;0;1;1",
        "aff_campus_unique": "Ningbo;Huzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561555",
        "title": "EMG-Based Neural Network Model of Human Arm Dynamics in a Haptic Training Simulator of Sinus Endoscopy",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an EMG-dependant neural network-based model of human forearm during interaction with a haptic training simulator of sinus endoscopy. We used a conventional lumped mass-spring-damper model as a base model, beside which we took effects of muscle activation level, using surface electromyography (EMG) signals, into consideration. Unknown parameters of a five-parameter mass-spring-damper model are optimised using experimental force and position data with a Levenberg\u2013Marquardt (LM) algorithm. In the training phase, parallel to this lumped model, a neural network (NN) structure is trained to learn the nonlinear mapping between the EMG signals (a way of measuring the muscles activation level that can be interpreted as muscle stiffness) and the parameters of the lumped model. In prediction (operational) phase, the trained neural network makes an estimate of the lumped parameters, using EMG and position data. Therefore, as apposed to conventional constant-parameter (CP) models, the parameters of the lumped model are not fixed in this method and are dependent to the muscle stiffness. Eight trials were performed while the operator was asked to to hold one\u2019s arm in a vertical plane such that their elbow had a right angle keep exerting a quasi-static and also reciprocating force in one direction\u2013a linear motion coaxial to their forearm. Haptic interface was programmed in a way to mimic the impedance model of sinus tissue, a nonlinear viscoelastic Kelvin-Voigt model previously developed by the authors. The estimated forces and the experimental forces are compared for two scenarios: once for the proposed EMG-dependant NN-based model and once again for the constant-parameter lumped model. Results demonstrate the precision improvement on the estimation of the exerted force from human hand to the haptic interface in the proposed model.",
        "primary_area": "",
        "author": "Mojtaba Esfandiari;Farzam Farahmand;Mojtaba Esfandiari;Farzam Farahmand",
        "authorids": "/38277118700;/37530736900;/38277118700;/37530736900",
        "aff": "Department of Biomedical Engineering, University of Calgary, Calgary, Canada; Department of Mechanical Engineering, Sharif University of Technology, Azadi Ave, Iran",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561555/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16180597211236924101&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Calgary;Sharif University of Technology",
        "aff_unique_dep": "Department of Biomedical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.ucalgary.ca;",
        "aff_unique_abbr": "U of C;",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Calgary;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Canada;Iran"
    },
    {
        "id": "9562024",
        "title": "ENCODE: a dEep poiNt Cloud ODometry nEtwork",
        "track": "main",
        "status": "Poster",
        "abstract": "Ego-motion estimation is a key requirement for the simultaneous localization and mapping (SLAM) problem. The traditional pipeline goes through feature extraction, feature matching and pose estimation, whose performance depends on the manually designed features. In this paper, we are motivated by the strong performance of deep learning methods in other computer vision and robotics tasks. We replace hand-crafted features with a neural network and directly estimate the relative pose between two adjacent scans from a LiDAR sensor using ENCODE: a dEep poiNt Cloud ODometry nEtwork. Firstly, a spherical projection of the input point cloud is performed to acquire a multi-channel vertex map. Then a multi-layer network backbone is applied to learn the abstracted features and a fully connected layer is adopted to estimate the 6-DoF ego-motion. Additionally, a map-to-map optimization module is applied to update the local poses and output a smooth map. Experiments on multiple datasets demonstrate that the proposed method achieves the best performance in comparison to state-of-the-art methods and is capable of providing accurate poses with low drift in various kinds of scenarios.",
        "primary_area": "",
        "author": "Yihuan Zhang;Liang Wang;Chen Fu;Yifan Dai;John M. Dolan;Yihuan Zhang;Liang Wang;Chen Fu;Yifan Dai;John M. Dolan",
        "authorids": "/37085624799;/37089775799;/37086544947;/37089001599;/37283756800;/37085624799;/37089775799;/37086544947;/37089001599;/37283756800",
        "aff": "Intelligent Connected Vehicle Center, Tsinghua Automotive Research Institute, Suzhou, China; Intelligent Connected Vehicle Center, Tsinghua Automotive Research Institute, Suzhou, China; Robotic Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Intelligent Connected Vehicle Center, Tsinghua Automotive Research Institute, Suzhou, China; Robotic Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562024/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10531320208374836356&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "Tsinghua University;Carnegie Mellon University",
        "aff_unique_dep": "Tsinghua Automotive Research Institute;Robotic Institute",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.cmu.edu",
        "aff_unique_abbr": "Tsinghua;CMU",
        "aff_campus_unique_index": "0;0;1;0;1",
        "aff_campus_unique": "Suzhou;Pittsburgh",
        "aff_country_unique_index": "0;0;1;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561759",
        "title": "EVA-Planner: Environmental Adaptive Quadrotor Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "The quadrotor is popularly used in challenging environments due to its superior agility and flexibility. In these scenarios, trajectory planning plays a vital role in generating safe motions to avoid obstacles while ensuring flight smoothness. Although many works on quadrotor planning have been proposed, a research gap exists in incorporating self-adaptation into a planning framework to enable a drone to automatically fly slower in denser environments and increase its speed in a safer area. In this paper, we propose an environmental adaptive planner to adjust the flight aggressiveness effectively based on the obstacle distribution and quadrotor state. Firstly, we design an environmental adaptive safety aware method to assign the priority of the surrounding obstacles according to the environmental risk level and instantaneous motion tendency. Then, we apply it into a multi-layered model predictive contouring control (Multi-MPCC) framework to generate adaptive, safe, and dynamical feasible local trajectories. Extensive simulations and real-world experiments verify the efficiency and robustness of our planning framework. Benchmark comparison also shows superior performances of our method with another advanced environmental adaptive planning algorithm. Moreover, we release our planning framework as open-source ros-packages1 .",
        "primary_area": "",
        "author": "Lun Quan;Zhiwei Zhang;Xingguang Zhong;Chao Xu;Fei Gao;Lun Quan;Zhiwei Zhang;Xingguang Zhong;Chao Xu;Fei Gao",
        "authorids": "/37088998553;/37088996226;/37089001168;/37404060100;/37086045143;/37088998553;/37088996226;/37089001168;/37404060100;/37086045143",
        "aff": "National Engineering Research Center for Industrial Automation (Ningbo Institute), Ningbo, China; National Engineering Research Center for Industrial Automation (Ningbo Institute), Ningbo, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561759/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14126207750012376912&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;1",
        "aff_unique_norm": "National Engineering Research Center for Industrial Automation;Zhejiang University",
        "aff_unique_dep": ";Huzhou Institute",
        "aff_unique_url": ";https://www.zju.edu.cn",
        "aff_unique_abbr": "NERC-IA;ZJU",
        "aff_campus_unique_index": "0;0;1;1;1",
        "aff_campus_unique": "Ningbo;Huzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562072",
        "title": "EagerMOT: 3D Multi-Object Tracking via Sensor Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-object tracking (MOT) enables mobile robots to perform well-informed motion planning and navigation by localizing surrounding objects in 3D space and time. Existing methods rely on depth sensors (e.g., LiDAR) to detect and track targets in 3D space, but only up to a limited sensing range due to the sparsity of the signal. On the other hand, cameras provide a dense and rich visual signal that helps to localize even distant objects, but only in the image domain. In this paper, we propose EagerMOT, a simple tracking formulation that eagerly integrates all available object observations from both sensor modalities to obtain a well-informed interpretation of the scene dynamics. Using images, we can identify distant incoming objects, while depth estimates allow for precise trajectory localization as soon as objects are within the depth-sensing range. With EagerMOT, we achieve state-of-the-art results across several MOT tasks on the KITTI and NuScenes datasets. Our code is available at https://github.com/aleksandrkim61/EagerMOT",
        "primary_area": "",
        "author": "Aleksandr Kim;Aljo\u0161a O\u0161ep;Laura Leal-Taix\u00e9;Aleksandr Kim;Aljo\u0161a O\u0161ep;Laura Leal-Taix\u00e9",
        "authorids": "/37088998663;/37085554303;/38286861700;/37088998663;/37085554303;/38286861700",
        "aff": "Technical University of Munich; Technical University of Munich; Technical University of Munich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562072/",
        "gs_citation": 275,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=922541162535340783&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9560876",
        "title": "Effective Crash Recovery of Robot Software Programs in ROS",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern robot systems use various software programs to autonomously perform different kinds of tasks. However, due to the risks of possible faults and errors, a robotic software program can inevitably crash in some cases, causing that the robot system fails to perform the current task. Thus, for robustness, the crashed program should be correctly recovered to continue the failed task. For this purpose, ROS provides a default restart method to automatically restart crashed programs. However, our case studies of typical ROS programs show that the restart method can perform incorrect crash recovery, and it can even cause the robot to perform dangerous behaviors, because this method loses the program\u2019s important data that was stored before the crash and is used after recovery. To solve this problem, we develop a practical approach named RORY, to perform effective crash recovery of robot software programs in ROS. RORY uses a hybrid checkpoint-replay method, and it is generic to different ROS programs by considering ROS properties. We evaluate RORY on 6 common ROS programs, and show that RORY performs correct crash recovery in both virtual and realistic environments with modest overhead. The comparison experiments indicate that RORY outperforms the restart, checkpoint-alone and replay-alone methods.",
        "primary_area": "",
        "author": "Yong-Hao Zou;Jia-Ju Bai;Yong-Hao Zou;Jia-Ju Bai",
        "authorids": "/37088999910;/37085383997;/37088999910;/37085383997",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560876/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5046357405440432651&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561587",
        "title": "Efficient Configuration Exploration in Inverse Dynamics Acquisition of Robotic Manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "The inverse dynamics of a robotic manipulator is instrumental in precise robot control and manipulation. However, acquiring such a model is challenging, not only due to unmodelled non-linearities such as joint friction, but also from a machine learning perspective (e.g., input space dimension, amount of data needed). The accuracy of such models, regardless of the learning techniques, relies on proper excitation and exploration of the robot\u2019s configuration space, in order to collect a rich dataset. This study aims to provide rich data in learning the inverse dynamics of a serial robotic manipulator using supervised machine learning techniques. We propose a method, called Max-Information Configuration Exploration (MICE), to incrementally explore and generate information-rich data via computing parameters of a trajectory set. We also introduce a new set of excitation trajectories that explores robot\u2019s configuration through imposed stable limit cycles in robot joints\u2019 phase space while satisfying feasibility constraints and physical bounds. We benchmark MICE against state-of-the-art in terms of data quality and learning accuracy. The proposed methodology for data collection, model learning, and evaluation, is validated with a KUKA IIWA14 robotic arm where the results prove significant improvement over traditional approaches.",
        "primary_area": "",
        "author": "Farshad Khadivar;Sthithparagya Gupta;Walid Amanhoud;Aude Billard;Farshad Khadivar;Sthithparagya Gupta;Walid Amanhoud;Aude Billard",
        "authorids": "/37086456377;/37088997050;/37088504835;/37273980800;/37086456377;/37088997050;/37088504835;/37273980800",
        "aff": "Learning Algorithms and Systems Laboratory (LASA), Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Learning Algorithms and Systems Laboratory (LASA), Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Learning Algorithms and Systems Laboratory (LASA), Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland; Learning Algorithms and Systems Laboratory (LASA), Ecole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), Lausanne, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561587/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5392440213302241083&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "Learning Algorithms and Systems Laboratory (LASA)",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561007",
        "title": "Efficient Haptic Rendering of Regolith",
        "track": "main",
        "status": "Poster",
        "abstract": "Driven by the need for physically accurate and haptically convincing models of lunar and planetary regolith for model-mediated teleoperation in space, we present an approach to modelling regolith in an efficient yet realistic way. Model parameters are derived from physical characteristics of the regolith, to render regoliths with different density profiles, cohesion, internal friction and in different gravitational fields. Users could distinguish between changes in parameters\u2013 specifically friction and gravity field\u2013and also gave qualitative feedback relevant to modelling regolith. We discuss the challenges in haptically rendering soils and the next steps.",
        "primary_area": "",
        "author": "Aaron Pereira;Annika Schmidt;Aaron Pereira;Annika Schmidt",
        "authorids": "/37086936191;/37086936669;/37086936191;/37086936669",
        "aff": "Human-Robot Interaction Lab, European Space Agency, Noordwijk, Netherlands; Dept. of Informatics, Sensor Based Robotic Systems and Intelligent Assistance Systems, TU, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561007/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16242960096549289611&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "European Space Agency;Technical University of Munich",
        "aff_unique_dep": "Human-Robot Interaction Lab;Dept. of Informatics, Sensor Based Robotic Systems and Intelligent Assistance Systems",
        "aff_unique_url": "https://www.esa.int;https://www.tum.de",
        "aff_unique_abbr": "ESA;TUM",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Noordwijk;Munich",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Netherlands;Germany"
    },
    {
        "id": "9561472",
        "title": "Efficient Heuristic Generation for Robot Path Planning with Recurrent Generative Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot path planning is difficult to solve due to the contradiction between the optimality of results and the complexity of algorithms, even in 2D environments. To find an optimal path, the algorithm needs to search all the state space, which costs many computation resources. To address this issue, we present a novel recurrent generative model (RGM), which generates efficient heuristic to reduce the search efforts of path planning algorithms. This RGM model adopts the framework of general generative adversarial networks (GAN), which consists of a novel generator that can generate heuristic by refining the outputs recurrently and two discriminators that check the connectivity and safety properties of heuristic. We test the proposed RGM module in various 2D environments to demonstrate its effectiveness and efficiency. The results show that, compared with a model without recurrence, the RGM successfully generates appropriate heuristic in both seen and new unseen maps with higher accuracy, demonstrating the good generalization ability of the RGM model. We also compare the rapidly-exploring random tree star (RRT*) with generated heuristic and the conventional RRT* in four different maps, showing that the generated heuristic can guide the algorithm to efficiently find both initial and optimal solutions in a faster and more efficient way.",
        "primary_area": "",
        "author": "Zhaoting Li;Jiankun Wang;Max Q.-H. Meng;Zhaoting Li;Jiankun Wang;Max Q.-H. Meng",
        "authorids": "/37088990774;/37086100720;/37274117000;/37088990774;/37086100720;/37274117000",
        "aff": "Department of Electronic and Electrical Engineering of the Southern, University of Science and Technology, Shenzhen, China; Department of Electronic and Electrical Engineering of the Southern, University of Science and Technology, Shenzhen, China; Shenzhen Research Institute of the Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561472/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12064851063056688392&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Science and Technology;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electronic and Electrical Engineering;Shenzhen Research Institute",
        "aff_unique_url": "https://www.ust.hk;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "UST;CUHK",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561353",
        "title": "Efficient Map Prediction via Low-Rank Matrix Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "In many autonomous mapping tasks, the maps cannot be accurately constructed due to various reasons such as sparse, noisy, and partial sensor measurements. We propose a novel map prediction method built upon recent success of Low-Rank Matrix Completion. The proposed map prediction is able to achieve both map interpolation and extrapolation on raw poor-quality maps with missing or noisy observations. We validate with extensive simulated experiments that the approach can achieve real-time computation for large maps, and the performance is superior to state-of-the-art map prediction approach \u2014 Bayesian Hilbert Mapping in terms of mapping accuracy and computation time. Then we demonstrate that with the proposed real-time map prediction framework, the coverage convergence rate (per action step) for a set of representative coverage planning methods commonly used for environmental modeling and monitoring tasks can be significantly improved.",
        "primary_area": "",
        "author": "Zheng Chen;Shi Bai;Lantao Liu;Zheng Chen;Shi Bai;Lantao Liu",
        "authorids": "/37088488606;/37085731010;/37085785167;/37088488606;/37085731010;/37085785167",
        "aff": "Luddy School of Informatics, Computing, and Engineering at Indiana University, Bloomington, IN, USA; Wing, Alphabet Inc.; Luddy School of Informatics, Computing, and Engineering at Indiana University, Bloomington, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561353/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10424482481551261348&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Indiana University;Alphabet Inc.",
        "aff_unique_dep": "Luddy School of Informatics, Computing, and Engineering;Wing",
        "aff_unique_url": "https://www.indiana.edu;https://abc.xyz",
        "aff_unique_abbr": "IU;Alphabet",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bloomington;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560826",
        "title": "Efficient Multi-Robot Inspection of Row Crops via Kernel Estimation and Region-Based Task Allocation",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern agriculture relies on accurate and timely data. Currently, most of this data is gathered using remote sensing, which uses a combination of satellite and aerial imagery. However, ground robots are needed to fill in the gaps for finer ground-level data and the execution of physical tasks such as sample collection. The scales at which crops are produced preclude the inspection of each and every plant, thus requiring the selection of a smaller number of inspection targets. In this paper, we solve this multi-robot inspection problem using a novel task allocation algorithm. The algorithm derives its utility function from a model based on Gaussian process machine learning with a kernel that is learned from previous data. The algorithm also considers the physical limitations of moving within crop rows by dividing the plot into geodesic Voronoi regions based on robot locations. Simulation studies are performed to validate the method.",
        "primary_area": "",
        "author": "Merrill Edmonds;Jingang Yi;Merrill Edmonds;Jingang Yi",
        "authorids": "/37086962204;/37277001600;/37086962204;/37277001600",
        "aff": "Department of Mechanical and Aerospace Engineering, Rutgers, State University of New Jersey, Piscataway, NJ; Department of Mechanical and Aerospace Engineering, Rutgers, State University of New Jersey, Piscataway, NJ",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560826/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10815080214723896224&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561047",
        "title": "Efficient Multi-scale POMDPs for Robotic Object Search and Delivery",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel hierarchical POMDP framework to solve an object search and delivery task where the agent is given a prior belief about the possible item locations. Solving POMDPs is computationally demanding and, as such, applications have typically been limited to small environments. The proposed hierarchical POMDP framework performs reasoning on multiple spatial scales in order to reduce computation time. The problem is first solved in the top layer of the hierarchy with a coarsely discretized state space. Its solution is refined in the lower layers with increasing resolution. Three different methods for propagating information down the spatial hierarchy are discussed and validated in simulation. We show that a two-layer multi-scale POMDP decreases computation time by an order of magnitude allowing for real-time applications while maintaining high solution quality. For large problems that require three layers to reach the desired resolution, computation time speedups by two orders of magnitude are achieved.",
        "primary_area": "",
        "author": "Luc Holzherr;Julian F\u00f6rster;Michel Breyer;Juan Nieto;Roland Siegwart;Jen Jen Chung;Luc Holzherr;Julian F\u00f6rster;Michel Breyer;Juan Nieto;Roland Siegwart;Jen Jen Chung",
        "authorids": "/37088996582;/37088912058;/37086692289;/37085778635;/37281398300;/37085668354;/37088996582;/37088912058;/37086692289;/37085778635;/37281398300;/37085668354",
        "aff": "Autonomous Systems Lab, ETH Zurich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Zurich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Zurich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Zurich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Zurich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Zurich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561047/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18431796100575158167&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561254",
        "title": "Efficient Multi-sensor Aided Inertial Navigation with Online Calibration",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we design a versatile multi-sensor aided inertial navigation system (MINS) that can efficiently fuse multi-modal measurements of IMU, camera, wheel encoder, GPS, and 3D LiDAR along with online spatiotemporal sensor calibration. Building upon our prior work [1] \u2013[3], in this work we primarily focus on efficient LiDAR integration in a sliding-window filtering fashion. As each 3D LiDAR scan contains a large volume of 3D points which poses great challenges for real-time performance, we advocate using plane patches, which contain the environmental structural information, extracted from the sparse LiDAR point cloud to update/calibrate the system efficiently. The proposed LiDAR plane patch processing algorithm (including extraction, data association, and update) is shown to be efficient and consistent. Both Extensive Monte-Carlo simulations and real-world datasets with large-scale urban driving scenarios have been used to verify the accuracy and consistency of the proposed MINS algorithm.",
        "primary_area": "",
        "author": "Woosik Lee;Yulin Yang;Guoquan Huang;Woosik Lee;Yulin Yang;Guoquan Huang",
        "authorids": "/37087323297;/37085990232;/37077670600;/37087323297;/37085990232;/37077670600",
        "aff": "Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561254/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10962262213148003714&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Robot Perception and Navigation Group",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560912",
        "title": "Efficient Online Calibration for Autonomous Vehicle\u2019s Longitudinal Dynamical System: A Gaussian Model Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an efficient online calibration system for longitudinal vehicle dynamics of driverless cars. Instead of modeling vehicle\u2019s longitudinal dynamical system analytically, we employ a data-driven method to generate an \"end-to-end\" numerical model with a look-up table which saves vehicle\u2019s velocity, control command, and acceleration. This reference table should be calibrated to account for variations of vehicle\u2019s hardware status over time. To reduce the expensive labor in calibration process, we propose an effective algorithm to update this reference look-up table with a Gaussian model approach. We introduce a 2-D Gaussian distribution to model acceleration error between interpolated one from look-up table and actual one from vehicle sensors. We estimate model\u2019s standard deviations with a \"three-sigma rule\" heuristic and calculate its height with a backtracking method such that monotonicity constraint between acceleration and control command is strictly satisfied in the updated table. The effectiveness of our proposed system is verified in realworld road tests with Lincoln MKZ.",
        "primary_area": "",
        "author": "Shihao Wang;Canqiang Deng;Qingjie Qi;Shihao Wang;Canqiang Deng;Qingjie Qi",
        "authorids": "/37086312971;/37089001119;/37089613589;/37086312971;/37089001119;/37089613589",
        "aff": "Department of Mechanical Engineering and Materials Science, Duke University, Durham, NC, USA; Deeproute.ai Ltd, Fremont, CA, USA; Deeproute.ai Ltd, Fremont, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560912/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6208044916053523336&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Duke University;Deeproute.ai Ltd",
        "aff_unique_dep": "Department of Mechanical Engineering and Materials Science;",
        "aff_unique_url": "https://www.duke.edu;",
        "aff_unique_abbr": "Duke;",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Durham;Fremont",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561675",
        "title": "Efficient RGB-D Semantic Segmentation for Indoor Scene Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Analyzing scenes thoroughly is crucial for mobile robots acting in different environments. Semantic segmentation can enhance various subsequent tasks, such as (semantically assisted) person perception, (semantic) free space detection, (semantic) mapping, and (semantic) navigation. In this paper, we propose an efficient and robust RGB-D segmentation approach that can be optimized to a high degree using NVIDIA TensorRT and, thus, is well suited as a common initial processing step in a complex system for scene analysis on mobile robots. We show that RGB-D segmentation is superior to processing RGB images solely and that it can still be performed in real time if the network architecture is carefully designed. We evaluate our proposed Efficient Scene Analysis Network (ESANet) on the common indoor datasets NYUv2 and SUNRGB-D and show that we reach state-of-the-art performance while enabling faster inference. Furthermore, our evaluation on the outdoor dataset Cityscapes shows that our approach is suitable for other areas of application as well. Finally, instead of presenting benchmark results only, we also show qualitative results in one of our indoor application scenarios.",
        "primary_area": "",
        "author": "Daniel Seichter;Mona K\u00f6hler;Benjamin Lewandowski;Tim Wengefeld;Horst-Michael Gross;Daniel Seichter;Mona K\u00f6hler;Benjamin Lewandowski;Tim Wengefeld;Horst-Michael Gross",
        "authorids": "/37085814238;/37088530153;/37086317277;/37085449849;/37270612700;/37085814238;/37088530153;/37086317277;/37085449849;/37270612700",
        "aff": "Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany; Neuroinformatics and Cognitive Robotics Lab, Technische Universit\u00e4t Ilmenau, Ilmenau, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561675/",
        "gs_citation": 294,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14493992541386327857&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Ilmenau",
        "aff_unique_dep": "Neuroinformatics and Cognitive Robotics Lab",
        "aff_unique_url": "https://www.tu-ilmenau.de",
        "aff_unique_abbr": "TU Ilmenau",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Ilmenau",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561348",
        "title": "Efficient Reachability Analysis of Closed-Loop Systems with Neural Network Controllers",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural Networks (NNs) can provide major empirical performance improvements for robotic systems, but they also introduce challenges in formally analyzing those systems\u2019 safety properties. In particular, this work focuses on estimating the forward reachable set of closed-loop systems with NN controllers. Recent work provides bounds on these reachable sets, yet the computationally efficient approaches provide overly conservative bounds (thus cannot be used to verify useful properties), whereas tighter methods are too intensive for online computation. This work bridges the gap by formulating a convex optimization problem for reachability analysis for closed-loop systems with NN controllers. While the solutions are less tight than prior semidefinite program-based methods, they are substantially faster to compute, and some of the available computation time can be used to refine the bounds through input set partitioning, which more than overcomes the tightness gap. The proposed framework further considers systems with measurement and process noise, thus being applicable to realistic systems with uncertainty. Finally, numerical comparisons show that our approach based on linear programming and partitioning can give 10\u00d7 reduction in conservatism in \\frac{1}{2}\\frac{1}{2} of the computation time compared to the state-of-the-art, and the ability to handle various sources of uncertainty is highlighted on a quadrotor model.",
        "primary_area": "",
        "author": "Michael Everett;Golnaz Habibi;Jonathan P. How;Michael Everett;Golnaz Habibi;Jonathan P. How",
        "authorids": "/37418751400;/37947606400;/37276347700;/37418751400;/37947606400;/37276347700",
        "aff": "Aerospace Controls Laboratory, Massachusetts Institute of Technology; Aerospace Controls Laboratory, Massachusetts Institute of Technology; Aerospace Controls Laboratory, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561348/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13238492343104655413&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Aerospace Controls Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560784",
        "title": "Efficient Real-Time Inference in Temporal Convolution Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "It has been recently demonstrated that Temporal Convolution Networks (TCNs) provide state-of-the-art results in many problem domains where the input data is a time-series. TCNs typically incorporate information from a long history of inputs (the receptive field) into a single output using many convolution layers. Real-time inference using a trained TCN can be challenging on devices with limited compute and memory, especially if the receptive field is large. This paper introduces the RT-TCN algorithm that reuses the output of prior convolution operations to minimize the computational requirements and persistent memory footprint of a TCN during real-time inference. We also show that when a TCN is trained using time slices of the input time-series, it can be executed in realtime continually using RT-TCN. In addition, we provide TCN architecture guidelines that ensure that real-time inference can be performed within memory and computational constraints.",
        "primary_area": "",
        "author": "Piyush Khandelwal;James MacGlashan;Peter Wurman;Peter Stone;Piyush Khandelwal;James MacGlashan;Peter Wurman;Peter Stone",
        "authorids": "/38490919800;/37085510936;/37285001000;/37269574900;/38490919800;/37085510936;/37285001000;/37269574900",
        "aff": "Sony AI, Sony Corporation of America, New York, NY, USA; Sony AI, Sony Corporation of America, New York, NY, USA; Sony AI, Sony Corporation of America, New York, NY, USA; Department of Computer Science, University of Texas at Austin, Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560784/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16790858741024204350&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Sony AI;University of Texas at Austin",
        "aff_unique_dep": "Sony Corporation of America;Department of Computer Science",
        "aff_unique_url": "https://www.sony.com;https://www.utexas.edu",
        "aff_unique_abbr": "Sony;UT Austin",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561796",
        "title": "Efficient Recovery of Multi-Camera Motion from Two Affine Correspondences",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an efficient method to estimate the relative pose of a multi-camera system from a minimum of two affine correspondences (ACs). Our solution is novel as it computes the 6DOF relative pose by utilizing a first-order rotation approximation. We directly derive a single polynomial based on the constraint between ACs and the generalized camera model. Then a closed-form solution is found analytically and it produces an accurate relative pose estimation efficiently. Benefiting from the low number of exploited correspondences and the speed of the solver, it speeds up robust estimators, e.g. RANSAC, significantly. The proposed method is evaluated both on synthetic data and real-world image sequences from the KITTI benchmark. It is shown that the proposed solver is superior to the state-of-the-art algorithms in terms of accuracy.",
        "primary_area": "",
        "author": "Banglei Guan;Ji Zhao;Daniel Barath;Friedrich Fraundorfer;Banglei Guan;Ji Zhao;Daniel Barath;Friedrich Fraundorfer",
        "authorids": "/37086452960;/37963498600;/37086108821;/37266352400;/37086452960;/37963498600;/37086108821;/37266352400",
        "aff": "College of Aerospace Science and Engineering, National University of Defense Technology, China; Ji Zhao; Machine Perception Research Laboratory, MTA SZTAKI, Hungary; Remote Sensing Technology Institute, German Aerospace Center, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561796/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15199026743775544786&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;2;3",
        "aff_unique_norm": "National University of Defense Technology;;MTA SZTAKI;German Aerospace Center",
        "aff_unique_dep": "College of Aerospace Science and Engineering;;Machine Perception Research Laboratory;Remote Sensing Technology Institute",
        "aff_unique_url": ";;https://www.sztaki.hu;https://www.dlr.de",
        "aff_unique_abbr": ";;;DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;2;3",
        "aff_country_unique": "China;;Hungary;Germany"
    },
    {
        "id": "9561921",
        "title": "Efficient SE(3) Reachability Map Generation via Interplanar Integration of Intra-planar Convolutions",
        "track": "main",
        "status": "Poster",
        "abstract": "Convolution has been used for fast computation of reachability maps, but it has high computational costs when performing SE(3) convolution operations for general joint arrangements in industrial robots and 3D workspace. Its application is also limited to planar robots, 2D workspace, or robots with special spatial arrangements for joints. In this paper, we find that the SE(3) convolution can be decomposed into a set of SE(2) convolutions, which significantly reduces the computational complexity when computing the reachability map of high-DOF robotic manipulators in the 3D workspace. We also leverage GPU parallel computing and Fast Fourier transform to further accelerate the computation procedure. We demonstrate the time efficiency and quality of our approach using a set of numerical experiments for constructing reachability maps and also present a multi-robot plant phenotyping system that uses the computed reachability map for efficient viewpoint selection and path planning.",
        "primary_area": "",
        "author": "Yiheng Han;Jia Pan;Mengfei Xia;Long Zeng;Yong-Jin Liu;Yiheng Han;Jia Pan;Mengfei Xia;Long Zeng;Yong-Jin Liu",
        "authorids": "/37086529078;/37535628800;/37088956287;/37087324062;/37279426700;/37086529078;/37535628800;/37088956287;/37087324062;/37279426700",
        "aff": "Department of Computer Science and Technology, BNRist, MOE-Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China; Department of Computer Science, The University of Hong Kong; Department of Computer Science and Technology, BNRist, MOE-Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China; Shenzhen International Graduate School, Tsinghua University; Department of Computer Science and Technology, BNRist, MOE-Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561921/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9863859592884269822&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Tsinghua University;University of Hong Kong",
        "aff_unique_dep": "Department of Computer Science and Technology;Department of Computer Science",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.hku.hk",
        "aff_unique_abbr": "THU;HKU",
        "aff_campus_unique_index": "0;1;0;2;0",
        "aff_campus_unique": "Beijing;Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561097",
        "title": "Efficient Self-Supervised Data Collection for Offline Robot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "A practical approach to robot reinforcement learning is to first collect a large batch of real or simulated robot interaction data, using some data collection policy, and then learn from this data to perform various tasks, using offline learning algorithms. Previous work focused on manually designing the data collection policy, and on tasks where suitable policies can easily be designed, such as random picking policies for collecting data about object grasping. For more complex tasks, however, it may be difficult to find a data collection policy that explores the environment effectively, and produces data that is diverse enough for the downstream task. In this work, we propose that data collection policies should actively explore the environment to collect diverse data. In particular, we develop a simple-yet-effective goal-conditioned reinforcement-learning method that actively focuses data collection on novel observations, thereby collecting a diverse data-set. We evaluate our method on simulated robot manipulation tasks with visual inputs and show that the improved diversity of active data collection leads to significant improvements in the downstream learning tasks.",
        "primary_area": "",
        "author": "Shadi Endrawis;Gal Leibovich;Guy Jacob;Gal Novik;Aviv Tamar;Shadi Endrawis;Gal Leibovich;Guy Jacob;Gal Novik;Aviv Tamar",
        "authorids": "/37088996479;/37088998683;/37089000829;/37088997297;/37086002269;/37088996479;/37088998683;/37089000829;/37088997297;/37086002269",
        "aff": "Intel Labs; Intel Labs; Intel Labs; Intel Labs; Technion \u2013 Israel Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561097/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=25530505585178123&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Intel;Technion \u2013 Israel Institute of Technology",
        "aff_unique_dep": "Intel Labs;",
        "aff_unique_url": "https://www.intel.com;https://www.technion.ac.il/en/",
        "aff_unique_abbr": "Intel;Technion",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "9561299",
        "title": "Efficient and Robust LiDAR-Based End-to-End Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning has been used to demonstrate end-to-end neural network learning for autonomous vehicle control from raw sensory input. While LiDAR sensors provide reliably accurate information, existing end-to-end driving solutions are mainly based on cameras since processing 3D data requires a large memory footprint and computation cost. On the other hand, increasing the robustness of these systems is also critical; however, even estimating the model\u2019s uncertainty is very challenging due to the cost of sampling-based methods. In this paper, we present an efficient and robust LiDAR-based end-to-end navigation framework. We first introduce Fast-LiDARNet that is based on sparse convolution kernel optimization and hardware-aware model design. We then propose Hybrid Evidential Fusion that directly estimates the uncertainty of the prediction from only a single forward pass and then fuses the control predictions intelligently. We evaluate our system on a full-scale vehicle and demonstrate lane-stable as well as navigation capabilities. In the presence of out-of-distribution events (e.g., sensor failures), our system significantly improves robustness and reduces the number of takeovers in the real world.",
        "primary_area": "",
        "author": "Zhijian Liu;Alexander Amini;Sibo Zhu;Sertac Karaman;Song Han;Daniela L. Rus;Zhijian Liu;Alexander Amini;Sibo Zhu;Sertac Karaman;Song Han;Daniela L. Rus",
        "authorids": "/37087231394;/37086454594;/37088687809;/37304113000;/37086460117;/37279652300;/37087231394;/37086454594;/37088687809;/37304113000;/37086460117;/37279652300",
        "aff": "Microsystems Technology Laboratories (MTL), Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology; Microsystems Technology Laboratories (MTL), Massachusetts Institute of Technology; Laboratory for Information and Decision Systems (LIDS), Massachusetts Institute of Technology; Microsystems Technology Laboratories (MTL), Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Lab (CSAIL), Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561299/",
        "gs_citation": 56,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13446746357784773665&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Microsystems Technology Laboratories (MTL)",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561848",
        "title": "Efficient and Robust Orientation Estimation of Strawberries for Fruit Picking Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent developments in agriculture have high-lighted the potential of as well as the need for the use of robotics. Various processes in this field can benefit from the proper use of state of the art technology [1], in terms of efficiency as well as quality. One of these areas is the harvesting of ripe fruit.In order to be able to automate this process, a robotic harvester needs to be aware of the full poses of the crop/fruit to be collected in order to perform proper path- and collision-planning. The current state of the art mainly considers problems of detection and segmentation of fruit with localisation limited to the 3D position only. The reliable and real-time estimation of the respective orientations remains a mostly unaddressed problem.In this paper, we present a compact and efficient network architecture for estimating the orientation of soft fruit such as strawberries from colour and, optionally, depth images. The proposed system can be automatically trained in a realistic simulation environment. We evaluate the system\u2019s performance on simulated datasets and validate its operation on publicly available images of strawberries to demonstrate its practical use. Depending on the amount of training data used, coverage of state space, as well as the availability of RGB-D or RGB data only, mean errors of as low as 11\u00b0 could be achieved.",
        "primary_area": "",
        "author": "Nikolaus Wagner;Raymond Kirk;Marc Hanheide;Grzegorz Cielniak;Nikolaus Wagner;Raymond Kirk;Marc Hanheide;Grzegorz Cielniak",
        "authorids": "/37089000115;/37089001059;/37270387300;/37550177700;/37089000115;/37089001059;/37270387300;/37550177700",
        "aff": "Nikolaus Wagner; Raymond Kirk; Marc Hanheide; Grzegorz Cielniak",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561848/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=380897196800384726&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9561109",
        "title": "Efficient solution method based on inverse dynamics for optimal control problems of rigid body systems",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an efficient way of solving optimal control problems for rigid-body systems on the basis of inverse dynamics and the multiple-shooting method. We treat all variables, including the state, acceleration, and control input torques, as optimization variables and treat the inverse dynamics as an equality constraint. We eliminate the update of the control input torques from the linear equation of Newton\u2019s method by applying condensing for inverse dynamics. The size of the resultant linear equation is the same as that of the multiple-shooting method based on forward dynamics except for the variables related to the passive joints and contacts. Compared with the conventional methods based on forward dynamics, the proposed method reduces the computational cost of the dynamics and their sensitivities by utilizing the recursive Newton-Euler algorithm (RNEA) and its partial derivatives. In addition, it increases the sparsity of the Hessian of the Karush\u2013Kuhn\u2013Tucker conditions, which reduces the computational cost, e.g., of Riccati recursion. Numerical experiments show that the proposed method outperforms state-of-the-art implementations of differential dynamic programming based on forward dynamics in terms of computational time and numerical robustness.",
        "primary_area": "",
        "author": "Sotaro Katayama;Toshiyuki Ohtsuka;Sotaro Katayama;Toshiyuki Ohtsuka",
        "authorids": "/37086294817;/37270839500;/37086294817;/37270839500",
        "aff": "Department of System Science, Graduate School of Informatics, Kyoto University, Kyoto, Japan; Department of System Science, Graduate School of Informatics, Kyoto University, Kyoto, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561109/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8375972393804022264&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Kyoto University",
        "aff_unique_dep": "Department of System Science, Graduate School of Informatics",
        "aff_unique_url": "https://www.kyoto-u.ac.jp",
        "aff_unique_abbr": "Kyoto U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kyoto",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561385",
        "title": "Ego-centric Stereo Navigation Using Stixel World",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores the use of passive, stereo sensing for vision-based navigation. The traditional approach uses dense depth algorithms, which can be computationally costly or potentially inaccurate. These drawbacks compound when including the additional computational demands associated to the sensor fusion, collision checking, and path planning modules that interpret the dense depth measurements. These problems can be avoided through the use of the stixel representation, a compact and sparse visual representation for local free-space. When integrated into a Planning in Perception Space based hierarchical navigation framework, stixels permit fast and scalable navigation for different robot geometries. Computational studies quantify the processing performance and demonstrate the favorable scaling properties over comparable dense depth methods. Navigation benchmarking demonstrates more consistent performance across high and low performance compute hardware for PiPS-based stixel navigation versus traditional hierarchical navigation.",
        "primary_area": "",
        "author": "Shiyu Feng;Fanzhe Lyu;Jin Ha Hwang;Patricio A. Vela;Shiyu Feng;Fanzhe Lyu;Jin Ha Hwang;Patricio A. Vela",
        "authorids": "/37088958834;/37089001121;/37088999506;/37329553400;/37088958834;/37089001121;/37088999506;/37329553400",
        "aff": "School of Mechanical Engineering and the School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561385/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14466343747245370754&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561736",
        "title": "Elastic and Efficient LiDAR Reconstruction for Large-Scale Exploration Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an efficient, elastic 3D LiDAR reconstruction framework which can reconstruct up to maximum Li-DAR ranges (60 m) at multiple frames per second, thus enabling robot exploration in large-scale environments. Our approach only requires a CPU. We focus on three main challenges of large-scale reconstruction: integration of long-range LiDAR scans at high frequency, the capacity to deform the reconstruction after loop closures are detected, and scalability for long-duration exploration. Our system extends upon a state-of-the-art efficient RGB-D volumetric reconstruction technique, called supereight, to support LiDAR scans and a newly developed submapping technique to allow for dynamic correction of the 3D reconstruction. We then introduce a novel pose graph clustering and submap fusion feature to make the proposed system more scalable for large environments. We evaluate the performance using two public datasets including outdoor exploration with a handheld device and a drone, and with a mobile robot exploring an underground room network. Experimental results demonstrate that our system can reconstruct at 3 Hz with 60 m sensor range and ~5 cm resolution, while state-of-the-art approaches can only reconstruct to 25 cm resolution or 20 m range at the same frequency.",
        "primary_area": "",
        "author": "Yiduo Wang;Nils Funk;Milad Ramezani;Sotiris Papatheodorou;Marija Popovi\u0107;Marco Camurri;Stefan Leutenegger;Maurice Fallon;Yiduo Wang;Nils Funk;Milad Ramezani;Sotiris Papatheodorou;Marija Popovi\u0107;Marco Camurri;Stefan Leutenegger;Maurice Fallon",
        "authorids": "/37088689824;/37086189909;/37088504403;/37085837932;/37086001290;/37085638130;/37698403100;/37540365100;/37088689824;/37086189909;/37088504403;/37085837932;/37086001290;/37085638130;/37698403100;/37540365100",
        "aff": "Oxford Robotics Institute, University of Oxford, UK; Smart Robotics Lab, Department of Computing, Imperial College London, UK; Oxford Robotics Institute, University of Oxford, UK; Smart Robotics Lab, Department of Computing, Imperial College London, UK; Smart Robotics Lab, Department of Computing, Imperial College London, UK; Oxford Robotics Institute, University of Oxford, UK; Smart Robotics Lab, Department of Computing, Imperial College London, UK; Oxford Robotics Institute, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561736/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13327320102250487985&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;1;1;0;1;0",
        "aff_unique_norm": "University of Oxford;Imperial College London",
        "aff_unique_dep": "Oxford Robotics Institute;Department of Computing",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.imperial.ac.uk",
        "aff_unique_abbr": "Oxford;ICL",
        "aff_campus_unique_index": "0;1;0;1;1;0;1;0",
        "aff_campus_unique": "Oxford;London",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561676",
        "title": "Elevation control of a soft jumping robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Jumping with controllable elevation is significant for insect-scale robots to improve terrain adaptability and to escape from risks. However, jumping robots based on soft materials with low stiffness cannot transmit displacement precisely, exhibiting poor control of jumping. Here, we propose a modified two-bars catapult mechanism combined with an asynchronous sequential releasing strategy to realize elevation controllable jumping. In this work, an 80 mg prototype robot, 56 (long) \u00d7 29 mm (wide) \u00d7 3 mm (high) mm in size, is designed with the controllable elevation range from 63\u00b0 to 112\u00b0. The soft robot is mainly composed of a shape memory alloy actuator and four electrostatic pads acting as the lock/release structures. Elevation control is realized by asynchronously releasing the electrostatic pads in a small time interval (about 10 ms). A maximum jump height of 62 mm and a maximum half-distance of 41 mm are also achieved.",
        "primary_area": "",
        "author": "H. Chen;J. Liang;Z. Miao;G. Zhou;Y. Liu;M. Zhang;H. Chen;J. Liang;Z. Miao;G. Zhou;Y. Liu;M. Zhang",
        "authorids": "/37281172600;/37087045612;/37086002897;/37088998161;/37088999544;/37089261058;/37281172600;/37087045612;/37086002897;/37088998161;/37088999544;/37089261058",
        "aff": "Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Tsinghua-Berkeley Shenzhen Institute, Tsinghua University, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Tsinghua-Berkeley Shenzhen Institute, Tsinghua University, Shenzhen, China; Tsinghua-Berkeley Shenzhen Institute, Tsinghua University, Shenzhen, China; Shenzhen International Graduate School, Tsinghua University, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561676/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1789405666843136057&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Shenzhen International Graduate School",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561536",
        "title": "Ellipse Loss for Scene-Compliant Motion Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion prediction is a critical part of self-driving technology, responsible for inferring future behavior of traffic actors in autonomous vehicle\u2019s surroundings. In order to ensure safe and efficient operations, prediction models need to output accurate trajectories that obey the map constraints. In this paper, we address this task and propose a novel ellipse loss that allows the models to better reason about scene compliance and predict more realistic trajectories. Ellipse loss penalizes off-road predictions directly in a supervised manner, by projecting the output trajectories into the top-down map frame using a differentiable trajectory rasterizer module. Moreover, it takes into account actor dimensions and orientation, providing more direct training signals to the model. We applied ellipse loss to a recently proposed state-of-the-art joint detection-prediction model to showcase its benefits. Evaluation on large-scale autonomous driving data strongly indicates that the method allows for more accurate and more realistic trajectory predictions.",
        "primary_area": "",
        "author": "Henggang Cui;Hoda Shajari;Sai Yalamanchi;Nemanja Djuric;Henggang Cui;Hoda Shajari;Sai Yalamanchi;Nemanja Djuric",
        "authorids": "/37086936263;/37088996621;/37088596755;/37085410883;/37086936263;/37088996621;/37088596755;/37085410883",
        "aff": "Uber Advanced Technologies Group (ATG), Pittsburgh, PA; Uber ATG, University of Florida, Work Done During Internship; Uber Advanced Technologies Group (ATG), Pittsburgh, PA; Uber Advanced Technologies Group (ATG), Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561536/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1847570094615635780&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Uber Advanced Technologies Group;University of Florida",
        "aff_unique_dep": "ATG;",
        "aff_unique_url": "https://www.uber.com;https://www.ufl.edu",
        "aff_unique_abbr": "Uber ATG;UF",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561199",
        "title": "Embedded Neuromorphic Architecture for Form + Function 4-D Printing of Robotic Materials: Emulation of Optimized Neurons",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes the optimization of a neuromorphic architecture for printable organic neurons as part of an ongoing project to develop Form + Function 4-D Printing. The previously proposed architecture prioritizes simplicity and massive redundancy for a printable analog neural network consisting of only one transistor plus memristors for synapses, per neuron, but sacrifices negative synaptic weights. This paper demonstrates an optimization technique to minimize the insertion of inverting amplifiers to realize a minimal approximating set of negative weights. This helps to develop a compact, printable and accurate neuromorphic computer to bring new function to the 3-D printing of form in multi-functional robotic materials. An example robotic skin is developed with the ability to compute the centroid of touch \"compiled into the skin\" to an average accuracy of 9.19% in comparison to an unconstrained Artificial Neural Network (ANN). The presented soft robotic skin is fabricated by hand using conventional silicon components, but serves as a proof-of-concept for radical new capabilities in Form + Function 4-D Printing.",
        "primary_area": "",
        "author": "Sangjun Eom;Praveen Abbaraju;Yuqing Xu;Bharath Rajiv Nair;Richard M. Voyles;Sangjun Eom;Praveen Abbaraju;Yuqing Xu;Bharath Rajiv Nair;Richard M. Voyles",
        "authorids": "/37089363650;/37089001824;/37089000967;/37089002170;/37283531400;/37089363650;/37089001824;/37089000967;/37089002170;/37283531400",
        "aff": "Purdue Polytechnic Institute, Purdue University, West Lafayette, IN, USA; Purdue Polytechnic Institute, Purdue University, West Lafayette, IN, USA; Purdue Polytechnic Institute, Purdue University, West Lafayette, IN, USA; Department of Mechanical Engineering, Columbia University, New York, NY, USA; Purdue Polytechnic Institute, Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561199/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10330219563687657573&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Purdue University;Columbia University",
        "aff_unique_dep": "Purdue Polytechnic Institute;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.purdue.edu;https://www.columbia.edu",
        "aff_unique_abbr": "Purdue;Columbia",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "West Lafayette;New York",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561952",
        "title": "Embedding Symbolic Temporal Knowledge into Deep Sequential Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Sequences and time-series often arise in robot tasks, e.g., in activity recognition and imitation learning. In recent years, deep neural networks (DNNs) have emerged as an effective data-driven methodology for processing sequences given sufficient training data and compute resources. However, when data is limited, simpler models such as logic/rule-based methods work surprisingly well, especially when relevant prior knowledge is applied in their construction. However, unlike DNNs, these \"structured\" models can be difficult to extend, and do not work well with raw unstructured data. In this work, we seek to learn flexible DNNs, yet leverage prior temporal knowledge when available. Our approach is to embed symbolic knowledge expressed as linear temporal logic (LTL) and use these embeddings to guide the training of deep models. Specifically, we construct semantic-based embeddings of automata generated from LTL formula via a Graph Neural Network. Experiments show that these learnt embeddings can lead to improvements on downstream robot tasks such as sequential action recognition and imitation learning.",
        "primary_area": "",
        "author": "Yaqi Xie;Fan Zhou;Harold Soh;Yaqi Xie;Fan Zhou;Harold Soh",
        "authorids": "/37086802724;/37088999712;/37684942300;/37086802724;/37088999712;/37684942300",
        "aff": "Dept. of Computer Science, National University of Singapore; Dept. of Computer Science, National University of Singapore; Dept. of Computer Science, National University of Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561952/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5096762266274396744&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Dept. of Computer Science",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9561212",
        "title": "Embodied Reasoning for Discovering Object Properties via Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an integrated system that includes reasoning from visual and natural language inputs, action and motion planning, executing tasks by a robotic arm, manipulating objects, and discovering their properties. A vision to action module recognises the scene with objects and their attributes and analyses enquiries formulated in natural language. It performs multi-modal reasoning and generates a sequence of simple actions that can be executed by a robot. The scene model and action sequence are sent to a planning and execution module that generates a motion plan with collision avoidance, simulates the actions, and executes them. We use synthetic data to train various components of the system and test on a real robot to show the generalization capabilities. We focus on a tabletop scenario with objects that can be grasped by our embodied agent i.e. a 7DoF manipulator with a two-finger gripper. We evaluate the agent on 60 representative queries repeated 3 times (e.g., \u2019Check what is on the other side of the soda can\u2019) concerning different objects and tasks in the scene. We perform experiments in a simulated and real environment and report the success rate for various components of the system. Our system achieves up to 80.6% success rate on challenging scenes and queries. We also analyse and discuss the challenges that such an intelligent embodied system faces.",
        "primary_area": "",
        "author": "Jan Kristof Behrens;Michal Nazarczuk;Karla Stepanova;Matej Hoffmann;Yiannis Demiris;Krystian Mikolajczyk;Jan Kristof Behrens;Michal Nazarczuk;Karla Stepanova;Matej Hoffmann;Yiannis Demiris;Krystian Mikolajczyk",
        "authorids": "/37086828985;/37088504654;/37085758961;/37594773300;/37296338900;/37392300400;/37086828985;/37088504654;/37085758961;/37594773300;/37296338900;/37392300400",
        "aff": "Czech Institute of Informatics, Robotics, and Cybernetics, CTU in Prague, CR; Department of Electrical and Electronic Engineering, Imperial College London, London, UK; Dep. of Cybernetics, Faculty of Electrical Engineering, CTU in Prague; Dep. of Cybernetics, Faculty of Electrical Engineering, CTU in Prague; Department of Electrical and Electronic Engineering, Imperial College London, London, UK; Department of Electrical and Electronic Engineering, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561212/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=383317987140072522&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;1;1",
        "aff_unique_norm": "Czech Technical University in Prague;Imperial College London",
        "aff_unique_dep": "Czech Institute of Informatics, Robotics, and Cybernetics;Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.cvut.cz;https://www.imperial.ac.uk",
        "aff_unique_abbr": "CTU;ICL",
        "aff_campus_unique_index": "0;1;0;0;1;1",
        "aff_campus_unique": "Prague;London",
        "aff_country_unique_index": "0;1;0;0;1;1",
        "aff_country_unique": "Czech Republic;United Kingdom"
    },
    {
        "id": "9562092",
        "title": "Emergent Hand Morphology and Control from Optimizing Robust Grasps of Diverse Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Evolution in nature illustrates that the creatures\u2019 biological structure and their sensorimotor skills adapt to the environmental changes for survival. Likewise, the ability to morph and acquire new skills can facilitate an embodied agent to solve tasks of varying complexities. In this work, we introduce a data-driven approach where effective hand designs naturally emerge for the purpose of grasping diverse objects. Jointly optimizing morphology and control imposes computational challenges since it requires constant evaluation of a black-box function that measures the performance of a combination of embodiment and behavior. We develop a novel Bayesian Optimization algorithm that efficiently co-designs the morphology and grasping skills through learned latent-space representations. We design the grasping tasks based on a taxonomy of human grasp types: power grasp, pinch grasp, and lateral grasp. Through experimentation and comparative study, we demonstrate that our approach discovers robust and cost-efficient hand morphologies for grasping novel objects. Additional videos and results at https://xinleipan.github.io/emergent_morphology",
        "primary_area": "",
        "author": "Xinlei Pan;Animesh Garg;Animashree Anandkumar;Yuke Zhu;Xinlei Pan;Animesh Garg;Animashree Anandkumar;Yuke Zhu",
        "authorids": "/37086934323;/37086330576;/37322138800;/37086080772;/37086934323;/37086330576;/37322138800;/37086080772",
        "aff": "University of California, Berkeley; Vector Institute, University of Toronto; Caltech; The University of Texas, Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562092/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=198719882928574933&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "University of California, Berkeley;University of Toronto;California Institute of Technology;University of Texas at Austin",
        "aff_unique_dep": ";Vector Institute;;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.vectorinstitute.ai;https://www.caltech.edu;https://www.utexas.edu",
        "aff_unique_abbr": "UC Berkeley;Vector Institute;Caltech;UT Austin",
        "aff_campus_unique_index": "0;1;2;3",
        "aff_campus_unique": "Berkeley;Toronto;Pasadena;Austin",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "United States;Canada"
    },
    {
        "id": "9561169",
        "title": "Enabling spatio-temporal aggregation in Birds-Eye-View Vehicle Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Constructing Birds-Eye-View (BEV) maps from monocular images is typically a complex multi-stage process involving the separate vision tasks of ground plane estimation, road segmentation and 3D object detection. However, recent approaches have adopted end-to-end solutions which warp image-based features from the image-plane to BEV while implicitly taking account of camera geometry. In this work, we show how such instantaneous BEV estimation of a scene can be learnt, and a better state estimation of the world can be achieved by incorporating temporal information. Our model learns a representation from monocular video through factorised 3D convolutions and uses this to estimate a BEV occupancy grid of the final frame. We achieve state-of-the-art results for BEV estimation from monocular images, and establish a new benchmark for single-scene BEV estimation from monocular video.",
        "primary_area": "",
        "author": "Avishkar Saha;Oscar Mendez;Chris Russell;Richard Bowden;Avishkar Saha;Oscar Mendez;Chris Russell;Richard Bowden",
        "authorids": "/37089002033;/37710939600;/37089653118;/37268872100;/37089002033;/37710939600;/37089653118;/37268872100",
        "aff": "Centre for Vision Speech and Signal Processing, University of Surrey, Guildford, UK; Centre for Vision Speech and Signal Processing, University of Surrey, Guildford, UK; Amazon, Tubingen, Germany; Centre for Vision Speech and Signal Processing, University of Surrey, Guildford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561169/",
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18284526016190394696&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Surrey;Amazon",
        "aff_unique_dep": "Centre for Vision Speech and Signal Processing;Amazon",
        "aff_unique_url": "https://www.surrey.ac.uk;https://www.amazon.de",
        "aff_unique_abbr": "Surrey;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Guildford;Tubingen",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;Germany"
    },
    {
        "id": "9560788",
        "title": "Encoding Defensive Driving as a Dynamic Nash Game",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots deployed in real-world environments should operate safely in a robust manner. In scenarios where an \"ego\" agent navigates in an environment with multiple other \"non-ego\" agents, two modes of safety are commonly proposed\u2014adversarial robustness and probabilistic constraint satisfaction. However, while the former is generally computationally intractable and leads to overconservative solutions, the latter typically relies on strong distributional assumptions and ignores strategic coupling between agents.To avoid these drawbacks, we present a novel formulation of robustness within the framework of general-sum dynamic game theory, modeled on defensive driving. More precisely, we prepend an adversarial phase to the ego agent\u2019s cost function. That is, we prepend a time interval during which other agents are assumed to be temporarily distracted, in order to render the ego agent\u2019s equilibrium trajectory robust against other agents\u2019 potentially dangerous behavior during this time. We demonstrate the effectiveness of our new formulation in encoding safety via multiple traffic scenarios.",
        "primary_area": "",
        "author": "Chih-Yuan Chiu;David Fridovich-Keil;Claire J. Tomlin;Chih-Yuan Chiu;David Fridovich-Keil;Claire J. Tomlin",
        "authorids": "/37088951911;/37086041251;/37271692600;/37088951911;/37086041251;/37271692600",
        "aff": "Dept. of Electrical Engineering & Computer Sciences, UC Berkeley; Dept. of Aeronautics & Astronautics, Stanford University; Dept. of Electrical Engineering & Computer Sciences, UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560788/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8207210872151454616&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Berkeley;Stanford University",
        "aff_unique_dep": "Department of Electrical Engineering & Computer Sciences;Dept. of Aeronautics & Astronautics",
        "aff_unique_url": "https://www.berkeley.edu;https://www.stanford.edu",
        "aff_unique_abbr": "UC Berkeley;Stanford",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Berkeley;Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561777",
        "title": "Encoding Human Driving Styles in Motion Planning for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Driving styles play a major role in the acceptance and use of autonomous vehicles. Yet, existing motion planning techniques can often only incorporate simple driving styles that are modeled by the developers of the planner and not tailored to the passenger. We present a new approach to encode human driving styles through the use of signal temporal logic and its robustness metrics. Specifically, we use a penalty structure that can be used in many motion planning frameworks, and calibrate its parameters to model different automated driving styles. We combine this penalty structure with a set of signal temporal logic formula, based on the Responsibility-Sensitive Safety model, to generate trajectories that we expected to correlate with three different driving styles: aggressive, neutral, and defensive. An online study showed that people perceived different parameterizations of the motion planner as unique driving styles, and that most people tend to prefer a more defensive automated driving style, which correlated to their self-reported driving style.",
        "primary_area": "",
        "author": "Jesper Karlsson;Sanne van Waveren;Christian Pek;Ilaria Torre;Iolanda Leite;Jana Tumova;Jesper Karlsson;Sanne van Waveren;Christian Pek;Ilaria Torre;Iolanda Leite;Jana Tumova",
        "authorids": "/37086455375;/37086802619;/37085906854;/38228000400;/38576988500;/38230312900;/37086455375;/37086802619;/37085906854;/38228000400;/38576988500;/38230312900",
        "aff": "Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561777/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10279680014450841993&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology",
        "aff_unique_dep": "Division of Robotics, Perception and Learning",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9561889",
        "title": "End-to-End Semi-supervised Learning for Differentiable Particle Filters",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in incorporating neural networks into particle filters provide the desired flexibility to apply particle filters in large-scale real-world applications. The dynamic and measurement models in this framework are learnable through the differentiable implementation of particle filters. Past efforts in optimising such models often require the knowledge of true states which can be expensive to obtain or even unavailable in practice. In this paper, in order to reduce the demand for annotated data, we present an end-to-end learning objective based upon the maximisation of a pseudo-likelihood function which can improve the estimation of states when large portion of true states are unknown. We assess performance of the proposed method in state estimation tasks in robotics with simulated and real-world datasets.",
        "primary_area": "",
        "author": "Hao Wen;Xiongjie Chen;Georgios Papagiannis;Conghui Hu;Yunpeng Li;Hao Wen;Xiongjie Chen;Georgios Papagiannis;Conghui Hu;Yunpeng Li",
        "authorids": "/37088996786;/37088997880;/37088996689;/37086568543;/37085378909;/37088996786;/37088997880;/37088996689;/37086568543;/37085378909",
        "aff": "Department of Computer Science, University of Surrey, Surrey, United Kingdom; Department of Computer Science, University of Surrey, Surrey, United Kingdom; Department of Computer Science, University of Surrey, Surrey, United Kingdom; Department of Computer Science, University of Surrey, Surrey, United Kingdom; Department of Computer Science, University of Surrey, Surrey, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561889/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7617906487214701867&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Surrey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.surrey.ac.uk",
        "aff_unique_abbr": "Surrey",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Surrey",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561518",
        "title": "End-to-end Multi-Instance Robotic Reaching from Monocular Vision",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-instance scenes are especially challenging for end-to-end visuomotor (image-to-control) learning algorithms. \"Pipeline\" visual servo control algorithms use separate detection, selection and servo stages, allowing algorithms to focus on a single object instance during servo control. End-to-end systems do not have separate detection and selection stages and need to address the visual ambiguities introduced by the presence of an arbitrary number of visually identical or similar objects during servo control. However, end-to-end schemes avoid embedding errors from detection and selection stages in the servo control behaviour, are more dynamically robust to changing scenes and are algorithmically simpler. In this paper, we present a reactive real-time end-to-end visuomotor learning algorithm for multi-instance reaching. The proposed algorithm uses a monocular RGB image and the manipulator\u2019s joint angles as the input to a light-weight fully-convolutional network (FCN) to generate control candidates. A key innovation of the proposed method is identifying the optimal control candidate by regressing a control-Lyapunov function (cLf) value. The multi-instance capability emerges naturally from the stability analysis associated with the cLf formulation. We demonstrate the proposed algorithm effectively reaching and grasping objects from different categories on a table-top amid other instances and distractors from an over-the-shoulder monocular RGB camera. The network is able to run up to \u223c160 fps during inference on one GTX 1080 Ti GPU.",
        "primary_area": "",
        "author": "Zheyu Zhuang;Xin Yu;Robert Mahony;Zheyu Zhuang;Xin Yu;Robert Mahony",
        "authorids": "/37087324996;/37086213475;/37283743600;/37087324996;/37086213475;/37283743600",
        "aff": "\"Australian Centre for Robotic Vision\", Research School of Engineering, The Australian National University; School of Computer Science, The University of Technology Sydney; \"Australian Centre for Robotic Vision\", Research School of Engineering, The Australian National University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561518/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12207463673405296161&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Australian National University;University of Technology Sydney",
        "aff_unique_dep": "Research School of Engineering;School of Computer Science",
        "aff_unique_url": "https://www.anu.edu.au;https://www.uts.edu.au",
        "aff_unique_abbr": "ANU;UTS",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Sydney",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9561398",
        "title": "End-to-end Trainable Deep Neural Network for Robotic Grasp Detection and Semantic Segmentation from RGB",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we introduce a novel, end-to-end trainable CNN-based architecture to deliver high quality results for grasp detection suitable for a parallel-plate gripper, and semantic segmentation. Utilizing this, we propose a novel refinement module that takes advantage of previously calculated grasp detection and semantic segmentation and further increases grasp detection accuracy. Our proposed network delivers state-of-the-art accuracy on two popular grasp dataset, namely Cornell and Jacquard. As additional contribution, we provide a novel dataset extension for the OCID dataset, making it possible to evaluate grasp detection in highly challenging scenes. Using this dataset, we show that semantic segmentation can additionally be used to assign grasp candidates to object classes, which can be used to pick specific objects in the scene.",
        "primary_area": "",
        "author": "Stefan Ainetter;Friedrich Fraundorfer;Stefan Ainetter;Friedrich Fraundorfer",
        "authorids": "/37089000824;/37266352400;/37089000824;/37266352400",
        "aff": "Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria; Institute of Computer Graphics and Vision, Graz University of Technology, Graz, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561398/",
        "gs_citation": 167,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8613039445616184548&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Graz University of Technology",
        "aff_unique_dep": "Institute of Computer Graphics and Vision",
        "aff_unique_url": "https://www.tugraz.at",
        "aff_unique_abbr": "TU Graz",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Graz",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9561937",
        "title": "End-to-end grasping policies for human-in-the-loop robots via deep reinforcement learning",
        "track": "main",
        "status": "Poster",
        "abstract": "State-of-the-art human-in-the-loop robot grasping is hugely suffered by Electromyography (EMG) inference robustness issues. As a workaround, researchers have been looking into integrating EMG with other signals, often in an ad hoc manner. In this paper, we are presenting a method for end-to-end training of a policy for human-in-the-loop robot grasping on real reaching trajectories. For this purpose we use Reinforcement Learning (RL) and Imitation Learning (IL) in DEXTRON (DEXTerity enviRONment), a stochastic simulation environment with real human trajectories that are augmented and selected using a Monte Carlo (MC) simulation method. We also offer a success model which once trained on the expert policy data and the RL policy roll-out transitions, can provide transparency to how the deep policy works and when it is probably going to fail.",
        "primary_area": "",
        "author": "Mohammadreza Sharif;Deniz Erdogmus;Christopher Amato;Taskin Padir;Mohammadreza Sharif;Deniz Erdogmus;Christopher Amato;Taskin Padir",
        "authorids": "/37086012946;/37285051800;/37901317700;/38496444600;/37086012946;/37285051800;/37901317700;/38496444600",
        "aff": "Electrical and Computer Engineering Department, Northeastern University, Boston, MA, USA; Electrical and Computer Engineering Department, Northeastern University, Boston, MA, USA; Khoury College of Computer Sciences, Northeastern University, Boston, MA, USA; Electrical and Computer Engineering Department, Northeastern University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561937/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11298880937588571743&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561865",
        "title": "Energy-optimal Path Planning with Active Flow Perception for Autonomous Underwater Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate flow predictions are critical for energy-optimal path planning of AUVs with endurance requirements. However, the complex dynamics of ocean currents make it difficult to achieve accurate flow predictions. For an AUV with flow and location sensing capabilities, one can optimize vehicle actions so that the flow information collected along the vehicle path reduces flow prediction uncertainty, referred to as active flow perception. In this paper, we propose an energy-optimal path planning approach that incorporates active flow perception. The proposed approach achieves the objectives of vehicle energy consumption minimization and flow prediction uncertainty reduction. To quantify flow prediction uncertainty, an empirical flow model parameterized using the proper orthogonal decomposition (POD) is constructed based on historical data. Assuming negligible unmodeled dynamics in the POD model, the flow prediction uncertainty is evaluated by the Cramer-Rao (CR) bound of estimated model parameters. To establish active flow perception combined with energy optimal path planning, we formulate the cost to be minimized during path planning in terms of vehicle energy using estimated flow parameters and CR bound. Through simulations, the proposed approach is compared with approaches that plan energy-optimal paths using i) true flow and ii) flow predictions without active flow perception. Simulation results demonstrate the satisfactory energy-saving performance of the proposed approach.",
        "primary_area": "",
        "author": "Niankai Yang;Dongsik Chang;Matthew Johnson-Roberson;Jing Sun;Niankai Yang;Dongsik Chang;Matthew Johnson-Roberson;Jing Sun",
        "authorids": "/37086592707;/37086937241;/38271635400;/37293638400;/37086592707;/37086937241;/38271635400;/37293638400",
        "aff": "Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, USA; Department of Naval Architecture and Marine Engineering, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561865/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3674364931085921407&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "Department of Naval Architecture and Marine Engineering",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561687",
        "title": "Engagement Estimation During Child Robot Interaction Using Deep Convolutional Networks Focusing on ASD Children",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating the engagement of children is an essential prerequisite for constructing natural Child-Robot Interaction. Especially in the case of children with Autism Spectrum Disorder, monitoring the engagement of the other party allows robots to adjust their actions according to the educational and therapeutic goals in hand. In this work we delve into engagement estimation with a focus on children with autism spectrum disorder. We propose deep convolutional architectures for engagement estimation that outperform previous methods, and explore their performance under variable conditions, in four databases depicting ASD and TD children interacting with robots or humans.",
        "primary_area": "",
        "author": "Dafni Anagnostopoulou;Niki Efthymiou;Christina Papailiou;Petros Maragos;Dafni Anagnostopoulou;Niki Efthymiou;Christina Papailiou;Petros Maragos",
        "authorids": "/37089001378;/37085415030;/37086189905;/37285070800;/37089001378;/37085415030;/37086189905;/37285070800",
        "aff": "School of ECE, National Technical University of Athens, Athens, Greece; School of ECE, National Technical University of Athens, Athens, Greece; Department of Early Childhood Education and Care, University of West Attica, Athens, Greece; School of ECE, National Technical University of Athens, Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561687/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1736534415069524800&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "National Technical University of Athens;University of West Attica",
        "aff_unique_dep": "School of ECE;Department of Early Childhood Education and Care",
        "aff_unique_url": "https://www.ntua.gr;https://www.uoa.gr",
        "aff_unique_abbr": "NTUA;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Athens",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9561343",
        "title": "Enhancement for Robustness of Koopman Operator-based Data-driven Mobile Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Koopman operator theory has served as the basis to extract dynamics for nonlinear system modeling and control across settings, including non-holonomic mobile robot control. There is a growing interest in research to derive robustness (and/or safety) guarantees for systems the dynamics of which are extracted via the Koopman operator. In this paper, we propose a way to quantify the prediction error because of noisy measurements when the Koopman operator is approximated via Extended Dynamic Mode Decomposition. We further develop an enhanced robot control strategy to endow robustness to a class of data-driven (robotic) systems that rely on Koopman operator theory, and we show how part of the strategy can happen offline in an effort to make our algorithm capable of real-time implementation. We perform a parametric study to evaluate the (theoretical) performance of the algorithm using a Van der Pol oscillator, and conduct a series of simulated experiments in Gazebo using a non-holonomic wheeled robot.",
        "primary_area": "",
        "author": "Lu Shi;Konstantinos Karydis;Lu Shi;Konstantinos Karydis",
        "authorids": "/37088516219;/38252121900;/37088516219;/38252121900",
        "aff": "Dept. of Electrical and Computer Engineering, University of California, Riverside; Dept. of Electrical and Computer Engineering, University of California, Riverside",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561343/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12803562024359964539&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Riverside",
        "aff_unique_dep": "Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucr.edu",
        "aff_unique_abbr": "UCR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Riverside",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562114",
        "title": "Enhancing Robot Perception in Grasping and Dexterous Manipulation through Crowdsourcing and Gamification",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot grasping and manipulation planning in unstructured and dynamic environments is heavily dependent on the attributes of manipulated objects. Although deep learning approaches have delivered exceptional performance in robot perception, human perception and reasoning are still superior in processing novel object classes. Moreover, training such models requires large datasets that are generally expensive to obtain. This work combines crowdsourcing and gamification to leverage human intelligence, enhancing the object recognition and attribute estimation aspects of robot perception. The framework employs an attribute matching system that encodes visual information into an online puzzle game, utilizing the collective intelligence of players to expand an initial attribute database and react to real-time perception conflicts. The framework is deployed and evaluated in a proof-of-concept application for enhancing object recognition in autonomous robot grasping and a model for estimating the response time is proposed. The obtained results demonstrate that given enough players, the framework can offer near real-time labeling of novel objects, based purely on visual information and human experience.",
        "primary_area": "",
        "author": "Gal Gorjup;Lucas Gerez;Minas Liarokapis;Gal Gorjup;Lucas Gerez;Minas Liarokapis",
        "authorids": "/37087237844;/37086448935;/38558084100;/37087237844;/37086448935;/38558084100",
        "aff": "New Dexterity research group, The University of Auckland, New Zealand; New Dexterity research group, The University of Auckland, New Zealand; New Dexterity research group, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562114/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1596636351460720207&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Auckland",
        "aff_unique_dep": "New Dexterity research group",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9561857",
        "title": "Enhancing Safety of Students with Mobile Air Filtration during School Reopening from COVID-19",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper discusses how robots enable occupant-safe continuous protection for students when schools reopen. Conventionally, fixed air filters are not used as a key pandemic prevention method for public indoor spaces because they are unable to trap the airborne pathogens in time in the entire room. However, by combining the mobility of a robot with air filtration, the efficacy of cleaning up the air around multiple people is largely increased. A disinfection co-robot prototype is thus developed to provide continuous and occupant-friendly protection to people gathering indoors, specifically for students in a classroom scenario. In a static classroom with students sitting in a grid pattern, the mobile robot is able to serve up to 14 students per cycle while reducing the worst-case pathogen dosage by 20%, and with higher robustness compared to a static filter. The extent of robot protection is optimized by tuning the passing distance and speed, such that a robot is able to serve more people given a threshold of worst-case dosage a person can receive.",
        "primary_area": "",
        "author": "Haoguang Yang;Mythra V. Balakuntala;Abigayle E. Moser;Jhon J. Qui\u00f1ones;Ali Doosttalab;Antonio Esquivel-Puentes;Tanya Purwar;Luciano Castillo;Nina Mahmoudian;Richard M. Voyles;Haoguang Yang;Mythra V. Balakuntala;Abigayle E. Moser;Jhon J. Qui\u00f1ones;Ali Doosttalab;Antonio Esquivel-Puentes;Tanya Purwar;Luciano Castillo;Nina Mahmoudian;Richard M. Voyles",
        "authorids": "/37088998093;/37087236032;/37089000284;/37089000009;/37088996620;/37089001815;/37088996128;/37086589619;/37401735600;/37283531400;/37088998093;/37087236032;/37089000284;/37089000009;/37088996620;/37089001815;/37088996128;/37086589619;/37401735600;/37283531400",
        "aff": "Polytechnic Institute, Purdue University; Polytechnic Institute, Purdue University; Dept. of Aerospace Engineering, Iowa State University; Polytechnic Institute, Purdue University; Dept. of Mechanical Engineering, Purdue University; Dept. of Mechanical Engineering, Purdue University; Dept. of Mechanical Engineering, Purdue University; Dept. of Mechanical Engineering, Purdue University; Dept. of Mechanical Engineering, Purdue University; Polytechnic Institute, Purdue University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561857/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11283013857485897084&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;1;0;0;0;0;0;0;0",
        "aff_unique_norm": "Purdue University;Iowa State University",
        "aff_unique_dep": "Polytechnic Institute;Dept. of Aerospace Engineering",
        "aff_unique_url": "https://www.purdue.edu;https://www.iastate.edu",
        "aff_unique_abbr": "Purdue;ISU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "West Lafayette;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560799",
        "title": "Environment Reconfiguration Planning for Autonomous Robotic Manipulation to overcome Mobility Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel strategy for intelligent robotic environment reconfiguration applied to overcome mobility constraints with an autonomously exploring mobile manipulation system. A realistic problem arising during exploration of unknown challenging environments is the encountering of untraversable areas \u2013given the robot\u2019s mobility constraints\u2013 resulting in the robot getting stuck. We propose that given manipulation capabilities of an autonomous system, it should be possible to leverage loose entities in its surrounding to reconfigure its environment, and therefore potentially restore traversability to an unreachable region. This work\u2019s contribution is two-fold: first, it proposes a mid-range traversability estimation graph-based backend which also allows early detection of terrain gaps, and secondly, it provides an algorithm for focused environment alteration that ensures stable and valid configurations. The plans of this generic policy are evaluated to decide if they resolve the robot\u2019s problem, and are subsequently applied. The effectiveness of the proposed approach is demonstrated via experimental studies using a relevant autonomous system within a mobility-constrained mock-up environment.",
        "primary_area": "",
        "author": "Prateek Arora;Christos Papachristos;Prateek Arora;Christos Papachristos",
        "authorids": "/37085797792;/37681703400;/37085797792;/37681703400",
        "aff": "Robotic Workers (RoboWork) Lab, University of Nevada, Reno, NV, USA; Robotic Workers (RoboWork) Lab, University of Nevada, Reno, NV, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560799/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1767106178809443701&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Nevada, Reno",
        "aff_unique_dep": "Robotic Workers (RoboWork) Lab",
        "aff_unique_url": "https://www.unr.edu",
        "aff_unique_abbr": "UNR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Reno",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561185",
        "title": "Environmental Hotspot Identification in Limited Time with a UAV Equipped with a Downward-Facing Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "Our work is motivated by environmental monitoring tasks, where finding the global maxima (i.e., hotspot) of a spatially varying field is crucial. We investigate the problem of identifying the hotspot for fields that can be sensed using an Unmanned Aerial Vehicle (UAV) equipped with a downward-facing camera. The UAV has a limited time budget which it can use for learning the unknown field and identifying the hotspot. Our contribution is to show how this problem can be formulated as a novel multi-fidelity variant of the Gaussian Process (GP) multi-armed bandit problem. The novelty is two-fold: (i) unlike standard multi-armed bandit settings, the rewards of the arms are correlated with each other; and (ii) unlike standard GP regression, the measurements in our problem are images (i.e., vector measurements) whose quality depends on the altitude of the UAV. We present a strategy for finding the sequence of UAV sensing locations and empirically compare it with several baselines. Experimental results using images gathered onboard a UAV are also presented and the scalability of the proposed methodology is assessed in a large-scale simulated environment.",
        "primary_area": "",
        "author": "Yoonchang Sung;Deeksha Dixit;Pratap Tokekar;Yoonchang Sung;Deeksha Dixit;Pratap Tokekar",
        "authorids": "/38235977600;/37089002129;/37546532700;/38235977600;/37089002129;/37546532700",
        "aff": "CSAIL, MIT, Cambridge, MA, USA; Department of Computer Science, University of Maryland, College Park, MD, USA; Department of Computer Science, University of Maryland, College Park, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561185/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13465756904325072914&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Maryland",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;Department of Computer Science",
        "aff_unique_url": "https://www.csail.mit.edu;https://www/umd.edu",
        "aff_unique_abbr": "MIT;UMD",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Cambridge;College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561339",
        "title": "Equality Constrained Differential Dynamic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "Trajectory optimization is an important tool in task-based robot motion planning, due to its generality and convergence guarantees under some mild conditions. It is often used as a post-processing operation to smooth out trajectories that are generated by probabilistic methods or to directly control the robot motion. Unconstrained trajectory optimization problems have been well studied, and are commonly solved using Differential Dynamic Programming methods that allow for fast convergence at a relatively low computational cost. In this paper, we propose an augmented Lagrangian approach that extends these ideas to equality-constrained trajectory optimization problems, while maintaining a balance between convergence speed and numerical stability. We illustrate our contributions on various standard robotic problems and highlights their benefits compared to standard approaches.",
        "primary_area": "",
        "author": "Sarah El Kazdadi;Justin Carpentier;Jean Ponce;Sarah El Kazdadi;Justin Carpentier;Jean Ponce",
        "authorids": "/37089001780;/37085506841;/37282647000;/37089001780;/37085506841;/37282647000",
        "aff": "Inria and D\u00e9partement d\u2019Informatique de l\u2019Ecole Normale Suprieure, PSL Research University, Paris, France; Inria and D\u00e9partement d\u2019Informatique de l\u2019Ecole Normale Suprieure, PSL Research University, Paris, France; Inria and D\u00e9partement d\u2019Informatique de l\u2019Ecole Normale Suprieure, PSL Research University, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561339/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1252523153148987989&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "INRIA",
        "aff_unique_dep": "D\u00e9partement d\u2019Informatique de l\u2019Ecole Normale Sup\u00e9rieure",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9562000",
        "title": "Equality Constrained Linear Optimal Control With Factor Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel factor graph-based approach to solve the discrete-time finite-horizon Linear Quadratic Regulator problem subject to auxiliary linear equality constraints within and across time steps. We represent such optimal control problems using constrained factor graphs and optimize the factor graphs to obtain the optimal trajectory and the feedback control policies using the variable elimination algorithm with a modified Gram-Schmidt process. We prove that our approach has the same order of computational complexity as the state-of-the-art dynamic programming approach. Furthermore, current dynamic programming approaches can only handle equality constraints between variables at the same time step, but ours can handle equality constraints among any combination of variables at any time step while maintaining linear complexity with respect to trajectory length. Our approach can be used to efficiently generate trajectories and feedback control policies to achieve periodic motion or repetitive manipulation.",
        "primary_area": "",
        "author": "Shuo Yang;Gerry Chen;Yetong Zhang;Howie Choset;Frank Dellaert;Shuo Yang;Gerry Chen;Yetong Zhang;Howie Choset;Frank Dellaert",
        "authorids": "/37088996427;/37089000441;/37088998216;/37281322200;/37282902200;/37088996427;/37089000441;/37088998216;/37281322200;/37282902200",
        "aff": "Robotics Institute and Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta; Robotics Institute and Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh; Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562000/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2947188843461567155&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Carnegie Mellon University;Georgia Institute of Technology",
        "aff_unique_dep": "Robotics Institute and Department of Mechanical Engineering;Institute for Robotics and Intelligent Machines",
        "aff_unique_url": "https://www.cmu.edu;https://www.gatech.edu",
        "aff_unique_abbr": "CMU;Georgia Tech",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Pittsburgh;Atlanta",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561746",
        "title": "Ergodic imitation: Learning from what to do and what not to do",
        "track": "main",
        "status": "Poster",
        "abstract": "With growing access to versatile robotics, it is beneficial for end users to be able to teach robots tasks without needing to code a control policy. One possibility is to teach the robot through successful task executions. However, near-optimal demonstrations of a task can be difficult to provide and even successful demonstrations can fail to capture task aspects key to robust skill replication. Here, we propose a learning from demonstration (LfD) approach that enables learning of robust task definitions without the need for near-optimal demonstrations. We present a novel algorithmic framework for learning tasks based on the ergodic metric\u2014a measure of information content in motion. Moreover, we make use of negative demonstrations\u2014demonstrations of what not to do\u2014and show that they can help compensate for imperfect demonstrations, reduce the number of demonstrations needed, and highlight crucial task elements improving robot performance. In a proof-of-concept example of cart-pole inversion, we show that negative demonstrations alone can be sufficient to successfully learn and recreate a skill. Through a human subject study with 24 participants, we show that consistently more information about a task can be captured from combined positive and negative (posneg) demonstrations than from the same amount of just positive demonstrations. Finally, we demonstrate our learning approach on simulated tasks of target reaching and table cleaning with a 7-DoF Franka arm. Our results point towards a future with robust, data-efficient LfD for novice users.",
        "primary_area": "",
        "author": "Aleksandra Kalinowska;Ahalya Prabhakar;Kathleen Fitzsimons;Todd Murphey;Aleksandra Kalinowska;Ahalya Prabhakar;Kathleen Fitzsimons;Todd Murphey",
        "authorids": "/37086934650;/37085730832;/37085841035;/37329499800;/37086934650;/37085730832;/37085841035;/37329499800",
        "aff": "Mechanical Engineering, Northwestern University, Evanston, IL; Mechanical Engineering, Northwestern University, Evanston, IL; Mechanical Engineering, Northwestern University, Evanston, IL; Physical Therapy and Human Movement Sciences, Northwestern University, Chicago, IL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561746/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4275340162079214934&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Northwestern University",
        "aff_unique_dep": "Mechanical Engineering",
        "aff_unique_url": "https://www.northwestern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Evanston;Chicago",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561679",
        "title": "Estimation and Adaption of Indoor Ego Airflow Disturbance with Application to Quadrotor Trajectory Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "It is ubiquitously accepted that during the autonomous navigation of the quadrotors, one of the most widely adopted unmanned aerial vehicles (UAVs), safety always has the highest priority. However, it is observed that the ego airflow disturbance can be a significant adverse factor during flights, causing potential safety issues, especially in narrow and confined indoor environments. Therefore, we propose a novel method to estimate and adapt indoor ego airflow disturbance of quadrotors, meanwhile applying it to trajectory planning. Firstly, the hover experiments for different quadrotors are conducted against the proximity effects. Then with the collected acceleration variance, the disturbances are modeled for the quadrotors according to the proposed formulation. The disturbance model is also verified under hover conditions in different reconstructed complex environments. Furthermore, the approximation of Hamilton-Jacobi reachability analysis is performed according to the estimated disturbances to facilitate the safe trajectory planning, which consists of kinodynamic path search as well as B-spline trajectory optimization. The whole planning framework is validated on multiple quadrotor platforms in different indoor environments.",
        "primary_area": "",
        "author": "Luqi Wang;Boyu Zhou;Chuhao Liu;Shaojie Shen;Luqi Wang;Boyu Zhou;Chuhao Liu;Shaojie Shen",
        "authorids": "/37086690004;/37086574790;/37086922152;/37954847200;/37086690004;/37086574790;/37086922152;/37954847200",
        "aff": "Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561679/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8750467502157117153&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561544",
        "title": "Estimation of Spatially-Correlated Ocean Currents from Ensemble Forecasts and Online Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method to estimate two-dimensional, time-invariant oceanic flow fields based on data from both ensemble forecasts and online measurements. Our method produces a realistic estimate in a computationally efficient manner suitable for use in marine robotics for path planning and related applications. We use kernel methods and singular value decomposition to find a compact model of the ensemble data that is represented as a linear combination of basis flow fields and that preserves the spatial correlations present in the data. Online measurements of ocean current, taken for example by marine robots, can then be incorporated using recursive Bayesian estimation. We provide computational analysis, performance comparisons with related methods, and demonstration with real-world ensemble data to show the computational efficiency and validity of our method. Possible applications in addition to path planning include active perception for model improvement through deliberate choice of measurement locations.",
        "primary_area": "",
        "author": "K. Y. Cadmus To;Felix H. Kong;Ki Myung Brian Lee;Chanyeol Yoo;Stuart Anstee;Robert Fitch;K. Y. Cadmus To;Felix H. Kong;Ki Myung Brian Lee;Chanyeol Yoo;Stuart Anstee;Robert Fitch",
        "authorids": "/37086933783;/37088545936;/37086938150;/37086933786;/37601910400;/38466367800;/37086933783;/37088545936;/37086938150;/37086933786;/37601910400;/38466367800",
        "aff": "University of Technology, Sydney, NSW, Australia; University of Technology, Sydney, NSW, Australia; University of Technology, Sydney, NSW, Australia; University of Technology, Sydney, NSW, Australia; Department of Defence, Defence Science and Technology Group, Australia; University of Technology, Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561544/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9400632962079282589&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "University of Technology Sydney;Defence Science and Technology Group",
        "aff_unique_dep": ";Department of Defence",
        "aff_unique_url": "https://www.uts.edu.au;https://www.dstgroup.com.au",
        "aff_unique_abbr": "UTS;DST Group",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9560882",
        "title": "Evaluating Initialization Methods for Discriminative and Fast-Converging HGMM Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Discriminative data representations for point cloud data are critical for computer vision applications. Recently, the Hierarchical Gaussian Mixture Model (HGMM) has become a popular representation due to its compactness and real-time execution. However, HGMM still lacks a well-designed and robust initialization criterion. Ad-hoc initializations for HGMM can lead to a low discriminative clustering capability, slow convergence, and loss of scale-invariance. To adopt the optimal initialization scheme, we evaluate four potential candidates: K-Means++, Fuzzy C-Means (FCM), uniform, and random initialization across a few synthetic and measured datasets. Our experiments involve comparing the quality of HGMM point cloud reconstruction based on different initialization methods. The reconstruction quality is evaluated by the peak signal-to-noise ratio (PSNR). Our experiments show that clustering-based initialization methods can result in higher-quality HGMMs because of i) faster convergence of the Expectation-Maximization (EM) optimization, ii) better scaleinvariance across differently sized datasets, and iii) greater stability for different initial scales of covariance matrices of the HGMM.",
        "primary_area": "",
        "author": "Haohan Lin;Xuzhan Chen;Matthew Tucsok;Li Ji;Homayoun Najjaran;Haohan Lin;Xuzhan Chen;Matthew Tucsok;Li Ji;Homayoun Najjaran",
        "authorids": "/37088997766;/37086312030;/37089001540;/37088662302;/37284326900;/37088997766;/37086312030;/37089001540;/37088662302;/37284326900",
        "aff": "University of British Columbia, Canada; Huazhong University of Science and Technology, China; University of British Columbia, Canada; LlamaZOO Interactive Inc., Canada; University of British Columbia, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560882/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2834090711724222894&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;0",
        "aff_unique_norm": "University of British Columbia;Huazhong University of Science and Technology;LlamaZOO Interactive Inc.",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.ubc.ca;http://www.hust.edu.cn;",
        "aff_unique_abbr": "UBC;HUST;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Canada;China"
    },
    {
        "id": "9561088",
        "title": "Evaluation of a drone-based camera calibration approach for hard-to-reach cameras",
        "track": "main",
        "status": "Poster",
        "abstract": "Several applications of video rely on camera calibration, a key enabler towards the measurement of metric parameters from images. Existing calibration methods have not been adapted for use with cameras that are hard to reach such as security cameras. This paper presents a drone-based camera calibration technique for the calibration of cameras in a broader range of operating environments. The technique is enabled by the use of a drone that is equipped with location sensors. In the proposed approach, the drone is used to sample points in the 3D space and its detection on the images provides the 2D matching points enabling the calibration. To design a flight path that allows for an accurate calibration, the paper proposes a methodology to evaluate the impact of path parameters and drone localization and detection uncertainties on the calibration uncertainty. This methodology is applied to evaluate the performance of different sampling paths for the calibration of a large diversity of cameras for the purpose of recommending reliable path parameters.",
        "primary_area": "",
        "author": "Domitille Commun;C\u00e9dric Pradalier;Michael Balchanos;Olivia Fischer;Dimitri Mavris;Domitille Commun;C\u00e9dric Pradalier;Michael Balchanos;Olivia Fischer;Dimitri Mavris",
        "authorids": "/37089001826;/37279005400;/37660708100;/37088996183;/37395973000;/37089001826;/37279005400;/37660708100;/37088996183;/37395973000",
        "aff": "Aerospace Systems Design Laboratory, Georgia Tech, Atlanta, USA; CNRS UMI 2958, Georgia Tech, Lorraine, France; Aerospace Systems Design Laboratory, Georgia Tech, Atlanta, USA; Aerospace Systems Design Laboratory, Georgia Tech, Atlanta, USA; Aerospace Systems Design Laboratory, Georgia Tech, Atlanta, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561088/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7494193523543075069&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology;Georgia Tech",
        "aff_unique_dep": "Aerospace Systems Design Laboratory;",
        "aff_unique_url": "https://www.gatech.edu;https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech;GT",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Atlanta;Lorraine",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "9560881",
        "title": "Event-driven Vision and Control for UAVs on a Neuromorphic Chip",
        "track": "main",
        "status": "Poster",
        "abstract": "Event-based vision sensors achieve up to three orders of magnitude better speed vs. power consumption trade off in high-speed control of UAVs compared to conventional image sensors. Event-based cameras produce a sparse stream of events that can be processed more efficiently and with a lower latency than images, enabling ultra-fast vision-driven control. Here, we explore how an event-based vision algorithm can be implemented as a spiking neuronal network on a neuromorphic chip and used in a drone controller. We show how seamless integration of event-based perception on chip leads to even faster control rates and lower latency. In addition, we demonstrate how online adaptation of the SNN controller can be realised using on-chip learning. Our spiking neuronal network on chip is the first example of a neuromorphic vision-based controller on chip solving a high-speed UAV control task. The excellent scalability of processing in neuromorphic hardware opens the possibility to solve more challenging visual tasks in the future and integrate visual perception in fast control loops.",
        "primary_area": "",
        "author": "Antonio Vitale;Alpha Renner;Celine Nauer;Davide Scaramuzza;Yulia Sandamirskaya;Antonio Vitale;Alpha Renner;Celine Nauer;Davide Scaramuzza;Yulia Sandamirskaya",
        "authorids": "/37528489200;/37086575464;/37088996952;/37397688400;/38498075300;/37528489200;/37086575464;/37088996952;/37397688400;/38498075300",
        "aff": "Neuromorphic Computing Lab of Intel, Intel Labs, Munich, Germany; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Institute of Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Robotic Perception Group, at both Institutes of Informatics, University of Zurich, and Neuroinformatics, University of Zurich and ETH Zurich, Switzerland; Neuromorphic Computing Lab of Intel, Intel Labs, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560881/",
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15716697847697029586&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Intel;University of Zurich",
        "aff_unique_dep": "Neuromorphic Computing Lab;Institute of Neuroinformatics",
        "aff_unique_url": "https://www.intel.de;https://www.neuro.ethz.ch/",
        "aff_unique_abbr": "Intel;UZH",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Munich;",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "id": "9561602",
        "title": "Evolvable Motion-planning Method using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "A motion-planning method that can adapt to changes in the surrounding environment is proposed and evaluated. Automation of work is progressing in factories and distribution warehouses due to labor shortages. However, utilizing robots for transport operations in a distribution warehouse faces a problem; that is, tasks for setting up a robot, such as adjustment of acceleration for stabilization of the transportation operation, are time consuming. To solve that problem, we developed an \"evolvable robot motion-planning method.\" The aim of this method is to reduce the preparation cost by allowing the robot to automatically learn the optimized acceleration according to the weight and center of gravity of the objects to be transported. It was experimentally demonstrated that the proposed method can learn the optimized acceleration control from time-series data such as sensor information. The proposed method was evaluated in a simulator environment, and the results of the evaluation demonstrate that the learned model reduced the inertial force due to the acceleration of robot motion and shortened the transport time by 35% compared with the conventional method of manual adjustment. The proposed method was also evaluated in a real machine environment, and the evaluation results demonstrate that the method can be applied to a real robot. Since the speed of the robot does not need to be adjusted in the case of the proposed method, the adjustment man-hours can be reduced.",
        "primary_area": "",
        "author": "Kaichiro Nishi;Nobuaki Nakasu;Kaichiro Nishi;Nobuaki Nakasu",
        "authorids": "/37086329489;/37087327591;/37086329489;/37087327591",
        "aff": "Production Systems Research Department, Center for Technology Innovation - Production Engineering, Hitachi, Ltd. Research and Development Group, Yokohama, Japan; Production Systems Research Department, Center for Technology Innovation - Production Engineering, Hitachi, Ltd. Research and Development Group, Yokohama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561602/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10496448298381976473&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hitachi, Ltd.",
        "aff_unique_dep": "Production Systems Research Department",
        "aff_unique_url": "https://www.hitachi.com",
        "aff_unique_abbr": "Hitachi",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Yokohama",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561346",
        "title": "Expansive Voronoi Tree: A Motion Planner for Assembly Sequence Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "One major challenge in Assembly Sequence Planning (ASP) for complex real-world CAD-scenarios is to find an appropriate disassembly path for each assembled part. Complex real-world scenes are characterized by a large installation space. There each part has many different possible disassembly paths that differ in length and clearance. However, due to tight packing in the installation space, these paths can contain narrow passages. Therefore a motion planner is needed that is able to globally search for a reasonable path and to locally overcome narrow passages. Moreover, since motion planning requests are executed in the ASP context over and over again for many parts, both for those that can be disassembled in the next step and for those that cannot be yet, the motion planner has to be reliably fast.We present a new rigid body motion planner, called Expansive Voronoi Tree (EVT), which is optimized for complex ASP scenarios. The EVT estimates a globally reasonable path using a General Voronoi Diagram of the complete scene. With a novel EST-based sampling strategy, which is the contribution of this paper, it then locally explores the environment along the estimated path. The EVT automatically adapts to different clearance situations. It passes wide environments quickly and samples densely at narrow passages.We compare our EVT to state of the art motion planners which use different sampling strategies on a real-world data set consisting of a large subset of a car. The experiments show that the EVT is reliably many times faster and delivers shorter paths.",
        "primary_area": "",
        "author": "Sebastian Dorn;Nicola Wolpert;Elmar Sch\u00f6mer;Sebastian Dorn;Nicola Wolpert;Elmar Sch\u00f6mer",
        "authorids": "/37088503781;/37085352554;/37331462600;/37088503781;/37085352554;/37331462600",
        "aff": "Production Planning, Mercedes-Benz AG, Germany; Department: Geomatics, Computer Science and Mathematics, University of Applied Science Stuttgart, Germany; Department: Physics, Mathematics and Computer Science, Johannes Gutenberg - University Mainz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561346/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=914282946385174699&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Mercedes-Benz AG;University of Applied Sciences Stuttgart;Johannes Gutenberg University Mainz",
        "aff_unique_dep": "Production Planning;Department of Geomatics, Computer Science and Mathematics;Department of Physics, Mathematics and Computer Science",
        "aff_unique_url": "https://www.mercedes-benz.com;https://www.hft-stuttgart.de;https://www.jgu.de",
        "aff_unique_abbr": "MBAG;;JGU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mainz",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9562010",
        "title": "Experimental Validation of Unsteady Wave Induced Loads on a Stationary Remotely Operated Vehicle",
        "track": "main",
        "status": "Poster",
        "abstract": "Shallow water environments pose daunting scenarios for the operation of Unmanned Underwater Vehicles (UUVs), due to significantly larger wave disturbances being present in comparison to a typical deep sea situation. Performing inspection and maintenance tasks at close quarters in these conditions requires reliable control methods robust to external disturbances, allowing accurate position and attitude control, an aspect which classical control methods are often lacking. Improved performance can be achieved through predictive control methods, however, these require accurate and time-efficient estimations of the hydrodynamic forces produced by the immediate ocean environment around the vehicle. Considering this, we present a low-order model for faster-than-real time estimation of the wave-induced hydrodynamic forces acting on a submerged vehicle in various sea state conditions. The model is thoroughly corroborated by experimental tests, performed using a Remotely Operated Vehicle (ROV) situated at shallow depth whilst subjected to realistic sea wave disturbances. Validation between simulations and the collected experimental data showed a maximum normalised mean error deviation of 0.16 and 0.27 for surge and heave forces respectively, and 0.34 for the pitching moment. This empirical evidence demonstrates that accurate predictions of wave-generated forces can be produced through low-order models at a speed suitable for incorporation within predictive control architectures.",
        "primary_area": "",
        "author": "Kyle L. Walker;Roman Gabl;Simona Aracri;Yu Cao;Adam A. Stokes;Aristides Kiprakis;Francesco Giorgio-Serchi;Kyle L. Walker;Roman Gabl;Simona Aracri;Yu Cao;Adam A. Stokes;Aristides Kiprakis;Francesco Giorgio-Serchi",
        "authorids": "/37088836969;/37088760382;/37086842614;/37088496422;/37824805800;/38549458500;/37085546251;/37088836969;/37088760382;/37086842614;/37088496422;/37824805800;/38549458500;/37085546251",
        "aff": "Institute for Integrated Micro and Nano Systems, School of Engineering, University of Edinburgh, Edinburgh, U.K; FloWave Ocean Research Facility, School of Engineering, University of Edinburgh, Edinburgh, U.K; Institute for Integrated Micro and Nano Systems, School of Engineering, University of Edinburgh, Edinburgh, U.K; Institute for Energy Systems, School of Engineering, University of Edinburgh, Edinburgh, U.K; Institute for Integrated Micro and Nano Systems, School of Engineering, University of Edinburgh, Edinburgh, U.K; Institute for Energy Systems, School of Engineering, University of Edinburgh, Edinburgh, U.K; Institute for Integrated Micro and Nano Systems, School of Engineering, University of Edinburgh, Edinburgh, U.K",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562010/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5869773153378384003&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "School of Engineering",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561327",
        "title": "Exploiting Local Geometry for Feature and Graph Construction for Better 3D Point Cloud Processing with Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose simple yet effective improvements in point representations and local neighborhood graph construction within the general framework of graph neural networks (GNNs) for 3D point cloud processing. As a first contribution, we propose to augment the vertex representations with important local geometric information of the points, followed by nonlinear projection using a MLP. As a second contribution, we propose to improve the graph construction for GNNs for 3D point clouds. The existing methods work with a k-NN based approach for constructing the local neighborhood graph. We argue that it might lead to reduction in coverage in case of dense sampling by sensors in some regions of the scene. The proposed methods aims to counter such problems and improve coverage in such cases. As the traditional GNNs were designed to work with general graphs, where vertices may have no geometric interpretations, we see both our proposals as augmenting the general graphs to incorporate the geometric nature of 3D point clouds. While being simple, we demonstrate with multiple challenging benchmarks, with relatively clean CAD models, as well as with real world noisy scans, that the proposed method achieves state of the art results on benchmarks for 3D classification (ModelNet40) , part segmentation (ShapeNet) and semantic segmentation (Stanford 3D Indoor Scenes Dataset). We also show that the proposed network achieves faster training convergence, i.e. \u223c 40% less epochs for classification. The project details are available at https://siddharthsrivastava.github.io/publication/geomgcnn/",
        "primary_area": "",
        "author": "Siddharth Srivastava;Gaurav Sharma;Siddharth Srivastava;Gaurav Sharma",
        "authorids": "/37085783892;/37274173200;/37085783892;/37274173200",
        "aff": "Centre for Development of Advanced Computing, Noida, India; TensorTour and IIT Kanpur",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561327/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5628405449733658828&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Centre for Development of Advanced Computing;IIT Kanpur",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cdac.in;https://www.iitk.ac.in",
        "aff_unique_abbr": "CDAC;IITK",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Noida;Kanpur",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9561757",
        "title": "Exploiting Probabilistic Siamese Visual Tracking with a Conditional Variational Autoencoder",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual tracking is a fundamental capability for robots tasked with humans and environment interaction. However, state-of-the-art visual tracking methods are still prone to failures and are imprecise when applied to challenging stereos, and their results are generally confidence agonistic. These methods depend on an embedded deep learning model to provide deterministic features or regression maps. A deterministic output with low confidence can result in disastrous consequences and lacks evidence needed for subsequent operations. Moreover, training data ambiguities or noise in the observations (so-called data uncertainty) can also lead to inherent uncertainty. In this paper, we focus on exploiting probabilistic Siamese visual tracking with a conditional variational autoencoder (CVAE). First, we build a bridge between the Siamese architecture and the CVAE and propose a novel Bayesian visual tracking method. Second, the proposed method generates a complete probability distribution that enables the production of multiple plausible tracking outputs. Third, CVAE conditioned by ground truth data encodes a low-dimensional latent space and conducts noise-injection training to prevent overfitting. Our proposed tracking method outperformed the state-of-the-art trackers on the VOT2016, VOT2018 and TColor-128 datasets.",
        "primary_area": "",
        "author": "Wenhui Huang;Jason Gu;Peiyong Duan;Sujuan Hou;Yuanjie Zheng;Wenhui Huang;Jason Gu;Peiyong Duan;Sujuan Hou;Yuanjie Zheng",
        "authorids": "/37085481429;/37276928500;/37086406243;/37087043523;/37293341700;/37085481429;/37276928500;/37086406243;/37087043523;/37293341700",
        "aff": "School of Information Science and Engineering, Shandong Normal University, China; Department of Electrical and Computer Engineering, Dalhousie University, Halifax, Canada; School of Information Science and Engineering, Shandong Normal University, China; School of Information Science and Engineering, Shandong Normal University, China; Shandong Provincial Key Laboratory for Novel Distributed Computer Software Technology, Shandong Normal University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561757/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4360616187156741090&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Shandong Normal University;Dalhousie University",
        "aff_unique_dep": "School of Information Science and Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.sdu.edu.cn;https://www.dal.ca",
        "aff_unique_abbr": ";Dalhousie",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Halifax",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "9561166",
        "title": "Exploiting collisions for sampling-based multicopter motion planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Multicopters with collision-resilient designs can operate with trajectories involving collisions. This paper presents a sampling-based method that can exploit collisions for better motion planning. The method is built upon the basis of the RRT* algorithm and takes advantages of fast motion primitive generation and collision checking for multicopters. It generates collision states by detecting potential intersections between motion primitives and obstacles, and connects these states with other sampled states to form collision-inclusive trajectories. We show that allowing collision helps improve the performance of the sampling-based planner in narrow spaces like tunnels. Finally, an experiment of tracking the trajectory generated by the collision-inclusive planner is presented.",
        "primary_area": "",
        "author": "Jiaming Zha;Mark W. Mueller;Jiaming Zha;Mark W. Mueller",
        "authorids": "/37086939196;/37086448968;/37086939196;/37086448968",
        "aff": "HiPeRLab, University of California, Berkeley, CA, USA; HiPeRLab, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561166/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17741057160478125784&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "HiPeRLab",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561467",
        "title": "Exploiting latent representation of sparse semantic layers for improved short-term motion prediction with Capsule Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "As urban environments manifest high levels of complexity it is of vital importance that safety systems embedded within autonomous vehicles (AVs) are able to accurately anticipate short-term future motion of nearby agents. This problem can be further understood as generating a sequence of coordinates describing the future motion of the tracked agent. Various proposed approaches demonstrate significant benefits of using a rasterised top-down image of the road, with a combination of Convolutional Neural Networks (CNNs), for extraction of relevant features that define the road structure (eg. driveable areas, lanes, walkways). In contrast, this paper explores use of Capsule Networks (CapsNets) in the context of learning a hierarchical representation of sparse semantic layers corresponding to small regions of the High-Definition (HD) map. Each region of the map is dismantled into separate geometrical layers that are extracted with respect to the agent\u2019s current position. By using an architecture based on CapsNets the model is able to retain hierarchical relationships between detected features within images whilst also preventing loss of spatial data often caused by the pooling operation. We train and evaluate our model on publicly available dataset nuTonomy scenes and compare it to recently published methods. We show that our model achieves significant improvement over recently published works on deterministic prediction, whilst drastically reducing the overall size of the network.",
        "primary_area": "",
        "author": "Albert Dulian;John C. Murray;Albert Dulian;John C. Murray",
        "authorids": "/37088997653;/37088861736;/37088997653;/37088861736",
        "aff": "Department of Computer Science and Technology, The University of Hull, Kingston Upon Hull, United Kingdom; Department of Computer Science and Technology, The University of Hull, Kingston Upon Hull, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561467/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1688542066149682548&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Hull",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.hull.ac.uk",
        "aff_unique_abbr": "Hull",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kingston Upon Hull",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9560739",
        "title": "Exploiting visual servoing and centroidal momentum for whole-body motion control of humanoid robots in absence of contacts and gravity",
        "track": "main",
        "status": "Poster",
        "abstract": "The big potential of humanoid robots is not restricted to the ground, but these versatile machines can be successfully employed in unconventional scenarios, e.g. space, where contacts are not always present. In these situations, the robot\u2019s limbs can be used to assist or even generate the angular motion of the floating base, as a consequence of the centroidal momentum conservation. In this paper, we propose to combine, in the same whole-body motion control, visual servoing and centroidal momentum conservation. The former dictates a rotation to the floating humanoid to achieve a task in the Cartesian space; the latter is exploited to realize the desired rotation by moving the robot\u2019s articulations. Simulations in a space scenario are carried out using COMAN, a humanoid robot developed at the Istituto Italiano di Tecnologia.",
        "primary_area": "",
        "author": "Enrico Mingo Hoffman;Antonio Paolillo;Enrico Mingo Hoffman;Antonio Paolillo",
        "authorids": "/37085377101;/37077525100;/37085377101;/37077525100",
        "aff": "Humanoids & Human Centred Mechatronics (HHCM) Lab., Istituto Italiano di Tecnologia (IIT), Genova, Italy; Dalle Molle Institute for Artificial Intelligence (IDSIA), USI-SUPSI, Lugano, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560739/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=351634099445449643&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;Dalle Molle Institute for Artificial Intelligence",
        "aff_unique_dep": "Humanoids & Human Centred Mechatronics (HHCM) Lab.;Institute for Artificial Intelligence",
        "aff_unique_url": "https://www.iit.it;https://www.idsia.ch/",
        "aff_unique_abbr": "IIT;IDSIA",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Genova;Lugano",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Italy;Switzerland"
    },
    {
        "id": "9561580",
        "title": "Exploration of Large Outdoor Environments Using Multi-Criteria Decision Making",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a Multi-Criteria Decision Making (MCDM) framework specifically designed for planetary exploration. Our work is based on PROMETHEE II, which allows operators to add task-specific criteria and conditions. We extended this algorithm to improve its resource usage by reducing the number of candidate exploration goals that have to be evaluated and compared. This is crucial when given a large number of goals, as is typical for outdoor environments. In addition, we identified five different criteria for planetary exploration, including a novel criterion that we call Direction of Interest (DOI), and use a categorization of these for further resource optimizations. We thereby ensure that the CPU usage of our decision making method can meet the limited budget of a space rover. We present simulated and real-world experiments with the Lightweight Rover Unit (LRU) and show a reduction of the processing time for decision making of approx. 70%.",
        "primary_area": "",
        "author": "Hannah Lehner;Martin J. Schuster;Tim Bodenm\u00fcller;Rudolph Triebel;Hannah Lehner;Martin J. Schuster;Tim Bodenm\u00fcller;Rudolph Triebel",
        "authorids": "/37086336373;/37604581900;/37273191300;/37542908700;/37086336373;/37604581900;/37273191300;/37542908700",
        "aff": "Department of Perception and Cognition, German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), Wessling, Germany; Department of Perception and Cognition, German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), Wessling, Germany; Department of Perception and Cognition, German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), Wessling, Germany; Department of Perception and Cognition, German Aerospace Center (DLR), Robotics and Mechatronics Center (RMC), Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561580/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15490937325945180429&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "German Aerospace Center (DLR)",
        "aff_unique_dep": "Department of Perception and Cognition",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Wessling",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9562034",
        "title": "Exploring Dynamic Context for Multi-path Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "To accurately predict future positions of different agents in traffic scenarios is crucial for safely deploying intelligent autonomous systems in the real-world environment. However, it remains a challenge due to the behavior of a target agent being affected by other agents dynamically and there being more than one socially possible paths the agent could take. In this paper, we propose a novel framework, named Dynamic Context Encoder Network (DCENet). In our framework, first, the spatial context between agents is explored by using self-attention architectures. Then, the two-stream encoders are trained to learn temporal context between steps by taking the respective observed trajectories and the extracted dynamic spatial context as input. The spatial-temporal context is encoded into a latent space using a Conditional Variational Auto-Encoder (CVAE) module. Finally, a set of future trajectories for each agent is predicted conditioned on the learned spatial-temporal context by sampling from the latent space, repeatedly. DCENet is evaluated on one of the most popular challenging benchmarks for trajectory forecasting Trajnet and reports a new state-of-the-art performance. It also demonstrates superior performance evaluated on the benchmark inD for mixed traffic at intersections. A series of ablation studies is conducted to validate the effectiveness of each proposed module. Our code is available at https://github.com/wtliao/DCENet.",
        "primary_area": "",
        "author": "Hao Cheng;Wentong Liao;Xuejiao Tang;Michael Ying Yang;Monika Sester;Bodo Rosenhahn;Hao Cheng;Wentong Liao;Xuejiao Tang;Michael Ying Yang;Monika Sester;Bodo Rosenhahn",
        "authorids": "/37086547045;/37085621891;/37089398045;/37086073066;/37085706434;/37294525800;/37086547045;/37085621891;/37089398045;/37086073066;/37085706434;/37294525800",
        "aff": "Institute of Cartography and Geoinformatics, Leibniz University Hannover, Germany; Institute of Information Processing, Leibniz University Hannover, Germany; Institute of Information Processing, Leibniz University Hannover, Germany; Scene Understanding Group, University of Twente, The Netherlands; Institute of Cartography and Geoinformatics, Leibniz University Hannover, Germany; Institute of Information Processing, Leibniz University Hannover, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562034/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6681611771482157310&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Leibniz University Hannover;University of Twente",
        "aff_unique_dep": "Institute of Cartography and Geoinformatics;Scene Understanding Group",
        "aff_unique_url": "https://www.leibniz-uni-hannover.de;https://www.utwente.nl",
        "aff_unique_abbr": "LUH;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hannover;",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "Germany;Netherlands"
    },
    {
        "id": "9561916",
        "title": "Exploring Large and Complex Environments Fast and Efficiently",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes a novel framework for autonomous exploration in large and complex environments. We show that the framework is efficient as a result of its hierarchical structure, where at one level it maintains a sparse representation of the environment and at another level, a dense representation is used within a local planning horizon around the robot. The exploration path is computed at the two levels, coarsely at the global scale and finely around the robot. Such a framework produces detailed paths in the vicinity of the robot, while trades off data resolution far away from the robot for computational efficiency. In experiments, we evaluate our method with a real robot exploring large and complex indoor and outdoor environments. Results show that our method is twice as efficient in covering spaces while using less than one-fifth of processing in comparison to state-of-the-art methods.",
        "primary_area": "",
        "author": "Chao Cao;Hongbiao Zhu;Howie Choset;Ji Zhang;Chao Cao;Hongbiao Zhu;Howie Choset;Ji Zhang",
        "authorids": "/37086934694;/37086564449;/37281322200;/38541910000;/37086934694;/37086564449;/37281322200;/38541910000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561916/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6698684700004136720&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561040",
        "title": "Extendable Navigation Network based Reinforcement Learning for Indoor Robot Exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a navigation network based deep reinforcement learning framework for autonomous indoor robot exploration. The presented method features a pattern cognitive non-myopic exploration strategy that can better reflect universal preferences for structure. We propose the Extendable Navigation Network (ENN) to encode the partially observed high-dimensional indoor Euclidean space to a sparse graph representation. The robot\u2019s motion is generated by a learned Q-network whose input is the ENN. The proposed framework is applied to a robot equipped with a 2D LIDAR sensor in the GAZEBO simulation where floor plans of real buildings are implemented. The experiments demonstrate the efficiency of the framework in terms of exploration time.",
        "primary_area": "",
        "author": "Woo-Cheol Lee;Ming Chong Lim;Han-Lim Choi;Woo-Cheol Lee;Ming Chong Lim;Han-Lim Choi",
        "authorids": "/37086550757;/37086550858;/37308867500;/37086550757;/37086550858;/37308867500",
        "aff": "Department of Aerospace Engineering, KAIST, Daejeon, Korea; Department of Aerospace Engineering, KAIST, Daejeon, Korea; Department of Aerospace Engineering, KAIST, Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561040/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6335932047403995023&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "KAIST",
        "aff_unique_dep": "Department of Aerospace Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561781",
        "title": "Extrinsic Contact Sensing with Relative-Motion Tracking from Distributed Tactile Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the localization of contacts of an unknown grasped rigid object with its environment, i.e., extrinsic to the robot. We explore the key role that distributed tactile sensing plays in localizing contacts external to the robot, in contrast to the role that aggregated force/torque measurements traditionally play in localizing contacts on the robot. When in contact with the environment, an object will move in accordance with the kinematic and possibly frictional constraints imposed by that contact. Small motions of the object, which are observable with tactile sensors, indirectly encode those constraints and the geometry that defines them.We formulate the extrinsic contact sensing problem as a constraint-based estimation problem. The estimation is subject to the kinematic constraints imposed by the tactile measurements of object motion, as well as the kinematic (e.g., non-penetration) and possibly frictional (e.g., sticking) constraints imposed by rigid-body mechanics. We validate the approach in simulation and with real experiments on the case studies of fixed point and line contacts.This paper discusses the theoretical basis for the value of distributed tactile sensing in contrast to aggregated force/torque measurements. It also provides an estimation framework for localizing environmental contacts with potential impact in contact-rich manipulation scenarios such as assembling or packing.",
        "primary_area": "",
        "author": "Daolin Ma;Siyuan Dong;Alberto Rodriguez;Daolin Ma;Siyuan Dong;Alberto Rodriguez",
        "authorids": "/37086410541;/37086249096;/38194796600;/37086410541;/37086249096;/38194796600",
        "aff": "Mechanical Engineering Department, Massachusetts Institute of Technology, MA, US; Mechanical Engineering Department, Massachusetts Institute of Technology, MA, US; Mechanical Engineering Department, Massachusetts Institute of Technology, MA, US",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561781/",
        "gs_citation": 68,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17341281185017275640&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561509",
        "title": "F-SIOL-310: A Robotic Dataset and Benchmark for Few-Shot Incremental Object Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning has achieved remarkable success in object recognition tasks through the availability of large scale datasets like ImageNet. However, deep learning systems suffer from catastrophic forgetting when learning incrementally without replaying old data. For real-world applications, robots also need to incrementally learn new objects. Further, since robots have limited human assistance available, they must learn from only a few examples. However, very few object recognition datasets and benchmarks exist to test incremental learning capability for robotic vision. Further, there is no dataset or benchmark specifically designed for incremental object learning from a few examples. To fill this gap, we present a new dataset termed F-SIOL-310 (Few-Shot Incremental Object Learning) which is specifically captured for testing few-shot incremental object learning capability for robotic vision. We also provide benchmarks and evaluations of 8 incremental learning algorithms on F-SIOL-310 for future comparisons. Our results demonstrate that the few-shot incremental object learning problem for robotic vision is far from being solved.",
        "primary_area": "",
        "author": "Ali Ayub;Alan R. Wagner;Ali Ayub;Alan R. Wagner",
        "authorids": "/37090081937;/37267411100;/37090081937;/37267411100",
        "aff": "Department of Electrical Engineering, The Pennsylvania State University, State College, PA, USA; Department of Aerospace Engineering, The Pennsylvania State University, State College, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561509/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5097357727097554194&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Pennsylvania State University",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.psu.edu",
        "aff_unique_abbr": "PSU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "State College",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561496",
        "title": "FG-Conv: Large-Scale LiDAR Point Clouds Understanding Leveraging Feature Correlation Mining and Geometric-Aware Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a general deep learning framework for large-scale point clouds understanding without voxelizations, called FG-Conv, which achieves an accurate and real-time understanding of point clouds. Through our novel design combining feature level correlation mining and deformable convolutions based geometric aware modeling, the local feature relationships and geometric patterns can be captured. The attention mechanism is also adopted to enhance the global long-range feature correlations. Finally, the feature pyramid residual learning network is proposed to combine patterns at different resolutions in a memory-efficient way. Extensive experiments on real-world challenging datasets demonstrated that our approaches outperform state-of-the-art methods in terms of accuracy and efficiency. Weakly supervised transfer learning demonstrates the generalization capacity of our methods.",
        "primary_area": "",
        "author": "Kangcheng Liu;Zhi Gao;Feng Lin;Ben M. Chen;Kangcheng Liu;Zhi Gao;Feng Lin;Ben M. Chen",
        "authorids": "/37087245508;/37085495662;/37532105500;/38520079900;/37087245508;/37085495662;/37532105500;/38520079900",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Shatin N.T. Hong Kong, China; School of Remote Sensing and Information Engineering, Wuhan University, Hubei, China; Peng Cheng Laboratory, Guangdong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Shatin N.T. Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561496/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11896294771081126967&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Wuhan University;Pengcheng Laboratory",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;School of Remote Sensing and Information Engineering;Peng Cheng Laboratory",
        "aff_unique_url": "https://www.cuhk.edu.hk;http://www.whu.edu.cn/;",
        "aff_unique_abbr": "CUHK;WHU;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Shatin;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561245",
        "title": "FGR: Frustum-Aware Geometric Reasoning for Weakly Supervised 3D Vehicle Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we investigate the problem of weakly supervised 3D vehicle detection. Conventional methods for 3D object detection usually require vast amounts of manually labelled 3D data as supervision signals. However, annotating large datasets needs huge human efforts, especially for 3D area. To tackle this problem, we propose a frustum-aware geometric reasoning (FGR) method to detect vehicles in point clouds without any 3D annotations. Our method consists of two stages: coarse 3D segmentation and 3D bounding box estimation. For the first stage, a context-aware adaptive region growing algorithm is designed to segment objects based on 2D bounding boxes. Leveraging predicted segmentation masks, we develop an anti-noise approach to estimate 3D bounding boxes in the second stage. Finally 3D pseudo labels generated by our method are utilized to train a 3D detector. Independent of any 3D groundtruth, FGR reaches comparable performance with fully supervised methods on the KITTI dataset. The findings indicate that it is able to accurately detect objects in 3D space with only 2D bounding boxes and sparse point clouds.",
        "primary_area": "",
        "author": "Yi Wei;Shang Su;Jiwen Lu;Jie Zhou;Yi Wei;Shang Su;Jiwen Lu;Jie Zhou",
        "authorids": "/37087233204;/37089001359;/37404390100;/37278266700;/37087233204;/37089001359;/37404390100;/37278266700",
        "aff": "Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Department of Automation, Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University, Beijing, China; Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561245/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3049538064357808519&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Beijing;Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561147",
        "title": "FISAR: Forward Invariant Safe Reinforcement Learning with a Deep Neural Network-Based Optimizer",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates reinforcement learning with constraints, which are indispensable in safety-critical environments. To drive the constraint violation to decrease monotonically, we take the constraints as Lyapunov functions and impose new linear constraints on the policy parameters\u2019 updating dynamics. As a result, the original safety set can be forward-invariant. However, because the new guaranteed-feasible constraints are imposed on the updating dynamics instead of the original policy parameters, classic optimization algorithms are no longer applicable. To address this, we propose to learn a generic deep neural network (DNN)-based optimizer to optimize the objective while satisfying the linear constraints. The constraint-satisfaction is achieved via projection onto a polytope formulated by multiple linear inequality constraints, which can be solved analytically with our newly designed metric. To the best of our knowledge, this is the first DNN-based optimizer for constrained optimization with the forward invariance guarantee. We show that our optimizer trains a policy to decrease the constraint violation and maximize the cumulative reward monotonically. Results on numerical constrained optimization and obstacle-avoidance navigation validate the theoretical findings.",
        "primary_area": "",
        "author": "Chuangchuang Sun;Dong-Ki Kim;Jonathan P. How;Chuangchuang Sun;Dong-Ki Kim;Jonathan P. How",
        "authorids": "/37085353469;/37087324178;/37276347700;/37085353469;/37087324178;/37276347700",
        "aff": "Laboratory for Information & Decision Systems (LIDS), Massachusetts Institute of Technology, Cambridge, MA; Laboratory for Information & Decision Systems (LIDS), Massachusetts Institute of Technology, Cambridge, MA; Laboratory for Information & Decision Systems (LIDS), Massachusetts Institute of Technology, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561147/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11667461984455899831&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information & Decision Systems (LIDS)",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560993",
        "title": "FLEXotendon Glove-III: Soft Robotic Hand Rehabilitation Exoskeleton for Spinal Cord Injury",
        "track": "main",
        "status": "Poster",
        "abstract": "Cervical spinal cord injury (SCI) can severely impact hand motor and sensory function, and accordingly, patients with SCI are often unable to complete basic everyday tasks without assistance. In recent years, there has been an increase in hand exoskeleton research due to their distinct advantages for improving rehabilitation. In this work, we present a voice-controlled, tendon-driven soft robotic hand rehabilitation exoskeleton for hand function improvement in patients with cervical SCI. A new fabrication process utilizing high consistency rubber silicone is used to construct a formfitting, durable, and customizable exoskeleton glove. Bioinspired tendon routing pathways embedded within the glove create 5 actively actuated degrees-of-freedom in the index finger, middle finger, and thumb for both extension and flexion. Tendon tension sensors are developed and integrated into the exoskeleton system. The force feedback from the sensors is used in the implementation of admittance control for the exoskeleton system to improve grasping motions. The exoskeleton was evaluated in a case study with a healthy participant through range-of-motion characterization, pinch force testing, admittance controller validation, and object manipulation.",
        "primary_area": "",
        "author": "Phillip Tran;Seokhwan Jeong;Kinsey Herrin;Shovan Bhatia;Scott Kozin;Jaydev P. Desai;Phillip Tran;Seokhwan Jeong;Kinsey Herrin;Shovan Bhatia;Scott Kozin;Jaydev P. Desai",
        "authorids": "/37086830310;/37087324027;/37088442887;/37088998583;/37088999126;/37282117700;/37086830310;/37087324027;/37088442887;/37088998583;/37088999126;/37282117700",
        "aff": "Department of Biomedical Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Department of Mechanical Engineering, Sogang University, Seoul, South Korea; Woodruff School of Mechanical Engineering and the Institute for Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Department of Biomedical Engineering, Georgia Institute of Technology, Atlanta, GA, USA; Shriners Hospitals for Children, Philadelphia, PA, USA; Department of Biomedical Engineering, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560993/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6189898303854904072&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;2;0",
        "aff_unique_norm": "Georgia Institute of Technology;Sogang University;Shriners Hospitals for Children",
        "aff_unique_dep": "Department of Biomedical Engineering;Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.gatech.edu;http://www.sogang.ac.kr;https://www.shrinershospitals.org",
        "aff_unique_abbr": "Georgia Tech;Sogang;",
        "aff_campus_unique_index": "0;1;0;0;2;0",
        "aff_campus_unique": "Atlanta;Seoul;Philadelphia",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "9561092",
        "title": "Fabric defect detection using tactile information",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a method of fabric structure defect detection based on tactile information. Different from traditional visual-based detection methods, the proposed method uses a tactile sensor to attain the information of fabric. The advantage of using tactile information is to avoid different irregular dyeing patterns and reduce the influence of ambient light. Therefore, the proposed method can be more concise and universal, which makes the defect detection system more robust. Experiments are conducted to verify the performance of the developed tactile method. The results demonstrate that the proposed method is much better than the visual method in the detection of structural defects. In addition, we propose a design of a tactile sensing device that can greatly improve the actual detection efficiency of the tactile method. It is showed that the proposed method is efficient enough to meet our requirements and it provides a possible solution for the application of the tactile method in actual fabric production.",
        "primary_area": "",
        "author": "Xingming Long;Bin Fang;Yifan Zhang;GuoYi Luo;Fuchun Sun;Xingming Long;Bin Fang;Yifan Zhang;GuoYi Luo;Fuchun Sun",
        "authorids": "/37088996803;/37089577630;/37088998797;/37089001555;/37279269000;/37088996803;/37089577630;/37088998797;/37089001555;/37279269000",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Automation, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561092/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6427392683756661635&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561372",
        "title": "Factor Graph-Based Trajectory Optimization for a Pneumatically-Actuated Jumping Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Roboticists have increasingly sought to incorporate mechanical compliance into legged robots to realize a range of potential benefits, from improved agility to resilience in complex environments. A promising approach for building compliance into robot legs is to utilize the pneumatic artificial muscle, a pneumatic actuator with inherent compliance due to the compressibility of air. While previous work has explored the capabilities of pneumatic-muscle driven robots in highly dynamic tasks like jumping, there is a lack of trajectory planning strategies for such robots. In this paper, we detail our approach to planning vertical jumping trajectories for a planar two-legged robot driven by four pneumatic artificial muscles using on/off \"burst inflation\" control. The trajectory optimization problem is represented as a factor graph and solved with the GTSAM optimizer. A hybrid dynamics approach is used to handle foot-ground contacts. The average jump height error between simulation and experiment across multiple jumping trajectories of varying heights was 9.5 cm; the average RMS error between all four joints was 5.6 deg. This work provides a basis to plan more complex jumping and leaping trajectories for pneumatic muscle-driven robots.",
        "primary_area": "",
        "author": "Lucas Tiziani;Yetong Zhang;Frank Dellaert;Frank L. Hammond;Lucas Tiziani;Yetong Zhang;Frank Dellaert;Frank L. Hammond",
        "authorids": "/37086107599;/37088998216;/37282902200;/37394264300;/37086107599;/37088998216;/37282902200;/37394264300",
        "aff": "Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA; School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, USA; Coulter Department of Biomedical Engineering, Woodruff School of Mechanical Engineering, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561372/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6185387276127149702&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Woodruff School of Mechanical Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561269",
        "title": "Fast Few-Shot Classification by Few-Iteration Meta-Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous agents interacting with the real world need to learn new concepts efficiently and reliably. This requires learning in a low-data regime, which is a highly challenging problem. We address this task by introducing a fast optimization-based meta-learning method for few-shot classification. It consists of an embedding network, providing a general representation of the image, and a base learner module. The latter learns a linear classifier during the inference through an unrolled optimization procedure. We design an inner learning objective composed of (i) a robust classification loss on the support set and (ii) an entropy loss, allowing transductive learning from unlabeled query samples. By employing an efficient initialization module and a Steepest Descent based optimization algorithm, our base learner predicts a powerful classifier within only a few iterations. Further, our strategy enables important aspects of the base learner objective to be learned during meta-training. To the best of our knowledge, this work is the first to integrate both induction and transduction into the base learner in an optimization-based meta-learning framework. We perform a comprehensive experimental analysis, demonstrating the speed and effectiveness of our approach on four few-shot classification datasets. The Code is available at https://github.com/4rdhendu/FIML.",
        "primary_area": "",
        "author": "Ardhendu Shekhar Tripathi;Martin Danelljan;Luc Van Gool;Radu Timofte;Ardhendu Shekhar Tripathi;Martin Danelljan;Luc Van Gool;Radu Timofte",
        "authorids": "/37088369160;/37085558596;/37277167600;/37393691200;/37088369160;/37085558596;/37277167600;/37393691200",
        "aff": "Department of Electrical Engineering, Computer Vision Lab, ETH Zurich, Switzerland; Department of Electrical Engineering, Computer Vision Lab, ETH Zurich, Switzerland; Department of Electrical Engineering, Computer Vision Lab, ETH Zurich, Switzerland; Department of Electrical Engineering, Computer Vision Lab, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561269/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4223827055750810021&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561493",
        "title": "Fast Footstep Planning with Aborting A",
        "track": "main",
        "status": "Poster",
        "abstract": "Footstep planning is the dominating approach when it comes to controlling the walk of a humanoid robot, even though a footstep plan is expensive to compute. The most prominent proposals typically spend up to a few seconds of computation time and output a sequence of up to 30 steps all the way to the goal. This way, footstep planning is applicable only in static environments where nothing changes after a plan has been computed. Since uncontrolled environments present challenges such as unforeseen motion of other objects and unexpected disturbances to balance, fast replanning of a footstep plan while the robot is in motion is highly desirable. We present a new way of fast footstep planning - Aborting A* - which is able to guarantee a replanning rate of 50 Hz by aborting an A* search before completion. We make aborting possible by using a novel, obstacle-aware heuristic function that lays out rotate-translate-rotate motions along the shortest path to the goal, enabling us to stop the planning progress prematurely with a target-oriented solution at any time during the search, even after only a few nodes have been expanded. We show in our experiments that despite the bounded computation time, our planner computes good results and does not get stuck in local minima.",
        "primary_area": "",
        "author": "Marcell Missura;Maren Bennewitz;Marcell Missura;Maren Bennewitz",
        "authorids": "/37947347600;/37324765000;/37947347600;/37324765000",
        "aff": "Humanoid Robots Lab, University of Bonn, Germany; Humanoid Robots Lab, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561493/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6804216765514389829&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Humanoid Robots Lab",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561445",
        "title": "Fast Light Show Design Platform for K-12 Children",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper aims to present a drone swarm light show design platform to support STEAM (science, technology, engineering, art and mathematics) education for K-12 children. With this platform, children can use this platform to design a drone swarm light show easily. To this end, the architecture of this platform contents three layers: UI layer, command layer, and physical layer. The UI layer has an easy-to-use interface for children. Children can feed parameters about the light show by clicking buttons and dragging sliders of four tracks. All actions designed for the swarm in the UI layer will be generated automatically in the form of the drone\u2019s desired trajectories through the command layer. The physical layer includes a router for communication and a drone swarm for the light show. Our experimental results demonstrate that this platform works efficiently and suits for being applied to real STEAM education.",
        "primary_area": "",
        "author": "Pengda Mao;Yan Gao;Bo Wang;An Yan;Xiaoyu Chi;Quan Quan;Pengda Mao;Yan Gao;Bo Wang;An Yan;Xiaoyu Chi;Quan Quan",
        "authorids": "/37089000416;/37088986380;/37088999208;/37088556067;/37088551707;/37406014700;/37089000416;/37088986380;/37088999208;/37088556067;/37088551707;/37406014700",
        "aff": "School of Automation Science and Electrical Engineering, Beihang University, Beijing, P.R. China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, P.R. China; Goertek Robotics Co., Ltd., Shanghai, P.R. China; Goertek Robotics Co., Ltd., Shanghai, P.R. China; Qingdao Research Institute of Beihang University, Qingdao, P.R. China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561445/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8968057440289889054&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "1;1;2",
        "aff_unique_norm": ";Goertek Robotics Co., Ltd.;Beihang University",
        "aff_unique_dep": ";;Qingdao Research Institute",
        "aff_unique_url": ";;",
        "aff_unique_abbr": ";;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Qingdao",
        "aff_country_unique_index": "1;1;1",
        "aff_country_unique": ";China"
    },
    {
        "id": "9561290",
        "title": "Fast Motion Understanding with Spatiotemporal Neural Networks and Dynamic Vision Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a Dynamic Vision Sensor (DVS) based system for reasoning about high-speed motion. As a representative scenario we consider a robot at rest, reacting to a small, fast approaching object at speeds higher than 15 m/s. Since conventional image sensors at typical frame rates observe such an object for only a few frames, estimating the underlying motion presents a considerable challenge for standard computer vision systems and algorithms. We present a method motivated by how animals such as insects solve this problem with their relatively simple vision systems.Our solution takes the event stream from a DVS and first encodes the temporal events with a set of causal exponential filters across multiple time scales. We couple these filters with a Convolutional Neural Network (CNN) to efficiently extract relevant spatiotemporal features. The combined network learns to output both the expected time to collision of the object, as well as the predicted collision point on a discretized polar grid. These critical estimates are computed with minimal delay by the network in order to react appropriately to the incoming object. We highlight our system\u2019s results with a toy dart moving at 23.4 m/s with a 24.73\u00b0 error in \u03b8, 18.4 mm average discretized radius prediction error, and 25.03% median time to collision prediction error.",
        "primary_area": "",
        "author": "Anthony Bisulco;Fernando Cladera;Volkan Isler;Daniel D. Lee;Anthony Bisulco;Fernando Cladera;Volkan Isler;Daniel D. Lee",
        "authorids": "/37085794585;/37089148940;/37298487800;/37280609600;/37085794585;/37089148940;/37298487800;/37280609600",
        "aff": "Samsung AI Center NY, New York, New York; Samsung AI Center NY, New York, New York; Samsung AI Center NY, New York, New York; Samsung AI Center NY, New York, New York",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561290/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=321353891651506779&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "SAC NY",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560880",
        "title": "Fast Near-Optimal Heterogeneous Task Allocation via Flow Decomposition",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-robot systems are uniquely well-suited to performing complex tasks such as patrolling and tracking, information gathering, and pick-up and delivery problems, offering significantly higher performance than single-robot systems. A fundamental building block in most multi-robot systems is task allocation: assigning robots to tasks (e.g., patrolling an area, or servicing a transportation request) as they appear based on the robots\u2019 states to maximize reward. In many practical situations, the allocation must account for heterogeneous capabilities (e.g., availability of appropriate sensors or actuators) to ensure the feasibility of execution, and to promote a higher reward, over a long time horizon. To this end, we present the FlowDec algorithm for efficient heterogeneous task-allocation, and show that it achieves an approximation factor of at least 1/2 of the optimal reward. Our approach decomposes the heterogeneous problem into several homogeneous subproblems that can be solved efficiently using min-cost flow. Through simulation experiments, we show that our algorithm is faster by several orders of magnitude than a MILP approach.",
        "primary_area": "",
        "author": "Kiril Solovey;Saptarshi Bandyopadhyay;Federico Rossi;Michael T. Wolf;Marco Pavone;Kiril Solovey;Saptarshi Bandyopadhyay;Federico Rossi;Michael T. Wolf;Marco Pavone",
        "authorids": "/37085671184;/37927592300;/37085471827;/37398766100;/37307912900;/37085671184;/37927592300;/37085471827;/37398766100;/37307912900",
        "aff": "Department of Aeronautics & Astronautics, Stanford University, Stanford, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, CA; Department of Aeronautics & Astronautics, Stanford University, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560880/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17349603028374932220&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Stanford University;California Institute of Technology",
        "aff_unique_dep": "Department of Aeronautics & Astronautics;Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.stanford.edu;https://www.caltech.edu",
        "aff_unique_abbr": "Stanford;Caltech",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Stanford;Pasadena",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561758",
        "title": "Fast Object Segmentation Learning with Kernel-based Methods for Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Object segmentation is a key component in the visual system of a robot that performs tasks like grasping and object manipulation, especially in presence of occlusions. Like many other computer vision tasks, the adoption of deep architectures has made available algorithms that perform this task with remarkable performance. However, adoption of such algorithms in robotics is hampered by the fact that training requires large amount of computing time and it cannot be performed on-line.In this work, we propose a novel architecture for object segmentation, that overcomes this problem and provides comparable performance in a fraction of the time required by the state-of-the-art methods. Our approach is based on a pre-trained Mask R-CNN, in which various layers have been replaced with a set of classifiers and regressors that are retrained for a new task. We employ an efficient Kernel-based method that allows for fast training on large scale problems. Our approach is validated on the YCB-Video dataset which is widely adopted in the computer vision and robotics community, demonstrating that we can achieve and even surpass performance of the state-of-the-art, with a significant reduction (~6\u00d7) of the training time.The code to reproduce the experiments is publicly available on GitHub1.",
        "primary_area": "",
        "author": "Federico Ceola;Elisa Maiettini;Giulia Pasquale;Lorenzo Rosasco;Lorenzo Natale;Federico Ceola;Elisa Maiettini;Giulia Pasquale;Lorenzo Rosasco;Lorenzo Natale",
        "authorids": "/37087104955;/37086315907;/37086099680;/37869474900;/37542770000;/37087104955;/37086315907;/37086099680;/37869474900;/37542770000",
        "aff": "Laboratory for Computational and Statistical Learning and with Dipartimento di Informatica, Bioingegneria, Robotica e Ingegneria dei Sistemi, University of Genoa, Genoa, Italy; Humanoid Sensing and Perception, Istituto Italiano di Tecnologia, Genoa, Italy; Humanoid Sensing and Perception, Istituto Italiano di Tecnologia, Genoa, Italy; Istituto Italiano di Tecnologia and Massachusetts Institute of Technology, Cambridge, MA; Humanoid Sensing and Perception, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561758/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5348493355129033856&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "University of Genoa;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Dipartimento di Informatica, Bioingegneria, Robotica e Ingegneria dei Sistemi;Humanoid Sensing and Perception",
        "aff_unique_url": "https://www.unige.it;https://www.iit.it",
        "aff_unique_abbr": ";IIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genoa;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9561241",
        "title": "Fast Path Computation using Lattices in the Sensor-Space for Forest Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Fast autonomous motion in cluttered and unknown environments, such as forests, is highly dependent on low-latency obstacle avoidance strategies. In this context, this paper presents a motion planning strategy that relies on lattices for the fast computation of local paths that both avoid obstacles and follow a vector field that encodes the global robot task. Lattices are constructed in the sensor space and represent a set of search trees that can be quickly pruned in function of the detected obstacles. The remaining lattice trees are used to optimize a vector field-dependent functional, thus generating the best free local path that tracks the field. To illustrate the proposed approach, we present simulation and real-world experiments of a planar robot moving in a cluttered, forest-like environment.",
        "primary_area": "",
        "author": "Bernardo Martinez R. Junior;Guilherme A. S. Pereira;Bernardo Martinez R. Junior;Guilherme A. S. Pereira",
        "authorids": "/37089876325;/37287384300;/37089876325;/37287384300",
        "aff": "Department of Mechanical and Aerospace, Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University, Morgantown, WV, USA; Department of Mechanical and Aerospace, Benjamin M. Statler College of Engineering and Mineral Resources, West Virginia University, Morgantown, WV, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561241/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9125985156797308181&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "West Virginia University",
        "aff_unique_dep": "Department of Mechanical and Aerospace",
        "aff_unique_url": "https://www.wvu.edu",
        "aff_unique_abbr": "WVU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Morgantown",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561928",
        "title": "Fast Replanning Multi-Heuristic A",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we proposed a novel path replanning algorithm on arbitrary graphs. To avoid computationally heavy preprocessing and to reduce required memory to store the expanded vertices of the previous search, we defined the feature vertices, which are extracted from the previous path by a simple algorithm to compare the costs between adjacent vertices along the path once. Proper additional heuristic functions are designed for these feature vertices to work as local attractors guiding the search toward the previous path\u2019s neighbors. To avoid unnecessary expansions and speed up the search, these additional heuristic functions are properly managed to stop intriguing or guiding search toward the feature vertices. The proposed algorithm of Fast Replanning Multi-Heuristic A* is a variation of Shared Multi-Heuristic A* while removing or deactivating the additional heuristic functions during the search. Fast Replanning Multi-Heuristic A* guarantees the bounded suboptimality while efficiently exploring the graph toward the goal vertex. The performance of the proposed algorithm was compared with weighted A* and D* lite by simulating numerous path replanning problems in maze-like maps.",
        "primary_area": "",
        "author": "Junhyoung Ha;Soonkyum Kim;Junhyoung Ha;Soonkyum Kim",
        "authorids": "/37085682210;/37088506788;/37085682210;/37088506788",
        "aff": "Senior Research Scientist of Center for Healthcare Robotics in Artificial Intelligence & Robotics Institute, Korea Institute of Science and Technology, Republic of Korea; Senior Research Scientist of Center for Healthcare Robotics in Artificial Intelligence & Robotics Institute, Korea Institute of Science and Technology, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561928/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2565991492275614627&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Institute of Science and Technology",
        "aff_unique_dep": "Center for Healthcare Robotics in Artificial Intelligence & Robotics Institute",
        "aff_unique_url": "https://www.kist.re.kr",
        "aff_unique_abbr": "KIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9562107",
        "title": "Fast Sampling-based Next-Best-View Exploration Algorithm for a MAV",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present a new exploration algorithm for Micro Aerial Vehicles (MAVs). The planner uses a combination of Next-Best-View (NBV) sampling and frontier-based approaches to reduce the impact of finding unexplored areas in large scenarios. For each sampled point, the yaw angle is optimized to maximize the potential gain for mapping. The gain is expressed as a ratio between the exploration objective and the time it would take to reach the pose, thus, balancing the nearby exploration and global coverage. We reduce the gain computation bottleneck in the sampling strategy by managing a dual-map with different resolutions. The planner maintains a history graph, with nodes that indicate regions of interest for map expansion. We demonstrate the abilities of the proposed algorithm with simulations and real-world experiments. The results outperform state-of-the-art methods in exploration time and computational cost.",
        "primary_area": "",
        "author": "Victor Massagu\u00e9 Respall;Dmitry Devitt;Roman Fedorenko;Alexandr Klimchik;Victor Massagu\u00e9 Respall;Dmitry Devitt;Roman Fedorenko;Alexandr Klimchik",
        "authorids": "/37088383613;/37088602152;/37086484277;/37077323100;/37088383613;/37088602152;/37086484277;/37077323100",
        "aff": "Center for Technologies in Robotics and Mechatronics Components, Innopolis University, Russia; Center for Technologies in Robotics and Mechatronics Components, Innopolis University, Russia; Center for Technologies in Robotics and Mechatronics Components, Innopolis University, Russia; Center for Technologies in Robotics and Mechatronics Components, Innopolis University, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562107/",
        "gs_citation": 43,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1965062075902671500&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Innopolis University",
        "aff_unique_dep": "Center for Technologies in Robotics and Mechatronics Components",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Russian Federation"
    },
    {
        "id": "9561093",
        "title": "Fast Swing-Up Trajectory Optimization for a Spherical Pendulum on a 7-DoF Collaborative Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, the experimental swing-up of a spherical pendulum mounted on a collaborative robot is presented. The complete mechanical system consists of nine degrees of freedom (DoFs). The primary focus of this work is the design of a fast trajectory planning for the swing-up by systematically incorporating the kinematic and dynamics constraints. The proposed algorithm consists of two steps: First, an offline trajectory optimization is used to build a database of swing-up trajectories, with an average computing time of 10 s for one trajectory. Second, a fast trajectory replanner based on a constrained quadratic program is described, which computes the swing-up trajectory for an arbitrary initial configuration of the system with an average computing time of 0.2 s. Simulations and experimental results demonstrate the swing-up of the spherical pendulum using a discrete time-variant linear quadratic regulator as a feedback controller.",
        "primary_area": "",
        "author": "Minh Nhat Vu;Christian Hartl-Nesic;Andreas Kugi;Minh Nhat Vu;Christian Hartl-Nesic;Andreas Kugi",
        "authorids": "/37086029999;/37088822824;/37282440900;/37086029999;/37088822824;/37282440900",
        "aff": "TU Wien, Automation & Control Institute (ACIN), Vienna, Austria; TU Wien, Automation & Control Institute (ACIN), Vienna, Austria; Center for Vision, Automation & Control, AIT Austrian Institute of Technology GmbH, Vienna, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561093/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5866385094507176972&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "TU Wien;AIT Austrian Institute of Technology GmbH",
        "aff_unique_dep": "Automation & Control Institute (ACIN);Center for Vision, Automation & Control",
        "aff_unique_url": "https://www.tuwien.ac.at;https://www.ait.ac.at",
        "aff_unique_abbr": "TU Wien;AIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Vienna",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9561483",
        "title": "Fast Uncertainty Quantification for Deep Object Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning-based object pose estimators are often unreliable and overconfident especially when the input image is outside the training domain, for instance, with sim2real transfer. Efficient and robust uncertainty quantification (UQ) in pose estimators is critically needed in many robotic tasks. In this work, we propose a simple, efficient, and plug-and-play UQ method for 6-DoF object pose estimation. We ensemble 2\u20133 pre-trained models with different neural network architectures and/or training data sources, and compute their average pair-wise disagreement against one another to obtain the uncertainty quantification. We propose four disagreement metrics, including a learned metric, and show that the average distance (ADD) is the best learning-free metric and it is only slightly worse than the learned metric, which requires labeled target data. Our method has several advantages compared to the prior art: 1) our method does not require any modification of the training process or the model inputs; and 2) it needs only one forward pass for each model. We evaluate the proposed UQ method on three tasks where our uncertainty quantification yields much stronger correlations with pose estimation errors than the baselines. Moreover, in a real robot grasping task, our method increases the grasping success rate from 35% to 90%. Video and code are available at https://sites.google.com/view/fastuq.",
        "primary_area": "",
        "author": "Guanya Shi;Yifeng Zhu;Jonathan Tremblay;Stan Birchfield;Fabio Ramos;Animashree Anandkumar;Yuke Zhu;Guanya Shi;Yifeng Zhu;Jonathan Tremblay;Stan Birchfield;Fabio Ramos;Animashree Anandkumar;Yuke Zhu",
        "authorids": "/37086937305;/37088690974;/37086455314;/37371627300;/37285364500;/37322138800;/37086080772;/37086937305;/37088690974;/37086455314;/37371627300;/37285364500;/37322138800;/37086080772",
        "aff": "California Institute of Technology; The University of Texas at Austin; NVIDIA; NVIDIA; The University of Sydney; California Institute of Technology; The University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561483/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3058372493543181200&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;2;3;0;1",
        "aff_unique_norm": "California Institute of Technology;University of Texas at Austin;NVIDIA;University of Sydney",
        "aff_unique_dep": ";;NVIDIA Corporation;",
        "aff_unique_url": "https://www.caltech.edu;https://www.utexas.edu;https://www.nvidia.com;https://www.sydney.edu.au",
        "aff_unique_abbr": "Caltech;UT Austin;NVIDIA;USYD",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Pasadena;Austin;",
        "aff_country_unique_index": "0;0;0;0;1;0;0",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "9561948",
        "title": "Fast-Tracker: A Robust Aerial System for Tracking Agile Target in Cluttered Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a systematic solution that uses an unmanned aerial vehicle (UAV) to aggressively and safely track an agile target. It properly handles the challenging situations where the intent of the target and the dense environments are unknown. Our work is divided into two parts: target motion prediction and tracking trajectory planning. The target motion prediction method utilizes target observations to reliably predict its future motion. The tracking trajectory planner follows the hierarchical workflow. A target informed kinody-namic searching method is adopted as the front-end, which heuristically searches for a safe tracking trajectory. The back- end optimizer then refines it into a spatial-temporal optimal trajectory. The proposed solution is integrated into an onboard quadrotor system. We fully test the system in challenging real-world tracking missions. Moreover, benchmark comparisons validate that the proposed method surpasses the cutting-edge methods on time efficiency and tracking effectiveness.",
        "primary_area": "",
        "author": "Zhichao Han;Ruibin Zhang;Neng Pan;Chao Xu;Fei Gao;Zhichao Han;Ruibin Zhang;Neng Pan;Chao Xu;Fei Gao",
        "authorids": "/37088982526;/37088557832;/37088986697;/37404060100;/37086045143;/37088982526;/37088557832;/37088986697;/37404060100;/37086045143",
        "aff": "National Engineering Research Center for Industrial Automation (Ningbo Institute), Ningbo, China; National Engineering Research Center for Industrial Automation (Ningbo Institute), Ningbo, China; National Engineering Research Center for Industrial Automation (Ningbo Institute), Ningbo, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561948/",
        "gs_citation": 78,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15988186375836003929&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "National Engineering Research Center for Industrial Automation;Zhejiang University",
        "aff_unique_dep": ";Huzhou Institute",
        "aff_unique_url": ";https://www.zju.edu.cn",
        "aff_unique_abbr": "NERC-IA;ZJU",
        "aff_campus_unique_index": "0;0;0;1;1",
        "aff_campus_unique": "Ningbo;Huzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560800",
        "title": "FastFlowNet: A Lightweight Network for Fast Optical Flow Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Dense optical flow estimation plays a key role in many robotic vision tasks. In the past few years, with the advent of deep learning, we have witnessed great progress in optical flow estimation. However, current networks often consist of a large number of parameters and require heavy computation costs, largely hindering its application on low power-consumption devices such as mobile phones. In this paper, we tackle this challenge and design a lightweight model for fast and accurate optical flow prediction. Our proposed FastFlowNet follows the widely-used coarse-to-fine paradigm with following innovations. First, a new head enhanced pooling pyramid (HEPP) feature extractor is employed to intensify high-resolution pyramid features while reducing parameters. Second, we introduce a new center dense dilated correlation (CDDC) layer for constructing compact cost volume that can keep large search radius with reduced computation burden. Third, an efficient shuffle block decoder (SBD) is implanted into each pyramid level to accelerate flow estimation with marginal drops in accuracy. Experiments on both synthetic Sintel data and real-world KITTI datasets demonstrate the effectiveness of the proposed approach, which needs only 1/10 computation of comparable networks to achieve on par accuracy. In particular, FastFlowNet only contains 1.37M parameters; and can execute at 90 FPS (with a single GTX 1080Ti) or 5.7 FPS (embedded Jetson TX2 GPU) on a pair of Sintel images of resolution 1024 \u00d7 436.Code is available at: https://git.io/fastflow",
        "primary_area": "",
        "author": "Lingtong Kong;Chunhua Shen;Jie Yang;Lingtong Kong;Chunhua Shen;Jie Yang",
        "authorids": "/37088690689;/37089403904;/37089395032;/37088690689;/37089403904;/37089395032",
        "aff": "Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, China; The University of Adelaide, Australia; Institute of Image Processing and Pattern Recognition, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560800/",
        "gs_citation": 78,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14704969366836146922&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;University of Adelaide",
        "aff_unique_dep": "Institute of Image Processing and Pattern Recognition;",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.adelaide.edu.au",
        "aff_unique_abbr": "SJTU;Adelaide",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Shanghai;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;Australia"
    },
    {
        "id": "9560735",
        "title": "Faster R-CNN-based Decision Making in a Novel Adaptive Dual-Mode Robotic Anchoring System",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel adaptive anchoring module that can be integrated into robots to enhance their mobility and manipulation abilities. The module can deploy a suitable mode of attachment, via spines or vacuum suction, to different contact surfaces in response to the textural properties of the surfaces. In order to make a decision on the suitable mode of attachment, an original dataset of 100 images of outdoor and indoor surfaces was enhanced using a WGAN-GP to generate an additional 200 synthetic images. The enhanced dataset was then used to train a visual surface examination model using Faster RCNN. The addition of synthetic images increased the mean average precision of the Faster R-CNN model from 81.6% to 93.9%. We have also conducted a series of load tests to characterize the module\u2019s strength of attachments. The results of the experiments indicate that the anchoring module can withstand an applied detachment force of around 22N and 20N when attached using spines and vacuum suction on the ideal surfaces, respectively.",
        "primary_area": "",
        "author": "Shahrooz Shahin;Rasoul Sadeghian;Sina Sareh;Shahrooz Shahin;Rasoul Sadeghian;Sina Sareh",
        "authorids": "/37086346623;/37085635080;/37085434081;/37086346623;/37085635080;/37085434081",
        "aff": "RCA Robotics Laboratory, Royal College of Art, London, UK; RCA Robotics Laboratory, Royal College of Art, London, UK; RCA Robotics Laboratory, Royal College of Art, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560735/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18286538389952680041&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Royal College of Art",
        "aff_unique_dep": "RCA Robotics Laboratory",
        "aff_unique_url": "https://www.rca.ac.uk",
        "aff_unique_abbr": "RCA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561380",
        "title": "Feasible and Adaptive Multimodal Trajectory Prediction with Semantic Maneuver Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Predicting trajectories of participating vehicles is a crucial task towards full and safe autonomous driving. General unconstrained machine learning methods often report unrealistic predictions, and need to be combined with different motion constraints. Existing work either defines some shallow maneuvers and modes to regulate the output, or uses vehicle dynamics as the main source of constraints, for instance via kinematic models. In contrast, we present a new approach that guides the learning models by complex semantic maneuvers, constructing from both vehicle states and the surrounding objects. We propose a novel Maneuver Fusion layer to incorporate the logic-based semantic maneuvers into deep neural networks. We also incorporate and refine the different loss functions to account for the feasibility of the trajectories, adapting to different maneuver types. Finally, we design a hierarchical multi-task learning framework with adaptive loss to provide a multimodal trajectory prediction. Our method was evaluated on a large-scale real world data set for urban driving and was shown to give promising improvement over the states of the art.",
        "primary_area": "",
        "author": "Hendrik Berkemeyer;Riccardo Franceschini;Tuan Tran;Lin Che;Gordon Pipa;Hendrik Berkemeyer;Riccardo Franceschini;Tuan Tran;Lin Che;Gordon Pipa",
        "authorids": "/37088998237;/37089001000;/37089001918;/37088997310;/37088998972;/37088998237;/37089001000;/37089001918;/37088997310;/37088998972",
        "aff": "Institute of Cognitive Science, University of Osnabrueck, Osnabrueck, Germany; Aalto University, Espoo, Finland; Robert Bosch GmbH, Abstatt, Germany; Technical University of Munich, Munich, Germany; Institute of Cognitive Science, University of Osnabrueck, Osnabrueck, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561380/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10579597480888368444&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "University of Osnabrueck;Aalto University;Robert Bosch GmbH;Technical University of Munich",
        "aff_unique_dep": "Institute of Cognitive Science;;;",
        "aff_unique_url": "https://www.uni-osnabrueck.de;https://www.aalto.fi;https://www.bosch.com;https://www.tum.de",
        "aff_unique_abbr": ";Aalto;Bosch;TUM",
        "aff_campus_unique_index": "0;1;2;3;0",
        "aff_campus_unique": "Osnabrueck;Espoo;Abstatt;Munich",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Germany;Finland"
    },
    {
        "id": "9561558",
        "title": "Feature Enhanced Projection Network for Zero-shot Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "In environmental perception of autonomous driving, zero-shot semantic segmentation that can make prediction of new categories without using any labeled training samples is considered as a challenging task. One key step in this task is to transfer knowledge across categories via auxiliary semantic word embeddings. In this paper, we propose a feature enhanced projection network (FEPNet) that takes full advantage of transferred knowledge to enrich semantic representations. In FEPNet, two projection layers are added to a segmentation network so as to map features into seen (S) and unseen (U) category spaces, respectively. During training, U-space features are transferred to S-space using similarity relations to enhance the representation of seen categories. In the inference stage, the representation of unseen categories is also strengthened by incorporating features transferred from S-space. Moreover, a novel strategy is proposed to effectively alleviate prediction bias by performing segmentation independently in separate areas that contain seen and unseen categories. We conduct extensive experiments on three benchmark datasets. The experimental results show that our FEPNet achieves new state-of-the-art results compared to existing approaches.",
        "primary_area": "",
        "author": "Hongchao Lu;Longwei Fang;Matthieu Lin;Zhidong Deng;Hongchao Lu;Longwei Fang;Matthieu Lin;Zhidong Deng",
        "authorids": "/37086350105;/37088997916;/37088998437;/37330240100;/37086350105;/37088997916;/37088998437;/37330240100",
        "aff": "Department of Computer Science, Tsinghua University, Beijing, China; Computer Vision Group, Intel, China; Department of Computer Science, Tsinghua University, Beijing, China; Department of Computer Science, State Key Laboratory of Intelligent Technology and Systems, THUAI, BNRist, Center for Intelligent Connected Vehicles and Transportation, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561558/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11299427955607465922&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Tsinghua University;Intel",
        "aff_unique_dep": "Department of Computer Science;Computer Vision Group",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.intel.com",
        "aff_unique_abbr": "THU;Intel",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561708",
        "title": "Feedback Linearization for Quadrotors with a Learned Acceleration Error Model",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper enhances the feedback linearization controller for multirotors with a learned acceleration error model and a thrust input delay mitigation model. Feedback linearization controllers are theoretically appealing but their performance suffers on real systems, where the true system does not match the known system model. We take a step in reducing these robustness issues by learning an acceleration error model, applying this model in the position controller, and further propagating it forward to the attitude controller. We show how this approach improves performance over the standard feedback linearization controller in the presence of unmodeled dynamics and repeatable external disturbances in both simulation and hardware experiments. We also show that our thrust control input delay model improves the step response on hardware systems.",
        "primary_area": "",
        "author": "Alexander Spitzer;Nathan Michael;Alexander Spitzer;Nathan Michael",
        "authorids": "/37088999608;/37302499000;/37088999608;/37302499000",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561708/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17291279682054026249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562081",
        "title": "Fingertip Pulse-Echo Ultrasound and Optoacoustic Dual-Modal and Dual Sensing Mechanisms Near-Distance Sensor for Ranging and Material Sensing in Robotic Grasping",
        "track": "main",
        "status": "Poster",
        "abstract": "To improve robotic grasping, we are interested in developing a new non-contact fingertip-mounted sensor for near-distance ranging and material sensing. Here we report new progress in combining direct pulse-echo ultrasound and optoacoustic effects in sensor design to deal with optically and/or acoustically challenging targets (OACTs). Our dual-modal and dual sensing mechanisms (DMDSM) sensor design is enabled by a novel wideband ultrasound transmitter embedded inside a piezoelectric (lead zirconate titanate - PZT) ring transducer. The new DMDSM sensor is capable of differentiating a variety of OACTs. To verify our design, both distance ranging tests and material sensing tests have been conducted. The ranging tests show the sensor can perform both optoacoustic ranging (for light-absorbing materials) and pulse-echo ultrasound ranging (for reflective or transparent materials). For material sensing, the dual-modal spectra from OACTs are collected to compare the new sensor with previous designs. The overall 100% accuracy from the confusion matrices indicates the initial success of our sensor design in differentiating conventional targets as well as the OACTs with the new DMDSM sensor.",
        "primary_area": "",
        "author": "Cheng Fang;Di Wang;Dezhen Song;Jun Zou;Cheng Fang;Di Wang;Dezhen Song;Jun Zou",
        "authorids": "/37085893142;/37086453325;/37275586600;/37576103200;/37085893142;/37086453325;/37275586600;/37576103200",
        "aff": "Electrical and Computer Engineering Department, Texas A&M University, College Station, TX, USA; Computer Science and Engineering Department, Texas A&M University, College Station, TX, USA; Computer Science and Engineering Department, Texas A&M University, College Station, TX, USA; Electrical and Computer Engineering Department, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562081/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17702978578549771978&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561297",
        "title": "Finite-Horizon Synthesis for Probabilistic Manipulation Domains",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots have begun operating and collaborating with humans in industrial and social settings. This collaboration introduces challenges: the robot must plan while taking the human\u2019s actions into account. In prior work, the problem was posed as a 2-player deterministic game, with a limited number of human moves. The limit on human moves is unintuitive, and in many settings determinism is undesirable. In this paper, we present a novel planning method for collaborative human-robot manipulation tasks via probabilistic synthesis. We introduce a probabilistic manipulation domain that captures the interaction by allowing for both robot and human actions with states that represent the configurations of the objects in the workspace. The task is specified using Linear Temporal Logic over finite traces (LTLf). We then transform our manipulation domain into a Markov Decision Process (MDP) and synthesize an optimal policy to satisfy the specification on this MDP. We present two novel contributions: a formalization of probabilistic manipulation domains allowing us to apply existing techniques and a comparison of different encodings of these domains. Our framework is validated on a physical UR5 robot.",
        "primary_area": "",
        "author": "M. Wells;Zachary Kingston;Morteza Lahijanian;Lydia E. Kavraki;Moshe Y. Vardi;M. Wells;Zachary Kingston;Morteza Lahijanian;Lydia E. Kavraki;Moshe Y. Vardi",
        "authorids": "/37089001604;/37085542480;/37398443600;/37279015600;/37282738000;/37089001604;/37085542480;/37398443600;/37279015600;/37282738000",
        "aff": "CS department, Rice University; CS department, Rice University; Aerospace Engineering Sciences and Computer Science departments, University of Colorado, Boulder; CS department, Rice University; CS department, Rice University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561297/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1023357449942696360&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Rice University;University of Colorado Boulder",
        "aff_unique_dep": "Computer Science department;Aerospace Engineering Sciences and Computer Science departments",
        "aff_unique_url": "https://www.rice.edu;https://www.colorado.edu",
        "aff_unique_abbr": "Rice;CU Boulder",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Boulder",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561923",
        "title": "Fixed-root Aerial Manipulator: Design, Modeling, and Control of Multilink Aerial Arm to Adhere Foot Module to Ceilings using Rotor Thrust",
        "track": "main",
        "status": "Poster",
        "abstract": "Precise aerial manipulation is important for multirotor robots. For multirotors equipped with arms, the root pose error due to the floating body affects the precision at the end effector. Fixed-root approaches, such as perching on surfaces using the rotor suction force, are useful to address this problem. Furthermore, it is difficult for arm-equipped multirotors to generate large wrenches at the end effector owing to joint torque limitations. For multilink aerial robots with rotors distributed to each link, the thrust of rotors can produce large torques. Therefore, such multirotor robots can generate comparatively large wrenches at the end effector. In this paper, we introduce a rotor-distributed multilink robot that can perch on surfaces. First, we designed a root footplate and arm module for a multilink aerial robot. During perching, the joint between these two links can be passive to prevent peeling. Second, we propose a quadratic programming (QP) based controller to calculate the desired thrust for perching motion, considering the static friction and zero moment point (ZMP) conditions on the footplate. Finally, we conducted root-body perching motion tests. The manipulations of the multilink aerial robot during perching become more accurate than those during flight because the root position adheres to the environment.",
        "primary_area": "",
        "author": "Takuzumi Nishio;Moju Zhao;Tomoki Anzai;Kunio Kojima;Kei Okada;Masayuki Inaba;Takuzumi Nishio;Moju Zhao;Tomoki Anzai;Kunio Kojima;Kei Okada;Masayuki Inaba",
        "authorids": "/37088506280;/37085684946;/37086287194;/37085360901;/37280639000;/37286658200;/37088506280;/37085684946;/37086287194;/37085360901;/37280639000;/37286658200",
        "aff": "Takuzumi Nishio; Moju Zhao; Tomoki Anzai; Kunio Kojima; Kei Okada; Masayuki Inaba",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561923/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12797988534189473185&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9560843",
        "title": "FlexDMP \u2013 Extending Dynamic Movement Primitives towards Flexible Joint Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamic Movement Primitives (DMPs) are a well-known tool for encoding robotic motions. Their popularity stems from invariance properties in time and space, the ability to describe complex coordinated motions in multiple degrees of freedom with a relatively small number of parameters, and the linearity in the parameters that describe the motion. The latter allows easily fitting a DMP to motions e.g. demonstrated by a human. DMPs are at their core second order autonomous differential equations. However, feedforward controls of robots with flexible joints are known to require reference trajectories up to the fourth derivative of position. Consequently, classical DMPs are mechanically not compatible with flexible joint robots. In this paper, we propose an extension of DMPs by introducing FlexDMPs. This concept retains the structural properties and benefits of classical DMPs but generates trajectories up to the fourth derivative that can theoretically be tracked ideally (i.e. with zero tracking error) by flexible joint robots. The concept is demonstrated on a high fidelity simulation model of an industrial robot and in experimental results on a collaborative manipulator.",
        "primary_area": "",
        "author": "Arne Wahrburg;Simone Guida;Nima Enayati;Andrea Maria Zanchettin;Paolo Rocco;Arne Wahrburg;Simone Guida;Nima Enayati;Andrea Maria Zanchettin;Paolo Rocco",
        "authorids": "/38233633900;/37088549994;/37085446214;/37546427600;/37274178600;/38233633900;/37088549994;/37085446214;/37546427600;/37274178600",
        "aff": "ABB Corporate Research, Ladenburg, Germany; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; ABB Corporate Research, Ladenburg, Germany; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Milan, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560843/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7625405195272111536&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;1",
        "aff_unique_norm": "ABB Corporate Research;Politecnico di Milano",
        "aff_unique_dep": ";Department of Electronics, Information and Bioengineering",
        "aff_unique_url": "https://new.abb.com/research;https://www.polimi.it",
        "aff_unique_abbr": "ABB;Politecnico di Milano",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Milan",
        "aff_country_unique_index": "0;1;0;1;1",
        "aff_country_unique": "Germany;Italy"
    },
    {
        "id": "9561412",
        "title": "Flocking-Segregative Swarming Behaviors using Gibbs Random Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel approach that allows a swarm of heterogeneous robots to produce simultaneously segregative and flocking behaviors using only local sensing. These behaviors have been widely studied in swarm robotics and their combination allows the execution of several complex tasks. Our approach consists of modeling the swarm as a Gibbs Random Field (GRF) and using appropriate potential functions to reach segregation, cohesion and consensus on the velocity of the swarm. Simulations and proof-of-concept experiments using real robots are presented to evaluate the performance of our methodology in comparison to some of the state-of-the-art works that tackle segregative behaviors.",
        "primary_area": "",
        "author": "Paulo Rezeck;Renato M. Assun\u00e7\u00e3o;Luiz Chaimowicz;Paulo Rezeck;Renato M. Assun\u00e7\u00e3o;Luiz Chaimowicz",
        "authorids": "/37086210134;/37085580375;/37277207100;/37086210134;/37085580375;/37277207100",
        "aff": "Department of Computer Science, Universidade Federal de Minas Gerais, Brazil; Department of Computer Science, Universidade Federal de Minas Gerais, Brazil; Department of Computer Science, Universidade Federal de Minas Gerais, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561412/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10472356205731886819&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universidade Federal de Minas Gerais",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "http://www.ufmg.br",
        "aff_unique_abbr": "UFMG",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Brazil"
    },
    {
        "id": "9560791",
        "title": "Flow-FL: Data-Driven Federated Learning for Spatio-Temporal Predictions in Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we show how the Federated Learning (FL) framework enables learning collectively from distributed data in connected robot teams. This framework typically works with clients collecting data locally, updating neural network weights of their model, and sending updates to a server for aggregation into a global model. We explore the design space of FL by comparing two variants of this concept. The first variant follows the traditional FL approach in which a server aggregates the local models. In the second variant, that we call Flow-FL, the aggregation process is serverless thanks to the use of a gossip-based shared data structure. In both variants, we use a data-driven mechanism to synchronize the learning process in which robots contribute model updates when they collect sufficient data. We validate our approach with an agent trajectory forecasting problem in a multi-agent setting. Using a centralized implementation as a baseline, we study the effects of staggered online data collection, and variations in data flow, number of participating robots, and time delays introduced by the decentralization of the framework in a multi-robot setting.",
        "primary_area": "",
        "author": "Nathalie Majcherczyk;Nishan Srishankar;Carlo Pinciroli;Nathalie Majcherczyk;Nishan Srishankar;Carlo Pinciroli",
        "authorids": "/37086582203;/37088507083;/37283183600;/37086582203;/37088507083;/37283183600",
        "aff": "Robotics Engineering, Worcester Polytechnic Institute, MA, USA; Robotics Engineering, Worcester Polytechnic Institute, MA, USA; Robotics Engineering, Worcester Polytechnic Institute, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560791/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4934795589610760370&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Robotics Engineering",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560820",
        "title": "FlowDriveNet: An End-to-End Network for Learning Driving Policies from Image Optical Flow and LiDAR Point Flow",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning driving policies using an end-to-end network has been proved a promising solution for autonomous driving. Due to the lack of a benchmark driver behavior dataset that contains both the visual and the LiDAR data, existing works solely focus on learning driving from visual sensors. Besides, most works are limited to predict steering angle yet neglect the more challenging vehicle speed control problem. In this paper, we propose a novel end-to-end network, FlowDriveNet, which takes advantages of sequential visual data and LiDAR data jointly to predict steering angle and vehicle speed. The main challenges of this problem are how to efficiently extract driving-related information from images and point clouds, and how to fuse them effectively. To tackle these challenges, we propose a concept of point flow and declare that image optical flow and LiDAR point flow are significant motion cues for driving policy learning. Specifically, we first create an enhanced dataset that consists of images, point clouds and corresponding human driver behaviors. Then, in FlowDriveNet, a deep but efficient visual feature extraction module and a point feature extraction module are utilized to extract spatial features from optical flow and point flow, respectively. Additionally, a novel temporal fusion and prediction module is designed to fuse temporal information from the extracted spatial feature sequences and predict vehicle driving commands. Finally, a series of ablation experiments verify the importance of optical flow and point flow and comparison experiments show that our flow-based method outperforms the existing image-based approaches on the task of driving policy learning.",
        "primary_area": "",
        "author": "Shuai Wang;Jiahu Qin;Menglin Li;Yaonan Wang;Shuai Wang;Jiahu Qin;Menglin Li;Yaonan Wang",
        "authorids": "/37089393849;/37398575900;/37086012386;/37281429000;/37089393849;/37398575900;/37086012386;/37281429000",
        "aff": "Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China; National Engineering Laboratory for Robot Visual Perception and Control Technology, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560820/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16509491538688332394&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Science and Technology of China;National Engineering Laboratory for Robot Visual Perception and Control Technology",
        "aff_unique_dep": "Department of Automation;",
        "aff_unique_url": "http://www.ustc.edu.cn;",
        "aff_unique_abbr": "USTC;",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Hefei;Changsha",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561165",
        "title": "Fool Me Once: Robust Selective Segmentation via Out-of-Distribution Detection with Contrastive Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, a neural network is trained to simultaneously perform segmentation and pixel-wise Out-of-Distribution (OoD) detection, such that the segmentation of unknown regions of scenes can be rejected. This is made possible by leveraging an OoD dataset with a novel contrastive objective and data augmentation scheme. By including unknown classes in the training data, a more robust feature representation is learned with known classes represented distinctly from those unknown. In comparison, when presented with unknown classes or conditions, many current approaches for segmentation frequently exhibit high confidence in their inaccurate segmentations and cannot be trusted in many operational environments. We validate our system on a real-world dataset of unusual driving scenes, and show that by selectively segmenting scenes based on what is predicted as OoD, we can increase the segmentation accuracy by an IoU of 0.2 with respect to alternative techniques.",
        "primary_area": "",
        "author": "David S. W. Williams;Matthew Gadd;Daniele De Martini;Paul Newman;David S. W. Williams;Matthew Gadd;Daniele De Martini;Paul Newman",
        "authorids": "/37088596724;/37085439081;/37086933606;/37335903100;/37088596724;/37085439081;/37086933606;/37335903100",
        "aff": "Oxford Robotics Institute, Dept. Engineering Science, University of Oxford, UK; Oxford Robotics Institute, Dept. Engineering Science, University of Oxford, UK; Oxford Robotics Institute, Dept. Engineering Science, University of Oxford, UK; Oxford Robotics Institute, Dept. Engineering Science, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561165/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15574828900590898581&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Dept. Engineering Science",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561887",
        "title": "Foot Control of a Surgical Laparoscopic Gripper via 5DoF Haptic Robotic Platform: Design, Dynamics and Haptic Shared Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Foot devices have been ubiquitously used in surgery to control surgical equipment. Most common applications are foot switches for electro-surgery, endoscope positioning and tele-robotic consoles. Switches fall short of providing continuous control as required for precise use of instruments. We developed a haptic foot interface to provide continuous assistance in surgical procedures. This paper concerns the foot control of simultaneous five degrees of freedom (DoF) of a surgical laparoscopic gripper. We assess systematically precision at controlling position and orientation at the target and closing of the forceps. Our controller provides position:position mapping between the foot and the robotic tool, as well as haptic feedback, compensating for gravity of the lower limb of the operator so as to alleviate fatigue. A dynamic model compensation and closed loop force feedback is used to achieve high transparency and backdrivability. The assistance is based on a novel type of haptic fixtures combining spring-damper with selective dynamic compensation in the direction aligned with the task of grasping, so as to simplify control of certain poses, made difficult due to the coupling between human lower limbs\u2019 DoF\u2019s. We experimentally evaluated the control strategy with six users on a position control surgical task in simulation. Results show the proposed assistance greatly eases the foot grasping task leading to higher completeness, efficiency, and lower mental and physical load.",
        "primary_area": "",
        "author": "Jacob Hernandez Sanchez;Walid Amanhoud;Aude Billard;Mohamed Bouri;Jacob Hernandez Sanchez;Walid Amanhoud;Aude Billard;Mohamed Bouri",
        "authorids": "/37089001034;/37088504835;/37273980800;/37294221500;/37089001034;/37088504835;/37273980800;/37294221500",
        "aff": "LASA Laboratory, Swiss Federal School of Technology in Lausanne EPFL, Switzerland; LASA Laboratory, Swiss Federal School of Technology in Lausanne EPFL, Switzerland; LASA Laboratory, Swiss Federal School of Technology in Lausanne EPFL, Switzerland; REHAssist Group, Swiss Federal School of Technology in Lausanne EPFL, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561887/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5590456500474473398&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Swiss Federal Institute of Technology in Lausanne (EPFL)",
        "aff_unique_dep": "LASA Laboratory",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lausanne",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561816",
        "title": "Force-Sensing Tensegrity for Investigating Physical Human-Robot Interaction in Compliant Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Advancements in the domain of physical human-robot interaction (pHRI) have tremendously improved the ability of humans and robots to communicate, collaborate, and coexist. In particular, compliant robotic systems offer many characteristics that can be leveraged towards enabling physical interactions that more efficiently and intuitively communicate intent, making compliant systems potentially useful in more physically demanding subsets of human-robot collaborative scenarios. Tensegrity robots are an example of compliant systems that are well-suited to physical interactions while still retaining useful rigid properties that make them practical for a variety of applications. In this paper, we present the design and preliminary testing of a 6-bar spherical tensegrity with force-sensing capabilities. Using this prototype, we demonstrate the ability of its force-sensor array to detect a variety of physical interaction types that might arise in a human context. We then train and test a series of classifiers using data from unique and representative interactions in order to demonstrate the feasibility of using this physical modality of sensing to reliably communicate goals and intents from a human operator in a human-robot collaborative setting.",
        "primary_area": "",
        "author": "Andrew R. Barkan;Akhil Padmanabha;Sala R. Tiemann;Albert Lee;Matthew P. Kanter;Yash S. Agarwal;Alice M. Agogino;Andrew R. Barkan;Akhil Padmanabha;Sala R. Tiemann;Albert Lee;Matthew P. Kanter;Yash S. Agarwal;Alice M. Agogino",
        "authorids": "/37085366741;/37088507364;/37088996424;/37088996372;/37088999636;/37088560759;/37358366200;/37085366741;/37088507364;/37088996424;/37088996372;/37088999636;/37088560759;/37358366200",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA; Department of Mechanical Engineering, University of California, Berkeley, Berkeley, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561816/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3490232085952313937&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561191",
        "title": "Formal Verification of ROS Based Systems Using a Linear Logic Theorem Prover",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel representation and verification technique for software components in a robotic system using a linear logic theorem prover. Linear logic includes consumable resources together with persistent resources, enabling representing and reasoning of robotic domains. We demonstrate model representation and verification of formal specifications through Robot Operating System (ROS) components. The system model can be either statically extracted by HAROS (a ROS based static analysis framework) or dynamically extracted once all system components are running. After ten years of its first release, ROS has become one of the most popular middlewares among robotic programming frameworks. Even though ROS is very popular among robotic developers, we believe that a framework for easily representing and verifying robotic systems is missing. This paper introduces a new technique for formally representing and verifying robotic systems using a linear logic theorem prover and finally presents a number of illustrations of model representation and safety property checking both statically and dynamically for the robot Kobuki.",
        "primary_area": "",
        "author": "Sitar Kortik;Tejas Kumar Shastha;Sitar Kortik;Tejas Kumar Shastha",
        "authorids": "/37085419348;/37086918075;/37085419348;/37086918075",
        "aff": "Fraunhofer IPA, Stuttgart, Germany; Fraunhofer IPA, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561191/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7568817952267636770&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ipa.fraunhofer.de/",
        "aff_unique_abbr": "Fraunhofer IPA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9562076",
        "title": "Freyja: A Full Multirotor System for Agile & Precise Outdoor Flights",
        "track": "main",
        "status": "Poster",
        "abstract": "Several independent approaches exist for state estimation and control of multirotor unmanned aerial systems (UASs) that address specific and constrained operational conditions. This work presents a complete end-to-end pipeline that enables precise, aggressive and agile maneuvers for multirotor UASs under real and challenging outdoor environments. We leverage state-of-the-art optimal methods from the literature for trajectory planning and control, such that designing and executing dynamic paths is fast, robust and easy to customize for a particular application. The complete pipeline, built entirely using commercially available components, is made open-source and fully documented to facilitate adoption. We demonstrate its performance in a variety of operational settings, such as hovering at a spot under dynamic wind speeds of up to 5\u2013 6m/s (12\u201315mi/h) while staying within 12cm of 3D error. We also characterize its capabilities in flying high-speed trajectories outdoors, and enabling fast aerial docking with a moving target with planning and interception occurring in under 8s.",
        "primary_area": "",
        "author": "Ajay Shankar;Sebastian Elbaum;Carrick Detweiler;Ajay Shankar;Sebastian Elbaum;Carrick Detweiler",
        "authorids": "/37086145944;/37272376100;/38535355300;/37086145944;/37272376100;/38535355300",
        "aff": "Department of Computer Science & Engineering, University of Nebraska-Lincoln, USA; Department of Computer Science, University of Virginia, Virginia, USA; Department of Computer Science & Engineering, University of Nebraska-Lincoln, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562076/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11323591575712026621&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Nebraska-Lincoln;University of Virginia",
        "aff_unique_dep": "Department of Computer Science & Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.unl.edu;https://www.virginia.edu",
        "aff_unique_abbr": "UNL;UVA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Lincoln;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560964",
        "title": "Friction Estimation for Tendon-Driven Robotic Hands",
        "track": "main",
        "status": "Poster",
        "abstract": "In tendon-driven robotic hands, tendons are usually routed along several pulleys. The resulting friction is often substantial, and must therefore be modelled and estimated, for instance for accurate control and contact detection. Common approaches for friction estimation consider special dedicated setups, where the parameters of a static or dynamic friction model at a single contact point are determined. In this paper, we rather combine such individual friction models into an overall friction model for the entire finger. Furthermore, we propose a method for estimating the parameters of this overall model in situ, i.e. from trajectories executed on the assembled hand, avoiding the need for dedicated setups. An important component of the proposed model is a varying bias for treating friction at low velocities, allowing a simpler static friction model to be used. We demonstrate that our approach enables contacts to be detected more accurately on the DLR David hand, without additional sensors.",
        "primary_area": "",
        "author": "Friedrich Lange;Martin Pfanne;Franz Steinmetz;Sebastian Wolf;Freek Stulp;Friedrich Lange;Martin Pfanne;Franz Steinmetz;Sebastian Wolf;Freek Stulp",
        "authorids": "/37327865200;/37086332896;/37085752163;/37546936800;/37681682200;/37327865200;/37086332896;/37085752163;/37546936800;/37681682200",
        "aff": "Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560964/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16768358469153526075&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Wessling",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561125",
        "title": "Friction-driven Three-foot Robot Inspired by Snail Movement",
        "track": "main",
        "status": "Poster",
        "abstract": "Snails\u2019 unique locomotion abilities help them realise stable movement by muscular exploiting travelling waves and friction modulation. Inspired by these characteristics, snaillike robots have recently become the focus of growing research. In this paper, we present a novel friction-driven three-foot snaillike robot which employs a simple mechanism to partially mimic and replicate snail-like motion, but in a novel form. This robot is driven by two servo motors, which makes it easy and low-cost to fabricate. The robot operates by breaking frictional symmetry in the cyclic motion of the three feet, in much the same way as the three-sphere Golestanian swimmer. The symmetry of its structure and properties of friction give the robot distinctive movements. We present a mathematical model of the robot\u2019s locomotion, focusing on its kinetic harmonic-peristaltic movement. We designed and fabricated the robot, then undertook simulations and experiments, which closely match the analytic solutions. This robot provides a new approach to realising simpler and lower cost biomimetic mobile robots.",
        "primary_area": "",
        "author": "Tianqi Yue;Hermes Bloomfield-Gad\u00ealha;Jonathan Rossiter;Tianqi Yue;Hermes Bloomfield-Gad\u00ealha;Jonathan Rossiter",
        "authorids": "/37088997424;/37088910937;/37271190700;/37088997424;/37088910937;/37271190700",
        "aff": "Department of Engineering Mathematics and Bristol Robotics Laboratory, University of Bristol, Bristol, UK; Department of Engineering Mathematics and Bristol Robotics Laboratory, University of Bristol, Bristol, UK; Department of Engineering Mathematics and Bristol Robotics Laboratory, University of Bristol, Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561125/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16381518565407616864&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bristol",
        "aff_unique_dep": "Department of Engineering Mathematics",
        "aff_unique_url": "https://www.bristol.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bristol",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561213",
        "title": "From Multi-Target Sensory Coverage to Complete Sensory Coverage: An Optimization-Based Robotic Sensory Coverage Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers progressively more demanding off-line shortest path sensory coverage problems in an optimization framework. In the first problem, a robot finds the shortest path to cover a set of target nodes with its sensors. Because this mixed integer nonlinear optimization problem (MINLP) is NP-hard, we develop a polynomial-time approximation algorithm with a bounded approximation ratio. The next problem shortens the coverage path when possible by viewing multiple targets from a single pose. Its polynomial-time approximation simplifies the coverage path geometry. Finally, we show how the complete sensory coverage problem can be formulated as a MINLP over a decomposition of a given region into arbitrary convex polygons. Extensions of the previously introduced algorithms provides a polynomial time solution with bounded approximation. Examples illustrate the methods.",
        "primary_area": "",
        "author": "Joel W. Burdick;Amanda Bouman;Elon Rimon;Joel W. Burdick;Amanda Bouman;Elon Rimon",
        "authorids": "/37265975700;/37087322528;/37265270200;/37265975700;/37087322528;/37265270200",
        "aff": "Engineering and Applied Sciences, California Institute of Technology, Pasadena, CA; Engineering and Applied Sciences, California Institute of Technology, Pasadena, CA; Engineering and Applied Sciences, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561213/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7983104762499116920&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Engineering and Applied Sciences",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561136",
        "title": "Fusing RGBD Tracking and Segmentation Tree Sampling for Multi-Hypothesis Volumetric Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite rapid progress in scene segmentation in recent years, 3D segmentation methods are still limited when there is severe occlusion. The key challenge is estimating the segment boundaries of (partially) occluded objects, which are inherently ambiguous when considering only a single frame. In this work, we propose Multihypothesis Segmentation Tracking (MST), a novel method for volumetric segmentation in changing scenes, which allows scene ambiguity to be tracked and our estimates to be adjusted over time as we interact with the scene. Two main innovations allow us to tackle this difficult problem: 1) A novel way to sample possible segmentations from a segmentation tree; and 2) A novel approach to fusing tracking results with multiple segmentation estimates. These methods allow MST to track the segmentation state over time and incorporate new information, such as new objects being revealed. We evaluate our method on several cluttered tabletop environments in simulation and reality. Our results show that MST outperforms baselines in all tested scenes.",
        "primary_area": "",
        "author": "Andrew Price;Kun Huang;Dmitry Berenson;Andrew Price;Kun Huang;Dmitry Berenson",
        "authorids": "/37088997419;/37088999616;/37542925700;/37088997419;/37088999616;/37542925700",
        "aff": "the University of Michigan, Ann Arbor, MI, USA; the University of Michigan, Ann Arbor, MI, USA; the University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561136/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14198618586682876012&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561115",
        "title": "Fusion-DHL: WiFi, IMU, and Floorplan Fusion for Dense History of Locations in Indoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper proposes a multi-modal sensor fusion algorithm that fuses WiFi, IMU, and floorplan information to infer an accurate and dense location history in indoor environments. The algorithm uses 1) an inertial navigation algorithm to estimate a relative motion trajectory from IMU sensor data; 2) a WiFi-based localization API in industry to obtain positional constraints and geo-localize the trajectory; and 3) a convolutional neural network to refine the location history to be consistent with the floorplan. We have developed a data acquisition app to build a new dataset with WiFi, IMU, and floorplan data with ground-truth positions at 4 university buildings and 3 shopping malls. Our qualitative and quantitative evaluations demonstrate that the proposed system is able to produce twice as accurate and a few orders of magnitude denser location history than the current standard, while requiring minimal additional energy consumption. We will publicly share our code and models.",
        "primary_area": "",
        "author": "Sachini Herath;Saghar Irandoust;Bowen Chen;Yiming Qian;Pyojin Kim;Yasutaka Furukawa;Sachini Herath;Saghar Irandoust;Bowen Chen;Yiming Qian;Pyojin Kim;Yasutaka Furukawa",
        "authorids": "/37085715341;/37088997422;/37089001181;/37085580008;/37085573756;/37086288534;/37085715341;/37088997422;/37089001181;/37085580008;/37085573756;/37086288534",
        "aff": "Simon Fraser University; Simon Fraser University; Simon Fraser University; Simon Fraser University; Sookmyung Women\u2019s University; Simon Fraser University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561115/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15955915147597202357&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Simon Fraser University;Sookmyung Women's University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.sfu.ca;https://www.sookmyung.ac.kr",
        "aff_unique_abbr": "SFU;SWU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Canada;South Korea"
    },
    {
        "id": "9561259",
        "title": "Fuzz Testing in Behavior-Based Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "The behavior of a robot is typically expressed as a set of source code files written using a programming language. As for any software engineering activity, programming robotic behaviors is a complex and error-prone task. This paper propose a methodology that aims to reduce the cost of producing a reliable software describing a robotic behavior by automatically testing it.We employ a fuzz testing technique to stress software components with randomly generated data. By applying fuzz testing to a complex robotic-software, we identified errors related to the coding, the way data is handled, the logic of the robotic behavior, and the initialization of architectural components. Furthermore, a panel of experts acquainted with the analyzed behavior have highlighted the relevance and the significance of our findings. Our fuzzer operates on the SMACH and ROS frameworks and it is available under the MIT public open source license.",
        "primary_area": "",
        "author": "Rodrigo Delgado;Miguel Campusano;Alexandre Bergel;Rodrigo Delgado;Miguel Campusano;Alexandre Bergel",
        "authorids": "/37086805213;/37085732026;/37680079100;/37086805213;/37085732026;/37680079100",
        "aff": "Department of Computer Science (DCC), ISCLab, University of Chile; SDU UAS, MMMI, University of Southern Denmark; Department of Computer Science (DCC), ISCLab, University of Chile",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561259/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1449622865306975449&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Chile;University of Southern Denmark",
        "aff_unique_dep": "Department of Computer Science;SDU UAS, MMMI",
        "aff_unique_url": "https://www.uchile.cl;https://www.sdu.dk",
        "aff_unique_abbr": "UChile;SDU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Chile;Denmark"
    },
    {
        "id": "9561627",
        "title": "Fuzzing Mobile Robot Environments for Fast Automated Crash Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Testing mobile robots is difficult and expensive, and many faults go undetected. In this work we explore whether fuzzing, an automated test input generation technique, can more quickly find failure inducing inputs in mobile robots. We developed a simple fuzzing adaptation, BASE-FUZZ, and one specialized for fuzzing mobile robots, PHYS-FUZZ. PHYS-FUZZ is unique in that it accounts for physical attributes such as the robot dimensions, estimated trajectories, and time to impact measures to guide the test input generation process. The results of evaluating PHYS-FUZZ suggest that it has the potential to speed up the discovery of input scenarios that reveal failures, finding 56.5% more than uniform random input selection and 7.0% more than BASE-FUZZ during 7 days of testing.",
        "primary_area": "",
        "author": "Trey Woodlief;Sebastian Elbaum;Kevin Sullivan;Trey Woodlief;Sebastian Elbaum;Kevin Sullivan",
        "authorids": "/37089001912;/37272376100;/37284180800;/37089001912;/37272376100;/37284180800",
        "aff": "University of Virginia, USA; University of Virginia, USA; University of Virginia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561627/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4159919877121249756&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561885",
        "title": "GCC-PHAT with Speech-oriented Attention for Robotic Sound Source Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic audition is a basic sense that helps robots perceive the surroundings and interact with humans. Sound Source Localization (SSL) is an essential module for a robotic system. However, the performance of most sound source localization techniques degrades in noisy and reverberant environments due to inaccurate Time Difference of Arrival (TDoA) estimation. In robotic sound source localization, we are more interested in detecting the arrival of human speech than other sound sources. Ideally, we expect an effective TDoA estimation to respond only to speech signals, while masking off other interferences. In this paper, we propose a novel technique that learns to attend to speech fundamental frequency and harmonics while suppressing noise interference and reverberation. The novel TDoA feature is referred to as Generalized Cross Correlation with Phase Transform and Speech Mask (GCC-PHAT-SM). We perform sound source localization experiments on real-world data captured from a robotic platform. Experiments show that GCC-PHAT-SM feature significantly outperforms traditional Generalized Cross Correlation (GCC) feature in noisy and reverberant acoustic environments.",
        "primary_area": "",
        "author": "Jiadong Wang;Xinyuan Qian;Zihan Pan;Malu Zhang;Haizhou Li;Jiadong Wang;Xinyuan Qian;Zihan Pan;Malu Zhang;Haizhou Li",
        "authorids": "/37088919829;/37086008136;/37086479543;/37086254640;/37407157000;/37088919829;/37086008136;/37086479543;/37086254640;/37407157000",
        "aff": "Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Department of Electrical and Computer Engineering, National University of Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561885/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5339523028881419661&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9561355",
        "title": "GPR-based Model Reconstruction System for Underground Utilities Using GPRNet",
        "track": "main",
        "status": "Poster",
        "abstract": "Ground Penetrating Radar (GPR) is one of the most important non-destructive evaluation (NDE) instruments to detect and locate underground objects (i.e. rebars, utility pipes). Many of the previous researches focus on GPR image-based feature detection only, and none can process sparse GPR measurements to successfully reconstruct a very fine and detailed 3D model of underground objects for better visualization. To address this problem, this paper presents a novel robotic system to collect GPR data, localize the underground utilities, and reconstruct the underground objects\u2019 dense point cloud model. This system is composed of three modules: 1) visual-inertial-based GPR data collection module which tags the GPR measurements with positioning information provided by an omnidirectional robot; 2) a deep neural network (DNN) migration module to interpret the raw GPR B-scan image into a cross-section of object model; 3) a DNN-based 3D reconstruction module, i.e., GPRNet, to generate underground utility model with the fine 3D point cloud. In this paper, both the quantitative and qualitative experiment results verify our method that can generate a dense and complete point cloud model of pipe-shaped utilities based on a sparse input, i.e., GPR raw data, with incompleteness and various noise. The experiment results on synthetic data as well as field test data further support the effectiveness of our approach.",
        "primary_area": "",
        "author": "Jinglun Feng;Liang Yang;Ejup Hoxha;Diar Sanakov;Stanislav Sotnikov;Jizhong Xiao;Jinglun Feng;Liang Yang;Ejup Hoxha;Diar Sanakov;Stanislav Sotnikov;Jizhong Xiao",
        "authorids": "/37088373434;/37085495533;/37088997966;/37088999797;/37088371181;/37278647800;/37088373434;/37085495533;/37088997966;/37088999797;/37088371181;/37278647800",
        "aff": "Electrical Engineering Department, The City College of New York, New York, USA; Electrical Engineering Department, The City College of New York, New York, USA; Electrical Engineering Department, The City College of New York, New York, USA; Electrical Engineering Department, The City College of New York, New York, USA; Electrical Engineering Department, The City College of New York, New York, USA; Electrical Engineering Department, The City College of New York, New York, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561355/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=236896822484351659&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "City College of New York",
        "aff_unique_dep": "Electrical Engineering Department",
        "aff_unique_url": "https://www.ccny.cuny.edu",
        "aff_unique_abbr": "CCNY",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561868",
        "title": "GPR: Grasp Pose Refinement Network for Cluttered Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Object grasping in cluttered scenes is a widely investigated field of robot manipulation. Most of the current works focus on estimating grasp pose from point clouds based on an efficient single-shot grasp detection network. However, due to the lack of geometry awareness of the local grasping area, it may cause severe collisions and unstable grasp configurations. In this paper, we propose a two-stage grasp pose refinement network which detects grasps globally while fine-tuning low-quality grasps and filtering noisy grasps locally. Furthermore, we extend the 6-DoF grasp with an extra dimension as grasp width which is critical for collisionless grasping in cluttered scenes. It takes a single-view point cloud as input and predicts dense and precise grasp configurations. To enhance the generalization ability, we build a synthetic single-object grasp dataset including 150 commodities of various shapes, and a complex multi-object cluttered scene dataset including 100k point clouds with robust, dense grasp poses and mask annotations. Experiments conducted on Yumi IRB-1400 Robot demonstrate that the model trained on our dataset performs well in real environments and outperforms previous methods by a large margin.",
        "primary_area": "",
        "author": "Wei Wei;Yongkang Luo;Fuyu Li;Guangyun Xu;Jun Zhong;Wanyi Li;Peng Wang;Wei Wei;Yongkang Luo;Fuyu Li;Guangyun Xu;Jun Zhong;Wanyi Li;Peng Wang",
        "authorids": "/37088998436;/37085483874;/37088647988;/37088999560;/37089001468;/38469175800;/37538869400;/37088998436;/37085483874;/37088647988;/37088999560;/37089001468;/38469175800;/37538869400",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; CAS Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561868/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4180323949991332343&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;1;1;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_unique_dep": "School of Artificial Intelligence;Institute of Automation",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.ia.cas.cn",
        "aff_unique_abbr": "UCAS;CAS",
        "aff_campus_unique_index": "0;0;0;0;0;0;1",
        "aff_campus_unique": "Beijing;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561849",
        "title": "GPU-Efficient Dense Convolutional Network for Real-time Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time semantic segmentation is a challenging task as both accuracy and inference speed need to be considered simultaneously. In real-world applications, it is usually achieved by deploying a deep neural network in modern GPU device. However, most of the work focused on real-time semantic segmentation is designed by significantly reducing computation complexity and model size. There are other factors that have a significant impact on inference speed are overlooked, especially when the network is running in modern GPU device. In this paper, we focus on designing a GPU-efficient network as backbone for real-time semantic segmentation. Dense connectivity can preserve and accumulate feature maps of multiple receptive fields and is therefore ideal for semantic segmentation. Therefore, we design a GPU-efficient network (DenseENet) with dense connectivity. The proposed DenseENet shows an obvious advantage in balancing accuracy and inference speed in modern GPU device. Specifically, on Cityscapes test set, DenseENet with a simple FCN decoder achieves 75.2% mIoU with 83.6 FPS for an input of 1024 \u00d7 2048 resolution and 73.6% mIoU with 132 FPS for an input of 768 \u00d7 1536 resolution on a single GTX 1080Ti card.",
        "primary_area": "",
        "author": "Xinneng Yang;Yan Wu;Junqiao Zhao;Feilin Liu;Xinneng Yang;Yan Wu;Junqiao Zhao;Feilin Liu",
        "authorids": "/37088998267;/37281232900;/37086158636;/37089001162;/37088998267;/37281232900;/37086158636;/37089001162",
        "aff": "College of Electronics and Information Engineering, Tongji University, Shanghai, China; College of Electronics and Information Engineering, Tongji University, Shanghai, China; Institute of Intelligent Vehicle, Tongji University, Shanghai, China; College of Electronics and Information Engineering, Tongji University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561849/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7465894654556334640&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tongji University",
        "aff_unique_dep": "College of Electronics and Information Engineering",
        "aff_unique_url": "http://www.tongji.edu.cn",
        "aff_unique_abbr": "Tongji",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560783",
        "title": "GelSight Wedge: Measuring High-Resolution 3D Contact Geometry with a Compact Robot Finger",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision-based tactile sensors have the potential to provide important contact geometry to localize the objective with visual occlusion. However, it is challenging to measure high-resolution 3D contact geometry for a compact robot finger, to simultaneously meet optical and mechanical constraints. In this work, we present the GelSight Wedge sensor, which is optimized to have a compact shape for robot fingers, while achieving high-resolution 3D reconstruction. We evaluate the 3D reconstruction under different lighting configurations, and extend the method from 3 lights to 1 or 2 lights. We demonstrate the flexibility of the design by shrinking the sensor to the size of a human finger for fine manipulation tasks. We also show the effectiveness and potential of the reconstructed 3D geometry for pose tracking in the 3D space.",
        "primary_area": "",
        "author": "Shaoxiong Wang;Yu She;Branden Romero;Edward Adelson;Shaoxiong Wang;Yu She;Branden Romero;Edward Adelson",
        "authorids": "/37086252778;/37089130545;/37088505353;/37349732300;/37086252778;/37089130545;/37088505353;/37349732300",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560783/",
        "gs_citation": 145,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3495208017577834835&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561654",
        "title": "GenGrid: A Generalised Distributed Experimental Environmental Grid for Swarm Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "GenGrid is a novel comprehensive open-source, distributed platform intended for conducting extensive swarm robotic experiments. The modular platform is designed to run swarm robotics experiments that are compatible with different types of mobile robots ranging from Colias, Kilobot, and E-puck [1]\u2013[4]. The platform offers programmable control over the experimental setup and its parameters and acts as a tool to collect swarm robot data, including localization, sensory feedback, messaging, and interaction. GenGrid is designed as a modular grid of attachable computing nodes that offers bidirectional communication between the robotic agent and grid nodes and within grids. The paper describes the hardware and software architecture design of the GenGrid system. Further, it discusses some common experimental studies covering multi-robot and swarm robotics to showcase the platform\u2019s use. GenGrid of 25 homogeneous cells with identical sensing and communication characteristics with a footprint of 37.5 cm \u00d7 37.5 cm, exhibits multiple capabilities with minimal resources. The open-source hardware platform is handy for running swarm experiments, including robot hopping based on multiple gradients, collective transport, shepherding, continuous pheromone deposition, and subsequent evaporation. The low-cost, modular, and open-source platform is significant in the swarm robotics research community, which is currently driven by commercial platforms that allow minimal modifications.",
        "primary_area": "",
        "author": "Pranav Kedia;Madhav Rao;Pranav Kedia;Madhav Rao",
        "authorids": "/37087094208;/37574450600;/37087094208;/37574450600",
        "aff": "IIIT, Bangalore; IIIT, Bangalore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561654/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:MxCegTgIkvcJ:scholar.google.com/&scioq=GenGrid:+A+Generalised+Distributed+Experimental+Environmental+Grid+for+Swarm+Robotics&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "International Institute of Information Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://iiitb.ac.in",
        "aff_unique_abbr": "IIIT-B",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bangalore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9561103",
        "title": "Generalization in Reinforcement Learning by Soft Data Augmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Extensive efforts have been made to improve the generalization ability of Reinforcement Learning (RL) methods via domain randomization and data augmentation. However, as more factors of variation are introduced during training, optimization becomes increasingly challenging, and empirically may result in lower sample efficiency and unstable training. Instead of learning policies directly from augmented data, we propose SOft Data Augmentation (SODA), a method that decouples augmentation from policy learning. Specifically, SODA imposes a soft constraint on the encoder that aims to maximize the mutual information between latent representations of augmented and non-augmented data, while the RL optimization process uses strictly non-augmented data. Empirical evaluations are performed on diverse tasks from DeepMind Control suite as well as a robotic manipulation task, and we find SODA to significantly advance sample efficiency, generalization, and stability in training over state-of-the-art vision-based RL methods.1",
        "primary_area": "",
        "author": "Nicklas Hansen;Xiaolong Wang;Nicklas Hansen;Xiaolong Wang",
        "authorids": "/37088478670;/37085652454;/37088478670;/37085652454",
        "aff": "Technical University of Denmark, Denmark; University of California, San Diego, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561103/",
        "gs_citation": 209,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16451015885216130142&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Technical University of Denmark;University of California, San Diego",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tek.dk;https://ucsd.edu",
        "aff_unique_abbr": "DTU;UCSD",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";San Diego",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Denmark;United States"
    },
    {
        "id": "9561543",
        "title": "Generalized Nonlinear and Finsler Geometry for Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotics research has found numerous important applications of Riemannian geometry. Despite that, the concept remain challenging to many roboticists because the background material is complex and strikingly foreign. Beyond Riemannian geometry, there are many natural generalizations in the mathematical literature\u2014areas such as Finsler geometry and spray geometry\u2014but those generalizations are largely inaccessible, and as a result there remain few applications within robotics. This paper presents a re-derivation of spray and Finsler geometries, critical for the development of our recent work on geometric fabrics, which builds the ideas from familiar concepts in advanced calculus and the calculus of variations. We focus on the pragmatic and calculable results, avoiding the use of tensor notation to appeal to a broader audience and emphasizing geometric path consistency over ideas around connections and curvature. We hope that they will contribute to an increased understanding of generalized nonlinear, and even classical Riemannian, geometry within the robotics community and inspire future research into new applications.",
        "primary_area": "",
        "author": "Nathan D. Ratliff;Karl Van Wyk;Mandy Xie;Anqi Li;Muhammad Asif Rana;Nathan D. Ratliff;Karl Van Wyk;Mandy Xie;Anqi Li;Muhammad Asif Rana",
        "authorids": "/37579950900;/37085779307;/37088999924;/37086580906;/37086935482;/37579950900;/37085779307;/37088999924;/37086580906;/37086935482",
        "aff": "NVIDIA; NVIDIA; Georgia Tech; University of Washington; Georgia Tech",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561543/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13393277874089066084&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;1",
        "aff_unique_norm": "NVIDIA;Georgia Institute of Technology;University of Washington",
        "aff_unique_dep": "NVIDIA Corporation;;",
        "aff_unique_url": "https://www.nvidia.com;https://www.gatech.edu;https://www.washington.edu",
        "aff_unique_abbr": "NVIDIA;Georgia Tech;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560824",
        "title": "Generalized Point Set Registration with the Kent Distribution",
        "track": "main",
        "status": "Poster",
        "abstract": "Point set registration (PSR) is an essential problem in communities of computer vision, medical robotics and biomedical engineering. This paper is motivated by considering the anisotropic characteristics of the error values in estimating both the positional and orientational vectors from the PSs to be registered. To do this, the multi-variate Gaussian and Kent distributions are utilized to model the positional and orientational uncertainties, respectively. Our contributions of this paper are three-folds: (i) the PSR problem using normal vectors is formulated as a maximum likelihood estimation (MLE) problem, where the anisotropic characteristics in both positional and normal vectors are considered; (ii) the matrix forms of the objective function and its associated gradients with respect to the desired parameters are provided, which can facilitate the computational process; (iii) two approaches of computing the normalizing constant in the Kent distribution are compared. We verify our proposed registration method on various PSs (representing pelvis and femur bones) in computer- assisted orthopedic surgery (CAOS). Extensive experimental results demonstrate that our method outperforms the state- of-the-art methods in terms of the registration accuracy and the robustness.",
        "primary_area": "",
        "author": "Zhe Min;Delong Zhu;Max Q.-H. Meng;Zhe Min;Delong Zhu;Max Q.-H. Meng",
        "authorids": "/37086002886;/37086137408;/37274117000;/37086002886;/37086137408;/37274117000",
        "aff": "Department of Electronic Engineering, The Chinese University of Hong Kong, N.T., Hong Kong SAR, China; Department of Electronic Engineering, The Chinese University of Hong Kong, N.T., Hong Kong SAR, China; Shenzhen Research Institute, The Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560824/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1788401413397175658&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electronic Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "N.T.;Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561577",
        "title": "Generalizing Object-Centric Task-Axes Controllers using Keypoints",
        "track": "main",
        "status": "Poster",
        "abstract": "To perform manipulation tasks in the real world, robots need to operate on objects with various shapes, sizes and without access to geometric models. To achieve this it is often infeasible to train monolithic neural network policies across such large variations in object properties. Towards this generalization challenge, we propose to learn modular task policies which compose object-centric task-axes controllers. These task-axes controllers are parameterized by properties associated with underlying objects in the scene. We infer these controller parameters directly from visual input using multi-view dense correspondence learning. Our overall approach provides a simple and yet powerful framework for learning manipulation tasks. We empirically evaluate our approach on 3 different manipulation tasks and show its ability to generalize to large variance in object size, shape and geometry.",
        "primary_area": "",
        "author": "Mohit Sharma;Oliver Kroemer;Mohit Sharma;Oliver Kroemer",
        "authorids": "/37086376038;/37593222300;/37086376038;/37593222300",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561577/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5725849885272669554&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561117",
        "title": "Generating Continuous Motion and Force Plans in Real-Time for Legged Mobile Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulators can be added to legged robots, allowing them to interact with and change their environment. Legged mobile manipulation planners must consider how contact forces generated by these manipulators affect the system. Current planning strategies either treat these forces as immutable during planning or are unable to optimize over these contact forces while operating in real-time. This paper presents the Stability and Task Oriented Receding-Horizon Motion and Manipulation Autonomous Planner (STORMMAP) that is able to generate continuous plans for the robot\u2019s motion and manipulation force trajectories that ensure dynamic feasibility and stability of the platform, and incentivizes accomplishing manipulation and motion tasks specified by a user. A variety of simulated experiments on a quadruped with a manipulator mounted to its torso demonstrate the versatility of STOR-MMAP. In contrast to existing state of the art methods, the approach described in this paper generates continuous plans in under ten milliseconds, an order of magnitude faster than previous strategies.",
        "primary_area": "",
        "author": "Parker Ewen;Jean-Pierre Sleiman;Yuxin Chen;Wei-Chun Lu;Marco Hutter;Ram Vasudevan;Parker Ewen;Jean-Pierre Sleiman;Yuxin Chen;Wei-Chun Lu;Marco Hutter;Ram Vasudevan",
        "authorids": "/37088997720;/37087322472;/37089443942;/37086180248;/37545251000;/37648237800;/37088997720;/37087322472;/37089443942;/37086180248;/37545251000;/37648237800",
        "aff": "Robotics and Optimization for Analysis of Human Motion Lab, University of Michigan, USA; Robotic Systems Laboratory, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Robotics and Optimization for Analysis of Human Motion Lab, University of Michigan, USA; Robotics and Optimization for Analysis of Human Motion Lab, University of Michigan, USA; Robotic Systems Laboratory, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Robotics and Optimization for Analysis of Human Motion Lab, University of Michigan, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561117/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4978855709060281338&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;1;0",
        "aff_unique_norm": "University of Michigan;ETH Zurich",
        "aff_unique_dep": "Robotics and Optimization for Analysis of Human Motion Lab;Robotic Systems Laboratory",
        "aff_unique_url": "https://www.umich.edu;https://www.ethz.ch",
        "aff_unique_abbr": "UM;ETH",
        "aff_campus_unique_index": "0;1;0;0;1;0",
        "aff_campus_unique": "Ann Arbor;Z\u00fcrich",
        "aff_country_unique_index": "0;1;0;0;1;0",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "9561585",
        "title": "Generating Large-Scale Trajectories Efficiently using Double Descriptions of Polynomials",
        "track": "main",
        "status": "Poster",
        "abstract": "For quadrotor trajectory planning, describing a polynomial trajectory through coefficients and end-derivatives both enjoy their own convenience in energy minimization. We name them double descriptions of polynomial trajectories. The transformation between them, causing most of the inefficiency and instability, is formally analyzed in this paper. Leveraging its analytic structure, we design a linear-complexity scheme for both jerk/snap minimization and parameter gradient evaluation, which possesses efficiency, stability, flexibility, and scalability. With the help of our scheme, generating an energy optimal (minimum snap) trajectory only costs 1 \u00b5s per piece at the scale up to 1,000,000 pieces. Moreover, generating large-scale energy-time optimal trajectories is also accelerated by an order of magnitude against conventional methods.",
        "primary_area": "",
        "author": "Zhepei Wang;Hongkai Ye;Chao Xu;Fei Gao;Zhepei Wang;Hongkai Ye;Chao Xu;Fei Gao",
        "authorids": "/37086601081;/37086811929;/37404060100;/37086045143;/37086601081;/37086811929;/37404060100;/37086045143",
        "aff": "National Engineering Research Center for Industrial Automation (Ningbo Institute), Ningbo, China; National Engineering Research Center for Industrial Automation (Ningbo Institute), Ningbo, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561585/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=87567185575093044&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "National Engineering Research Center for Industrial Automation;Zhejiang University",
        "aff_unique_dep": ";Huzhou Institute",
        "aff_unique_url": ";https://www.zju.edu.cn",
        "aff_unique_abbr": "NERC-IA;ZJU",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Ningbo;Huzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561196",
        "title": "Generative Design of NU\u2019s Husky Carbon, A Morpho-Functional, Legged Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "We report the design of a morpho-functional robot called Husky Carbon. Our goal is to integrate two forms of mobility, aerial and quadrupedal legged locomotion, within a single platform. There are prohibitive design restrictions such as tight power budget and payload, which can particularly become important in aerial flights. To address these challenges, we pose a problem called the Mobility Value of Added Mass (MVAM) problem. In the MVAM problem, we attempt to allocate mass in our designs such that the energetic performance is affected the least. To solve the MVAM problem, we adopted a generative design approach using Grasshopper\u2019s evolutionary solver to synthesize a parametric design space for Husky. Then, this space was searched for the morphologies that could yield a minimized Total Cost Of Transport (TCOT) and payload. This approach revealed that a front heavy quadrupedal robot can achieve a lower TCOT while retaining larger margins on allowable added mass to its design. Based on this framework Husky was built and tested as a front heavy robot.",
        "primary_area": "",
        "author": "Alireza Ramezani;Pravin Dangol;Eric Sihite;Andrew Lessieur;Peter Kelly;Alireza Ramezani;Pravin Dangol;Eric Sihite;Andrew Lessieur;Peter Kelly",
        "authorids": "/37398489300;/37088482241;/37088452718;/37088922727;/37088451377;/37398489300;/37088482241;/37088452718;/37088922727;/37088451377",
        "aff": "Department of Electrical and Computer Engineering, Silicon-Synapse Laboratory, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Silicon-Synapse Laboratory, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Silicon-Synapse Laboratory, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Silicon-Synapse Laboratory, Northeastern University, Boston, MA, USA; Department of Electrical and Computer Engineering, Silicon-Synapse Laboratory, Northeastern University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561196/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11228514236195032135&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Northeastern University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.northeastern.edu",
        "aff_unique_abbr": "NU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560823",
        "title": "Generic Hand\u2013Eye Calibration of Uncertain Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We provide a generic framework for the hand\u2013 eye calibration of vision-guided industrial robots. In contrast to traditional methods, we explicitly model the uncertainty of the robot in a statistically sound manner. Albeit the precision of modern industrial robots is high, their absolute accuracy typically is much lower. This uncertainty \u2014 if not considered \u2014 deteriorates the result of the hand\u2013eye calibration. Our proposed framework not only results in a high accuracy of the computed hand\u2013eye pose but also provides reliable information about the uncertainty of the robot. It further provides corrected robot poses for a convenient and inexpensive robot calibration. Our framework is generic in several respects: It supports the use of a calibration target as well as self-calibration without the need for known 3D points. It optionally allows the simultaneous calibration of the interior camera parameters. The framework is also generic with regard to the robot type, and hence supports articulated as well as SCARA robots, for example. Simulated and real experiments show the validity of the proposed methods.",
        "primary_area": "",
        "author": "Markus Ulrich;Markus Hillemann;Markus Ulrich;Markus Hillemann",
        "authorids": "/37543470000;/37089002205;/37543470000;/37089002205",
        "aff": "Institute of Photogrammetry and Remote Sensing, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute of Photogrammetry and Remote Sensing, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560823/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4024560943345654467&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute of Photogrammetry and Remote Sensing",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561628",
        "title": "Geometry-Aware Unsupervised Domain Adaptation for Stereo Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently proposed DNN-based stereo matching methods that learn priors directly from data are known to suffer a drastic drop in accuracy in new environments. Although supervised approaches with ground truth disparity maps often work well, collecting them in each deployment environment is cumbersome and costly. For this reason, many unsupervised domain adaptation methods based on image-to-image translation have been proposed, but these methods do not preserve the geometric structure of a stereo image pair because the image-to-image translation is applied to each view separately. To address this problem, in this paper, we propose an attention mechanism that aggregates features in the left and right views, called Stereoscopic Cross Attention (SCA). Incorporating SCA to an image-to-image translation network makes it possible to preserve the geometric structure of a stereo image pair in the process of the image-to-image translation. We empirically demonstrate the effectiveness of the proposed unsupervised domain adaptation based on the image-to-image translation with SCA.",
        "primary_area": "",
        "author": "Hiroki Sakuma;Yoshinori Konishi;Hiroki Sakuma;Yoshinori Konishi",
        "authorids": "/37088996077;/37089000750;/37088996077;/37089000750",
        "aff": "SenseTime Japan Ltd; SenseTime Japan Ltd",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561628/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17820072971677562896&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "SenseTime",
        "aff_unique_dep": "SenseTime Japan Ltd",
        "aff_unique_url": "https://www.sensetime.com",
        "aff_unique_abbr": "SenseTime",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561774",
        "title": "Geometry-aware Compensation Scheme for Morphing Drones",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent studies have shown that enabling drones to change their morphology in flight can significantly increase their versatility in different tasks. In this paper, we investigate the aerodynamic effects caused by the partial overlap between the propellers and the main body of a morphing quadrotor during flight. We experimentally characterize such effects and design a morphology-aware control scheme to compensate them. We demonstrate the effectiveness of our approach by deploying the compensation scheme on a quadrotor that can fold its arms around the main body, comparing it against the same controller without the compensation scheme. Experimental results show that our compensation scheme can address the loss of thrust due to the overlap between the main body and the propellers, guaranteeing higher tracking accuracy, without requiring complex and computationally expensive aerodynamical models. To the best of our knowledge, this is the first work counteracting the aerodynamic effects of a morphing quadrotor during flight and showing the effects of partial overlap between a propeller and the central body of the drone.",
        "primary_area": "",
        "author": "Amedeo Fabris;Kevin Kleber;Davide Falanga;Davide Scaramuzza;Amedeo Fabris;Kevin Kleber;Davide Falanga;Davide Scaramuzza",
        "authorids": "/37088997788;/37086554532;/37085994484;/37397688400;/37088997788;/37086554532;/37085994484;/37397688400",
        "aff": "Dep. of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Dep. of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Dep. of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland; Dep. of Neuroinformatics, University of Zurich and ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561774/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12448376502076443260&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Zurich",
        "aff_unique_dep": "Department of Neuroinformatics",
        "aff_unique_url": "https://www.unizh.ch",
        "aff_unique_abbr": "UZH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9562005",
        "title": "Global Aerial Localisation Using Image and Map Embeddings",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a purely vision based geolocation method for aircraft flying over urban and suburban environments. The method is based on matching aerial images with geolocated map tiles using a shared low dimensional embedded space of descriptors. The Euclidean distance between descriptors is used as a similarity measure between domains. The similarity between the observation and map locations is then integrated with visual odometry to track the aircraft\u2019s position and yaw using a particle filter. Furthermore, we propose an efficient method to generate map descriptors in testing time based on interpolation, allowing compact representation of large areas giving the potential for high levels of scalability. We experimented in different cities with areas above 20 km2 in size and preliminary results based on a database of aerial imagery demonstrate that the method gives good results.",
        "primary_area": "",
        "author": "Noe Samano;Mengjie Zhou;Andrew Calway;Noe Samano;Mengjie Zhou;Andrew Calway",
        "authorids": "/37088997215;/37089000993;/37326243500;/37088997215;/37089000993;/37326243500",
        "aff": "Department of Computer Science, University of Bristol, Bristol, U.K.; Department of Computer Science, University of Bristol, Bristol, U.K.; Department of Computer Science, University of Bristol, Bristol, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562005/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15390938982450345516&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bristol",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bristol.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bristol",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561961",
        "title": "Global Position Control on Underactuated Bipedal Robots: Step-to-step Dynamics Approximation for Step Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Global position control for underactuated bipedal walking is a challenging problem due to the lack of actuation on the feet of the robots. In this paper, we apply the Hybrid-Linear Inverted Pendulum (H-LIP) based stepping on 3D underactuated bipedal robots for global position control. The step-to-step (S2S) dynamics of the H-LIP walking approximates the actual S2S dynamics of the walking of the robot, where the step size is considered as the input. Thus the feedback controller based on the H-LIP approximately controls the robot to behave like the H-LIP, the differences between which stay in an error invariant set. Model Predictive Control (MPC) is applied to the H-LIP for global position control in 3D. The H-LIP stepping then generates desired step sizes for the robot to track. Moreover, turning behavior is integrated with the step planning. The proposed framework is verified on the 3D underactuated bipedal robot Cassie in simulation together with a proof-of-concept experiment.",
        "primary_area": "",
        "author": "Xiaobin Xiong;Jenna Reher;Aaron D. Ames;Xiaobin Xiong;Jenna Reher;Aaron D. Ames",
        "authorids": "/37086275102;/37085715578;/37300877900;/37086275102;/37085715578;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561961/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17952498545546654375&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560810",
        "title": "Globally Optimal Online Redundancy Resolution for Serial 7-DOF Kinematics Along SE(3) Trajectories",
        "track": "main",
        "status": "Poster",
        "abstract": "Redundant robots offer the possibility of improving agility, compared to their non-redundant counterparts, by exploiting the additional kinematic DOFs to increase a measure called manipulability. While it is common to maximize the manipulability measure during redundancy resolution locally, global optimization of a full trajectory is usually computationally too expensive and thus only considered for offline procedures in current literature. However, local maximization is prone to be sub-optimal and at times even fails at preserving agility of a robot that ought to be reactive. In this work we build upon our previous contributions on online trajectory generation on SE(3) and closed-form task space manipulability of a 7-DOF serial robot, and combine it with graph search techniques for global optimization. This enables, for the first time, online trajectory generation with globally optimal redundancy resolution regarding manipulability, to maintain agility in reactive robot behavior.",
        "primary_area": "",
        "author": "Gerold Huber;Dirk Wollherr;Gerold Huber;Dirk Wollherr",
        "authorids": "/37085637435;/37295545400;/37085637435;/37295545400",
        "aff": "Chair of Automatic Control Engineering (LSR), Faculty of Electrical Engineering, Technical University of Munich, M\u00fcnchen, Germany; Chair of Automatic Control Engineering (LSR), Faculty of Electrical Engineering, Technical University of Munich, M\u00fcnchen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560810/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1390589814106009067&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Faculty of Electrical Engineering",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "M\u00fcnchen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561835",
        "title": "Go Fetch! - Dynamic Grasps using Boston Dynamics Spot with External Robotic Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "We combine Boston Dynamics Spot\u00ae with a light-weight, external robot arm to perform dynamic grasping maneuvers. While Spot is a reliable, robust and easy-to-control mobile robot, these highly desirable qualities come with the price that the control access granted to the user is restricted. Consequently Spot\u2019s behavior must largely be treated as a black box, which causes difficulties when combined with a moving payload such as a robotic arm. We overcome the arising challenges by building a model of the combined platform, fitting the corresponding model parameters using experimental data and a straight-forward optimization framework. We use this model to generate control commands for the physical platform using trajectory optimization. We demonstrate that even with a simple model, and control trajectories deployed in a feed-forward manner, the combined platform is capable of executing grasping tasks in a dynamic fashion. Furthermore, we show how the platform can use the additional degrees of freedom of the legs to extend the reachability of the arm.",
        "primary_area": "",
        "author": "Simon Zimmermann;Roi Poranne;Stelian Coros;Simon Zimmermann;Roi Poranne;Stelian Coros",
        "authorids": "/37088231270;/37085580542;/37077396200;/37088231270;/37085580542;/37077396200",
        "aff": "Department of Computer Science, ETH, Zurich, Switzerland; Department of Computer Science, University of Haifa, Haifa, Israel; Department of Computer Science, ETH, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561835/",
        "gs_citation": 121,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10930832594350945975&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "ETH Zurich;University of Haifa",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.ethz.ch;https://www.haifa.ac.il",
        "aff_unique_abbr": "ETHZ;UoH",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Zurich;Haifa",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Switzerland;Israel"
    },
    {
        "id": "9560738",
        "title": "GoSafe: Globally Optimal Safe Robot Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "When learning policies for robotic systems from data, safety is a major concern, as violation of safety constraints may cause hardware damage. SafeOpt is an efficient Bayesian optimization (BO) algorithm that can learn policies while guaranteeing safety with high probability. However, its search space is limited to an initially given safe region. We extend this method by exploring outside the initial safe area while still guaranteeing safety with high probability. This is achieved by learning a set of initial conditions from which we can recover safely using a learned backup controller in case of a potential failure. We derive conditions for guaranteed convergence to the global optimum and validate GoSafe in hardware experiments.",
        "primary_area": "",
        "author": "Dominik Baumann;Alonso Marco;Matteo Turchetta;Sebastian Trimpe;Dominik Baumann;Alonso Marco;Matteo Turchetta;Sebastian Trimpe",
        "authorids": "/37086423452;/37085789250;/37086465712;/37542844600;/37086423452;/37085789250;/37086465712;/37542844600",
        "aff": "Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Department of Computer Science, ETH Z\u00fcrich, Switzerland; Max Planck Institute for Intelligent Systems, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560738/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15300401309133844829&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;ETH Zurich",
        "aff_unique_dep": ";Department of Computer Science",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.ethz.ch",
        "aff_unique_abbr": "MPI-IS;ETHZ",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stuttgart;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "id": "9560752",
        "title": "Goal-Conditioned End-to-End Visuomotor Control for Versatile Skill Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "Visuomotor control (VMC) is an effective means of achieving basic manipulation tasks such as pushing or pick- and-place from raw images. Conditioning VMC on desired goal states is a promising way of achieving versatile skill primitives. However, common conditioning schemes either rely on task-specific fine tuning - e.g. using one-shot imitation learning (IL) - or on sampling approaches using a forward model of scene dynamics i.e. model-predictive control (MPC), leaving deployability and planning horizon severely limited. In this paper we propose a conditioning scheme which avoids these pitfalls by learning the controller and its conditioning in an end-to-end manner. Our model predicts complex action sequences based directly on a dynamic image representation of the robot motion and the distance to a given target observation. In contrast to related works, this enables our approach to efficiently perform complex manipulation tasks from raw image observations without predefined control primitives or test time demonstrations. We report significant improvements in task success over representative MPC and IL baselines. We also demonstrate our model's generalisation capabilities in challenging, unseen tasks featuring visual noise, cluttered scenes and unseen object geometries.",
        "primary_area": "",
        "author": "Oliver Groth;Chia-Man Hung;Andrea Vedaldi;Ingmar Posner;Oliver Groth;Chia-Man Hung;Andrea Vedaldi;Ingmar Posner",
        "authorids": "/37086075089;/37088998853;/37398040100;/37601368300;/37086075089;/37088998853;/37398040100;/37601368300",
        "aff": "Department of Engineering Science, University of Oxford, United Kingdom; Department of Engineering Science, University of Oxford, United Kingdom; Department of Engineering Science, University of Oxford, United Kingdom; Department of Engineering Science, University of Oxford, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560752/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1275033280191399614&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Department of Engineering Science",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561008",
        "title": "Gramian-based optimal active sensing control under intermittent measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an online optimal perception-aware strategy meant to maximize the information collected along the trajectory via the available measurements while simultaneously minimizing the negative effects of actuation/process noise. Indeed, in several robotic applications, the actuation/process noise is far from negligible and its negative effects are particularly relevant especially with intermittent measurements (e.g. collected by a vision system with limited Field-Of-View). New metrics are proposed as combinations of the Constructability Gramian, for measuring the amount of information collected via the available sensors, and the Reachability Gramian, for measuring the degrading effects of actuation/process noise. Control inputs that optimize those cost functions are provided. To show the effectiveness of our method, we consider one case study involving a unicycle-like vehicle, subject to Gaussian measurement noise and Gaussian or Brownian actuation noise, that estimates its state using intermittent distances from known environmental markers.",
        "primary_area": "",
        "author": "Olga Napolitano;Daniele Fontanelli;Lucia Pallottino;Paolo Salaris;Olga Napolitano;Daniele Fontanelli;Lucia Pallottino;Paolo Salaris",
        "authorids": "/37089000072;/37398642200;/37278580100;/37398653000;/37089000072;/37398642200;/37278580100;/37398653000",
        "aff": "Dipartimento di Ingegneria Dell\u2019Informazione, Centro di Ricerca \"E. Piaggio,\", Universit\u00e0 di Pisa, Italy; Department of Industrial Engineering, Universit\u00e0 di Trento, Italy; Dipartimento di Ingegneria Dell\u2019Informazione, Centro di Ricerca \"E. Piaggio,\", Universit\u00e0 di Pisa, Italy; Dipartimento di Ingegneria Dell\u2019Informazione, Centro di Ricerca \"E. Piaggio,\", Universit\u00e0 di Pisa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561008/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5763842732263002447&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Universit\u00e0 di Pisa;Universit\u00e0 di Trento",
        "aff_unique_dep": "Dipartimento di Ingegneria Dell\u2019Informazione;Department of Industrial Engineering",
        "aff_unique_url": "https://www.unipi.it;https://www.unitn.it",
        "aff_unique_abbr": "UniPi;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9561340",
        "title": "Graph Convolutional Network based Configuration Detection for Freeform Modular Robot Using Magnetic Sensor Array",
        "track": "main",
        "status": "Poster",
        "abstract": "Modular self-reconfigurable robotic (MSRR) systems are potentially more robust and more adaptive than conventional systems. Following our previous work where we proposed a freeform MSRR module called FreeBOT, this paper presents a novel configuration detection system for FreeBOT using a magnetic sensor array. A FreeBOT module can be connected by up to 11 modules, and the proposed configuration detection system can locate a variable number of connection points accurately in real-time. By equipping FreeBOT with 24 magnetic sensors, the magnetic field density produced by magnets and steel spherical shells can be monitored. The connectable area is split into 199 non-uniform regions, including 84 uniform regions. Using a Graph Convolutional Network (GCN) based algorithm, the connection points can be located accurately under ferromagnetic environments. The system can locate a variable number of connection points for such a region division with only single connection point training data. Finally, the localization algorithm can run faster than 40 Hz on FreeBOT. With the real-time configuration detection system, the FreeBOT system has the potential to reconfigure automatically and accurately.",
        "primary_area": "",
        "author": "Yuxiao Tu;Guanqi Liang;Tin Lun Lam;Yuxiao Tu;Guanqi Liang;Tin Lun Lam",
        "authorids": "/37089000919;/37088687610;/37571111600;/37089000919;/37088687610;/37571111600",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561340/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12800115664466096325&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.siarfs.org/",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561107",
        "title": "Graph-SIM: A Graph-based Spatiotemporal Interaction Modelling for Pedestrian Action Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the most crucial yet challenging tasks for autonomous vehicles in urban environments is predicting the future behaviour of nearby pedestrians, especially at points of crossing. Predicting behaviour depends on many social and environmental factors, particularly interactions between road users. Capturing such interactions requires a global view of the scene and dynamics of the road users in three-dimensional space. This information, however, is missing from the current pedestrian behaviour benchmark datasets. Motivated by these challenges, we propose 1) a novel graph-based model for predicting pedestrian crossing action. Our method models pedestrians\u2019 interactions with nearby road users through clustering and relative importance weighting of interactions using features obtained from the bird\u2019s-eye-view. 2) We introduce a new dataset that provides 3D bounding box and pedestrian behavioural annotations for the existing nuScenes dataset. On the new data, our approach achieves state-of-the-art performance by improving on various metrics by more than 15% in comparison to existing methods. The dataset is available at https://github.com/huawei-noah/datasets/PePScenes.",
        "primary_area": "",
        "author": "Tiffany Yau;Saber Malekmohammadi;Amir Rasouli;Peter Lakner;Mohsen Rohani;Jun Luo;Tiffany Yau;Saber Malekmohammadi;Amir Rasouli;Peter Lakner;Mohsen Rohani;Jun Luo",
        "authorids": "/37088997467;/37087889545;/37086037019;/37088999806;/37088997658;/37089002073;/37088997467;/37087889545;/37086037019;/37088999806;/37088997658;/37089002073",
        "aff": "Noah\u2019s Ark Lab, Huawei, Canada; Noah\u2019s Ark Lab, Huawei, Canada; Noah\u2019s Ark Lab, Huawei, Canada; Noah\u2019s Ark Lab, Huawei, Canada; Noah\u2019s Ark Lab, Huawei, Canada; Noah\u2019s Ark Lab, Huawei, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561107/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2171646296576953017&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Noah\u2019s Ark Lab",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561830",
        "title": "Graph-based Topological Exploration Planning in Large-scale 3D Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Currently, state-of-the-art exploration methods maintain high-resolution map representations in order to optimize exploration goals in each step that maximizes information gain. However, during exploring, those \"optimal\" selections could quickly become obsolete due to the influx of new information, especially in large-scale environments, and result in high-frequency re-planning that hinders the overall exploration efficiency. In this paper, we propose a graph-based topological planning framework, building a sparse topological map in three-dimensional (3D) space to guide exploration steps with high-level intents so as to render consistent exploration maneuvers. Specifically, this work presents a novel method to estimate 3D space\u2019s geometry with convex polyhedrons. Then, the geometry information is utilized to group space into distinctive regions. And those regions are added as nodes into the topological map, directing the exploration process. We compared our method with the state-of-the-art in simulated environments. The proposed method achieves higher space coverage and outperforms exploration efficiency by more than 40% during experiments. Finally, a field experiment was conducted to further evaluate the applicability of our method to empower efficient and robust exploration in real-world environments.",
        "primary_area": "",
        "author": "Fan Yang;Dung-Han Lee;John Keller;Sebastian Scherer;Fan Yang;Dung-Han Lee;John Keller;Sebastian Scherer",
        "authorids": "/37089000155;/37088998294;/37088999161;/37584159000;/37089000155;/37088998294;/37088999161;/37584159000",
        "aff": "Robotics Institue at Carnegie Mellon University, Pittsburgh; Robotics Institue at Carnegie Mellon University, Pittsburgh; Robotics Institue at Carnegie Mellon University, Pittsburgh; Robotics Institue at Carnegie Mellon University, Pittsburgh",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561830/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9216468585310183099&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561332",
        "title": "Grasp Analysis and Manipulation Kinematics for Isoperimetric Truss Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft isoperimetric truss robots have demonstrated an ability to grasp and manipulate objects using the members of their structure. The compliance of the members affords large contact areas with even force distribution, allowing for successful grasping even with imprecise open-loop control. In this work we present methods of analyzing and controlling isoperimetric truss robots in the context of grasping and manipulating objects. We use a direct stiffness model to characterize the structural properties of the robot and its interactions with external objects. With this approach we can estimate grasp forces and stiffnesses with limited computation compared to higher fidelity finite elements methods, which, given the many degrees-of-freedom of truss robots, are prohibitively expensive to run on-board. In conjunction with the structural model, we build upon a literature of differential kinematics for truss robots and apply it to the task of manipulating an object within the robot\u2019s workspace.",
        "primary_area": "",
        "author": "Zachary M. Hammond;Nathan S. Usevitch;Sean Follmer;Zachary M. Hammond;Nathan S. Usevitch;Sean Follmer",
        "authorids": "/37086066571;/37086062994;/37085667725;/37086066571;/37086062994;/37085667725",
        "aff": "Dept. of Mechanical Engineering, Stanford University, Stanford, CA, USA; Dept. of Mechanical Engineering, Stanford University, Stanford, CA, USA; Dept. of Mechanical Engineering, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561332/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14812189685115271819&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560970",
        "title": "Grasp Detection for Robot to Human Handovers Using Capacitive Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "As it happens, despite yet unmatched by robots perception and motor skills humans drop objects during handover because of false grasp detection and early release. Accordingly, the fluent robot-human handover is still an open challenge. This paper presents an approach to a natural robot to human handover using Capacitive Proximity Sensor (CPS) for robust grasp detection and release trigger. We propose an experimental setup for the evaluation using a collaborative robot, an eye-in-hand depth camera, and CPS integrated into the gripper. Three grasp detection methods were implemented and an object release was triggered based on torque-sensing, capacitive sensing, and the combination of both. Finally, a user study was designed and conducted, indicating that the capacitive method is the most preferred type with the shortest human idle time and the highest fluency ratings.",
        "primary_area": "",
        "author": "Ilshat Mamaev;David Kretsch;Hosam Alagi;Bj\u00f6rn Hein;Ilshat Mamaev;David Kretsch;Hosam Alagi;Bj\u00f6rn Hein",
        "authorids": "/37088996085;/37088996648;/38666348400;/37604448500;/37088996085;/37088996648;/38666348400;/37604448500",
        "aff": "Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics Lab (IAR - IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics Lab (IAR - IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Institute for Anthropomatics and Robotics - Intelligent Process Automation and Robotics Lab (IAR - IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Karlsruhe University of Applied Science",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560970/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=50949164941709235&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Karlsruhe Institute of Technology;Karlsruhe University of Applied Sciences",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics;",
        "aff_unique_url": "https://www.kit.edu;https://www.hs-karlsruhe.de",
        "aff_unique_abbr": "KIT;HsKA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Karlsruhe;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561662",
        "title": "Grasping with Chopsticks: Combating Covariate Shift in Model-free Imitation Learning for Fine Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Billions of people use chopsticks, a simple yet versatile tool, for fine manipulation of everyday objects. The small, curved, and slippery tips of chopsticks pose a challenge for picking up small objects, making them a suitably complex test case. This paper leverages human demonstrations to develop an autonomous chopsticks-equipped robotic manipulator. Due to the lack of accurate models for fine manipulation, we explore model-free imitation learning, which traditionally suffers from the covariate shift phenomenon that causes poor generalization. We propose two approaches to reduce covariate shift, neither of which requires access to an interactive expert or a model, unlike previous approaches. First, we alleviate singlestep prediction errors by applying an invariant operator to increase the data support at critical steps for grasping. Second, we generate synthetic corrective labels by adding bounded noise and combining parametric and non-parametric methods to prevent error accumulation. We demonstrate our methods on a real chopstick-equipped robot that we built, and observe the agent\u2019s success rate increase from 37.3% to 80%, which is comparable to the human expert performance of 82.6%.",
        "primary_area": "",
        "author": "Liyiming Ke;Jingqiang Wang;Tapomayukh Bhattacharjee;Byron Boots;Siddhartha Srinivasa;Liyiming Ke;Jingqiang Wang;Tapomayukh Bhattacharjee;Byron Boots;Siddhartha Srinivasa",
        "authorids": "/37088688640;/37088687393;/37531634500;/37085459219;/37339877600;/37088688640;/37088687393;/37531634500;/37085459219;/37339877600",
        "aff": "University of Washington, Seattle, WA, USA; University of Washington, Seattle, WA, USA; University of Washington, Seattle, WA, USA; University of Washington, Seattle, WA, USA; University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561662/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3715316329252922705&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Washington",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.washington.edu",
        "aff_unique_abbr": "UW",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561262",
        "title": "Greedy-Based Feature Selection for Efficient LiDAR SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern LiDAR-SLAM (L-SLAM) systems have shown excellent results in large-scale, real-world scenarios. However, they commonly have a high latency due to the expensive data association and nonlinear optimization. This paper demonstrates that actively selecting a subset of features significantly improves both the accuracy and efficiency of an L-SLAM system. We formulate the feature selection as a combinatorial optimization problem under a cardinality constraint to preserve the information matrix's spectral attributes. The stochastic-greedy algorithm is applied to approximate the optimal results in real-time. To avoid ill-conditioned estimation, we also propose a general strategy to evaluate the environment's degeneracy and modify the feature number online. The proposed feature selector is integrated into a multi-LiDAR SLAM system. We validate this enhanced system with extensive experiments covering various scenarios on two sensor setups and computation platforms. We show that our approach exhibits low localization error and speedup compared to the state-of-the-art L-SLAM systems. To benefit the community, we have released the source code: https://ram-lab.com/file/site/m-loam.",
        "primary_area": "",
        "author": "Jianhao Jiao;Yilong Zhu;Haoyang Ye;Huaiyang Huang;Peng Yun;Linxin Jiang;Lujia Wang;Ming Liu;Jianhao Jiao;Yilong Zhu;Haoyang Ye;Huaiyang Huang;Peng Yun;Linxin Jiang;Lujia Wang;Ming Liu",
        "authorids": "/37086552343;/37086964447;/37086022108;/37087103064;/37086640426;/37089000373;/37406752700;/37085398677;/37086552343;/37086964447;/37086022108;/37087103064;/37086640426;/37089000373;/37406752700;/37085398677",
        "aff": "Robotics Institute, HKUST, Hong Kong SAR, China; Robotics Institute, HKUST, Hong Kong SAR, China; Robotics Institute, HKUST, Hong Kong SAR, China; Robotics Institute, HKUST, Hong Kong SAR, China; Robotics Institute, HKUST, Hong Kong SAR, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Robotics Institute, HKUST, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561262/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8326790701813827744&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Shenzhen Institute of Advanced Technology",
        "aff_unique_dep": "Robotics Institute;Chinese Academy of Sciences",
        "aff_unique_url": "https://www.ust.hk;http://www.siat.cas.cn",
        "aff_unique_abbr": "HKUST;SIAT",
        "aff_campus_unique_index": "0;0;0;0;0;1;1;0",
        "aff_campus_unique": "HKUST;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560928",
        "title": "Group Feature Learning and Domain Adversarial Neural Network for aMCI Diagnosis System Based on EEG",
        "track": "main",
        "status": "Poster",
        "abstract": "Medical diagnostic robot systems have been paid more and more attention due to its objectivity and accuracy. The diagnosis of mild cognitive impairment (MCI) is considered an effective means to prevent Alzheimer's disease (AD). Doctors diagnose MCI based on various clinical examinations, which are expensive and the diagnosis results rely on the knowledge of doctors. Therefore, it is necessary to develop a robot diagnostic system to eliminate the influence of human factors and obtain a higher accuracy rate. In this paper, we propose a novel Group Feature Domain Adversarial Neural Network (GF- DANN) for amnestic MCI (aMCI) diagnosis, which involves two important modules. A Group Feature Extraction (GFE) module is proposed to reduce individual differences by learning group- level features through adversarial learning. A Dual Branch Domain Adaptation (DBDA) module is carefully designed to reduce the distribution difference between the source and target domain in a domain adaption way. On three types of data set, GF-DANN achieves the best accuracy compared with classic machine learning and deep learning methods. On the DMS data set, GF-DANN has obtained an accuracy rate of 89.47%, and the sensitivity and specificity are 90% and 89%. In addition, by comparing three EEG data collection paradigms, our results demonstrate that the DMS paradigm has the potential to build an aMCI diagnose robot system.",
        "primary_area": "",
        "author": "Chen-Chen Fan;Haiqun Xie;Liang Peng;Hongjun Yang;Zhen-Liang Ni;Guan\u2019an Wang;Yan-Jie Zhou;Sheng Chen;Zhijie Fang;Shuyun Huang;Zeng-Guang Hou;Chen-Chen Fan;Haiqun Xie;Liang Peng;Hongjun Yang;Zhen-Liang Ni;Guan\u2019an Wang;Yan-Jie Zhou;Sheng Chen;Zhijie Fang;Shuyun Huang;Zeng-Guang Hou",
        "authorids": "/37089268878;/37088997839;/37085383206;/37086347000;/37087030579;/37088219192;/37087016101;/37086479272;/37088955549;/37089001318;/37279945000;/37089268878;/37088997839;/37085383206;/37086347000;/37087030579;/37088219192;/37087016101;/37086479272;/37088955549;/37089001318;/37279945000",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Department of Neurology, First People's Hospital of Foshan, Foshan, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Management and Control for Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Department of Neurology, First People's Hospital of Foshan, Foshan, China; CASIA-MUST Joint Laboratory of Intelligence Science and Technology, Institute of Systems Engineering, Macau University of Science and Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560928/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11723535483940965635&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;1;2;2;0;0;0;0;0;1;3",
        "aff_unique_norm": "University of Chinese Academy of Sciences;First People's Hospital of Foshan;Chinese Academy of Sciences;Macau University of Science and Technology",
        "aff_unique_dep": "School of Artificial Intelligence;Department of Neurology;Institute of Automation;Institute of Systems Engineering",
        "aff_unique_url": "http://www.ucas.ac.cn;;http://www.ia.cas.cn;https://www.must.edu.mo",
        "aff_unique_abbr": "UCAS;;CAS;MUST",
        "aff_campus_unique_index": "0;1;0;0;0;0;0;0;0;1",
        "aff_campus_unique": "Beijing;Foshan;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561214",
        "title": "Gyrubot: nonanthropomorphic stabilization for a biped",
        "track": "main",
        "status": "Poster",
        "abstract": "Demands on leg degrees of freedom and control precision for bipedal robotics are steadily increasing, especially for the tasks involving walking on a rough terrain. In this paper we present an alternative, as well as a working proof-of-concept. Meet gyrubot: a 5-link almost planar bipedal robot with a torso complemented by a nonanthropomorphic stabilization system, capable of blindly walking through uneven areas. Despite being almost planar, the robot does not need any support in the frontal plane! This paper describes the mechanical design and the architecture of the controllers. We also provide the experimental evidence of the ability of gyrubot to navigate across non-flat terrains.",
        "primary_area": "",
        "author": "Nikita Mikhalkov;Alexey Prutskiy;Semyon Sechenev;Dmitry Kazakov;Alexey Simulin;Dmitry Sokolov;Igor Ryadchikov;Nikita Mikhalkov;Alexey Prutskiy;Semyon Sechenev;Dmitry Kazakov;Alexey Simulin;Dmitry Sokolov;Igor Ryadchikov",
        "authorids": "/37089000393;/37088996850;/37089000026;/37088998903;/37089000866;/37086174890;/37087405509;/37089000393;/37088996850;/37089000026;/37088998903;/37089000866;/37086174890;/37087405509",
        "aff": "Neurolab LTD, Moscow, Russia; Kuban State University, Krasnodar, Russia; Neurolab LTD, Moscow, Russia; Neurolab LTD, Moscow, Russia; Neurolab LTD, Moscow, Russia; Universit\u00e9 de Lorraine, CNRS, Inria, LORIA, Nancy, France; Kuban State University, Krasnodar, Russia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561214/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12075945584462898046&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;2;1",
        "aff_unique_norm": "Neurolab LTD;Kuban State University;Universit\u00e9 de Lorraine",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";http://www.kubsu.ru;https://www.univ-lorraine.fr",
        "aff_unique_abbr": ";;UL",
        "aff_campus_unique_index": "1;2;1",
        "aff_campus_unique": ";Krasnodar;Nancy",
        "aff_country_unique_index": "0;0;0;0;0;1;0",
        "aff_country_unique": "Russian Federation;France"
    },
    {
        "id": "9561016",
        "title": "H-ModQuad: Modular Multi-Rotors with 4, 5, and 6 Controllable DOF",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional aerial vehicles are usually custom-designed for specific tasks. Although they offer an efficient solution, they are not always able to adapt to changes in the task specification, e.g., increasing the payload. This applies to quadrotors, having a maximum payload and only four controllable degrees of freedom, limiting their adaptability to the task\u2019s variations. We propose a versatile modular robotic system that can increase its payload and degrees of freedom by assembling heterogeneous modules; we call it H-ModQuad. It consists of cuboid modules propelled by quadrotors with tilted propellers that can generate forces in different directions. By connecting different types of modules, an H-ModQuad can increase its controllable degrees of freedom from 4 to 5 and 6. We model the general structure and propose three controllers, one for each number of controllable degrees of freedom. We extend the concept of the actuation ellipsoid to find the best reference orientation that can maximize the performance of the structure. Our approach is validated with experiments using actual robots, showing the independence of the translation and orientation of a structure.",
        "primary_area": "",
        "author": "Jiawei Xu;Diego S. D\u2019Antonio;David Salda\u00f1a;Jiawei Xu;Diego S. D\u2019Antonio;David Salda\u00f1a",
        "authorids": "/37088996257;/37088760719;/38543033800;/37088996257;/37088760719;/38543033800",
        "aff": "Autonomous and Intelligent Robotics Laboratory (AIRLab), Lehigh University, PA, USA; Autonomous and Intelligent Robotics Laboratory (AIRLab), Lehigh University, PA, USA; Autonomous and Intelligent Robotics Laboratory (AIRLab), Lehigh University, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561016/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16405241231310067323&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Lehigh University",
        "aff_unique_dep": "Autonomous and Intelligent Robotics Laboratory (AIRLab)",
        "aff_unique_url": "https://www.lehigh.edu",
        "aff_unique_abbr": "Lehigh",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "PA",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561237",
        "title": "Handling Object Symmetries in CNN-based Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we investigate the problems that Convolutional Neural Networks (CNN)-based pose estimators have with symmetric objects. We considered the value of the CNN\u2019s output representation when continuously rotating the object and found that it has to form a closed loop after each step of symmetry. Otherwise, the CNN (which is itself a continuous function) has to replicate an uncontinuous function. On a 1-DOF toy example we show that commonly used representations do not fulfill this demand and analyze the problems caused thereby. In particular, we find that the popular min-over-symmetries approach for creating a symmetry-aware loss tends not to work well with gradient-based optimization, i.e. deep learning.We propose a representation called \"closed symmetry loop\" (csl) from these insights, where the angle of relevant vectors is multiplied by the symmetry order and then generalize it to 6-DOF. The representation extends our algorithm from [1] including a method to disambiguate symmetric equivalents during the final pose estimation. The algorithm handles continuous rotational symmetry (e.g. a bottle) and discrete rotational symmetry (e.g. a 4-fold symmetric box). It is evaluated on the T-LESS dataset, where it reaches state-of-the-art for unrefining RGB-based methods.",
        "primary_area": "",
        "author": "Jesse Richter-Klug;Udo Frese;Jesse Richter-Klug;Udo Frese",
        "authorids": "/37087322060;/37419163800;/37087322060;/37419163800",
        "aff": "Faculty of Mathematics and Computer Science, University of Bremen, Bremen, Germany; Faculty of Mathematics and Computer Science, University of Bremen, Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561237/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14787896355140615155&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bremen",
        "aff_unique_dep": "Faculty of Mathematics and Computer Science",
        "aff_unique_url": "https://www.uni-bremen.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9560991",
        "title": "Haptic Feedback Improves Human-Robot Agreement and User Satisfaction in Shared-Autonomy Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "Shared autonomy teleoperation can guarantee safety, but does so by reducing the human operator\u2019s control authority, which can lead to reduced levels of human-robot agreement and user satisfaction. This paper presents a novel haptic shared autonomy teleoperation paradigm that uses haptic feedback to inform the user about the inner state of a shared autonomy paradigm, while still guaranteeing safety. This differs from haptic shared control, which uses haptic feedback to inform the user\u2019s actions, but gives the human operator full control over the robot\u2019s actions. We conducted a user study in which twelve users flew a simulated UAV in a search-and-rescue task with no assistance or assistance provided by haptic shared control, shared autonomy, or haptic shared autonomy. All assistive teleoperation methods use control barrier functions to find a control command that is both safe and as close as possible to the human-generated control command. For assistive teleoperation conditions with haptic feedback, we apply a force to the user that is proportional to the difference between the human-generated control and the safe control. We find that haptic shared autonomy improves the user\u2019s task performance and satisfaction. We also find that haptic feedback in assistive teleoperation can improve the user\u2019s situational awareness. Finally, results show that adding haptic feedback to shared-autonomy teleoperation can improve human-robot agreement.",
        "primary_area": "",
        "author": "Dawei Zhang;Roberto Tron;Rebecca P. Khurshid;Dawei Zhang;Roberto Tron;Rebecca P. Khurshid",
        "authorids": "/37088335718;/37398528900;/37086187687;/37088335718;/37398528900;/37086187687",
        "aff": "Department of Mechanical Engineering, Boston University, Boston, MA, USA; Department of Mechanical Engineering, The Division of Systems Engineering, Boston University, Boston, MA, USA; Department of Mechanical Engineering, The Division of Systems Engineering, Boston University, Boston, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560991/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3594580172462833872&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Boston University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.bu.edu",
        "aff_unique_abbr": "BU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560839",
        "title": "Heart Position Estimation based on Bone Distribution toward Autonomous Robotic Fetal Ultrasonography",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous fetal ultrasonography with a robotic ultrasound (US) can potentially solve the issue of the shortage of ob-gyn physicians in prenatal care. In fetal cardiac diagnosis, acoustic shading derived from the fetal skeleton makes the scanning procedure using a robotic US cumbersome. We hypothesize that fetal bone distribution can be used for determining the fetal position and for subsequently estimating the heart position. This paper serves a method for estimating fetal heart position for autonomous cardiac diagnosis. Our proposed system is comprised of following three processes. First, the fetal bone distribution is generated by following steps: detect shadow areas derived from fetal bones; calculate the three-dimensional (3D) position of the bones; and identify bone types (skull, spine, and others) based on its shadow features. Next, the fetal head position and body axis are estimated based on the generated 3D bone distribution. Finally, the fetal chest position and thoracic sagittal axis of the fetus are estimated based on anatomical structures, and the position of the heart is determined. We validated the proposed method by evaluating the accuracies of bone detection and heart position estimation with three pregnant volunteers. The false positive rate of bone detection is less than 10%, which is sufficient for the proposed method; further, the estimation error for the heart position was within an acceptable error of 15 mm. These results demonstrate the sufficient accuracy of the proposed estimation method and suggest the potential of autonomous fetal cardiac diagnosis using robotic US scanning.",
        "primary_area": "",
        "author": "Yuuki Shida;Ryosuke Tsumura;Takabumi Watanabe;Hiroyasu Iwata;Yuuki Shida;Ryosuke Tsumura;Takabumi Watanabe;Hiroyasu Iwata",
        "authorids": "/37088592690;/37085879374;/37088591109;/37326645800;/37088592690;/37085879374;/37088591109;/37326645800",
        "aff": "Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Global Robot Academia Laboratory, Waseda University; Global Robot Academia Laboratory, Waseda University; Faculty of Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560839/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15455936439085026490&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Graduate School of Creative Science and Engineering",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561806",
        "title": "Hierarchical Cross-Modal Agent for Robotics Vision-and-Language Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Learning has revolutionized our ability to solve complex problems such as Vision-and-Language Navigation (VLN). This task requires the agent to navigate to a goal purely based on visual sensory inputs given natural language instructions. However, prior works formulate the problem as a navigation graph with a discrete action space. In this work, we lift the agent off the navigation graph and propose a more complex VLN setting in continuous 3D reconstructed environments. Our proposed setting, Robo-VLN, more closely mimics the challenges of real world navigation. Robo-VLN tasks have longer trajectory lengths, continuous action spaces, and challenges such as obstacles. We provide a suite of baselines inspired by state-of-the-art works in discrete VLN and show that they are less effective at this task. We further propose that decomposing the task into specialized high- and low-level policies can more effectively tackle this task. With extensive experiments, we show that by using layered decision making, modularized training, and decoupling reasoning and imitation, our proposed Hierarchical Cross-Modal (HCM) agent outperforms existing baselines in all key metrics and sets a new benchmark for Robo-VLN.",
        "primary_area": "",
        "author": "Muhammad Zubair Irshad;Chih-Yao Ma;Zsolt Kira;Muhammad Zubair Irshad;Chih-Yao Ma;Zsolt Kira",
        "authorids": "/37089000067;/37086576228;/37681676600;/37089000067;/37086576228;/37681676600",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561806/",
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=569287583696736789&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561408",
        "title": "Hierarchical Learning from Demonstrations for Long-Horizon Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Although reinforcement learning (RL) has achieved great success in robotic manipulation skills learning, it is still challenging for long-horizon tasks. Combining RL with demonstrations is an effective solution. In this paper, we propose a novel hierarchical learning from demonstrations method for long-horizon tasks, which leverages (i) object-centered segmentation of demonstrations to automatically segment the teaching trajectories into episodes. (ii) a bi-level hierarchical imitation learning method with a parallel training mechanism to train the two-level policies simultaneously. Experimental results on three challenging long-horizon tasks with sparse rewards show that our proposed method significantly outperforms state-of-art approaches in terms of both sample-efficiency and success rate. Moreover, our method is the only one which achieves satisfactory performance in tasks of multi-object stack and multi-object push&stack.",
        "primary_area": "",
        "author": "Boyao Li;Jiayi Li;Tao Lu;Yinghao Cai;Shuo Wang;Boyao Li;Jiayi Li;Tao Lu;Yinghao Cai;Shuo Wang",
        "authorids": "/37087008702;/37087244449;/37855750400;/37654083400;/37280458600;/37087008702;/37087244449;/37855750400;/37654083400;/37280458600",
        "aff": "Research and Development Department, China Academy of Launch Vehicle Technology, Beijing, China; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; State Key Laboratory for Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561408/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13531770290798062734&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "China Academy of Launch Vehicle Technology;Chinese Academy of Sciences",
        "aff_unique_dep": "Research and Development Department;Institute of Automation",
        "aff_unique_url": ";http://www.ia.cas.cn",
        "aff_unique_abbr": ";CAS",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Beijing;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561064",
        "title": "Hierarchical MCTS for Scalable Multi-Vessel Multi-Float Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Systems of multiple low-cost, underactuated floats combined with fully actuated surface vessels can improve the scalability and cost-effectiveness of autonomous systems for marine science and environmental monitoring. Here, we consider a coordination problem where surface vessels must drop off floats at locations such that they are likely to drift to observe given points of interest, and later must pick up the floats for redeployment. We define the Multi-Vessel Multi-Float (MVMF) problem and present a hierarchical solution based on the Dec-MCTS algorithm. Our solution defines customised sampling, rollout, and action generation algorithms to accommodate the problem\u2019s large search space and provide computational performance sufficient for practical application. We report analytical and simulation results that demonstrate the computational efficiency of our method and validate its behaviour in practical problems. These results immediately enable field experiments to progress the development of this exciting concept in multi-robot marine systems.",
        "primary_area": "",
        "author": "Giovanni D\u2019Urso;James Ju Heon Lee;Oscar Pizarro;Chanyeol Yoo;Robert Fitch;Giovanni D\u2019Urso;James Ju Heon Lee;Oscar Pizarro;Chanyeol Yoo;Robert Fitch",
        "authorids": "/37088997125;/37088505668;/37265974600;/37086933786;/38466367800;/37088997125;/37088505668;/37265974600;/37086933786;/38466367800",
        "aff": "University of Technology Sydney, NSW, Australia; University of Technology Sydney, NSW, Australia; Australian Centre for Field Robotics, University of Sydney, NSW, Australia; University of Technology Sydney, NSW, Australia; University of Technology Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561064/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15226095293048752607&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Technology Sydney;University of Sydney",
        "aff_unique_dep": ";Australian Centre for Field Robotics",
        "aff_unique_url": "https://www.uts.edu.au;https://www.sydney.edu.au",
        "aff_unique_abbr": "UTS;USYD",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Sydney",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9561225",
        "title": "Hierarchical Object Map Estimation for Efficient and Robust Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a hierarchical representation of objects, where the representation of each object is allowed to change based on the quality of accumulated measurements. We initially estimate each object as a 2D bounding box or a 3D point, encoding only the geometric properties that can be well-constrained using limited viewpoints. With additional measurements, we allow each object to become a higher dimensional 3D volumetric model for improved reconstruction accuracy and collision-testing. Our Hierarchical Object Map Estimation (HOME) is robust to deficiencies in viewpoints and allows planning safe and efficient trajectories around object obstacles using a monocular camera. We demonstrate the advantages of our approach on a real-world TUM dataset and during visual-inertial navigation of a quad-rotor in simulation.",
        "primary_area": "",
        "author": "Kyel Ok;Katherine Liu;Nicholas Roy;Kyel Ok;Katherine Liu;Nicholas Roy",
        "authorids": "/38469784900;/37086454373;/37274058700;/38469784900;/37086454373;/37274058700",
        "aff": "Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology (MIT), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561225/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13323486103487287577&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561548",
        "title": "Hierarchical Planning for Long-Horizon Manipulation with Geometric and Symbolic Scene Graphs",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a visually grounded hierarchical planning algorithm for long-horizon manipulation tasks. Our algorithm offers a joint framework of neuro-symbolic task planning and low-level motion generation conditioned on the specified goal. At the core of our approach is a two-level scene graph representation, namely geometric scene graph and symbolic scene graph. This hierarchical representation serves as a structured, object-centric abstraction of manipulation scenes. Our model uses graph neural networks to process these scene graphs for predicting high-level task plans and low-level motions. We demonstrate that our method scales to long-horizon tasks and generalizes well to novel task goals. We validate our method in a kitchen storage task in both physical simulation and the real world. Experiments show that our method achieves over 70% success rate and nearly 90% of subgoal completion rate on the real robot while being four orders of magnitude faster in computation time compared to standard search-based task-and-motion planner. 1",
        "primary_area": "",
        "author": "Yifeng Zhu;Jonathan Tremblay;Stan Birchfield;Yuke Zhu;Yifeng Zhu;Jonathan Tremblay;Stan Birchfield;Yuke Zhu",
        "authorids": "/37088690974;/37086455314;/37371627300;/37086080772;/37088690974;/37086455314;/37371627300;/37086080772",
        "aff": "The University of Texas, Austin; NVIDIA; NVIDIA; The University of Texas, Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561548/",
        "gs_citation": 138,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13679292037548359090&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Texas at Austin;NVIDIA",
        "aff_unique_dep": ";NVIDIA Corporation",
        "aff_unique_url": "https://www.utexas.edu;https://www.nvidia.com",
        "aff_unique_abbr": "UT Austin;NVIDIA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560828",
        "title": "Hierarchical and Flexible Traffic Management of Multi-AGV Systems Applied to Industrial Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with the traffic management of multiple Automated Guided Vehicles (AGVs) in an automatic factory or warehouse. We propose innovative methods, evolved from the studies previously conducted in [1], to coordinate a fleet of AGVs in an industrial environment, and we describe the methodologies developed to build a complete traffic manager software. The software is based on a multi-layer control architecture: a higher-level layer useful to model the traffic of vehicles among the different areas of the warehouse, a middle layer which acts as a bridge between the traffic model and the path planner, and a lower-level layer which represents the roadmap itself and, hence, defines the optimal path to be followed by each vehicle. Finally, the AGVs movement coordination is managed separately through a centralized control in order to avoid conflicts and deadlocks.The aim is to make theoretical methods applicable to a real environment facing the usual problems related to the industrial applications, which have been overlooked in [1]. Indeed, the roadmap is usually constrained by the plant layout, especially in medium size factories, and paths can not be arbitrarily defined. Hence, the aim is to realize a reliable and robust software able to manage real scenarios, allowing the traffic management of multiple AGVs. The proposed method aims at flexibility by considering a coordination strategy not based on assumptions and ad-hoc rules.",
        "primary_area": "",
        "author": "Federico Pratissoli;Nicola Battilani;Cesare Fantuzzi;Lorenzo Sabattini;Federico Pratissoli;Nicola Battilani;Cesare Fantuzzi;Lorenzo Sabattini",
        "authorids": "/37087091605;/37086301559;/37300904700;/37594737400;/37087091605;/37086301559;/37300904700;/37594737400",
        "aff": "Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy; Industria Tecnologica Italiana S.r.l (IT-I), Reggio Emilia, Italy; Industria Tecnologica Italiana S.r.l (IT-I), Reggio Emilia, Italy; Department of Sciences and Methods for Engineering (DISMI), University of Modena and Reggio Emilia, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560828/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7966943685155136083&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Modena and Reggio Emilia;Industria Tecnologica Italiana S.r.l",
        "aff_unique_dep": "Department of Sciences and Methods for Engineering (DISMI);",
        "aff_unique_url": "https://www.unimore.it;",
        "aff_unique_abbr": ";IT-I",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9561151",
        "title": "Hierarchies of Planning and Reinforcement Learning for Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Solving robotic navigation tasks via reinforcement learning (RL) is challenging due to their sparse reward and long decision horizon nature. However, in many navigation tasks, high-level (HL) task representations, like a rough floor plan, are available. Previous work has demonstrated efficient learning by hierarchal approaches consisting of path planning in the HL representation and using sub-goals derived from the plan to guide the RL policy in the source task. However, these approaches usually neglect the complex dynamics and sub-optimal sub-goal-reaching capabilities of the robot during planning. This work overcomes these limitations by proposing a novel hierarchical framework that utilizes a trainable planning policy for the HL representation. Thereby robot capabilities and environment conditions can be learned utilizing collected rollout data. We specifically introduce a planning policy based on value iteration with a learned transition model (VI-RL). In simulated robotic navigation tasks, VI-RL results in consistent strong improvement over vanilla RL, is on par with vanilla hierarchal RL on single layouts but more broadly applicable to multiple layouts, and is on par with trainable HL path planning baselines except for a parking task with difficult non-holonomic dynamics where it shows marked improvements.",
        "primary_area": "",
        "author": "Jan W\u00f6hlke;Felix Schmitt;Herke van Hoof;Jan W\u00f6hlke;Felix Schmitt;Herke van Hoof",
        "authorids": "/37088999363;/37085843481;/38541925500;/37088999363;/37085843481;/38541925500",
        "aff": "UvA-Bosch Delta Lab, University of Amsterdam, Amsterdam, Netherlands; Bosch Center for Artificial Intelligence, Renningen, Germany; UvA-Bosch Delta Lab, University of Amsterdam, Amsterdam, Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561151/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14279322346722262368&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Amsterdam;Bosch Center for Artificial Intelligence",
        "aff_unique_dep": "UvA-Bosch Delta Lab;Artificial Intelligence",
        "aff_unique_url": "https://www.uva.nl;https://www.bosch-ai.com",
        "aff_unique_abbr": "UvA;BCAI",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Amsterdam;Renningen",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Netherlands;Germany"
    },
    {
        "id": "9560990",
        "title": "High-Frequency Nonlinear Model Predictive Control of a Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Model Predictive Control (MPC) promises to endow robots with enough reactivity to perform complex tasks in dynamic environments by frequently updating their motion plan based on measurements. Despite its appeal, it has seldom been deployed on real machines because of scaling constraints. This paper presents the first hardware implementation of closed-loop nonlinear MPC on a 7-DoF torque-controlled robot. Our controller leverages a state-of-the art optimal control solver, namely Differential Dynamic Programming (DDP), in order to replan state and control trajectories at real-time rates (1kHz). In addition to this experimental proof of concept, an exhaustive performance analysis shows that our controller outperforms open-loop MPC on a rapid cyclic end-effector task. We also exhibit the importance of a sufficient preview horizon and full robot dynamics through comparisons with inverse dynamics and kinematic optimization.",
        "primary_area": "",
        "author": "Sebastien Kleff;Avadesh Meduri;Rohan Budhiraja;Nicolas Mansard;Ludovic Righetti;Sebastien Kleff;Avadesh Meduri;Rohan Budhiraja;Nicolas Mansard;Ludovic Righetti",
        "authorids": "/37086163635;/37088355351;/37086291965;/37542913400;/37295828600;/37086163635;/37088355351;/37086291965;/37542913400;/37295828600",
        "aff": "LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; Tandon School of Engineering, New York University, Brooklyn, NY; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; Artificial and Natural Intelligence Toulouse Institute, France; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560990/",
        "gs_citation": 93,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13234572812649199921&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;3",
        "aff_unique_norm": "LAAS-CNRS;New York University;Artificial and Natural Intelligence Toulouse Institute;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": ";Tandon School of Engineering;;",
        "aff_unique_url": "https://www.laas.fr/;https://www.nyu.edu;;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "LAAS-CNRS;NYU;ANITI;MPI-IS",
        "aff_campus_unique_index": "0;1;0;3",
        "aff_campus_unique": "Toulouse;Brooklyn;;T\u00fcbingen",
        "aff_country_unique_index": "0;1;0;0;2",
        "aff_country_unique": "France;United States;Germany"
    },
    {
        "id": "9560773",
        "title": "High-Speed Planning in Unknown Environments for Multirotors Considering Drag",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a new planning scheme for high-speed flight in an unknown environment while taking into account drag forces. Drag forces become non-negligible at high speeds and may lead to unfeasible trajectories. The method leverages a new Mixed-Integer Quadratic Program/Model Predictive Control formulation that allows to easily account for drag forces. This formulation makes use of a state-of-the-art Safe Corridors generator to guarantee safety. It uses state-of-the-art mapping algorithms and solvers to achieve a higher computational efficiency than similar state-of-the-art methods. To the best of our knowledge, our method is the first high-speed planner that generates safe trajectories while accounting for drag. The proposed method is tested in simulation and compared to similar state-of-the-art methods for planning in unknown environments in terms of quality and computation time.",
        "primary_area": "",
        "author": "Charbel Toumieh;Alain Lambert;Charbel Toumieh;Alain Lambert",
        "authorids": "/37089000208;/37282387200;/37089000208;/37282387200",
        "aff": "CNRS, Laboratoire de recherche en informatique, Universit\u00e9 Paris-Saclay, Orsay, France; CNRS, Laboratoire de recherche en informatique, Universit\u00e9 Paris-Saclay, Orsay, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560773/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1271494374019719108&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "CNRS",
        "aff_unique_dep": "Laboratoire de recherche en informatique",
        "aff_unique_url": "https://www.cnrs.fr",
        "aff_unique_abbr": "CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561034",
        "title": "High-Speed Robot Navigation using Predicted Occupancy Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "Safe and high-speed navigation is a key enabling capability for real world deployment of robotic systems. A significant limitation of existing approaches is the computational bottleneck associated with explicit mapping and the limited field of view (FOV) of existing sensor technologies. In this paper, we study algorithmic approaches that allow the robot to predict spaces extending beyond the sensor horizon for robust planning at high speeds. We accomplish this using a generative neural network trained from real-world data without requiring human annotated labels. Further, we extend our existing control algorithms to support leveraging the predicted spaces to improve collision-free planning and navigation at high speeds. Our experiments are conducted on a physical robot based on the MIT race car using an RGBD sensor where were able to demonstrate improved performance at 4 m/s compared to a controller not operating on predicted regions of the map.",
        "primary_area": "",
        "author": "Kapil D. Katyal;Adam Polevoy;Joseph Moore;Craig Knuth;Katie M. Popek;Kapil D. Katyal;Adam Polevoy;Joseph Moore;Craig Knuth;Katie M. Popek",
        "authorids": "/38228973900;/37088996357;/37086037338;/37088851710;/37077733500;/38228973900;/37088996357;/37086037338;/37088851710;/37077733500",
        "aff": "Dept. of Comp. Sci., Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University Applied Physics Lab, Laurel, MD, USA; Johns Hopkins University Applied Physics Lab, Laurel, MD, USA; Johns Hopkins University Applied Physics Lab, Laurel, MD, USA; Johns Hopkins University Applied Physics Lab, Laurel, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561034/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7724784900732151&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Baltimore;Laurel",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560931",
        "title": "Highly Efficient Line Segment Tracking with an IMU-KLT Prediction and a Convex Geometric Distance Minimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Line segment features become popular in SLAM community. Usually, line-based SLAM systems utilize local appearance descriptors for line segment tracking. However, traditional descriptor-based line segment tracking algorithms suffer from the problem that accuracy and speed cannot be possessed simultaneously, which affects the performance of line-based SLAM systems negatively. We propose a novel line segment tracking method with an IMU-KLT line segment prediction and a convex geometric distance minimization to boost line segment tracking performance in both accuracy and speed. Particularly, the proposed convex geometric distance minimization uses a \u21131-norm model to minimize geometric constraints between predicted line segments and extracted line segments efficiently. Furthermore, the line segment tracking is embedded into a VIO system and we adapt it to obtain more reliable point tracking. Experimental results on public datasets show that the proposed line segment tracking method achieves much higher accuracy and much less time cost than state-of-the-art level, where not only the number of correct matches increases but also the inlier ratios are increased by at least 35.1% along with a 3 times faster speed. Besides, the VIO system combining the proposed line segment tracking is improved in terms of accuracy.",
        "primary_area": "",
        "author": "Hao Wei;Fulin Tang;Chaofan Zhang;Yihong Wu;Hao Wei;Fulin Tang;Chaofan Zhang;Yihong Wu",
        "authorids": "/37086561611;/37086567542;/37086798273;/37337262300;/37086561611;/37086567542;/37086798273;/37337262300",
        "aff": "National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, Beijing, China; Anhui Institute of Optics and Fine Mechanics, Hefei Institutes of Physical Science, Chinese Academy of Sciences; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560931/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=174971098032664888&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Chinese Academy of Sciences;Anhui Institute of Optics and Fine Mechanics;University of Chinese Academy of Sciences",
        "aff_unique_dep": "Institute of Automation;Optics and Fine Mechanics;School of Artificial Intelligence",
        "aff_unique_url": "http://www.ia.cas.cn;http://www.aiofm.ac.cn;http://www.ucas.ac.cn",
        "aff_unique_abbr": "CAS;AIOFM;UCAS",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Beijing;Hefei",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561873",
        "title": "Highly Manoeuvrable Eversion Robot Based on Fusion of Function with Structure",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite their soft and compliant bodies, most of today\u2019s soft robots have limitations when it comes to elongation or extension of their main structure. In contrast to this, a new type of soft robot called the eversion robot can grow longitudinally, exploiting the principle of eversion. Eversion robots can squeeze through narrow openings, giving the possibility to access places that are inaccessible by conventional robots. The main drawback of these types of robots is their limited bending capability due to the tendency to move along a straight line. In this paper, we propose a novel way to fuse bending actuation with the robot\u2019s structure. We devise an eversion robot whose body forms both the central chamber that acts as the backbone as well as the actuators that cause bending and manoeuvre the manipulator. The proposed technique shows a significantly improved bending capability compared to externally attaching actuators to an eversion robot showing a 133% improvement in bending angle. Due to the increased manoeuvrability, the proposed solution is a step towards the employment of eversion robots in remote and difficult-to-access environments.",
        "primary_area": "",
        "author": "T. Abrar;F. Putzu;A. Ataka;H. Godaba;K. Althoefer;T. Abrar;F. Putzu;A. Ataka;H. Godaba;K. Althoefer",
        "authorids": "/37086477644;/37086478870;/37085781916;/37085735503;/37265264700;/37086477644;/37086478870;/37085781916;/37085735503;/37265264700",
        "aff": "Centre for Advanced Robotics @ Queen Mary (ARQ), Queen Mary University of London, London, United Kingdom; Centre for Advanced Robotics @ Queen Mary (ARQ), Queen Mary University of London, London, United Kingdom; Department of Electrical Engineering and Information Technology, Gadjah Mada University, Indonesia; Centre for Advanced Robotics @ Queen Mary (ARQ), Queen Mary University of London, London, United Kingdom; Centre for Advanced Robotics @ Queen Mary (ARQ), Queen Mary University of London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561873/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12393234701440001124&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Queen Mary University of London;Gadjah Mada University",
        "aff_unique_dep": "Centre for Advanced Robotics;Department of Electrical Engineering and Information Technology",
        "aff_unique_url": "https://www.qmul.ac.uk;https://ugm.ac.id",
        "aff_unique_abbr": "QMUL;UGM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United Kingdom;Indonesia"
    },
    {
        "id": "9561862",
        "title": "Homotopy-Driven Exploration of Human-made Spaces Using Signs",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots deployed in airports, malls, and stadiums today require expert oversight, pre-provided maps, and infrastructure. These systems are engineered to their specific deployment spaces and rely heavily on geometric maps for motion planning. In this work we consider a robot with only local-sensing and present a navigation strategy that uses signs and homotopy classes to fuel planning. We prove that in the worst-case, this strategy still maintains the probabilistic completeness that sampling based motion planners provide. Furthermore, we experimentally show that this exploration strategy results in 100% goal completion in real airport floor plans, and demonstrate how the robot\u2019s sensing capabilities affects efficiency. We also show the effect of the environment variables, such as total number of obstacles, and density of obstacles, on navigation.",
        "primary_area": "",
        "author": "Claire Liang;Hadas Kress-Gazit;Claire Liang;Hadas Kress-Gazit",
        "authorids": "/37086513789;/38307602100;/37086513789;/38307602100",
        "aff": "The Department of Computer Science, Cornell University, Ithaca, NY, USA; The Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561862/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15866522946671391266&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Cornell University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.cornell.edu",
        "aff_unique_abbr": "Cornell",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ithaca",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561243",
        "title": "How People Use Active Telepresence Cameras in Tele-manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot teleoperation is a reliable way to perform a variety of tasks with complex robotic systems. However, the remote control of active telepresence cameras on the robot for improved telepresence adds an additional degree of complexity while teleoperating and can thus affect the operator\u2019s performance during tele-manipulation. Our previous user study investigates the general human performance and preference when using various wearable cameras. In this paper, we further investigate how humans respond to the usage of telepresence cameras in terms of motion behavior. The findings from our human motion analysis inform several desired designs for robot teleoperation interfaces and assistive autonomy.",
        "primary_area": "",
        "author": "Tsung-Chi Lin;Achyuthan Unni Krishnan;Zhi Li;Tsung-Chi Lin;Achyuthan Unni Krishnan;Zhi Li",
        "authorids": "/37087325287;/37087323052;/37085821311;/37087325287;/37087323052;/37085821311",
        "aff": "Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561243/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4797785908185559472&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Robotics Engineering",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561783",
        "title": "HueCode: A Meta-marker Exposing Relative Pose and Additional Information in Different Colored Layers",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, HueCode, a meta-marker that robustly and simultaneously exposes the relative pose between a marker and a camera along with additional information, is proposed. It occupies the area of a single marker by overlaying multiple types of markers in different colored layers. Using perspective information from the first (most recognizable) type of element marker, the second or higher marker can be recognized with a better success rate. An experiment using a HueCode made from an ArUco marker and a QR code showed that the QR code within the HueCode is recognizable at an elevation angle of up to 15\u00b0, compared to 25\u00b0 for a normal QR code. In addition, the versatility of HueCode is demonstrated using two robotic applications. The first is a lightweight estimation of absolute 6-DoF poses for mobile robots in a GNSS-denied environment, and the other is object annotation in two-dimensional image or three-dimensional space without any prior knowledge. The former realized pose estimation with a position error of less than 0.05 m, and the latter enabled annotation of a mirror and a transparent object, which are difficult for other sensors and machine learning to recognize.",
        "primary_area": "",
        "author": "Yoshito Okada;Daiki Fujikura;Yu Ozawa;Kenjiro Tadakuma;Kazunori Ohno;Satoshi Tadokoro;Yoshito Okada;Daiki Fujikura;Yu Ozawa;Kenjiro Tadakuma;Kazunori Ohno;Satoshi Tadokoro",
        "authorids": "/37402546000;/37088687774;/37088441287;/38534909200;/37285220400;/37296054300;/37402546000;/37088687774;/37088441287;/38534909200;/37285220400;/37296054300",
        "aff": "RIKEN Center for Advanced Intelligence Project, Tokyo, Japan; Tohoku University, Sendai, Japan; Tohoku University, Sendai, Japan; Tohoku University, Sendai, Japan; RIKEN Center for Advanced Intelligence Project, Tokyo, Japan; Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561783/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6909551502960290099&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;0;1",
        "aff_unique_norm": "RIKEN Center for Advanced Intelligence Project;Tohoku University",
        "aff_unique_dep": "Center for Advanced Intelligence Project;",
        "aff_unique_url": "https://www.riken.jp/en/c-aip/;https://www.tohoku.ac.jp",
        "aff_unique_abbr": "RIKEN C-AIP;Tohoku U",
        "aff_campus_unique_index": "0;1;1;1;0;1",
        "aff_campus_unique": "Tokyo;Sendai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561794",
        "title": "Human Arm Stability in Relation to Damping-Defined Mechanical Environments in Physical Interaction with a Robotic Arm",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an experimental study that investigated how humans interact with viscous, damping-defined mechanical environments and quantified the lower bounds of robotic damping that they can stably interact with. Human subjects performed posture maintenance tasks for different arm postures while holding a robotic arm manipulator simulating unstable (negative) damping-defined environments and applying rapid perturbations to disturb the arm posture and challenge arm stability. The results of this study demonstrated that the lower bound of robotic damping for stable physical human-robot interaction was more than twice as low in the anterior-posterior (AP) direction than the medial-lateral (ML) direction, with lower limits of -50.3 Ns/m and -21.6 Ns/m in the AP and ML directions, respectively. The results further showed that the human arm is less capable of adjusting to the unstable environments when it is close to the body and laterally displaced for the AP and ML directions, respectively. Secondary analysis on the kinematic response in the phase space also demonstrated that arm stability in the unstable environments can be more easily achieved in the AP than ML direction. The outcomes of this study can be used to design less conservative robotic impedance or admittance controllers that utilize a wider range of robotic damping up to a certain extent of negative damping but do not compromise coupled stability of the human-robot system, which could improve the overall performance in physical human-robot interaction by achieving more agile operations and reducing user effort.",
        "primary_area": "",
        "author": "Fatemeh Zahedi;Hyunglae Lee;Fatemeh Zahedi;Hyunglae Lee",
        "authorids": "/37088505564;/37085768762;/37088505564;/37085768762",
        "aff": "School for Engineering of Matter, Transport, and Energy, Arizona State University, Tempe, AZ, USA; School for Engineering of Matter, Transport, and Energy, Arizona State University, Tempe, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561794/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7492648113061631380&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School for Engineering of Matter, Transport, and Energy",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561669",
        "title": "Human Driven Compliant Transmission Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "Energetically-passive robot exoskeletons, mimicking the function of the bicycle, could enable humans to reach previously unprecedented mobility. However, energetically-passive robot exoskeletons require a sophisticated mechanism to enable the human to supply energy, similar to what is enabled by the variable gear transmission mechanism of the bicycle. In this work, we present a new type of human-driven compliant transmission mechanism that could enable humans to supply energy when the leg is in the air, store the supplied energy, and release the stored energy when the leg is on the ground, in order to amplify the leg force and power. The compliant transmission mechanism presented in this paper is the first prototype and key component of a future human-driven artificial limb that aims to augment human mobility without using external energy.",
        "primary_area": "",
        "author": "Tiange Zhang;David J. Braun;Tiange Zhang;David J. Braun",
        "authorids": "/37088504178;/37609773600;/37088504178;/37609773600",
        "aff": "Department of Mechanical Engineering, Advanced Robotics and Control Laboratory within the Center for Rehabilitation Engineering and Assistive Technology, Vanderbilt University, Nashville, Tennessee, USA; Department of Mechanical Engineering, Advanced Robotics and Control Laboratory within the Center for Rehabilitation Engineering and Assistive Technology, Vanderbilt University, Nashville, Tennessee, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561669/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3984210012184377403&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Vanderbilt University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.vanderbilt.edu",
        "aff_unique_abbr": "Vanderbilt",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nashville",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561765",
        "title": "Human Initiated Grasp Space Exploration Algorithm for an Underactuated Robot Gripper Using Variational Autoencoder",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasp planning and most specifically the grasp space exploration is still an open issue in robotics. This article presents an efficient procedure for exploring the grasp space of a multifingered adaptive gripper for generating reliable grasps given a known object pose. This procedure relies on a limited dataset of manually specified expert grasps, and use a mixed analytic and data-driven approach based on the use of a grasp quality metric and variational autoencoders. The performances of this method are assessed by generating grasps in simulation for three different objects. On this grasp planning task, this method reaches a grasp success rate of 99.91% on 7000 trials.",
        "primary_area": "",
        "author": "Cl\u00e9ment Rolinat;Mathieu Grossard;Saifeddine Aloui;Christelle Godin;Cl\u00e9ment Rolinat;Mathieu Grossard;Saifeddine Aloui;Christelle Godin",
        "authorids": "/37088996210;/37831627500;/37903731300;/37392221500;/37088996210;/37831627500;/37903731300;/37392221500",
        "aff": "CEA, List, Universit\u00e9 Paris-Saclay, Palaiseau, France; CEA, List, Universit\u00e9 Paris-Saclay, Palaiseau, France; CEA, Leti, Universit\u00e9 Grenoble Alpes, Grenoble, France; CEA, Leti, Universit\u00e9 Grenoble Alpes, Grenoble, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561765/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16746667732428414405&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "CEA;Universit\u00e9 Grenoble Alpes",
        "aff_unique_dep": "List;CEA, Leti",
        "aff_unique_url": "https://www.cea.fr;https://www.univ-grenoble-alpes.fr",
        "aff_unique_abbr": "CEA;UGA",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Palaiseau;Grenoble",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561152",
        "title": "Human-Like Artificial Skin Sensor for Physical Human-Robot Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "Physical Human-Robot-Interaction (pHRI) is beneficial for communication in social interaction or to perform collaborative tasks but is also crucial for safety. While robotic devices embed sensors for this sole purpose, their design often is the results of a trade-off between technical capabilities and rarely considers human factors. We propose a novel approach to design and fabricate compliant Human-like artificial skin sensors for robots, with similar mechanical properties as human skin and capable of precisely detecting touch. Our artificial skin relies on the use of different silicone elastomers to replicate the human skin layers and comprises an embedded electrode matrix to perform mutual capacitance sensing. We present the sensor and describe its fabrication process which is scalable, low-cost and ensures flexibility, compliance and robustness. We introduce Muca, an open-source sensing development board and then evaluate the performance of the sensor.",
        "primary_area": "",
        "author": "Marc Teyssier;Brice Parilusyan;Anne Roudaut;J\u00fcrgen Steimle;Marc Teyssier;Brice Parilusyan;Anne Roudaut;J\u00fcrgen Steimle",
        "authorids": "/37089001539;/37088995849;/37085810090;/37546734300;/37089001539;/37088995849;/37085810090;/37546734300",
        "aff": "Research Center, P\u00f4le Universitaire L\u00e9onard de Vinci, France; Research Center, P\u00f4le Universitaire L\u00e9onard de Vinci, France; Bristol Interaction Group, University of Bristol, UK; Saarland Informatics Campus, Saarland University, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561152/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15278971429847897770&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "P\u00f4le Universitaire L\u00e9onard de Vinci;University of Bristol;Saarland University",
        "aff_unique_dep": "Research Center;Bristol Interaction Group;",
        "aff_unique_url": ";https://www.bristol.ac.uk;https://www.uni-saarland.de",
        "aff_unique_abbr": ";UoB;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Saarland Informatics Campus",
        "aff_country_unique_index": "0;0;1;2",
        "aff_country_unique": "France;United Kingdom;Germany"
    },
    {
        "id": "9560995",
        "title": "Human-Robot Collaborative Multi-Agent Path Planning using Monte Carlo Tree Search and Social Reward Sources",
        "track": "main",
        "status": "Poster",
        "abstract": "The collaboration between humans and robots in an object search task requires the achievement of shared plans obtained from communicating and negotiating. In this work, we assume that the robot computes, as a first step, a multi-agent plan for both itself and the human. Then, both plans are submitted to human scrutiny, who either agrees or modifies it forcing the robot to adapt its own restrictions or preferences. This process is repeated along the search task as many times as required by the human. Our planner is based on a decentralized variant of Monte Carlo Tree Search (MCTS), with one robot and one human as agents. Moreover, our algorithm allows the robot and the human to optimize their own actions by maintaining a probability distribution over the plans in a joint-action space. The method allows an objective function definition over action sequences, it assumes intermittent communication, it is anytime and suitable for on-line replanning. To test it, we have developed a human-robot communication mobile phone interface. Validation is provided by real-life search experiments of a Parcheesi token in an urban space, including also an acceptability study.",
        "primary_area": "",
        "author": "Marc Dalmasso;Ana\u00eds Garrell;Jos\u00e9 Enrique Dom\u00ednguez;Pablo Jim\u00e9nez;Alberto Sanfeliu;Marc Dalmasso;Ana\u00eds Garrell;Jos\u00e9 Enrique Dom\u00ednguez;Pablo Jim\u00e9nez;Alberto Sanfeliu",
        "authorids": "/37088998290;/37586306600;/37088996776;/37883257700;/37270957300;/37088998290;/37586306600;/37088996776;/37883257700;/37270957300",
        "aff": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (CSIC-UPC), Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (CSIC-UPC), Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (CSIC-UPC), Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (CSIC-UPC), Barcelona, Spain; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial (CSIC-UPC), Barcelona, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560995/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=855833151638958506&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Institut de Rob\u00f2tica i Inform\u00e0tica Industrial",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.iri.upc.edu",
        "aff_unique_abbr": "IRI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Barcelona",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9562035",
        "title": "Human-robot collaborative object transfer using human motion prediction based on Cartesian pose Dynamic Movement Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, the problem of human-robot collaborative object transfer to unknown target poses is addressed. The desired pattern of the end-effector pose trajectory to a known target pose is encoded using DMPs (Dynamic Movement Primitives). During transportation of the object to new unknown targets, a DMP-based reference model and an EKF (Extended Kalman Filter) for estimating the target pose and time duration of the human's intended motion is proposed. A stability analysis of the overall scheme is provided. Experiments using a Kuka LWR4+ robot equipped with an ATI sensor at its end-effector validate its efficacy with respect to the required human effort and compare it with an admittance control scheme.",
        "primary_area": "",
        "author": "Antonis Sidiropoulos;Yiannis Karayiannidis;Zoe Doulgeri;Antonis Sidiropoulos;Yiannis Karayiannidis;Zoe Doulgeri",
        "authorids": "/37089372642;/37300987100;/37274011500;/37089372642;/37300987100;/37274011500",
        "aff": "Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece; Department of Electrical Engineering, Chalmers University of Technology, G\u00f6teborg, Sweeden; Department of Electrical and Computer Engineering, Aristotle University of Thessaloniki, Thessaloniki, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562035/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11428186791809225936&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Aristotle University of Thessaloniki;Chalmers University of Technology",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Electrical Engineering",
        "aff_unique_url": "http://www.auth.gr;https://www.chalmers.se",
        "aff_unique_abbr": "AUTH;Chalmers",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Thessaloniki;G\u00f6teborg",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Greece;Sweden"
    },
    {
        "id": "9560900",
        "title": "Hybrid Bird\u2019s-Eye Edge Based Semantic Visual SLAM for Automated Valet Parking",
        "track": "main",
        "status": "Poster",
        "abstract": "Vision-based localization and mapping solution is promising to be adopted in the automated valet parking task. In this paper, a semantic SLAM framework that leverages the hybrid edge information on bird\u2019s-eye view images is presented. To extract useful edges from the synthesized bird\u2019s-eye view image and the free-space contours for the SLAM task, different segmentation methods are designed to remove the noisy glare edges and distorted object edges caused by the inverse perspective mapping in view synthesis. Since only the free-space segmentation model needs training, our methods can dramatically reduce the labeling burden compared with previous road marking based methods. Those incorrect and incomplete edges are further cleaned and recovered by a temporal fusion of consecutive edges in a local map, respectively. Both a semantic edge point cloud map and an occupancy grid map can be built simultaneously in real time. Experiments in a parking garage demonstrate that the proposed framework can achieve higher accuracy and perform more robustly than previous point feature based methods.",
        "primary_area": "",
        "author": "Zhenzhen Xiang;Anbo Bao;Jianbo Su;Zhenzhen Xiang;Anbo Bao;Jianbo Su",
        "authorids": "/37085750570;/37087246205;/37281319700;/37085750570;/37087246205;/37281319700",
        "aff": "Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560900/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10901915327892358738&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561000",
        "title": "Hybrid Model Control of WalkON Suit for Precise and Robust Gait Assistance of Paraplegics",
        "track": "main",
        "status": "Poster",
        "abstract": "Powered exoskeletons for people with paraplegia have been widely developed. To generate the basic but essential motions for daily human life, precise control algorithms to follow the joint reference trajectories are necessary. The dynamic characteristics of the exoskeletal joints, however, varies signifi-cantly during walking because the load side is exchanged from legs in the air to the wearer\u2019s body. To ensure robustness and tracking performance for any case of gait even in the presence of exogenous disturbances such as human\u2019s active movements and repeated ground contacts, customized robust control algorithms need to be developed. In this paper, therefore, hybrid model control of the powered exoskeleton, WalklON Suit, utilized with the disturbance observer is introduced. A hybrid nominal model, whose model parameters are interchanged between the gait phases, i.e., swing and stance, is developed by the parameter adatpation algorithm. By the proposed method, the disturbance observer can fully reject the exogenous disturbance during walking and achieve high-performance gait assistance to the people with complete paraplegia. In this paper, the experimental verification of the designed model and the controller with the WalkON Suit, are also introduced.",
        "primary_area": "",
        "author": "Kyeong-Won Park;Jungsu Choi;Kyoungchul Kong;Kyeong-Won Park;Jungsu Choi;Kyoungchul Kong",
        "authorids": "/37088687129;/37085898280;/37410344000;/37088687129;/37085898280;/37410344000",
        "aff": "Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Korea; Department of Robotics Engineering, Yeungnam University, Gyeongsan, Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561000/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1003434312777743525&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;Yeungnam University",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Robotics Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr;http://www.yu.ac.kr",
        "aff_unique_abbr": "KAIST;YU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Daejeon;Gyeongsan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561939",
        "title": "Hybrid Sampling/Optimization-based Planning for Agile Jumping Robots on Challenging Terrains",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a hybrid planning framework that generates complex dynamic motion plans for jumping legged robots to traverse challenging terrains. By employing a motion primitive, the original problem is decoupled as path planning followed by a trajectory optimization (TO) module that handles dynamics. A variant of a kinodynamic Rapidly-exploring Random Trees (RRT) planner finds a path as a parabola sequence between stance phases. To make this fast, a reachability informed control sampling scheme leverages a precomputed velocity reachability map. The path is post-processed to eliminate redundant jumps and passed to the TO module to find a dynamically feasible trajectory. Simulation results are presented where the proposed hybrid planner solves challenging terrains by executing multiple consecutive jumps, producing novel strategies to leap over large gaps by leveraging dynamics. In a physical experiment, the hybrid planner is tested on a real robot successfully traversing a challenging terrain.",
        "primary_area": "",
        "author": "Yanran Ding;Mengchao Zhang;Chuanzheng Li;Hae-Won Park;Kris Hauser;Yanran Ding;Mengchao Zhang;Chuanzheng Li;Hae-Won Park;Kris Hauser",
        "authorids": "/37086268690;/37089001334;/37086575086;/37086265865;/37543748800;/37086268690;/37089001334;/37086575086;/37086265865;/37543748800",
        "aff": "Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, IL, USA; Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, IL, USA; Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, IL, USA; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, South Korea; Department of Computer Science, University of Illinois at Urbana-Champaign, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561939/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9722992609341925617&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Science and Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://illinois.edu;https://www.kaist.ac.kr",
        "aff_unique_abbr": "UIUC;KAIST",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Urbana-Champaign;Daejeon",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "9561039",
        "title": "Hybrid Vision/Force Control for Interaction with the Bottle-like Object",
        "track": "main",
        "status": "Poster",
        "abstract": "This study proposes a hybrid vision/force control scheme for interaction with the inner surface of the bottle-like object. Based on the geometry of the object, a new generalized constraint called the bottleneck (BN) constraint is proposed, which ensures the tool passes through a fixed 3-D region and avoid collisions with the boundary of the region. To realize the hybrid vision/force control under the BN constraint, a novel dynamic controller is designed inspired by the hierarchical operational space, which can complete the different tasks defined in the decoupled subspace. To enhance the robustness of the algorithm, we develop a data-driven method and an adaptive method to estimate the Jacobian matrix online in force space and image space, respectively. The asymptotic stability of the closed-loop system is rigorously proved by the Lyapunov theory. Experiments are conducted to validate the performance of the proposed method.",
        "primary_area": "",
        "author": "Lijun Han;Hesheng Wang;Weidong Chen;Jingchuan Wang;Jianjun Yuan;Lijun Han;Hesheng Wang;Weidong Chen;Jingchuan Wang;Jianjun Yuan",
        "authorids": "/37086833462;/37292567100;/37279187800;/37539010600;/37293594200;/37086833462;/37292567100;/37279187800;/37539010600;/37293594200",
        "aff": "Department of Automation, Insititue of Medical Robotics, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Insititue of Medical Robotics, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Insititue of Medical Robotics, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Shanghai, China; Department of Automation, Insititue of Medical Robotics, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Shanghai, China; Shanghai Robotics Institute, School of Mechatronic Engineering and Automation, Shanghai University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561039/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11278639264133369565&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Shanghai Jiao Tong University;Shanghai University",
        "aff_unique_dep": "Department of Automation;School of Mechatronic Engineering and Automation",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.shu.edu.cn",
        "aff_unique_abbr": "SJTU;SHU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561864",
        "title": "HyperMap: Compressed 3D Map for Monocular Camera Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of image registration to a compressed 3D map. While this is most often performed by comparing LiDAR scans to the point cloud based map, it depends on an expensive LiDAR sensor at run time and the large point cloud based map creates overhead in data storage and transmission. Recently, efforts have been underway to replace the expensive LiDAR sensor with cheaper cameras and perform 2D-3D localization. In contrast to the previous work that learns relative pose by comparing projected depth and camera images, we propose HyperMap, a paradigm shift from online depth map feature extraction to offline 3D map feature computation for the 2D-3D camera registration task through end-to-end training. In the proposed pipeline, we first perform offline 3D sparse convolution to extract and compress the voxelwise hypercolumn features for the whole map. Then at run-time, we project and decode the compressed map features to the rough initial camera pose to form a virtual feature image. A Convolutional Neural Network (CNN) is then used to predict the relative pose between the camera image and the virtual feature image. In addition, we propose an efficient occlusion handling layer, specifically designed for large point clouds, to remove occluded points in projection. Our experiments on synthetic and real datasets show that, by moving the feature computation load offline and compressing, we reduced map size by 87\u221294% while maintaining comparable or better accuracy.",
        "primary_area": "",
        "author": "Ming-Fang Chang;Joshua Mangelson;Michael Kaess;Simon Lucey;Ming-Fang Chang;Joshua Mangelson;Michael Kaess;Simon Lucey",
        "authorids": "/37086391653;/37086109836;/37324200400;/37266130100;/37086391653;/37086109836;/37324200400;/37266130100",
        "aff": "Carnegie Mellon University; Brigham Young University; Carnegie Mellon University; Australian Institute of Machine Learning (AIML) at the The University of Adelaide",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561864/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2110167833956967803&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Carnegie Mellon University;Brigham Young University;University of Adelaide",
        "aff_unique_dep": ";;Australian Institute of Machine Learning",
        "aff_unique_url": "https://www.cmu.edu;https://www.byu.edu;https://www.adelaide.edu.au",
        "aff_unique_abbr": "CMU;BYU;Adelaide",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;Australia"
    },
    {
        "id": "9561451",
        "title": "Hypergame-based Adaptive Behavior Path Planning for Combined Exploration and Visual Search",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we present an adaptive behavior path planning method for autonomous exploration and visual search of unknown environments. As volumetric exploration and visual coverage of unknown environments, with possibly different sensors, are non-identical objectives, a principled combination of the two is proposed. In particular, the method involves three distinct planning policies, namely exploration, and sparse or dense visual coverage. A hypergame formulation is proposed which allows the robot to select for the next-best planning behavior in response to the currently encountered environment challenges in terms of geometry and visual conditions, alongside a self-assessment of its performance. The proposed planner is evaluated in a collection of experimental and simulation studies in diverse environments, while comparative results against a state-of-the-art exploration method are also presented.",
        "primary_area": "",
        "author": "Mihir Dharmadhikari;Harshal Deshpande;Tung Dang;Kostas Alexis;Mihir Dharmadhikari;Harshal Deshpande;Tung Dang;Kostas Alexis",
        "authorids": "/37088504973;/37088998482;/37086410051;/37546514600;/37088504973;/37088998482;/37086410051;/37546514600",
        "aff": "University of Nevada, Reno, NV, USA; BITS-Pilani Goa Campus, India; University of Nevada, Reno, NV, USA; NTNU, Trondheim, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561451/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2615201267401878616&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "University of Nevada, Reno;Birla Institute of Technology and Science, Pilani;Norwegian University of Science and Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.unr.edu;https://www.bits-pilani.ac.in/goa/;https://www.ntnu.no",
        "aff_unique_abbr": "UNR;BITS Pilani;NTNU",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Reno;Goa;Trondheim",
        "aff_country_unique_index": "0;1;0;2",
        "aff_country_unique": "United States;India;Norway"
    },
    {
        "id": "9562048",
        "title": "I Know What You Meant: Learning Human Objectives by (Under)estimating Their Choice Set",
        "track": "main",
        "status": "Poster",
        "abstract": "Assistive robots have the potential to help people perform everyday tasks. However, these robots first need to learn what it is their user wants them to do. Teaching assistive robots is hard for inexperienced users, elderly users, and users living with physical disabilities, since often these individuals are unable to show the robot their desired behavior. We know that inclusive learners should give human teachers credit for what they cannot demonstrate. But today\u2019s robots do the opposite: they assume every user is capable of providing any demonstration. As a result, these robots learn to mimic the demonstrated behavior, even when that behavior is not what the human really meant! Here we propose a different approach to reward learning: robots that reason about the user\u2019s demonstrations in the context of similar or simpler alternatives. Unlike prior works \u2014 which err towards overestimating the human\u2019s capabilities \u2014 here we err towards underestimating what the human can input (i.e., their choice set). Our theoretical analysis proves that underestimating the human\u2019s choice set is riskaverse, with better worst-case performance than overestimating. We formalize three properties to generate similar and simpler alternatives. Across simulations and a user study, our resulting algorithm better extrapolates the human\u2019s objective. See the user study here: https://youtu.be/RgbH2YULVRo.",
        "primary_area": "",
        "author": "Ananth Jonnavittula;Dylan P. Losey;Ananth Jonnavittula;Dylan P. Losey",
        "authorids": "/37088998510;/37085812055;/37088998510;/37085812055",
        "aff": "Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA; Dept. of Mechanical Engineering, Collaborative Robotics Lab (Collab), Virginia Tech, Blacksburg, VA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562048/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1952047072389798597&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Virginia Tech",
        "aff_unique_dep": "Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.vt.edu",
        "aff_unique_abbr": "VT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Blacksburg",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560986",
        "title": "IKEA Furniture Assembly Environment for Long-Horizon Complex Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "The IKEA Furniture Assembly Environment is one of the first benchmarks for testing and accelerating the automation of long-horizon and hierarchical manipulation tasks. The environment is designed to advance reinforcement learning and imitation learning from simple toy tasks to complex tasks requiring both long-term planning and sophisticated low-level control. Our environment features 60 furniture models, 6 robots, photorealistic rendering, and domain randomization. We evaluate reinforcement learning and imitation learning methods on the proposed environment. Our experiments show furniture assembly is a challenging task due to its long horizon and sophisticated manipulation requirements, which provides ample opportunities for future research. The environment is publicly available at https://clvrai.com/furniture.",
        "primary_area": "",
        "author": "Youngwoon Lee;Edward S. Hu;Joseph J. Lim;Youngwoon Lee;Edward S. Hu;Joseph J. Lim",
        "authorids": "/37089001511;/37089001937;/37534868000;/37089001511;/37089001937;/37534868000",
        "aff": "Department of Computer Science, University of Southern California, Los Angeles, CA; Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA; Department of Computer Science, University of Southern California, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560986/",
        "gs_citation": 159,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11101289858173394771&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Southern California;University of Pennsylvania",
        "aff_unique_dep": "Department of Computer Science;Department of Computer and Information Science",
        "aff_unique_url": "https://www.usc.edu;https://www.upenn.edu",
        "aff_unique_abbr": "USC;UPenn",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Los Angeles;Philadelphia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561172",
        "title": "IMU Data Processing For Inertial Aided Navigation: A Recurrent Neural Network Based Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a novel method for performing inertial aided navigation, by using deep neural net-works (DNNs). To date, most DNN inertial navigation methods focus on the task of inertial odometry, by taking gyroscope and accelerometer readings as input and regressing for integrated IMU poses (i.e., position and orientation). While this design has been successfully applied on a number of applications, it is not of theoretical performance guarantee unless patterned motion is involved. This inevitably leads to significantly reduced accuracy and robustness in certain use cases. To solve this problem, we design a framework to compute observable IMU integration terms using DNNs, followed by the numerical pose integration and sensor fusion to achieve the performance gain. Specifically, we perform detailed analysis on the motion terms in IMU kinematic equations, propose a dedicated network design, loss functions, and training strategies for the IMU data processing, and conduct extensive experiments. The results show that our method is generally applicable and outperforms both traditional and DNN methods by wide margins.",
        "primary_area": "",
        "author": "Ming Zhang;Mingming Zhang;Yiming Chen;Mingyang Li;Ming Zhang;Mingming Zhang;Yiming Chen;Mingyang Li",
        "authorids": "/37087473541;/37087325241;/37900421300;/37086936897;/37087473541;/37087325241;/37900421300;/37086936897",
        "aff": "Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China; Alibaba Group, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561172/",
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10018370188726456906&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Alibaba Group",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.alibaba.com",
        "aff_unique_abbr": "Alibaba",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560767",
        "title": "IMU/Vehicle Calibration and Integrated Localization for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "The localization system, which outputs vehicle position, velocity, and attitude, is one of the fundamental components in the autonomous driving vehicle. The global pose is not only used for the planning and control system, but also an important reference for the cloud source-based HD Map building and updating. The accuracy, availability, and reliability are key requirements for the localization system to ensure that the whole system runs smoothly and efficiently.IMU/Vehicle extrinsic calibration is one of the primary jobs that should be addressed. Due to the observability issue, the IMU/vehicle relative roll cannot be calibrated by the traditional maneuver-based calibration method. In this paper, we solve this issue with the proposed Multiple Orientation-based Vehicle/IMU Extrinsic Calibration (MOVIE-Cali) method, which is evaluated by Monte Carlo simulations and experiments.When the vehicle is cornering or making a U-turn, the sideslip of the tires will have negative influence on the localization system which uses Non-Holonomic Constraints (NHC)/Wheel speed sensor measurement in the model. We derive a sideslip angle model and propose an online slip parameter calibration and compensation method to improve the localization accuracy. The performance of proposed method has been evaluated by the vehicle tests.",
        "primary_area": "",
        "author": "Zhenbo Liu;Leijie Wang;Feng Wen;Hongbo Zhang;Zhenbo Liu;Leijie Wang;Feng Wen;Hongbo Zhang",
        "authorids": "/37086550922;/37089001583;/37088690190;/37089733800;/37086550922;/37089001583;/37088690190;/37089733800",
        "aff": "Noah\u2019s Ark Lab, Huawei, Beijing, China; Noah\u2019s Ark Lab, Huawei, Beijing, China; Noah\u2019s Ark Lab, Huawei, Beijing, China; Noah\u2019s Ark Lab, Huawei, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560767/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9612441352797034449&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Noah\u2019s Ark Lab",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561967",
        "title": "Identifying Driver Interactions via Conditional Behavior Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Interactive driving scenarios, such as lane changes, merges and unprotected turns, are some of the most challenging situations for autonomous driving. Planning in interactive scenarios requires accurately modeling the reactions of other agents to different future actions of the ego agent. We develop end-to-end models for conditional behavior prediction (CBP) that take as an input a query future trajectory for an ego-agent, and predict distributions over future trajectories for other agents conditioned on the query. Leveraging such a model, we develop a general-purpose agent interactivity score derived from probabilistic first principles. The interactivity score allows us to find interesting interactive scenarios for training and evaluating behavior prediction models. We further demonstrate that the proposed score is effective for agent prioritization under computational budget constraints.",
        "primary_area": "",
        "author": "Ekaterina Tolstaya;Reza Mahjourian;Carlton Downey;Balakrishnan Vadarajan;Benjamin Sapp;Dragomir Anguelov;Ekaterina Tolstaya;Reza Mahjourian;Carlton Downey;Balakrishnan Vadarajan;Benjamin Sapp;Dragomir Anguelov",
        "authorids": "/37086432156;/37938208600;/37667269800;/37089001345;/37089406608;/37278026400;/37086432156;/37938208600;/37667269800;/37089001345;/37089406608;/37278026400",
        "aff": "General Robotics Automation Sensing and Perception (GRASP) Laboratory, University of Pennsylvania; Waymo; Waymo; Waymo; Waymo; Waymo",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561967/",
        "gs_citation": 89,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9694932361166297242&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;1",
        "aff_unique_norm": "University of Pennsylvania;Waymo",
        "aff_unique_dep": "General Robotics Automation Sensing and Perception (GRASP) Laboratory;",
        "aff_unique_url": "https://www.upenn.edu;https://www.waymo.com",
        "aff_unique_abbr": "UPenn;Waymo",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Philadelphia;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561761",
        "title": "Identifying External Contacts from Joint Torque Measurements on Serial Robotic Arms and Its Limitations",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to detect and estimate external contacts is essential for robot arms to operate in unstructured environments occupied by humans. However, most robot arms are not equipped with adequate sensors to detect contacts on their entire body. What many robot arms do have is torque sensors for individual joints. Through a quantitative analysis, we argue that it is fairly likely for two distinct contacts on the robot\u2019s surface to generate almost identical joint torque measurements. When this happens, the best contact estimate achievable is the set of possible contact positions, all of which would reproduce the measured joint torque. Searching for elements of this set is equivalent to solving to global optimality a nonlinear program.By combining rejection sampling with gradient descent, we propose a contact estimation method which in practice finds all local optima of the nonlinear program at real-time rates. In addition, we propose an active contact exploration method which falsifies spurious contact estimates in the set of local optima by making small motions around the robot\u2019s current configuration. The proposed methods highlight the caveats of contact estimation from only joint torque, which, coupled with known limitations of such estimators, suggest that a more capable sensor is probably needed for robust whole-body contact estimation.",
        "primary_area": "",
        "author": "Tao Pang;Jack Umenberger;Russ Tedrake;Tao Pang;Jack Umenberger;Russ Tedrake",
        "authorids": "/37089309719;/37077683200;/37283152200;/37089309719;/37077683200;/37283152200",
        "aff": "Tao Pang; Jack Umenberger; Russ Tedrake",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561761/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5102454134151156151&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9561552",
        "title": "Image Representation of a City and Its Taxi Fleet for End-To-End Learning of Rebalancing Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, mobility on demand has experienced a major revival due to various ride-hailing companies entering the market. Competing in this field requires an efficient operation. Therefore, the applied policy, which cares for vehicle-to-customer assignment and vehicle repositioning, has to achieve good customer service and minimize cost while trying to keep the impact on the environment as low as possible. A promising approach is to coordinate the control of the entire fleet, which is foreseen to become even easier with the possibility of autonomous vehicles in mind. Anticipating future demand requires a good understanding of the spatiotemporal distributions of request origins and destinations, and the resulting imbalance between vehicle demand and availability. This results from a multitude of topological, demographic, and social effects, which are almost impossible to sufficiently capture in a handcrafted model of reasonable complexity. This can be circumvented by leveraging machine learning approaches. In this paper, an image-like representation of the city and its fleet's state is introduced. It is comprehensive and intuitive to use as input to convolutional neural networks, which in the past have already been proven to capture spatial relationships very well. This allows operating on realistic, full-sized traffic networks without greatly increasing the number of parameters the neural network has to learn and, hence, keeps the training effort low. Additionally, this state is combined with a similarly constructed repositioning action, reflecting a 2D distribution of a well-performing operational policy. This approach allows replacement of complex, handcrafted mathematical models by a single, compact, auto-encoder-like neural network.",
        "primary_area": "",
        "author": "Joel G\u00e4chter;Alessandro Zanardi;Claudio Ruch;Emilio Frazzoli;Joel G\u00e4chter;Alessandro Zanardi;Claudio Ruch;Emilio Frazzoli",
        "authorids": "/37088648753;/37086163473;/37085351327;/37283368500;/37088648753;/37086163473;/37085351327;/37283368500",
        "aff": "Joel G\u00e4chter; Alessandro Zanardi; Claudio Ruch; Emilio Frazzoli",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561552/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1902309945205700665&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9561444",
        "title": "Imitation Learning from MPC for Quadrupedal Multi-Gait Control",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a learning algorithm for training a single policy that imitates multiple gaits of a walking robot. To achieve this, we use and extend MPC-Net, which is an Imitation Learning approach guided by Model Predictive Control (MPC). The strategy of MPC-Net differs from many other approaches since its objective is to minimize the control Hamiltonian, which derives from the principle of optimality. To represent the policies, we employ a mixture-of-experts network (MEN) and observe that the performance of a policy improves if each expert of a MEN specializes in controlling exactly one mode of a hybrid system, such as a walking robot. We introduce new loss functions for single- and multi-gait policies to achieve this kind of expert selection behavior. Moreover, we benchmark our algorithm against Behavioral Cloning and the original MPC implementation on various rough terrain scenarios. We validate our approach on hardware and show that a single learned policy can replace its teacher to control multiple gaits.",
        "primary_area": "",
        "author": "Alexander Reske;Jan Carius;Yuntao Ma;Farbod Farshidian;Marco Hutter;Alexander Reske;Jan Carius;Yuntao Ma;Farbod Farshidian;Marco Hutter",
        "authorids": "/37089001021;/37086291987;/37088998578;/37085428006;/37545251000;/37089001021;/37086291987;/37088998578;/37085428006;/37545251000",
        "aff": "Robotic Systems Lab, ETH Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561444/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10003375649631908418&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561686",
        "title": "Imitation Learning with Inconsistent Demonstrations through Uncertainty-based Data Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Aleatoric uncertainty estimation, based on the observed training data, is applied for the detection of conflicts in a demonstration data set. The particular focus of this paper is the resolution of conflicting data resulting from scenarios with equivalent action choices, such as obstacle avoidance, path planning or multiple joint configurations. In terms of the estimated uncertainty, the proposed algorithm aims to decrease this otherwise irreducible value through direct alteration of the accrued data set and to provide data that a policy-learning neural network is able to fit appropriately. The proposed algorithm was validated with real robot scenarios while learning from inconsistent demonstrations, where the resulting policies consistently achieved their prescribed objectives. A video showing our method and experiments can be found at: https://youtu.be/oGYnzlW9Ncw.",
        "primary_area": "",
        "author": "Peter Valletta;Rodrigo P\u00e9rez-Dattari;Jens Kober;Peter Valletta;Rodrigo P\u00e9rez-Dattari;Jens Kober",
        "authorids": "/37088997631;/37086933555;/37542833400;/37088997631;/37086933555;/37542833400",
        "aff": "Cognitive Robotics Department, TU Delft, Delft, The Netherlands; Cognitive Robotics Department, TU Delft, Delft, The Netherlands; Cognitive Robotics Department, TU Delft, Delft, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561686/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4047014571217838650&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Cognitive Robotics Department",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Delft",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9561641",
        "title": "Impact Mitigation for Dynamic Legged Robots with Steel Wire Transmission Using Nonlinear Active Compliance Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Impact mitigation is crucial to the stable locomotion of legged robots, especially in high-speed dynamic locomotion. This paper presents a leg locomotion system, including the nonlinear active compliance control and the active impedance control for the steel wire transmission-based legged robot. The developed control system enables high-speed dynamic locomotion with excellent impact mitigation and leg position tracking performance, where three strategies are applied. a) The feed-forward controller is designed according to the linear motor-leg model with the information of Coulomb friction and viscous friction. b) Steel wire transmission model-based compensation guarantees ideal virtual spring compliance characteristics. c) Nonlinear active compliance control and active impedance control ensure better impact mitigation performance than linear scheme and guarantee position tracking performance. The proposed control system is verified on a real robot named SCIT Dog, and the experiment demonstrates the ideal impact mitigation ability in high-speed dynamic locomotion without any passive spring mechanism.",
        "primary_area": "",
        "author": "Junjie Yang;Hao Sun;Hao An;Changhong Wang;Junjie Yang;Hao Sun;Hao An;Changhong Wang",
        "authorids": "/37088998950;/37088688060;/37085778282;/37280022000;/37088998950;/37088688060;/37085778282;/37280022000",
        "aff": "Space Control and Inertial Technology Research Center, Harbin Institute of Technology, Harbin, P.R. China; Space Control and Inertial Technology Research Center, Harbin Institute of Technology, Harbin, P.R. China; Space Control and Inertial Technology Research Center, Harbin Institute of Technology, Harbin, P.R. China; Space Control and Inertial Technology Research Center, Harbin Institute of Technology, Harbin, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561641/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16479702189200550124&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "Space Control and Inertial Technology Research Center",
        "aff_unique_url": "http://www.hhit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Harbin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561559",
        "title": "Implementation of a Reactive Walking Controller for the New Open-Hardware Quadruped Solo-12",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper aims at showing the dynamic performance and reliability of the low-cost, open-access quadruped robot Solo-12, which is developed within the framework of Open Dynamic Robot Initiative. It presents the implementation of a state-of-the-art control pipeline, close to the one that was previously implemented on Mini Cheetah, which implements a model predictive controller based on the centroidal dynamics to compute desired contact forces in order to track a reference velocity. Different contributions are proposed to speed up the computation process, notably at the level of the state estimation and the whole body controller. Experimental results demonstrate that the robot closely follow the reference velocity while being highly reactive and able to recover from perturbations.",
        "primary_area": "",
        "author": "Pierre-Alexandre L\u00e9ziart;Thomas Flayols;Felix Grimminger;Nicolas Mansard;Philippe Sou\u00e8res;Pierre-Alexandre L\u00e9ziart;Thomas Flayols;Felix Grimminger;Nicolas Mansard;Philippe Sou\u00e8res",
        "authorids": "/37087901433;/37086293347;/37627163100;/37542913400;/37377500300;/37087901433;/37086293347;/37627163100;/37542913400;/37377500300",
        "aff": "LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France; Artificial and Natural Intelligence Toulouse Institute, France; Max Planck Institute for Intelligent Systems, Tubingen, Germany; Artificial and Natural Intelligence Toulouse Institute, France; LAAS-CNRS, Universit\u00e9 de Toulouse, CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561559/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15698354143714711187&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;0",
        "aff_unique_norm": "LAAS-CNRS;Artificial and Natural Intelligence Toulouse Institute;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.laas.fr/;;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "LAAS-CNRS;ANITI;MPI-IS",
        "aff_campus_unique_index": "0;2;0",
        "aff_campus_unique": "Toulouse;;Tubingen",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "France;Germany"
    },
    {
        "id": "9560924",
        "title": "Implicit Integration for Articulated Bodies with Contact via the Nonconvex Maximal Dissipation Principle",
        "track": "main",
        "status": "Poster",
        "abstract": "We present non-convex maximal dissipation principle (NMDP), a time integration scheme for articulated bodies with simultaneous contacts. Our scheme resolves contact forces via the maximal dissipation principle (MDP). Whereas prior MDP solvers assume linearized dynamics and integrate using the forward multistep scheme, we consider the coupled system of nonlinear Newton-Euler dynamics and MDP and integrate using the backward integration scheme. We show that the coupled system of equations can be solved efficiently using a novel projected gradient method with guaranteed convergence. We evaluate our method by predicting several locomotion trajectories for a quadruped robot. The results show that our NMDP scheme has several desirable properties including: (1) generalization to novel contact models; (2) stability under large timestep sizes; (3) consistent trajectory generation under varying timestep sizes.",
        "primary_area": "",
        "author": "Zherong Pan;Kris Hauser;Zherong Pan;Kris Hauser",
        "authorids": "/37086067204;/37543748800;/37086067204;/37543748800",
        "aff": "Department of Computer Science, University of Illinois, Urbana-Champaign; Department of Computer Science, University of Illinois, Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560924/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:QM2Sjqc9VVIJ:scholar.google.com/&scioq=Implicit+Integration+for+Articulated+Bodies+with+Contact+via+the+Nonconvex+Maximal+Dissipation+Principle&hl=en&as_sdt=0,5",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois, Urbana-Champaign",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561529",
        "title": "Improving Dynamics of an Aerial Manipulator with Elastic Suspension Using Nonlinear Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Aerial manipulation increases significantly the workspace size of robotic manipulators. However, aerial manipulation suffers from a lack of autonomy due to limited embedded energy. The Aerial Manipulator with Elastic Suspension (AMES) is designed to cope with this issue. It is an omnidirectional aerial vehicle equipped with a gripper and suspended under a robotic carrier by a spring for gravity compensation. In this paper, the AMES is controlled with a nonlinear model predictive controller (NMPC). To eliminate the steady-state errors, an observer based on a model of the AMES augmented with constant disturbances is implemented in conjunction with the NMPC controller. Experiments illustrate the efficiency of the NMPC by comparing it to a computed torque controller.",
        "primary_area": "",
        "author": "Arda Yi\u011fit;Miguel Arpa Perozo;Lo\u00efc Cuvillon;Sylvain Durand;Jacques Gangloff;Arda Yi\u011fit;Miguel Arpa Perozo;Lo\u00efc Cuvillon;Sylvain Durand;Jacques Gangloff",
        "authorids": "/37088507420;/37088652283;/37563879500;/37411970500;/37283578200;/37088507420;/37088652283;/37563879500;/37411970500;/37283578200",
        "aff": "ICube Laboratory, University of Strasbourg, INSA Strasbourg, Strasbourg, France; ICube Laboratory, University of Strasbourg, INSA Strasbourg, Strasbourg, France; ICube Laboratory, University of Strasbourg, INSA Strasbourg, Strasbourg, France; ICube Laboratory, University of Strasbourg, INSA Strasbourg, Strasbourg, France; ICube Laboratory, University of Strasbourg, INSA Strasbourg, Strasbourg, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561529/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7573026574493267247&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Strasbourg",
        "aff_unique_dep": "ICube Laboratory",
        "aff_unique_url": "https://www.unistra.fr",
        "aff_unique_abbr": "UNistra",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Strasbourg",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561750",
        "title": "Improving Grasp Classification through Spatial Metrics Available from Sensors",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for classifying the quality of near-contact grasps using spatial metrics that are recoverable from sensor data. Current methods often rely on calculating precise contact points, which are difficult to calculate in real life, or on tactile sensors or image data, which may be unavailable for some applications. Our method, in contrast, uses a mix of spatial metrics that do not depend on the fingers being in contact with the object, such as the object\u2019s approximate size and location. The grasp quality can be calculated before the fingers actually contact the object, enabling near-grasp quality prediction. Using a random forest classifier, the resulting system is able to predict grasp quality with 96% accuracy using spatial metrics based on the locations of the robot palm, fingers and object. Furthermore, it can maintain an accuracy of 90% when exposed to 10% noise across all its inputs.",
        "primary_area": "",
        "author": "Nigel Swenson;Garrett Scott;Peter Bloch;Paresh Soni;Nuha Nishat;Anjali Asar;Cindy Grimm;Xiaoli Fern;Ravi Balasubramanian;Nigel Swenson;Garrett Scott;Peter Bloch;Paresh Soni;Nuha Nishat;Anjali Asar;Cindy Grimm;Xiaoli Fern;Ravi Balasubramanian",
        "authorids": "/37088997404;/37088996865;/37088997520;/37088997542;/37088996618;/37088998943;/37085798146;/37088999382;/37399991400;/37088997404;/37088996865;/37088997520;/37088997542;/37088996618;/37088998943;/37085798146;/37088999382;/37399991400",
        "aff": "Nigel Swenson; Garrett Scott; Peter Bloch; Paresh Soni; Nuha Nishat; Anjali Asar; Cindy Grimm; Xiaoli Fern; Ravi Balasubramanian",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561750/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4145894883611150010&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "1",
        "aff_unique_norm": ";Xiaoli Fern",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9561881",
        "title": "Improving Off-road Planning Techniques with Learned Costs from Physical Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous ground vehicles have improved greatly over the past decades, but they still have their limitations when it comes to off-road environments. There is still a need for planning techniques that effectively handle physical interactions between a vehicle and its surroundings. We present a method of modifying a standard path planning algorithm to address these problems by incorporating a learned model to account for complexities that would be too hard to address manually. The model predicts how well a vehicle will be able to follow a potential plan in a given environment. These predictions are then used to assign costs to their associated paths, where the path predicted to be the most feasible will be output as the final path. This results in a planner that doesn't rely solely on engineered features to evaluate traversability of obstacles, and can also choose a better path based on an understanding of its own capability that it has learned from previous interactions. This modification was integrated into the Hybrid A* algorithm and experimental results demonstrated an improvement of 14.29% over the original version on a physical platform.",
        "primary_area": "",
        "author": "Matthew Sivaprakasam;Samuel Triest;Wenshan Wang;Peng Yin;Sebastian Scherer;Matthew Sivaprakasam;Samuel Triest;Wenshan Wang;Peng Yin;Sebastian Scherer",
        "authorids": "/37088996836;/37088642042;/37087322184;/37085692390;/37584159000;/37088996836;/37088642042;/37087322184;/37085692390;/37584159000",
        "aff": "University of Pittsburgh, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561881/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4658987412697527794&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "University of Pittsburgh;Carnegie Mellon University",
        "aff_unique_dep": ";Robotics Institute",
        "aff_unique_url": "https://www.pitt.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Pitt;CMU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560750",
        "title": "Improving Ranging-Based Location Estimation with Rigidity-Constrained CRLB-Based Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Ranging systems can provide inexpensive, accurate, energy- and computationally-efficient navigation solutions for mobile robots. This work focuses on location and pose estimation in ranging networks composed of anchors with known positions as well as mobile robots modeled as rigid bodies, each carrying multiple tags to localize. Noisy distance measurements can be obtained between a subset of the nodes (anchors and tags), and the robots can move in order to improve the accuracy of the localization process, which depends on the geometry of the network. We propose a method to find trajectories for the robots leading to configurations that locally optimize this localization accuracy. These trajectories minimize a cost function based on the constrained Cram\u00e9r-Rao Lower Bound (CRLB), where the constraints capture the information about the known distances between tags carried by the same robot. A primal-dual optimization scheme aims to enforce these distance constraints between tags in the motion planner as well. An important feature of the approach is that the gradient terms necessary to plan the motion can be computed essentially in closed form, thereby simplifying the implementation. We compare the proposed method to a naive two-stage algorithm that optimizes the positions and orientations of the robots independently. Simulation results illustrate the benefits of using the constrained optimization approach.",
        "primary_area": "",
        "author": "Justin Cano;Jerome Le Ny;Justin Cano;Jerome Le Ny",
        "authorids": "/37086933423;/37546028800;/37086933423;/37546028800",
        "aff": "Department of Electrical Engineering, Polytechnique Montreal and with GERAD, Montreal, Canada; Department of Electrical Engineering, Polytechnique Montreal and with GERAD, Montreal, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560750/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1352898368715181379&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Polytechnique Montreal",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.polymtl.ca",
        "aff_unique_abbr": "Polytechnique",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561025",
        "title": "Improving Safety and Accuracy of Impedance Controlled Robot Manipulators with Proximity Perception and Proactive Impact Reactions",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a system which improves the safety and accuracy of impedance controlled robotic manipulators with proximity perception. Proximity servoed manipulators, which use proximity sensors attached to the robot\u2019s outer shell, have recently demonstrated robust collision avoidance abilities. Nevertheless, unwanted collisions cannot be avoided entirely. As a fallback safety mechanism, robots with joint force/torque sensing rely on impedance controllers for impact attenuation and compliant behavior. However, impedance controllers induce undesired deflections of the robot from its trajectory when it is not in contact. These deviations are more pronounced at soft configurations and when the robot grasps objects of unknown weight distribution, thus a compromise must be made between high positional accuracy and softness (safety). The proximity information allows the robot to react to anticipated impacts proactively for attenuation and damage reduction of unavoidable collisions, while still maintaining high accuracy during regular operation. This is achieved through variations of impedance parameters according to proximity measurements and motions towards safe joint configurations during the preimpact phase.",
        "primary_area": "",
        "author": "Yitao Ding;Ulrike Thomas;Yitao Ding;Ulrike Thomas",
        "authorids": "/37086576023;/37281523200;/37086576023;/37281523200",
        "aff": "Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology, SN Chemnitz, Germany; Lab of Robotics and Human-Machine-Interaction, Chemnitz University of Technology, SN Chemnitz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561025/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=524448068025218757&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Chemnitz University of Technology",
        "aff_unique_dep": "Lab of Robotics and Human-Machine-Interaction",
        "aff_unique_url": "https://www.tu-chemnitz.de",
        "aff_unique_abbr": "TUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Chemnitz",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561055",
        "title": "In Situ Translational Hand-Eye Calibration of Laser Profile Sensors using Arbitrary Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Hand-eye calibration of laser profile sensors is the process of extracting the homogeneous transformation between the laser profile sensor frame and the end-effector frame of a robot in order to express the data extracted by the sensor in the robot\u2019s global coordinate system. For laser profile scanners this is a challenging procedure, as they provide data only in two dimensions and state-of-the-art calibration procedures require the use of specialised calibration targets. This paper presents a novel method to extract the translation-part of the hand-eye calibration matrix with rotation-part known a priori in a target-agnostic way. Our methodology is applicable to any 2D image or 3D object as a calibration target and can also be performed in situ in the final application. The method is experimentally validated on a real robot-sensor setup with 2D and 3D targets.",
        "primary_area": "",
        "author": "Prajval Kumar Murali;Ines Sorrentino;Angelo Rendiniello;Claudio Fantacci;Enrico Villagrossi;Andrea Polo;Alessandro Ardesi;Marco Maggiali;Lorenzo Natale;Daniele Pucci;Silvio Traversaro;Prajval Kumar Murali;Ines Sorrentino;Angelo Rendiniello;Claudio Fantacci;Enrico Villagrossi;Andrea Polo;Alessandro Ardesi;Marco Maggiali;Lorenzo Natale;Daniele Pucci;Silvio Traversaro",
        "authorids": "/37088524017;/37088520348;/37086524477;/38469567100;/37073322000;/37088521372;/37088525099;/37295800800;/37542770000;/37706167200;/37085503650;/37088524017;/37088520348;/37086524477;/38469567100;/37073322000;/37088521372;/37088525099;/37295800800;/37542770000;/37706167200;/37085503650",
        "aff": "Fondazione Istituto Italiano di Tecnologia, Genova, Italy; Fondazione Istituto Italiano di Tecnologia, Genova, Italy; Fondazione Istituto Italiano di Tecnologia, Genova, Italy; Fondazione Istituto Italiano di Tecnologia, Genova, Italy; Danieli Automation S.p.A, Buttrio, Italy; Danieli Automation S.p.A, Buttrio, Italy; Danieli Automation S.p.A, Buttrio, Italy; Fondazione Istituto Italiano di Tecnologia, Genova, Italy; Fondazione Istituto Italiano di Tecnologia, Genova, Italy; Fondazione Istituto Italiano di Tecnologia, Genova, Italy; Fondazione Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561055/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11838159752432130904&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;1;1;1;0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;Danieli Automation S.p.A",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.iit.it;",
        "aff_unique_abbr": "IIT;",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Genova;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9561500",
        "title": "In-Process Workpiece Geometry Estimation for Robotic Arc Welding based on Supervised Learning for Multi-Sensor Inputs",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to manufacturing tolerances, the geometry parameters of workpieces are not constant in industrial welding applications. Today, this problem is addressed by either accepting fluctuating part quality or by measuring the geometry and adjusting the configuration of the robot and process controller for each individual part. However, measuring the geometry requires additional manufacturing time or reduces the accessibility of the welding tool. This paper presents an approach for estimating the workpiece geometry based on process data during the welding process, which eliminates the need of measuring the geometry in advance, yet provides the same accessibility of the welding tool. For this approach, a data set is generated by conducting welding experiments with varying part geometries. Welding current, welding voltage and acoustic emissions are recorded. Three supervised learning techniques, which are Support Vector Machines, Random Forest Decision Trees and k-Nearest-Neighbors, are used to train models for estimating the geometry. The results show, that the trained models successfully estimate the part geometry with over 90% accuracy.",
        "primary_area": "",
        "author": "Alexander Schmidt;Christian Kotschote;Oliver Riedel;Alexander Schmidt;Christian Kotschote;Oliver Riedel",
        "authorids": "/37088984809;/37088984578;/37086269580;/37088984809;/37088984578;/37086269580",
        "aff": "Institute for Control Engineering of Machine Tools and Manufacturing Units, University of Stuttgart, Stuttgart, Germany; Department for Development Production and Logistics, AUDI AG, Neckarsulm, Germany; Institute for Control Engineering of Machine Tools and Manufacturing Units, University of Stuttgart, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561500/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6226974985632859598&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Stuttgart;AUDI AG",
        "aff_unique_dep": "Institute for Control Engineering of Machine Tools and Manufacturing Units;Department for Development Production and Logistics",
        "aff_unique_url": "https://www.uni-stuttgart.de;https://www.audi.de",
        "aff_unique_abbr": "Uni Stuttgart;AUDI",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Stuttgart;Neckarsulm",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561511",
        "title": "Inertial Aided 3D LiDAR SLAM with Hybrid Geometric Primitives in Large-scale Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a comprehensive inertial aided 3D LiDAR SLAM system with hybrid geometric primitives in large-scale environments, including a tightly-coupled LiDAR-Inertial-Odometry (LIO), a global mapping module supported by learning-based loop closure detection and a sub-maps matching algorithm. An efficient method is developed to simultaneously extract explicit plane features and point features from each raw point cloud. To make full use of the structural information of the surroundings, plane features and point features (ground and edge) are tracked across a fix-sized group of LiDAR keyframes in the local map. For effective loop closure detection in large-scale environments, we integrate the learning-based point cloud network and a keyframe sequence matching method to detect loops. Finally, a novel, deterministic and near real-time plane-driven sub-maps matching algorithm is proposed to close the loops. The proposed SLAM system is validated with experiments on different types of environments.",
        "primary_area": "",
        "author": "Wen Chen;Hongchao Zhao;Qi Shen;Chao Xiong;Shunbo Zhou;Yun-Hui Liu;Wen Chen;Hongchao Zhao;Qi Shen;Chao Xiong;Shunbo Zhou;Yun-Hui Liu",
        "authorids": "/37087239966;/37086346685;/37089001128;/37088822601;/37086345412;/37279412600;/37087239966;/37086346685;/37089001128;/37088822601;/37086345412;/37279412600",
        "aff": "T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, HKSAR, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, HKSAR, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, HKSAR, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, HKSAR, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, HKSAR, China; T Stone Robotics Institute and Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, HKSAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561511/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15900243954456800614&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561575",
        "title": "Initialisation of Autonomous Aircraft Visual Inspection Systems via CNN-Based Camera Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "General Visual Inspection is a manual inspection process regularly used to detect and localise obvious damage on the exterior of commercial aircraft. There has been increasing demand to perform this process at the boarding gate to minimize the downtime of the aircraft and automating this process is desired to reduce the reliance on human labour. This automation typically requires the first step of estimating a camera\u2019s pose with respect to the aircraft for initialisation. However, localisation methods often require infrastructure, which can be very challenging when performed in uncontrolled outdoor environments and within the limited turnover time (approximately 2 hours) on an airport tarmac. In addition, access to commercial aircraft can be very restricted, causing development and testing of solutions to be a challenge. Hence, this paper proposes an on-site infrastructure-less initialisation method, by using the same pan-tilt-zoom camera used for the inspection task to estimate its own pose. This is achieved using a Deep Convolutional Neural Network trained with only synthetic images to regress the camera\u2019s pose. We apply domain randomisation when generating our dataset for training our network and improve prediction accuracy by introducing a new component to an existing loss function that leverages on known aircraft geometry to relate position and orientation. Experiments are conducted and we have successfully regressed camera poses with a median error of 0.22 m and 0.73\u00b0.",
        "primary_area": "",
        "author": "Xueyan Oh;Leonard Loh;Shaohui Foong;Zhong Bao Andy Koh;Kow Leong Ng;Poh Kang Tan;Pei Lin Pearlin Toh;U-Xuan Tan;Xueyan Oh;Leonard Loh;Shaohui Foong;Zhong Bao Andy Koh;Kow Leong Ng;Poh Kang Tan;Pei Lin Pearlin Toh;U-Xuan Tan",
        "authorids": "/37088999180;/37089000513;/37542925800;/37089000317;/37088998293;/37088996705;/37088997703;/37085617165;/37088999180;/37089000513;/37542925800;/37089000317;/37088998293;/37088996705;/37088997703;/37085617165",
        "aff": "Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore; ST Engineering Aerospace Ltd., Singapore; ST Engineering Aerospace Ltd., Singapore; ST Engineering Aerospace Ltd., Singapore; ST Engineering Aerospace Ltd., Singapore; Pillar of Engineering Product Development, Singapore University of Technology and Design, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561575/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11936528608298735484&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;1;1;1;0",
        "aff_unique_norm": "Singapore University of Technology and Design;ST Engineering Aerospace Ltd.",
        "aff_unique_dep": "Pillar of Engineering Product Development;",
        "aff_unique_url": "https://www.sutd.edu.sg;https://www.stengg.com/aerospace",
        "aff_unique_abbr": "SUTD;STEL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9561060",
        "title": "Innovative Design and Simulation of a Transformable Robot with Flexibility and Versatility, RHex-T3",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a transformable RHex-inspired robot, RHex-T3, with high energy efficiency, excellent flexibility and versatility. By using the innovative 2-DoF transformable structure, RHex-T3 inherits most of RHex\u2019s mobility, and can also switch to other 4 modes for handling various missions. The wheel-mode improves the efficiency of RHex-T3, and the leg-mode helps to generate a smooth locomotion when RHex-T3 is overcoming obstacles. In addition, RHex-T3 can switch to the claw-mode for transportation missions, and even climb ladders by using the hook-mode. The simulation model is conducted based on the mechanical structure, and thus the properties in different modes are verified and analyzed through numerical simulations.",
        "primary_area": "",
        "author": "Yue Lin;Yujia Tian;Yongjiang Xue;Shujun Han;Huaiyu Zhang;Wenxin Lai;Xuan Xiao;Yue Lin;Yujia Tian;Yongjiang Xue;Shujun Han;Huaiyu Zhang;Wenxin Lai;Xuan Xiao",
        "authorids": "/37088574571;/37088574341;/37088996143;/37088572522;/37089000550;/37088575071;/37088987287;/37088574571;/37088574341;/37088996143;/37088572522;/37089000550;/37088575071;/37088987287",
        "aff": "School of Computer Science and Technology, Tiangong University, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561060/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2444890016226762828&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Tiangong University",
        "aff_unique_dep": "School of Computer Science and Technology",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tianjin",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561235",
        "title": "Instance-Aware Predictive Navigation in Multi-Agent Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we aim to achieve efficient end-to-end learning of driving policies in dynamic multi-agent environments. Predicting and anticipating future events at the object level are critical for making informed driving decisions. We propose an Instance-Aware Predictive Control (IPC) approach, which forecasts interactions between agents as well as future scene structures. We adopt a novel multi-instance event prediction module to estimate the possible interaction among agents in the ego-centric view, conditioned on the selected action sequence of the ego-vehicle. To decide the action at each step, we seek the action sequence that can lead to safe future states based on the prediction module outputs by repeatedly sampling likely action sequences. We design a sequential action sampling strategy to better leverage predicted states on both scene-level and instance-level. Our method establishes a new state of the art in the challenging CARLA multi-agent driving simulation environments without expert demonstration, giving better explainability and sample efficiency.",
        "primary_area": "",
        "author": "Jinkun Cao;Xin Wang;Trevor Darrell;Fisher Yu;Jinkun Cao;Xin Wang;Trevor Darrell;Fisher Yu",
        "authorids": "/37088997033;/37089001589;/37282910600;/37086564244;/37088997033;/37089001589;/37282910600;/37086564244",
        "aff": "Carnegie Mellon University; University of California, Berkeley; University of California, Berkeley; ETH, Zurich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561235/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6242991604659628336&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "Carnegie Mellon University;University of California, Berkeley;ETH Zurich",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.cmu.edu;https://www.berkeley.edu;https://www.ethz.ch",
        "aff_unique_abbr": "CMU;UC Berkeley;ETHZ",
        "aff_campus_unique_index": "1;1;2",
        "aff_campus_unique": ";Berkeley;Zurich",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "United States;Switzerland"
    },
    {
        "id": "9561522",
        "title": "Integration of a Human-aware Risk-based Braking System into an Open-Field Mobile Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety integration components for robotic applications are a mandatory feature for any autonomous mobile application, including human avoidance behaviors. This paper proposes a novel parametrizable scene risk evaluator for open-field applications that use humans motion predictions and pre-defined hazard zones to estimate a braking factor. Parameters optimization uses simulated data. The evaluation is carried out by simulated and real-time scenarios, showing the impact of human predictions in favor of risk reductions on agricultural applications.",
        "primary_area": "",
        "author": "Jos\u00e9 C. Mayoral;Lars Grimstad;P\u00e5l J. From;Grzegorz Cielniak;Jos\u00e9 C. Mayoral;Lars Grimstad;P\u00e5l J. From;Grzegorz Cielniak",
        "authorids": "/37088998822;/37085721771;/37571980700;/37550177700;/37088998822;/37085721771;/37571980700;/37550177700",
        "aff": "Norwegian University of Life Sciences (NMBU); Norwegian University of Life Sciences (NMBU); Norwegian University of Life Sciences (NMBU); University of Lincoln (UoL)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561522/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18376453018101683237&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Norwegian University of Life Sciences;University of Lincoln",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.nmbu.no;https://www.lincoln.ac.uk",
        "aff_unique_abbr": "NMBU;UoL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Norway;United Kingdom"
    },
    {
        "id": "9561351",
        "title": "Intent-aware control in kinematically redundant systems: Towards collaborative wearable robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Many human-robot collaboration scenarios can be seen as a redundant leader-follower setup where the human (i.e., the leader) can potentially perform the task without the assistance of the robot (i.e., the follower). Thus, the goal of the collaboration, beside stable execution of the task, is to reduce the human cost; e.g., ergonomic, or cognitive cost. Such system redundancies (where the same task be achieved in different manner) can also be exploited as a communication channel for the human to convey his/her intention to the robot; since it is essential for the overall performance (both execution and assistance) that the follower recognizes the intended task in an online fashion. Having an estimation for the intended task, the robot can assist the human by reducing the human cost over the task null-space; i.e., the null-space which arises from the overall system redundancies with respect to the intended task. With the prospective of supernumerary and prosthetic robots, in this work, we primarily focus on serial manipulation in which the proximal/distal part of the kinematic chain is controlled by the leader/follower respectively. By exploiting kinematic redundancies for intention-recognition and cost-minimization, our proposed control strategy (for the follower) ensures assistance under stable execution of the task. Our results (simulations and preliminary experimentation) show the efficacy of our method in providing a seamless robotic assistance (i.e., improving human posture) toward human intended tasks (i.e., reaching motions) for wearable robotics.",
        "primary_area": "",
        "author": "Mahdi Khoramshahi;Guillaume Morel;Nathanael Jarrass\u00e9;Mahdi Khoramshahi;Guillaume Morel;Nathanael Jarrass\u00e9",
        "authorids": "/37085359323;/37274022000;/38324251300;/37085359323;/37274022000;/38324251300",
        "aff": "CNRS, INSERM, Institute for Intelligent Systems and Robotics (ISIR), Sorbonne Universit\u00e9, Paris, France; CNRS, INSERM, Institute for Intelligent Systems and Robotics (ISIR), Sorbonne Universit\u00e9, Paris, France; CNRS, INSERM, Institute for Intelligent Systems and Robotics (ISIR), Sorbonne Universit\u00e9, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561351/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17695054931764895685&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Sorbonne Universit\u00e9",
        "aff_unique_dep": "Institute for Intelligent Systems and Robotics (ISIR)",
        "aff_unique_url": "https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "Sorbonne U",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561344",
        "title": "Interactive Planning for Autonomous Urban Driving in Adversarial Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous urban driving among human-driven cars requires a holistic understanding of road rules, driver intents and driving styles. This is challenging as a short-term, single instance, driver intent of lane change may not correspond to their driving styles for a longer duration. This paper presents an interactive behavior planner which accounts for road context, short-term driver intent, and long-term driving style to infer beliefs over the latent states of surrounding vehicles. We use a specialized Partially Observable Markov Decision Process to provide risk-averse decisions. Specifically, we consider adversarial driving scenarios caused by irrational drivers to validate the robustness of our proposed interactive behavior planner in simulation as well as on a full-size self-driving car. Our experimental results show that our algorithm enables safer and more travel time-efficient autonomous driving compared to baselines even in adversarial scenarios.",
        "primary_area": "",
        "author": "Yuanfu Luo;Malika Meghjani;Qi Heng Ho;David Hsu;Daniela Rus;Yuanfu Luo;Malika Meghjani;Qi Heng Ho;David Hsu;Daniela Rus",
        "authorids": "/37086426724;/37393934900;/37087321977;/37421581500;/37279652300;/37086426724;/37393934900;/37087321977;/37421581500;/37279652300",
        "aff": "SZ DJI Technology Co., Ltd., China; Singapore-MIT Alliance for Research and Technology, Singapore; Singapore-MIT Alliance for Research and Technology, Singapore; National University of Singapore, Singapore; Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561344/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14752183317637513763&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;3",
        "aff_unique_norm": "DJI Technology Co., Ltd.;Singapore-MIT Alliance for Research and Technology;National University of Singapore;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;;",
        "aff_unique_url": "https://www.dji.com;;https://www.nus.edu.sg;https://www.mit.edu",
        "aff_unique_abbr": "DJI;SMART;NUS;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;1;1;1;2",
        "aff_country_unique": "China;Singapore;United States"
    },
    {
        "id": "9561562",
        "title": "Interleaving Fast and Slow Decision Making",
        "track": "main",
        "status": "Poster",
        "abstract": "The \"Thinking, Fast and Slow\" paradigm of Kahneman proposes that we use two different styles of thinking\u2014a fast and intuitive System 1 for certain tasks, along with a slower but more analytical System 2 for others. While the idea of using this two-system style of thinking is gaining popularity in AI and robotics, our work considers how to interleave the two styles of decision-making, i.e., how System 1 and System 2 should be used together. For this, we propose a novel and general framework which includes a new System 0 to oversee Systems 1 and 2. At every point when a decision needs to be made, System 0 evaluates the situation and quickly hands over the decision-making process to either System 1 or System 2. We evaluate such a framework on a modified version of the classic Pac-Man game, with an already-trained RL algorithm for System 1, a Monte-Carlo tree search for System 2, and several different possible strategies for System 0. As expected, arbitrary switches between Systems 1 and 2 do not work, but certain strategies do well. With System 0, an agent is able to perform better than one that uses only System 1 or System 2.",
        "primary_area": "",
        "author": "Aditya Gulati;Sarthak Soni;Shrisha Rao;Aditya Gulati;Sarthak Soni;Shrisha Rao",
        "authorids": "/37088997415;/37089001744;/37089268266;/37088997415;/37089001744;/37089268266",
        "aff": "International Institute of Information Technology, Bangalore, India; International Institute of Information Technology, Bangalore, India; International Institute of Information Technology, Bangalore, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561562/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12888536244969220538&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "International Institute of Information Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://iiitb.ac.in",
        "aff_unique_abbr": "IIITB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Bangalore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9561070",
        "title": "Intermittent Visual Servoing: Efficiently Learning Policies Robust to Instrument Changes for High-precision Surgical Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Assisting surgeons with automation of surgical subtasks is challenging due to backlash, hysteresis, and variable tensioning in cable-driven robots. These issues are exacerbated as surgical instruments are changed during an operation. In this work, we propose a framework for automation of high- precision surgical subtasks by learning local, sample-efficient, accurate, closed-loop policies that use visual feedback instead of robot encoder estimates. This framework, which we call deep Intermittent Visual Servoing (IVS), switches to a learned visual servo policy for high-precision segments of repetitive surgical tasks while relying on a coarse open-loop policy for the segments where precision is not necessary. We train the policy using only 180 human demonstrations that are roughly 2 seconds each. Results on a da Vinci Research Kit suggest that combining the coarse policy with half a second of corrections from the learned policy during each high-precision segment improves the success rate on the Fundamentals of Laparoscopic Surgery peg transfer task from 72.9% to 99.2%, 31.3% to 99.2%, and 47.2% to 100.0% for 3 instruments with differing cable properties. In the contexts we studied, IVS attains the highest published success rates for automated surgical peg transfer and is significantly more reliable than previous techniques when instruments are changed. Supplementary material is available at https://tinyurl.com/ivs-icra.",
        "primary_area": "",
        "author": "Samuel Paradis;Minho Hwang;Brijen Thananjeyan;Jeffrey Ichnowski;Daniel Seita;Danyal Fer;Thomas Low;Joseph E. Gonzalez;Ken Goldberg;Samuel Paradis;Minho Hwang;Brijen Thananjeyan;Jeffrey Ichnowski;Daniel Seita;Danyal Fer;Thomas Low;Joseph E. Gonzalez;Ken Goldberg",
        "authorids": "/37088451566;/37085406507;/37086105009;/38541287200;/37086012763;/37086541068;/37532299200;/37086566024;/37273026700;/37088451566;/37085406507;/37086105009;/38541287200;/37086012763;/37086541068;/37532299200;/37086566024;/37273026700",
        "aff": "University of California, Berkeley, USA; University of California, Berkeley, USA; University of California, Berkeley, USA; University of California, Berkeley, USA; University of California, Berkeley, USA; UC San Francisco East Bay, USA; SRI International, USA; University of California, Berkeley, USA; University of California, Berkeley, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561070/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10803166895698562912&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;1;2;0;0",
        "aff_unique_norm": "University of California, Berkeley;University of California, San Francisco;SRI International",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.berkeley.edu;https://www.ucsf.edu;https://www.sri.com",
        "aff_unique_abbr": "UC Berkeley;UCSF;SRI",
        "aff_campus_unique_index": "0;0;0;0;0;1;0;0",
        "aff_campus_unique": "Berkeley;East Bay;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560920",
        "title": "Interpretability in Contact-Rich Manipulation via Kinodynamic Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Neural Networks (NNs) have been widely utilized in contact-rich manipulation tasks to model the complicated contact dynamics. However, NN-based models are often difficult to decipher which can lead to seemingly inexplicable behaviors and unidentifiable failure cases. In this work, we address the interpretability of NN-based models by introducing the kinodynamic images. We propose a methodology that creates images from kinematic and dynamic data of contact-rich manipulation tasks. By using images as the state representation, we enable the application of interpretability modules that were previously limited to vision-based tasks. We use this representation to train a Convolutional Neural Network (CNN) and we extract interpretations with Grad-CAM to produce visual explanations. Our method is versatile and can be applied to any classification problem in manipulation tasks to visually interpret which parts of the input drive the model\u2019s decisions and distinguish its failure modes, regardless of the features used. Our experiments demonstrate that our method enables detailed visual inspections of sequences in a task, and high-level evaluations of a model\u2019s behavior. Code for this work is available at [1].",
        "primary_area": "",
        "author": "Ioanna Mitsioni;Joonatan M\u00e4ntt\u00e4ri;Yiannis Karayiannidis;John Folkesson;Danica Kragic;Ioanna Mitsioni;Joonatan M\u00e4ntt\u00e4ri;Yiannis Karayiannidis;John Folkesson;Danica Kragic",
        "authorids": "/37086293438;/37086488007;/37300987100;/37282372400;/37281296000;/37086293438;/37086488007;/37300987100;/37282372400;/37281296000",
        "aff": "Division of Robotics, Perception and Learning (RPL), CAS, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning (RPL), CAS, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Dept. of Electrical Engineering, Division of Systems and Control, Chalmers University of Technology, Gothenburg, Sweden; Division of Robotics, Perception and Learning (RPL), CAS, EECS, KTH Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning (RPL), CAS, EECS, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560920/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8345359717463124278&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "KTH Royal Institute of Technology;Chalmers University of Technology",
        "aff_unique_dep": "Division of Robotics, Perception and Learning (RPL);Dept. of Electrical Engineering, Division of Systems and Control",
        "aff_unique_url": "https://www.kth.se;https://www.chalmers.se",
        "aff_unique_abbr": "KTH;Chalmers",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Stockholm;Gothenburg",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9560849",
        "title": "Interpretable Goal-based Prediction and Planning for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an integrated prediction and planning system for autonomous driving which uses rational inverse planning to recognise the goals of other vehicles. Goal recognition informs a Monte Carlo Tree Search (MCTS) algorithm to plan optimal maneuvers for the ego vehicle. Inverse planning and MCTS utilise a shared set of defined maneuvers and macro actions to construct plans which are explainable by means of rationality principles. Evaluation in simulations of urban driving scenarios demonstrate the system\u2019s ability to robustly recognise the goals of other vehicles, enabling our vehicle to exploit non-trivial opportunities to significantly reduce driving times. In each scenario, we extract intuitive explanations for the predictions which justify the system\u2019s decisions.",
        "primary_area": "",
        "author": "Stefano V. Albrecht;Cillian Brewitt;John Wilhelm;Balint Gyevnar;Francisco Eiras;Mihai Dobre;Subramanian Ramamoorthy;Stefano V. Albrecht;Cillian Brewitt;John Wilhelm;Balint Gyevnar;Francisco Eiras;Mihai Dobre;Subramanian Ramamoorthy",
        "authorids": "/37088996736;/37088995850;/37088761487;/37088998776;/37086581181;/37085732104;/37529920500;/37088996736;/37088995850;/37088761487;/37088998776;/37086581181;/37085732104;/37529920500",
        "aff": "School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; Department of Engineering Science, University of Oxford, UK; FiveAI Ltd., UK; School of Informatics, University of Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560849/",
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11440007353769468582&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;0",
        "aff_unique_norm": "University of Edinburgh;University of Oxford;FiveAI Ltd.",
        "aff_unique_dep": "School of Informatics;Department of Engineering Science;",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.ox.ac.uk;",
        "aff_unique_abbr": "Edinburgh;Oxford;",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Edinburgh;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9560825",
        "title": "Interpreting Contact Interactions to Overcome Failure in Robot Assembly Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "A key challenge towards autonomous multi-part object assembly is robust sensorimotor control under uncertainty. In contrast to previous works that rely on a priori knowledge on whether two parts match, we aim to learn this through physical interaction. We propose a hierarchical approach that enables a robot to autonomously assemble parts while being uncertain about part types and positions. In particular, our probabilistic approach learns a set of differentiable filters that leverage the tactile sensorimotor trace from failed assembly attempts to update its belief about part position and type. This enables a robot to overcome assembly failure. We demonstrate the effectiveness of our approach on a set of object fitting tasks. The experimental results show that the proposed approach achieves higher precision in object position and type estimation, and accomplishes object fitting tasks faster than baselines.",
        "primary_area": "",
        "author": "Peter A. Zachares;Michelle A. Lee;Wenzhao Lian;Jeannette Bohg;Peter A. Zachares;Michelle A. Lee;Wenzhao Lian;Jeannette Bohg",
        "authorids": "/37088414588;/37086935666;/37088998889;/37591153900;/37088414588;/37086935666;/37088998889;/37591153900",
        "aff": "Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; X, The Moonshot Factory; Department of Computer Science, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560825/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12068909114938596221&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Stanford University;X Development LLC",
        "aff_unique_dep": "Department of Computer Science;",
        "aff_unique_url": "https://www.stanford.edu;https://xdevllc.com",
        "aff_unique_abbr": "Stanford;X",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561749",
        "title": "Introspective Visuomotor Control: Exploiting Uncertainty in Deep Visuomotor Control for Failure Recovery",
        "track": "main",
        "status": "Poster",
        "abstract": "End-to-end visuomotor control is emerging as a compelling solution for robot manipulation tasks. However, imitation learning-based visuomotor control approaches tend to suffer from a common limitation, lacking the ability to recover from an out-of-distribution state caused by compounding errors. In this paper, instead of using tactile feedback or explicitly detecting the failure through vision, we investigate using the uncertainty of a policy neural network. We propose a novel uncertainty-based approach to detect and recover from failure cases. Our hypothesis is that policy uncertainties can implicitly indicate the potential failures in the visuomotor control task and that robot states with minimum uncertainty are more likely to lead to task success. To recover from high uncertainty cases, the robot monitors its uncertainty along a trajectory and explores possible actions in the state-action space to bring itself to a more certain state. Our experiments verify this hypothesis and show a significant improvement on task success rate: 12% in pushing, 15% in pick-and-reach and 22% in pick-and-place.",
        "primary_area": "",
        "author": "Chia-Man Hung;Li Sun;Yizhe Wu;Ioannis Havoutis;Ingmar Posner;Chia-Man Hung;Li Sun;Yizhe Wu;Ioannis Havoutis;Ingmar Posner",
        "authorids": "/37088998853;/37088997838;/37089001627;/37542879900;/37601368300;/37088998853;/37088997838;/37089001627;/37542879900;/37601368300",
        "aff": "Dynamic Robot Systems (DRS) Oxford Robotics Institute (ORI), University of Oxford; Applied AI Lab (A2I) Oxford Robotics Institute (ORI), University of Oxford; Applied AI Lab (A2I) Oxford Robotics Institute (ORI), University of Oxford; Dynamic Robot Systems (DRS) Oxford Robotics Institute (ORI), University of Oxford; Applied AI Lab (A2I) Oxford Robotics Institute (ORI), University of Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561749/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8131242720999594729&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561951",
        "title": "Invariant EKF based 2D Active SLAM with Exploration Task",
        "track": "main",
        "status": "Poster",
        "abstract": "Right invariant extended Kalman filter (RIEKF) based simultaneous localization and mapping (SLAM) proposed recently has shown to be able to produce more consistent SLAM estimates as compared with traditional EKF based SLAM methods, including some improved EKF SLAM methods such as observability constrained-EKF (OC-EKF) SLAM. Latest results have demonstrated that its performance is very close to optimization based SLAM algorithms such as iSAM. In this paper, we propose to use RIEKF SLAM algorithm in active SLAM where both the predicted SLAM results for choosing control actions and the actual estimated SLAM results applying the selected control actions are computed using RIEKF algorithms. The advantages over traditional EKF based active SLAM are the more accurate and consistent predicted uncertainty estimates which result in robustness of the active SLAM algorithm. The advantages over optimization based active SLAM is the reduced computational cost. Simulation results are presented to validate the advantages of the proposed algorithm3.",
        "primary_area": "",
        "author": "Mengya Xu;Yang Song;Yongbo Chen;Shoudong Huang;Qi Hao;Mengya Xu;Yang Song;Yongbo Chen;Shoudong Huang;Qi Hao",
        "authorids": "/37089000274;/37088999165;/37086455426;/37421307400;/37403530000;/37089000274;/37088999165;/37086455426;/37421307400;/37403530000",
        "aff": "Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Centre for Autonomous Systems, University of Technology Sydney, NSW, Australia; Centre for Autonomous Systems, University of Technology Sydney, NSW, Australia; Centre for Autonomous Systems, University of Technology Sydney, NSW, Australia; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561951/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=555514049428560610&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Southern University of Science and Technology;University of Technology Sydney",
        "aff_unique_dep": "Department of Computer Science and Engineering;Centre for Autonomous Systems",
        "aff_unique_url": "https://www.sustech.edu.cn;https://www.uts.edu.au",
        "aff_unique_abbr": "SUSTech;UTS",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Shenzhen;Sydney",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "China;Australia"
    },
    {
        "id": "9561150",
        "title": "Invariant Extended Kalman Filtering Using Two Position Receivers for Extended Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers the use of two position receivers and an inertial measurement unit (IMU) to estimate the position, velocity, and attitude of a rigid body, collectively called extended pose. The measurement model consisting of the position of one receiver and the relative position between the two receivers is left invariant, enabling the use of the invariant extended Kalman filter (IEKF) framework. The IEKF possesses various advantages over the standard multiplicative extended Kalman filter, such as state-estimate-independent Jacobians. Monte Carlo simulations demonstrate that the two-receiver IEKF approach yields improved estimates over a two-receiver multiplicative extended Kalman filter (MEKF) and a singlereceiver IEKF approach. An experiment further validates the proposed approach, confirming that the two-receiver IEKF has improved performance over the other filters considered.",
        "primary_area": "",
        "author": "Natalia Pavlasek;Alex Walsh;James Richard Forbes;Natalia Pavlasek;Alex Walsh;James Richard Forbes",
        "authorids": "/37089001442;/37085354826;/37543396800;/37089001442;/37085354826;/37543396800",
        "aff": "Department of Mechanical Engineering, McGill University, Montreal, QC, Canada; Alex Walsh; Department of Mechanical Engineering, McGill University, Montreal, QC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561150/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14056551792483304393&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "McGill University;",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.mcgill.ca;",
        "aff_unique_abbr": "McGill;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Montreal;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada;"
    },
    {
        "id": "9560906",
        "title": "Inverse Dynamics Control of Compliant Hybrid Zero Dynamic Walking",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a trajectory planning and control architecture for bipedal locomotion at a variety of speeds on a highly underactuated and compliant bipedal robot. A library of compliant walking trajectories are planned offline, and stored as compact arrays of polynomial coefficients for tracking online. The control implementation uses a floating-base inverse dynamics controller which generates dynamically consistent feedforward torques to realize walking using information obtained from the trajectory optimization. The effectiveness of the controller is demonstrated in simulation and on hardware for walking both indoors on flat terrain and over unplanned disturbances outdoors. Additionally, both the controller and optimization source code are made available on GitHub.",
        "primary_area": "",
        "author": "Jenna Reher;Aaron D. Ames;Jenna Reher;Aaron D. Ames",
        "authorids": "/37085715578;/37300877900;/37085715578;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560906/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15382895863615845495&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561306",
        "title": "Inverse Dynamics vs. Forward Dynamics in Direct Transcription Formulations for Trajectory Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Benchmarks of state-of-the-art rigid-body dynamics libraries report better performance solving the inverse dynamics problem than the forward alternative. Those benchmarks encouraged us to question whether that computational advantage would translate to direct transcription, where calculating rigid-body dynamics and their derivatives accounts for a significant share of computation time. In this work, we implement an optimization framework where both approaches for enforcing the system dynamics are available. We evaluate the performance of each approach for systems of varying complexity, for domains with rigid contacts. Our tests reveal that formulations using inverse dynamics converge faster, require less iterations, and are more robust to coarse problem discretization. These results indicate that inverse dynamics should be preferred to enforce the nonlinear system dynamics in simultaneous methods, such as direct transcription.",
        "primary_area": "",
        "author": "Henrique Ferrolho;Vladimir Ivan;Wolfgang Merkt;Ioannis Havoutis;Sethu Vijayakumar;Henrique Ferrolho;Vladimir Ivan;Wolfgang Merkt;Ioannis Havoutis;Sethu Vijayakumar",
        "authorids": "/37086190451;/37085552022;/37086118415;/37542879900;/37295595500;/37086190451;/37085552022;/37086118415;/37542879900;/37295595500",
        "aff": "School of Informatics, University of Edinburgh, United Kingdom; School of Informatics, University of Edinburgh, United Kingdom; Oxford Robotics Institute, University of Oxford, United Kingdom; Oxford Robotics Institute, University of Oxford, United Kingdom; School of Informatics, University of Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561306/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=627986006675519663&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 15,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "University of Edinburgh;University of Oxford",
        "aff_unique_dep": "School of Informatics;Oxford Robotics Institute",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.ox.ac.uk",
        "aff_unique_abbr": "Edinburgh;Oxford",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Edinburgh;Oxford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561182",
        "title": "Investigation of Multiple Resource Theory Design Principles on Robot Teleoperation and Workload Management",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot interfaces often only use the visual channel. Inspired by Wickens\u2019 Multiple Resource Theory, we investigated if the addition of audio elements would reduce cognitive workload and improve performance. Specifically, we designed a search and threat-defusal task (primary) with a memory test task (secondary). Eleven participants \u2013 predominantly first responders \u2013 were recruited to control a robot to clear all threats in a combination of four conditions of primary and secondary tasks in visual and auditory channels. While we did not find any statistically significant differences in performance or workload across subjects, making it questionable that Multiple Resource Theory could shorten longer-term task completion time and reduce workload. Our results suggest that considering individual differences for splitting interface modalities across multiple channels requires further investigation.",
        "primary_area": "",
        "author": "Zhao Han;Adam Norton;Eric McCann;Lisa Baraniecki;Will Ober;Dave Shane;Anna Skinner;Holly A. Yanco;Zhao Han;Adam Norton;Eric McCann;Lisa Baraniecki;Will Ober;Dave Shane;Anna Skinner;Holly A. Yanco",
        "authorids": "/37086803826;/38059491100;/38075114500;/37088999239;/37086733877;/37086733750;/37088997809;/37282462100;/37086803826;/38059491100;/38075114500;/37088999239;/37086733877;/37086733750;/37088997809;/37282462100",
        "aff": "University of Massachusetts Lowell, Lowell, MA; University of Massachusetts Lowell, Lowell, MA; University of Massachusetts Lowell, Lowell, MA; AnthroTronix, Inc, Silver Spring, MD; Boston Engineering Corp, Waltham, MA; Boston Engineering Corp, Waltham, MA; AnthroTronix, Inc, Silver Spring, MD; University of Massachusetts Lowell, Lowell, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561182/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12389962261322791927&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;2;2;1;0",
        "aff_unique_norm": "University of Massachusetts Lowell;AnthroTronix, Inc;Boston Engineering Corp",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.uml.edu;;",
        "aff_unique_abbr": "UMass Lowell;;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lowell;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561094",
        "title": "Investigation of Unmanned Aerial Vehicle Gesture Perceptibility and Impact of Viewpoint Variance",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned Aerial Vehicle (UAV) flight paths have been shown to communicate meaning to human observers, similar to human gestural communication. This paper presents the results of a UAV gesture perception study designed to assess how observer viewpoint perspective may impact how humans perceive the shape of UAV gestural motion. Robot gesture designers have demonstrated that robots can indeed communicate meaning through gesture; however, many of these results are limited to an idealized range of viewer perspectives and do not consider how the perception of a robot gesture may suffer from obfuscation or self-occlusion from some viewpoints. This paper presents the results of three online user-studies that examine participants' ability to accurately perceive the intended shape of two-dimensional UAV gestures from varying viewer perspectives. We used a logistic regression model to characterize participant gesture classification accuracy, demonstrating that viewer perspective does impact how participants perceive the shape of UAV gestures. Our results yielded a viewpoint angle threshold from beyond which participants were able to assess the intended shape of a gesture's motion with 90% accuracy. We also introduce a perceptibility score to capture user confidence, time to decision, and accuracy in labeling and to understand how differences in flight paths impact perception across viewpoints. These findings will enable UAV gesture systems that, with a high degree of confidence, ensure gesture motions can be accurately perceived by human observers.",
        "primary_area": "",
        "author": "Paul Fletcher;Angeline Luther;Brittany Duncan;Carrick Detweiler;Paul Fletcher;Angeline Luther;Brittany Duncan;Carrick Detweiler",
        "authorids": "/37089000102;/37088419771;/37408070300;/38535355300;/37089000102;/37088419771;/37408070300;/38535355300",
        "aff": "NIMBUS Lab in the Department of Computer Science and Engineering, University of Nebraska, Lincoln, NE, USA; NIMBUS Lab in the Department of Computer Science and Engineering, University of Nebraska, Lincoln, NE, USA; NIMBUS Lab in the Department of Computer Science and Engineering, University of Nebraska, Lincoln, NE, USA; NIMBUS Lab in the Department of Computer Science and Engineering, University of Nebraska, Lincoln, NE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561094/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7138319600755629493&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Nebraska",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.unl.edu",
        "aff_unique_abbr": "UNL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lincoln",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561712",
        "title": "Investigations on Output Parameterizations of Neural Networks for Single Shot 6D Object Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Single shot approaches have demonstrated tremendous success on various computer vision tasks. Finding good parameterizations for 6D object pose estimation remains an open challenge. In this work, we propose different novel parameterizations for the output of the neural network for single shot 6D object pose estimation. Our learning-based approach achieves state-of-the-art performance on two public benchmark datasets. Furthermore, we demonstrate that the pose estimates can be used for real-world robotic grasping tasks without additional ICP refinement.",
        "primary_area": "",
        "author": "Kilian Kleeberger;Markus V\u00f6lk;Richard Bormann;Marco F. Huber;Kilian Kleeberger;Markus V\u00f6lk;Richard Bormann;Marco F. Huber",
        "authorids": "/37087323129;/37088690304;/38541025900;/37392400600;/37087323129;/37088690304;/38541025900;/37392400600",
        "aff": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Fraunhofer Institute for Manufacturing Engineering and Automation IPA, Stuttgart, Germany; Institute of Industrial Manufacturing and Management IFF, University of Stuttgart, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561712/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1087356376136521084&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Fraunhofer Institute for Manufacturing Engineering and Automation IPA;University of Stuttgart",
        "aff_unique_dep": ";Institute of Industrial Manufacturing and Management IFF",
        "aff_unique_url": "https://www.ipa.fraunhofer.de;https://www.uni-stuttgart.de",
        "aff_unique_abbr": "Fraunhofer IPA;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561110",
        "title": "Joint Object Detection and Multi-Object Tracking with Graph Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Object detection and data association are critical components in multi-object tracking (MOT) systems. Despite the fact that the two components are dependent on each other, prior works often design detection and data association modules separately which are trained with separate objectives. As a result, one cannot back-propagate the gradients and optimize the entire MOT system, which leads to sub-optimal performance. To address this issue, recent works simultaneously optimize detection and data association modules under a joint MOT framework, which has shown improved performance in both modules. In this work, we propose a new instance of joint MOT approach based on Graph Neural Networks (GNNs). The key idea is that GNNs can model relations between variablesized objects in both the spatial and temporal domains, which is essential for learning discriminative features for detection and data association. Through extensive experiments on the MOT15/16/17/20 datasets, we demonstrate the effectiveness of our GNN-based joint MOT approach and show state-of-the-art performance for both detection and MOT tasks.",
        "primary_area": "",
        "author": "Yongxin Wang;Kris Kitani;Xinshuo Weng;Yongxin Wang;Kris Kitani;Xinshuo Weng",
        "authorids": "/37088459463;/37294510900;/37086376142;/37088459463;/37294510900;/37086376142",
        "aff": "Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561110/",
        "gs_citation": 382,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14710400670742394568&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561778",
        "title": "Joint Representation of Temporal Image Sequences and Object Motion for Video Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a new video object detection (VoD) method, referred to as temporal feature aggregation and motion-aware VoD (TM-VoD), that produces a joint representation of temporal image sequences and object motion. The TM-VoD generates strong spatiotemporal features for VOD by temporally redundant information in an image sequence and the motion context. These are produced at the feature level in the region proposal stage and at the instance level in the refinement stage. In the region proposal stage, visual features are temporally fused with appropriate weights at the pixel level via gated attention model. Furthermore, pixel level motion features are obtained by capturing the changes between adjacent visual feature maps. In the refinement stage, the visual features are aligned and aggregated at the instance level. We propose a novel feature alignment method, which uses the initial region proposals as anchors to predict the box coordinates for all video frames. Moreover, the instance level motion features are obtained by applying the region of interest (RoI) pooling to the pixel level motion features and by encoding the sequential changes in the box coordinates. Finally, all these instance level features are concatenated to produce a joint representation of the objects. Experiments on the ImageNet VID dataset demonstrate that the proposed method significantly outperforms existing VoDs and achieves performance comparable with that of state-of-the-art VoDs.",
        "primary_area": "",
        "author": "Junho Koh;Jaekyum Kim;Younji Shin;Byeongwon Lee;Seungji Yang;Jun Won Choi;Junho Koh;Jaekyum Kim;Younji Shin;Byeongwon Lee;Seungji Yang;Jun Won Choi",
        "authorids": "/37086487628;/37085788691;/37088996216;/37088368362;/37086768104;/37405961800;/37086487628;/37085788691;/37088996216;/37088368362;/37086768104;/37405961800",
        "aff": "Department of Electrical Engineering, Hanyang University, Seoul, Korea; Department of Electrical Engineering, Hanyang University, Seoul, Korea; Department of Electrical Engineering, Hanyang University, Seoul, Korea; T3K Vision AI Product Center of Excellence, SK Telecom, Seongnam, Korea; T3K Vision AI Product Center of Excellence, SK Telecom, Seongnam, Korea; Department of Electrical Engineering, Hanyang University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561778/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16038230701314445380&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "Hanyang University;SK Telecom",
        "aff_unique_dep": "Department of Electrical Engineering;T3K Vision AI Product Center of Excellence",
        "aff_unique_url": "http://www.hanyang.ac.kr;https://www.sktelecom.com",
        "aff_unique_abbr": "HYU;SK Telecom",
        "aff_campus_unique_index": "0;0;0;1;1;0",
        "aff_campus_unique": "Seoul;Seongnam",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561324",
        "title": "KFS-LIO: Key-Feature Selection for Lightweight Lidar Inertial Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Feature-based lidar odometry methods have attracted increasing attention due to their low computational cost. However, theoretically analysis of the effect of extracted features on pose estimation is still lacked. In this paper, we propose a method of key-feature selection for lightweight lidar inertial odometry, KFS-LIO, to further enhance the real-time performance by selecting the most effective subset of lidar feature constraints. Aiming at explaining the correlation between the feature distribution and state errors, a quantitative evaluation method of lidar constraints is introduced. In addition, to avoid recalculating the reprojection matrices in de-skewing step, we use the intermediate variables in IMU preintegration to compensate for lidar motion distortion. The experimental results demonstrate that KFS-LIO can reduce half of the LOAM features and provide comparable accuracy with the state-of-the-art odometry.",
        "primary_area": "",
        "author": "Wei Li;Yu Hu;Yinhe Han;Xiaowei Li;Wei Li;Yu Hu;Yinhe Han;Xiaowei Li",
        "authorids": "/37089000125;/37277445400;/37280848500;/37280862300;/37089000125;/37277445400;/37280848500;/37280862300",
        "aff": "Research Center for Intelligent Computing Systems, Institute of Computing Technology, the Chinese Academy of Sciences, Beijing, China; Research Center for Intelligent Computing Systems, Institute of Computing Technology, the Chinese Academy of Sciences, Beijing, China; Research Center for Intelligent Computing Systems, Institute of Computing Technology, the Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, the Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561324/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14877250261889303594&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chinese Academy of Sciences",
        "aff_unique_dep": "Institute of Computing Technology",
        "aff_unique_url": "http://www.cas.cn",
        "aff_unique_abbr": "CAS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561501",
        "title": "Kernel-Based 3-D Dynamic Occupancy Mapping with Particle Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "Mapping three-dimensional (3-D) dynamic environments is essential for aerial robots but challenging to consider the increased dimensions in both space and time compared to 2-D static mapping. This paper presents a kernel-based 3-D dynamic occupancy mapping algorithm, K3DOM, that distinguishes between static and dynamic objects while estimating the velocities of dynamic cells via particle tracking. The proposed algorithm brings the benefits of kernel inference such as its simple computation, consideration of spatial correlation, and natural measure of uncertainty to the domain of dynamic mapping. We formulate the dynamic occupancy mapping problem in a Bayesian framework and represent the map through Dirichlet distribution to update posteriors in a recursive way with intuitive heuristics. The proposed algorithm demonstrates its promising performance compared to baseline in diverse scenarios simulated in ROS environments.",
        "primary_area": "",
        "author": "Youngjae Min;Do-Un Kim;Han-Lim Choi;Youngjae Min;Do-Un Kim;Han-Lim Choi",
        "authorids": "/37087015731;/37089001914;/37308867500;/37087015731;/37089001914;/37308867500",
        "aff": "Department of Aerospace Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea; Department of Aerospace Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea; Department of Aerospace Engineering, Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561501/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7417054609035447109&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Aerospace Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561090",
        "title": "Kimera-Multi: a System for Distributed Multi-Robot Metric-Semantic Simultaneous Localization and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the first fully distributed multi-robot system for dense metric-semantic Simultaneous Localization and Mapping (SLAM). Our system, dubbed Kimera-Multi, is implemented by a team of robots equipped with visual-inertial sensors, and builds a 3D mesh model of the environment in real-time, where each face of the mesh is annotated with a semantic label (e.g., building, road, objects). In Kimera-Multi, each robot builds a local trajectory estimate and a local mesh using Kimera [1]. Then, when two robots are within communication range, they initiate a distributed place recognition and robust pose graph optimization protocol with a novel incremental maximum clique outlier rejection; the protocol allows the robots to improve their local trajectory estimates by leveraging inter-robot loop closures. Finally, each robot uses its improved trajectory estimate to correct the local mesh using mesh deformation techniques. We demonstrate Kimera-Multi in photo-realistic simulations and real data. Kimera-Multi (i) is able to build accurate 3D metric-semantic meshes, (ii) is robust to incorrect loop closures while requiring less computation than state-of-the-art distributed SLAM backends, and (iii) is efficient, both in terms of computation at each robot as well as communication bandwidth.",
        "primary_area": "",
        "author": "Yun Chang;Yulun Tian;Jonathan P. How;Luca Carlone;Yun Chang;Yulun Tian;Jonathan P. How;Luca Carlone",
        "authorids": "/37087500049;/37088451604;/37276347700;/37545784100;/37087500049;/37088451604;/37276347700;/37545784100",
        "aff": "Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory for Information & Decision Systems, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561090/",
        "gs_citation": 97,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6289694349735723201&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information & Decision Systems",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560741",
        "title": "Kinematic Stability based AFG-RRT Path Planning for Cable-Driven Parallel Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning for Cable-Driven Parallel Robots (CDPRs) is a challenging task due to various restrictions on cable tensions, collisions and obstacle avoidance. The presented work aims at proposing an optimal path planning strategy in order to both maximize the wrench capability and the dexterity of the robot in a cluttered environment. First, an asymptoticallyoptimal path finding method based on a variant of rapidly exploring random trees (RRT) is implemented along with the GilbertJohnsonKeerthi (GJK) algorithm to account for the collision detections. Then, a goal biased Artificial Field Guide (AFG) is employed to reduce convergence time and ensure directional exploration. Finally, a post-processing algorithm is added to get a short and smooth resultant path by fitting appropriate splines. The proposed path planning strategy is analyzed and demonstrated on a simulated and experimental setup of a six-DOF spatial CDPR.",
        "primary_area": "",
        "author": "Utkarsh A. Mishra;Marceau M\u00e9tillon;St\u00e9phane Caro;Utkarsh A. Mishra;Marceau M\u00e9tillon;St\u00e9phane Caro",
        "authorids": "/37088490178;/37088997878;/37589701400;/37088490178;/37088997878;/37589701400",
        "aff": "Mechanical and Industrial Department, Indian Institute of Technology, Roorkee, Uttrakhand, India; CNRS, Laboratoire des Sciences du Num\u00e9rique de Nantes, UMR CNRS, Nantes, France; CNRS, Laboratoire des Sciences du Num\u00e9rique de Nantes, UMR CNRS, Nantes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560741/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=375112659276980518&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Indian Institute of Technology Roorkee;CNRS",
        "aff_unique_dep": "Mechanical and Industrial Department;Laboratoire des Sciences du Num\u00e9rique de Nantes",
        "aff_unique_url": "https://www.iitr.ac.in;https://www.cnrs.fr",
        "aff_unique_abbr": "IIT Roorkee;CNRS",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Roorkee;Nantes",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "India;France"
    },
    {
        "id": "9561634",
        "title": "Kinematic analysis of a flexible surgical instrument for robot-assisted minimally invasive surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Flexible surgical instruments can flexibly adjust their posture with a high degree of freedom, which makes them highly suitable for performing surgical tasks in narrow workspaces. However, redundant degrees of freedom increase their kinematic difficulty, which may cause redundant solutions, complex calculations, and low speeds. In this paper, a flexible surgical instrument is presented. The structural characteristics of this flexible instrument were explored in terms of force balance, it was concluded that the instrument had a constant curvature during bending. Based on this, the kinematics and inverse kinematics were solved via the geometric and Newton iteration methods, respectively. Our experiments showed that the proposed method for solving flexible instrument kinematics had high precision, a unique solution, and high speed; the instrument can be well controlled to perform refined operations. The proposed geometric method for solving the flexible instrument kinematics avoided the calculation of the Jacobian matrix, making it fast and capable of meeting the master-slave control requirement for real-time surgery. Furthermore, the proposed kinematics solution method is not limited by the mechanical structure, so it can be used for flexible instruments owning to its constant curvature bending.",
        "primary_area": "",
        "author": "Mei Feng;Zhixue Ni;Yili Fu;Xingze Jin;Wei Liu;Xiuquan Lu;Mei Feng;Zhixue Ni;Yili Fu;Xingze Jin;Wei Liu;Xiuquan Lu",
        "authorids": "/37086163095;/37089000402;/37286601800;/37086158820;/37088999502;/37088997599;/37086163095;/37089000402;/37286601800;/37086158820;/37088999502;/37088997599",
        "aff": "Key Laboratory of CNC Equipment Reliability, Ministry of Education, School of Mechanical and Aerospace Engineering, Jilin University, Changchun, China; Key Laboratory of CNC Equipment Reliability, Ministry of Education, School of Mechanical and Aerospace Engineering, Jilin University, Changchun, China; State Key Lab Robot & Systems, Harbin Institute of Technology, Harbin, China; Key Laboratory of CNC Equipment Reliability, Ministry of Education, School of Mechanical and Aerospace Engineering, Jilin University, Changchun, China; Norman Bethune Health Science Center of Jilin University, Changchun, China; Key Laboratory of CNC Equipment Reliability, Ministry of Education, School of Mechanical and Aerospace Engineering, Jilin University, Changchun, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561634/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2622709736214384866&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Jilin University;Harbin Institute of Technology",
        "aff_unique_dep": "School of Mechanical and Aerospace Engineering;State Key Lab Robot & Systems",
        "aff_unique_url": "http://www.jlu.edu.cn;http://www.hit.edu.cn/",
        "aff_unique_abbr": "JLU;HIT",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Changchun;Harbin",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561341",
        "title": "Kinesthetic feedback improves grasp performance in cable-driven prostheses",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite significant progress in the realm of upper-limb prosthetic design, end-users still abandon modern myoelectric prostheses, with haptic feedback listed as a primary need. The passive scheme of cable-driven body-powered prostheses provides kinesthetic sensory information to the user but can also lead to discomfort and fatigue due to the large loads applied to the body during operation. In order to investigate the role of this kinesthetic feedback on grasp force control, we design a body-powered prosthesis emulator capable of varying the amount of displayed force feedback along a continuous scale. Using this experimental test bed, we collect data from 9 participants while they perform a grasp and lift task. Analysis shows that, with increasing amounts of force feedback, people produce lower and steadier grasp forces but also become more prone to dropping held objects. These results suggest that the use of moderate amounts of feedback provides significant grasp performance benefits while also mitigating some of the shortcomings of cable-driven prostheses. These findings support the continued study of the incorporation of kinesthetic feedback into novel prosthetic designs.",
        "primary_area": "",
        "author": "Michael E. Abbott;Joshua D. Fajardo;H.W. Lim;Hannah S. Stuart;Michael E. Abbott;Joshua D. Fajardo;H.W. Lim;Hannah S. Stuart",
        "authorids": "/37088476766;/37089000163;/37088996254;/37085437460;/37088476766;/37089000163;/37088996254;/37085437460",
        "aff": "Dept. of Mechanical Engineering, Embodied Dexterity Group, University of California Berkeley, Berkeley, CA, USA; Dept. of Mechanical Engineering, Embodied Dexterity Group, University of California Berkeley, Berkeley, CA, USA; Dept. of Mechanical Engineering, University College London, London, England; Dept. of Mechanical Engineering, Embodied Dexterity Group, University of California Berkeley, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561341/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9645291684036899018&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;University College London",
        "aff_unique_dep": "Department of Mechanical Engineering;Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu;https://www.ucl.ac.uk",
        "aff_unique_abbr": "UC Berkeley;UCL",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Berkeley;London",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9561795",
        "title": "Kinetostatics for variable cross-section continuum manipulators",
        "track": "main",
        "status": "Poster",
        "abstract": "Continuum manipulators have shown a wide range of applications due to their inherent compliance and dexterity. At present, the cross-sectional dimension of these manipulators is often kept constant, which facilitates the design, fabrication and modeling processes. The famous piecewise-constant-curvature (PCC) assumption is widely used in the kinematics and motion control. By contrast, most natural creatures that have continuum structures usually exhibit variable cross sections, such as the elephant trunk and the octopus tentacle. Inspired by these creatures, variable cross-section continuum manipulators have been proposed in literature. For variable cross-section, the PCC assumption is no longer valid. In fact, the manipulator\u2019s kinematics and statics are coupled, which should be considered and solved together. This paper establishes the general kinetostatic model of variable cross-section continuum manipulators, and performs experimental validations under various actuating and loading situations. Results showed that the proposed model has satisfactory accuracy in predicting the manipulator profile under various actuating and loading situations. The average root-mean-square error of the proposed model was 1.67 mm, and even the maximum error did not exceed 2.6 mm, according to all the 51 groups of tests on three 100 mm long prototypes. Furthermore, results also indicated that Type-1 manipulator (only varying the spacer dimension) has larger deflections and tends to be \"softer\" than Type-2 manipulator (only varying the backbone cross-sectional area). Results of this paper could be helpful for the design and analysis of variable cross-section continuum manipulators.",
        "primary_area": "",
        "author": "Han Yuan;Zuan Li;Wenfu Xu;Han Yuan;Zuan Li;Wenfu Xu",
        "authorids": "/37086032159;/37089000788;/37291470000;/37086032159;/37089000788;/37291470000",
        "aff": "School of Mechanical Engineering and Automation, Harbin Institute of Technology Shenzhen, Shenzhen, PR China; School of Mechanical Engineering and Automation, Harbin Institute of Technology Shenzhen, Shenzhen, PR China; School of Mechanical Engineering and Automation, Harbin Institute of Technology Shenzhen, Shenzhen, PR China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561795/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5486449674865624627&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "School of Mechanical Engineering and Automation",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562002",
        "title": "Koopman NMPC: Koopman-based Learning and Nonlinear Model Predictive Control of Control-affine Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Koopman-based learning methods can potentially be practical and powerful tools for dynamical robotic systems. However, common methods to construct Koopman representations seek to learn lifted linear models that cannot capture nonlinear actuation effects inherent in many robotic systems. This paper presents a learning and control methodology that is a first step towards overcoming this limitation. Using the Koopman canonical transform, control-affine dynamics can be expressed by a lifted bilinear model. The learned model is used for nonlinear model predictive control (NMPC) design where the bilinear structure can be exploited to improve computational efficiency. The benefits for control-affine dynamics compared to existing Koopman-based methods are highlighted through an example of a simulated planar quadrotor. Prediction error is greatly reduced and closed loop performance similar to NMPC with full model knowledge is achieved.",
        "primary_area": "",
        "author": "Carl Folkestad;Joel W. Burdick;Carl Folkestad;Joel W. Burdick",
        "authorids": "/37088482867;/37265975700;/37088482867;/37265975700",
        "aff": "Division of Engineering and Applied Sciences, California Institute of Technology, Pasadena, CA, USA; Division of Engineering and Applied Sciences, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562002/",
        "gs_citation": 74,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13816007033515677837&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Division of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561263",
        "title": "LAFFNet: A Lightweight Adaptive Feature Fusion Network for Underwater Image Enhancement",
        "track": "main",
        "status": "Poster",
        "abstract": "Underwater image enhancement is an important low-level computer vision task for autonomous underwater vehicles and remotely operated vehicles to explore and understand the underwater environments. Recently, deep convolutional neural networks (CNNs) have been successfully used in many computer vision problems, and so does underwater image enhancement. There are many deep-learning-based methods with impressive performance for underwater image enhancement, but their memory and model parameter costs are hindrances in practical application. To address this issue, we propose a lightweight adaptive feature fusion network (LAFFNet). The model is the encoder-decoder model with multiple adaptive feature fusion (AAF) modules. AAF subsumes multiple branches with different kernel sizes to generate multi-scale feature maps. Furthermore, channel attention is used to merge these feature maps adaptively. Our method reduces the number of parameters from 2.5M to 0.15M (around 94% reduction) but outperforms state-of-the-art algorithms by extensive experiments. Furthermore, we demonstrate our LAFFNet effectively improves high-level vision tasks like salience object detection and single image depth estimation.",
        "primary_area": "",
        "author": "Hao-Hsiang Yang;Kuan-Chih Huang;Wei-Ting Chen;Hao-Hsiang Yang;Kuan-Chih Huang;Wei-Ting Chen",
        "authorids": "/37087245013;/37088999620;/37086524660;/37087245013;/37088999620;/37086524660",
        "aff": "ASUS Intelligent Cloud Services, Asustek Computer Inc., Taipei, Taiwan; ASUS Intelligent Cloud Services, Asustek Computer Inc., Taipei, Taiwan; Graduate Institute of Electronics Engineering, National Taiwan University, Taipei, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561263/",
        "gs_citation": 95,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3156758709717845809&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "ASUSTeK Computer Inc.;National Taiwan University",
        "aff_unique_dep": "ASUS Intelligent Cloud Services;Graduate Institute of Electronics Engineering",
        "aff_unique_url": "https://www.asus.com;https://www.ntu.edu.tw",
        "aff_unique_abbr": "ASUS;NTU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561232",
        "title": "LASER: Learning a Latent Action Space for Efficient Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The process of learning a manipulation task depends strongly on the action space used for exploration: posed in the incorrect action space, solving a task with reinforcement learning can be drastically inefficient. Additionally, similar tasks or instances of the same task family impose latent manifold constraints on the most effective action space: the task family can be best solved with actions in a manifold of the entire action space of the robot. Combining these insights we present LASER, a method to learn latent action spaces for efficient reinforcement learning. LASER factorizes the learning problem into two sub-problems, namely action space learning and policy learning in the new action space. It leverages data from similar manipulation task instances, either from an offline expert or online during policy learning, and learns from these trajectories a mapping from the original to a latent action space. LASER is trained as a variational encoder-decoder model to map raw actions into a disentangled latent action space while maintaining action reconstruction and latent space dynamic consistency. We evaluate LASER on two contact-rich robotic tasks in simulation, and analyze the benefit of policy learning in the generated latent action space. We show improved sample efficiency compared to the original action space from better alignment of the action space to the task space, as we observe with visualizations of the learned action space manifold. Additional details: pair.toronto.edu/laser",
        "primary_area": "",
        "author": "Arthur Allshire;Roberto Mart\u00edn-Mart\u00edn;Charles Lin;Shawn Manuel;Silvio Savarese;Animesh Garg;Arthur Allshire;Roberto Mart\u00edn-Mart\u00edn;Charles Lin;Shawn Manuel;Silvio Savarese;Animesh Garg",
        "authorids": "/37089002143;/37085788640;/37089092338;/37088588488;/37298502600;/37086330576;/37089002143;/37085788640;/37089092338;/37088588488;/37298502600;/37086330576",
        "aff": "Vector Institute, University of Toronto; Stanford University; Stanford University; Stanford University; Stanford University; Nvidia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561232/",
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13341345849207440370&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;1;2",
        "aff_unique_norm": "University of Toronto;Stanford University;NVIDIA",
        "aff_unique_dep": "Vector Institute;;NVIDIA Corporation",
        "aff_unique_url": "https://www.vectorinstitute.ai;https://www.stanford.edu;https://www.nvidia.com",
        "aff_unique_abbr": "Vector Institute;Stanford;NVIDIA",
        "aff_campus_unique_index": "0;1;1;1;1",
        "aff_campus_unique": "Toronto;Stanford;",
        "aff_country_unique_index": "0;1;1;1;1;1",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9560914",
        "title": "LBGP: Learning Based Goal Planning for Autonomous Following in Front",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper investigates a hybrid solution which combines deep reinforcement learning (RL) and classical trajectory planning for the \"following in front\" application. Here, an autonomous robot aims to stay ahead of a person as the person freely walks around. Following in front is a challenging problem as the user\u2019s intended trajectory is unknown and needs to be estimated, explicitly or implicitly, by the robot. In addition, the robot needs to find a feasible way to safely navigate ahead of human trajectory. Our deep RL module makes decisions at a high level by implicitly estimates the human trajectory and produces short-term navigational goals to guide the robot. These goals are used by a trajectory planner, which is responsible for low-level execution, to smoothly navigate the robot to the short-term goals, and eventually in front of the user. We employ curriculum learning in the deep RL module to efficiently achieve a high return. Our system outperforms the state-of-the-art in following ahead and is more reliable compared to end-to-end alternatives in both the simulation and real world experiments. In contrast to a pure deep RL approach, we demonstrate zero-shot transfer of the trained policy from simulation to the real world.",
        "primary_area": "",
        "author": "Payam Nikdel;Richard Vaughan;Mo Chen;Payam Nikdel;Richard Vaughan;Mo Chen",
        "authorids": "/37086454305;/37335176000;/37085494765;/37086454305;/37335176000;/37085494765",
        "aff": "School of Computing Science, Simon Fraser University, Canada; School of Computing Science, Simon Fraser University, Canada; School of Computing Science, Simon Fraser University, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560914/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10596806322005906218&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Simon Fraser University",
        "aff_unique_dep": "School of Computing Science",
        "aff_unique_url": "https://www.sfu.ca",
        "aff_unique_abbr": "SFU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9560922",
        "title": "LEAF: Latent Exploration Along the Frontier",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-supervised goal proposal and reaching is a key component for exploration and efficient policy learning algorithms. Such a self-supervised approach without access to any oracle goal sampling distribution requires deep exploration and commitment so that long horizon plans can be efficiently discovered. In this paper, we propose an exploration framework, which learns a dynamics-aware manifold of reachable states. For a goal, our proposed method deterministically visits a state at the current frontier of reachable states (commit- ment/reaching) and then stochastically explores to reach the goal (exploration). This allocates exploration budget near the frontier of the reachable region instead of its interior. We target the challenging problem of policy learning from initial and goal states specified as images, and do not assume any access to the underlying ground-truth states of the robot and the environment. To keep track of reachable latent states, we propose a distance-conditioned reachability network that is trained to infer whether one state is reachable from another within the specified latent space distance. Given an initial state, we obtain a frontier of reachable states from that state. By incorporating a curriculum for sampling easier goals (closer to the start state) before more difficult goals, we demonstrate that the proposed self-supervised exploration algorithm, superior performance compared to existing baselines on a set of challenging robotic environments. https://sites.google.com/view/leaf-exploration",
        "primary_area": "",
        "author": "Homanga Bharadhwaj;Animesh Garg;Florian Shkurti;Homanga Bharadhwaj;Animesh Garg;Florian Shkurti",
        "authorids": "/37086638775;/37086330576;/37706697200;/37086638775;/37086330576;/37706697200",
        "aff": "Department of Computer Science, University of Toronto, Canada; Department of Computer Science, University of Toronto, Canada; Department of Computer Science, University of Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560922/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2410740812560192968&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9560954",
        "title": "LIRO: Tightly Coupled Lidar-Inertia-Ranging Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, thanks to the continuously reduced cost and weight of 3D lidar, the applications of this type of sensor in the community have become increasingly popular. Despite many progresses, estimation drift and tracking loss are still prevalent concerns associated with these systems. However, in theory these issues can be resolved with the use of some observations to fixed landmarks in the operation environments. This motivates us to investigate a sensor fusion scheme of lidar and inertia measurements with Ultra-Wideband (UWB) range measurements to such landmarks, which can be easily deployed in the environments with minimal cost and time. Hence, data from IMU, lidar and UWB are tightly-coupled with the robot's states on a sliding window based on their timestamps. Then, we construct a cost function comprising of factors from UWB, lidar and IMU preintegration measurements. Finally an optimization process is carried out to estimate the robot's position and orientation. It is demonstrated through some real world experiments that the method can effectively resolve the drift issue, while only requiring two or three anchors deployed in the environment.",
        "primary_area": "",
        "author": "Thien-Minh Nguyen;Muqing Cao;Shenghai Yuan;Yang Lyu;Thien Hoang Nguyen;Lihua Xie;Thien-Minh Nguyen;Muqing Cao;Shenghai Yuan;Yang Lyu;Thien Hoang Nguyen;Lihua Xie",
        "authorids": "/37086267121;/37086439772;/37085527198;/37085535967;/37086562147;/37274139300;/37086267121;/37086439772;/37085527198;/37085535967;/37086562147;/37274139300",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560954/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6444859668056813403&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9561502",
        "title": "LTO: Lazy Trajectory Optimization with Graph-Search Planning for High DOF Robots in Cluttered Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Although Trajectory Optimization (TO) is one of the most powerful motion planning tools, it suffers from expensive computational complexity as a time horizon increases in cluttered environments. It can also fail to converge to a globally optimal solution. In this paper, we present Lazy Trajectory Optimization (LTO) that unifies local short-horizon TO and global Graph-Search Planning (GSP) to generate a long-horizon global optimal trajectory. LTO solves TO with the same constraints as the original long-horizon TO with improved time complexity. We also propose a TO-aware cost function that can balance both solution cost and planning time. Since LTO solves many nearly identical TO in a roadmap, it can provide an informed warm-start for TO to accelerate the planning process. We also present proofs of the computational complexity and optimality of LTO. Finally, we demonstrate LTO\u2019s performance on motion planning problems for a 2 DOF free-flying robot and a 21 DOF legged robot, showing that LTO outperforms existing algorithms in terms of its runtime and reliability.",
        "primary_area": "",
        "author": "Yuki Shirai;Xuan Lin;Ankur Mehta;Dennis Hong;Yuki Shirai;Xuan Lin;Ankur Mehta;Dennis Hong",
        "authorids": "/37086344073;/37085891795;/37086302574;/37575333900;/37086344073;/37085891795;/37086302574;/37575333900",
        "aff": "Department of Electrical and Computer Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA; Department of Electrical and Computer Engineering, University of California, Los Angeles, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561502/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2454944539228256171&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561996",
        "title": "LVI-SAM: Tightly-coupled Lidar-Visual-Inertial Odometry via Smoothing and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a framework for tightly-coupled lidar-visual-inertial odometry via smoothing and mapping, LVI-SAM, that achieves real-time state estimation and map-building with high accuracy and robustness. LVI-SAM is built atop a factor graph and is composed of two sub-systems: a visual-inertial system (VIS) and a lidar-inertial system (LIS). The two sub-systems are designed in a tightly-coupled manner, in which the VIS leverages LIS estimation to facilitate initialization. The accuracy of the VIS is improved by extracting depth information for visual features using lidar measurements. In turn, the LIS utilizes VIS estimation for initial guesses to support scan-matching. Loop closures are first identified by the VIS and further refined by the LIS. LVI-SAM can also function when one of the two sub-systems fails, which increases its robustness in both texture-less and feature-less environments. LVI-SAM is extensively evaluated on datasets gathered from several platforms over a variety of scales and environments. Our implementation is available at https://git.io/lvi-sam.",
        "primary_area": "",
        "author": "Tixiao Shan;Brendan Englot;Carlo Ratti;Daniela Rus;Tixiao Shan;Brendan Englot;Carlo Ratti;Daniela Rus",
        "authorids": "/37085681623;/37601539900;/37590016800;/37279652300;/37085681623;/37601539900;/37590016800;/37279652300",
        "aff": "Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, USA; Department of Mechanical Engineering, Stevens Institute of Technology, USA; Department of Urban Studies and Planning, Massachusetts Institute of Technology, USA; Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561996/",
        "gs_citation": 489,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13834697459100485213&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Stevens Institute of Technology",
        "aff_unique_dep": "Computer Science & Artificial Intelligence Laboratory;Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu;https://www.stevens.edu",
        "aff_unique_abbr": "MIT;SIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562015",
        "title": "Lane-free Autonomous Intersection Management: A Batch-processing Framework Integrating Reservation-based and Planning-based Methods",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous intersection management (AIM) refers to planning the trajectories for multiple connected and automated vehicles (CAVs) when they traverse an unsignalized intersection cooperatively. As an extension of the conventional AIM, lane-free AIM allows the CAVs to adjust their velocities and paths flexibly within the intersection. Nominally, one needs to formulate a centralized optimal control problem (OCP) to describe the concerned lane-free AIM scheme, but solving such an intractably scaled problem is challenging. This work proposes a batch-processing framework, which divides the traffic flow into batches. The cooperative trajectories within one batch are planned by numerically solving a small-scale OCP; all the batches are managed via a reservation-based method following the first-come-first-serve policy. The proposed batch-processing framework aims to run as fast as a reservation-based method at the macro level while taking care of the cooperative driving quality at the micro level. The proposed method is validated via simulation and preliminary experiments.",
        "primary_area": "",
        "author": "Bai Li;Youmin Zhang;Tankut Acarman;Yakun Ouyang;Cagdas Yaman;Yaonan Wang;Bai Li;Youmin Zhang;Tankut Acarman;Yakun Ouyang;Cagdas Yaman;Yaonan Wang",
        "authorids": "/37085459453;/37405807400;/37332972700;/37088799433;/37085529494;/37281429000;/37085459453;/37405807400;/37332972700;/37088799433;/37085529494;/37281429000",
        "aff": "College of Mechanical and Vehicle Engineering, Hunan University, Changsha, China; Department of Mechanical, Industrial and Aerospace Engineering, Concordia University, Montreal, Canada; Computer Engineering Department, Galatasaray University, Istanbul, Turkey; College of Mechanical and Vehicle Engineering, Hunan University, Changsha, China; Computer Engineering Department, Galatasaray University, Istanbul, Turkey; School of Robotics, Hunan University, Changsha, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562015/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10427169638884135219&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;2;0",
        "aff_unique_norm": "Hunan University;Concordia University;Galatasaray University",
        "aff_unique_dep": "College of Mechanical and Vehicle Engineering;Department of Mechanical, Industrial and Aerospace Engineering;Computer Engineering Department",
        "aff_unique_url": "http://www.hnu.edu.cn;https://www.concordia.ca;https://www.gsu.edu.tr",
        "aff_unique_abbr": ";Concordia;GSU",
        "aff_campus_unique_index": "0;1;2;0;2;0",
        "aff_campus_unique": "Changsha;Montreal;Istanbul",
        "aff_country_unique_index": "0;1;2;0;2;0",
        "aff_country_unique": "China;Canada;T\u00fcrkiye"
    },
    {
        "id": "9560768",
        "title": "LatentSLAM: unsupervised multi-sensor representation learning for localization and mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Biologically inspired algorithms for simultaneous localization and mapping (SLAM) such as RatSLAM have been shown to yield effective and robust robot navigation in both indoor and outdoor environments. One drawback however is the sensitivity to perceptual aliasing due to the template matching of low-dimensional sensory templates. In this paper, we propose an unsupervised representation learning method that yields low-dimensional latent state descriptors that can be used for RatSLAM. Our method is sensor agnostic and can be applied to any sensor modality, as we illustrate for camera images, radar range-doppler maps and lidar scans. We also show how combining multiple sensors can increase the robustness, by reducing the number of false matches. We evaluate on a dataset captured with a mobile robot navigating in a warehouse-like environment, moving through different aisles with similar appearance, making it hard for the SLAM algorithms to disambiguate locations.",
        "primary_area": "",
        "author": "Ozan \u00c7atal;Wouter Jansen;Tim Verbelen;Bart Dhoedt;Jan Steckel;Ozan \u00c7atal;Wouter Jansen;Tim Verbelen;Bart Dhoedt;Jan Steckel",
        "authorids": "/37088488135;/37086993878;/37072400100;/37279070000;/37885021400;/37088488135;/37086993878;/37072400100;/37279070000;/37885021400",
        "aff": "IDlab, Ghent University - Imec; CoSys-Lab, University of Antwerp - Flanders Make; IDlab, Ghent University - Imec; IDlab, Ghent University - Imec; CoSys-Lab, University of Antwerp - Flanders Make",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560768/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2050024517114541248&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "Ghent University;University of Antwerp",
        "aff_unique_dep": "IDlab;CoSys-Lab",
        "aff_unique_url": "https://www.ugent.be;https://www.uantwerp.be",
        "aff_unique_abbr": "UGent;UA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ghent;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9560879",
        "title": "Learn to Path: Using neural networks to predict Dubins path characteristics for aerial vehicles in wind",
        "track": "main",
        "status": "Poster",
        "abstract": "For asymptotically optimal sampling-based path planners such as RRT*, path quality improves as the number of samples added to the motion tree increases. However, each additional sample requires a nearest-neighbor search. Calculating state transition costs can be particularly difficult in cases with complex dynamics such as aerial vehicles in non-isotropic cost fields like wind. Computationally costly nearest neighbor searches increase the time required to add new samples to the search tree, thereby reducing the likelihood of finding low-cost paths in a given computational time. In this paper, we propose the use of a lightweight neural network to approximate nearest neighbor cost calculations. The network approach uses a low-dimensional encoding of the cost space along with a start and goal query pair and returns an estimate of the path cost that can be used for nearest neighbor and path validity estimation. We demonstrate our method for a Dubins airplane model in a 3D wind field and show that the network method achieves equivalent path lengths as an existing iterative solver 32% faster and, when given the same search time, up to 10.8% shorter.",
        "primary_area": "",
        "author": "Trevor Phillips;Maximilian St\u00f6lzle;Erick Turricelli;Florian Achermann;Nicholas Lawrance;Roland Siegwart;Jen Jen Chung;Trevor Phillips;Maximilian St\u00f6lzle;Erick Turricelli;Florian Achermann;Nicholas Lawrance;Roland Siegwart;Jen Jen Chung",
        "authorids": "/37089002077;/37089000305;/37089002063;/37086866506;/37571923900;/37281398300;/37085668354;/37089002077;/37089000305;/37089002063;/37086866506;/37571923900;/37281398300;/37085668354",
        "aff": "Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Autonomous Systems Lab, ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560879/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4068648520835615248&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETH",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Z\u00fcrich",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561179",
        "title": "Learned Uncertainty Calibration for Visual Inertial Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "The widely-used Extended Kalman Filter (EKF) provides a straightforward recipe to estimate the mean and covariance of the state given all past measurements in a causal and recursive fashion. For a wide variety of applications, the EKF is known to produce accurate estimates of the mean and typically inaccurate estimates of the covariance. For applications in visual inertial localization, we show that inaccuracies in the covariance estimates are systematic, i.e. it is possible to learn a nonlinear map from the empirical ground truth to the estimated one. This is demonstrated on both a standard EKF in simulation and a Visual Inertial Odometry system on real-world data.",
        "primary_area": "",
        "author": "Stephanie Tsuei;Stefano Soatto;Paulo Tabuada;Mark B. Milam;Stephanie Tsuei;Stefano Soatto;Paulo Tabuada;Mark B. Milam",
        "authorids": "/37085998256;/37282915600;/37300854400;/37333153100;/37085998256;/37282915600;/37300854400;/37333153100",
        "aff": "Department of Computer Science, UCLA, Los Angeles, CA; Department of Computer Science, UCLA, Los Angeles, CA; Department of Electrical Engineering, UCLA, Los Angeles, CA; NG Next, Northrop Grumman, Redondo Beach, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561179/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15005587747424138691&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of California, Los Angeles;Northrop Grumman",
        "aff_unique_dep": "Department of Computer Science;NG Next",
        "aff_unique_url": "https://www.ucla.edu;https://www.northropgrumman.com",
        "aff_unique_abbr": "UCLA;NG",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Los Angeles;Redondo Beach",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561567",
        "title": "Learning Agile Locomotion Skills with a Mentor",
        "track": "main",
        "status": "Poster",
        "abstract": "Developing agile behaviors for legged robots re-mains a challenging problem. While deep reinforcement learning is a promising approach, learning truly agile behaviors typically requires tedious reward shaping and careful curriculum design. We formulate agile locomotion as a multi-stage learning problem in which a mentor guides the agent throughout the training. The mentor is optimized to place a checkpoint to guide the movement of the robot\u2019s center of mass while the student (i.e. the robot) learns to reach these checkpoints. Once the student can solve the task, we teach the student to perform the task without the mentor. We evaluate our proposed learning system with a simulated quadruped robot on a course consisting of randomly generated gaps and hurdles. Our method significantly outperforms a single-stage RL baseline without a mentor, and the quadruped robot can agilely run and jump across gaps and obstacles. Finally, we present a detailed analysis of the learned behaviors\u2019 feasibility and efficiency.",
        "primary_area": "",
        "author": "Atil Iscen;George Yu;Alejandro Escontrela;Deepali Jain;Jie Tan;Ken Caluwaerts;Atil Iscen;George Yu;Alejandro Escontrela;Deepali Jain;Jie Tan;Ken Caluwaerts",
        "authorids": "/37085362056;/37089000984;/37088999819;/37087325315;/37086455820;/37586652300;/37085362056;/37089000984;/37088999819;/37087325315;/37086455820;/37586652300",
        "aff": "Robotics at Google; Robotics at Google; Georgia Institute of Technology; Robotics at Google; Robotics at Google; Robotics at Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561567/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8840223658958462929&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Google;Georgia Institute of Technology",
        "aff_unique_dep": "Robotics;",
        "aff_unique_url": "https://www.google.com;https://www.gatech.edu",
        "aff_unique_abbr": "Google Robotics;Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562088",
        "title": "Learning Behavior Trees with Genetic Programming in Unpredictable Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern industrial applications require robots to operate in unpredictable environments, and programs to be created with a minimal effort, to accommodate frequent changes to the task. Here, we show that genetic programming can be effectively used to learn the structure of a behavior tree (BT) to solve a robotic task in an unpredictable environment. We propose to use a simple simulator for learning, and demonstrate that the learned BTs can solve the same task in a realistic simulator, converging without the need for task specific heuristics, making our method appealing for real robotic applications.",
        "primary_area": "",
        "author": "Matteo Iovino;Jonathan Styrud;Pietro Falco;Christian Smith;Matteo Iovino;Jonathan Styrud;Pietro Falco;Christian Smith",
        "authorids": "/37089000726;/38580337300;/38076626900;/37559467400;/37089000726;/38580337300;/38076626900;/37559467400",
        "aff": "Division of Robotics, Perception and Learning, KTH - Royal Institute of Technology, Stockholm, Sweden; Division of Robotics, Perception and Learning, KTH - Royal Institute of Technology, Stockholm, Sweden; ABB Corporate Research, Vsters, Sweden; Division of Robotics, Perception and Learning, KTH - Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562088/",
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11521899606181688614&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "KTH - Royal Institute of Technology;ABB Corporate Research",
        "aff_unique_dep": "Division of Robotics, Perception and Learning;",
        "aff_unique_url": "https://www.kth.se;https://new.abb.com/research",
        "aff_unique_abbr": "KTH;ABB",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stockholm;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9561591",
        "title": "Learning Bipedal Robot Locomotion from Human Movement",
        "track": "main",
        "status": "Poster",
        "abstract": "Teaching an anthropomorphic robot from human example offers the opportunity to impart humanlike qualities on its movement. In this work we present a reinforcement learning based method for teaching a real world bipedal robot to perform movements directly from human motion capture data. Our method seamlessly transitions from training in a simulation environment to executing on a physical robot without requiring any real world training iterations or offline steps. To overcome the disparity in joint configurations between the robot and the motion capture actor, our method incorporates motion re-targeting into the training process. Domain randomization techniques are used to compensate for the differences between the simulated and physical systems. We demonstrate our method on an internally developed humanoid robot with movements ranging from a dynamic walk cycle to complex balancing and waving. Our controller preserves the style imparted by the motion capture data and exhibits graceful failure modes resulting in safe operation for the robot. This work was performed for research purposes only.",
        "primary_area": "",
        "author": "Michael Taylor;Sergey Bashkirov;Javier Fernandez Rico;Ike Toriyama;Naoyuki Miyada;Hideki Yanagisawa;Kensaku Ishizuka;Michael Taylor;Sergey Bashkirov;Javier Fernandez Rico;Ike Toriyama;Naoyuki Miyada;Hideki Yanagisawa;Kensaku Ishizuka",
        "authorids": "/37089000858;/37089001812;/37088996867;/37088997397;/37088996773;/37088997708;/37088995900;/37089000858;/37089001812;/37088996867;/37088997397;/37088996773;/37088997708;/37088995900",
        "aff": "Sony Interactive Entertainment; Sony Interactive Entertainment; Sony Interactive Entertainment; Sony Interactive Entertainment; Sony Interactive Entertainment; Sony Interactive Entertainment; Sony Interactive Entertainment",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561591/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=783827935531020246&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Sony Interactive Entertainment",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sonyinteractive.com",
        "aff_unique_abbr": "SIE",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561650",
        "title": "Learning Camera Performance Models for Active Multi-Camera Visual Teach and Repeat",
        "track": "main",
        "status": "Poster",
        "abstract": "In dynamic and cramped industrial environments, achieving reliable Visual Teach and Repeat (VT&R) with a single-camera is challenging. In this work, we develop a robust method for non-synchronized multi-camera VT&R. Our contribution are expected Camera Performance Models (CPM) which evaluate the camera streams from the teach step to determine the most informative one for localization during the repeat step. By actively selecting the most suitable camera for localization, we are able to successfully complete missions when one of the cameras is occluded, faces into feature poor locations or if the environment has changed. Furthermore, we explore the specific challenges of achieving VT&R on a dynamic quadruped robot, ANYmal. The camera does not follow a linear path (due to the walking gait and holonomicity) such that precise path-following cannot be achieved. Our experiments feature forward and backward facing stereo cameras showing VT&R performance in cluttered indoor and outdoor scenarios. We compared the trajectories the robot executed during the repeat steps demonstrating typical tracking precision of less than 10 cm on average. With a view towards omni-directional localization, we show how the approach generalizes to four cameras in simulation.",
        "primary_area": "",
        "author": "Matias Mattamala;Milad Ramezani;Marco Camurri;Maurice Fallon;Matias Mattamala;Milad Ramezani;Marco Camurri;Maurice Fallon",
        "authorids": "/37088686013;/37088504403;/37085638130;/37540365100;/37088686013;/37088504403;/37085638130;/37540365100",
        "aff": "Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561650/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3829128524597159090&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561828",
        "title": "Learning Collaborative Pushing and Grasping Policies in Dense Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots must reason about pushing and grasping in order to engage in flexible manipulation in cluttered environments. Earlier works on learning pushing and grasping only consider each operation in isolation or are limited to top-down grasping and bin-picking. We train a robot to learn joint planar pushing and 6-degree-of-freedom (6-DoF) grasping policies by self-supervision. Two separate deep neural networks are trained to map from 3D visual observations to actions with a Q-learning framework. With collaborative pushes and expanded grasping action space, our system can deal with cluttered scenes with a wide variety of objects (e.g. grasping a plate from the side after pushing away surrounding obstacles). We compare our system to the state-of-the-art baseline model VPG [1] in simulation and outperform it with 10% higher action efficiency and 20% higher grasp success rate. We then demonstrate our system on a KUKA LBR iiwa arm with a Robotiq 3-finger gripper.",
        "primary_area": "",
        "author": "Bingjie Tang;Matthew Corsaro;George Konidaris;Stefanos Nikolaidis;Stefanie Tellex;Bingjie Tang;Matthew Corsaro;George Konidaris;Stefanos Nikolaidis;Stefanie Tellex",
        "authorids": "/37088998844;/37089001880;/38318614200;/37643766400;/37402794800;/37088998844;/37089001880;/38318614200;/37643766400;/37402794800",
        "aff": "Bingjie Tang; Matthew Corsaro; George Konidaris; Stefanos Nikolaidis; Stefanie Tellex",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561828/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10719923503995607364&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9560818",
        "title": "Learning Conditional Postural Synergies for Dexterous Hands: A Generative Approach Based on Variational Auto-Encoders and Conditioned on Object Size and Category",
        "track": "main",
        "status": "Poster",
        "abstract": "Postural synergies are used in robotics to facilitate the control of dexterous artificial hands. This is achieved by learning a latent space (synergy space) from grasp postures and directly controlling the hand in this space. In this work, we propose the use of a non-linear conditional model for learning the latent space, that can incorporate the object shape and size as additional variables. While on most of the previous works the evaluation criterion is the reconstruction error, we propose to use the smoothness of the latent space. Our model ranks better than other non-linear models in smoothness, which is a better criterion to evaluate in-hand manipulation tasks. We validate our arguments by executing regrasp trajectories in which our model outperforms all previous approaches.",
        "primary_area": "",
        "author": "Dimitrios Dimou;Jos\u00e9 Santos-Victor;Plinio Moreno;Dimitrios Dimou;Jos\u00e9 Santos-Victor;Plinio Moreno",
        "authorids": "/37086573410;/38274231800;/38274327100;/37086573410;/38274231800;/38274327100",
        "aff": "Institute for Systems and Robotics, Instituto Superior Tecnico, Universidade de Lisboa, Portugal; Institute for Systems and Robotics, Instituto Superior Tecnico, Universidade de Lisboa, Portugal; Institute for Systems and Robotics, Instituto Superior Tecnico, Universidade de Lisboa, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560818/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12124655836374029242&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universidade de Lisboa",
        "aff_unique_dep": "Institute for Systems and Robotics, Instituto Superior Tecnico",
        "aff_unique_url": "https://www IST Lisbon",
        "aff_unique_abbr": "IST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "9561891",
        "title": "Learning Dense Rewards for Contact-Rich Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Rewards play a crucial role in reinforcement learning. To arrive at the desired policy, the design of a suitable reward function often requires significant domain expertise as well as trial-and-error. Here, we aim to minimize the effort involved in designing reward functions for contact-rich manipulation tasks. In particular, we provide an approach capable of extracting dense reward functions algorithmically from robots\u2019 high-dimensional observations, such as images and tactile feedback. In contrast to state-of-the-art high-dimensional reward learning methodologies, our approach does not leverage adversarial training, and is thus less prone to the associated training instabilities. Instead, our approach learns rewards by estimating task progress in a self-supervised manner. We demonstrate the effectiveness and efficiency of our approach on two contact-rich manipulation tasks, namely, peg-in-hole and USB insertion. The experimental results indicate that the policies trained with the learned reward function achieves better performance and faster convergence compared to the baselines.",
        "primary_area": "",
        "author": "Zheng Wu;Wenzhao Lian;Vaibhav Unhelkar;Masayoshi Tomizuka;Stefan Schaal;Zheng Wu;Wenzhao Lian;Vaibhav Unhelkar;Masayoshi Tomizuka;Stefan Schaal",
        "authorids": "/37088444305;/37088998889;/37085482072;/37281933000;/37282144700;/37088444305;/37088998889;/37085482072;/37281933000;/37282144700",
        "aff": "University of California, Berkeley, Berkeley, CA, USA; X, the Moonshot Factory, Mountain View, CA, USA; Rice University, Houston, TX, USA; University of California, Berkeley, Berkeley, CA, USA; X, the Moonshot Factory, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561891/",
        "gs_citation": 50,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17014673417142653961&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;0;1",
        "aff_unique_norm": "University of California, Berkeley;X Development LLC;Rice University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.berkeley.edu;https://xdevllc.com;https://www.rice.edu",
        "aff_unique_abbr": "UC Berkeley;X;Rice",
        "aff_campus_unique_index": "0;1;2;0;1",
        "aff_campus_unique": "Berkeley;Mountain View;Houston",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561980",
        "title": "Learning Dense Visual Correspondences in Simulation to Smooth and Fold Real Fabrics",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic fabric manipulation is challenging due to the infinite dimensional configuration space, self-occlusion, and complex dynamics of fabrics. There has been significant prior work on learning policies for specific fabric manipulation tasks, but comparatively less focus on algorithms which can perform many different tasks. We take a step towards this goal by learning point-pair correspondences across different fabric configurations in simulation. Then, given a single demonstration of a new task from an initial fabric configuration, these correspondences can be used to compute geometrically equivalent actions in a new fabric configuration. This makes it possible to define policies to robustly imitate a broad set of multi-step fabric smoothing and folding tasks. The resulting policies achieve 80.3% average task success rate across 10 fabric manipulation tasks on two different physical robotic systems. Results also suggest robustness to fabrics of various colors, sizes, and shapes. See https://tinyurl.com/fabric-descriptors for supplementary material and videos.",
        "primary_area": "",
        "author": "Aditya Ganapathi;Priya Sundaresan;Brijen Thananjeyan;Ashwin Balakrishna;Daniel Seita;Jennifer Grannen;Minho Hwang;Ryan Hoque;Joseph E. Gonzalez;Nawid Jamali;Katsu Yamane;Soshi Iba;Ken Goldberg;Aditya Ganapathi;Priya Sundaresan;Brijen Thananjeyan;Ashwin Balakrishna;Daniel Seita;Jennifer Grannen;Minho Hwang;Ryan Hoque;Joseph E. Gonzalez;Nawid Jamali;Katsu Yamane;Soshi Iba;Ken Goldberg",
        "authorids": "/37088688406;/37087011905;/37086105009;/37085692655;/37086012763;/37088507002;/37085406507;/37088687016;/37086566024;/37546207800;/37291289300;/37329555300;/37273026700;/37088688406;/37087011905;/37086105009;/37085692655;/37086012763;/37088507002;/37085406507;/37088687016;/37086566024;/37546207800;/37291289300;/37329555300;/37273026700",
        "aff": "AUTOLab at the University of California, Berkeley, USA; AUTOLab at the University of California, Berkeley, USA; AUTOLab at the University of California, Berkeley, USA; AUTOLab at the University of California, Berkeley, USA; AUTOLab at the University of California, Berkeley, USA; AUTOLab at the University of California, Berkeley, USA; AUTOLab at the University of California, Berkeley, USA; AUTOLab at the University of California, Berkeley, USA; AUTOLab at the University of California, Berkeley, USA; Honda Research Institute, USA; Honda Research Institute, USA; Honda Research Institute, USA; AUTOLab at the University of California, Berkeley, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561980/",
        "gs_citation": 84,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11619647684854922355&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 26,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;1;1;1;0",
        "aff_unique_norm": "University of California, Berkeley;Honda Research Institute",
        "aff_unique_dep": "AUTOLab;",
        "aff_unique_url": "https://www.berkeley.edu;https://honda-ri.com",
        "aff_unique_abbr": "UC Berkeley;HRI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561802",
        "title": "Learning Dexterous Grasping with Object-Centric Visual Affordances",
        "track": "main",
        "status": "Poster",
        "abstract": "Dexterous robotic hands are appealing for their agility and human-like morphology, yet their high degree of freedom makes learning to manipulate challenging. We introduce an approach for learning dexterous grasping. Our key idea is to embed an object-centric visual affordance model within a deep reinforcement learning loop to learn grasping policies that favor the same object regions favored by people. Unlike traditional approaches that learn from human demonstration trajectories (e.g., hand joint sequences captured with a glove), the proposed prior is object-centric and image-based, allowing the agent to anticipate useful affordance regions for objects unseen during policy learning. We demonstrate our idea with a 30-DoF five-fingered robotic hand simulator on 40 objects from two datasets, where it successfully and efficiently learns policies for stable functional grasps. Our affordance-guided policies are significantly more effective, generalize better to novel objects, train 3\u00d7 faster than the baselines, and are more robust to noisy sensor readings and actuation. Our work offers a step towards manipulation agents that learn by watching how people use objects, without requiring state and action information about the human body. Project website with videos: http://vision.cs.utexas.edu/projects/graff-dexterous-affordance-grasp.",
        "primary_area": "",
        "author": "Priyanka Mandikal;Kristen Grauman;Priyanka Mandikal;Kristen Grauman",
        "authorids": "/37086698102;/37282612200;/37086698102;/37282612200",
        "aff": "Department of Computer Science, The University of Texas, Austin; Facebook AI Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561802/",
        "gs_citation": 167,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18130686244166860587&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Texas at Austin;Meta",
        "aff_unique_dep": "Department of Computer Science;Facebook AI Research",
        "aff_unique_url": "https://www.utexas.edu;https://research.facebook.com",
        "aff_unique_abbr": "UT Austin;FAIR",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561569",
        "title": "Learning Domain Adaptation with Model Calibration for Surgical Report Generation in Robotic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Generating a surgical report in robot-assisted surgery, in the form of natural language expression of surgical scene understanding, can play a significant role in document entry tasks, surgical training, and post-operative analysis. Despite the state-of-the-art accuracy of the deep learning algorithm, the deployment performance often drops when applied to the Target Domain (TD) data. For this purpose, we develop a multi-layer transformer-based model with the gradient reversal adversarial learning to generate a caption for the multi-domain surgical images that can describe the semantic relationship between instruments and surgical Region of Interest (ROI). In the gradient reversal adversarial learning scheme, the gradient multiplies with a negative constant and updates adversarially in backward propagation, discriminating between the source and target domains and emerging domain-invariant features. We also investigate model calibration with label smoothing technique and the effect of a well-calibrated model for the penultimate layer\u2019s feature representation and Domain Adaptation (DA). We annotate two robotic surgery datasets of MICCAI robotic scene segmentation and Transoral Robotic Surgery (TORS) with the captions of procedures and empirically show that our proposed method improves the performance in both source and target domain surgical reports generation in the manners of unsupervised, zero-shot, one-shot, and few-shot learning.",
        "primary_area": "",
        "author": "Mengya Xu;Mobarakol Islam;Chwee Ming Lim;Hongliang Ren;Mengya Xu;Mobarakol Islam;Chwee Ming Lim;Hongliang Ren",
        "authorids": "/37089000258;/37086799020;/37088999467;/37287561300;/37089000258;/37086799020;/37088999467;/37287561300",
        "aff": "NUSRI, Suzhou, China; Dept. of Biomedical Engineering, National University of Singapore, Singapore; Dept. of Otolaryngology-Head and Neck Surgery, Duke-NUS Medical School, Singapore; Dept. of Electronic Engineering, The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561569/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=834008096603161903&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Nanjing University of Science and Technology Research Institute;National University of Singapore;Duke-NUS Medical School;Chinese University of Hong Kong",
        "aff_unique_dep": ";Dept. of Biomedical Engineering;Dept. of Otolaryngology-Head and Neck Surgery;Dept. of Electronic Engineering",
        "aff_unique_url": "http://www.nusri.edu.cn/;https://www.nus.edu.sg;https://www.duke-nus.edu.sg;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "NUSRI;NUS;Duke-NUS;CUHK",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Suzhou;;Hong Kong SAR",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "9560978",
        "title": "Learning Efficient Constraint Graph Sampling for Robotic Sequential Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Efficient sampling from constraint manifolds, and thereby generating a diverse set of solutions for feasibility problems, is a fundamental challenge. We consider the case where a problem is factored, that is, the underlying nonlinear program is decomposed into differentiable equality and inequality constraints, each of which depends only on some variables. Such problems are at the core of efficient and robust sequential robot manipulation planning. Naive sequential conditional sampling of individual variables, as well as fully joint sampling of all variables at once (e.g., leveraging optimization methods), can be highly inefficient and non-robust. We propose a novel framework to learn how to break the overall problem into smaller sequential sampling problems. Specifically, we leverage Monte-Carlo Tree Search to learn assignment orders for the variable-subsets, in order to minimize the computation time to generate feasible full samples. This strategy allows us to efficiently compute a set of diverse valid robot configurations for mode-switches within sequential manipulation tasks, which are waypoints for subsequent trajectory optimization or sampling-based motion planning algorithms. We show that the learning method quickly converges to the best sampling strategy for a given problem, and outperforms user-defined orderings or fully joint optimization, while providing a higher sample diversity. Video: https://youtu.be/mCNdvjTbHNI",
        "primary_area": "",
        "author": "Joaquim Ortiz-Haro;Valentin N. Hartmann;Ozgur S. Oguz;Marc Toussaint;Joaquim Ortiz-Haro;Valentin N. Hartmann;Ozgur S. Oguz;Marc Toussaint",
        "authorids": "/37088998356;/37088690890;/37085638620;/37528418600;/37088998356;/37088690890;/37085638620;/37528418600",
        "aff": "Machine Learning & Robotics Lab, University of Stuttgart, Germany; Learning and Intelligent Systems Lab, TU Berlin, Germany; Max Planck Institute for Intelligent Systems, Germany; Learning and Intelligent Systems Lab, TU Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560978/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3411619829361019847&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "University of Stuttgart;Technische Universit\u00e4t Berlin;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Machine Learning & Robotics Lab;Learning and Intelligent Systems Lab;",
        "aff_unique_url": "https://www.uni-stuttgart.de;https://www.tu-berlin.de;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": ";TU Berlin;MPI-IS",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Berlin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9560934",
        "title": "Learning Geometric Reasoning and Control for Long-Horizon Tasks from Visual Input",
        "track": "main",
        "status": "Poster",
        "abstract": "Long-horizon manipulation tasks require joint reasoning over a sequence of discrete actions and their associated continuous control parameters. While Task and Motion Planning (TAMP) approaches are capable of generating motion plans that account for this joint reasoning, they usually assume full knowledge about the environment (e.g. in terms of shapes, poses of objects) and often require computation times not suitable for real-time control.To overcome this, we propose a learning framework where a high-level reasoning network predicts, based on an image of the scene, a sequence of discrete actions and the parameter values of their associated low-level controllers. These controllers are parameterized in terms of a learned energy function, leading to time-invariant controllers for each phase. We train the whole framework end-to-end using a dataset of TAMP solutions computed using Logic Geometric Programming. A key feature is that the reasoning network determines the parameters of the controllers jointly, such that the overall task can be solved. Despite having no explicit representation of the geometry nor pose of the objects in the scene, our network is still able to accomplish geometrically precise manipulation tasks, including handovers and an accurate pointing task where the parameters of early actions are tightly coupled with those of later actions. Video: https://youtu.be/AcPWRTkr3_g",
        "primary_area": "",
        "author": "Danny Driess;Jung-Su Ha;Russ Tedrake;Marc Toussaint;Danny Driess;Jung-Su Ha;Russ Tedrake;Marc Toussaint",
        "authorids": "/37085994159;/38543013300;/37283152200;/37528418600;/37085994159;/38543013300;/37283152200;/37528418600",
        "aff": "MPI for Intelligent Systems; TU Berlin; Massachusetts Institute of Technology; TU Berlin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560934/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12905584598265844834&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;1",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;Technische Universit\u00e4t Berlin;Massachusetts Institute of Technology",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.tu-berlin.de;https://web.mit.edu",
        "aff_unique_abbr": "MPI-IS;TU Berlin;MIT",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Berlin",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9560829",
        "title": "Learning Human Objectives from Sequences of Physical Corrections",
        "track": "main",
        "status": "Poster",
        "abstract": "When personal, assistive, and interactive robots make mistakes, humans naturally and intuitively correct those mistakes through physical interaction. In simple situations, one correction is sufficient to convey what the human wants. But when humans are working with multiple robots or the robot is performing an intricate task often the human must make several corrections to fix the robot\u2019s behavior. Prior research assumes each of these physical corrections are independent events, and learns from them one-at-a-time. However, this misses out on crucial information: each of these interactions are interconnected, and may only make sense if viewed together. Alternatively, other work reasons over the final trajectory produced by all of the human\u2019s corrections. But this method must wait until the end of the task to learn from corrections, as opposed to inferring from the corrections in an online fashion. In this paper we formalize an approach for learning from sequences of physical corrections during the current task. To do this we introduce an auxiliary reward that captures the human\u2019s trade-off between making corrections which improve the robot\u2019s immediate reward and long-term performance. We evaluate the resulting algorithm in remote and in-person human-robot experiments, and compare to both independent and final baselines. Our results indicate that users are best able to convey their objective when the robot reasons over their sequence of corrections.",
        "primary_area": "",
        "author": "Mengxi Li;Alper Canberk;Dylan P. Losey;Dorsa Sadigh;Mengxi Li;Alper Canberk;Dylan P. Losey;Dorsa Sadigh",
        "authorids": "/37088689162;/37088997829;/37085812055;/38234464200;/37088689162;/37088997829;/37085812055;/38234464200",
        "aff": "Dept of Computer Science, Intelligent and Interactive Autonomous Systems Group (ILIAD), Stanford University, Stanford, CA; Dept of Computer Science, Intelligent and Interactive Autonomous Systems Group (ILIAD), Stanford University, Stanford, CA; Collaborative Robotics Lab (Collab), Virginia Tech; Dept of Computer Science, Intelligent and Interactive Autonomous Systems Group (ILIAD), Stanford University, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560829/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5838381932129276044&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Stanford University;Virginia Tech",
        "aff_unique_dep": "Dept of Computer Science;Collaborative Robotics Lab (Collab)",
        "aff_unique_url": "https://www.stanford.edu;https://www.vt.edu",
        "aff_unique_abbr": "Stanford;VT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560746",
        "title": "Learning Human-like Hand Reaching for Human-Robot Handshaking",
        "track": "main",
        "status": "Poster",
        "abstract": "One of the first and foremost non-verbal interactions that humans perform is a handshake. It has an impact on first impressions as touch can convey complex emotions. This makes handshaking an important skill for the repertoire of a social robot. In this paper, we present a novel framework for learning reaching behaviours for humanrobot handshaking behaviours for humanoid robots solely using third-person human-human interaction data. This is especially useful for non-backdrivable robots that cannot be taught by demonstrations via kinesthetic teaching. Our approach can be easily executed on different humanoid robots. This removes the need for re-training, which is especially tedious when training with human-interaction partners. We show this by applying the learnt behaviours on two different humanoid robots with similar degrees of freedom but different shapes and control limits.",
        "primary_area": "",
        "author": "Vignesh Prasad;Ruth Stock-Homburg;Jan Peters;Vignesh Prasad;Ruth Stock-Homburg;Jan Peters",
        "authorids": "/37086487640;/37085467936;/37533077600;/37086487640;/37085467936;/37533077600",
        "aff": "Technical University of Darmstadt, Germany; Technical University of Darmstadt, Germany; Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560746/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14686146422982362927&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Technical University of Darmstadt;Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tu-darmstadt.de;https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "TUD;MPI-IS",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";T\u00fcbingen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561334",
        "title": "Learning Interpretable End-to-End Vision-Based Motion Planning for Autonomous Driving with Optical Flow Distillation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, deep-learning based approaches have achieved impressive performance for autonomous driving. However, end-to-end vision-based methods typically have limited interpretability, making the behaviors of the deep networks difficult to explain. Hence, their potential applications could be limited in practice. To address this problem, we propose an interpretable end-to-end vision-based motion planning approach for autonomous driving, referred to as IVMP. Given a set of past surrounding-view images, our IVMP first predicts future egocentric semantic maps in bird\u2019s-eye-view space, which are then employed to plan trajectories for self-driving vehicles. The predicted future semantic maps not only provide useful interpretable information, but also allow our motion planning module to handle objects with low probability, thus improving the safety of autonomous driving. Moreover, we also develop an optical flow distillation paradigm, which can effectively enhance the network while still maintaining its real-time performance. Extensive experiments on the nuScenes dataset and closed-loop simulation show that our IVMP significantly outperforms the state-of-the-art approaches in imitating human drivers with a much higher success rate. Our project page is available at https://sites.google.com/view/ivmp.",
        "primary_area": "",
        "author": "Hengli Wang;Peide Cai;Yuxiang Sun;Lujia Wang;Ming Liu;Hengli Wang;Peide Cai;Yuxiang Sun;Lujia Wang;Ming Liu",
        "authorids": "/37086939511;/37087104388;/37085435479;/37406752700;/37085398677;/37086939511;/37087104388;/37085435479;/37406752700;/37085398677",
        "aff": "Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561334/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15227457944260202230&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561378",
        "title": "Learning Motor Resonance in Human-Human and Human-Robot Interaction with Coupled Dynamical Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Human interaction involves very sophisticated non-verbal communication skills like understanding the goals and actions of others and coordinating our own actions accordingly. Neuroscience refers to this mechanism as motor resonance, in the sense that the perception of another persons actions and sensory experiences activates the observer\u2019s brain as if (s)he would be performing the same actions and having the same experiences.We analyze and model the non-verbal cues exchanged between two humans in handover actions. The contributions of this paper are the following: (i) computational models, using recorded motion data, describing the motor behaviour of each actor in action-in-interaction situations; (ii) a computational model that captures the behaviour of the \"giver\" and \"receiver\" during an object handover action, by coupling the wrist kinematic motion of the actors; and (iii) the transfer of these models to the iCub robot for both action execution and recognition.Our results show that: (i) the robot is able to interpret the human wrist motion and infer whether or not the observed action is an \"handover\"; and (ii) use the motor resonance model to coordinate its actions with the human partner, during handover actions.",
        "primary_area": "",
        "author": "Nuno Ferreira Duarte;Mirko Rakovi\u0107;Jos\u00e9 Santos-Victor;Nuno Ferreira Duarte;Mirko Rakovi\u0107;Jos\u00e9 Santos-Victor",
        "authorids": "/37086436863;/37705388700;/38274231800;/37086436863;/37705388700;/38274231800",
        "aff": "Vislab, Institute for Systems and Robotics, Instituto Superior T\u00e9cnico, Universidade de Lisboa, Portugal; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; Vislab, Institute for Systems and Robotics, Instituto Superior T\u00e9cnico, Universidade de Lisboa, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561378/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7400175562771634131&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Universidade de Lisboa;University of Novi Sad",
        "aff_unique_dep": "Institute for Systems and Robotics, Instituto Superior T\u00e9cnico;Faculty of Technical Sciences",
        "aff_unique_url": "https://www IST Lisbon;https://www.uns.ac.rs",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Novi Sad",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Portugal;Serbia"
    },
    {
        "id": "9561491",
        "title": "Learning Multi-Arm Manipulation Through Collaborative Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "Imitation Learning (IL) is a powerful paradigm to teach robots to perform manipulation tasks by allowing them to learn from human demonstrations collected via teleoperation, but has mostly been limited to single-arm manipulation. However, many real-world tasks require multiple arms, such as lifting a heavy object or assembling a desk. Unfortunately, applying IL to multi-arm manipulation tasks has been challenging \u2013asking a human to control more than one robotic arm can impose significant cognitive burden and is often only possible for a maximum of two robot arms. To address these challenges, we present MULTI-ARM ROBOTURK (MART), a multi-user data collection platform that allows multiple remote users to simultaneously teleoperate a set of robotic arms and collect demonstrations for multi-arm tasks. Using MART, we collected demonstrations for five novel two and three-arm tasks from several geographically separated users. From our data we arrived at a critical insight: most multi-arm tasks do not require global coordination throughout its full duration, but only during specific moments. We show that learning from such data consequently presents challenges for centralized agents that directly attempt to model all robot actions simultaneously, and perform a comprehensive study of different policy architectures with varying levels of centralization on our tasks. Finally, we propose and evaluate a base-residual policy framework that allows trained policies to better adapt to the mixed coordination setting common in multi-arm manipulation, and show that a centralized policy augmented with a decentralized residual model outperforms all other models on our set of benchmark tasks. Additional results and videos at https://roboturk.stanford.edu/multiarm",
        "primary_area": "",
        "author": "Albert Tung;Josiah Wong;Ajay Mandlekar;Roberto Mart\u00edn-Mart\u00edn;Yuke Zhu;Li Fei-Fei;Silvio Savarese;Albert Tung;Josiah Wong;Ajay Mandlekar;Roberto Mart\u00edn-Mart\u00edn;Yuke Zhu;Li Fei-Fei;Silvio Savarese",
        "authorids": "/37087323479;/37088968066;/37086331393;/37085788640;/37086080772;/38273560700;/37298502600;/37087323479;/37088968066;/37086331393;/37085788640;/37086080772;/38273560700;/37298502600",
        "aff": "Stanford Vision & Learning Lab; Stanford Vision & Learning Lab; Stanford Vision & Learning Lab; Stanford Vision & Learning Lab; The University of Texas at Austin; Stanford Vision & Learning Lab; Stanford Vision & Learning Lab",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561491/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4078423551993160078&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "Stanford University;University of Texas at Austin",
        "aff_unique_dep": "Vision & Learning Lab;",
        "aff_unique_url": "https://vision.stanford.edu;https://www.utexas.edu",
        "aff_unique_abbr": "Stanford V&L;UT Austin",
        "aff_campus_unique_index": "0;0;0;0;1;0;0",
        "aff_campus_unique": "Stanford;Austin",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561734",
        "title": "Learning Multimodal Contact-Rich Skills from Demonstrations Without Reward Engineering",
        "track": "main",
        "status": "Poster",
        "abstract": "Everyday contact-rich tasks, such as peeling, cleaning, and writing, demand multimodal perception for effective and precise task execution. However, these present a novel challenge to robots as they lack the ability to combine these multimodal stimuli for performing contact-rich tasks. Learning-based methods have attempted to model multi-modal contact-rich tasks, but they often require extensive training examples and task-specific reward functions which limits their practicality and scope. Hence, we propose a generalizable model-free learning-from-demonstration framework for robots to learn contact-rich skills without explicit reward engineering. We present a novel multi-modal sensor data representation which improves the learning performance for contact-rich skills. We performed training and experiments using the real-life Sawyer robot for three everyday contact-rich skills \u2013 cleaning, writing, and peeling. Notably, the framework achieves a success rate of 100% for the peeling and writing skill, and 80% for the cleaning skill. Hence, this skill learning framework can be extended for learning other physical manipulation skills.",
        "primary_area": "",
        "author": "Mythra V. Balakuntala;Upinder Kaur;Xin Ma;Juan Wachs;Richard M. Voyles;Mythra V. Balakuntala;Upinder Kaur;Xin Ma;Juan Wachs;Richard M. Voyles",
        "authorids": "/37087236032;/37938211700;/37085857304;/37327560600;/37283531400;/37087236032;/37938211700;/37085857304;/37327560600;/37283531400",
        "aff": "School of Engineering Technology; School of Engineering Technology; School of Engineering Technology; School of Industrial Engineering, Purdue University, IN, USA; School of Engineering Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561734/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13710754130811448566&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "School of Engineering Technology;Purdue University",
        "aff_unique_dep": "Engineering Technology;School of Industrial Engineering",
        "aff_unique_url": ";https://www.purdue.edu",
        "aff_unique_abbr": ";Purdue",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Indiana",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "9562074",
        "title": "Learning Optical Flow with R-CNN for Visual Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Addressing on monocular visual odometry problem, this paper presents a novel end-to-end network for estimation of camera ego-motion. The network learns the latent space of optical flow (OF) and models sequential dynamics so that the motion estimation is constrained by the relations between sequential images. We compute the OF field of consecutive images and extract the latent OF representation in a self-encoding manner. A Recurrent Neural Network is then followed to examine the OF changes, i.e., to conduct sequential learning. The extracted sequential OF latent space is used to compute the regression of the 6-dimensional pose vector. Particularly, we separately train the encoder in an unsupervised manner. By this means, we avoid non-convergence during the training of the whole network and allow more generalized and effective feature representation. Substantial experiments have been conducted on KITTI and Malaga datasets, and the results demonstrate that our model outperforms most learning-based VO approaches.",
        "primary_area": "",
        "author": "Yingping Huang;Baigan Zhao;Chong Gao;Xing Hu;Yingping Huang;Baigan Zhao;Chong Gao;Xing Hu",
        "authorids": "/37536901600;/37088979149;/37088999052;/37086507709;/37536901600;/37088979149;/37088999052;/37086507709",
        "aff": "School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, China; School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, China; School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, China; School of Optical-Electrical and Computer Engineering, University of Shanghai for Science and Technology, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562074/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10065729961030142058&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Shanghai for Science and Technology",
        "aff_unique_dep": "School of Optical-Electrical and Computer Engineering",
        "aff_unique_url": "https://www.usst.edu.cn",
        "aff_unique_abbr": "USST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560798",
        "title": "Learning Panoptic Segmentation from Instance Contours",
        "track": "main",
        "status": "Poster",
        "abstract": "Panoptic Segmentation aims to provide an understanding of background (stuff) and instances of objects (things) at a pixel level. It combines the separate tasks of semantic segmentation (pixel level classification) and instance segmentation to build a single unified scene understanding task. Typically, panoptic segmentation is derived by combining semantic and instance segmentation tasks that are learned separately or jointly (multi-task networks). In general, instance segmentation networks are built by adding a foreground mask estimation layer on top of object detectors or using instance clustering methods that assign a pixel to an instance center. In this work, we present a fully convolution neural network that learns instance segmentation from semantic segmentation and instance contours (boundaries of things). Instance contours along with semantic segmentation yield a boundary aware semantic segmentation of things. Connected component labeling on these results produces instance segmentation. We merge semantic and instance segmentation results to output panoptic segmentation. We evaluate our proposed method on the CityScapes dataset to demonstrate qualitative and quantitative performances along with several ablation studies. Our overview video can be accessed from https://youtu.be/wBtcxRhG3e0.",
        "primary_area": "",
        "author": "Sumanth Chennupati;Venkatraman Narayanan;Ganesh Sistu;Senthil Yogamani;Samir A Rawashdeh;Sumanth Chennupati;Venkatraman Narayanan;Ganesh Sistu;Senthil Yogamani;Samir A Rawashdeh",
        "authorids": "/37086087446;/37088690605;/37087107513;/37086351846;/38234632000;/37086087446;/37088690605;/37087107513;/37086351846;/38234632000",
        "aff": "Department of Electrical and Computer Engineering, University of Michigan-Dearborn, Dearborn, MI, USA; University of Maryland-College Park, College Park, MD, USA; Valeo Vision Systems, Tuam, Ireland; Valeo Vision Systems, Tuam, Ireland; Department of Electrical and Computer Engineering, University of Michigan-Dearborn, Dearborn, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560798/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5083274062933987420&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;0",
        "aff_unique_norm": "University of Michigan-Dearborn;University of Maryland;Valeo Vision Systems",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;;",
        "aff_unique_url": "https://umdearborn.edu;https://www/umd.edu;",
        "aff_unique_abbr": "UM-Dearborn;UMD;",
        "aff_campus_unique_index": "0;1;2;2;0",
        "aff_campus_unique": "Dearborn;College Park;Tuam",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "United States;Ireland"
    },
    {
        "id": "9561589",
        "title": "Learning Reachable Manifold and Inverse Mapping for a Redundant Robot manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Validating the kinematic feasibility of a planned robot motion and finding corresponding inverse solutions are time-consuming processes, especially for long-horizon manipulation tasks. Most existing approaches are based on solving iterative gradient-based optimization, so the processes are time-consuming and have a high risk of falling in local minima. In this work, we propose a unified framework to learn a kinematic feasibility model and a one-shot inverse mapping model for a redundant robot manipulator. Once they are trained, the models can compute the kinematic reachability of a target pose and its inverse solutions without iterative process. We validate our approach using a 7-DOF robot arm with an object grasping application.",
        "primary_area": "",
        "author": "Seungsu Kim;Julien Perez;Seungsu Kim;Julien Perez",
        "authorids": "/37633629100;/37088998752;/37633629100;/37088998752",
        "aff": "NAVER LABS Europe, Meylan, France; NAVER LABS Europe, Meylan, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561589/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10225994925397705737&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "NAVER LABS Europe",
        "aff_unique_dep": "",
        "aff_unique_url": "https://labs.naver.com",
        "aff_unique_abbr": "NAVER LABS Europe",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Meylan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561083",
        "title": "Learning Reactive and Predictive Differentiable Controllers for Switching Linear Dynamical Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans leverage the dynamics of the environment and their own bodies to accomplish challenging tasks such as grasping an object while walking past it or pushing off a wall to turn a corner. Such tasks often involve switching dynamics as the robot makes and breaks contact. Learning these dynamics is a challenging problem and prone to model inaccuracies, especially near contact regions. In this work, we present a framework for learning composite dynamical behaviors from expert demonstrations. We learn a switching linear dynamical model with contacts encoded in switching conditions as a close approximation of our system dynamics. We then use discrete-time LQR as the differentiable policy class for data-efficient learning of control to develop a control strategy that operates over multiple dynamical modes and takes into account discontinuities due to contact. In addition to predicting interactions with the environment, our policy effectively reacts to inaccurate predictions such as unanticipated contacts. Through simulation and real world experiments, we demonstrate generalization of learned behaviors to different scenarios and robustness to model inaccuracies during execution.",
        "primary_area": "",
        "author": "Saumya Saxena;Alex LaGrassa;Oliver Kroemer;Saumya Saxena;Alex LaGrassa;Oliver Kroemer",
        "authorids": "/37086365761;/37088689868;/37593222300;/37086365761;/37088689868;/37593222300",
        "aff": "Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561083/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16283418300632103641&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute, School of Computer Science",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561159",
        "title": "Learning Robot Trajectories subject to Kinematic Joint Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an approach to learn fast and dynamic robot motions without exceeding limits on the position \u03b8, velocity \\dot \\theta \\dot \\theta  , acceleration \\ddot \\theta \\ddot \\theta  and jerk \\dddot \\theta \\dddot \\theta  of each robot joint. Movements are generated by mapping the predictions of a neural network to safely executable joint accelerations. The neural network is invoked periodically and trained via reinforcement learning. Our main contribution is an analytical procedure for calculating safe joint accelerations, which considers the prediction frequency fN of the neural network. As a result, the frequency fN can be freely chosen and treated as a hyperparameter. We show that our approach is preferable to penalizing constraint violations as it provides explicit guarantees and does not distort the desired optimization target. In addition, the influence of the selected prediction frequency on the learning performance and on the computing effort is highlighted by various experiments.",
        "primary_area": "",
        "author": "Jonas C. Kiemel;Torsten Kr\u00f6ger;Jonas C. Kiemel;Torsten Kr\u00f6ger",
        "authorids": "/37088504301;/37283223400;/37088504301;/37283223400",
        "aff": "Institute for Anthropomatics and Robotics \u2013 Intelligent Process Automation and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT); Institute for Anthropomatics and Robotics \u2013 Intelligent Process Automation and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561159/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10354826196763912661&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics \u2013 Intelligent Process Automation and Robotics (IAR-IPR)",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561104",
        "title": "Learning Sampling Distributions Using Local 3D Workspace Decompositions for Motion Planning in High Dimensions",
        "track": "main",
        "status": "Poster",
        "abstract": "Earlier work has shown that reusing experience from prior motion planning problems can improve the efficiency of similar, future motion planning queries. However, for robots with many degrees-of-freedom, these methods exhibit poor generalization across different environments and often require large datasets that are impractical to gather. We present SPARK and FLAME, two experience-based frameworks for sampling-based planning applicable to complex manipulators in 3D environments. Both combine samplers associated with features from a workspace decomposition into a global biased sampling distribution. SPARK decomposes the environment based on exact geometry while FLAME is more general, and uses an octree-based decomposition obtained from sensor data. We demonstrate the effectiveness of SPARK and FLAME on a real and simulated Fetch robot tasked with challenging pick-and-place manipulation problems. Our approaches can be trained incrementally and significantly improve performance with only a handful of examples, generalizing better over diverse tasks and environments as compared to prior approaches.",
        "primary_area": "",
        "author": "Constantinos Chamzas;Zachary Kingston;Carlos Quintero-Pe\u00f1a;Anshumali Shrivastava;Lydia E. Kavraki;Constantinos Chamzas;Zachary Kingston;Carlos Quintero-Pe\u00f1a;Anshumali Shrivastava;Lydia E. Kavraki",
        "authorids": "/37086933748;/37085542480;/37088997672;/37085998758;/37279015600;/37086933748;/37085542480;/37088997672;/37085998758;/37279015600",
        "aff": "Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA; Department of Computer Science, Rice University, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561104/",
        "gs_citation": 51,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9222434855804015043&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561431",
        "title": "Learning Seed Placements and Automation Policies for Polyculture Farming with Companion Plants",
        "track": "main",
        "status": "Poster",
        "abstract": "Polyculture farming is a sustainable farming technique based on synergistic interactions between differing plant types that make them more resistant to diseases and pests and better able to retain water. Reduced uniformity can reduce use of pesticides, fertilizer, and water, but is more labor intensive and more challenging to automate. We describe a scaled physical testbed (1.5m\u00d73.0m) that uses a high resolution camera and soil sensors to monitor polyculture plants to facilitate tuning of plant growth, companion effects, and irrigation parameters for a first-order garden simulator. We use this simulator to develop a novel seed placement algorithm that increases coverage and diversity, and a learned pruning policy. In simulation experiments, the seed placement algorithm yields 60% more coverage and 10% more diversity than random seed placement and the learned pruning policy runs 1000X faster than a procedural lookahead policy to achieve high leaf coverage and plant diversity on adversarial gardens that include plant species with diverse growth rates. These models and policies provide the groundwork for a fully-automated system under development. Code, datasets and supplementary material can be found at https://github.com/BerkeleyAutomation/AlphaGarden/.",
        "primary_area": "",
        "author": "Yahav Avigal;Anna Deza;William Wong;Sebastian Oehme;Mark Presten;Mark Theis;Jackson Chui;Paul Shao;Huang Huang;Atsunobu Kotani;Satvik Sharma;Rishi Parikh;Michael Luo;Sandeep Mukherjee;Stefano Carpin;Joshua H. Viers;Stavros Vougioukas;Ken Goldberg;Yahav Avigal;Anna Deza;William Wong;Sebastian Oehme;Mark Presten;Mark Theis;Jackson Chui;Paul Shao;Huang Huang;Atsunobu Kotani;Satvik Sharma;Rishi Parikh;Michael Luo;Sandeep Mukherjee;Stefano Carpin;Joshua H. Viers;Stavros Vougioukas;Ken Goldberg",
        "authorids": "/37088504860;/37088999124;/37088525514;/37088996500;/37088525753;/37088526473;/37088525765;/37088996958;/37089855068;/37086936681;/37089000005;/37088997522;/37088846967;/37089000421;/37328709200;/37085902294;/37085902883;/37273026700;/37088504860;/37088999124;/37088525514;/37088996500;/37088525753;/37088526473;/37088525765;/37088996958;/37089855068;/37086936681;/37089000005;/37088997522;/37088846967;/37089000421;/37328709200;/37085902294;/37085902883;/37273026700",
        "aff": "The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; Department of Electrical and Computer Engineering, TU Munich; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; The AUTOLab, UC Berkeley; School of Engineering, UC Merced; Environmental Systems, School of Engineering, UC Merced; Biological and Agricultural Engineering, UC Davis; The AUTOLab, UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561431/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11145749381562986855&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 36,
        "aff_unique_index": "0;0;0;1;0;0;0;0;0;0;0;0;0;0;2;2;3;0",
        "aff_unique_norm": "University of California, Berkeley;Technical University of Munich;University of California, Merced;University of California, Davis",
        "aff_unique_dep": "The AUTOLab;Department of Electrical and Computer Engineering;School of Engineering;Department of Biological and Agricultural Engineering",
        "aff_unique_url": "https://www.berkeley.edu;https://www.tum.de;https://www.ucmerced.edu;https://www.ucdavis.edu",
        "aff_unique_abbr": "UC Berkeley;TUM;UC Merced;UC Davis",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0;2;2;3;0",
        "aff_campus_unique": "Berkeley;;Merced;Davis",
        "aff_country_unique_index": "0;0;0;1;0;0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "9561029",
        "title": "Learning Sequences of Manipulation Primitives for Robotic Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper explores the idea that skillful assembly is best represented as dynamic sequences of Manipulation Primitives, and that such sequences can be automatically discovered by Reinforcement Learning. Manipulation Primitives, such as \"Move down until contact\", \"Slide along x while maintaining contact with the surface\", have enough complexity to keep the search tree shallow, yet are generic enough to generalize across a wide range of assembly tasks. Moreover, the additional \"semantics\" of the Manipulation Primitives make them more robust in sim2real and against model/environment variations and uncertainties, as compared to more elementary actions. Policies are learned in simulation, and then transferred onto a physical platform. Direct sim2real transfer (without retraining in real) achieves excellent success rates on challenging assembly tasks, such as round peg insertion with 0.04mm clearance or square peg insertion with large hole position/orientation estimation errors.",
        "primary_area": "",
        "author": "Nghia Vuong;Hung Pham;Quang-Cuong Pham;Nghia Vuong;Hung Pham;Quang-Cuong Pham",
        "authorids": "/37088998949;/37086073905;/38191381800;/37088998949;/37086073905;/38191381800",
        "aff": "Singapore Centre for 3D Printing (SC3DP), School of Mechanical and Aerospace Engineering, NTU, Singapore; Eureka Robotics, Singapore; Eureka Robotics, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561029/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7589363460962455565&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Nanyang Technological University;Eureka Robotics",
        "aff_unique_dep": "School of Mechanical and Aerospace Engineering;",
        "aff_unique_url": "https://www.ntu.edu.sg;",
        "aff_unique_abbr": "NTU;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9561984",
        "title": "Learning Shape Control of Elastoplastic Deformable Linear Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Deformable object manipulation tasks have long been regarded as challenging robotic problems. However, until recently very little work has been done on the subject, with most robotic manipulation methods being developed for rigid objects. Deformable objects are more difficult to model and simulate, which has limited the use of model-free Reinforcement Learning (RL) strategies, due to their need for large amounts of data that can only be satisfied in simulation. This paper proposes a new shape control task for Deformable Linear Objects (DLOs). More notably, we present the first study on the effects of elastoplastic properties on this type of problem. Objects with elastoplasticity such as metal wires, are found in various applications and are challenging to manipulate due to their nonlinear behavior. We first highlight the challenges of solving such a manipulation task from an RL perspective, particularly in defining the reward. Then, based on concepts from differential geometry, we propose an intrinsic shape representation using discrete curvature and torsion. Finally, we show through an empirical study that in order to successfully solve the proposed task using Deep Deterministic Policy Gradient (DDPG), the reward needs to include intrinsic information about the shape of the DLO.",
        "primary_area": "",
        "author": "Rita Laezza;Yiannis Karayiannidis;Rita Laezza;Yiannis Karayiannidis",
        "authorids": "/37088996941;/37300987100;/37088996941;/37300987100",
        "aff": "Department of Electrical Engineering, Division of Systems and Control, Chalmers University of Technology, Sweden; Department of Electrical Engineering, Division of Systems and Control, Chalmers University of Technology, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561984/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6694953620936466474&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Chalmers University of Technology",
        "aff_unique_dep": "Department of Electrical Engineering, Division of Systems and Control",
        "aff_unique_url": "https://www.chalmers.se",
        "aff_unique_abbr": "Chalmers",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9561960",
        "title": "Learning Spatial Context with Graph Neural Network for Multi-Person Pose Grouping",
        "track": "main",
        "status": "Poster",
        "abstract": "Bottom-up approaches for image-based multi-person pose estimation consist of two stages: (1) keypoint detection and (2) grouping of the detected keypoints to form person instances. Current grouping approaches rely on learned embedding from only visual features that completely ignore the spatial configuration of human poses. In this work, we formulate the grouping task as a graph partitioning problem, where we learn the affinity matrix with a Graph Neural Network (GNN). More specifically, we design a Geometry-aware Association GNN that utilizes spatial information of the keypoints and learns local affinity from the global context. The learned geometry-based affinity is further fused with appearance-based affinity to achieve robust keypoint association. Spectral clustering is used to partition the graph for the formation of the pose instances. Experimental results on two benchmark datasets show that our proposed method outperforms existing appearance-only grouping frameworks, which shows the effectiveness of utilizing spatial context for robust grouping. Source code is available at: https://github.com/jiahaoLjh/PoseGrouping.",
        "primary_area": "",
        "author": "J Jiahao Lin;Gim Hee Lee;J Jiahao Lin;Gim Hee Lee",
        "authorids": "/37088997145;/37088505845;/37088997145;/37088505845",
        "aff": "Department of Computer Science, National University of Singapore; Department of Computer Science, National University of Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561960/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10806540315409377629&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9562071",
        "title": "Learning Stable Normalizing-Flow Control for Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement Learning (RL) of robotic manipulation skills, despite its impressive successes, stands to benefit from incorporating domain knowledge from control theory. One of the most important properties that is of interest is control stability. Ideally, one would like to achieve stability guarantees while staying within the framework of state-of-the-art deep RL algorithms. Such a solution does not exist in general, especially one that scales to complex manipulation tasks. We contribute towards closing this gap by introducing normalizing-flow control structure, that can be deployed in any latest deep RL algorithms. While stable exploration is not guaranteed, our method is designed to ultimately produce deterministic controllers with provable stability. In addition to demonstrating our method on challenging contact-rich manipulation tasks, we also show that it is possible to achieve considerable exploration efficiency\u2013reduced state space coverage and actuation efforts\u2013 without losing learning efficiency.",
        "primary_area": "",
        "author": "Shahbaz Abdul Khader;Hang Yin;Pietro Falco;Danica Kragic;Shahbaz Abdul Khader;Hang Yin;Pietro Falco;Danica Kragic",
        "authorids": "/37085591944;/37088353838;/38076626900;/37281296000;/37085591944;/37088353838;/38076626900;/37281296000",
        "aff": "ABB Corporate Research, Vasteras, Sweden; Robotics, Perception, and Learning lab, KTH Royal Institute of Technology, Stockholm, Sweden; ABB Corporate Research, Vasteras, Sweden; Robotics, Perception, and Learning lab, KTH Royal Institute of Technology, Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562071/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4097211576822241774&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "ABB Corporate Research;KTH Royal Institute of Technology",
        "aff_unique_dep": ";Robotics, Perception, and Learning lab",
        "aff_unique_url": "https://new.abb.com/research;https://www.kth.se",
        "aff_unique_abbr": "ABB;KTH",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Stockholm",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9561603",
        "title": "Learning Surgical Motion Pattern from Small Data in Endoscopic Sinus and Skull Base Surgeries",
        "track": "main",
        "status": "Poster",
        "abstract": "Existing studies demonstrated that surgical motion patterns are strongly correlated with surgical outcomes. Real surgeries are complicated and it is expensive to harvest surgical data. Consequently, existing researches on surgical motion patterns focus on specific concise surgical tasks or simple surgical procedures. The paper presents a surgical motion pattern modeling technique that uses small data but can be applied to virtually any Endoscopic Sinus and Skull Base Surgeries (ESSBSs). The proposed method decreases the dimensionalities of the feature space through projecting surgical instrument motions into the endoscope coordinate, based on human expert domain knowledge. Furthermore, the method uses kinematic features and learns the motion pattern with Gaussian Process learning techniques. Comparing with existing surgical motion pattern modeling methods, the proposed method: 1, learns the motion model from small data; 2, can be generally applied to ESSBSs because it neither assumes nor depends on specific surgical tasks; 3, provides informative results in a real-time manner for optimizing surgical motions for improving surgical outcomes. The proposed method was verified by predicting surgical skill levels on cadaver surgeries. The results show the real-time prediction precision is higher than 81% and the offline accumulated precision reach 100%.",
        "primary_area": "",
        "author": "Yangming Li;Randall Bly;Sarah Akkina;Fangbo Qin;Rajeev C. Saxena;Ian Humphreys;Mark Whipple;Kris Moe;Blake Hannaford;Yangming Li;Randall Bly;Sarah Akkina;Fangbo Qin;Rajeev C. Saxena;Ian Humphreys;Mark Whipple;Kris Moe;Blake Hannaford",
        "authorids": "/37086145026;/37088474747;/37088996997;/37085793636;/37089001109;/37088999442;/37088997272;/37088193333;/37272234100;/37086145026;/37088474747;/37088996997;/37085793636;/37089001109;/37088999442;/37088997272;/37088193333;/37272234100",
        "aff": "RoCAL, Rochester Institute of Technology, Rochester, NY, USA; School of Medicine, University of Washington, Seattle, WA, USA; School of Medicine, University of Washington, Seattle, WA, USA; BioRobotics Lab., University of Washington, Seattle, WA, USA; School of Medicine, University of Washington, Seattle, WA, USA; School of Medicine, University of Washington, Seattle, WA, USA; School of Medicine, University of Washington, Seattle, WA, USA; School of Medicine, University of Washington, Seattle, WA, USA; BioRobotics Lab., University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561603/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3427834704876856739&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;1;1;1;1;1;1;1",
        "aff_unique_norm": "Rochester Institute of Technology;University of Washington",
        "aff_unique_dep": "RoCAL;School of Medicine",
        "aff_unique_url": "https://www.rit.edu;https://www.washington.edu",
        "aff_unique_abbr": "RIT;UW",
        "aff_campus_unique_index": "0;1;1;1;1;1;1;1;1",
        "aff_campus_unique": "Rochester;Seattle",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561011",
        "title": "Learning Tactile Models for Factor Graph-based Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We\u2019re interested in the problem of estimating object states from touch during manipulation under occlusions. In this work, we address the problem of estimating object poses from touch during planar pushing. Vision-based tactile sensors provide rich, local image measurements at the point of contact. A single such measurement, however, contains limited information and multiple measurements are needed to infer latent object state. We solve this inference problem using a factor graph. In order to incorporate tactile measurements in the graph, we need local observation models that can map highdimensional tactile images onto a low-dimensional state space. Prior work has used low-dimensional force measurements or engineered functions to interpret tactile measurements. These methods, however, can be brittle and difficult to scale across objects and sensors. Our key insight is to directly learn tactile observation models that predict the relative pose of the sensor given a pair of tactile images. These relative poses can then be incorporated as factors within a factor graph. We propose a two-stage approach: first we learn local tactile observation models supervised with ground truth data, and then integrate these models along with physics and geometric factors within a factor graph optimizer. We demonstrate reliable object tracking using only tactile feedback for ~150 real-world planar pushing sequences with varying trajectories across three object shapes.",
        "primary_area": "",
        "author": "Paloma Sodhi;Michael Kaess;Mustafa Mukadam;Stuart Anderson;Paloma Sodhi;Michael Kaess;Mustafa Mukadam;Stuart Anderson",
        "authorids": "/38469682300;/37324200400;/37085562050;/37089001454;/38469682300;/37324200400;/37085562050;/37089001454",
        "aff": "Work done when Paloma Sodhi interned at Facebook AI Research. psodhi@cs.cmu.edu.; Camegie Mellon University; Facebook AI Research; Facebook AI Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561011/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7150890189942522133&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Meta;Carnegie Mellon University",
        "aff_unique_dep": "Facebook AI Research;",
        "aff_unique_url": "https://research.facebook.com;https://www.cmu.edu",
        "aff_unique_abbr": "FAIR;CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561705",
        "title": "Learning Task Space Actions for Bipedal Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work has demonstrated the success of reinforcement learning (RL) for training bipedal locomotion policies for real robots. This prior work, however, has focused on learning joint-coordination controllers based on an objective of following joint trajectories produced by already available controllers. As such, it is difficult to train these approaches to achieve higher-level goals of legged locomotion, such as simply specifying the desired end-effector foot movement or ground reaction forces. In this work, we propose an approach for integrating knowledge of the robot system into RL to allow for learning at the level of task space actions in terms of feet setpoints. In particular, we integrate learning a task space policy with a model-based inverse dynamics controller, which translates task space actions into joint-level controls. With this natural action space for learning locomotion, the approach is more sample efficient and produces desired task space dynamics compared to learning purely joint space actions. We demonstrate the approach in simulation and also show that the learned policies are able to transfer to the real bipedal robot Cassie. This result encourages further research towards incorporating bipedal control techniques into the structure of the learning process to enable dynamic behaviors.",
        "primary_area": "",
        "author": "Helei Duan;Jeremy Dao;Kevin Green;Taylor Apgar;Alan Fern;Jonathan Hurst;Helei Duan;Jeremy Dao;Kevin Green;Taylor Apgar;Alan Fern;Jonathan Hurst",
        "authorids": "/37086154386;/37086114282;/37087323965;/37089002051;/37353413400;/37267365600;/37086154386;/37086114282;/37087323965;/37089002051;/37353413400;/37267365600",
        "aff": "Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Agility Robotics, Albany, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA; Collaborative Robotics and Intelligent Systems Institute, Oregon State University, Corvallis, Oregon, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561705/",
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16983360375795898506&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Oregon State University;Agility Robotics",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems Institute;",
        "aff_unique_url": "https://oregonstate.edu;",
        "aff_unique_abbr": "OSU;",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Corvallis;Albany",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562073",
        "title": "Learning Task-Oriented Dexterous Grasping from Human Knowledge",
        "track": "main",
        "status": "Poster",
        "abstract": "Industrial automation requires robot dexterity to automate many processes such as product assembling, packaging, and material handling. The existing robotic systems lack the capability to determining proper grasp strategies in the context of object affordances and task designations. In this paper, a framework of task-oriented dexterous grasping is proposed to learn grasp knowledge from human experience and to deploy the grasp strategies while adapting to grasp context. Grasp topology is defined and grasp strategies are learned from an established dataset for task-oriented dexterous manipulation. To adapt to various grasp context, a reinforcement-learning based grasping policy was implemented to deploy different task-oriented strategies. The performance of the system was evaluated in a simulated grasping environment by using an AR10 anthropomorphic hand installed in a Sawyer robotic arm. The proposed framework achieved a hit rate of 100% for grasp strategies and an overall top-3 match rate of 95.6%. The success rate of grasping was 85.6% during 2700 grasping experiments for manipulation tasks given in natural-language instructions.",
        "primary_area": "",
        "author": "Hui Li;Yinlong Zhang;Yanan Li;Hongsheng He;Hui Li;Yinlong Zhang;Yanan Li;Hongsheng He",
        "authorids": "/37087243324;/37085338122;/37089398754;/37085561124;/37087243324;/37085338122;/37089398754;/37085561124",
        "aff": "Department of Electrical Engineering and Computer Science, Wichita State University, USA; State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences, Shenyang, China; Department of Engineering and Design, University of Sussex, UK; Department of Electrical Engineering and Computer Science, Wichita State University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562073/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1349757895326501214&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Wichita State University;Shenyang Institute of Automation, Chinese Academy of Sciences;University of Sussex",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science;State Key Laboratory of Robotics;Department of Engineering and Design",
        "aff_unique_url": "https://www.wichita.edu;http://www.sia.cas.cn;https://www.sussex.ac.uk",
        "aff_unique_abbr": "WSU;SIA;Sussex",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shenyang",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "United States;China;United Kingdom"
    },
    {
        "id": "9561737",
        "title": "Learning Visual Affordances with Target-Orientated Deep Q-Network to Grasp Objects by Harnessing Environmental Fixtures",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a challenging object grasping task and proposes a self-supervised learning approach. The goal of the task is to grasp an object which is not feasible with a single parallel gripper, but only with harnessing environment fixtures (e.g., walls, furniture, heavy objects). This Slide-to-Wall grasping task assumes no prior knowledge except the partial observation of a target object. Hence the robot should learn an effective policy given a scene observation that may include the target object, environmental fixtures, and any other disturbing objects. We formulate the problem as visual affordances learning for which Target-Oriented Deep Q-Network (TO-DQN) is proposed to efficiently learn visual affordance maps (i.e., Q-maps) to guide robot actions. Since the training necessitates robot's exploration and collision with the fixtures, TO-DQN is first trained safely with a simulated robot manipulator and then applied to a real robot. We empirically show that TO-DQN can learn to solve the task in different environment settings in simulation and outperforms a standard and a variant of Deep Q-Network (DQN) in terms of training efficiency and robustness. The testing performance in both simulation and real-robot experiments shows that the policy trained by TO-DQN achieves comparable performance to humans.",
        "primary_area": "",
        "author": "Hengyue Liang;Xibai Lou;Yang Yang;Changhyun Choi;Hengyue Liang;Xibai Lou;Yang Yang;Changhyun Choi",
        "authorids": "/37088072759;/37088504165;/37088070512;/37085811337;/37088072759;/37088504165;/37088070512;/37085811337",
        "aff": "University of Minnesota, Minneapolis, MN, USA; University of Minnesota, Minneapolis, MN, USA; University of Minnesota, Minneapolis, MN, USA; University of Minnesota, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561737/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4396846230431520693&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.minnesota.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561973",
        "title": "Learning World Transition Model for Socially Aware Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Moving in dynamic pedestrian environments is one of the important requirements for autonomous mobile robots. We present a model-based reinforcement learning approach for robots to navigate through crowded environments. The navigation policy is trained with both real interaction data from multi-agent simulation and virtual data from a deep transition model that predicts the evolution of surrounding dynamics of mobile robots. A reward function considering social conventions is designed to guide the training of the policy. Specifically, the policy model takes laser scan sequence and robot\u2019s own state as input and outputs steering command. The laser sequence is further transformed into stacked local obstacle maps disentangled from robot\u2019s ego motion to separate the static and dynamic obstacles, simplifying the model training. We observe that the policy using our method can be trained with significantly less real interaction data in simulator but achieve similar level of success rate in social navigation tasks compared with other methods. Experiments are conducted in multiple social scenarios both in simulation and on real robots, the learned policy can guide the robots to the final targets successfully in a socially compliant manner. Code is available at https://github.com/YuxiangCui/model-based-social-navigation.",
        "primary_area": "",
        "author": "Yuxiang Cui;Haodong Zhang;Yue Wang;Rong Xiong;Yuxiang Cui;Haodong Zhang;Yue Wang;Rong Xiong",
        "authorids": "/37088954385;/37089393786;/37072299700;/37271511300;/37088954385;/37089393786;/37072299700;/37271511300",
        "aff": "State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561973/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5316791283178605615&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Zhejiang University",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology",
        "aff_unique_url": "http://www.zju.edu.cn",
        "aff_unique_abbr": "ZJU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562022",
        "title": "Learning a Centroidal Motion Planner for Legged Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Whole-body optimizers have been successful at automatically computing complex dynamic locomotion behaviors. However they are often limited to offline planning as they are computationally too expensive to replan with a high frequency. Simpler models are then typically used for online replanning. In this paper we present a method to generate whole body movements in real-time for locomotion tasks. Our approach consists in learning a centroidal neural network that predicts the desired centroidal motion given the current state of the robot and a desired contact plan. The network is trained using an existing whole body motion optimizer. Our approach enables to learn with few training samples dynamic motions that can be used in a complete whole-body control framework at high frequency, which is usually not attainable with typical full-body optimizers. We demonstrate our method to generate a rich set of walking and jumping motions on a real quadruped robot.",
        "primary_area": "",
        "author": "Julian Viereck;Ludovic Righetti;Julian Viereck;Ludovic Righetti",
        "authorids": "/37086428519;/37295828600;/37086428519;/37295828600",
        "aff": "Max Planck Institute for Intelligent Systems T\u00fcbingen, Germany; Max Planck Institute for Intelligent Systems T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562022/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16363080736638549352&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.mpi-is.mpg.de",
        "aff_unique_abbr": "MPI-IS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561793",
        "title": "Learning a Geometric Representation for Data-Efficient Depth Estimation via Gradient Field and Contrastive Loss",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating a depth map from a single RGB image has been investigated widely for localization, mapping, and 3- dimensional object detection. Recent studies on a single-view depth estimation are mostly based on deep Convolutional neural Networks (ConvNets) which require a large amount of training data paired with densely annotated labels. Depth annotation tasks are both expensive and inefficient, so it is inevitable to leverage RGB images which can be collected very easily to boost the performance of ConvNets without depth labels. However, most self-supervised learning algorithms are focused on capturing the semantic information of images to improve the performance in classification or object detection, not in depth estimation. In this paper, we show that existing self- supervised methods do not perform well on depth estimation and propose a gradient-based self-supervised learning algorithm with momentum contrastive loss to help ConvNets extract the geometric information with unlabeled images. As a result, the network can estimate the depth map accurately with a relatively small amount of annotated data. To show that our method is independent of the model structure, we evaluate our method with two different monocular depth estimation algorithms. Our method outperforms the previous state-of-the- art self-supervised learning algorithms and shows the efficiency of labeled data in triple compared to random initialization on the NYU Depth v2 dataset.",
        "primary_area": "",
        "author": "Dongseok Shim;H. Jin Kim;Dongseok Shim;H. Jin Kim",
        "authorids": "/37088567748;/37599626400;/37088567748;/37599626400",
        "aff": "Department of Mechanical and Aerospace Engineering, Seoul National University, Gwanak-gu, Seoul, Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Gwanak-gu, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561793/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5701130893343443479&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Gwanak-gu",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561819",
        "title": "Learning and Planning for Temporally Extended Tasks in Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel planning technique for satisfying tasks specified in temporal logic in partially revealed environments. We define high-level actions derived from the environment and the given task itself, and estimate how each action contributes to progress towards completing the task. As the map is revealed, we estimate the cost and probability of success of each action from images and an encoding of that action using a trained neural network. These estimates guide search for the minimum-expected-cost plan within our model. Our learned model is structured to generalize across environments and task specifications without requiring retraining. We demonstrate an improvement in total cost in both simulated and real-world experiments compared to a heuristic-driven baseline.",
        "primary_area": "",
        "author": "Christopher Bradley;Adam Pacheck;Gregory J. Stein;Sebastian Castro;Hadas Kress-Gazit;Nicholas Roy;Christopher Bradley;Adam Pacheck;Gregory J. Stein;Sebastian Castro;Hadas Kress-Gazit;Nicholas Roy",
        "authorids": "/37088507265;/37086835846;/37085348859;/38352614400;/38307602100;/37274058700;/37088507265;/37086835846;/37085348859;/38352614400;/38307602100;/37274058700",
        "aff": "CSAIL, MIT, Cambridge, MA, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA; Computer Science Department, George Mason University, Fairfax, VA, USA; CSAIL, MIT, Cambridge, MA, USA; Sibley School of Mechanical and Aerospace Engineering, Cornell University, Ithaca, NY, USA; CSAIL, MIT, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561819/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16420696591149765721&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Cornell University;George Mason University",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;Sibley School of Mechanical and Aerospace Engineering;Computer Science Department",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.cornell.edu;https://www.gmu.edu",
        "aff_unique_abbr": "MIT;Cornell;GMU",
        "aff_campus_unique_index": "0;1;2;0;1;0",
        "aff_campus_unique": "Cambridge;Ithaca;Fairfax",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560758",
        "title": "Learning from Demonstration for Real-Time User Goal Prediction and Shared Assistive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "In shared autonomy, the user input is blended with the assistive motion to accomplish a task where the user goal is typically unknown to the robot. Transparency between the human and robot is essential for effective collaboration. Prior works have provided methods for the robot to infer the user goal; however, they are usually dependent on the distance between the robot and object, which may not be directly associated with the real-time user control intention and thus cause low control feelings. Here, we propose a real-time goal prediction method driven by assistive motion generated by learning from demonstration (LfD) allowing more reactive assistive behaviors. This LfD-generated assistive motion is blended with the user input based on goal predictions to achieve targeted tasks. The LfD policy was learned offline and used with different users. To evaluate our proposed method, we compared it with a state-of-the-art Partially Observable Markov Decision Process (POMDP) based method using a distance cost, and a direct control method (i.e., joystick). A pilot study (N = 6) was conducted to control a 6-DoF Kinova Mico robotic arm to carry out three tasks: (1) reaching-and-grasping, (2) pouring, and (3) object-returning with the three control methods. We used both objective and subjective measures in the comparative study. Results show that our method has the shortest task completion time, the lowest amount of joystick control inputs among all three control methods, as well as a significantly lower angular difference between the user input and assistive motion compared to the POMDP-based method. Besides, it obtains the highest subjective score in the user preference and perceived speed ratings, and the second-highest in the control feeling and the robot did what I wanted ratings.",
        "primary_area": "",
        "author": "Calvin Z. Qiao;Maram Sakr;Katharina Muelling;Henny Admoni;Calvin Z. Qiao;Maram Sakr;Katharina Muelling;Henny Admoni",
        "authorids": "/37088998637;/37089465987;/37992473400;/38570430500;/37088998637;/37089465987;/37992473400;/38570430500",
        "aff": "Department of Mechanical Engineering, The University of British Columbia; Department of Mechanical Engineering, The University of British Columbia; Robotics Institute, Carnegie Mellon University; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560758/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10025552173438026910&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;1",
        "aff_unique_norm": "University of British Columbia;Carnegie Mellon University",
        "aff_unique_dep": "Department of Mechanical Engineering;Robotics Institute",
        "aff_unique_url": "https://www.ubc.ca;https://www.cmu.edu",
        "aff_unique_abbr": "UBC;CMU",
        "aff_campus_unique_index": "0;0;1;1",
        "aff_campus_unique": "Vancouver;Pittsburgh",
        "aff_country_unique_index": "0;0;1;1",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9561119",
        "title": "Learning from Demonstration without Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "State-of-the-art reinforcement learning (RL) algorithms suffer from high sample complexity, particularly in the sparse reward case. A popular strategy for mitigating this problem is to learn control policies by imitating a set of expert demonstrations. The drawback of such approaches is that an expert needs to produce demonstrations, which may be costly in practice. To address this shortcoming, we propose Probabilistic Planning for Demonstration Discovery (P2D2), a technique for automatically discovering demonstrations without access to an expert. We formulate discovering demonstrations as a search problem and leverage widely-used planning algorithms such as Rapidly-exploring Random Tree to find demonstration trajectories. These demonstrations are used to initialize a policy, then refined by a generic RL algorithm. We provide theoretical guarantees of P2D2 finding successful trajectories, as well as bounds for its sampling complexity. We experimentally demonstrate the method outperforms classic and intrinsic exploration RL techniques in a range of classic control and robotics tasks, requiring only a fraction of exploration samples and achieving better asymptotic performance.",
        "primary_area": "",
        "author": "Tom Blau;Philippe Morere;Gilad Francis;Tom Blau;Philippe Morere;Gilad Francis",
        "authorids": "/37086574012;/37086096993;/37086036906;/37086574012;/37086096993;/37086036906",
        "aff": "CSIRO, Australia; School of Computer Science, The University of Sydney, Australia; School of Computer Science, The University of Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561119/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9071196726856179258&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Commonwealth Scientific and Industrial Research Organisation;University of Sydney",
        "aff_unique_dep": ";School of Computer Science",
        "aff_unique_url": "https://www.csiro.au;https://www.sydney.edu.au",
        "aff_unique_abbr": "CSIRO;USYD",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";Sydney",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9562079",
        "title": "Learning from Simulation, Racing in Reality",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a reinforcement learning-based solution to autonomously race on a miniature race car platform. We show that a policy that is trained purely in simulation using a relatively simple vehicle model, including model randomization, can be successfully transferred to the real robotic setup. We achieve this by using a novel policy output regularization approach and a lifted action space which enables smooth actions but still aggressive race car driving. We show that this regularized policy does outperform the Soft Actor Critic (SAC) baseline method, both in simulation and on the real car, but it is still outperformed by a Model Predictive Controller (MPC) state-of-the-art method. The refinement of the policy with three hours of real-world interaction data allows the reinforcement learning policy to achieve lap times similar to the MPC controller while reducing track constraint violations by 50%.",
        "primary_area": "",
        "author": "Eugenio Chisari;Alexander Liniger;Alisa Rupenyan;Luc Van Gool;John Lygeros;Eugenio Chisari;Alexander Liniger;Alisa Rupenyan;Luc Van Gool;John Lygeros",
        "authorids": "/37086595380;/37085702116;/37088339059;/37277167600;/37301174800;/37086595380;/37085702116;/37088339059;/37277167600;/37301174800",
        "aff": "Automatic Control Lab, ETH Zurich, Switzerland; Computer Vision Lab, ETH Zurich, Switzerland; Automatic Control Lab, ETH Zurich, Switzerland; PSI, KU, Leuven, Belgium; Automatic Control Lab, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562079/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13381610588330239770&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "ETH Zurich;KU Leuven",
        "aff_unique_dep": "Automatic Control Lab;PSI",
        "aff_unique_url": "https://www.ethz.ch;https://www.kuleuven.be",
        "aff_unique_abbr": "ETHZ;KU Leuven",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Leuven",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Switzerland;Belgium"
    },
    {
        "id": "9561450",
        "title": "Learning robust driving policies without online exploration",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a multi-time-scale predictive representation learning method to efficiently learn robust driving policies in an offline manner that generalize well to novel road geometries, and damaged and distracting lane conditions which are not covered in the offline training data. We show that our proposed representation learning method can be applied easily in an offline (batch) reinforcement learning setting demonstrating the ability to generalize well and efficiently under novel conditions compared to standard batch RL methods. Our proposed method utilizes training data collected entirely offline in the real-world which removes the need of intensive online explorations that impede applying deep reinforcement learning on real-world robot training. Various experiments were conducted in both simulator and real-world scenarios for the purpose of evaluation and analysis of our proposed claims.",
        "primary_area": "",
        "author": "Daniel Graves;Nhat M. Nguyen;Kimia Hassanzadeh;Jun Jin;Jun Luo;Daniel Graves;Nhat M. Nguyen;Kimia Hassanzadeh;Jun Jin;Jun Luo",
        "authorids": "/37823099700;/37088503935;/37542809500;/37086574802;/37089002073;/37823099700;/37088503935;/37542809500;/37086574802;/37089002073",
        "aff": "Noah\u2019s Ark Lab, Huawei Technologies Canada; Noah\u2019s Ark Lab, Huawei Technologies Canada; Noah\u2019s Ark Lab, Huawei Technologies Canada; Noah\u2019s Ark Lab, Huawei Technologies Canada; Noah\u2019s Ark Lab, Huawei Technologies Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561450/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4895882459457105263&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Noah\u2019s Ark Lab",
        "aff_unique_url": "https://www.huawei.com/ca-en/",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561389",
        "title": "Learning the Next Best View for 3D Point Clouds via Topological Features",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we introduce a reinforcement learning approach utilizing a novel topology-based information gain metric for directing the next best view of a noisy 3D sensor. The metric combines the disjoint sections of an observed surface to focus on high-detail features such as holes and concave sections. Experimental results show that our approach can aid in establishing the placement of a robotic sensor to optimize the information provided by its streaming point cloud data. Furthermore, a labeled dataset of 3D objects, a CAD design for a custom robotic manipulator, and software for the transformation, union, and registration of point clouds has been publicly released to the research community.",
        "primary_area": "",
        "author": "Christopher Collander;William J. Beksi;Manfred Huber;Christopher Collander;William J. Beksi;Manfred Huber",
        "authorids": "/37088371544;/37085463379;/37325563900;/37088371544;/37085463379;/37325563900",
        "aff": "Department of Computer Science and Engineering, University of Texas at Arlington, Arlington, TX, USA; Department of Computer Science and Engineering, University of Texas at Arlington, Arlington, TX, USA; Department of Computer Science and Engineering, University of Texas at Arlington, Arlington, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561389/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18184280588218466046&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Texas at Arlington",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.uta.edu",
        "aff_unique_abbr": "UTA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Arlington",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560872",
        "title": "Learning to Localize in New Environments from Synthetic Training Data",
        "track": "main",
        "status": "Poster",
        "abstract": "Most existing approaches for visual localization either need a detailed 3D model of the environment or, in the case of learning-based methods, must be retrained for each new scene. This can either be very expensive or simply impossible for large, unknown environments, for example in search-and-rescue scenarios. Although there are learning-based approaches that operate scene-agnostically, the generalization capability of these methods is still outperformed by classical approaches. In this paper, we present an approach that can generalize to new scenes by applying specific changes to the model architecture, including an extended regression part, the use of hierarchical correlation layers, and the exploitation of scale and uncertainty information. Our approach outperforms the 5-point algorithm using SIFT features on equally big images and additionally surpasses all previous learning-based approaches that were trained on different data. It is also superior to most of the approaches that were specifically trained on the respective scenes. We also evaluate our approach in a scenario with only very few reference images, showing that under such more realistic conditions our learning-based approach considerably exceeds both existing learning-based and classical methods.",
        "primary_area": "",
        "author": "Dominik Winkelbauer;Maximilian Denninger;Rudolph Triebel;Dominik Winkelbauer;Maximilian Denninger;Rudolph Triebel",
        "authorids": "/37089000838;/37086577819;/37542908700;/37089000838;/37086577819;/37542908700",
        "aff": "Dep. of Perception and Cognition, German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; Dep. of Perception and Cognition, German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; Dep. of Perception and Cognition, German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560872/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17567719272783490352&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "German Aerospace Center",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561383",
        "title": "Learning to Predict Repeatability of Interest Points",
        "track": "main",
        "status": "Poster",
        "abstract": "Many robotics applications require interest points that are highly repeatable under varying viewpoints and lighting conditions. However, this requirement is very challenging as the environment changes continuously and indefinitely, leading to appearance changes of interest points with respect to time. This paper proposes to predict the repeatability of an interest point as a function of time, which can tell us the lifespan of the interest point considering daily or seasonal variation. The repeatability predictor (RP) is formulated as a regressor trained on repeated interest points from multiple viewpoints over a long period of time. Through comprehensive experiments, we demonstrate that our RP can estimate when a new interest point is repeated, and also highlight an insightful analysis about this problem. For further comparison, we apply our RP to the map summarization under visual localization framework, which builds a compact representation of the full context map given the query time. The experimental result shows a careful selection of potentially repeatable interest points predicted by our RP can significantly mitigate the degeneration of localization accuracy from map summarization.",
        "primary_area": "",
        "author": "Anh-Dzung Doan;Daniyar Turmukhambetov;Yasir Latif;Tat-Jun Chin;Soohyun Bae;Anh-Dzung Doan;Daniyar Turmukhambetov;Yasir Latif;Tat-Jun Chin;Soohyun Bae",
        "authorids": "/37086526070;/37085643350;/38541523400;/37411757200;/37088996264;/37086526070;/37085643350;/38541523400;/37411757200;/37088996264",
        "aff": "School of Computer Science, The University of Adelaide; Niantic; School of Computer Science, The University of Adelaide; School of Computer Science, The University of Adelaide; Niantic",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561383/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10578509972503224833&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "University of Adelaide;Niantic",
        "aff_unique_dep": "School of Computer Science;",
        "aff_unique_url": "https://www.adelaide.edu.au;https://www.nianticlabs.com",
        "aff_unique_abbr": "Adelaide;Niantic",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;1",
        "aff_country_unique": "Australia;United States"
    },
    {
        "id": "9561636",
        "title": "Learning to Propagate Interaction Effects for Modeling Deformable Linear Objects Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Modeling dynamics of deformable linear objects (DLOs), such as cables, hoses, sutures, and catheters, is an important and challenging problem for many robotic manipulation applications. In this paper, we propose the first method to model and learn full 3D dynamics of DLOs from data. Our approach is capable of capturing the complex twisting and bending dynamics of DLOs and allows local effects to propagate globally. To this end, we adapt the interaction network (IN) dynamics learning method for capturing the interaction between neighboring segments in a DLO and augment it with a recurrent model for propagating interaction effects along the length of a DLO. For learning twisting and bending dynamics in 3D, we also introduce a new suitable representation of DLO segments and their relationships. Unlike the original IN method, our model learns to propagate the effects of local interaction between neighboring segments to each segment in the chain within a single time step, without the need for iterated propagation steps. Evaluation of our model with synthetic and newly collected real-world data shows better accuracy and generalization in short-term and long- term predictions than the current state of the art. We further integrate our learned model in a model predictive control scheme and use it to successfully control the shape of a DLO. Our implementation is available at https://gitsvn-nt.oru.se/ammlab\u2013public/in\u2013bilstm.",
        "primary_area": "",
        "author": "Yuxuan Yang;Johannes A. Stork;Todor Stoyanov;Yuxuan Yang;Johannes A. Stork;Todor Stoyanov",
        "authorids": "/37088996310;/37544515300;/37601557800;/37088996310;/37544515300;/37601557800",
        "aff": "Autonomous Mobile Manipulation Lab, Center for Applied Autonomous Sensor Systems (AASS), \u00d6rebro University, Sweden; Autonomous Mobile Manipulation Lab, Center for Applied Autonomous Sensor Systems (AASS), \u00d6rebro University, Sweden; Autonomous Mobile Manipulation Lab, Center for Applied Autonomous Sensor Systems (AASS), \u00d6rebro University, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561636/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14300702931305857565&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "\u00d6rebro University",
        "aff_unique_dep": "Center for Applied Autonomous Sensor Systems (AASS)",
        "aff_unique_url": "https://www.oru.se",
        "aff_unique_abbr": "\u00d6rebro U",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9561391",
        "title": "Learning to Rearrange Deformable Cables, Fabrics, and Bags with Goal-Conditioned Transporter Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Rearranging and manipulating deformable objects such as cables, fabrics, and bags is a long-standing challenge in robotic manipulation. The complex dynamics and high-dimensional configuration spaces of deformables, compared to rigid objects, make manipulation difficult not only for multi-step planning, but even for goal specification. Goals cannot be as easily specified as rigid object poses, and may involve complex relative spatial relations such as \"place the item inside the bag\". In this work, we develop a suite of simulated benchmarks with 1D, 2D, and 3D deformable structures, including tasks that involve image-based goal-conditioning and multi-step deformable manipulation. We propose embedding goal-conditioning into Transporter Networks, a recently proposed model architecture for learning robotic manipulation that rearranges deep features to infer displacements that can represent pick and place actions. We demonstrate that goal-conditioned Transporter Networks enable agents to manipulate deformable structures into flexibly specified configurations without test-time visual anchors for target locations. We also significantly extend prior results using Transporter Networks for manipulating deformable objects by testing on tasks with 2D and 3D deformables. Supplementary material is available at https://berkeleyautomation.github.io/bags/.",
        "primary_area": "",
        "author": "Daniel Seita;Pete Florence;Jonathan Tompson;Erwin Coumans;Vikas Sindhwani;Ken Goldberg;Andy Zeng;Daniel Seita;Pete Florence;Jonathan Tompson;Erwin Coumans;Vikas Sindhwani;Ken Goldberg;Andy Zeng",
        "authorids": "/37086012763;/37085786926;/38093908100;/37086455409;/37282057000;/37273026700;/37086217185;/37086012763;/37085786926;/38093908100;/37086455409;/37282057000;/37273026700;/37086217185",
        "aff": "Autolab at the University of California, Berkeley, USA; Google Research, USA; Google Research, USA; Google Research, USA; Google Research, USA; Autolab at the University of California, Berkeley, USA; Google Research, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561391/",
        "gs_citation": 200,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13668760499382970037&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;1;0;1",
        "aff_unique_norm": "University of California, Berkeley;Google",
        "aff_unique_dep": "Autolab;Google Research",
        "aff_unique_url": "https://www.berkeley.edu;https://research.google",
        "aff_unique_abbr": "UC Berkeley;Google",
        "aff_campus_unique_index": "0;1;1;1;1;0;1",
        "aff_campus_unique": "Berkeley;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561071",
        "title": "Learning to Robustly Negotiate Bi-Directional Lane Usage in High-Conflict Driving Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, autonomous driving has made substantial progress in addressing the most common traffic scenarios like intersection navigation and lane changing. However, most of these successes have been limited to scenarios with well-defined traffic rules and require minimal negotiation with other vehicles. In this paper, we introduce a previously unconsidered, yet everyday, high-conflict driving scenario requiring negotiations between agents of equal rights and priorities. There exists no centralized control structure and we do not allow communications. Therefore, it is unknown if other drivers are willing to cooperate, and if so to what extent. We train policies to robustly negotiate with opposing vehicles of an unobservable degree of cooperativeness using multi-agent reinforcement learning (MARL). We propose Discrete Asymmetric Soft Actor-Critic (DASAC), a maximum- entropy off-policy MARL algorithm allowing for centralized training with decentralized execution. We show that using DASAC we are able to successfully negotiate and traverse the scenario considered over 99% of the time. Our agents are robust to an unknown timing of opponent decisions, an unobservable degree of cooperativeness of the opposing vehicle, and previously unencountered policies. Furthermore, they learn to exhibit human-like behaviors such as defensive driving, anticipating solution options and interpreting the behavior of other agents.",
        "primary_area": "",
        "author": "Christoph Killing;Adam Villaflor;John M. Dolan;Christoph Killing;Adam Villaflor;John M. Dolan",
        "authorids": "/37088999745;/37086454225;/37283756800;/37088999745;/37086454225;/37283756800",
        "aff": "The Robotics Institute, Carnegie Mellon University; The Robotics Institute, Carnegie Mellon University; The Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561071/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13969909181781801075&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "The Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561160",
        "title": "Learning to steer a locomotion contact planner",
        "track": "main",
        "status": "Poster",
        "abstract": "The combinatorics inherent to the issue of planning legged locomotion can be addressed by decomposing the problem: first, select a guide path abstracting the contacts with a heuristic model; then compute the contact sequence to balance the robot gait along the guide path. While several models have been proposed to compute such a path, none have yet managed to efficiently capture the complexity of legged locomotion on arbitrary terrain. In this paper, we present a novel method to automatically build a local controller, or steering method, to generate a guide path along which a feasible contact sequence can be built. Our reinforcement learning approach is coupled with a geometric condition for feasibility during the training, which improves the convergence rate without incurring a loss in generality. We have designed a dedicated environment along with an associated reward function to run a classical reinforcement learning algorithm that computes the steering method. The policy takes a target velocity and a local heightmap of the terrain around the robot as inputs, and steers the path where new contacts should be created. It is then coupled with a contact generator that creates the contacts to support the robot movement. We show that the trained policy has an improved generalization and higher success rate at generating feasible contact plans than previous approaches. As a result, this policy can be used with a path planning algorithm to navigate complex environments.",
        "primary_area": "",
        "author": "Jason Chemin;Pierre Fernbach;Daeun Song;Guilhem Saurel;Nicolas Mansard;Steve Tonneau;Jason Chemin;Pierre Fernbach;Daeun Song;Guilhem Saurel;Nicolas Mansard;Steve Tonneau",
        "authorids": "/37088995859;/37086326945;/37086254453;/37085810875;/37542913400;/37085790049;/37088995859;/37086326945;/37086254453;/37085810875;/37542913400;/37085790049",
        "aff": "LAAS-CNRS, Univ. Toulouse, CNRS, France; Toward, Toulouse, France; Dept. of CSE, Ewha Womans University, Korea; LAAS-CNRS, Univ. Toulouse, CNRS, France; Artificial and Natural Intelligence Toulouse Institute, France; LAAS-CNRS, Univ. Toulouse, CNRS, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561160/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2854583327173139486&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;3;0",
        "aff_unique_norm": "LAAS-CNRS;TOWARD;Ewha Womans University;Artificial and Natural Intelligence Toulouse Institute",
        "aff_unique_dep": ";;Dept. of CSE;",
        "aff_unique_url": "https://www.laas.fr/;;http://www.ewha.ac.kr;",
        "aff_unique_abbr": "LAAS-CNRS;;EWU;ANITI",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "France;South Korea"
    },
    {
        "id": "9562085",
        "title": "Learning-based Inverse Kinematics from Shape as Input for Concentric Tube Continuum Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a methodology to compute the inverse kinematics for concentric tube continuum robots from a desired shape as input. We demonstrate that it is possible to accurately learn joint parameters using neural networks for a discrete point-wise shape representation with different discretization. In comparison to a vanilla numerical method, the learning-based method is preferred in terms of accuracy in joint space and computation. Representing the shape with up to 20 equidistant points, a shape-to-joint inverse kinematics with errors of 2.22\u00b0 and 1.45 mm is obtained. Further, we extend the shape-to-joint inverse kinematics to image-to-joint inverse kinematics utilizing multi-view images as shape representation. This image-based method achieves errors of 6.02\u00b0 and 2.76 mm. Both approaches, i.e., shape-to-joint and image-to-joint, result in higher accuracy compared to the learning-based state-of-the-art approach which only considers the tip pose.",
        "primary_area": "",
        "author": "Nan Liang;Reinhard M. Grassmann;Sven Lilge;Jessica Burgner-Kahrs;Nan Liang;Reinhard M. Grassmann;Sven Lilge;Jessica Burgner-Kahrs",
        "authorids": "/37085749025;/37086574223;/37086640208;/37085433359;/37085749025;/37086574223;/37086640208;/37085433359",
        "aff": "Department of Mathematical & Computational Sciences, Continuum Robotics Laboratory, University of Toronto Mississauga, Canada; Department of Mathematical & Computational Sciences, Continuum Robotics Laboratory, University of Toronto Mississauga, Canada; Department of Mathematical & Computational Sciences, Continuum Robotics Laboratory, University of Toronto Mississauga, Canada; Department of Mathematical & Computational Sciences, Continuum Robotics Laboratory, University of Toronto Mississauga, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562085/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17467498434205066782&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Toronto Mississauga",
        "aff_unique_dep": "Department of Mathematical & Computational Sciences",
        "aff_unique_url": "https://www.utm.utoronto.ca",
        "aff_unique_abbr": "UTM",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Mississauga",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561313",
        "title": "Legged Robot State Estimation in Slippery Environments Using Invariant Extended Kalman Filter with Velocity Update",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a state estimator for legged robots operating in slippery environments. An Invariant Extended Kalman Filter (InEKF) is implemented to fuse inertial and velocity measurements from a tracking camera and leg kinematic constraints. The misalignment between the camera and the robot-frame is also modeled thus enabling auto-calibration of camera pose. The leg kinematics based velocity measurement is formulated as a right-invariant observation. Nonlinear observability analysis shows that other than the rotation around the gravity vector and the absolute position, all states are observable except for some singular cases. Discrete observability analysis demonstrates that our filter is consistent with the underlying nonlinear system. An online noise parameter tuning method is developed to adapt to the highly time-varying camera measurement noise. The proposed method is experimentally validated on a Cassie bipedal robot walking over slippery terrain. A video for the experiment can be found at https://youtu.be/VIqJL0cUr7s.",
        "primary_area": "",
        "author": "Sangli Teng;Mark Wilfried Mueller;Koushil Sreenath;Sangli Teng;Mark Wilfried Mueller;Koushil Sreenath",
        "authorids": "/37088995976;/37086448968;/37563179200;/37088995976;/37086448968;/37563179200",
        "aff": "Robotics Institute at University of Michigan, MI, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561313/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16653677515816187831&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Michigan;University of California, Berkeley",
        "aff_unique_dep": "Robotics Institute;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.umich.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "UM;UC Berkeley",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "MI;Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560757",
        "title": "Leveraging Enhanced Virtual Reality Methods and Environments for Efficient, Intuitive, and Immersive Teleoperation of Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Many studies have focused on Virtual Reality (VR) frameworks for remotely controlling robotic systems. Although VR systems have been used to teleoperate robots in simple scenarios, their effectiveness in terms of accuracy, speed, and usability has not been rigorously evaluated for complex tasks that require accurate trajectories. In this work, an Enhanced Virtual Reality (EVR) framework for robotic teleoperation is evaluated to assess if it can be efficiently used in complex tasks that require accurate control of the robotic end-effector. The environment and the employed robot are captured using RGB-D cameras, while the remote user controls the motion of the robot with VR controllers. The captured data are transmitted and reconstructed in 3D so as to allow the remote user to monitor the task execution progress in real time, using a VR headset. The EVR system is compared with two other interface alternatives: i) teleoperation in pure VR (the model of the robot is rendered with respect to its real joint states), and ii) teleoperation in EVRR (the model of the robot is superimposed on the real robot). The results show that pure point cloud interfaces suffer from visualization issues, reducing the effectiveness of the robot teleoperation. However, the accuracy and user experience can be greatly improved by including the robot model.",
        "primary_area": "",
        "author": "Francesco De Pace;Gal Gorjup;Huidong Bai;Andrea Sanna;Minas Liarokapis;Mark Billinghurst;Francesco De Pace;Gal Gorjup;Huidong Bai;Andrea Sanna;Minas Liarokapis;Mark Billinghurst",
        "authorids": "/37088999779;/37087237844;/37086823749;/37351391600;/38558084100;/37265766900;/37088999779;/37087237844;/37086823749;/37351391600;/38558084100;/37265766900",
        "aff": "Politechnico di Torino, Italy; New Dexterity Research Group, The University of Auckland, New Zealand; Auckland Bio-Engineering Institute, New Zealand; Politechnico di Torino, Italy; New Dexterity Research Group, The University of Auckland, New Zealand; Auckland Bio-Engineering Institute, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560757/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1557316735877895307&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;0;1;2",
        "aff_unique_norm": "Politechnico di Torino;University of Auckland;Auckland Bio-Engineering Institute",
        "aff_unique_dep": ";New Dexterity Research Group;Bio-Engineering",
        "aff_unique_url": "https://www.polito.it;https://www.auckland.ac.nz;",
        "aff_unique_abbr": "Polito;;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;0;1;1",
        "aff_country_unique": "Italy;New Zealand"
    },
    {
        "id": "9561396",
        "title": "Leveraging Forward Model Prediction Error for Learning Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning for model based control can be sample-efficient and generalize well, however successfully learning models and controllers that represent the problem at hand can be challenging for complex tasks. Using inaccurate models for learning can lead to sub-optimal solutions that are unlikely to perform well in practice. In this work, we present a learning approach which iterates between model learning and data collection and leverages forward model prediction error for learning control. We show how using the controller\u2019s prediction as input to a forward model can create a differentiable connection between the controller and the model, allowing us to formulate a loss in the state space. This lets us include forward model prediction error during controller learning and we show that this creates a loss objective that significantly improves learning on different motor control tasks. We provide empirical and theoretical results that show the benefits of our method and present evaluations in simulation for learning control on a 7 DoF manipulator and an underactuated 12 DoF quadruped. We show that our approach successfully learns controllers for challenging motor control tasks involving contact switching.",
        "primary_area": "",
        "author": "Sarah Bechtle;Bilal Hammoud;Akshara Rai;Franziska Meier;Ludovic Righetti;Sarah Bechtle;Bilal Hammoud;Akshara Rai;Franziska Meier;Ludovic Righetti",
        "authorids": "/37085663643;/37086100914;/37085480350;/38227805500;/37295828600;/37085663643;/37086100914;/37085480350;/38227805500;/37295828600",
        "aff": "Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Tandon School of Engineering, New York University, Brooklyn, NY; Facebook AI Research, Menlo Park, CA; Facebook AI Research, Menlo Park, CA; Tandon School of Engineering, New York University, Brooklyn, NY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561396/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6726761344835610113&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;1",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;New York University;Meta",
        "aff_unique_dep": ";Tandon School of Engineering;Facebook AI Research",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.nyu.edu;https://research.facebook.com",
        "aff_unique_abbr": "MPI-IS;NYU;FAIR",
        "aff_campus_unique_index": "0;1;2;2;1",
        "aff_campus_unique": "T\u00fcbingen;Brooklyn;Menlo Park",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9561443",
        "title": "Leveraging Neural Network Gradients within Trajectory Optimization for Proactive Human-Robot Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "To achieve seamless human-robot interactions, robots need to intimately reason about complex interaction dynamics and future human behaviors within their motion planning process. However, there is a disconnect between state-of-the-art neural network-based human behavior models and robot motion planners\u2014either the behavior models are limited in their consideration of downstream planning or a simplified behavior model is used to ensure tractability of the planning problem. In this work, we present a framework that fuses together the interpretability and flexibility of trajectory optimization (TO) with the predictive power of state-of-the-art human trajectory prediction models. In particular, we leverage gradient information from data-driven prediction models to explicitly reason about human-robot interaction dynamics within a gradient-based TO problem. We demonstrate the efficacy of our approach in a multi-agent scenario whereby a robot is required to safely and efficiently navigate through a crowd of up to ten pedestrians. We compare against a variety of planning methods, and show that by explicitly accounting for interaction dynamics within the planner, our method offers safer and more efficient behaviors, even yielding proactive and nuanced behaviors such as waiting for a pedestrian to pass before moving.",
        "primary_area": "",
        "author": "Simon Schaefer;Karen Leung;Boris Ivanovic;Marco Pavone;Simon Schaefer;Karen Leung;Boris Ivanovic;Marco Pavone",
        "authorids": "/37088998632;/37086453267;/37086527859;/37307912900;/37088998632;/37086453267;/37086527859;/37307912900",
        "aff": "Institute of Dynamic Systems and Control, ETH Zurich, Zurich, Switzerland; Department of Aeronautics and Astronautics, Stanford University, USA; Department of Aeronautics and Astronautics, Stanford University, USA; Department of Aeronautics and Astronautics, Stanford University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561443/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18256619400150793405&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "ETH Zurich;Stanford University",
        "aff_unique_dep": "Institute of Dynamic Systems and Control;Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.ethz.ch;https://www.stanford.edu",
        "aff_unique_abbr": "ETHZ;Stanford",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Zurich;Stanford",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "9561520",
        "title": "Leveraging Post Hoc Context for Faster Learning in Bandit Settings with Applications in Robot-Assisted Feeding",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous robot-assisted feeding requires the ability to acquire a wide variety of food items. However, it is impossible for such a system to be trained on all types of food in existence. Therefore, a key challenge is choosing a manipulation strategy for a previously unseen food item. Previous work showed that the problem can be represented as a linear bandit with visual context. However, food has a wide variety of multi-modal properties relevant to manipulation that can be hard to distinguish visually. Our key insight is that we can leverage the haptic context we collect during and after manipulation (i.e., \"post hoc\") to learn some of these properties and more quickly adapt our visual model to previously unseen food. In general, we propose a modified linear contextual bandit framework augmented with post hoc context observed after action selection to empirically increase learning speed and reduce cumulative regret. Experiments on synthetic data demonstrate that this effect is more pronounced when the dimensionality of the context is large relative to the post hoc context or when the post hoc context model is particularly easy to learn. Finally, we apply this framework to the bite acquisition problem and demonstrate the acquisition of 8 previously unseen types of food with 21% fewer failures across 64 attempts.",
        "primary_area": "",
        "author": "Ethan K. Gordon;Sumegh Roychowdhury;Tapomayukh Bhattacharjee;Kevin Jamieson;Siddhartha S. Srinivasa;Ethan K. Gordon;Sumegh Roychowdhury;Tapomayukh Bhattacharjee;Kevin Jamieson;Siddhartha S. Srinivasa",
        "authorids": "/37088688098;/37088997683;/37531634500;/37889325000;/37339877600;/37088688098;/37088997683;/37531634500;/37889325000;/37339877600",
        "aff": "Department of Computer Science and Engineering, University of Washington, Seattle, WA; Indian Institute of Technology Kharagpur, Kharagpur, India; Department of Computer Science and Engineering, University of Washington, Seattle, WA; Department of Computer Science and Engineering, University of Washington, Seattle, WA; Department of Computer Science and Engineering, University of Washington, Seattle, WA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561520/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17427481698108795078&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University of Washington;Indian Institute of Technology Kharagpur",
        "aff_unique_dep": "Department of Computer Science and Engineering;",
        "aff_unique_url": "https://www.washington.edu;https://www.iitkgp.ac.in",
        "aff_unique_abbr": "UW;IIT Kharagpur",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Seattle;Kharagpur",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;India"
    },
    {
        "id": "9561466",
        "title": "LiDAR few-shot domain adaptation via integrated CycleGAN and 3D object detector with joint learning delay",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Eduardo R. Corral-Soto;Amir Nabatchian;Martin Gerdzhev;Liu Bingbing;Eduardo R. Corral-Soto;Amir Nabatchian;Martin Gerdzhev;Liu Bingbing",
        "authorids": "/38305749200;/38272684200;/37089001111;/38257785200;/38305749200;/38272684200;/37089001111;/38257785200",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561466/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3265877073438179209&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8
    },
    {
        "id": "9560740",
        "title": "LiDAR-Based Initial Global Localization Using Two-Dimensional (2D) Submap Projection Image (SPI)",
        "track": "main",
        "status": "Poster",
        "abstract": "Initial global localization is important to mobile robotics in terms of navigation initialization (or re-initialization) and loop closure in SLAM. 3D LiDARs are commonly used for mobile robotics, yet LiDAR-based initial global localization (especially at large scale such as in outdoor environments) is still challenging due to lack of salient features in LiDAR range data. Inspired by visual SLAM oriented initial global localization methods, we propose a method of LiDAR-based initial global localization using 2D submap projection image (SPI). For this, global descriptors from SPIs are extracted for place recognition; pose estimation is realized by feature point matching between the queried SPI and SPIs from a global map database. The proposed initial global localization module runs at 2.4 Hz with precision of 1.2 m and for translation and 1.2\u00b0 for rotation, which can serve as a suitable initial estimate for subsequent pose estimation refinement via existing mature point cloud registration methods.",
        "primary_area": "",
        "author": "Yanhao Li;Hao Li;Yanhao Li;Hao Li",
        "authorids": "/37088647554;/37600684200;/37088647554;/37600684200",
        "aff": "\u00c9cole d\u2019Ing\u00e9nieurs SJTU-ParisTech (SPEIT), Shanghai, China; \u00c9cole d\u2019Ing\u00e9nieurs SJTU-ParisTech (SPEIT), Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560740/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16929675048643503418&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "\u00c9cole d\u2019Ing\u00e9nieurs SJTU-ParisTech",
        "aff_unique_dep": "SPEIT",
        "aff_unique_url": "",
        "aff_unique_abbr": "SJTU-ParisTech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561255",
        "title": "LiDARNet: A Boundary-Aware Domain Adaptation Model for Point Cloud Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a boundary-aware domain adaptation model for LiDAR scan full-scene semantic segmentation (LiDARNet). Our model can extract both the domain private features and the domain shared features with a two branch structure. We embedded Gated-SCNN into the segmentor component of LiDARNet to learn boundary information while learning to predict full-scene semantic segmentation labels. Moreover, we further reduce the domain gap by inducing the model to learn a mapping between two domains using the domain shared and private features. Additionally, we introduce a new dataset (SemanticUSL1) for domain adaptation for LiDAR point cloud semantic segmentation. The dataset has the same data format and ontology as SemanticKITTI. We conducted experiments on real-world datasets SemanticKITTI, SemanticPOSS, and SemanticUSL, which have differences in channel distributions, reflectivity distributions, diversity of scenes, and sensors setup. Using our approach, we can get a single projection-based Li-DAR full-scene semantic segmentation model working on both domains. Our model can keep almost the same performance on the source domain after adaptation and get an 8%-22% mIoU performance increase in the target domain.",
        "primary_area": "",
        "author": "Peng Jiang;Srikanth Saripalli;Peng Jiang;Srikanth Saripalli",
        "authorids": "/37088982909;/37278939200;/37088982909;/37278939200",
        "aff": "J. Mike Walker \u201966 Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA; J. Mike Walker \u201966 Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561255/",
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12398817562303915593&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560947",
        "title": "LiTAMIN2: Ultra Light LiDAR-based SLAM using Geometric Approximation applied with KL-Divergence",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a three-dimensional light detection and ranging simultaneous localization and mapping (SLAM) method is proposed that is available for tracking and mapping with 500\u20131000 Hz processing. The proposed method significantly reduces the number of points used for point cloud registration using a novel ICP metric to speed up the registration process while maintaining accuracy. Point cloud registration with ICP is less accurate when the number of points is reduced because ICP basically minimizes the distance between points. To avoid this problem, symmetric KL-divergence is introduced to the ICP cost that reflects the difference between two probabilistic distributions. The cost includes not only the distance between points but also differences between distribution shapes. The experimental results on the KITTI dataset indicate that the proposed method has high computational efficiency, strongly outperforms other methods, and has similar accuracy to the state-of-the-art SLAM method.",
        "primary_area": "",
        "author": "Masashi Yokozuka;Kenji Koide;Shuji Oishi;Atsuhiko Banno;Masashi Yokozuka;Kenji Koide;Shuji Oishi;Atsuhiko Banno",
        "authorids": "/38230409400;/37086179385;/37085895378;/37391486400;/38230409400;/37086179385;/37085895378;/37391486400",
        "aff": "Human-Centered Mobility Research Center (HCMRC), National Institute of Advanced Industrial Science and Technology (AIST), Japan; Human-Centered Mobility Research Center (HCMRC), National Institute of Advanced Industrial Science and Technology (AIST), Japan; Human-Centered Mobility Research Center (HCMRC), National Institute of Advanced Industrial Science and Technology (AIST), Japan; Human-Centered Mobility Research Center (HCMRC), National Institute of Advanced Industrial Science and Technology (AIST), Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560947/",
        "gs_citation": 111,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17793493412753984910&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Human-Centered Mobility Research Center (HCMRC)",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561437",
        "title": "Lidar-Monocular Surface Reconstruction Using Line Segments",
        "track": "main",
        "status": "Poster",
        "abstract": "Structure from Motion (SfM) often fails to estimate accurate poses in environments that lack suitable visual features. In such cases, the quality of the final 3D mesh, which is contingent on the accuracy of those estimates, is reduced. One way to overcome this problem is to combine data from a monocular camera with that of a LIDAR. This allows fine details and texture to be captured while still accurately representing featureless subjects. However, fusing these two sensor modalities is challenging due to their fundamentally different characteristics. Rather than directly fusing image features and LIDAR points, we propose to leverage common geometric features that are detected in both the LIDAR scans and image data, allowing data from the two sensors to be processed in a higher-level space. In particular, we propose to find correspondences between 3D lines extracted from LIDAR scans and 2D lines detected in images before performing a bundle adjustment to refine poses. We also exploit the detected and optimized line segments to improve the quality of the final mesh. We test our approach on the recently published dataset, Newer College Dataset. We compare the accuracy and the completeness of the 3D mesh to a ground truth obtained with a survey-grade 3D scanner. We show that our method delivers results that are comparable to a state-of-the-art LIDAR survey while not requiring highly accurate ground truth pose estimates. We plan to release our code before publication.",
        "primary_area": "",
        "author": "Victor Amblard;Timothy P. Osedach;Arnaud Croux;Andrew Speck;John J. Leonard;Victor Amblard;Timothy P. Osedach;Arnaud Croux;Andrew Speck;John J. Leonard",
        "authorids": "/37089000794;/37088835552;/37086171096;/37088837480;/37329387400;/37089000794;/37088835552;/37086171096;/37088837480;/37329387400",
        "aff": "MIT CSAIL, Mines ParisTech; General Dynamics Mission Systems, Schlumberger Doll-Research; Schlumberger-Doll Research, Cambridge, MA; Schlumberger-Doll Research, Cambridge, MA; MIT CSAIL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561437/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10376638679246376175&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;General Dynamics Mission Systems;Schlumberger-Doll Research",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;;",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.gdmissionsystems.com;https://www.slb.com",
        "aff_unique_abbr": "MIT CSAIL;GDMS;",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561584",
        "title": "Lifelong Localization in Semi-Dynamic Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "Mapping and localization in non-static environments are fundamental problems in robotics. Most of previous methods mainly focus on static and highly dynamic objects in the environment, which may suffer from localization failure in semi-dynamic scenarios without considering objects with lower dynamics, such as parked cars and stopped pedestrians. In this paper, we introduce semantic mapping and lifelong localization approaches to recognize semi-dynamic objects in non-static environments. We also propose a generic framework that can integrate mainstream object detection algorithms with mapping and localization algorithms. The mapping method combines an object detection algorithm and a SLAM algorithm to detect semi-dynamic objects and constructs a semantic map that only contains semi-dynamic objects in the environment. During navigation, the localization method can classify observation corresponding to static and non-static objects respectively and evaluate whether those semi-dynamic objects have moved, to reduce the weight of invalid observation and localization fluctuation. Real-world experiments show that the proposed method can improve the localization accuracy of mobile robots in non-static scenarios.",
        "primary_area": "",
        "author": "Shifan Zhu;Xinyu Zhang;Shichun Guo;Jun Li;Huaping Liu;Shifan Zhu;Xinyu Zhang;Shichun Guo;Jun Li;Huaping Liu",
        "authorids": "/37088999176;/37085619542;/37088999028;/37088999341;/37310126400;/37088999176;/37085619542;/37088999028;/37088999341;/37310126400",
        "aff": "State Key Laboratory of Automotive Safety and Energy, and the School of Vehicle and Mobility, Tsinghua University, Beijing, China; State Key Laboratory of Automotive Safety and Energy, and the School of Vehicle and Mobility, Tsinghua University, Beijing, China; State Key Laboratory of Automotive Safety and Energy, and the School of Vehicle and Mobility, Tsinghua University, Beijing, China; State Key Laboratory of Automotive Safety and Energy, and the School of Vehicle and Mobility, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561584/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9770164196736611430&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "School of Vehicle and Mobility",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560996",
        "title": "Lightweight Semantic Mesh Mapping for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Lightweight and semantically meaningful environment maps are crucial for many applications in robotics and autonomous driving to facilitate higher-level tasks such as navigation and planning. In this paper we present a novel approach to incrementally build a meaningful and lightweight semantic map directly as a 3D mesh from a monocular or stereo sequence. Our system leverages existing feature-based visual odometry paired with learned depth prediction and semantic image segmentation to identify and reconstruct semantically relevant environment structure. We introduce a probabilistic fusion scheme to incrementally refine and extend a 3D mesh with semantic labels for each face without intermediate voxel-based fusion. To demonstrate its effectiveness, we evaluate our system in outdoor driving scenarios with monocular depth prediction and stereo and present quantitative and qualitative reconstruction results with comparison to ground truth. Our results show that the proposed approach achieves reconstruction quality comparable to current state-of-the-art voxel-based methods while being much more lightweight both in storage and computation.",
        "primary_area": "",
        "author": "Markus Herb;Tobias Weiherer;Nassir Navab;Federico Tombari;Markus Herb;Tobias Weiherer;Nassir Navab;Federico Tombari",
        "authorids": "/37086308051;/38492400600;/37282965500;/37593332100;/37086308051;/38492400600;/37282965500;/37593332100",
        "aff": "Department of Informatics, Technical University of Munich, Germany; AUDI AG, Ingolstadt, Germany; Department of Informatics, Technical University of Munich, Germany; Google, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560996/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18153436021064846489&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Technical University of Munich;AUDI AG;Google",
        "aff_unique_dep": "Department of Informatics;;Google",
        "aff_unique_url": "https://www.tum.de;https://www.audi.de;https://www.google.ch",
        "aff_unique_abbr": "TUM;AUDI;Google",
        "aff_campus_unique_index": "0;0;2",
        "aff_campus_unique": "Munich;;Zurich",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Germany;Switzerland"
    },
    {
        "id": "9561843",
        "title": "Limits of Probabilistic Safety Guarantees when Considering Human Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "When autonomous robots interact with humans, such as during autonomous driving, explicit safety guarantees are crucial in order to avoid potentially life-threatening accidents. Many data-driven methods have explored learning probabilistic bounds over human agents\u2019 trajectories (i.e. confidence tubes that contain trajectories with probability \u03b4), which can then be used to guarantee safety with probability 1\u2212 \u03b4. However, almost all existing works consider \u03b4 \u2265 0.001. The purpose of this paper is to argue that (1) in safety-critical applications, it is necessary to provide safety guarantees with \u03b4 < 10\u22128, and (2) current learning-based methods are illequipped to compute accurate confidence bounds at such low \u03b4. Using human driving data (from the highD dataset), as well as synthetically generated data, we show that current uncertainty models use inaccurate distributional assumptions to describe human behavior and/or require infeasible amounts of data to accurately learn confidence bounds for \u03b4 \u2264 10\u22128. These two issues result in unreliable confidence bounds, which can have dangerous implications if deployed on safety-critical systems.",
        "primary_area": "",
        "author": "Richard Cheng;Richard M. Murray;Joel W. Burdick;Richard Cheng;Richard M. Murray;Joel W. Burdick",
        "authorids": "/37086493605;/37267068200;/37265975700;/37086493605;/37267068200;/37265975700",
        "aff": "California Institute of Technology, Pasadena, CA, USA; California Institute of Technology, Pasadena, CA, USA; California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561843/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=507482889795332818&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561216",
        "title": "Line-based Automatic Extrinsic Calibration of LiDAR and Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "Reliable real-time extrinsic parameters of 3D Light Detection and Ranging (LiDAR) and camera are a key component of multi-modal perception systems. However, extrinsic transformation may drift gradually during operation, which can result in decreased accuracy of perception system. To solve this problem, we propose a line-based method that enables automatic online extrinsic calibration of LiDAR and camera in real-world scenes. Herein, the line feature is selected to constrain the extrinsic parameters for its ubiquity. Initially, the line features are extracted and filtered from point clouds and images. Afterwards, an adaptive optimization is utilized to provide accurate extrinsic parameters. We demonstrate that line features are robust geometric features that can be extracted from point clouds and images, thus contributing to the extrinsic calibration. To demonstrate the benefits of this method, we evaluate it on KITTI benchmark with ground truth value. The experiments verify the accuracy of the calibration approach. In online experiments on hundreds of frames, our approach automatically corrects miscalibration errors and achieves an accuracy of 0.2 degrees, which verifies its applicability in various scenarios. This work can provide basis for perception systems and further improve the performance of other algorithms that utilize these sensors.",
        "primary_area": "",
        "author": "Xinyu Zhang;Shifan Zhu;Shichun Guo;Jun Li;Huaping Liu;Xinyu Zhang;Shifan Zhu;Shichun Guo;Jun Li;Huaping Liu",
        "authorids": "/37085619542;/37088999176;/37088999028;/37088999341;/37310126400;/37085619542;/37088999176;/37088999028;/37088999341;/37310126400",
        "aff": "School of Vehicle and Mobility, State Key Laboratory of Automotive Safety and Energy, Tsinghua University, Beijing, China; School of Vehicle and Mobility, State Key Laboratory of Automotive Safety and Energy, Tsinghua University, Beijing, China; School of Vehicle and Mobility, State Key Laboratory of Automotive Safety and Energy, Tsinghua University, Beijing, China; School of Vehicle and Mobility, State Key Laboratory of Automotive Safety and Energy, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561216/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12306791205164131173&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "School of Vehicle and Mobility",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560813",
        "title": "Linear Inverse Problem for Depth Completion with RGB Image and Sparse LIDAR Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Comprehensive depth information from surrounding scenes is important for perception in autonomous driving and robots. Sparse LIDAR sensors give a low-density point cloud of the environment, but are more affordable than their high-density counterparts. In this paper, we propose a novel sensor fusion architecture for sparse LIDAR depth completion. Instead of the traditional end-to-end neural network-based algorithm, we formulate depth completion as a Linear Inverse Problem (LIP) with a multi-modal proximal operator. This sensor fusion architecture allows a better signal prior and finds the unique optimal solution to the LIP. Instead of learning a unified network for the sparse input which treats pixels evenly, the proposed architecture guarantees both the data consistency and smoothness of the predicted depth map. To demonstrate the performance of our algorithm, we benchmark on the simulation dataset TartanAir, and the real indoor NYUdepthv2 and real outdoor KITTI datasets. Our proposed method outperforms previous methods and uses fewer parameters in both indoor and outdoor datasets.",
        "primary_area": "",
        "author": "Chen Fu;Christoph Mertz;John M. Dolan;Chen Fu;Christoph Mertz;John M. Dolan",
        "authorids": "/37086544947;/37666676000;/37283756800;/37086544947;/37666676000;/37283756800",
        "aff": "Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560813/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6949884819027720924&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561871",
        "title": "Linear-Quadratic Optimal Control in Maximal Coordinates",
        "track": "main",
        "status": "Poster",
        "abstract": "The linear-quadratic regulator (LQR) is an efficient control method for linear and linearized systems. Typically, LQR is implemented in minimal coordinates (also called generalized or \"joint\" coordinates). However, other coordinates are possible and recent research suggests that there may be numerical and control-theoretic advantages when using higher-dimensional non-minimal state parameterizations for dynamical systems. One such parameterization is maximal coordinates, in which each link in a multi-body system is parameterized by its full six degrees of freedom and joints between links are modeled with algebraic constraints. Such constraints can also represent closed kinematic loops or contact with the environment. This paper investigates the difference between minimal- and maximal-coordinate LQR control laws. A case study of applying LQR to a simple pendulum and simulations comparing the basins of attraction of minimal- and maximal-coordinate LQR controllers suggest that maximal-coordinate LQR achieves greater robustness and improved performance compared to minimal-coordinate LQR when applied to nonlinear systems.",
        "primary_area": "",
        "author": "Jan Br\u00fcdigam;Zachary Manchester;Jan Br\u00fcdigam;Zachary Manchester",
        "authorids": "/37088997232;/37086011525;/37088997232;/37086011525",
        "aff": "Department of Electrical and Computer Engineering, Technical University of Munich, Munich, Germany; The Robotics Institute, Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561871/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17646980697994701155&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Technical University of Munich;Carnegie Mellon University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;The Robotics Institute",
        "aff_unique_url": "https://www.tum.de;https://www.cmu.edu",
        "aff_unique_abbr": "TUM;CMU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Munich;Pittsburgh",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9561519",
        "title": "Linguistic Descriptions of Human Motion with Generative Adversarial Seq2Seq Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a generative model that learns a sequence-to-sequence (Seq2Seq) translation between human whole-body motions and linguistic descriptions by natural language. Our model merges the Seq2Seq model with the training strategy of sequence generative adversarial nets (SeqGAN), which extends a GAN framework to solve the problem that the gradient cannot pass back to the generator network. This model considers a generator, trained using a policy gradient method, as a stochastic parameterized policy. In the policy gradient, we employ a Monte Carlo (MC) search to receive the final reinforcement learning (RL) reward from the discriminator. The proposed generative network is trained on the KIT Motion-Language Dataset, which is one of the few large-scale datasets available and includes 3,911 human motions and 6,278 natural language descriptions. During the experiments, we evaluated the effectiveness of our model by comparing its various configurations and parameter settings. Finally, our model achieves a remarkably high performance, outperforming an existing state-of-the-art method under the same dataset split for fair comparison. In addition, the qualitative results of the motion-to-language translation demonstrate that our model can generate semantically and grammatically correct sentences with detailed linguistic descriptions from human motions.",
        "primary_area": "",
        "author": "Yusuke Goutsu;Tetsunari Inamura;Yusuke Goutsu;Tetsunari Inamura",
        "authorids": "/37085412409;/37294612600;/37085412409;/37294612600",
        "aff": "Institute of Industrial Science, The University of Tokyo, Tokyo, Japan; National Institute of Informatics, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561519/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13869431161407003253&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Tokyo;National Institute of Informatics",
        "aff_unique_dep": "Institute of Industrial Science;",
        "aff_unique_url": "https://www.iis.u-tokyo.ac.jp;https://www.nii.ac.jp",
        "aff_unique_abbr": "UTokyo;NII",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561171",
        "title": "Lite-HDSeg: LiDAR Semantic Segmentation Using Lite Harmonic Dense Convolutions",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous driving vehicles and robotic systems rely on accurate perception of their surroundings. Scene understanding is one of the crucial components of perception modules. Among all available sensors, LiDARs are one of the essential sensing modalities of autonomous driving systems due to their active sensing nature with high resolution of sensor readings. Accurate and fast semantic segmentation methods are needed to fully utilize LiDAR sensors for scene understanding. In this paper, we present Lite-HDSeg, a novel real-time convolutional neural network for semantic segmentation of full 3D LiDAR point clouds. Lite-HDSeg can achieve the best accuracy vs. computational complexity trade-off in SemanticKITTI bench-mark and is designed on the basis of a new encoder-decoder architecture with light-weight harmonic dense convolutions as its core. Moreover, we introduce ICM, an improved global contextual module to capture multi-scale contextual features, and MCSPN, a multi-class Spatial Propagation Network to further refine the semantic boundaries. Our experimental results show that the proposed method outperforms state-of- the-art semantic segmentation approaches which can run real-time, thus is suitable for robotic and autonomous driving applications.",
        "primary_area": "",
        "author": "Ryan Razani;Ran Cheng;Ehsan Taghavi;Liu Bingbing;Ryan Razani;Ran Cheng;Ehsan Taghavi;Liu Bingbing",
        "authorids": "/37086404456;/37088997657;/37077023400;/38257785200;/37086404456;/37088997657;/37077023400;/38257785200",
        "aff": "Huawei Noah's Ark Lab, Toronto, Canada; Huawei Noah's Ark Lab, Toronto, Canada; Huawei Noah's Ark Lab, Toronto, Canada; Huawei Noah's Ark Lab, Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561171/",
        "gs_citation": 66,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17632429827584547388&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Huawei Noah's Ark Lab",
        "aff_unique_url": "https://www.huawei.com/en/ai/noahs-ark-lab",
        "aff_unique_abbr": "HNAL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561720",
        "title": "Locomotion Adaptation in Heavy Payload Transportation Tasks with the Quadruped Robot CENTAURO",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a reactive legged locomotion generation scheme that enables our quadruped robot CEN-TAURO to adapt to varying payloads while walking. The center-of-mass (CoM) trajectories are generated in real time in a model predictive control (MPC) fashion, trading off large stability margins against evenly stretched legs. Vertex-based zero-moment-point (ZMP) constraints are imposed to ensure quasi-static walking stability. A Kalman filter is then implemented to estimate the CoM states and the impact of external payloads which can vary online and affect/disturb the locomotion differently. The CoM estimation is used to update the MPC motion planner at every replanning instant so that the robot can react to unknown and time-varying payloads on the fly.We validate the proposed scheme through experimental trials where the robot walks on flat ground or steps on different surface levels while carrying heavy payloads. It is shown that the proposed reactive locomotion strategy enables the robot to carry 20 kg payloads, which is close to the maximum capacity of the robot arms.",
        "primary_area": "",
        "author": "Xinyuan Zhao;Yangwei You;Arturo Laurenzi;Navvab Kashiri;Nikos Tsagarakis;Xinyuan Zhao;Yangwei You;Arturo Laurenzi;Navvab Kashiri;Nikos Tsagarakis",
        "authorids": "/37089396456;/37085753674;/37086141170;/38667578800;/37295830800;/37089396456;/37085753674;/37086141170;/38667578800;/37295830800",
        "aff": "DIBRIS, Universita di Genova, Italy; Institute for Infocomm Research, Agency for Science, Technology and Research, Singapore; Humanoid and Human Centered Mechatronics Research Line, Istituto Italiano di Tecnologia, Genova, Italy; Humanoid and Human Centered Mechatronics Research Line, Istituto Italiano di Tecnologia, Genova, Italy; Humanoid and Human Centered Mechatronics Research Line, Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561720/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4643145903450194827&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;2",
        "aff_unique_norm": "Universita di Genova;Agency for Science, Technology and Research;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "DIBRIS;Institute for Infocomm Research;Humanoid and Human Centered Mechatronics Research Line",
        "aff_unique_url": "https://www.unige.it;https://www.a-star.edu.sg;https://www.iit.it",
        "aff_unique_abbr": ";A*STAR;IIT",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Genova",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Italy;Singapore"
    },
    {
        "id": "9561184",
        "title": "Locomotion and Control of a Friction-Driven Tripedal Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel omnidirectional gait design and feedback control of a radially symmetric tripedal friction-driven robot. The robot features 3 servo motors mounted on a 3-D printed chassis 7 cm from the center of mass and separated 120 degrees. These motors drive limbs, which impart frictional reactive forces on the body. We first introduce a mathematical model for the robot motion, then show experimental observations performed on a uniform friction surface, which validated the accuracy of the model. This model was then used to create an omnidirectional gait that allows the robot to translate in any direction. Based on this gait, we also introduce a Proportional-Integral (PI) feedback control framework that enables the robot to closely follow a desired path. Contrasting with feedforward motion generation, the proposed feedback controller reduced the tracking error by approximately 46%. We have successfully demonstrated the approach in our robot hardware for the problem of line following using live feedback from an overhead tracking camera. Our controller is also able to correct for aerodynamic disturbances generated by a high-volume industrial fan with a mean flow speed of 5.5ms\u22121, reducing path error by 65% relative to the basic position update procedure.",
        "primary_area": "",
        "author": "Mark Hermes;Taylor McLaughlin;Mitul Luhar;Quan Nguyen;Mark Hermes;Taylor McLaughlin;Mitul Luhar;Quan Nguyen",
        "authorids": "/37086242934;/37088996711;/37086936084;/37085362091;/37086242934;/37088996711;/37086936084;/37085362091",
        "aff": "Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA; Department of Mechanical Engineering, University of Michigan, Ann Arbor, MI; Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA; Department of Aerospace and Mechanical Engineering, University of Southern California, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561184/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11780547321928890151&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Southern California;University of Michigan",
        "aff_unique_dep": "Department of Aerospace and Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.usc.edu;https://www.umich.edu",
        "aff_unique_abbr": "USC;UM",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Los Angeles;Ann Arbor",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560915",
        "title": "Locus: LiDAR-based Place Recognition using Spatiotemporal Higher-Order Pooling",
        "track": "main",
        "status": "Poster",
        "abstract": "Place Recognition enables the estimation of a globally consistent map and trajectory by providing non-local constraints in Simultaneous Localisation and Mapping (SLAM). This paper presents Locus, a novel place recognition method using 3D LiDAR point clouds in large-scale environments. We propose a method for extracting and encoding topological and temporal information related to components in a scene and demonstrate how the inclusion of this auxiliary information in place description leads to more robust and discriminative scene representations. Second-order pooling along with a non- linear transform is used to aggregate these multi-level features to generate a fixed-length global descriptor, which is invariant to the permutation of input features. The proposed method outperforms state-of-the-art methods on the KITTI dataset. Furthermore, Locus is demonstrated to be robust across several challenging situations such as occlusions and viewpoint changes in 3D LiDAR point clouds. The open-source implementation is available at: https://github.com/csiro-robotics/locus.",
        "primary_area": "",
        "author": "Kavisha Vidanapathirana;Peyman Moghadam;Ben Harwood;Muming Zhao;Sridha Sridharan;Clinton Fookes;Kavisha Vidanapathirana;Peyman Moghadam;Ben Harwood;Muming Zhao;Sridha Sridharan;Clinton Fookes",
        "authorids": "/37087049355;/37666497200;/37086139795;/37088999923;/37266096100;/37281919100;/37087049355;/37666497200;/37086139795;/37088999923;/37266096100;/37281919100",
        "aff": "School of Electrical Engineering and Robotics, Queensland University of Technology (QUT), Brisbane, Australia; School of Electrical Engineering and Robotics, Queensland University of Technology (QUT), Brisbane, Australia; DATA61, CSIRO, Robotics and Autonomous Systems Group, Brisbane, QLD, Australia; DATA61, CSIRO, Robotics and Autonomous Systems Group, Brisbane, QLD, Australia; School of Electrical Engineering and Robotics, Queensland University of Technology (QUT), Brisbane, Australia; School of Electrical Engineering and Robotics, Queensland University of Technology (QUT), Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560915/",
        "gs_citation": 91,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8792774460036744272&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "Queensland University of Technology;CSIRO",
        "aff_unique_dep": "School of Electrical Engineering and Robotics;Robotics and Autonomous Systems Group",
        "aff_unique_url": "https://www.qut.edu.au;https://www.csiro.au",
        "aff_unique_abbr": "QUT;CSIRO",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9562101",
        "title": "Long-Horizon Motion Planning for Autonomous Vehicle Parking Incorporating Incomplete Map Information",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a hierarchical motion planning approach that can provide real-time parking plans for autonomous vehicles with limited memory. Through combining a high-level route planner that searches for collision-free routes given traffic and obstacle information and a low level motion planner that considers vehicle dynamics, our approach generates smooth trajectories with reasonable parking behaviors rapidly with very low memory consumption. This hierarchical approach allows for online path repairing and replanning when newly detected obstacles that were not indicated on the offline map obstruct the original planned trajectory. It employs a fast clearance checking procedure to obtain a practical indicator of repairability as well as heuristic guidance for rapid trajectory repairing, and utilizes the high-level route planner to conduct real-time replanning when trajectory repairing is deemed to be difficult. Performance analysis on parking tasks in simulation environments demonstrates the advantages of the proposed approach in terms of both trajectory quality and planning time.",
        "primary_area": "",
        "author": "Siyu Dai;Yebin Wang;Siyu Dai;Yebin Wang",
        "authorids": "/37086573852;/37407582500;/37086573852;/37407582500",
        "aff": "MIT, Cambridge, MA, USA; Mitsubishi Electric Research Laboratories, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562101/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13277757657133351318&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Mitsubishi Electric Research Laboratories",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www.merl.com",
        "aff_unique_abbr": "MIT;MERL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561189",
        "title": "Long-Range Hand Gesture Recognition via Attention-based SSD Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Hand gesture recognition plays an essential role in the human-robot interaction (HRI) field. Most previous research only studies hand gesture recognition in a short distance, which cannot be applied for interaction with mobile robots like unmanned aerial vehicles (UAVs) at a longer and safer distance. Therefore, we investigate the challenging long-range hand gesture recognition problem for the interaction between humans and UAVs. To this end, we propose a novel attention-based single shot multibox detector (SSD) model that incorporates both spatial and channel attention for hand gesture recognition. We notably extend the recognition distance from 1 meter to 7 meters through the proposed model without sacrificing speed. Besides, we present a long-range hand gesture (LRHG) dataset collected by the USB camera mounted on mobile robots. The hand gestures are collected at discrete distance levels from 1 meter to 7 meters, where most of the hand gestures are small and at low resolution. Experiments with the self-built LRHG dataset show our methods reach the surprising performance-boosting over the state-of-the-art method like the SSD network on both short-range (1 meter) and long-range (up to 7 meters) hand gesture recognition tasks.",
        "primary_area": "",
        "author": "Liguang Zhou;Chenping Du;Zhenglong Sun;Tin Lun Lam;Yangsheng Xu;Liguang Zhou;Chenping Du;Zhenglong Sun;Tin Lun Lam;Yangsheng Xu",
        "authorids": "/37086212444;/37088998653;/37086799406;/37571111600;/37277722000;/37086212444;/37088998653;/37086799406;/37571111600;/37277722000",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society; Sun Yat-sen University; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561189/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=818505551316474414&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Shenzhen Institute of Artificial Intelligence and Robotics for Society;Sun Yat-sen University",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.siarfs.org/;http://www.sysu.edu.cn/",
        "aff_unique_abbr": ";SYSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561167",
        "title": "Long-term Multiple Time-Constant Model of a Spring Roll Dielectric Elastomer Actuator under Dynamic Loading",
        "track": "main",
        "status": "Poster",
        "abstract": "Dielectric elastomers are electro-mechanically coupled transducers that display a nonlinear viscoelastic stress-strain relationship. Modeling and controlling such nonlinear materials and actuators are of great challenge. A spring roll dielectric elastomer actuator is a linear actuator composed of a spring and sheets of wrapped dielectric elastomers. Since its shape and actuation performance resemble a human muscle, its application as an artificial muscle is investigated. To verify its applicability, the actuator\u2019s controllability and time-dependent actuation behavior are examined. In this paper, we derive a multiple time-constant model specifying the response of a long-term dynamic loading of the spring roll dielectric elastomer actuator. Our modeling approach is based on multiple viscoelastic elements, having different time responses, superposed into one rheological model. In addition to viscoelasticity, the model includes the effects of the spring core, external mechanical load, the internal stress of the elastomer, and the applied dynamic voltage signal, so that it can be applied in various working conditions. Experiments and simulations are conducted to confirm the applicability and accuracy of the proposed long-term multiple time-constant model.",
        "primary_area": "",
        "author": "Seung Mo Jeong;Ki-Uk Kyung;Seung Mo Jeong;Ki-Uk Kyung",
        "authorids": "/37086183875;/37283149200;/37086183875;/37283149200",
        "aff": "Mechanical Engineering Department, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Mechanical Engineering Department, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561167/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5187241043719533638&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Mechanical Engineering Department",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9562084",
        "title": "Look at my new blue force-sensing shoes!",
        "track": "main",
        "status": "Poster",
        "abstract": "To function autonomously in the physical world, humanoid robots need high-fidelity sensing systems, especially for forces that cannot be easily modeled. Modeling forces in robot feet is particularly challenging due to static indeterminacy, thereby requiring direct sensing. Unfortunately, resolving forces in the feet of some smaller-sized humanoids is limited both by the quality of sensors and the current algorithms used to interpret the data. This paper presents light-weight, low-cost and open-source force-sensing shoes to improve force measurement for popular smaller-sized humanoid robots, and a method for calibrating the shoes. The shoes measure center of pressure (CoP) and normal ground reaction force (GRF). The calibration method enables each individual shoe to reach high measurement precision by applying known forces at different locations of the shoe and using a regularized least squares optimization to interpret sensor outputs. A NAOTM robot is used as our experimental platform. Experiments are conducted to compare the measurement performance between the shoes and the robot\u2019s factory-installed force-sensing resistors (FSRs), and to evaluate the calibration method over these two sensing modules. Experimental results show that the shoes significantly improve CoP and GRF measurement precision compared to the robot\u2019s built-in FSRs. Moreover, the developed calibration method improves the measurement performance for both our shoes and the built-in FSRs.",
        "primary_area": "",
        "author": "Yuanfeng Han;Ruixin Li;Gregory S. Chirikjian;Yuanfeng Han;Ruixin Li;Gregory S. Chirikjian",
        "authorids": "/37088689259;/37088686627;/37283175100;/37088689259;/37088686627;/37283175100",
        "aff": "Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562084/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8139445062064752625&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561825",
        "title": "Looking Farther in Parametric Scene Parsing with Ground and Aerial Imagery",
        "track": "main",
        "status": "Poster",
        "abstract": "Parametric models that represent layout in terms of scene attributes are an attractive avenue for road scene understanding in autonomous navigation. Prior works that rely only on ground imagery are limited by the narrow field of view of the camera, occlusions and perspective foreshortening. In this paper, we demonstrate the effectiveness of using aerial imagery as an additional modality to overcome the above challenges. We propose a novel architecture, Unified, that combines features from both aerial and ground imagery to infer scene attributes. We quantitatively evaluate on the KITTI dataset and show that our Unified model outperforms prior works. Since this dataset is limited to road scenes close to the vehicle, we supplement the publicly available Argoverse dataset with scene attribute annotations and evaluate on far-away scenes. We show both quantitatively and qualitatively, the importance of aerial imagery in understanding road scenes, especially in regions farther away from the ego-vehicle. All code, models, and data, including scene attribute annotations on the Argoverse dataset along with collected and processed aerial imagery, are available at https://bit.ly/2QsKNeR.",
        "primary_area": "",
        "author": "Raghava Modhugu;Harish Rithish Sethuram;Manmohan Chandraker;C.V. Jawahar;Raghava Modhugu;Harish Rithish Sethuram;Manmohan Chandraker;C.V. Jawahar",
        "authorids": "/37088998985;/37088996797;/37397476800;/37270075200;/37088998985;/37088996797;/37397476800;/37270075200",
        "aff": "Center for Visual Information Technology(CVIT), IIIT Hyderabad, India; Center for Visual Information Technology(CVIT), IIIT Hyderabad, India; University of California, San Diego; Center for Visual Information Technology(CVIT), IIIT Hyderabad, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561825/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:AP6l5lOm35oJ:scholar.google.com/&scioq=Looking+Farther+in+Parametric+Scene+Parsing+with+Ground+and+Aerial+Imagery&hl=en&as_sdt=0,33",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "IIIT Hyderabad;University of California, San Diego",
        "aff_unique_dep": "Center for Visual Information Technology;",
        "aff_unique_url": "https://www.iiit Hyderabad.ac.in;https://www.ucsd.edu",
        "aff_unique_abbr": "IIIT-H;UCSD",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Hyderabad;San Diego",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "India;United States"
    },
    {
        "id": "9561128",
        "title": "Lywal: a Leg-Wheel Transformable Quadruped Robot with Picking up and Transport Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a leg-wheel transformable quadruped robot named Lywal which can switch to the leg-mode and the wheel-mode for locomotion, and the claw-mode for picking up and transport functions. First, the mechanical structure of Lywal is designed by using an innovative 2-DoF transformable mechanism. Second, the calculation of kinematics is analyzed in detail. Then, the switching-mode strategy and the mobile control strategies in different modes are designed. Finally, the prototype of Lywal is built. The properties of the mobile modes are analyzed, and the picking-up and transport functions of the claw-mode are verified through physical experiments.",
        "primary_area": "",
        "author": "Yongjiang Xue;Xichen Yuan;Yuhai Wang;Yang Yang;Siyu Lu;Bo Zhang;Juezhu Lai;Jianming Wang;Xuan Xiao;Yongjiang Xue;Xichen Yuan;Yuhai Wang;Yang Yang;Siyu Lu;Bo Zhang;Juezhu Lai;Jianming Wang;Xuan Xiao",
        "authorids": "/37088996143;/37088995935;/37089002312;/37088996588;/37088999104;/37088999518;/37088572943;/37538990400;/37088987287;/37088996143;/37088995935;/37089002312;/37088996588;/37088999104;/37088999518;/37088572943;/37538990400;/37088987287",
        "aff": "School of Computer Science and Technology, Tiangong University, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China; Tianjin Key Laboratory of Autonomous Intelligence Technology and Systems, Tianjin, China; School of Computer Science and Technology, Tiangong University, Tianjin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561128/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8717810328355197787&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;1;0",
        "aff_unique_norm": "Tiangong University;Tianjin Key Laboratory of Autonomous Intelligence Technology and Systems",
        "aff_unique_dep": "School of Computer Science and Technology;Autonomous Intelligence Technology and Systems",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Tianjin;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561893",
        "title": "MAPS-X: Explainable Multi-Robot Motion Planning via Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional multi-robot motion planning (MMP) focuses on computing trajectories for multiple robots acting in an environment, such that the robots do not collide when the trajectories are taken simultaneously. In safety-critical applications, a human supervisor may want to verify that the plan is indeed collision-free. In this work, we propose a notion of explanation for a plan of MMP, based on visualization of the plan as a short sequence of images representing time segments, where in each time segment the trajectories of the agents are disjoint, clearly illustrating the safety of the plan. We show that standard notions of optimality (e.g., makespan) may create conflict with short explanations. Thus, we propose meta-algorithms, namely multi-agent plan segmenting-X (MAPS-X) and its lazy variant, that can be plugged on existing centralized sampling-based tree planners X to produce plans with good explanations using a desirable number of images. We demonstrate the efficacy of this explanation-planning scheme and extensively evaluate the performance of MAPS-X and its lazy variant in various environments and agent dynamics.",
        "primary_area": "",
        "author": "Justin Kottinger;Shaull Almagor;Morteza Lahijanian;Justin Kottinger;Shaull Almagor;Morteza Lahijanian",
        "authorids": "/37089000996;/37089001811;/37398443600;/37089000996;/37089001811;/37398443600",
        "aff": "Department of Aerospace Engineering Sciences, University of Colorado Boulder, USA; The Henry and Marilyn Taub Faculty of Computer Science, Technion, Israel; Department of Computer Science, University of Colorado Boulder, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561893/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12098003367681761493&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Colorado Boulder;Technion",
        "aff_unique_dep": "Department of Aerospace Engineering Sciences;Faculty of Computer Science",
        "aff_unique_url": "https://www.colorado.edu;https://www.cs.technion.ac.il",
        "aff_unique_abbr": "CU Boulder;Technion",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boulder;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Israel"
    },
    {
        "id": "9560763",
        "title": "MCMC Occupancy Grid Mapping with a Data-Driven Patch Prior",
        "track": "main",
        "status": "Poster",
        "abstract": "Occupancy grids have been widely used for mapping with mobile robots for several decades. Occupancy grids discretize the analog environment and seek to determine the occupancy probability of each cell. More recent occupancy grid mapping algorithms have shown the advantage of capturing cell correlations in the measurement model and the posterior. By estimating the probability of a given map as opposed to a cell, these algorithms have been able to better capture the occupancy probability of cells in the map. The advantage of incorporating data-driven prior probabilities in occupancy grid mapping is explored. A form of Markov Chain Monte Carlo (MCMC) known as Gibbs sampling allows us to sample maps from the full posterior. Previous research has sampled the occupancy probability of each cell, but this paper extends that work to sample a larger patch of cells and highlights the benefit of obtaining the prior for each patch from real maps.",
        "primary_area": "",
        "author": "Rehman S. Merali;Timothy D. Barfoot;Rehman S. Merali;Timothy D. Barfoot",
        "authorids": "/38542466300;/37283734000;/38542466300;/37283734000",
        "aff": "University of Toronto Institute for Aerospace Studies (UTIAS), Toronto, Canada; University of Toronto Institute for Aerospace Studies (UTIAS), Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560763/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:8f8_QeBjdgMJ:scholar.google.com/&scioq=MCMC+Occupancy+Grid+Mapping+with+a+Data-Driven+Patch+Prior&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Toronto Institute for Aerospace Studies",
        "aff_unique_dep": "Institute for Aerospace Studies",
        "aff_unique_url": "https://utias.utoronto.ca",
        "aff_unique_abbr": "UTIAS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561490",
        "title": "MDANet: Multi-Modal Deep Aggregation Network for Depth Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth completion aims to recover the dense depth map from sparse depth data and RGB image respectively. However, due to the huge difference between the multi-modal signal input, vanilla convolutional neural network and simple fusion strategy cannot extract features from sparse data and aggregate multi-modal information effectively. To tackle this problem, we design a novel network architecture that takes full advantage of multi-modal features for depth completion. An effective Pre-completion algorithm is first put forward to increase the density of the input depth map and to provide distribution priors. Moreover, to effectively fuse the image features and the depth features, we propose a multi-modal deep aggregation block that consists of multiple connection and aggregation pathways for deeper fusion. Furthermore, based on the intuition that semantic image features are beneficial for accurate contour, we introduce the deformable guided fusion layer to guide the generation of the dense depth map. The resulting architecture, called MDANet, outperforms all the stateof-the-art methods on the popular KITTI Depth Completion Benchmark, meanwhile with fewer parameters than recent methods. The code of this work will be available at https://github.com/USTC-Keyanjie/MDANet_ICRA2021.",
        "primary_area": "",
        "author": "Yanjie Ke;Kun Li;Wei Yang;Zhenbo Xu;Dayang Hao;Liusheng Huang;Gang Wang;Yanjie Ke;Kun Li;Wei Yang;Zhenbo Xu;Dayang Hao;Liusheng Huang;Gang Wang",
        "authorids": "/37089001480;/37089401093;/37631814600;/37086533881;/37089001503;/37280053300;/37088996350;/37089001480;/37089401093;/37631814600;/37086533881;/37089001503;/37280053300;/37088996350",
        "aff": "University of Science and Technology of China; Damo Academy, Alibaba Group; University of Science and Technology of China; University of Science and Technology of China; Damo Academy, Alibaba Group; University of Science and Technology of China; Damo Academy, Alibaba Group",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561490/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12469685095432527055&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;1;0;1",
        "aff_unique_norm": "University of Science and Technology of China;Alibaba Group",
        "aff_unique_dep": ";Damo Academy",
        "aff_unique_url": "http://www.ustc.edu.cn;https://www.alibaba-group.com",
        "aff_unique_abbr": "USTC;Alibaba",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561878",
        "title": "MFPN-6D : Real-time One-stage Pose Estimation of Objects on RGB Images",
        "track": "main",
        "status": "Poster",
        "abstract": "6D pose estimation of objects is an important part of robot grasping. The latest research trend on 6D pose estimation is to train a deep neural network to directly predict the 2D projection position of the 3D key points from the image, establish the corresponding relationship, and finally use Pespective-n-Point (PnP) algorithm performs pose estimation. The current challenge of pose estimation is that when the object texture-less, occluded and scene clutter, the detection accuracy will be reduced, and most of the existing algorithm models are large and cannot take the real-time requirements. In this paper, we introduce a Multi-directional Feature Pyramid Network, MFPN, which can efficiently integrate and utilize features. We combined the Cross Stage Partial Network (CSPNet) with MFPN to design a new network for 6D pose estimation, MFPN-6D. At the same time, we propose a new confidence calculation method for object pose estimation, which can fully consider spatial information and plane information. At last, we tested our method on the LINEMOD and Occluded-LINEMOD datasets. The experimental results demonstrate that our algorithm is robust to textureless materials and occlusion, while running more efficiently compared to other methods.",
        "primary_area": "",
        "author": "Penglei Liu;Qieshi Zhang;Jin Zhang;Fei Wang;Jun Cheng;Penglei Liu;Qieshi Zhang;Jin Zhang;Fei Wang;Jun Cheng",
        "authorids": "/37088988776;/37086091868;/37088774203;/37088987682;/37277385900;/37088988776;/37086091868;/37088774203;/37088987682;/37277385900",
        "aff": "The Chinese University of Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China; The College of Computer Science and Software Engineering, Shenzhen University, China; The Chinese University of Hong Kong, Hong Kong, China; The Chinese University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561878/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13510767406565038571&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Shenzhen University",
        "aff_unique_dep": ";College of Computer Science and Software Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.szu.edu.cn",
        "aff_unique_abbr": "CUHK;SZU",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Hong Kong;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561148",
        "title": "MIDAS: Multi-agent Interaction-aware Decision-making with Adaptive Strategies for Urban Autonomous Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous navigation in crowded, complex urban environments requires interacting with other agents on the road. A common solution to this problem is to use a prediction model to guess the likely future actions of other agents. While this is reasonable, it leads to overly conservative plans because it does not explicitly model the mutual influence of the actions of interacting agents. This paper builds a reinforcement learning-based method named MIDAS where an Ego agent learns to affect the control actions of other cars in urban driving scenarios. MIDAS uses an attention mechanism to handle an arbitrary number of other agents and includes a \"driver-type\" parameter to learn a single policy that works across different planning objectives. We build a simulation environment that enables diverse interaction experiments with a large number of agents and develop methods for quantitatively studying the safety, efficiency, and interaction among vehicles. MIDAS is validated using extensive experiments and we show that it (i) can work across different road geometries, (ii) results in an adaptive Ego policy that can be tuned easily to satisfy different performance criteria, such as aggressive or cautious driving, (iii) is robust to changes in the driving policies of external agents, and (iv) is safer and more efficient than existing approaches to interaction-aware decision-making. Code available here.",
        "primary_area": "",
        "author": "Xiaoyi Chen;Pratik Chaudhari;Xiaoyi Chen;Pratik Chaudhari",
        "authorids": "/37088997928;/38113795600;/37088997928;/38113795600",
        "aff": "University of Pennsylvania. Currently at Nuro, Inc; Department of Electrical & Systems Engineering, GRASP Laboratory at the University of Pennsylvania",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561148/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3675943665836770382&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561846",
        "title": "MO-BBO: Multi-Objective Bilevel Bayesian Optimization for Robot and Behavior Co-Design",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot design is a time-consuming process involving repeated experiments in a variety of environments to optimize multiple, possibly conflicting performance metrics. Moreover, the optimal robot performance for a given design depends on how the robot adapts its behavior to its environment. We propose a multi-objective Bilevel Bayesian optimization (MO-BBO) technique to automate the process of form-behavior co-design. The approach expands the Pareto front of multiple metrics by simultaneously exploring the robot design and behavior. MO-BBO uses a bilevel optimization of the acquisition function with design and behavior parameters being the high- and low-level decision variables, respectively. In the low-level, we always choose environment-aware behaviors that maximize each metric. We evaluate MO-BBO in applications to grasping gripper design and bimanual arm placement, and show that our method can efficiently focus samples on the Pareto front and generate a diversity of designs.",
        "primary_area": "",
        "author": "Yeonju Kim;Zherong Pan;Kris Hauser;Yeonju Kim;Zherong Pan;Kris Hauser",
        "authorids": "/37088998944;/37086067204;/37543748800;/37088998944;/37086067204;/37543748800",
        "aff": "Dept. of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561846/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13268057850896183356&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Dept. of Mechanical Science and Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Urbana",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561023",
        "title": "MP-STSP: A Multi-Platform Steiner Traveling Salesman Problem Formulation for Precision Agriculture in Orchards",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose a global planning strategy specifically designed for precision agriculture settings, where field activities may have different requirements ranging from a full orchard inspection to sparse targeted per-plant interventions. This global planning strategy is formulated as a novel Multi-Platform Steiner Traveling Salesman Problem (MP-STSP) where, in order to guarantee the exploitation of multiple moving platforms and the minimization of the overall operational time, the proposed formulation explicitly takes into account the time required to perform each task. By doing so, the computed itineraries attempt to balance the workload among the deployed platforms. Comparative simulations, inspired by the needs of the EU H2020 Project PANTHEON 1, are provided to numerically demonstrate the effectiveness of the proposed planning strategy for an orchard precision agriculture setting.",
        "primary_area": "",
        "author": "Renzo Fabrizio Carpio;Jacopo Maiolini;Ciro Potena;Emanuele Garone;Giovanni Ulivi;Andrea Gasparn;Renzo Fabrizio Carpio;Jacopo Maiolini;Ciro Potena;Emanuele Garone;Giovanni Ulivi;Andrea Gasparn",
        "authorids": "/37086574459;/37087413803;/37086242890;/37299281800;/37298366900;/37088999433;/37086574459;/37087413803;/37086242890;/37299281800;/37298366900;/37088999433",
        "aff": "Roma Tre University, Rome, Italy; Roma Tre University, Rome, Italy; Roma Tre University, Rome, Italy; Universit\u00e9 Libre de Bruxelles, Brussels, Belgium; Roma Tre University, Rome, Italy; Roma Tre University, Rome, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561023/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1911409092076149675&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Roma Tre University;Universit\u00e9 Libre de Bruxelles",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.uniroma3.it;https://www.ulb.ac.be",
        "aff_unique_abbr": "Roma Tre;ULB",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Rome;Brussels",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "Italy;Belgium"
    },
    {
        "id": "9561901",
        "title": "MRPB 1.0: A Unified Benchmark for the Evaluation of Mobile Robot Local Planning Approaches",
        "track": "main",
        "status": "Poster",
        "abstract": "Local planning is one of the key technologies for mobile robots to achieve full autonomy and has been widely investigated. To evaluate mobile robot local planning approaches in a unified and comprehensive way, a mobile robot local planning benchmark called MRPB 1.0 is newly proposed in this paper. The benchmark facilitates both motion planning researchers who want to compare the performance of a new local planner relative to many other state-of-the-art approaches as well as end users in the mobile robotics industry who want to select a local planner that performs best on some problems of interest. We elaborately design various simulation scenarios to challenge the applicability of local planners, including large-scale, partially unknown, and dynamic complex environments. Furthermore, three types of principled evaluation metrics are carefully designed to quantitatively evaluate the performance of local planners, wherein the safety, efficiency, and smoothness of motions are comprehensively considered. We present the application of the proposed benchmark in two popular open-source local planners to show the practicality of the benchmark. In addition, some insights and guidelines about the design and selection of local planners are also provided. The benchmark website [1] contains all data of the designed simulation scenarios, detailed descriptions of these scenarios, and example code.",
        "primary_area": "",
        "author": "Jian Wen;Xuebo Zhang;Qingchen Bi;Zhangchao Pan;Yanghe Feng;Jing Yuan;Yongchun Fang;Jian Wen;Xuebo Zhang;Qingchen Bi;Zhangchao Pan;Yanghe Feng;Jing Yuan;Yongchun Fang",
        "authorids": "/37086601896;/37085511576;/37089001921;/37089399698;/37089405764;/37281353400;/37293583100;/37086601896;/37085511576;/37089001921;/37089399698;/37089405764;/37281353400;/37293583100",
        "aff": "Tianjin Key Laboratory of Intelligent Robotics, Nankai University, Tianjin, China; Tianjin Key Laboratory of Intelligent Robotics, Nankai University, Tianjin, China; School of Marine Science and Technology, Northwestern Polytechnical University, Xi\u2019an, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; College of Systems Engineering, National University of Defense Technology, Changsha, China; Tianjin Key Laboratory of Intelligent Robotics, Nankai University, Tianjin, China; Tianjin Key Laboratory of Intelligent Robotics, Nankai University, Tianjin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561901/",
        "gs_citation": 44,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4452376188267609127&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;2;3;0;0",
        "aff_unique_norm": "Nankai University;Northwestern Polytechnical University;Northeastern University;National University of Defense Technology",
        "aff_unique_dep": "Tianjin Key Laboratory of Intelligent Robotics;School of Marine Science and Technology;Faculty of Robot Science and Engineering;College of Systems Engineering",
        "aff_unique_url": "http://www.nankai.edu.cn;http://www.nwpu.edu.cn;http://www.neu.edu.cn/;http://www.nudt.edu.cn",
        "aff_unique_abbr": "Nankai;NPU;NEU;NUDT",
        "aff_campus_unique_index": "0;0;1;2;3;0;0",
        "aff_campus_unique": "Tianjin;Xi'an;Shenyang;Changsha",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561779",
        "title": "MS*: A New Exact Algorithm for Multi-agent Simultaneous Multi-goal Sequencing and Path Finding",
        "track": "main",
        "status": "Poster",
        "abstract": "In multi-agent applications such as surveillance and logistics, fleets of mobile agents are often expected to coordinate and safely visit a large number of goal locations as efficiently as possible. The multi-agent planning problem in these applications involves allocating and sequencing goals for each agent while simultaneously producing conflict-free paths for the agents. In this article, we introduce a new algorithm called MS* which computes an optimal solution for this multi-agent problem by fusing and advancing state of the art solvers for multi-agent path finding (MAPF) and multiple travelling salesman problem (mTSP). MS* leverages our prior subdimensional expansion approach for MAPF and embeds the mTSP solvers to optimally allocate and sequence goals for agents. Numerical results show that our new algorithm can solve the multi-agent problem with 20 agents and 50 goals in a minute of CPU time on a standard laptop.",
        "primary_area": "",
        "author": "Zhongqiang Ren;Sivakumar Rathinam;Howie Choset;Zhongqiang Ren;Sivakumar Rathinam;Howie Choset",
        "authorids": "/37086293378;/37268809800;/37281322200;/37086293378;/37268809800;/37281322200",
        "aff": "Robotics Institute and the Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Texas A&M University, College Station, TX; Robotics Institute and the Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561779/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17983038019710274908&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Texas A&M University",
        "aff_unique_dep": "Robotics Institute and Department of Mechanical Engineering;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.tamu.edu",
        "aff_unique_abbr": "CMU;TAMU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pittsburgh;College Station",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561565",
        "title": "MS-RANAS: Multi-Scale Resource-Aware Neural Architecture Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Neural Architecture Search (NAS) has proved effective in offering outperforming alternatives to handcrafted neural networks. In this paper we analyse the benefits of NAS for image classification tasks under strict computational constraints. Our aim is to automate the design of highly efficient deep neural networks, capable of offering fast and accurate predictions and that could be deployed on a low-memory, low-power system-on-chip. The task thus becomes a three-party trade-off between accuracy, computational complexity, and memory requirements. To address this concern, we propose Multi-Scale Resource-Aware Neural Architecture Search (MS-RANAS). We employ a one-shot architecture search approach in order to obtain a reduced search cost and we focus on an anytime prediction setting. Through the usage of multiple-scaled features and early classifiers, we achieved state-of-the-art results in terms of accuracy-speed trade-off.",
        "primary_area": "",
        "author": "Cristian Cioflan;Radu Timofte;Cristian Cioflan;Radu Timofte",
        "authorids": "/37089001851;/37393691200;/37089001851;/37393691200",
        "aff": "Computer Vision Laboratory, ETH Zurich; Computer Vision Laboratory, ETH Zurich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561565/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1678190272999678784&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Computer Vision Laboratory",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561533",
        "title": "MS2MP: A Min-Sum Message Passing Algorithm for Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Gaussian Process (GP) formulation of continuous-time trajectory offers a fast solution to the motion planning problem via probabilistic inference on factor graph. However, often the solution converges to in-feasible local minima and the planned trajectory is not collision-free. We propose a message passing algorithm that is more sensitive to obstacles with fast convergence time. We leverage the utility of min-sum message passing algorithm that performs local computations at each node to solve the inference problem on factor graph. We first introduce the notion of compound factor node to transform the factor graph to a linearly structured graph. We next develop an algorithm denoted as Min-sum Message Passing algorithm for Motion Planning (MS2MP) that combines numerical optimization with message passing to find collision- free trajectories. MS2MP performs numerical optimization to solve non-linear least square minimization problem at each compound factor node and then exploits the linear structure of factor graph to compute the maximum a posteriori (MAP) estimation of complete graph by passing messages among graph nodes. The decentralized optimization approach of each compound node increases sensitivity towards avoiding obstacles for harder planning problems. We evaluate our algorithm by performing extensive experiments for exemplary motion planning tasks for a robot manipulator. Our evaluation reveals that MS2MP improves existing work in convergence time and success rate.",
        "primary_area": "",
        "author": "Salman Bari;Volker Gabler;Dirk Wollherr;Salman Bari;Volker Gabler;Dirk Wollherr",
        "authorids": "/37086799443;/37085642348;/37295545400;/37086799443;/37085642348;/37295545400",
        "aff": "Department of Electrical and Computer Engineering, Automatic Control Engineering (LSR), Technical University of Munich, Germany; Department of Electrical and Computer Engineering, Automatic Control Engineering (LSR), Technical University of Munich, Germany; Department of Electrical and Computer Engineering, Automatic Control Engineering (LSR), Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561533/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7016880353372519119&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561371",
        "title": "MSTC\u2217:Multi-robot Coverage Path Planning under Physical Constrain",
        "track": "main",
        "status": "Poster",
        "abstract": "For large-scale tasks, coverage path planning (CPP) can benefit greatly from multiple robots. In this paper, we present an efficient algorithm MSTC\u2217 for multi-robot coverage path planning (mCPP) based on spiral spanning tree coverage (Spiral-STC). Our algorithm incorporates strict physical constraints like terrain traversability and material load capacity. We compare our algorithm against the state-of-the-art in mCPP for regular grid maps and real field terrains in simulation environments. The experimental results show that our method significantly outperforms existing spiral-STC based mCPP methods. Our algorithm can find a set of well-balanced workload distributions for all robots and therefore, achieve the overall minimum time to complete the coverage.",
        "primary_area": "",
        "author": "Jingtao Tang;Chun Sun;Xinyu Zhang;Jingtao Tang;Chun Sun;Xinyu Zhang",
        "authorids": "/37088952602;/37088954040;/37558390400;/37088952602;/37088954040;/37558390400",
        "aff": "Shanghai Key Laboratory of Trustworthy Computing, Engineering Research Center of Software/Hardware Co-Design Technology and Application (MoE) and School of Software Engineering, East China Normal University, Shanghai; Shanghai Key Laboratory of Trustworthy Computing, Engineering Research Center of Software/Hardware Co-Design Technology and Application (MoE) and School of Software Engineering, East China Normal University, Shanghai; Shanghai Key Laboratory of Trustworthy Computing, Engineering Research Center of Software/Hardware Co-Design Technology and Application (MoE) and School of Software Engineering, East China Normal University, Shanghai",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561371/",
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7166907786603165925&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "East China Normal University",
        "aff_unique_dep": "School of Software Engineering",
        "aff_unique_url": "http://www.ecnu.edu.cn",
        "aff_unique_abbr": "ECNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561471",
        "title": "MSTSL: Multi-Sensor Based Two-Step Localization in Geometrically Symmetric Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Symmetric environment is one of the most intractable and challenging scenarios for mobile robots to accomplish global localization tasks, due to the highly similar geometrical structures and insufficient distinctive features. Existing localization solutions in such scenarios either depend on pre-deployed infrastructures which are expensive, inflexible, and hard to maintain; or rely on single sensor-based methods whose initialization module is incapable to provide enough unique information. Thus, this paper proposes a novel Multi-Sensor based Two-Step Localization framework named MSTSL, which addresses the problem of mobile robot global localization in geometrically symmetric environments by utilizing the measured magnetic field, 2-D LiDAR, and wheel odometry information. The proposed system mainly consists of two steps: 1) Magnetic Field-based Initialization, and 2) LiDAR-based Localization. Based on the pre-built magnetic field database, multiple initial hypotheses poses can firstly be determined by the proposed two-stage initialization algorithm. Then, utilizing the obtained multiple initial hypotheses, the robot can be localized more accurately by LiDAR-based localization. Extensive experiments demonstrate the practical utility and accuracy of the proposed system over the alternative approaches in real-world scenarios.",
        "primary_area": "",
        "author": "Zhenyu Wu;Yufeng Yue;Mingxing Wen;Jun Zhang;Guohao Peng;Danwei Wang;Zhenyu Wu;Yufeng Yue;Mingxing Wen;Jun Zhang;Guohao Peng;Danwei Wang",
        "authorids": "/37088406849;/37086172414;/37086451677;/37086009222;/37087049757;/37279547600;/37088406849;/37086172414;/37086451677;/37086009222;/37087049757;/37279547600",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Automation, Beijing Institute of Technology, Beijing, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561471/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11313819351332813520&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Nanyang Technological University;Beijing Institute of Technology",
        "aff_unique_dep": "School of Electrical and Electronic Engineering;School of Automation",
        "aff_unique_url": "https://www.ntu.edu.sg;http://www.bit.edu.cn",
        "aff_unique_abbr": "NTU;BIT",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Singapore;Beijing",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9561364",
        "title": "MULLS: Versatile LiDAR SLAM via Multi-metric Linear Least Square",
        "track": "main",
        "status": "Poster",
        "abstract": "The rapid development of autonomous driving and mobile mapping calls for off-the-shelf LiDAR SLAM solutions that are adaptive to LiDARs of different specifications on various complex scenarios. To this end, we propose MULLS, an efficient, low-drift, and versatile 3D LiDAR SLAM system. For the front-end, roughly classified feature points (ground, facade, pillar, beam, etc.) are extracted from each frame using dual-threshold ground filtering and principal components analysis. Then the registration between the current frame and the local submap is accomplished efficiently by the proposed multi-metric linear least square iterative closest point algorithm. Point-to-point (plane, line) error metrics within each point class are jointly optimized with a linear approximation to estimate the ego-motion. Static feature points of the registered frame are appended into the local map to keep it updated. For the back-end, hierarchical pose graph optimization is conducted among regularly stored history submaps to reduce the drift resulting from dead reckoning. Extensive experiments are carried out on three datasets with more than 100,000 frames collected by seven types of LiDAR on various outdoor and indoor scenarios. On the KITTI benchmark, MULLS ranks among the top LiDAR-only SLAM systems with real-time performance.",
        "primary_area": "",
        "author": "Yue Pan;Pengchuan Xiao;Yujie He;Zhenlei Shao;Zesong Li;Yue Pan;Pengchuan Xiao;Yujie He;Zhenlei Shao;Zesong Li",
        "authorids": "/37088999871;/37089000767;/37089267286;/37088996598;/37089000907;/37088999871;/37089000767;/37089267286;/37088996598;/37089000907",
        "aff": "Department of Civil, Environmental and Geomatic Engineering, ETH, Zurich, Switzerland; Hesai Technology Co., Ltd., Shanghai, China; the School of Engineering, EPFL, Lausanne, Switzerland; Hesai Technology Co., Ltd., Shanghai, China; Hesai Technology Co., Ltd., Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561364/",
        "gs_citation": 236,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11560335241082419180&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;1;1",
        "aff_unique_norm": "ETH Zurich;Hesai Technology Co., Ltd.;EPFL",
        "aff_unique_dep": "Department of Civil, Environmental and Geomatic Engineering;;School of Engineering",
        "aff_unique_url": "https://www.ethz.ch;;https://www.epfl.ch",
        "aff_unique_abbr": "ETHZ;;EPFL",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Zurich;;Lausanne",
        "aff_country_unique_index": "0;1;0;1;1",
        "aff_country_unique": "Switzerland;China"
    },
    {
        "id": "9561058",
        "title": "MaAST: Map Attention with Semantic Transformers for Efficient Visual Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual navigation for autonomous agents is a core task in the fields of computer vision and robotics. Learning-based methods, such as deep reinforcement learning, have the potential to outperform the classical solutions developed for this task; however, they come at a significantly increased computational load. Through this work, we design a novel approach that focuses on performing better or comparable to the existing learning-based solutions but under a clear time/computational budget. To this end, we propose a method to encode vital scene semantics such as traversable paths, unexplored areas, and observed scene objects\u2013alongside raw visual streams such as RGB, depth, and semantic segmentation masks\u2014into a semantically informed, top-down egocentric map representation. Further, to enable the effective use of this information, we introduce a novel 2-D map attention mechanism, based on the successful multi-layer Transformer networks. We conduct experiments on 3-D reconstructed indoor PointGoal visual navigation and demonstrate the effectiveness of our approach. We show that by using our novel attention schema and auxiliary rewards to better utilize scene semantics, we outperform multiple baselines trained with only raw inputs or implicit semantic information while operating with an 80% decrease in the agent\u2019s experience.",
        "primary_area": "",
        "author": "Zachary Seymour;Kowshik Thopalli;Niluthpol Mithun;Han-Pang Chiu;Supun Samarasekera;Rakesh Kumar;Zachary Seymour;Kowshik Thopalli;Niluthpol Mithun;Han-Pang Chiu;Supun Samarasekera;Rakesh Kumar",
        "authorids": "/37088996752;/37086864864;/37845735800;/37596940200;/37326240700;/37272667800;/37088996752;/37086864864;/37845735800;/37596940200;/37326240700;/37272667800",
        "aff": "SRI International; Arizona State University; SRI International; SRI International; SRI International; SRI International",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561058/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14357172841001347258&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "SRI International;Arizona State University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.sri.com;https://www.asu.edu",
        "aff_unique_abbr": "SRI;ASU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561691",
        "title": "Machine Learning-based Human-Following System: Following the Predicted Position of a Walking Human",
        "track": "main",
        "status": "Poster",
        "abstract": "Human\u2013robot interaction (HRI) has been widely researched in diverse applications. A robot following a person is one such scenario investigated in the HRI field. However, human movements and actions are complex and can change dramatically. We herein demonstrate a machine learning-based system that allows a person-following robot to track in real-time the predicted future motion of a walking human, from a first-person perspective. We assume that a depth sensor that can detect the human skeleton is loaded on a mobile robot to provide data on the user\u2019s motion from a first-person perspective. The system calculates the coordinates of the center of gravity (COG) and 25 body joints of the user. These coordinates of COG and 25 body joints are relative to the robot based on the position of the person tracked, and these are used for the input dataset of a neural network (NN) that predicts human motion. A five-layered NN estimates the relative vectors in real-time between the current person\u2019s COG and the future position of the 25 body joints. Using a proportional\u2013integral\u2013derivative (PID) controller, the person-following robot can track the predicted position of a walking human 0.5 s in advance to increase the robustness of following and to avoid delays.",
        "primary_area": "",
        "author": "Ansheng Wang;Yasutoshi Makino;Hiroyuki Shinoda;Ansheng Wang;Yasutoshi Makino;Hiroyuki Shinoda",
        "authorids": "/37088999536;/37280554800;/37280567100;/37088999536;/37280554800;/37280567100",
        "aff": "Graduate School of Frontier Sciences, University of Tokyo, Kashiwa-shi, Chiba; JST PRESTO, Tokyo, Japan; Graduate School of Frontier Sciences, University of Tokyo, Kashiwa-shi, Chiba",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561691/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15457480650194141909&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Tokyo;Japan Science and Technology Agency",
        "aff_unique_dep": "Graduate School of Frontier Sciences;PRESTO",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.jst.go.jp",
        "aff_unique_abbr": "UTokyo;JST",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Kashiwa-shi, Chiba;Tokyo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9560786",
        "title": "Macro-Mini Actuation of Pneumatic Pouches for Soft Wearable Haptic Displays",
        "track": "main",
        "status": "Poster",
        "abstract": "Pneumatic wearable haptic devices can provide distributed pressure feedback to human operators during robot teleoperation and in virtual and augmented reality. However, these devices have an inherent trade-off between the spatial coverage of their pressure output and their resolution and dynamic response. To achieve specified spatial resolution and dynamic response, we propose a macro-mini actuation approach that stacks a number of smaller inflatable pouches atop a larger inflatable pouch. We develop models for the static and dynamic responses of single and stacked pouches and compare these with experimental results, providing guidelines for the design of wearable stacked pneumatic displays. Finally, we demonstrate this pneumatic macro-mini approach by replicating the time series pressure profiles of data collected from a huggable robot embedded with distributed force sensors.",
        "primary_area": "",
        "author": "Brian H. Do;Allison M. Okamura;Katsu Yamane;Laura H. Blumenschein;Brian H. Do;Allison M. Okamura;Katsu Yamane;Laura H. Blumenschein",
        "authorids": "/37086414589;/37276156400;/37291289300;/37085849839;/37086414589;/37276156400;/37291289300;/37085849839",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Honda Research Institute, San Jose, CA, USA; School of Mechanical Engineering, Purdue University, Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560786/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5263876657604367030&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Stanford University;Honda Research Institute;Purdue University",
        "aff_unique_dep": "Department of Mechanical Engineering;;School of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu;https://honda-ri.com;https://www.purdue.edu",
        "aff_unique_abbr": "Stanford;HRI;Purdue",
        "aff_campus_unique_index": "0;0;1;2",
        "aff_campus_unique": "Stanford;San Jose;Lafayette",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561141",
        "title": "Magnetically-Connected Modular Reconfigurable Mini-robotic System with Bilateral Isokinematic Mapping and Fast On-site Assembly towards Minimally Invasive Procedures",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a modular and reconfigurable mini-robotic system with 5 degrees of freedom (DoFs) towards minimally invasive surgery (MIS). The mini-robotic system consists of two modules, a 2-DoFs rotational end-effector, and a 3-DoFs positioning platform. The 2-DoFs rotational end-effector is based on a spring-spherical joint mechanism, whose rotation is controlled by Bowden-cable. The 3-DoFs positioning platform is based on the linear Delta parallel mechanism. Magnetic spherical joints are adopted to replace the traditional spherical joint. The magnetic joint connections enable fast assembling and disassemble of the end platform and kinematic chains. Different surgical instruments can be installed without changing the driver and control system. A flexible shaft actuates the 3-DoFs positioning platform to arrange the motors away from the manipulator side. Based on these structure characteristics, the 3-DoFs positioning platform\u2019s size is dramatically reduced. The outer diameter of the current prototype is 32.5 mm. The single-axis positioning accuracy of the 3-DoFs positioning platform is within -1 mm to 0.85 mm. Three axes tracking experiments are also carried out, with the positioning errors of \u00b1 1.2 mm for cylindrical curves and -1.5 mm to 2 mm for spherical helix curves. Static and dynamic load capabilities are also tested. Finally, the feasibility of the proposed system is demonstrated.",
        "primary_area": "",
        "author": "Xiao Xiao;Shilei Xu;Changsheng Li;Xiaoyi Gu;Huxin Gao;Max Q.-H. Meng;Hongliang Ren;Xiao Xiao;Shilei Xu;Changsheng Li;Xiaoyi Gu;Huxin Gao;Max Q.-H. Meng;Hongliang Ren",
        "authorids": "/37086545706;/37089399331;/37086224774;/37085619877;/37088379696;/37274117000;/37287561300;/37086545706;/37089399331;/37086224774;/37085619877;/37088379696;/37274117000;/37287561300",
        "aff": "Department of Biomedical Engineering, National University of Singapore, Singapore, Singapore; School of Electrical and Electronic Engineering, Shijiazhuang Tiedao University, Shijiazhuang, China; School of Mechatronical Engineering & Beijing Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, Beijing, China; NUS (Suzhou) Research Institute (NUSRI), Suzhou, China; NUS (Suzhou) Research Institute (NUSRI), Suzhou, China; Department of Electrical and Electronic Engineering, Southern University of Science and Technology, Shenzhen, China; NUS (Suzhou) Research Institute (NUSRI), Suzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561141/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11585174484996225185&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;3;3;4;3",
        "aff_unique_norm": "National University of Singapore;Shijiazhuang Tiedao University;Beijing Institute of Technology;National University of Singapore (NUS);Southern University of Science and Technology",
        "aff_unique_dep": "Department of Biomedical Engineering;School of Electrical and Electronic Engineering;School of Mechatronical Engineering;Research Institute;Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.nus.edu.sg;;http://www.bit.edu.cn;https://www.nus.edu.sg;https://www.sustech.edu.cn",
        "aff_unique_abbr": "NUS;;BIT;NUS;SUSTech",
        "aff_campus_unique_index": "1;2;3;3;4;3",
        "aff_campus_unique": ";Shijiazhuang;Beijing;Suzhou;Shenzhen",
        "aff_country_unique_index": "0;1;1;1;1;1;1",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9561210",
        "title": "Maintaining a Reliable World Model using Action-aware Perceptual Anchoring",
        "track": "main",
        "status": "Poster",
        "abstract": "Reliable perception is essential for robots that interact with the world. But sensors alone are often insufficient to provide this capability, and they are prone to errors due to various conditions in the environment. Furthermore, there is a need for robots to maintain a model of its surroundings even when objects go out of view and are no longer visible. This requires anchoring perceptual information onto symbols that represent the objects in the environment. In this paper, we present a model for action-aware perceptual anchoring that enables robots to track objects in a persistent manner. Our rule-based approach considers inductive biases to perform high-level reasoning over the results from low-level object detection, and it improves the robot\u2019s perceptual capability for complex tasks. We evaluate our model against existing baseline models for object permanence and show that it outperforms these on a snitch localisation task using a dataset of 1,371 videos. We also integrate our action-aware perceptual anchoring in the context of a cognitive architecture and demonstrate its benefits in a realistic gearbox assembly task on a Universal Robot.",
        "primary_area": "",
        "author": "Ying Siu Liang;Dongkyu Choi;Kenneth Kwok;Ying Siu Liang;Dongkyu Choi;Kenneth Kwok",
        "authorids": "/37088998440;/37088998738;/37088996704;/37088998440;/37088998738;/37088996704",
        "aff": "Social and Cognitive Computing, Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore; Social and Cognitive Computing, Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore; Social and Cognitive Computing, Institute of High Performance Computing, Agency for Science, Technology and Research, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561210/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3156498410116934922&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Agency for Science, Technology and Research",
        "aff_unique_dep": "Institute of High Performance Computing",
        "aff_unique_url": "https://www.a-star.edu.sg",
        "aff_unique_abbr": "A*STAR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9562030",
        "title": "ManhattanSLAM: Robust Planar Tracking and Mapping Leveraging Mixture of Manhattan Frames",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a robust RGB-D SLAM system is proposed to utilize the structural information in indoor scenes, allowing for accurate tracking and efficient dense mapping on a CPU. Prior works have used the Manhattan World (MW) assumption to estimate low-drift camera pose, in turn limiting the applications of such systems. This paper, in contrast, proposes a novel approach delivering robust tracking in MW and non-MW environments. We check orthogonal relations between planes to directly detect Manhattan Frames, modeling the scene as a Mixture of Manhattan Frames. For MW scenes, we decouple pose estimation and provide a novel drift-free rotation estimation based on Manhattan Frame observations. For translation estimation in MW scenes and full camera pose estimation in non-MW scenes, we make use of point, line and plane features for robust tracking in challenging scenes. Additionally, by exploiting plane features detected in each frame, we also propose an efficient surfel-based dense mapping strategy, which divides each image into planar and non-planar regions. Planar surfels are initialized directly from sparse planes in our map while non-planar surfels are built by extracting superpixels. We evaluate our method on public benchmarks for pose estimation, drift and reconstruction accuracy, achieving superior performance compared to other state-of-the-art methods. We will open-source our code in the future.",
        "primary_area": "",
        "author": "Raza Yunus;Yanyan Li;Federico Tombari;Raza Yunus;Yanyan Li;Federico Tombari",
        "authorids": "/37088996793;/37088471090;/37593332100;/37088996793;/37088471090;/37593332100",
        "aff": "Technical University of Munich, Germany; Technical University of Munich, Germany; Google Inc",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562030/",
        "gs_citation": 85,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15846362743700450762&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Technical University of Munich;Google",
        "aff_unique_dep": ";Google",
        "aff_unique_url": "https://www.tum.de;https://www.google.com",
        "aff_unique_abbr": "TUM;Google",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9561105",
        "title": "Manipulability optimization for multi-arm teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "Teleoperation provides a way for human operators to guide robots in situations where full autonomy is challenging or where direct human intervention is required. It can also be an important tool to teach robots in order to achieve autonomous behaviour later on. The increased availability of collaborative robot arms and Virtual Reality (VR) devices, provides ample opportunity for development of novel teleoperation methods. Since robot arms are often kinematically different from human arms, mapping human motions to a robot in real-time is not trivial. Additionally, a human operator might steer the robot arm toward singularities or its workspace limits, which can lead to undesirable behaviour. This is further accentuated for the orchestration of multiple robots. In this paper, we present a VR interface targeted to multi-arm payload manipulation, which can closely match real-time input motion. Allowing the user to manipulate the payload rather than mapping their motions to individual arms we are able to simultaneously guide multiple collaborative arms. By releasing a single rotational degree of freedom, and by using a local optimization method, we can improve each arm\u2019s manipulability index, which in turn lets us avoid kinematic singularities and workspace limitations. We apply our approach to predefined trajectories as well as real-time teleoperation on different robot arms and compare performance in terms of end-effector position error and relevant joint motion metrics.",
        "primary_area": "",
        "author": "Florian Kennel-Maushart;Roi Poranne;Stelian Coros;Florian Kennel-Maushart;Roi Poranne;Stelian Coros",
        "authorids": "/37088998456;/37085580542;/37077396200;/37088998456;/37085580542;/37077396200",
        "aff": "Department of Computer Science, ETH, Zurich, Switzerland; Department of Computer Science, University of Haifa, Haifa, Israel; Department of Computer Science, ETH, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561105/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11145759191634369913&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "ETH Zurich;University of Haifa",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.ethz.ch;https://www.haifa.ac.il",
        "aff_unique_abbr": "ETHZ;UoH",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Zurich;Haifa",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Switzerland;Israel"
    },
    {
        "id": "9561221",
        "title": "Manipulation Planning Among Movable Obstacles Using Physics-Based Adaptive Motion Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot manipulation in cluttered scenes often requires contact-rich interactions with objects. It can be more economical to interact via non-prehensile actions, for example, push through other objects to get to the desired grasp pose, instead of deliberate prehensile rearrangement of the scene. For each object in a scene, depending on its properties, the robot may or may not be allowed to make contact with, tilt, or topple it. To ensure that these constraints are satisfied during non-prehensile interactions, a planner can query a physics-based simulator to evaluate the complex multi-body interactions caused by robot actions. Unfortunately, it is infeasible to query the simulator for thousands of actions that need to be evaluated in a typical planning problem as each simulation is time-consuming. In this work, we show that (i) manipulation tasks (specifically pick-and-place style tasks from a tabletop or a refrigerator) can often be solved by restricting robot-object interactions to adaptive motion primitives in a plan, (ii) these actions can be incorporated as subgoals within a multi-heuristic search framework, and (iii) limiting interactions to these actions can help reduce the time spent querying the simulator during planning by up to 40\u00d7 in comparison to baseline algorithms. Our algorithm is evaluated in simulation and in the real-world on a PR2 robot using PyBullet as our physics-based simulator. Supplementary video: https://youtu.be/ABQc7JbeJPM.",
        "primary_area": "",
        "author": "Dhruv Mauria Saxena;Muhammad Suhail Saleem;Maxim Likhachev;Dhruv Mauria Saxena;Muhammad Suhail Saleem;Maxim Likhachev",
        "authorids": "/37086188218;/37088999044;/37309318800;/37086188218;/37088999044;/37309318800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561221/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15391976838664765108&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561108",
        "title": "Manipulator Task Space Trajectory Tracking with Kinematics and Dynamics Uncertainties",
        "track": "main",
        "status": "Poster",
        "abstract": "The paper develops a control scheme for task-space trajectory tracking of robot manipulators in the face of unknown kinematic and dynamic parameters of both the manipulator and picked object/tool, and in the presence of time varying disturbances/noise and certain unmodelled dynamics. The proposed scheme consists of an outer task-space control loop and an inner joint space control loop. The two control loops in combination ensure that the errors tend to zero asymptotically and thus achieve precise task-space tracking. Other features of the proposed method are simple control structure that do not require decomposition of the dynamics into the regressor matrix-parameter vector. Simulation results are provided for a full 6-DOF manipulator performing complex tasks while carrying a tool with unknown kinematics and dynamics parameters.",
        "primary_area": "",
        "author": "Mahmoud Tarokh;Mahmoud Tarokh",
        "authorids": "/37299023800;/37299023800",
        "aff": "Department of Computer Science, Intelligent Robots and Systems Laboratory, San Diego State University, San Diego, CA, U.S.A.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561108/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2890121877919912820&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "San Diego State University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.sdsu.edu",
        "aff_unique_abbr": "SDSU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561460",
        "title": "Mapless-Planner: A Robust and Fast Planning Framework for Aggressive Autonomous Flight without Map Fusion",
        "track": "main",
        "status": "Poster",
        "abstract": "Maintaining a map online is resource-consuming while a robust navigation system usually needs environment abstraction via a well-fused map. In this paper, we propose a mapless local planner which directly conducts such abstraction on the unfused sensor data. A limited-memory data structure with a reliable proximity query algorithm is proposed for maintaining raw historical information. A sampling-based scheme is designed to extract the free-space skeleton. A smart waypoint selection strategy enables to generate high-quality trajectories within the resultant flight corridors. Our planner differs from other mapless ones in that it can abstract and exploit the environment information more efficiently. The online replan consistency and success rate are both significantly improved against conventional mapless methods.",
        "primary_area": "",
        "author": "Jialin Ji;Zhepei Wang;Yingjian Wang;Chao Xu;Fei Gao;Jialin Ji;Zhepei Wang;Yingjian Wang;Chao Xu;Fei Gao",
        "authorids": "/37088999913;/37086601081;/37089002292;/37404060100;/37086045143;/37088999913;/37086601081;/37089002292;/37404060100;/37086045143",
        "aff": "National Engineering Research Center for Industrial Automation, Ningbo Institute, Ningbo, China; National Engineering Research Center for Industrial Automation, Ningbo Institute, Ningbo, China; National Engineering Research Center for Industrial Automation, Ningbo Institute, Ningbo, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561460/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=740887110234687680&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "National Engineering Research Center for Industrial Automation;Zhejiang University",
        "aff_unique_dep": ";Huzhou Institute",
        "aff_unique_url": ";https://www.zju.edu.cn",
        "aff_unique_abbr": ";ZJU",
        "aff_campus_unique_index": "0;0;0;1;1",
        "aff_campus_unique": "Ningbo;Huzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562044",
        "title": "Markov Localisation using Heatmap Regression and Deep Convolutional Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "In the context of self-driving vehicles there is strong competition between approaches based on visual localisation and Light Detection And Ranging (LiDAR). While LiDAR provides important depth information, it is sparse in resolution and expensive. On the other hand, cameras are low-cost and recent developments in deep learning mean they can provide high localisation performance. However, several fundamental problems remain, particularly in the domain of uncertainty, where learning based approaches can be notoriously over-confident.Markov, or grid-based, localisation was an early solution to the localisation problem but fell out of favour due to its computational complexity. Representing the likelihood field as a grid (or volume) means there is a trade off between accuracy and memory size. Furthermore, it is necessary to perform expensive convolutions across the entire likelihood volume. Despite the benefit of simultaneously maintaining a likelihood for all possible locations, grid based approaches were superseded by more efficient particle filters and Monte Carlo sampling (MCL). However, MCL introduces its own problems e.g. particle deprivation.Recent advances in deep learning hardware allow large likelihood volumes to be stored directly on the GPU, along with the hardware necessary to efficiently perform GPU-bound 3D convolutions and this obviates many of the disadvantages of grid based methods. In this work, we present a novel CNN-based localisation approach that can leverage modern deep learning hardware. By implementing a grid-based Markov localisation approach directly on the GPU, we create a hybrid Convolutional Neural Network (CNN) that can perform image-based localisation and odometry-based likelihood propagation within a single neural network. The resulting approach is capable of outperforming direct pose regression methods as well as state-of-the-art localisation systems.",
        "primary_area": "",
        "author": "Oscar Mendez;Simon Hadfield;Richard Bowden;Oscar Mendez;Simon Hadfield;Richard Bowden",
        "authorids": "/37710939600;/38232557500;/37268872100;/37710939600;/38232557500;/37268872100",
        "aff": "Centre for Vision Speech and Signal Processing, University of Surrey, Guildford, UK; Centre for Vision Speech and Signal Processing, University of Surrey, Guildford, UK; Centre for Vision Speech and Signal Processing, University of Surrey, Guildford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562044/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7329468449448669619&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Surrey",
        "aff_unique_dep": "Centre for Vision Speech and Signal Processing",
        "aff_unique_url": "https://www.surrey.ac.uk",
        "aff_unique_abbr": "Surrey",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Guildford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561238",
        "title": "Markov Parallel Tracking and Mapping for Probabilistic SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "Parallel tracking and mapping (PTAM) as a time-efficient framework for simultaneous localization and mapping (SLAM) has been becoming popular in recent years. However, in this paper, we vigilantly point out that the favorite parallel-pipeline design realized by recent proposed SLAM algorithms may lead to inaccurate state estimates which, as a consequence, cannot always guarantee the performance of the estimators in real application. This is mainly due to the imperfect design for processing loop-closure measurements which accidentally violates the Markov assumption for probabilistic SLAM problem. To address this issue, a novel estimator design is proposed that holds the advantage of parallel processing, while striving to be consistent with the Markov property of the batch probabilistic SLAM estimator, therefore, termed Markov parallel tracking and mapping (MPTAM). Especially, the experiments on challenging visual-inertial datasets are employed to further demonstrate the improvements of proposed estimator in terms of accuracy and efficiency, as compared with the state-of-the-art SLAM system.",
        "primary_area": "",
        "author": "Zheng Huai;Guoquan Huang;Zheng Huai;Guoquan Huang",
        "authorids": "/37086580080;/37077670600;/37086580080;/37077670600",
        "aff": "Department of Mechanical Engineering, University of Delaware, Newark, DE, USA; Department of Mechanical Engineering, University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561238/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2202171809452629571&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560975",
        "title": "Mass Estimation of a Moving Object Through Minimal Manipulation Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the problem of dynamic interaction between a robot and an unknown object (e.g., catching a ball, or handing off an object during locomotion). In particular, we propose a method for estimating the inertial parameters of an object during dynamic interaction, while minimally altering the trajectory of the object \u2013 a minimal interaction approach. Our method combines trajectory estimation (e.g., using standard methods from computer vision) with a model-based estimator that exploits the robot\u2019s known dynamic model. We first develop the method for a generalized three-dimensional problem, and then evaluate the method for the case of an object moving along a linear trajectory. We present experimental results obtained using a KUKA iiwa 7 interacting with rolling balls of varying mass. Our experiments demonstrate that the mass of the objects can be accurately estimated at the moment of impact when accurate object trajectory estimates are available, and that significant improvement can be obtained by incorporating force measurements at the contact point while following the object.",
        "primary_area": "",
        "author": "Sergio Aguilera;Muhammad Ali Murtaza;Ye Zhao;Seth Hutchinson;Sergio Aguilera;Muhammad Ali Murtaza;Ye Zhao;Seth Hutchinson",
        "authorids": "/37085576930;/37088316016;/37089401010;/37282386200;/37085576930;/37088316016;/37089401010;/37282386200",
        "aff": "Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA; Institute of Robotics and Intelligent Machines, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560975/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17040921645826374516&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "Institute of Robotics and Intelligent Machines",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560772",
        "title": "Mathematical Modeling of a Highly Underactuated Tool for Draping Fiber Plies on Double Curved Molds",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a model based approach for predicting the forward kinematics of a tool for picking prepreg fiber plies from a flat table and draping them onto a double curved mold. The tool consists of suction cups interlinked with springs. The tool has 60 actuated and 240 passive degrees of freedom. The prediction is based on establishing a kinematic model of the total potential energy of the tool and minimizing this energy, under the assumptions that dynamic artifacts can be neglected as the movements are relatively slow, and that the springs interpolate the orientation of the suction cups. Various assumptions and simplifications are presented to increase computational speed.Finally, the model predictions are compared to real configurations measured by a camera. Four configurations are simulated and measured and the largest RMS positional deviation measured is 1.99mm, the largest residual measured is 3.68mm. The tolerance of the layup process is 2.5mm so more work needs to be done to reduce the maximum deviations.",
        "primary_area": "",
        "author": "Gudmundur G. G. Serpina;Henrik G. Petersen;Gudmundur G. G. Serpina;Henrik G. Petersen",
        "authorids": "/37088999346;/37562505800;/37088999346;/37562505800",
        "aff": "SDU Robotics, University of Southern Denmark, Odense M, Denmark; SDU Robotics, University of Southern Denmark, Odense M, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560772/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6712587932404944137&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Southern Denmark",
        "aff_unique_dep": "SDU Robotics",
        "aff_unique_url": "https://www.sdu.dk",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Odense",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9560918",
        "title": "Meaningful Centroidal Frame Orientation of Multi-body Floating Locomotion Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a meaningful definition of rotational centroidal orientation which is somewhat missed in the state-of-the-art centroidal momentum and dynamics theory for locomotion robots with one floating base. This centroidal instantaneous orientation rotates as the robot runs, and it is extracted from the total system angular inertia. The new centroidal frame is proposed to be parallel with the principal axes of the centroidal angular inertia, which can describe the whole-robot rotational motion. To avoid high fluctuations of centroidal frame orientation parameters between adjacent control loops, we develop one algorithm to enable the centroidal instantaneous frame to be smooth. The relationship between the centroidal angle rate and the centroidal angular velocity is derived, as well as the relationship in the acceleration level, which can be used for whole-body torque control. The new centroidal orientation or Euler angle is verified by two-scenario simulations, and another scenario is used to track and control the centroidal angular motion in the first-order kinematics level. The idea has considerable potential for system design, motion generation, and torque control in robotics communities with different research topics and theoretical backgrounds.",
        "primary_area": "",
        "author": "Wenqian Du;Ze Wang;Etienne Moullet;Fa\u00efz Benamar;Wenqian Du;Ze Wang;Etienne Moullet;Fa\u00efz Benamar",
        "authorids": "/37087240306;/37088999473;/37088999671;/37283664500;/37087240306;/37088999473;/37088999671;/37283664500",
        "aff": "CNRS, Institut des Syst\u00e8mes Intelligents et de Robotique: ISIR, Sorbonne University, Paris, France; CNRS, Institut des Syst\u00e8mes Intelligents et de Robotique: ISIR, Sorbonne University, Paris, France; CNRS, Institut des Syst\u00e8mes Intelligents et de Robotique: ISIR, Sorbonne University, Paris, France; CNRS, Institut des Syst\u00e8mes Intelligents et de Robotique: ISIR, Sorbonne University, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560918/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3884517074952588255&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "CNRS",
        "aff_unique_dep": "Institut des Syst\u00e8mes Intelligents et de Robotique: ISIR",
        "aff_unique_url": "https://www.cnrs.fr",
        "aff_unique_abbr": "CNRS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9560834",
        "title": "Mecanum Crank: A Novel Omni-Directional Vehicle Using Crank Leg",
        "track": "main",
        "status": "Poster",
        "abstract": "A vehicle is expected to exhibit omni-directional locomotion capability to provide improved rough terrain vehicle functionality. Generally, rough terrain vehicles are not holonomic and cannot travel in the lateral direction, whereas typical omni-directional vehicles have difficulty in traveling on rough terrain. This paper proposes installing a crank leg for a Mecanum-wheeled vehicle (\"Mecanum crank\") to enhance its rough-terrain locomotion. Compared with other holonomic vehicles designed for rough terrain locomotion, the proposed design exhibited superior capability in the longitudinal wheel direction. To avoid the conflict between the crank leg and Mecanum wheel, this paper proposes the use of a differential gear system. The simple structure of the crank leg enables the implementation of a swing equalizer and roller grousers, which further enhance its rough-terrain locomotion. In longitudinal locomotion experiments, the proposed mechanism could climb a 95 mm-high step, which is 95% of the Mecanum wheel diameter. Furthermore, Mecanum crank could climb miniature scale stairs and execute lateral locomotion on them.",
        "primary_area": "",
        "author": "Satsuya Noda;Haruki Kunii;Mutsuki Yaginuma;Kazushi Yamanobe;Satsuya Noda;Haruki Kunii;Mutsuki Yaginuma;Kazushi Yamanobe",
        "authorids": "/37089001581;/37088997151;/37088997936;/37088999786;/37089001581;/37088997151;/37088997936;/37088999786",
        "aff": "Department of Mechanical System Engineering, National Institute of Technology, Fukushima College, Fukushima, Japan; Department of Mechanical System Engineering, National Institute of Technology, Fukushima College, Fukushima, Japan; Department of Mechanical System Engineering, National Institute of Technology, Fukushima College, Fukushima, Japan; Department of Mechanical System Engineering, National Institute of Technology, Fukushima College, Fukushima, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560834/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12548273139360935286&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Technology, Fukushima College",
        "aff_unique_dep": "Department of Mechanical System Engineering",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Fukushima",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561457",
        "title": "Mechanical Intelligence for Adaptive Precision Grasp",
        "track": "main",
        "status": "Poster",
        "abstract": "Mechanical intelligence is the use of mechanical and other physical properties to create robotic systems adaptable to new external situations using simple control schemes. Designs of robot hands have successfully been developed and optimised following this principle to produce self-adaptive and versatile power grasps via implementations based on underactuated fingers, elastic components, and open-loop motor control. However, these characteristics, and mechanical-intelligent strategies in general, have been seldom leveraged for precision grasping. This paper proposes a mechanical-intelligent technique to facilitate not only spiral caging power grasp, but also self-adaptive precision grasp with error tolerance. This approach is exemplified by the rigorous analysis, development, and testing of a novel three-fingered, two-actuator, underactuated robot hand, called the helical hand, which is capable of self-adaptive precision grasping, and of generating spiral helical power grasps of unknown objects by simply setting two actuators at a constant speed.",
        "primary_area": "",
        "author": "Qiujie Lu;Nicholas Baron;Guochao Bai;Nicolas Rojas;Qiujie Lu;Nicholas Baron;Guochao Bai;Nicolas Rojas",
        "authorids": "/37086808828;/37088416297;/37086601108;/37990657400;/37086808828;/37088416297;/37086601108;/37990657400",
        "aff": "REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK; REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK; Wangjing Science & Technology Innovation Park, ChangingTek Ltd, Chaoyang District, Beijing, China; REDS Lab, Dyson School of Design Engineering, Imperial College London, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561457/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13255863412593638444&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Imperial College London;ChangingTek Ltd",
        "aff_unique_dep": "Dyson School of Design Engineering;",
        "aff_unique_url": "https://www.imperial.ac.uk;",
        "aff_unique_abbr": "ICL;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9562052",
        "title": "Mechatronic Design of A Low-Noise Active Knee Prosthesis with High Backdrivability",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a low-damping active knee prosthesis (LDKP) with low noise and high backdrivability. The proposed prosthesis is driven by a motor and then decelerated by a four-stage synchronous belt. High backdrivability given by this structure accelerates the prosthetic response. A control system containing several sensors are embedded in the proposed prosthesis to recognize different modes and provide corresponding strategies. Preliminary experiments were carried out on a transfemoral amputee subject, demonstrating the features of low noise, high backdrivability and ability to reproduce natural walking gaits.",
        "primary_area": "",
        "author": "Guoxiang Fu;Jinying Zhu;Zilu Wang;Jingeng Mai;Qining Wang;Guoxiang Fu;Jinying Zhu;Zilu Wang;Jingeng Mai;Qining Wang",
        "authorids": "/37089002189;/37964245100;/37088457259;/38186603900;/37577407400;/37089002189;/37964245100;/37088457259;/38186603900;/37577407400",
        "aff": "Beijing Engineering Research Center of Intelligent Rehabilitation Engineering, Beijing, China; R&D Center of the SpeedSmart Co. Ltd., China; Beijing Engineering Research Center of Intelligent Rehabilitation Engineering, Beijing, China; Beijing Engineering Research Center of Intelligent Rehabilitation Engineering, Beijing, China; Beijing Engineering Research Center of Intelligent Rehabilitation Engineering, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562052/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2102212609696544992&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Beijing Engineering Research Center of Intelligent Rehabilitation Engineering;SpeedSmart Co. Ltd.",
        "aff_unique_dep": ";R&D Center",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561874",
        "title": "Mesh Based Analysis of Low Fractal Dimension Reinforcement Learning Policies",
        "track": "main",
        "status": "Poster",
        "abstract": "In previous work, using a process we call meshing, the reachable state spaces for various continuous and hybrid systems were approximated as a discrete set of states which can then be synthesized into a Markov chain. One of the applications for this approach has been to analyze locomotion policies obtained by reinforcement learning, in a step towards making empirical guarantees about the stability properties of the resulting system. In a separate line of research, we introduced a modified reward function for on-policy reinforcement learning algorithms that utilizes a \"fractal dimension\" of rollout trajectories. This reward was shown to encourage policies that induce individual trajectories which can be more compactly represented as a discrete mesh. In this work, we combine these two threads of research by building meshes of the reachable state space of a system subject to disturbances and controlled by policies obtained with the modified reward. Our analysis shows that the modified policies do produce much smaller reachable meshes. This shows that agents trained with the fractal dimension reward transfer their desirable quality of having a more compact state space to a setting with external disturbances. The results also suggest that the previous work using mesh based tools to analyze RL policies may be extended to higher dimensional systems or to higher resolution meshes than would have otherwise been possible.",
        "primary_area": "",
        "author": "Sean Gillen;Katie Byl;Sean Gillen;Katie Byl",
        "authorids": "/37088749406;/37569022700;/37088749406;/37569022700",
        "aff": "Electrical and Computer Engineering Department, University of California, Santa Barbara, CA; Electrical and Computer Engineering Department, University of California, Santa Barbara, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561874/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18083428382267441224&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Santa Barbara",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.ucsb.edu",
        "aff_unique_abbr": "UCSB",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Santa Barbara",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561337",
        "title": "Mesh Reconstruction from Aerial Images for Outdoor Terrain Mapping Using Joint 2D-3D Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses outdoor terrain mapping using overhead images obtained from an unmanned aerial vehicle. Dense depth estimation from aerial images during flight is challenging. While feature-based localization and mapping techniques can deliver real-time odometry and sparse points reconstruction, a dense environment model is generally recovered offline with significant computation and storage. This paper develops a joint 2D-3D learning approach to reconstruct local meshes at each camera keyframe, which can be assembled into a global environment model. Each local mesh is initialized from sparse depth measurements. We associate image features with the mesh vertices through camera projection and apply graph convolution to refine the mesh vertices based on joint 2-D reprojected depth and 3-D mesh supervision. Quantitative and qualitative evaluations using real aerial images show the potential of our method to support environmental monitoring and surveillance applications.",
        "primary_area": "",
        "author": "Qiaojun Feng;Nikolay Atanasov;Qiaojun Feng;Nikolay Atanasov",
        "authorids": "/37087322298;/37670511000;/37087322298;/37670511000",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561337/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17708186598323536800&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561330",
        "title": "Meta-Adversarial Inverse Reinforcement Learning for Decision-making Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning from demonstrations has made great progress over the past few years. However, it is generally data hungry and task specific. In other words, it requires a large amount of data to train a decent model on a particular task, and the model often fails to generalize to new tasks that have a different distribution. In practice, demonstrations from new tasks will be continuously observed and the data might be unlabeled or only partially labeled. Therefore, it is desirable for the trained model to adapt to new tasks that have limited data samples available. In this work, we build an adaptable imitation learning model based on the integration of Meta-learning and Adversarial Inverse Reinforcement Learning (Meta-AIRL). We exploit the adversarial learning and inverse reinforcement learning mechanisms to learn policies and reward functions simultaneously from available training tasks and then adapt them to new tasks with the meta-learning framework. Simulation results show that the adapted policy trained with Meta-AIRL can effectively learn from limited number of demonstrations, and quickly reach the performance comparable to that of the experts on unseen tasks.",
        "primary_area": "",
        "author": "Pin Wang;Hanhan Li;Ching-Yao Chan;Pin Wang;Hanhan Li;Ching-Yao Chan",
        "authorids": "/37086349924;/37086964505;/37280785000;/37086349924;/37086964505;/37280785000",
        "aff": "University of California, Berkeley; Google Research; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561330/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4744322629569802789&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of California, Berkeley;Google",
        "aff_unique_dep": ";Google Research",
        "aff_unique_url": "https://www.berkeley.edu;https://research.google",
        "aff_unique_abbr": "UC Berkeley;Google Research",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Berkeley;Mountain View",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560846",
        "title": "Micro Robotic Manipulation System for the Force Stimulation of Muscle Fiber-like Cell Structure",
        "track": "main",
        "status": "Poster",
        "abstract": "Many previous works have facilitated muscle cell (C2C12) alignment to form fiber-like cell structures. However, there still remains a challenge how to induce C2C12 myoblasts in the cell structures to differentiate into matured myocytes to form a functional muscle tissue, while external mechanical stimulation has been proved to have good effects on proliferation and differentiation of myoblasts. In this paper, we proposed a vision-based micro robotic manipulation system to achieve automatic mechanical stimulation for one single muscle fiber-like cell structures (MFCS). A tube, which is attached to a three degree-of-freedom (DOF) manipulator, and a probe are employed to apply the uniaxial mechanical stimulation to train the MFCS. To measure the force applied on MFCS, a vision-based measuring and correction method is utilized, which decrease the error by 74%. Moreover, based on the viscoelastic property of the MFCS, a feedback control algorithm has been applied to compensate for the force loss to realize the force stimulation. And the final value of force remains 699 \u00b1 1\u03bcN after 110s experiment.",
        "primary_area": "",
        "author": "Xie Chen;Qing Shi;Shingo Shimoda;Tao Sun;Huaping Wang;Qiang Huang;Toshio Fukuda;Xie Chen;Qing Shi;Shingo Shimoda;Tao Sun;Huaping Wang;Qiang Huang;Toshio Fukuda",
        "authorids": "/37087097351;/37593189500;/38185136400;/38022518100;/37964523300;/37279982900;/37279174500;/37087097351;/37593189500;/38185136400;/38022518100;/37964523300;/37279982900;/37279174500",
        "aff": "Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Intelligent Behavior Control Collaboration Unit, RIKEN Center of Brain Science, Nagoya, Japan; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Intelligent Robotics Institute, School of Mechatronical Engineering, Beijing Institute of Technology, Beijing, China; Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, Beijing, China; Advanced Innovation Center for Intelligent Robots and Systems, Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560846/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18053796438952038400&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;0;0;0",
        "aff_unique_norm": "Beijing Institute of Technology;RIKEN Center of Brain Science",
        "aff_unique_dep": "School of Mechatronical Engineering;Intelligent Behavior Control Collaboration Unit",
        "aff_unique_url": "http://www.bit.edu.cn;https://www.riken.jp/en/cbs/",
        "aff_unique_abbr": "BIT;RIKEN CBS",
        "aff_campus_unique_index": "0;0;1;0;0;0;0",
        "aff_campus_unique": "Beijing;Nagoya",
        "aff_country_unique_index": "0;0;1;0;0;0;0",
        "aff_country_unique": "China;Japan"
    },
    {
        "id": "9560913",
        "title": "Mid-Air Range-Visual-Inertial Estimator Initialization for Micro Air Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular Visual-Inertial Odometry (VIO) has become ubiquitous for navigation of autonomous Micro Air Vehicles (MAVs). Yet, state-of-the-art VIO is still very failure-prone, which can have dramatic consequences. To prevent this, VIO must be able to re-initialize in mid-air, either during a free fall or on a constant velocity trajectory after attitude control has been re-established. However, for both of these trajectories, the visual scale cannot be observed with VIO batch initializers because of the absence of acceleration change. We propose to use a small and lightweight laser-range finder (LRF) and a scene facet model to initialize vision-based navigation at the right scale under any motion condition and over any scene structure. This new range constraint is integrated into a visual-inertial bundle-adjustment initializer. We evaluate our approach in simulation, including robustness to various parameters, and demonstrate on real data how this approach can address midair state estimation failure in real-time.",
        "primary_area": "",
        "author": "Martin Scheiber;Jeff Delaune;Stephan Weiss;Roland Brockers;Martin Scheiber;Jeff Delaune;Stephan Weiss;Roland Brockers",
        "authorids": "/37087323697;/37086592626;/37535323400;/37266435300;/37087323697;/37086592626;/37535323400;/37266435300",
        "aff": "Faculty of Intelligent System Technologies, Group Control of Networked Systems, Universit\u00e4t Klagenfurt, Klagenfurt, Austria; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, California, USA; Faculty of Intelligent System Technologies, Group Control of Networked Systems, Universit\u00e4t Klagenfurt, Klagenfurt, Austria; Jet Propulsion Laboratory, California Institute of Technology, Pasadena, California, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560913/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10622797701680452525&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Universit\u00e4t Klagenfurt;California Institute of Technology",
        "aff_unique_dep": "Faculty of Intelligent System Technologies, Group Control of Networked Systems;Jet Propulsion Laboratory",
        "aff_unique_url": "https://www.aau.at;https://www.caltech.edu",
        "aff_unique_abbr": ";Caltech",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Klagenfurt;Pasadena",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Austria;United States"
    },
    {
        "id": "9561771",
        "title": "Min-Max Entropy Inverse RL of Multiple Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-task IRL recognizes that expert(s) could be switching between multiple ways of solving the same problem, or interleaving demonstrations of multiple tasks. The learner aims to learn the reward functions that individually guide these distinct ways. We present a new method for multi-task IRL that generalizes the well-known maximum entropy approach by combining it with a Dirichlet process based minimum entropy clustering of the observed data. This yields a single nonlinear optimization problem, called MinMaxEnt Multi-task IRL (MME-MTIRL), which can be solved using the Lagrangian relaxation and gradient descent methods. We evaluate MME-MTIRL on the robotic task of sorting onions on a processing line where the expert utilizes multiple ways of detecting and removing blemished onions. The method is able to learn the underlying reward functions to a high level of accuracy and it improves on the previous approaches.",
        "primary_area": "",
        "author": "Saurabh Arora;Prashant Doshi;Bikramjit Banerjee;Saurabh Arora;Prashant Doshi;Bikramjit Banerjee",
        "authorids": "/37089001750;/37284971800;/38084661100;/37089001750;/37284971800;/38084661100",
        "aff": "Dept. of Computer Science, THINC Lab, University of Georgia, Athens, GA, USA; Dept. of Computer Science, THINC Lab, University of Georgia, Athens, GA, USA; School of Computing Sciences and Computer Engineering, University of Southern Mississippi, Hattiesburg, MS, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561771/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8336709379200302351&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Georgia;University of Southern Mississippi",
        "aff_unique_dep": "Dept. of Computer Science;School of Computing Sciences and Computer Engineering",
        "aff_unique_url": "https://www.uga.edu;https://www.usm.edu",
        "aff_unique_abbr": "UGA;USM",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Athens;Hattiesburg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561976",
        "title": "Minimum directed information: A design principle for compliant robots",
        "track": "main",
        "status": "Poster",
        "abstract": "A robot\u2019s dynamics \u2013 especially the degree and location of compliance \u2013 can significantly affect performance and control complexity. Passive dynamics can be designed with good regions of attraction or limit cycles for a specific task, but achieving flexibility on a range of tasks requires co-design of control. This paper takes an information perspective: the robot dynamics should reduce the amount of information required for a controller to achieve a threshold of performance in a range of tasks. Towards this goal, an iterative method is proposed to minimize the directed information from state to control on discrete-time nonlinear systems. iLQG is used to find a controller and value of information, then the design parameters of the dynamics (e.g. stiffness of end-effector or joint) are optimized to reduce directed information while maintaining a minimum bound on performance. The approach is validated in simulation, on a two-mass system in contact with an uncertain wall position and a high-DOF door opening task, and shown to improve noise robustness and reduce time variance of control gains.",
        "primary_area": "",
        "author": "Kevin Haninger;Kevin Haninger",
        "authorids": "/38468165500;/38468165500",
        "aff": "Fraunhofer Institut f\u00fcr Produktionsanlagen und Konstruktionstechnik",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561976/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15088016914065432060&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Fraunhofer Institute for Production Systems and Construction Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ipk.fraunhofer.de/",
        "aff_unique_abbr": "IPK",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561273",
        "title": "Minimum-Effort Task-based Design Optimization of Modular Reconfigurable Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The flexibility and adaptability of modular and re-configurable robots opens up new opportunities for on-demand robot morphology optimization for varying tasks. In particular, multi-arm robotic systems can expand the solution space for any given task. In this paper, we present a novel approach to exploit this feature for generating optimal fit-to-task robot structures with respect to a minimum-effort objective. By describing the task in terms of relative poses between the end-effector and the constraint frame, and making use of the relative Jacobian, the minimum effort optimization problem can be equally expressed for single-arm or multi-arm robots. We test our approach for a peg-in-hole and a contour-following task and compare the performance of the optimal solution obtained with that of a standard manipulator configuration.",
        "primary_area": "",
        "author": "Edoardo Romiti;Navvab Kashiri;J\u00f6rn Malzahn;Nikos Tsagarakis;Edoardo Romiti;Navvab Kashiri;J\u00f6rn Malzahn;Nikos Tsagarakis",
        "authorids": "/37088998285;/38667578800;/38534818900;/37295830800;/37088998285;/38667578800;/38534818900;/37295830800",
        "aff": "Humanoids and Human-centered Mechatronics Lab, Istituto Italiano di Tecnologia, Genova, Italy; Humanoids and Human-centered Mechatronics Lab, Istituto Italiano di Tecnologia, Genova, Italy; Humanoids and Human-centered Mechatronics Lab, Istituto Italiano di Tecnologia, Genova, Italy; Humanoids and Human-centered Mechatronics Lab, Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561273/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9253630154122698991&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Humanoids and Human-centered Mechatronics Lab",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genova",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9561386",
        "title": "ModGNN: Expert Policy Approximation in Multi-Agent Systems with a Modular Graph Neural Network Architecture",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work in the multi-agent domain has shown the promise of Graph Neural Networks (GNNs) to learn complex coordination strategies. However, most current approaches use minor variants of a Graph Convolutional Network (GCN), which applies a convolution to the communication graph formed by the multi-agent system. In this paper, we investigate whether the performance and generalization of GCNs can be improved upon. We introduce ModGNN, a decentralized framework which serves as a generalization of GCNs, providing more flexibility. To test our hypothesis, we evaluate an implementation of ModGNN against several baselines in the multi-agent flocking problem. We perform an ablation analysis to show that the most important component of our framework is one that does not exist in a GCN. By varying the number of agents, we also demonstrate that an application-agnostic implementation of ModGNN possesses an improved ability to generalize to new environments.",
        "primary_area": "",
        "author": "Ryan Kortvelesy;Amanda Prorok;Ryan Kortvelesy;Amanda Prorok",
        "authorids": "/37086188040;/37542741000;/37086188040;/37542741000",
        "aff": "Department of Computer Science and Technology, University of Cambridge, Cambridge, United Kingdom; Department of Computer Science and Technology, University of Cambridge, Cambridge, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561386/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2653504079709329182&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Cambridge",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.cam.ac.uk",
        "aff_unique_abbr": "Cambridge",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561914",
        "title": "Modal Dynamic Modelling and Experimental Validation of a Curved Extensible Continuum Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "This study presents a novel dynamic modelling method for analyzing the modal properties of a curved extensible continuum manipulator (ECM). Considering the variable bending angle and the length, the kinematic and static models are firstly established for descripting the geometric posture deformation and deflection generated by gravity. Then, the modal dynamic model is developed along the centerline direction of the ECM in the polar coordinates, by which the modal properties, include modal frequency and mode shape of curved continuum manipulator with different posture parameters are analyzed. The modal response is further analyzed based on the generalized coordinate method. Finally, the modal properties of ECM with variable posture are experimentally tested and compared with the theoretical value using the in-house developed ECM physical prototype. In the experiments, the bending, length varying and circular tracking motion are performed for the comprehensive validation of the proposed dynamics modelling method.",
        "primary_area": "",
        "author": "Hao Wang;Xuping Zhang;Hao Wang;Xuping Zhang",
        "authorids": "/37089503836;/37085664403;/37089503836;/37085664403",
        "aff": "engineering department, Aarhus University; engineering department, Aarhus University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561914/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16431733358184065642&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Aarhus University",
        "aff_unique_dep": "Engineering Department",
        "aff_unique_url": "https://www.au.dk",
        "aff_unique_abbr": "AU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9561454",
        "title": "Model Identification of a Small Fully-Actuated Aquatic Surface Vehicle Using a Long Short-Term Memory Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "A long short-term memory neural network is used to provide a system model that captures the temporal-dynamics of a holonomic, fully-actuated aquatic surface vehicle. As is true in many fields, new developments in robotics often are made in simulation first before being applied to real systems. To simulate an aquatic or aerial robot, a dynamic system model of the robot is required. The more representative the dynamic model is of the real robot, the smaller the simulation-to-reality gap becomes. The performance of the neural network is compared against a classical parametric model, where coefficients of the parametric model were identified using the same data that was used to train the neural network. The results show that the neural network consistently outperforms the classical parametric model and significantly reduces the error between real velocities and estimated velocities. The neural network also demonstrated the ability to capture complex hydrodynamic effects that were not captured in the parametric model. In addition to the performance improvements, the neural network method can be easily adapted to similarly actuated aquatic vehicles by simply retraining, whereas the classical approach would require manual selection of new equation terms. The neural network model that was created has been used in a vehicle simulation and is presently being used as a research tool.",
        "primary_area": "",
        "author": "Marin Dimitrov;Keir Groves;David Howard;Barry Lennox;Marin Dimitrov;Keir Groves;David Howard;Barry Lennox",
        "authorids": "/37088691357;/37086497192;/37089393301;/37299751200;/37088691357;/37086497192;/37089393301;/37299751200",
        "aff": "Department of Electrical and Electronic Engineering, University of Manchester, UK; Department of Electrical and Electronic Engineering, University of Manchester, UK; Robotics and Autonomous Systems Group, Data61, CSIRO, Australia; Department of Electrical and Electronic Engineering, University of Manchester, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561454/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1512946858212967458&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Manchester;CSIRO",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering;Robotics and Autonomous Systems Group, Data61",
        "aff_unique_url": "https://www.manchester.ac.uk;https://www.csiro.au",
        "aff_unique_abbr": "UoM;CSIRO",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United Kingdom;Australia"
    },
    {
        "id": "9561298",
        "title": "Model Predictive Actor-Critic: Accelerating Robot Skill Acquisition with Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Substantial advancements to model-based reinforcement learning algorithms have been impeded by the model-bias induced by the collected data, which generally hurts performance. Meanwhile, their inherent sample efficiency warrants utility for most robot applications, limiting potential damage to the robot and its environment during training. Inspired by information theoretic model predictive control and advances in deep reinforcement learning, we introduce Model Predictive Actor-Critic (MoPAC)\u2020, a hybrid model-based/model-free method that combines model predictive rollouts with policy optimization as to mitigate model bias. MoPAC leverages optimal trajectories to guide policy learning, but explores via its model-free method, allowing the algorithm to learn more expressive dynamics models. This combination guarantees optimal skill learning up to an approximation error and reduces necessary physical interaction with the environment, making it suitable for real-robot training. We provide extensive results showcasing how our proposed method generally outperforms current state-of-the-art and conclude by evaluating MoPAC for learning on a physical robotic hand performing valve rotation and finger gaiting\u2013a task that requires grasping, manipulation, and then regrasping of an object.",
        "primary_area": "",
        "author": "Andrew S. Morgan;Daljeet Nandha;Georgia Chalvatzaki;Carlo D\u2019Eramo;Aaron M. Dollar;Jan Peters;Andrew S. Morgan;Daljeet Nandha;Georgia Chalvatzaki;Carlo D\u2019Eramo;Aaron M. Dollar;Jan Peters",
        "authorids": "/37086455182;/37088999521;/37085353493;/37086270695;/37604732600;/37533077600;/37086455182;/37088999521;/37085353493;/37086270695;/37604732600;/37533077600",
        "aff": "Department of Mechanical Engineering & Materials Science, Yale University, USA; Intelligent Autonomous Systems, Technische Universit\u00e4t, Darmstadt, Germany; Intelligent Autonomous Systems, Technische Universit\u00e4t, Darmstadt, Germany; Intelligent Autonomous Systems, Technische Universit\u00e4t, Darmstadt, Germany; Department of Mechanical Engineering & Materials Science, Yale University, USA; Intelligent Autonomous Systems, Technische Universit\u00e4t, Darmstadt, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561298/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6403653946569400429&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;0;1",
        "aff_unique_norm": "Yale University;Technische Universit\u00e4t Darmstadt",
        "aff_unique_dep": "Department of Mechanical Engineering & Materials Science;Intelligent Autonomous Systems",
        "aff_unique_url": "https://www.yale.edu;https://www.tu-darmstadt.de",
        "aff_unique_abbr": "Yale;TUD",
        "aff_campus_unique_index": "1;1;1;1",
        "aff_campus_unique": ";Darmstadt",
        "aff_country_unique_index": "0;1;1;1;0;1",
        "aff_country_unique": "United States;Germany"
    },
    {
        "id": "9561054",
        "title": "Model Predictive Control for Cooperative Hunting in Obstacle Rich and Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the cooperative hunting problem, where a group of agents encircle a target while avoiding collisions with each other and with obstacles in the environment. The paper deals with obstacle rich environments and dynamic (moving obstacle) environments by formulating the problem as both a control problem and a planning problem. A model predictive control (MPC) method is proposed which integrates a multi-agent planner with the cooperative hunting objective while also accounting for UAV dynamics. The effectiveness of the proposed method is verified through a comparative analysis with optimal reciprocal collision avoidance (ORCA), and then validated through experiments with quadrotor UAVs. Using the proposed method, agents no longer get stuck in local minima for obstacle rich environments and capture the target faster with shorter trajectories in moving obstacle environments.",
        "primary_area": "",
        "author": "Jacky Liao;Che Liu;Hugh H.T. Liu;Jacky Liao;Che Liu;Hugh H.T. Liu",
        "authorids": "/37089001760;/37088998561;/37279508300;/37089001760;/37088998561;/37279508300",
        "aff": "Flight Systems and Control Lab, Institute of Aerospace Studies, University of Toronto, North York, Canada; Flight Systems and Control Lab, Institute of Aerospace Studies, University of Toronto, North York, Canada; Flight Systems and Control Lab, Institute of Aerospace Studies, University of Toronto, North York, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561054/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13901431851964402694&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Institute of Aerospace Studies",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "North York",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561304",
        "title": "Model Predictive Control for Dynamic Quadrotor Bearing Formations",
        "track": "main",
        "status": "Poster",
        "abstract": "Formation control of multi-agent systems deals with groups of robots forming specific spatial geometries. Combined with the advancements of unmanned aerial vehicles (UAVs) in the past decade, formation control may potentially be applied to tasks such as search-and-rescue, surveillance, even collaborative manipulation. A key challenge is the decentralization of formation control, where each agent behaves independently using onboard sensors and computation, improving the scaleability and robustness of the system.This paper proposes a decentralized controller based on model predictive control (MPC), for the control of formations of quadrotor UAVs defined by inter-agent bearings. The use of MPC allows the controller to account for attitude kinematics, improving upon the results of existing bearing formation control methods based on rigidity and visual servoing approaches, which typically only consider the quadrotor as a single or double integrator. Furthermore the near-optimality of MPC permits a more optimal use of the quadrotors dynamic capabilities for faster maneuvering. Extensive simulations are performed to demonstrate the improved transient formation convergence and fast maneuvering permitted by this controller. Experiments show that it is indeed a real-time feasible solution for bearing formation control.",
        "primary_area": "",
        "author": "Julian Erskine;Rafael Balderas-Hill;Isabelle Fantoni;Abdelhamid Chriette;Julian Erskine;Rafael Balderas-Hill;Isabelle Fantoni;Abdelhamid Chriette",
        "authorids": "/37086938233;/37088997667;/37301364100;/37300806500;/37086938233;/37088997667;/37301364100;/37300806500",
        "aff": "\u00c9cole Centrale de Nantes, Laboratoire des Sciences du Num\u00e9rique de Nantes (LS2N), UMR CNRS 6004, Nantes, France; \u00c9cole Centrale de Nantes, Laboratoire des Sciences du Num\u00e9rique de Nantes (LS2N), UMR CNRS 6004, Nantes, France; LS2N, Centre National de la Recherche Scientifique, France; \u00c9cole Centrale de Nantes, Laboratoire des Sciences du Num\u00e9rique de Nantes (LS2N), UMR CNRS 6004, Nantes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561304/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13472661151858450224&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "\u00c9cole Centrale de Nantes;Centre National de la Recherche Scientifique",
        "aff_unique_dep": "Laboratoire des Sciences du Num\u00e9rique de Nantes (LS2N);LS2N",
        "aff_unique_url": "https://www.ecn.fr;https://www.cnrs.fr",
        "aff_unique_abbr": "ECN;CNRS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Nantes;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561682",
        "title": "Model Predictive Control of Nonlinear Latent Force Models: A Scenario-Based Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Control of nonlinear uncertain systems is a common challenge in the robotics field. Nonlinear latent force models, which incorporate latent uncertainty characterized as Gaussian processes, carry the promise of representing such systems effectively, and we focus on the control design for them in this work. To enable the design, we adopt the state-space representation of a Gaussian process to recast the nonlinear latent force model and thus build the ability to predict the future state and uncertainty concurrently. Using this feature, a stochastic model predictive control problem is formulated. To derive a computational algorithm for the problem, we use the scenario-based approach to formulate a deterministic approximation of the stochastic optimization. We evaluate the resultant scenario-based model predictive control approach through a simulation study based on motion planning of an autonomous vehicle, which shows much effectiveness. The proposed approach can find prospective use in various other robotics applications.",
        "primary_area": "",
        "author": "Thomas Woodruff;Iman Askari;Guanghui Wang;Huazhen Fang;Thomas Woodruff;Iman Askari;Guanghui Wang;Huazhen Fang",
        "authorids": "/37088999387;/37088922707;/37085999106;/38236507600;/37088999387;/37088922707;/37085999106;/38236507600",
        "aff": "Department of Electrical Engineering and Computer Science, University of Kansas, Lawrence, KS, USA; Department of Mechanical Engineering, University of Kansas, Lawrence, KS, USA; Department of Electrical Engineering and Computer Science, University of Kansas, Lawrence, KS, USA; Department of Mechanical Engineering, University of Kansas, Lawrence, KS, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561682/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:dkcxyv6-XU4J:scholar.google.com/&scioq=Model+Predictive+Control+of+Nonlinear+Latent+Force+Models:+A+Scenario-Based+Approach&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Kansas",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.ku.edu",
        "aff_unique_abbr": "KU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lawrence",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562066",
        "title": "Model Predictive Robot-Environment Interaction Control for Mobile Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern, torque-controlled service robots can regulate contact forces when interacting with their environment. Model Predictive Control (MPC) is a powerful method to solve the underlying control problem, allowing to plan for whole-body motions while including different constraints imposed by the robot dynamics or its environment. However, an accurate model of the robot-environment is needed to achieve a satisfying closed-loop performance. Currently, this necessity undermines the performance and generality of MPC in manipulation tasks. In this work, we combine an MPC-based whole-body controller with two adaptive schemes, derived from online system identification and adaptive control. As a result, we enable a general mobile manipulator to interact with unknown environments, without any need for re-tuning parameters or pre-modeling the interacting objects. In combination with the MPC controller, the two adaptive approaches are validated and benchmarked with a ball-balancing manipulator in door opening and object lifting tasks.",
        "primary_area": "",
        "author": "Maria Vittoria Minniti;Ruben Grandia;Kevin F\u00e4h;Farbod Farshidian;Marco Hutter;Maria Vittoria Minniti;Ruben Grandia;Kevin F\u00e4h;Farbod Farshidian;Marco Hutter",
        "authorids": "/37086923041;/37086355336;/37088998765;/37085428006;/37545251000;/37086923041;/37086355336;/37088998765;/37085428006;/37545251000",
        "aff": "Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland; Robotic Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562066/",
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17261445106088877042&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Robotic Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561091",
        "title": "Model and Validation of a Highly Extensible and Tough Actuator based on a Ballooning Membrane",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots are known for their ability to comply and having superior extensibility. However, one of the limitations of most of these robots is that they can stand only a limited amount of load before buckling, and they feature a non-negligible initial height. Hybrid soft-rigid actuators seem to offer a trade-off between compliance and the amount of load they can withstand, but only a few simple models have been proposed to describe the behavior of these actuators. In this paper, we propose a design, model and experimental validation of a soft actuator based on stackable Hyperelastic Ballooning Membranes (HBMA). This actuator shows an extensibility higher than 179%, as well as an ability to stand more than 20 times its own weight at a pressure as low as 35 kPa. Two models, giving the dynamic behavior of the HBMA in terms of displacement and pressure, have been derived from different hyperelastic models (Neo-Hookean and Mooney-Rivlin) and compared in terms of accuracy and robustness. Finally, an example of a hybrid soft-rigid continuum ballooning robot built with HBMAs is presented and characterized experimentally.",
        "primary_area": "",
        "author": "Nicolas Herzig;Joanna Jones;Eduardo Perez-Guagnelli;Dana D. Damian;Nicolas Herzig;Joanna Jones;Eduardo Perez-Guagnelli;Dana D. Damian",
        "authorids": "/37085514629;/37088198042;/37086453980;/37587456200;/37085514629;/37088198042;/37086453980;/37587456200",
        "aff": "Department of Engineering and Design, School of Engineering and Informatics, University of Sussex, Brighton, United Kingdom; Department of Automatic Control and Systems Engineering, the University of Sheffield, Sheffield, United Kingdom; Department of Automatic Control and Systems Engineering, the University of Sheffield, Sheffield, United Kingdom; Department of Automatic Control and Systems Engineering, the University of Sheffield, Sheffield, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561091/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3444643148521881443&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Sussex;University of Sheffield",
        "aff_unique_dep": "Department of Engineering and Design;Department of Automatic Control and Systems Engineering",
        "aff_unique_url": "https://www.sussex.ac.uk;https://www.sheffield.ac.uk",
        "aff_unique_abbr": "Sussex;Sheffield",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Brighton;Sheffield",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561727",
        "title": "Model based evaluation of human and lower-limb exoskeleton interaction during sit to stand motion",
        "track": "main",
        "status": "Poster",
        "abstract": "The interaction between an exoskeleton and its human user is complex, and needs to conform to various requirements related to safety, comfort and adaptability. It is however impractical to test a large number of prototype variations against a large number of user variations, especially in the initial design and testing phases. Model based methods can help at this design stage by providing a virtual testbed. In this study, we develop a MATLAB-based toolbox that can simulate the interaction between a human model and a lower limb exoskeleton during the sit to stand motion. We present results for different scales of human users as well as variation in levels of exoskeleton assistance. Our results show that large reductions in human joint torques upto 57Nm are possible, while also transmitting large forces upto 300N to the human model. Additionally, by varying the human body sizes by 15% we found that the interaction forces also changed by as much as 29.2%. Therefore, careful consideration of the human user and its limitation should be made in the exoskeleton design and concept phases.",
        "primary_area": "",
        "author": "Joel Bottin-Noonan;Manish Sreenivasa;Joel Bottin-Noonan;Manish Sreenivasa",
        "authorids": "/37088998054;/37542740000;/37088998054;/37542740000",
        "aff": "School of Mechanical, Mechatronic, Materials and Biomedical Engineering, Faculty of Engineering and Information Sciences, University of Wollongong, Australia; School of Mechanical, Mechatronic, Materials and Biomedical Engineering, Faculty of Engineering and Information Sciences, University of Wollongong, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561727/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14978091006688518172&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Wollongong",
        "aff_unique_dep": "School of Mechanical, Mechatronic, Materials and Biomedical Engineering",
        "aff_unique_url": "https://www.uow.edu.au",
        "aff_unique_abbr": "UOW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9561250",
        "title": "Model-Dependent Prosthesis Control with Interaction Force Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Current lower-limb prosthesis control methods are primarily model-independent \u2014 lacking formal guarantees of stability, relying largely on heuristic tuning parameters for good performance, and neglecting use of the natural dynamics of the system. Model-dependence for prosthesis controllers is difficult to achieve due to the unknown human dynamics. We build upon previous work which synthesized provably stable prosthesis walking through the use of rapidly exponentially stabilizing control Lyapunov functions (RES-CLFs). This paper utilizes RES-CLFs together with force estimation to construct model-based optimization-based controllers for the prosthesis. These are experimentally realized on hardware with onboard sensing and computation. This hardware demonstration has formal guarantees of stability, utilizes the natural dynamics of the system, and achieves superior tracking to other prosthesis trajectory tracking control methods.",
        "primary_area": "",
        "author": "Rachel Gehlhar;Aaron D. Ames;Rachel Gehlhar;Aaron D. Ames",
        "authorids": "/37088435299;/37300877900;/37088435299;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561250/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2244957112963382699&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561989",
        "title": "Model-Free Reinforcement Learning for Stochastic Games with Linear Temporal Logic Objectives",
        "track": "main",
        "status": "Poster",
        "abstract": "We study synthesis of control strategies from linear temporal logic (LTL) objectives in unknown environments. We model this problem as a turn-based zero-sum stochastic game between the controller and the environment, where the transition probabilities and the model topology are fully unknown. The winning condition for the controller in this game is the satisfaction of the given LTL specification, which can be captured by the acceptance condition of a deterministic Rabin automaton (DRA) directly derived from the LTL specification. We introduce a model-free reinforcement learning (RL) methodology to find a strategy that maximizes the probability of satisfying a given LTL specification when the Rabin condition of the derived DRA has a single accepting pair. We then generalize this approach to any LTL formulas, for which the Rabin accepting condition may have more than one pairs, providing a lower bound on the satisfaction probability. Finally, we show applicability of our RL method on two planning case studies.",
        "primary_area": "",
        "author": "Alper Kamil Bozkurt;Yu Wang;Michael M. Zavlanos;Miroslav Pajic;Alper Kamil Bozkurt;Yu Wang;Michael M. Zavlanos;Miroslav Pajic",
        "authorids": "/37088507578;/37085560879;/37300758300;/37294788600;/37088507578;/37085560879;/37300758300;/37294788600",
        "aff": "Duke University, Durham, NC, USA; Duke University, Durham, NC, USA; Duke University, Durham, NC, USA; Duke University, Durham, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561989/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9724550477109630661&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Durham",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561624",
        "title": "Model-Predictive Control of Blood Suction for Surgical Hemostasis using Differentiable Fluid Simulations",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent developments in surgical robotics have led to new advancements in the automation of surgical sub-tasks such as suturing, soft tissue manipulation, tissue tensioning and cutting. However, integration of dynamics to optimize these control policies for the variety of scenes encountered in surgery remains unsolved. Towards this effort, we investigate the integration of differentiable fluid dynamics to optimizing a suction tool\u2019s trajectory to clear the surgical field from blood as fast as possible. The fully differentiable fluid dynamics is integrated with a novel suction model for effective model predictive control of the tool. The differentiability of the fluid model is crucial because we utilize the gradients of the fluid states with respect to the suction tool position to optimize the trajectory. Through a series of experiments, we demonstrate how, by incorporating fluid models, the trajectories generated by our method can perform as good as or better than handcrafted human-intuitive suction policies. We also show that our method is adaptable and can work in different cavity conditions while using a single handcrafted strategy fails.",
        "primary_area": "",
        "author": "Jingbin Huang;Fei Liu;Florian Richter;Michael C. Yip;Jingbin Huang;Fei Liu;Florian Richter;Michael C. Yip",
        "authorids": "/37088760991;/37088689503;/37086936752;/37085382768;/37088760991;/37088689503;/37086936752;/37085382768",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561624/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12771714280793579460&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560842",
        "title": "Model-based Design and Digital Implementation to Improve Control of the da Vinci Research Kit Telerobotic Surgical System",
        "track": "main",
        "status": "Poster",
        "abstract": "The da Vinci Research Kit (dVRK) was introduced in 2012 to provide an affordable, open-source platform for research in robotic minimally-invasive surgery. It provides access to all levels of control but, until now, has relied on an analog controller for the motor current, which cannot easily be customized to improve performance. This paper aims to implement the low-level control digitally and to improve the overall control performance. To enable model-based controller design, the system is first identified using measurements provided by the encoders and internal electronics. The digital current controller is then implemented on the existing field programmable gate array (FPGA). Experiments demonstrate that the new digital current controller yields superior performance compared to the original analog design. In addition, the identified system model is used to design an improved position controller that is also implemented on the FPGA and provides better trajectory tracking than the position controller currently implemented on the control PC. The comparison between simulation and measurement, for both the current and position control, verifies the validity of the model based on the system identification, enabling utilization for future adaptations. The improved low-level control enlarges the possibilities for more accurate operation and the achieved digital implementation enables researchers worldwide to easily adapt the low-level control in future versions of the dVRK.",
        "primary_area": "",
        "author": "Stefan Kohlgrueber;Yeongmi Kim;Peter Kazanzides;Stefan Kohlgrueber;Yeongmi Kim;Peter Kazanzides",
        "authorids": "/37089000768;/37088998897;/37375173500;/37089000768;/37088998897;/37375173500",
        "aff": "Department of Mechatronics, MCI, University of Applied Sciences, Innsbruck, Austria; Department of Mechatronics, MCI, University of Applied Sciences, Innsbruck, Austria; Dept. of Computer Science, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560842/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9047208483921738204&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "University of Applied Sciences;Johns Hopkins University",
        "aff_unique_dep": "Department of Mechatronics;Dept. of Computer Science",
        "aff_unique_url": "https://www.mci.edu;https://www.jhu.edu",
        "aff_unique_abbr": "MCI;JHU",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Innsbruck;Baltimore",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Austria;United States"
    },
    {
        "id": "9561942",
        "title": "Model-based Domain Randomization of Dynamics System with Deep Bayesian Locally Linear Embedding",
        "track": "main",
        "status": "Poster",
        "abstract": "Domain randomization (DR) is a powerful tool to make a policy robust to the uncertainty of dynamics caused by unobservable environmental parameters. Conventional DR has adopted model-free reinforcement learning as a policy optimizer. However, the model-free methods in DR demand high time-complexity due to the randomization process where the environment is extremely changed. In this paper, we introduce model-based dynamics and policy learning for efficient DR. A Bayesian model of locally linear embedding is designed to fit the stochastic dynamics in DR. By virtue of locally linear dynamics, model-based optimal control is substituted for the policy optimization. Unlike previous works, our proposed Bayesian model with a MNIW prior allows the locally linear embedding to capture the dynamics in DR as a stochastic model. We show that a training method that combines variational and adversarial approaches is adequate for Bayesian embedding. Finally, a model-based controller is designed on our Bayesian locally linear embedding, and it shows better performance in DR environments compared with the non-Bayesian model of locally linear embedding.",
        "primary_area": "",
        "author": "J. Hyeon Park;Sungyong Park;H. Jin Kim;J. Hyeon Park;Sungyong Park;H. Jin Kim",
        "authorids": "/37085614810;/37088569460;/37599626400;/37085614810;/37088569460;/37599626400",
        "aff": "Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, Korea; Department of Mechanical and Aerospace Engineering, Seoul National University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561942/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12219369225107214053&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561253",
        "title": "Model-based Reinforcement Learning with Provable Safety Guarantees via Control Barrier Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety is a critical property in applications including robotics, transportation, and energy. Safety is especially challenging in reinforcement learning (RL) settings, in which uncertainty of the system dynamics may cause safety violations during exploration. Control Barrier Functions (CBFs), which enforce safety by constraining the control actions at each time step, are a promising approach for safety-critical control. This technique has been applied to ensure the safety of model-free RL, however, it has not been integrated into model-based RL. In this paper, we propose Uncertainty-Tolerant Control Barrier Functions (UTCBFs), a new class of CBFs to incorporate model uncertainty and provide provable safety guarantees with desired probability. Furthermore, we introduce an algorithm for model-based RL to guarantee safety by integrating CBFs with gradient-based policy search. Our approach is verified through a numerical study of a cart-pole system and an inverted pendulum system with comparison to state-of-the-art RL algorithms.",
        "primary_area": "",
        "author": "Hongchao Zhang;Zhouchi Li;Andrew Clark;Hongchao Zhang;Zhouchi Li;Andrew Clark",
        "authorids": "/37088757467;/37086958540;/37403462800;/37088757467;/37086958540;/37403462800",
        "aff": "Department of Electrical and Computer Engineering, Worcester Polytechnic Inistitute, Worcester, MA, USA; Department of Electrical and Computer Engineering, Worcester Polytechnic Inistitute, Worcester, MA, USA; Department of Electrical and Computer Engineering, Worcester Polytechnic Inistitute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561253/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10188303627355621727&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562098",
        "title": "Modeling Affect-based Intrinsic Rewards for Exploration and Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Positive affect has been linked to increased interest, curiosity and satisfaction in human learning. In reinforcement learning, extrinsic rewards are often sparse and difficult to define, intrinsically motivated learning can help address these challenges. We argue that positive affect is an important intrinsic reward that effectively helps drive exploration that is useful in gathering experiences. We present a novel approach leveraging a task-independent reward function trained on spontaneous smile behavior that reflects the intrinsic reward of positive affect. To evaluate our approach we trained several downstream computer vision tasks on data collected with our policy and several baseline methods. We show that the policy based on our affective rewards successfully increases the duration of episodes, the area explored and reduces collisions. The impact is the increased speed of learning for several downstream computer vision tasks.",
        "primary_area": "",
        "author": "Dean Zadok;Daniel McDuff;Ashish Kapoor;Dean Zadok;Daniel McDuff;Ashish Kapoor",
        "authorids": "/37087246375;/37541663500;/37397699500;/37087246375;/37541663500;/37397699500",
        "aff": "Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562098/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15329348531287835025&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "Microsoft Research",
        "aff_unique_url": "https://www.microsoft.com/en-us/research",
        "aff_unique_abbr": "MSR",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Redmond",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561882",
        "title": "Modeling and Control of an Untethered Magnetic Gripper",
        "track": "main",
        "status": "Poster",
        "abstract": "Small-scale robots have great potential in minimally invasive surgery (MIS). In this paper, we propose an untethered magnetic gripper with small scale and build a double-magnet model for it. The gripper is 4.3mm long and its maximum width is 4mm. It contains a spindle and two magnets, which can achieve precise control of orientation, position and open angle with external magnetic driven field. As a result, it can perform operations such as transporting medicines in confined and constrained environments. Modeling and analysis of the magnetic gripper have been carried out. Relationship between the open angle and external magnetic field has been established. Kinematics model of the gripper has been built. A 3-axis Helmholtz-Maxwell coil system has been established to generate the magnetic field, in which orientation and open angle can be controlled with uniform magnetic field while position can be controlled with gradient field. The proposed gripper have been validated with phantom experiments. An opened angle control error of 0.63\u00b0 and direction control error of 1.1\u00b0 have been obtained.",
        "primary_area": "",
        "author": "Yunxuan Mao;Sishen Yuan;Jiaole Wang;Jinmin Zhang;Shuang Song;Yunxuan Mao;Sishen Yuan;Jiaole Wang;Jinmin Zhang;Shuang Song",
        "authorids": "/37087245838;/37087245695;/37085418780;/37089002280;/37400326000;/37087245838;/37087245695;/37085418780;/37089002280;/37400326000",
        "aff": "School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China; School of Mechanical Engineering and Automation, Harbin Institute of Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561882/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18382202339832060962&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology;Chinese University of Hong Kong",
        "aff_unique_dep": "School of Mechanical Engineering and Automation;Department of Electronic Engineering",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "HIT;CUHK",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Shenzhen;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560802",
        "title": "Modeling and Optimal Control for Rope-Assisted Rappelling Maneuvers",
        "track": "main",
        "status": "Poster",
        "abstract": "Envisioning the employment of rope-assisted humanoid robots to reduce human intervention for operations in the heights, this preliminary work addresses the modeling and motion planning problems for a rope-assisted bipedal robot. The mathematical features of this system outnumber the ones of typical humanoid robots, including: under-actuation of the floating-base joints, the rope pulling effect and the passive connection between the robot body and the rope master-point. These characteristics render the study of a rope-assisted bipedal robot both fascinating and unexplored, raising motion planning challenges when attempting to plan dynamic suspended maneuvers, as rappelling. To this end, we first introduce a template three-mass model of a bipedal robot connected through passive joints to an extensible rope, which is in turn modeled as a two-mass body. Based on this, a family of optimal control problems is presented to plan rappelling maneuvers.",
        "primary_area": "",
        "author": "Enrico Mingo Hoffman;Matteo Parigi Polverini;Arturo Laurenzi;Nikos G. Tsagarakis;Enrico Mingo Hoffman;Matteo Parigi Polverini;Arturo Laurenzi;Nikos G. Tsagarakis",
        "authorids": "/37085377101;/37086601087;/37086141170;/37295830800;/37085377101;/37086601087;/37086141170;/37295830800",
        "aff": "Humanoids and Human Centered Mechatronics (HHCM) Lab, Istituto Italiano di Tecnologia, Genoa, Italy; Humanoids and Human Centered Mechatronics (HHCM) Lab, Istituto Italiano di Tecnologia, Genoa, Italy; Humanoids and Human Centered Mechatronics (HHCM) Lab, Istituto Italiano di Tecnologia, Genoa, Italy; Humanoids and Human Centered Mechatronics (HHCM) Lab, Istituto Italiano di Tecnologia, Genoa, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560802/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2058498358482037359&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Humanoids and Human Centered Mechatronics (HHCM) Lab",
        "aff_unique_url": "https://www.iit.it",
        "aff_unique_abbr": "IIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Genoa",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9561950",
        "title": "Modeling and Simulation of Running Expansion with Trunk and Pelvic Rotation Assist Suit",
        "track": "main",
        "status": "Poster",
        "abstract": "Human running motion is a complex motion that not only based on the movement of legs but also needs the entire body to participate in. Therefore, we focused on the upper body, designed a trunk and pelvic rotation assist suit to apply an external force on the chest and pelvis for assisting the running motion, changing the energy flow between the upper and lower body to improve the running efficiency. However, human motion is very complicated and difficult to analyze, it is hard to explore the specific effect of the external force which is provided by the rotation assist suit on human motion. In this paper, we proposed an advanced spring-loaded inverted pendulum model for simulating the human running motion in natural running status and expanded running status in which the motion is expanded by wearing the trunk and pelvic rotation assist suit, parametrically represent the changes of human due to the intervention of the external force, and discuss the effect of the external assistant force on the human running motion.",
        "primary_area": "",
        "author": "Hongyuan Ren;Takayuki Tanaka;Akihiko Murai;Hongyuan Ren;Takayuki Tanaka;Akihiko Murai",
        "authorids": "/37088998491;/37277533100;/37274016000;/37088998491;/37277533100;/37274016000",
        "aff": "Graduate School of Information Science and Technology, Hokkaido University, Hokkaido, Japan; Graduate School of Information Science and Technology, Hokkaido University, Hokkaido, Japan; AIST / JST, PRESTO, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561950/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=654984052139105949&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Hokkaido University;AIST",
        "aff_unique_dep": "Graduate School of Information Science and Technology;PRESTO",
        "aff_unique_url": "https://www.hokudai.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "Hokkaido U.;AIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hokkaido;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9562099",
        "title": "Modelling and optimisation of a mechanism-based metamaterial for a wrist flexion-extension assistive device",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we present a methodology for optimising the design of a metamaterial structure with one degree of freedom that is able to simultaneously bend and stretch. The structure is intended for assisting flexion-extension of the wrist joint. The metamaterial is comprised of serially connected, individually designed cells. The design parameters can be chosen to optimally fit a desired planar curve such as the curvature of the skin on a plane normal to the flexion/extension axis of the wrist joint. A tool for the optimised design is described and the experimental validation of the output is conducted, to show the ability of the mechanism to conform to a 2D curve, also exhibiting a change in length, which is desirable for reducing sliding and shear on the skin. The design tool allows the generation of metamaterials optimised for a multitude of other applications where actuated mechanisms must be worn by a user for rehabilitation or assistance purposes.",
        "primary_area": "",
        "author": "Suhas Raghavendra Kulkarni;Bernardo Noronha;Domenico Campolo;Dino Accoto;Suhas Raghavendra Kulkarni;Bernardo Noronha;Domenico Campolo;Dino Accoto",
        "authorids": "/37088533459;/37086172357;/37329581600;/37328826100;/37088533459;/37086172357;/37329581600;/37328826100",
        "aff": "Robotics Research Centre, School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; Robotics Research Centre, School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; Robotics Research Centre, School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore; Robotics Research Centre, School of Mechanical and Aerospace Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562099/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13627487215997182816&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nanyang Technological University",
        "aff_unique_dep": "School of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ntu.edu.sg",
        "aff_unique_abbr": "NTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Singapore",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9561667",
        "title": "Momentum Observer-Based Collision Detection Using LSTM for Model Uncertainty Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots begin to collaborate with people in real life, safety needs to be rigorously ensured to reliably employ robots nearby. In addition to collision prevention algorithms, studies are being actively conducted on collision handling methods. Momentum Observer (MOB) was developed to estimate disturbance torque without using joint acceleration. However, the estimated disturbance from MOB contains not only the applied external torque but also model uncertainty such as friction and modeling error due to imprecise system identification. Our proposed method handles this problem by learning the model uncertainty with Long Short-Term Memory (LSTM) and thereby estimates the purely applied external torque with only proprioceptive sensors. The proposed method can be applied even when the information on the robot model is not available. The experiments using a real robot show that the external torque can be estimated and collisions can be detected accordingly even in a limited situation where a precise dynamics model and friction model are not available.",
        "primary_area": "",
        "author": "Daegyu Lim;Donghyeon Kim;Jaeheung Park;Daegyu Lim;Donghyeon Kim;Jaeheung Park",
        "authorids": "/37086934345;/37087324205;/37281014000;/37086934345;/37087324205;/37281014000",
        "aff": "Department of Intelligence and Information, Seoul National University, Seoul, Republic of Korea; Department of Intelligence and Information, Seoul National University, Seoul, Republic of Korea; Advanced Institutes of Convergence Technology, Suwon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561667/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1321797531639443449&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Seoul National University;Advanced Institutes of Convergence Technology",
        "aff_unique_dep": "Department of Intelligence and Information;",
        "aff_unique_url": "https://www.snu.ac.kr;",
        "aff_unique_abbr": "SNU;",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Seoul;Suwon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561820",
        "title": "MonStereo: When Monocular and Stereo Meet at the Tail of 3D Human Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Monocular and stereo visions are cost-effective solutions for 3D human localization in the context of self-driving cars or social robots. However, they are usually developed independently and have their respective strengths and limitations. We propose a novel unified learning framework that leverages the strengths of both monocular and stereo cues for 3D human localization. Our method jointly (i) associates humans in left- right images, (ii) deals with occluded and distant cases in stereo settings by relying on the robustness of monocular cues, and (iii) tackles the intrinsic ambiguity of monocular perspective projection by exploiting prior knowledge of the human height distribution. We specifically evaluate outliers as well as challenging instances, such as occluded and far-away pedestrians, by analyzing the entire error distribution and by estimating calibrated confidence intervals. Finally, we critically review the official KITTI 3D metrics and propose a practical 3D localization metric tailored for humans.",
        "primary_area": "",
        "author": "Lorenzo Bertoni;Sven Kreiss;Taylor Mordan;Alexandre Alahi;Lorenzo Bertoni;Sven Kreiss;Taylor Mordan;Alexandre Alahi",
        "authorids": "/37087234203;/37086935785;/37086229048;/37601323900;/37087234203;/37086935785;/37086229048;/37601323900",
        "aff": "Visual Intelligence for Transportation (VITA) lab, EPFL, Switzerland; Visual Intelligence for Transportation (VITA) lab, EPFL, Switzerland; Visual Intelligence for Transportation (VITA) lab, EPFL, Switzerland; Visual Intelligence for Transportation (VITA) lab, EPFL, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561820/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15092900339039190329&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "EPFL",
        "aff_unique_dep": "Visual Intelligence for Transportation (VITA) lab",
        "aff_unique_url": "https://www.epfl.ch",
        "aff_unique_abbr": "EPFL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561085",
        "title": "Monitoring Fatigue-Induced Changes in Performance during Robot-Mediated Dynamic Movement",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic exoskeletons are promising devices capable of both administering therapeutic exercises and assessing human movement quality. Although assessing fatigue is crucial to informing effective strategies for rehabilitation, existing metrics for evaluating fatigue during robot-mediated exercise remain underdeveloped. Current techniques focus on monitoring localized muscle fatigue, but do not consider the complex relationship between changes in muscle activity and associated alterations in joint motion during dynamic movement. In this work, we propose a system-based monitoring paradigm for tracking fatigue-induced changes in performance. The method uses a time-series model to approximate the dynamics of a human-exoskeleton system by mapping muscle activity to movement variables. An index of performance is calculated from modeling errors to continuously track changes in this dynamic relationship over time. Results showed that the index effectively captured fatigue-induced degradation in performance over time during an exoskeleton-administered resistive exercise. The index outperformed a traditional indicator of fatigue that is typically used during robotic intervention, suggesting the proposed approach has the potential to improve fatigue monitoring efforts during robot-aided movement training.",
        "primary_area": "",
        "author": "Kaci E. Madden;Dragan Djurdjanovic;Ashish D. Deshpande;Kaci E. Madden;Dragan Djurdjanovic;Ashish D. Deshpande",
        "authorids": "/37085715886;/37369924000;/37405479700;/37085715886;/37369924000;/37405479700",
        "aff": "Department of Mechanical Engineering, The University of Texas at Austin, Austin, TX, USA; Department of Mechanical Engineering, The University of Texas at Austin, Austin, TX, USA; Department of Mechanical Engineering, The University of Texas at Austin, Austin, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561085/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:DGLS7wloArMJ:scholar.google.com/&scioq=Monitoring+Fatigue-Induced+Changes+in+Performance+during+Robot-Mediated+Dynamic+Movement&hl=en&as_sdt=0,5",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561211",
        "title": "MonoSOD: Monocular Salient Object Detection based on Predicted Depth",
        "track": "main",
        "status": "Poster",
        "abstract": "Salient object detection (SOD) can directly improve the performance of tasks like obstacle detection, semantic segmentation and object recognition. Such tasks are important for robotic and other autonomous navigation systems. State-of-the-art SOD methodologies, provide improved performance by incorporating depth information, usually acquired using additional specialized sensors, e.g., RGB-D cameras. This introduces an overhead to the overall cost and flexibility of such systems. Nevertheless, the recent advances of machine learning, have provided models, capable of generating depth map approximations, given a single RGB image. In this work, we propose a novel monocular SOD (MonoSOD) methodology, based on a two-branch CNN autoencoder architecture capable of predicting depth maps and estimating saliency through a trainable refinement scheme. Its application on benchmark datasets, indicates that its performance is comparable to that of state-of-the-art SOD methods relying on RGB-D data. Therefore, it could be considered as a lower-cost alternative of such methods for future applications.",
        "primary_area": "",
        "author": "George Dimas;Panagiota Gatoula;Dimitris K. Iakovidis;George Dimas;Panagiota Gatoula;Dimitris K. Iakovidis",
        "authorids": "/37086239947;/37088911685;/37268912800;/37086239947;/37088911685;/37268912800",
        "aff": "Dept. Of Computer Science and Biomedical Informatics, School of Science, University of Thessaly, Lamia, Greece; Dept. Of Computer Science and Biomedical Informatics, School of Science, University of Thessaly, Lamia, Greece; Dept. Of Computer Science and Biomedical Informatics, School of Science, University of Thessaly, Lamia, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561211/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5951690254237469624&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Thessaly",
        "aff_unique_dep": "Dept. Of Computer Science and Biomedical Informatics",
        "aff_unique_url": "https://www.uth.gr",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Lamia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9561116",
        "title": "MorphEyes: Variable Baseline Stereo For Quadrotor Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Morphable design and depth-based visual control are two upcoming trends leading to advancements in the field of quadrotor autonomy. Stereo-cameras have struck the perfect balance of weight and accuracy of depth estimation but suffer from the problem of depth range being limited and dictated by the baseline chosen at design time. In this paper, we present a framework for quadrotor navigation based on a stereo camera system whose baseline can be adapted on-the-fly. We present a method to calibrate the system at a small number of discrete baselines and interpolate the parameters for the entire baseline range. We present an extensive theoretical analysis of calibration and synchronization errors. We showcase three different applications of such a system for quadrotor navigation: (a) flying through a forest, (b) flying through an unknown shaped/location static/dynamic gap, and (c) accurate 3D pose detection of an independently moving object. We show that our variable baseline system is more accurate and robust in all three scenarios. To our knowledge, this is the first work that applies the concept of morphable design to achieve a variable baseline stereo vision system on a quadrotor.",
        "primary_area": "",
        "author": "Nitin J. Sanket;Chahat Deep Singh;Varun Asthana;Cornelia Ferm\u00fcller;Yiannis Aloimonos;Nitin J. Sanket;Chahat Deep Singh;Varun Asthana;Cornelia Ferm\u00fcller;Yiannis Aloimonos",
        "authorids": "/37086390746;/37086392092;/37088999598;/37269887600;/37282631400;/37086390746;/37086392092;/37088999598;/37269887600;/37282631400",
        "aff": "Perception and Robotics Group, University of Maryland, College Park; Perception and Robotics Group, University of Maryland, College Park; Perception and Robotics Group, University of Maryland, College Park; Perception and Robotics Group, University of Maryland, College Park; Perception and Robotics Group, University of Maryland, College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561116/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7308587237713014969&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "Perception and Robotics Group",
        "aff_unique_url": "https://www.umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560667",
        "title": "Morphologically Adapatative Quad-Rotor Towards Acquiring High-Performance Flight: A Comparative Study and Validation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents our comparative study on how the flight performances of an in-flight morphing quad-rotor are affected by the morph induced inertia variation. A custom-built in-flight morphing quad-rotor was employed in numerical and experimental tests for the study and analysis. In these tests, the quad-rotor is controlled to follow a predefined path and/or to hover in an environment with the constant wind disturbance. Our numerical results indicate that the morphing-size-down quad-rotor exhibits more agile in flight attributed to the compact volume/size, while the big-size one shows more flight stability in a disturbed and windy environment. Compared to regular scaled aerial vehicles whose volume/size changes follow a weight change proportionally, the numerical results reveal that our morphing quad-rotor that changes its volume with identical mass can acquire more merits towards high flight performances. Experimental validations further prove that through adaptatively transform its size in a complex and constrained environment, the in-flight morphing quad-rotor is not only capable of well performing path following tasks when encountering obstacles on the path or nearby the path, but also enhances the flight performance of withstanding external torques by extending its size so as to increase its moment-of-inertia. In summary, our in-flight morphing quad-rotor can acquire higher flight performances by adaptatively morphing when flying in complex environments.",
        "primary_area": "",
        "author": "Na Zhao;Weixin Yang;Cong Peng;Gang Wang;Yantao Shen;Na Zhao;Weixin Yang;Cong Peng;Gang Wang;Yantao Shen",
        "authorids": "/37086001139;/37086437281;/37087050834;/37089399181;/37274462800;/37086001139;/37086437281;/37087050834;/37089399181;/37274462800",
        "aff": "Department of Electrical and Biomedical Engineering, University of Nevada, Reno, Nevada, USA; Department of Electrical and Biomedical Engineering, University of Nevada, Reno, Nevada, USA; Department of Electrical and Biomedical Engineering, University of Nevada, Reno, Nevada, USA; Department of Electrical and Biomedical Engineering, University of Nevada, Reno, Nevada, USA; Department of Electrical and Biomedical Engineering, University of Nevada, Reno, Nevada, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560667/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:uHtNH6vEeVIJ:scholar.google.com/&scioq=Morphologically+Adapatative+Quad-Rotor+Towards+Acquiring+High-Performance+Flight:+A+Comparative+Study+and+Validation&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Nevada, Reno",
        "aff_unique_dep": "Department of Electrical and Biomedical Engineering",
        "aff_unique_url": "https://www.unr.edu",
        "aff_unique_abbr": "UNR",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Reno",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561764",
        "title": "Motion Coupling Analysis for the Decoupled Design of a Two-segment Notched Continuum Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-segment continuum robots, that offer inherent compliance and distal dexterity, are suitable for deployment in minimally invasive surgical procedures. Cable-driven mechanism is commonly used in continuum surgical robots but could lead to inter-segment motion coupling in a multi-segment robot. In this paper, we present a coupled mechanics model for a two-segment notched continuum robot to analyze the coupled deflection in the proximal segment due to the distal cable force. The model has been developed for two different conditions in which the proximal segment is initially bent (general condition) and initially straight (special condition). It allows us to introduce a decoupled design methodology that systematically determines a stiffness parameter in each of the segments, based on the desired coupled bending angle and other design requirements. Using the method, we fabricated a decoupled notched continuum robot and evaluated the model accuracy compared with experimental data with mean errors of 0.57\u00b0 and 0.61\u00b0, respectively for general and special conditions throughout the 90\u00b0 distal segment bending angle. It was also shown in a demonstration in a maxillary sinus phantom that the distal segment was capable of independently perform omnidirectional steering without the proximal segment getting in contact with its surrounding nasal wall.",
        "primary_area": "",
        "author": "Wenhui Zeng;Junyan Yan;Xu Huang;Shing Shin Cheng;Wenhui Zeng;Junyan Yan;Xu Huang;Shing Shin Cheng",
        "authorids": "/37088809100;/37088810297;/37088918983;/37088998635;/37088809100;/37088810297;/37088918983;/37088998635",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong; Shun Hing Institute of Advanced Engineering and Multi-Scale Medical Robotics Center, The Chinese University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561764/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6931395640333425176&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560963",
        "title": "Motion Planning and Feedback Control for Bipedal Robots Riding a Snakeboard",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper formulates a methodology to plan and control flat-terrain motions of an underactuated bipedal robot riding a snakeboard, which is a steerable variant of the skateboard. We use tools from non-holonomic motion planning to study snakeboard gaits and develop feedback control strategies that enable bipedal robots to produce the desired gaits while maintaining balance, regulating the magnitude and direction of the velocity of the snakeboard, achieving sharp turns, and avoiding obstacles.",
        "primary_area": "",
        "author": "Jonathan Anglingdarma;Ayush Agrawal;Joshua Morey;Koushil Sreenath;Jonathan Anglingdarma;Ayush Agrawal;Joshua Morey;Koushil Sreenath",
        "authorids": "/37088998345;/37086081045;/37088997386;/37563179200;/37088998345;/37086081045;/37088997386;/37563179200",
        "aff": "Department of Mechanical Engineering, University of California at Berkeley; Department of Mechanical Engineering, University of California at Berkeley; Department of Mechanical Engineering, University of California at Berkeley; Department of Mechanical Engineering, University of California at Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560963/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3637965526300592798&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561487",
        "title": "Motion-Aware Robotic 3D Ultrasound",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic three-dimensional (3D) ultrasound (US) imaging has been employed to overcome the drawbacks of traditional US examinations, such as high inter-operator variability and lack of repeatability. However, object movement remains a challenge as unexpected motion decreases the quality of the 3D compounding. Furthermore, attempted adjustment of objects, e.g., adjusting limbs to display the entire limb artery tree, is not allowed for conventional robotic US systems. To address this challenge, we propose a vision-based robotic US system that can monitor the object\u2019s motion and automatically update the sweep trajectory to provide 3D compounded images of the target anatomy seamlessly. To achieve these functions, a depth camera is employed to extract the manually planned sweep trajectory after which the normal direction of the object is estimated using the extracted 3D trajectory. Subsequently, to monitor the movement and further compensate for this motion to accurately follow the trajectory, the position of firmly attached passive markers is tracked in real-time. Finally, a stepwise compounding was performed. The experiments on a gel phantom demonstrate that the system can resume a sweep when the object is not stationary during scanning.",
        "primary_area": "",
        "author": "Zhongliang Jiang;Hanyu Wang;Zhenyu Li;Matthias Grimm;Mingchuan Zhou;Ulrich Eck;Sandra V. Brecht;Tim C. Lueth;Thomas Wendler;Nassir Navab;Zhongliang Jiang;Hanyu Wang;Zhenyu Li;Matthias Grimm;Mingchuan Zhou;Ulrich Eck;Sandra V. Brecht;Tim C. Lueth;Thomas Wendler;Nassir Navab",
        "authorids": "/37086374004;/37089002099;/37089000901;/37087470595;/37086332028;/37393628900;/37085991401;/37389804500;/38079671300;/37282965500;/37086374004;/37089002099;/37089000901;/37087470595;/37086332028;/37393628900;/37085991401;/37389804500;/38079671300;/37282965500",
        "aff": "Chair for Computer Aided Medical Procedures and Augmented Reality, Technical University of Munich, Germany; Chair for Computer Aided Medical Procedures and Augmented Reality, Technical University of Munich, Germany; Chair for Computer Aided Medical Procedures and Augmented Reality, Technical University of Munich, Germany; Chair for Computer Aided Medical Procedures and Augmented Reality, Technical University of Munich, Germany; College of Biosystems of Engineering and Food Science, Zhejiang University, China; Chair for Computer Aided Medical Procedures and Augmented Reality, Technical University of Munich, Germany; Institute of Micro Technology and Medical Device Technology, Technical University of Munich, Germany; Institute of Micro Technology and Medical Device Technology, Technical University of Munich, Germany; Chair for Computer Aided Medical Procedures and Augmented Reality, Technical University of Munich, Germany; Laboratory for Computational Sensing and Robotics, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561487/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14638155128652600251&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;0;0;0;1;0;0;0;0;2",
        "aff_unique_norm": "Technical University of Munich;Zhejiang University;Johns Hopkins University",
        "aff_unique_dep": "Chair for Computer Aided Medical Procedures and Augmented Reality;College of Biosystems of Engineering and Food Science;Laboratory for Computational Sensing and Robotics",
        "aff_unique_url": "https://www.tum.de;http://www.zju.edu.cn;https://www.jhu.edu",
        "aff_unique_abbr": "TUM;ZJU;JHU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Baltimore",
        "aff_country_unique_index": "0;0;0;0;1;0;0;0;0;2",
        "aff_country_unique": "Germany;China;United States"
    },
    {
        "id": "9562001",
        "title": "Movement recognition and prediction using DMPs",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an approach for (a) recognizing an observed trajectory from a library of pre-learned motions; and (b) predicting the target position of such trajectory. In our approach, motions are represented as Dynamic Movement Primitives (DMPs). We use critical points from the observed trajectory to time-align it with those in the library. To match the observed trajectory with those in the library, we compare the changes in velocity orientation between consecutive critical points. The proposed approach is computationally light and, as such, can be performed at execution time. As for the prediction, we adopt a similar approach: after matching the observed trajectory to one in the library, we use the latter to predict the target point, modulating it to match the observed trajectory. Both recognition and prediction approaches are probabilistic and, as such, provide a measure of certainty/uncertainty in the recognition/prediction process. Such a measure of uncertainty is important in tasks involving human-robot collaboration, as it allows the robot to decide when it is sufficiently certain to act conditioned on the estimated trajectory. We illustrate our approach both in simulation and in a human-robot interaction scenario involving the Baxter robot.",
        "primary_area": "",
        "author": "Ali H. Kordia;Francisco S. Melo;Ali H. Kordia;Francisco S. Melo",
        "authorids": "/37088756762;/37885650900;/37088756762;/37885650900",
        "aff": "INESC-ID and with Instituto Superior T\u00e9cnico, University of Lisbon, Portugal; INESC-ID and with Instituto Superior T\u00e9cnico, University of Lisbon, Portugal",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562001/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3510432437131941564&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Lisbon",
        "aff_unique_dep": "Instituto Superior T\u00e9cnico",
        "aff_unique_url": "https://www.ist.utl.pt",
        "aff_unique_abbr": "IST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Lisbon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Portugal"
    },
    {
        "id": "9561598",
        "title": "Multi-Agent Active Search using Realistic Depth-Aware Noise Model",
        "track": "main",
        "status": "Poster",
        "abstract": "The active search for objects of interest in an unknown environment has many robotics applications including search and rescue, detecting gas leaks or locating animal poachers. Existing algorithms often prioritize the location accuracy of objects of interest while other practical issues such as the reliability of object detection as a function of distance and lines of sight remain largely ignored. Additionally, in many active search scenarios, communication infrastructure may be unreliable or unestablished, making centralized control of multiple agents impractical. We present an algorithm called Noise-Aware Thompson Sampling (NATS) that addresses these issues for multiple ground-based robots performing active search considering two sources of sensory information from monocular optical imagery and depth maps. By utilizing Thompson Sampling, NATS allows for decentralized coordination among multiple agents. NATS also considers object detection uncertainty from depth as well as environmental occlusions and operates while remaining agnostic of the number of objects of interest. Using simulation results, we show that NATS significantly outperforms existing methods such as information-greedy policies or exhaustive search. We demonstrate the real-world viability of NATS using a pseudo-realistic environment created in the Unreal Engine 4 game development platform with the AirSim plugin.",
        "primary_area": "",
        "author": "Ramina Ghods;William J. Durkin;Jeff Schneider;Ramina Ghods;William J. Durkin;Jeff Schneider",
        "authorids": "/37085690543;/37088997990;/37281084800;/37085690543;/37088997990;/37281084800",
        "aff": "Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; School of Earth Sciences, Ohio State University, Columbus, OH; Robotics Institute, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561598/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11144957894547987890&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Ohio State University",
        "aff_unique_dep": "Robotics Institute, School of Computer Science;School of Earth Sciences",
        "aff_unique_url": "https://www.cmu.edu;https://www.osu.edu",
        "aff_unique_abbr": "CMU;OSU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pittsburgh;Columbus",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561257",
        "title": "Multi-Agent Ergodic Coverage in Urban Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "An important aspect of dynamic urban coverage is how building collision avoidance is incorporated into the overall coverage mission. We consider a multi-agent urban dynamic coverage problem in which a team of flying agents uses downward facing cameras to observe the street-level environment outside of buildings. Cameras are assumed to be ineffective above a maximum altitude (lower than building height), such that agents must move around or over buildings to complete their mission. The main objective of this paper is to compare three different building avoidance strategies that are compatible with dynamic ergodic methods. To provide context for these results, we also compare our results to three other common coverage methods including: boustrophedon coverage (lawn-mower sweep), Voronoi region based coverage, and a naive grid method. All algorithms are evaluated in simulation with respect to four performance metrics (percent coverage, revisit count, revisit time, and the integral of area viewed over time), across team sizes ranging from 1 to 25 agents, and in five types of urban environments of varying density and height. We find that the relative performance of algorithms changes based on the ratio of team size to search area, as well the height and density characteristics of the urban environment.",
        "primary_area": "",
        "author": "Shivang Patel;Senthil Hariharan;Pranav Dhulipala;Ming C Lin;Dinesh Manocha;Huan Xu;Michael Otte;Shivang Patel;Senthil Hariharan;Pranav Dhulipala;Ming C Lin;Dinesh Manocha;Huan Xu;Michael Otte",
        "authorids": "/37086931225;/37089001838;/37089000107;/37278387400;/37267825600;/38252880100;/37604381000;/37086931225;/37089001838;/37089000107;/37278387400;/37267825600;/38252880100;/37604381000",
        "aff": "Maryland Robotics Center, University of Maryland, College Park; Maryland Robotics Center, University of Maryland, College Park; Maryland Robotics Center, University of Maryland, College Park; The Department of Electrical and Computer Engineering, University of Maryland, College Park; The Department of Electrical and Computer Engineering, University of Maryland, College Park; The Institute for Systems Research, University of Maryland, College Park; The Department of Aerospace Engineering, University of Maryland, College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561257/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18027174490937516911&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;1;1",
        "aff_unique_norm": "University of Maryland;University of Maryland, College Park",
        "aff_unique_dep": "Maryland Robotics Center;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www/umd.edu;https://www.umd.edu",
        "aff_unique_abbr": "UMD;UMD",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561228",
        "title": "Multi-FinGAN: Generative Coarse-To-Fine Sampling of Multi-Finger Grasps",
        "track": "main",
        "status": "Poster",
        "abstract": "While there exists many methods for manipulating rigid objects with parallel-jaw grippers, grasping with multi-finger robotic hands remains a quite unexplored research topic. Reasoning and planning collision-free trajectories on the additional degrees of freedom of several fingers represents an important challenge that, so far, involves computationally costly and slow processes. In this work, we present Multi-FinGAN, a fast generative multi-finger grasp sampling method that synthesizes high quality grasps directly from RGB-D images in about a second. We achieve this by training in an end-to-end fashion a coarse-to-fine model composed of a classification network that distinguishes grasp types according to a specific taxonomy and a refinement network that produces refined grasp poses and joint angles. We experimentally validate and benchmark our method against a standard grasp-sampling method on 790 grasps in simulation and 20 grasps on a real Franka Emika Panda. All experimental results using our method show consistent improvements both in terms of grasp quality metrics and grasp success rate. Remarkably, our approach is up to 20-30 times faster than the baseline, a significant improvement that opens the door to feedback-based grasp re-planning and task informative grasping. Code is available at https://irobotics.aalto.fi/multi-fingan/.",
        "primary_area": "",
        "author": "Jens Lundell;Enric Corona;Tran Nguyen Le;Francesco Verdoja;Philippe Weinzaepfel;Gr\u00e9gory Rogez;Francesc Moreno-Noguer;Ville Kyrki;Jens Lundell;Enric Corona;Tran Nguyen Le;Francesco Verdoja;Philippe Weinzaepfel;Gr\u00e9gory Rogez;Francesc Moreno-Noguer;Ville Kyrki",
        "authorids": "/37086575749;/37086578863;/37088886216;/37085381448;/37945393000;/37267412500;/38274555200;/37274001900;/37086575749;/37086578863;/37088886216;/37085381448;/37945393000;/37267412500;/38274555200;/37274001900",
        "aff": "School of Electrical Engineering, Aalto University; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain; School of Electrical Engineering, Aalto University; School of Electrical Engineering, Aalto University; NAVER LABS Europe, Meylan, France; NAVER LABS Europe, Meylan, France; Institut de Rob\u00f2tica i Inform\u00e0tica Industrial, CSIC-UPC, Barcelona, Spain; School of Electrical Engineering, Aalto University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561228/",
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4635634986884422230&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;0;0;2;2;1;0",
        "aff_unique_norm": "Aalto University;Institut de Rob\u00f2tica i Inform\u00e0tica Industrial;NAVER LABS Europe",
        "aff_unique_dep": "School of Electrical Engineering;;",
        "aff_unique_url": "https://www.aalto.fi;http://www.iri.upc.edu/;https://labs.naver.com",
        "aff_unique_abbr": "Aalto;IRI;NAVER LABS Europe",
        "aff_campus_unique_index": "1;2;2;1",
        "aff_campus_unique": ";Barcelona;Meylan",
        "aff_country_unique_index": "0;1;0;0;2;2;1;0",
        "aff_country_unique": "Finland;Spain;France"
    },
    {
        "id": "9561695",
        "title": "Multi-Hypothesis Interactions in Game-Theoretic Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel method for handling uncertainty about the intentions of non-ego players in trajectory games, with application to motion planning for autonomous vehicles. Our method models the uncertainty about the intention of other agents by constructing multiple hypotheses about the objectives and constraints of other agents in the scene. For each candidate hypothesis, we associate a Bernoulli random variable representing the probability of that hypothesis, which may or may not be independent of the probability of other hypotheses. We leverage constraint asymmetries and feedback information patterns to incorporate the probabilities of hypotheses in a natural way. Specifically, increasing the probability associated with a given hypothesis from 0 to 1 shifts the responsibility of collision avoidance from the hypothesized agent to the ego agent. This method allows the generation of interactive trajectories for the ego agent, where the level of assertiveness or caution that the ego exhibits is directly related to the easy-to-model uncertainty it maintains about the scene.",
        "primary_area": "",
        "author": "Forrest Laine;David Fridovich-Keil;Chih-Yuan Chiu;Claire Tomlin;Forrest Laine;David Fridovich-Keil;Chih-Yuan Chiu;Claire Tomlin",
        "authorids": "/37085996251;/37086041251;/37088951911;/37271692600;/37085996251;/37086041251;/37088951911;/37271692600",
        "aff": "Department of Electrical Engineering & Computer Sciences, UC Berkeley; Department of Electrical Engineering & Computer Sciences, UC Berkeley; Department of Electrical Engineering & Computer Sciences, UC Berkeley; Department of Electrical Engineering & Computer Sciences, UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561695/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10728339370762056550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering & Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561510",
        "title": "Multi-Layered Safety for Legged Robots via Control Barrier Functions and Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem of dynamic locomotion over rough terrain requires both accurate foot placement together with an emphasis on dynamic stability. Existing approaches to this problem prioritize immediate safe foot placement over longer term dynamic stability considerations, or relegate the coordination of foot placement and dynamic stability to heuristic methods. We propose a multi-layered locomotion framework that unifies Control Barrier Functions (CBFs) with Model Predictive Control (MPC) to simultaneously achieve safe foot placement and dynamic stability. Our approach incorporates CBF based safety constraints both in a low frequency kinodynamic MPC formulation and a high frequency inverse dynamics tracking controller. This ensures that safety-critical execution is considered when optimizing locomotion over a longer horizon. We validate the proposed method in a 3D stepping-stone scenario in simulation and experimentally on the ANYmal quadruped platform.",
        "primary_area": "",
        "author": "Ruben Grandia;Andrew J. Taylor;Aaron D. Ames;Marco Hutter;Ruben Grandia;Andrew J. Taylor;Aaron D. Ames;Marco Hutter",
        "authorids": "/37086355336;/37087322409;/37300877900;/37545251000;/37086355336;/37087322409;/37300877900;/37545251000",
        "aff": "Department of Mechanical and Process Engineering, ETH Z\u00fcrich, Z\u00fcrich, Switzerland; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA, USA; Department of Mechanical and Process Engineering, ETH Z\u00fcrich, Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561510/",
        "gs_citation": 168,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1936107942378979268&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "ETH Zurich;California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Process Engineering;Department of Computing and Mathematical Sciences",
        "aff_unique_url": "https://www.ethz.ch;https://www.caltech.edu",
        "aff_unique_abbr": "ETH;Caltech",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Z\u00fcrich;Pasadena",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Switzerland;United States"
    },
    {
        "id": "9561859",
        "title": "Multi-Modal Motion Planning Using Composite Pose Graph Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a motion planning framework for multi-modal vehicle dynamics. Our proposed algorithm employs transcription of the optimization objective function, vehicle dynamics, and state and control constraints into sparse factor graphs, which\u2014combined with mode transition constraints\u2014constitute a composite pose graph. By formulating the multi-modal motion planning problem in composite pose graph form, we enable utilization of efficient techniques for optimization on sparse graphs, such as those widely applied in dual estimation problems, e.g., simultaneous localization and mapping (SLAM). The resulting motion planning algorithm optimizes the multi-modal trajectory, including the location of mode transitions, and is guided by the pose graph optimization process to eliminate unnecessary transitions, enabling efficient discovery of optimized mode sequences from rough initial guesses. We demonstrate multi-modal trajectory optimization in both simulation and real-world experiments for vehicles with various dynamics models, such as an airplane with taxi and flight modes, and a vertical take-off and landing (VTOL) fixed-wing aircraft that transitions between hover and horizontal flight modes.",
        "primary_area": "",
        "author": "Lukas Lao Beyer;Nadya Balabanska;Ezra Tal;Sertac Karaman;Lukas Lao Beyer;Nadya Balabanska;Ezra Tal;Sertac Karaman",
        "authorids": "/37088999158;/37088995903;/37086431381;/37304113000;/37088999158;/37088995903;/37086431381;/37304113000",
        "aff": "Laboratory for Information and Decision Systems, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA; Laboratory for Information and Decision Systems, Massachusetts Institute of Technology (MIT), Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561859/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15183610875784536031&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information and Decision Systems",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561187",
        "title": "Multi-Modal Mutual Information (MuMMI) Training for Robust Self-Supervised Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "This work focuses on learning useful and robust deep world models using multiple, possibly unreliable, sensors. We find that current methods do not sufficiently encourage a shared representation between modalities; this can cause poor performance on downstream tasks and over-reliance on specific sensors. As a solution, we contribute a new multi-modal deep latent state-space model, trained using a mutual information lower-bound. The key innovation is a specially-designed density ratio estimator that encourages consistency between the latent codes of each modality. We tasked our method to learn policies (in a self-supervised manner) on multi-modal Natural MuJoCo benchmarks and a challenging Table Wiping task. Experiments show our method significantly outperforms state-of-the-art deep reinforcement learning methods, particularly in the presence of missing observations.",
        "primary_area": "",
        "author": "Kaiqi Chen;Yong Lee;Harold Soh;Kaiqi Chen;Yong Lee;Harold Soh",
        "authorids": "/37089001097;/37089001517;/37684942300;/37089001097;/37089001517;/37684942300",
        "aff": "Dept. of Computer Science, National University of Singapore; Dept. of Computer Science, National University of Singapore; Dept. of Computer Science, National University of Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561187/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14738666512472000961&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National University of Singapore",
        "aff_unique_dep": "Dept. of Computer Science",
        "aff_unique_url": "https://www.nus.edu.sg",
        "aff_unique_abbr": "NUS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9561818",
        "title": "Multi-Objective Graph Heuristic Search for Terrestrial Robot Design",
        "track": "main",
        "status": "Poster",
        "abstract": "We present methods for co-designing rigid robots over control and morphology (including discrete topology) over multiple objectives. Previous work has addressed problems in single-objective robot co-design or multi-objective control. However, the joint multi-objective co-design problem is extremely important for generating capable, versatile, algorithmically designed robots. In this work, we present Multi-Objective Graph Heuristic Search, which extends a single-objective graph heuristic search from previous work to enable a highly efficient multi-objective search in a combinatorial design topology space. Core to this approach, we introduce a new universal, multiobjective heuristic function based on graph neural networks that is able to effectively leverage learned information between different task trade-offs. We demonstrate our approach on six combinations of seven terrestrial locomotion and design tasks, including one three-objective example. We compare the captured Pareto fronts across different methods and demonstrate that our multi-objective graph heuristic search quantitatively and qualitatively outperforms other techniques.",
        "primary_area": "",
        "author": "Jie Xu;Andrew Spielberg;Allan Zhao;Daniela Rus;Wojciech Matusik;Jie Xu;Andrew Spielberg;Allan Zhao;Daniela Rus;Wojciech Matusik",
        "authorids": "/37089503538;/37085376500;/37088827263;/37279652300;/37295070400;/37089503538;/37085376500;/37088827263;/37279652300;/37295070400",
        "aff": "MIT Computer Science And Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, Massachusetts; MIT Computer Science And Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, Massachusetts; MIT Computer Science And Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, Massachusetts; MIT Computer Science And Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, Massachusetts; MIT Computer Science And Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, Massachusetts",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561818/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11722815293280681499&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science And Artificial Intelligence Laboratory (CSAIL)",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561538",
        "title": "Multi-Parameter Optimization for a Robust RGB-D SLAM System",
        "track": "main",
        "status": "Poster",
        "abstract": "SLAM systems can retrieve their metric scales and depth information using RGB-D cameras. However, limited by the sensing range and objects structure, RGB-D cameras can not always work well, resulting in failures sometimes. In this work, we present initialization and localization methods based on maximum-a-posteriori estimation. Our system endows monocular keypoints with valid depth values and introduce them into bundle adjustment. Depth bias coefficient and scale factor are also optimized in the local window, obtaining robustness in large scale environments and long-running operations. The experimental results indicate that our system provides the best robustness compared with other excellent methods in the literature, being able to process the most challenging sequences in the TUM RGB-D dataset.",
        "primary_area": "",
        "author": "Yizhao Wang;Xiaoxiao Zhu;Guohan He;Qixin Cao;Yizhao Wang;Xiaoxiao Zhu;Guohan He;Qixin Cao",
        "authorids": "/37089002264;/37085563439;/37088749947;/37271507500;/37089002264;/37085563439;/37088749947;/37271507500",
        "aff": "State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; State Key Laboratory of Mechanical System and Vibration, Shanghai Jiao Tong University, Shanghai, China; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561538/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11059553989983148996&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "State Key Laboratory of Mechanical System and Vibration",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561934",
        "title": "Multi-Robot Distributed Semantic Mapping in Unfamiliar Environments through Online Matching of Learned Representations",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a solution to multi-robot distributed semantic mapping of novel and unfamiliar environments. Most state-of-the-art semantic mapping systems are based on supervised learning algorithms that cannot classify novel observations online. While unsupervised learning algorithms can invent labels for novel observations, approaches to detect when multiple robots have independently developed their own labels for the same new class are prone to erroneous or inconsistent matches. These issues worsen as the number of robots in the system increases and prevent fusing the local maps produced by each robot into a consistent global map, which is crucial for cooperative planning and joint mission summarization. Our proposed solution overcomes these obstacles by having each robot learn an unsupervised semantic scene model online and use a multiway matching algorithm to identify consistent sets of matches between learned semantic labels belonging to different robots. Compared to the state of the art, the proposed solution produces 20-60% higher quality global maps that do not degrade even as many more local maps are fused.",
        "primary_area": "",
        "author": "Stewart Jamieson;Kaveh Fathian;Kasra Khosoussi;Jonathan P. How;Yogesh Girdhar;Stewart Jamieson;Kaveh Fathian;Kasra Khosoussi;Jonathan P. How;Yogesh Girdhar",
        "authorids": "/37086936061;/37085866524;/37085362096;/37276347700;/37546414900;/37086936061;/37085866524;/37085362096;/37276347700;/37546414900",
        "aff": "Department of Aeronautics and Astronautics, Massachusetts Institute of Technology (MIT); Department of Aeronautics and Astronautics, Massachusetts Institute of Technology (MIT); Department of Aeronautics and Astronautics, Massachusetts Institute of Technology (MIT); Department of Aeronautics and Astronautics, Massachusetts Institute of Technology (MIT); Applied Ocean Physics and Engineering Department, Woods Hole Oceanographic Institution (WHOI)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561934/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14659425325873200062&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Woods Hole Oceanographic Institution",
        "aff_unique_dep": "Department of Aeronautics and Astronautics;Applied Ocean Physics and Engineering Department",
        "aff_unique_url": "https://web.mit.edu;https://www.whoi.edu",
        "aff_unique_abbr": "MIT;WHOI",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Cambridge;Woods Hole",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561014",
        "title": "Multi-Robot Dynamical Source Seeking in Unknown Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an algorithmic framework for the distributed on-line source seeking, termed as DoSS, with a multi-robot system in an unknown dynamical environment. Our algorithm, building on a novel concept called dummy confidence upper bound (D-UCB), integrates both estimation of the unknown environment and task planning for the multiple robots simultaneously, and as a result, drives the team of robots to a steady state in which multiple sources of interest are located. Unlike the standard UCB algorithm in the context of multi-armed bandits, the introduction of D-UCB significantly reduces the computational complexity in solving subproblems of the multi-robot task planning. This also enables our DoSS algorithm to be implementable in a distributed on-line manner. The performance of the algorithm is theoretically guaranteed by showing a sub-linear upper bound of the cumulative regret. Numerical results on a real-world methane emission seeking problem are also provided to demonstrate the effectiveness of the proposed algorithm.",
        "primary_area": "",
        "author": "Bin Du;Kun Qian;Hassan Iqbal;Christian Claudel;Dengfeng Sun;Bin Du;Kun Qian;Hassan Iqbal;Christian Claudel;Dengfeng Sun",
        "authorids": "/37087012245;/37089002177;/37090006231;/37397955400;/37896756700;/37087012245;/37089002177;/37090006231;/37397955400;/37896756700",
        "aff": "Purdue University, West Lafayette, IN; The University of Texas at Austin, Austin, TX; The University of Texas at Austin, Austin, TX; The University of Texas at Austin, Austin, TX; Purdue University, West Lafayette, IN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561014/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7959868309111317566&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Purdue University;University of Texas at Austin",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.purdue.edu;https://www.utexas.edu",
        "aff_unique_abbr": "Purdue;UT Austin",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "West Lafayette;Austin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560851",
        "title": "Multi-Robot Gaussian Process Estimation and Coverage: Deterministic Sequencing Algorithm and Regret Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of multi-robot coverage over an unknown, nonuniform sensory field. Modeling the sensory field as a realization of a Gaussian Process and using Bayesian techniques, we devise a policy which aims to balance the tradeoff between learning the sensory function and covering the environment. We propose an adaptive coverage algorithm called Deterministic Sequencing of Learning and Coverage (DSLC) that schedules learning and coverage epochs such that its emphasis gradually shifts from exploration to exploitation while never fully ceasing to learn. Using a novel definition of coverage regret which characterizes overall coverage performance of a multi-robot team over a time horizon T , we analyze DSLC to provide an upper bound on expected cumulative coverage regret. Finally, we illustrate the empirical performance of the algorithm through simulations of the coverage task over an unknown distribution of wildfires.",
        "primary_area": "",
        "author": "Lai Wei;Andrew McDonald;Vaibhav Srivastava;Lai Wei;Andrew McDonald;Vaibhav Srivastava",
        "authorids": "/37086432252;/37088998522;/37085506787;/37086432252;/37088998522;/37085506787",
        "aff": "Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA; Department of Electrical and Computer Engineering, Michigan State University, East Lansing, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560851/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11390517656830966168&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Michigan State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.msu.edu",
        "aff_unique_abbr": "MSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "East Lansing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560883",
        "title": "Multi-Robot Motion Planning with Unlabeled Goals for Mobile Robots with Differential Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the multi-robot motion-planning problem with unlabeled goals where n robots have to reach m goals. The proposed approach also takes into account the underlying dynamics of each robot to produce dynamically-feasible trajectories that enable the robots to reach all the goals while avoiding collisions with the obstacles and each other. The approach leverages the idea of combining sampling-based motion planning with goal assignment and multi-agent search. In fact, the goal-assignment layer seeks to effectively utilize the robots based on estimated costs to reach the remaining goals. The multi-agent search provides nonconflicting paths over roadmap graphs, which then guide the sampling-based expansion of a motion tree. The goal assignments and multi-agent paths are frequently updated based on the progress made during the motion-tree expansion. Simulation experiments using an increasing number of robots with nonlinear dynamics demonstrate the efficiency of the approach.",
        "primary_area": "",
        "author": "Duong Le;Erion Plaku;Duong Le;Erion Plaku",
        "authorids": "/37085558540;/37541383900;/37085558540;/37541383900",
        "aff": "Perceptive Automata, Inc; Department of Computer Science, George Mason University, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560883/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3335661985275249562&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Perceptive Automata;George Mason University",
        "aff_unique_dep": ";Department of Computer Science",
        "aff_unique_url": ";https://www.gmu.edu",
        "aff_unique_abbr": "Perceptive Automata;GMU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Fairfax",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561809",
        "title": "Multi-Robot Task Allocation Games in Dynamically Changing Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a game-theoretic multi-robot task allocation framework that enables a large team of robots to optimally allocate tasks in dynamically changing environments. As our main contribution, we design a decision-making algorithm that defines how the robots select tasks to perform and how they repeatedly revise their task selections in response to changes in the environment. Our convergence analysis establishes that the algorithm enables the robots to learn and asymptotically achieve the optimal stationary task allocation. Through experiments with a multi-robot trash collection application, we assess the algorithm\u2019s responsiveness to changing environments and resilience to failure of individual robots.",
        "primary_area": "",
        "author": "Shinkyu Park;Yaofeng Desmond Zhong;Naomi Ehrich Leonard;Shinkyu Park;Yaofeng Desmond Zhong;Naomi Ehrich Leonard",
        "authorids": "/37086183848;/37088334305;/37275145000;/37086183848;/37088334305;/37275145000",
        "aff": "Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ, USA; Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ, USA; Department of Mechanical and Aerospace Engineering, Princeton University, Princeton, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561809/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4081769199318163981&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Princeton University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.princeton.edu",
        "aff_unique_abbr": "Princeton",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Princeton",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560864",
        "title": "Multi-Scale Cost Volumes Cascade Network for Stereo Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Stereo matching is essential for robot navigation. However, the accuracy of current widely used traditional methods is low, while methods based on CNN need expensive computational cost and running time. This is because different cost volumes play a crucial role in balancing speed and accuracy. Thus we propose MSCVNet, which combines traditional methods and neural networks to improve the quality of cost volume. Concretely, our network first generates multiple 3D cost volumes with different resolutions and then uses 2D convolutions to construct a novel cascade hourglass network for cost aggregation. Meanwhile, we design an algorithm to distinguish and calculate the loss for discontinuous areas of the disparity result. According to the KITTI official website, our network is much faster than most top-performing methods (24than CSPN, 44than GANet, etc.). Meanwhile, compared to traditional methods (SPS-St, SGM) and other real-time stereo matching networks (Fast DS-CS, DispNetC, and RTSNet, etc.), our network achieves a big improvement in accuracy, demonstrating the feasibility and capability of the proposed method.",
        "primary_area": "",
        "author": "Xiaogang Jia;Wei Chen;Chen Li;Zhengfa Liang;Mingfei Wu;Yusong Tan;Libo Huang;Xiaogang Jia;Wei Chen;Chen Li;Zhengfa Liang;Mingfei Wu;Yusong Tan;Libo Huang",
        "authorids": "/37088654679;/37597877600;/37085457067;/37070422300;/37088932570;/37853317200;/37292522800;/37088654679;/37597877600;/37085457067;/37070422300;/37088932570;/37853317200;/37292522800",
        "aff": "Department of Computer Science, National University of Defense Technology, China; Department of Computer Science, National University of Defense Technology, China; Department of Computer Science, National University of Defense Technology, China; Department of Computer Science, National University of Defense Technology, China; Department of Computer Science, National University of Defense Technology, China; Department of Computer Science, National University of Defense Technology, China; Department of Computer Science, National University of Defense Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560864/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6172658536961444608&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "National University of Defense Technology",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "http://www.nudt.edu.cn",
        "aff_unique_abbr": "NUDT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561030",
        "title": "Multi-Step Recurrent Q-Learning for Robotic Velcro Peeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning object manipulation is a critical skill for robots to interact with their environment. Even though there has been significant progress in robotic manipulation of rigid objects, interacting with non-rigid objects remains challenging for robots. In this work, we introduce velcro peeling as a new application for robotic manipulation of non-rigid objects in complex environments. We present a method of learning force-based manipulation from noisy and incomplete sensor inputs in partially observable environments by modeling long term dependencies between measurements with a multi-step deep recurrent network. We present experiments on a real robot to show the necessity of modeling these long term dependencies and validate our approach in simulation and robot experiments. Our results show that using tactile input enables the robot to overcome geometric uncertainties present in the environment with high fidelity in \u223c 90% of all cases, outperforming the baselines by a large margin.",
        "primary_area": "",
        "author": "Jiacheng Yuan;Nicolai H\u00e4ni;Volkan Isler;Jiacheng Yuan;Nicolai H\u00e4ni;Volkan Isler",
        "authorids": "/37088998450;/37086198436;/37298487800;/37088998450;/37086198436;/37298487800",
        "aff": "Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN, USA; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561030/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13465090132627692128&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Minnesota",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561492",
        "title": "Multi-agent Aerial Monitoring of Moving Convoys using Elliptical Orbits",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel scheme for surveillance of a dynamic ground convoy moving along a non-linear trajectory, by aerial agents that maintain a uniformly spaced formation on a time-varying elliptical orbit encompassing the convoy. Elliptical orbits are used as they are more economical than circular orbits for circumnavigating the group of targets in the moving convoy. The proposed scheme includes an algorithm for computing feasible elliptical orbits, a vector guidance law for agent motion along the desired orbit, and a cooperative strategy to control the speeds of the aerial agents in order to quickly achieve and maintain the desired formation. It achieves mission objectives while accounting for linear and angular speed constraints on the aerial agents. The scheme is validated through simulations and actual experiments with a convoy of ground robots and a team of quadrotors as the aerial agents, in a motion capture environment.",
        "primary_area": "",
        "author": "Aseem V. Borkar;Girish Chowdhary;Aseem V. Borkar;Girish Chowdhary",
        "authorids": "/37086024567;/37402725200;/37086024567;/37402725200",
        "aff": "Coordinated Science Laboratory, University of Illinois at Urbana Champaign, USA; Agricultural and Biological Engineering and Computer Science, University of Illinois Urbana-Champaign, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561492/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6700095563810630939&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Coordinated Science Laboratory",
        "aff_unique_url": "https://www illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561643",
        "title": "Multi-agent Receding Horizon Search with Terminal Cost",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a multi-agent approach to receding horizon path planning that utilizes terminal costs. We show that the value of the receding horizon paths produced using the proposed methods have a guaranteed lower bound that can be determined using any readily-available, naive solution. We present a modified sequentially allocated optimal path planner with terminal costs that is guaranteed to satisfy the assumptions required to provide a guaranteed lower bound. We utilize a slightly modified version of the Decentralized Monte Carlo Tree Search algorithm to solve for near-optimal paths within a short planning horizon with an appended terminal cost to demonstrate the flexibility of the proposed method. We compare these receding horizon methods that incorporate a terminal cost to related receding horizon methods that do not incorporate a terminal cost. Our approach is developed specifically for multiple agents engaged in search, but can be easily adapted for other information gathering applications.",
        "primary_area": "",
        "author": "Benjamin Biggs;James McMahon;Philip Baldoni;Daniel J. Stilwell;Benjamin Biggs;James McMahon;Philip Baldoni;Daniel J. Stilwell",
        "authorids": "/37087324207;/37085353635;/37086071951;/37283170000;/37087324207;/37085353635;/37086071951;/37283170000",
        "aff": "Virginia Tech; Acoustics Division, US Naval Research Laboratory; US Naval Research Laboratory, Washington D.C., USA; Bradley Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561643/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4706034834374516743&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Virginia Tech;US Naval Research Laboratory",
        "aff_unique_dep": ";Acoustics Division",
        "aff_unique_url": "https://www.vt.edu;https://www.nrl.navy.mil",
        "aff_unique_abbr": "VT;NRL",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Washington D.C.;Blacksburg",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560985",
        "title": "Multi-objective Conflict-based Search for Multi-agent Path Finding",
        "track": "main",
        "status": "Poster",
        "abstract": "Conventional multi-agent path planners typically compute an ensemble of paths while optimizing a single objective, such as path length. However, many applications may require multiple objectives, say fuel consumption and completion time, to be simultaneously optimized during planning and these criteria may not be readily compared and sometimes lie in competition with each other. Naively applying existing multi-objective search algorithms to multi-agent path finding may prove to be inefficient as the size of the space of possible solutions, i.e., the Pareto-optimal set, can grow exponentially with the number of agents (the dimension of the search space). This article presents an approach named Multi-objective Conflict-based Search (MO-CBS) that bypasses this so-called curse of dimensionality by leveraging prior Conflict-based Search (CBS), a well-known algorithm for single-objective multi-agent path finding, and principles of dominance from multi-objective optimization literature. We prove that MO-CBS is able to compute the entire Pareto-optimal set. Our results show that MO-CBS can solve problem instances with hundreds of Pareto-optimal solutions which the standard multi-objective A* algorithms could not find within a bounded time.",
        "primary_area": "",
        "author": "Zhongqiang Ren;Sivakumar Rathinam;Howie Choset;Zhongqiang Ren;Sivakumar Rathinam;Howie Choset",
        "authorids": "/37086293378;/37268809800;/37281322200;/37086293378;/37268809800;/37281322200",
        "aff": "Carnegie Mellon University, Pittsburgh, PA, USA; Texas A&M University, College Station, TX; Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560985/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18316126323698032401&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Texas A&M University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.cmu.edu;https://www.tamu.edu",
        "aff_unique_abbr": "CMU;TAMU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Pittsburgh;College Station",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561031",
        "title": "Multi-output Infinite Horizon Gaussian Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning the uncertain dynamical environments for online learning and prediction from noisy sensory measurement streams is essential for various tasks in robotics. Recently, Gaussian process (GP) online learning such as an infinite-horizon Gaussian process (IHGP) has shown effectiveness to cope with non-stationary dynamical random processes in learning hyperparameters online by reducing the computational cost. However, the IHGP was originally proposed to deal with only a single-output. Therefore, to tackle complex real-world problems, we propose a multi-output infinite-horizon Gaussian process (MOIHGP) that generalizes the single-output IHGP to deal with multiple outputs for better prediction. Our approach allows us to consider correlations between multiple outputs for better prediction, even with occlusions in a Bayesian way. Finally, we successfully demonstrate the effectiveness of our approach by benchmark and experimental results. For simulated benchmark experiments with high noise levels, our approach reduced 16.6% of the averaged RMSE value achieved by the single-output IHGP.",
        "primary_area": "",
        "author": "Jaehyun Lim;Jehyun Park;Sungjae Nah;Jongeun Choi;Jaehyun Lim;Jehyun Park;Sungjae Nah;Jongeun Choi",
        "authorids": "/37087407081;/37086576103;/37088998007;/37405969800;/37087407081;/37086576103;/37088998007;/37405969800",
        "aff": "School of Mechanical Engineering, Yonsei University, Seoul, Republic of Korea; School of Mechanical Engineering, Yonsei University, Seoul, Republic of Korea; School of Mechanical Engineering, Yonsei University, Seoul, Republic of Korea; School of Mechanical Engineering and the Department of Artificial Intelligence, Yonsei University, Seoul, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561031/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10019938700203713166&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Yonsei University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.yonsei.ac.kr",
        "aff_unique_abbr": "Yonsei",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561231",
        "title": "Multi-robot Implicit Control of Herds",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel control strategy to herd a group of non-cooperative evaders by means of a team of robotic herders. In herding problems, the motion of the evaders is typically determined by strong nonlinear reactive dynamics, escaping from the herders. Many applications demand the herding of numerous and/or heterogeneous entities, making the development of flexible control solutions challenging. In this context, our main contribution is a control approach that finds suitable herding actions even when the nonlinearities in the evaders\u2019 dynamics yield to implicit equations. We resort to numerical analysis theory to characterise the existence conditions of such actions and propose two design methods to compute them, one transforming the continuous time implicit system into an expanded explicit system, and the other applying a numerical method to find the action in discrete time. Simulations and real experiments validate the proposal in different scenarios.",
        "primary_area": "",
        "author": "Eduardo Sebasti\u00e1n;Eduardo Montijano;Eduardo Sebasti\u00e1n;Eduardo Montijano",
        "authorids": "/37086025534;/37681715400;/37086025534;/37681715400",
        "aff": "RoPeRt group at DIIS - I3A, Universidad de Zaragoza, Spain; RoPeRt group at DIIS - I3A, Universidad de Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561231/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9587059437733770397&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Universidad de Zaragoza",
        "aff_unique_dep": "DIIS - I3A",
        "aff_unique_url": "https://www.unizar.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9561955",
        "title": "Multi-robot Informative Path Planning using a Leader-Follower Architecture",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider typical scenarios where an autonomous multi-robot team is used for surveying a large region. The desired output is a spatial map of the physical values of interest. Accounting for spatial correlation and uncertainty, the map is modeled using a Gaussian Process. Considering real-world constraints such as limited time budget and collision avoidance, we model team\u2019s mission as a joint informative path planning problem which is tackled using a leader-follower architecture balancing centralized and fully distributed computation of plans. The leader first identifies a convex containment region that is to be sampled by the team. Next, through a combination of Bayesian optimization and Monte Carlo simulation, distinct sampling locations are identified and assigned to the followers. Each follower independently solves an orienteering problem to find a collision-free path maximizing information gain. A team-level adaptive replanning criterion is designed to keep redirecting sampling towards the most informative regions. The algorithm has been validated in computational experiments for map estimation. Compared to a baseline reference algorithm, it has shown a significantly higher accuracy. Moreover, the approach has shown good ability to support network connectivity, as well as good scalability in computation.",
        "primary_area": "",
        "author": "Gianni A. Di Caro;Abdul Wahab Ziaullah Yousaf;Gianni A. Di Caro;Abdul Wahab Ziaullah Yousaf",
        "authorids": "/37621014100;/37089000687;/37621014100;/37089000687",
        "aff": "Gianni A. Di Caro; Abdul Wahab Ziaullah Yousaf",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561955/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17301915448099438912&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9561161",
        "title": "Multi-session Underwater Pose-graph SLAM using Inter-session Opti-acoustic Two-view Factor",
        "track": "main",
        "status": "Poster",
        "abstract": "Concurrent mapping necessitates data association among vehicles to overcome temporal and sensor modality differences. In this work, we focus on an underwater multi-vehicle mapping scenario in which vehicles have various sensor modalities, namely sonar and camera. This inter-session sonar-optical image matching poses two main challenges. First, ensuring covisibility for the opti-acoustic pair is complex due to their projection models and field of view (FOV) difference. Second, even with secured covisible frames, feature matching over various sensor modalities is not trivial. To overcome these challenges, we complete multi-session simultaneous localization and mapping (SLAM) by introducing an opti-acoustic pairwise factor. We alleviate the covisibility requirement by introducing inter-session measurements. We achieved opti-acoustic feature matching by applying a style-transfer and integration with SuperGlue. The proposed method is validated via simulation and real underwater tank tests.",
        "primary_area": "",
        "author": "Hyesu Jang;Sungho Yoon;Ayoung Kim;Hyesu Jang;Sungho Yoon;Ayoung Kim",
        "authorids": "/37088446752;/37088657667;/37403315600;/37088446752;/37088657667;/37403315600",
        "aff": "Depart. of Civil and Env. Eng, KAIST, Daejeon, S. Korea; Robotics Program, KAIST, Daejeon, S. Korea; Robotics Program, KAIST, Daejeon, S. Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561161/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8486687741865603166&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "KAIST",
        "aff_unique_dep": "Department of Civil and Environmental Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9562017",
        "title": "Multi-target Coverage with Connectivity Maintenance using Knowledge-incorporated Policy Framework",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers a multi-target coverage problem where a robot team aims to efficiently cover multi-targets while maintaining connectivity in a distributed manner. A novel knowledge-incorporated policy framework is proposed to derive a distributed, efficient, and connectivity guaranteed coverage policy. In particular, a knowledge-guided policy network (KGPnet) is designed, which consists of observation attention representation, interaction attention representation, and knowledge-guided policy learning. Giving credit to the KGPnet, the connectivity guaranteed coverage policy can be applied to different number targets. Moreover, based on the knowledge of the algebraic connectivity and coverage rate, a comprehensive reward is designed to guide the training of the behavior of multi-target coverage with connectivity maintenance. Furthermore, since the policy learned through deep reinforcement learning (DRL) can not guarantee the connectivity of the robot team, a knowledge-nested policy filtering is designed to filter dis-connectivity policies to satisfy the connectivity constraint based on the knowledge model of connectivity maintenance. Various simulations are conducted to verify the effectiveness of the proposed method. Besides, numerous real-world experiments with three-wheel omnidirectional cars and a motion capture system are presented to demonstrate the practicability of the proposed method.",
        "primary_area": "",
        "author": "Shiguang Wu;Zhiqiang Pu;Zhen Liu;Tenghai Qiu;Jianqiang Yi;Tianle Zhang;Shiguang Wu;Zhiqiang Pu;Zhen Liu;Tenghai Qiu;Jianqiang Yi;Tianle Zhang",
        "authorids": "/37087045549;/37956875200;/37085471998;/37087053504;/37277001200;/37088518501;/37087045549;/37956875200;/37085471998;/37087053504;/37277001200;/37088518501",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562017/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4631269283939813830&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_unique_dep": "School of Artificial Intelligence;Institute of Automation",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.ia.cas.cn",
        "aff_unique_abbr": "UCAS;CAS",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561810",
        "title": "Multi-view Sensor Fusion by Integrating Model-based Estimation and Graph Learning for Collaborative Object Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative object localization aims to collaboratively estimate locations of objects observed from multiple views or perspectives, which is a critical ability for multi-agent systems such as connected vehicles. To enable collaborative localization, several model-based state estimation and learning-based localization methods have been developed. Given their encouraging performance, model-based state estimation often lacks the ability to model the complex relationships among multiple objects, while learning-based methods are typically not able to fuse the observations from an arbitrary number of views and cannot well model uncertainty. In this paper, we introduce a novel spatiotemporal graph filter approach that integrates graph learning and model-based estimation to perform multi-view sensor fusion for collaborative object localization. Our approach models complex object relationships using a new spatiotemporal graph representation and fuses multi-view observations in a Bayesian fashion to improve location estimation under uncertainty. We evaluate our approach in the applications of connected autonomous driving and multiple pedestrian localization. Experimental results show that our approach outperforms previous techniques and achieves the state-of-the-art performance on collaborative localization.",
        "primary_area": "",
        "author": "Peng Gao;Rui Guo;Hongsheng Lu;Hao Zhang;Peng Gao;Rui Guo;Hongsheng Lu;Hao Zhang",
        "authorids": "/37089501844;/37086487136;/37085839592;/37085545929;/37089501844;/37086487136;/37085839592;/37085545929",
        "aff": "Human-Centered Robotics Laboratory at the Colorado School of Mines, Golden, CO, USA; Toyota Motor North America, Mountain View, CA; Toyota Motor North America, Mountain View, CA; Human-Centered Robotics Laboratory at the Colorado School of Mines, Golden, CO, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561810/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6336797555320715552&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Colorado School of Mines;Toyota Motor North America",
        "aff_unique_dep": "Human-Centered Robotics Laboratory;",
        "aff_unique_url": "https://www.mines.edu;https://www.toyota.com",
        "aff_unique_abbr": "CSM;Toyota",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Golden;Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562096",
        "title": "MultiViewStereoNet: Fast Multi-View Stereo Depth Estimation using Incremental Viewpoint-Compensated Feature Extraction",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel learning-based method for multi-view stereo (MVS) depth estimation capable of recovering depth from images taken from known, but unconstrained, views. Existing MVS methods extract features from each image independently before projecting them onto a set of planes at candidate depths to compute matching costs. By projecting features after extraction, networks must learn rotation and scale invariant representations even though the relative poses of the cameras are known. In our approach, we compensate for viewpoint changes directly in the extraction layers, allowing the network to learn features that are projected by construction and reducing the need for rotation and scale invariance.Compensating for viewpoint changes naively, however, can be computationally expensive as the feature layers must either be applied multiple times (once per depth hypothesis), or replaced by 3D convolutions. We overcome this limitation in two ways. First, we only compute our matching cost volume at a coarse image scale before upsampling and refining the outputs. Second, we incrementally compute our projected features such that the bulk of the layers need only be executed a single time across all depth hypotheses. The combination of these two techniques allows our method to perform competitively with the state-of-the-art, while being significantly faster. We call our method MultiViewStereoNet and release our source code publicly for the benefit of the robotics community.",
        "primary_area": "",
        "author": "W. Nicholas Greene;Nicholas Roy;W. Nicholas Greene;Nicholas Roy",
        "authorids": "/37085781116;/37274058700;/37085781116;/37274058700",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562096/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11180948301574850118&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562100",
        "title": "Multibranch Learning for Angiodysplasia Segmentation with Attention-Guided Networks and Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "As a common cause of anemia and gastrointestinal bleeding, angiodysplasia (AD) diagnosis in wireless capsule endoscopy (WCE) images is important in clinical. Current manual review requires undivided concentration of the gastroenterologists, which is laborious and time-consuming. The development of computational methods that can assist automated diagnosis of angiodysplasia is highly desirable. In this paper, we present a new approach, ADNet, for angiodysplasia segmentation using convolutional neural networks (CNNs). Compared with previous learning strategies, ADNet gains accuracy from attentionguided and domain-adversarial training via a multibranch CNN architecture. Specifically, the core branch is constructed for AD segmentation in a fully convolutional manner. Then we propose an attention module embedded in the attention branch to enhance network feature learning, which allows ADNet to focus on the most informative and AD relevant regions while processing. Furthermore, an adaptation branch is built to learn domain-invariant features by adversarial training, aiming to improve the performance when datasets are expanded while preventing the degradation induced by the variations in WCE image acquisition. ADNet is evaluated using two WCE datasets with angiodysplasia and the results show the accuracy gains we obtain, where the state-of-the-art segmentation performance on the public dataset of GIANA\u201917 is achieved.",
        "primary_area": "",
        "author": "Xiao Jia;Xiaochun Mai;Xiaohan Xing;Yutian Shen;Jiankun Wang;Max Q.-H. Meng;Xiao Jia;Xiaochun Mai;Xiaohan Xing;Yutian Shen;Jiankun Wang;Max Q.-H. Meng",
        "authorids": "/37085886867;/37086113153;/37086496866;/37088955451;/37086100720;/37274117000;/37085886867;/37086113153;/37086496866;/37088955451;/37086100720;/37274117000",
        "aff": "Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Electronic and Electrical Engineering, Southern University of Science and Technology in Shenzhen, China; Shenzhen Research Institute of the Chinese University of Hong Kong, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562100/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15119329544769130671&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Southern University of Science and Technology",
        "aff_unique_dep": "Department of Electronic Engineering;Department of Electronic and Electrical Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.sustech.edu.cn",
        "aff_unique_abbr": "CUHK;SUSTech",
        "aff_campus_unique_index": "0;0;0;0;1;1",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560968",
        "title": "Multifunctional Arm for Telerobotic Wind Turbine Blade Repair",
        "track": "main",
        "status": "Poster",
        "abstract": "Within the Multi-Platform Inspection, Maintenance and Repair in Extreme Environments (MIMRee) project, a lightweight and multifunctional robotic repair arm is created for wind turbine blades. The design features a toolbox at the base of the arm housing multiple end-effector tools and an autonomous end-effector tool-changer. The arm communicates commands and data via internet with a bespoke user interface enabling human-in-the-loop operation and overriding of autonomous repair actions. This paper outlines our approach in design, development, testing and control of the robotic repair system. The functionalities of the arm include cleaning, sanding, and filler material deposition and forming, each using a bespoke end-effector tool closely replicating the relevant manual repair process. The experimental results confirm the effectiveness of our approach indicating a maximum end-effector position error of 3 mm, a maximum tool switching time of 8 seconds, and a maximum arm\u2019s weight of 1.8 kg. This presents around 84% weight reduction compared with existing technologies used for the same purpose. Our standalone design enables modular integration into a wide range of mobile platform types used in industrial operations.",
        "primary_area": "",
        "author": "Rasoul Sadeghian;Sina Sareh;Rasoul Sadeghian;Sina Sareh",
        "authorids": "/37085635080;/37085434081;/37085635080;/37085434081",
        "aff": "CA Robotics Laboratory, Royal College of Art, London, UK; CA Robotics Laboratory, Royal College of Art, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560968/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5283499307171218969&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Royal College of Art",
        "aff_unique_dep": "CA Robotics Laboratory",
        "aff_unique_url": "https://www.rca.ac.uk",
        "aff_unique_abbr": "RCA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561586",
        "title": "Multimodal Anomaly Detection based on Deep Auto-Encoder for Object Slip Perception of Mobile Manipulation Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Object slip perception is essential for mobile manipulation robots to perform manipulation tasks reliably in the dynamic real-world. Traditional approaches to robot arms\u2019 slip perception use tactile or vision sensors. However, mobile robots still have to deal with noise in their sensor signals caused by the robot\u2019s movement in a changing environment. To solve this problem, we present an anomaly detection method that utilizes multisensory data based on a deep autoencoder model. The proposed framework integrates heterogeneous data streams collected from various robot sensors, including RGB and depth cameras, a microphone, and a force-torque sensor. The integrated data is used to train a deep autoencoder to construct latent representations of the multisensory data that indicate the normal status. Anomalies can then be identified by error scores measured by the difference between the trained encoder\u2019s latent values and the latent values of reconstructed input data. In order to evaluate the proposed framework, we conducted an experiment that mimics an object slip by a mobile service robot operating in a real-world environment with diverse household objects and different moving patterns. The experimental results verified that the proposed framework reliably detects anomalies in object slip situations despite various object types and robot behaviors, and visual and auditory noise in the environment.",
        "primary_area": "",
        "author": "Youngjae Yoo;Chung-Yeon Lee;Byoung-Tak Zhang;Youngjae Yoo;Chung-Yeon Lee;Byoung-Tak Zhang",
        "authorids": "/37088998747;/37088229821;/37336068500;/37088998747;/37088229821;/37336068500",
        "aff": "Interdisciplinary Program in Neuroscience, Seoul National University; Surromind Inc., Seoul, Korea; Dept. of Computer Science and Engineering, Seoul National University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561586/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3136101893141510115&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Seoul National University;Surromind Inc.",
        "aff_unique_dep": "Interdisciplinary Program in Neuroscience;",
        "aff_unique_url": "https://www.snu.ac.kr;",
        "aff_unique_abbr": "SNU;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561441",
        "title": "Multimodal Scale Consistency and Awareness for Monocular Self-Supervised Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Dense depth estimation is essential to scene-understanding for autonomous driving. However, recent self-supervised approaches on monocular videos suffer from scale-inconsistency across long sequences. Utilizing data from the ubiquitously copresent global positioning systems (GPS), we tackle this challenge by proposing a dynamically-weighted GPS-to-Scale (g2s) loss to complement the appearance-based losses. We emphasize that the GPS is needed only during the multimodal training, and not at inference. The relative distance between frames captured through the GPS provides a scale signal that is independent of the camera setup and scene distribution, resulting in richer learned feature representations. Through extensive evaluation on multiple datasets, we demonstrate scale-consistent and -aware depth estimation during inference, improving the performance even when training with low-frequency GPS data.",
        "primary_area": "",
        "author": "Hemang Chawla;Arnav Varma;Elahe Arani;Bahram Zonooz;Hemang Chawla;Arnav Varma;Elahe Arani;Bahram Zonooz",
        "authorids": "/37088595013;/37088998385;/37088597781;/37088596827;/37088595013;/37088998385;/37088597781;/37088596827",
        "aff": "The Advanced Research Lab, Navinfo Europe, The Netherlands; The Advanced Research Lab, Navinfo Europe, The Netherlands; The Advanced Research Lab, Navinfo Europe, The Netherlands; The Advanced Research Lab, Navinfo Europe, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561441/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4555976681209624645&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "NavInfo Europe",
        "aff_unique_dep": "The Advanced Research Lab",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9561910",
        "title": "Multimodal dynamics modeling for off-road autonomous vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Dynamics modeling in outdoor and unstructured environments is difficult because different elements in the environment interact with the robot in ways that can be hard to predict. Leveraging multiple sensors to perceive maximal information about the robot\u2019s environment is thus crucial when building a model to perform predictions about the robot\u2019s dynamics with the goal of doing motion planning. We design a model capable of long-horizon motion predictions, leveraging vision, lidar and proprioception, which is robust to arbitrarily missing modalities at test time. We demonstrate in simulation that our model is able to leverage vision to predict traction changes. We then test our model using a real-world challenging dataset of a robot navigating through a forest, performing predictions in trajectories unseen during training. We try different modality combinations at test time and show that, while our model performs best when all modalities are present, it is still able to perform better than the baseline even when receiving only raw vision input and no proprioception, as well as when only receiving proprioception. Overall, our study demonstrates the importance of leveraging multiple sensors when doing dynamics modeling in outdoor conditions.",
        "primary_area": "",
        "author": "Jean-Fran\u00e7ois Tremblay;Travis Manderson;Aur\u00e9lio Noca;Gregory Dudek;David Meger;Jean-Fran\u00e7ois Tremblay;Travis Manderson;Aur\u00e9lio Noca;Gregory Dudek;David Meger",
        "authorids": "/37088998947;/38491501400;/37089000551;/37274057100;/37542891800;/37088998947;/38491501400;/37089000551;/37274057100;/37542891800",
        "aff": "Mobile Robotics Laboratory (MRL), McGill University, Montr\u00e9al, Canada; Mobile Robotics Laboratory (MRL), McGill University, Montr\u00e9al, Canada; Mobile Robotics Laboratory (MRL), McGill University, Montr\u00e9al, Canada; Mobile Robotics Laboratory (MRL), McGill University, Montr\u00e9al, Canada; Mobile Robotics Laboratory (MRL), McGill University, Montr\u00e9al, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561910/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11789949723678710182&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "McGill University",
        "aff_unique_dep": "Mobile Robotics Laboratory (MRL)",
        "aff_unique_url": "https://www.mcgill.ca",
        "aff_unique_abbr": "McGill",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Montr\u00e9al",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561124",
        "title": "Multiple-Place Swarm Foraging with Dynamic Robot Chains",
        "track": "main",
        "status": "Poster",
        "abstract": "The goal of foraging robot swarms is to search and deliver resources to a specific central collection zone quickly. In the previously proposed multiple-place foraging algorithm with dynamic depots, foraging performance decreases as search areas and swarm sizes increase: depots need to travel long distances to deliver resources to the center, and more robots produce more congestion on their journeys. We propose a novel extension to the multiple-place foraging in which multiple robot chains are deployed dynamically. Each robot chain connects a foraging location to the central collection zone. Instead of delivering resources by a single robot, resources are passed on robot chains from foraging locations to the center directly such that congestion near the central collection zone can be avoided. Dynamic robot chains can also relocate themselves to get closer to the resources while avoiding obstacles. We simulate our robot swarms in the robot simulator ARGoS. Our experiments show that robots using the MPFA with dynamic chains outperform the MPFA with dynamic depots and have less congestion.",
        "primary_area": "",
        "author": "Dohee Lee;Qi Lu;Tsz-Chiu Au;Dohee Lee;Qi Lu;Tsz-Chiu Au",
        "authorids": "/37088998317;/37086209357;/37597553100;/37088998317;/37086209357;/37597553100",
        "aff": "Department of Computer Science and Engineering, Ulsan National Institute of Science and Technology (UNIST), South Korea; Department of Computer Science, The University of Texas, San Antonio, USA; Department of Computer Science and Engineering, Ulsan National Institute of Science and Technology (UNIST), South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561124/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12553281937876056344&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Ulsan National Institute of Science and Technology;University of Texas, San Antonio",
        "aff_unique_dep": "Department of Computer Science and Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.unist.ac.kr;https://www.utsa.edu",
        "aff_unique_abbr": "UNIST;UTSA",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Ulsan;San Antonio",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "South Korea;United States"
    },
    {
        "id": "9561015",
        "title": "Multiplexing Robot Experiments: Theoretical Underpinnings, Conditions for Existence, and Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "Scores of papers show, given some robots, how to improve the useful work they perform. Continuing this line, we consider the efficiency of robot experiments by examining the feasibility of conducting several experiments simultaneously, interleaving execution and sharing resources between them. This paper lays theoretical groundwork for that concept and demonstrates its feasibility and utility.",
        "primary_area": "",
        "author": "Rachel A. Moan;Dylan A. Shell;Jason M. O\u2019Kane;Rachel A. Moan;Dylan A. Shell;Jason M. O\u2019Kane",
        "authorids": "/37088505980;/37269198900;/37279835400;/37088505980;/37269198900;/37279835400",
        "aff": "Department of Computer Science, Winthrop University, Rock Hill, South Carolina, USA; Department of Computer Science and Engineering, Texas A&M University, College Station, Texas, USA; Department of Computer Science and Engineering, University of South Carolina, Columbia, South Carolina, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561015/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:TnvecMpnVzAJ:scholar.google.com/&scioq=Multiplexing+Robot+Experiments:+Theoretical+Underpinnings,+Conditions+for+Existence,+and+Demonstrations&hl=en&as_sdt=0,33",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Winthrop University;Texas A&M University;University of South Carolina",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science and Engineering;Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.winthrop.edu;https://www.tamu.edu;https://www.sc.edu",
        "aff_unique_abbr": ";TAMU;USC",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Rock Hill;College Station;Columbia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562039",
        "title": "Multiresolution Representations for Large-Scale Terrain with Local Gaussian Process Regression",
        "track": "main",
        "status": "Poster",
        "abstract": "To address the problem of building accurate and coherent models for large-scale terrains from incomplete and noisy sensor data, this paper proposes a novel framework that can efficiently infer terrain structures by divisionally providing the best linear unbiased estimates for the elevation values. To avoid data ambiguity caused by the uncertainty of sensor data, the proposed method introduces elevation filtering to extract the terrain surfaces, which reduces the amount of data greatly while the contained terrain information is basically unchanged. Then, for the large-scale terrains, the Gaussian mixture model is used to divide the interested regions, which remarkably improves the prediction accuracy and speed. Finally, for each subregion, a gaussian process regression model based on the static kernel is used to create a multiresolution terrain representation, which can deal with incompleteness of sensor data by considering the spatial correlations of the terrain. Evaluations of the proposed technique were conducted on diverse large-scale field terrains, including the quarry, planetary emulation terrain and highland, showing that the proposed method outperforms the state-of-art terrain modeling techniques in terms of the prediction accuracy, computation speed and memory consumption. As a practical application, the path planning problem was explored based on this terrain modeling technique to produce a better path.",
        "primary_area": "",
        "author": "Xu Liu;Decai Li;Yuqing He;Xu Liu;Decai Li;Yuqing He",
        "authorids": "/37086945181;/37086182699;/37288326300;/37086945181;/37086182699;/37288326300",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China; Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences, Shenyang, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562039/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7075846591558568863&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_unique_dep": ";Institutes for Robotics and Intelligent Manufacturing",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.cas.cn",
        "aff_unique_abbr": "UCAS;CAS",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Beijing;Shenyang",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560875",
        "title": "Muscular stimulation based biological actuator from locust\u2019s hindleg",
        "track": "main",
        "status": "Poster",
        "abstract": "The development and control of biological actuators have been an active research field. Biological actuators revealed high mobility with compact dimensions, which is critical for the design of microrobots. The powerful kicking motion of the locust is important for its quick jumping. Herein, we examined the kicking process of the locust\u2019s hindleg and controlled the flexion and extension motions via exogenous stimulation. Unlike a simple extension of the leg, co-contraction is adopted by locust to store energy and increase jumping power. Thus, we imitated the co-contraction process and transformed the locust\u2019s hindleg into a biological jumping actuator. Through coordinating the kicking of bilateral hindlegs together, we achieved the jumping control of a locust.",
        "primary_area": "",
        "author": "Songsong Ma;Peng Liu;Shen Liu;Yao Li;Bing Li;Songsong Ma;Peng Liu;Shen Liu;Yao Li;Bing Li",
        "authorids": "/37088996777;/37086298431;/37088997564;/37088420142;/37405869400;/37088996777;/37086298431;/37088997564;/37088420142;/37405869400",
        "aff": "State Key Laboratory of Robotics and Systems, Harbin Institute of Technology, Shenzhen, China; State Key Laboratory of Robotics and Systems, Harbin Institute of Technology, Shenzhen, China; State Key Laboratory of Robotics and Systems, Harbin Institute of Technology, Shenzhen, China; State Key Laboratory of Robotics and Systems, Harbin Institute of Technology, Shenzhen, China; State Key Laboratory of Robotics and Systems, Harbin Institute of Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560875/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15417425047800163830&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Harbin Institute of Technology",
        "aff_unique_dep": "State Key Laboratory of Robotics and Systems",
        "aff_unique_url": "http://www.hit.edu.cn/",
        "aff_unique_abbr": "HIT",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561931",
        "title": "Mutation Sensitive Correlation Filter for Real-Time UAV Tracking with Adaptive Hybrid Label",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned aerial vehicle (UAV) based visual tracking has been confronted with numerous challenges, e.g., object motion and occlusion. These challenges generally introduce unexpected mutations of target appearance and result in tracking failure. However, prevalent discriminative correlation filter (DCF) based trackers are insensitive to target mutations due to a predefined label, which concentrates on merely the centre of the training region. Meanwhile, appearance mutations caused by occlusion or similar objects usually lead to the inevitable learning of wrong information. To cope with appearance mutations, this paper proposes a novel DCF-based method to enhance the sensitivity and resistance to mutations with an adaptive hybrid label, i.e., MSCF. The ideal label is optimized jointly with the correlation filter and remains temporal consistency. Besides, a novel measurement of mutations called mutation threat factor (MTF) is applied to correct the label dynamically. Considerable experiments are conducted on widely used UAV benchmarks. The results indicate that the performance of MSCF tracker surpasses other 26 state-of-the- art DCF-based and deep-based trackers. With a real-time speed of ~38 frames/s, the proposed approach is sufficient for UAV tracking commissions.",
        "primary_area": "",
        "author": "Guangze Zheng;Changhong Fu;Junjie Ye;Fuling Lin;Fangqiang Ding;Guangze Zheng;Changhong Fu;Junjie Ye;Fuling Lin;Fangqiang Ding",
        "authorids": "/37088996628;/37086797986;/37088917418;/37088212953;/37088456219;/37088996628;/37086797986;/37088917418;/37088212953;/37088456219",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China; School of Mechanical Engineering, Tongji University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561931/",
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1371365679504233103&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tongji University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn",
        "aff_unique_abbr": "Tongji",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560932",
        "title": "NDT-Transformer: Large-Scale 3D Point Cloud Localisation using the Normal Distribution Transform Representation",
        "track": "main",
        "status": "Poster",
        "abstract": "3D point cloud-based place recognition is highly demanded by autonomous driving in GPS-challenged environments and serves as an essential component (i.e. loop-closure detection) in lidar-based SLAM systems. This paper proposes a novel approach, named NDT-Transformer, for real-time and large-scale place recognition using 3D point clouds. Specifically, a 3D Normal Distribution Transform (NDT) representation is employed to condense the raw, dense 3D point cloud as probabilistic distributions (NDT cells) to provide the geometrical shape description. Then a novel NDT-Transformer network learns a global descriptor from a set of 3D NDT cell representations. Benefiting from the NDT representation and NDT-Transformer network, the learned global descriptors are enriched with both geometrical and contextual information. Finally, descriptor retrieval is achieved using a query-database for place recognition. Compared to the state-of-the-art methods, the proposed approach achieves an improvement of 7.52% on average top 1 recall and 2.73% on average top 1% recall on the Oxford Robotcar benchmark.",
        "primary_area": "",
        "author": "Zhicheng Zhou;Cheng Zhao;Daniel Adolfsson;Songzhi Su;Yang Gao;Tom Duckett;Li Sun;Zhicheng Zhou;Cheng Zhao;Daniel Adolfsson;Songzhi Su;Yang Gao;Tom Duckett;Li Sun",
        "authorids": "/37088999713;/37085614336;/37086335293;/37539584700;/37089265450;/37419160900;/37086401506;/37088999713;/37085614336;/37086335293;/37539584700;/37089265450;/37419160900;/37086401506",
        "aff": "Visual Computing Group, University of Sheffield, UK; Department of Engineering Science, University of Oxford, UK; AASS Mobile Robotics Lab, Orebro University, Sweden; IMT Lab, Xiamen University, China; STAR LAB, Surrey Space Centre, University of Surrey, UK; Lincoln Centre for Autonomous Systems, University of Lincoln, UK; Visual Computing Group, University of Sheffield, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560932/",
        "gs_citation": 117,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15904575962956440138&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 13,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;3;4;5;0",
        "aff_unique_norm": "University of Sheffield;University of Oxford;Orebro University;Xiamen University;University of Surrey;University of Lincoln",
        "aff_unique_dep": "Visual Computing Group;Department of Engineering Science;AASS Mobile Robotics Lab;IMT Lab;Surrey Space Centre;Lincoln Centre for Autonomous Systems",
        "aff_unique_url": "https://www.sheffield.ac.uk;https://www.ox.ac.uk;https://www.oru.se;https://www.xmu.edu.cn;https://www.surrey.ac.uk;https://www.lincoln.ac.uk",
        "aff_unique_abbr": ";Oxford;;;UoS;",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Xiamen;Guildford",
        "aff_country_unique_index": "0;0;1;2;0;0;0",
        "aff_country_unique": "United Kingdom;Sweden;China"
    },
    {
        "id": "9561436",
        "title": "NF-iSAM: Incremental Smoothing and Mapping via Normalizing Flows",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel non-Gaussian inference algorithm, Normalizing Flow iSAM (NF-iSAM), for solving SLAM problems with non-Gaussian factors and/or non-linear measurement models. NF-iSAM exploits the expressive power of neural networks, and trains normalizing flows to draw samples from the joint posterior of non-Gaussian factor graphs. By leveraging the Bayes tree, NF-iSAM is able to exploit the sparsity structure of SLAM, thus enabling efficient incremental updates similar to iSAM2, albeit in the more challenging non- Gaussian setting. We demonstrate the performance of NF-iSAM and compare it against the state-of-the-art algorithms such as iSAM2 (Gaussian) and mm-iSAM (non-Gaussian) in synthetic and real range-only SLAM datasets.",
        "primary_area": "",
        "author": "Qiangqiang Huang;Can Pu;Dehann Fourie;Kasra Khosoussi;Jonathan P. How;John J. Leonard;Qiangqiang Huang;Can Pu;Dehann Fourie;Kasra Khosoussi;Jonathan P. How;John J. Leonard",
        "authorids": "/37089002085;/37088996130;/37670490400;/37085362096;/37276347700;/37329387400;/37089002085;/37088996130;/37670490400;/37085362096;/37276347700;/37329387400",
        "aff": "MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT Department of Nuclear Science and Engineering, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA; MIT Department of Aeronautical and Astronautical Engineering, Cambridge, MA, USA; MIT Department of Aeronautical and Astronautical Engineering, Cambridge, MA, USA; MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561436/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16066280820229300740&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560951",
        "title": "NavRep: Unsupervised Representations for Reinforcement Learning of Robot Navigation in Dynamic Human Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot navigation is a task where reinforcement learning approaches are still unable to compete with traditional path planning. State-of-the-art methods differ in small ways, and do not all provide reproducible, openly available implementations. This makes comparing methods a challenge. Recent research has shown that unsupervised learning methods can scale impressively, and be leveraged to solve difficult problems. In this work, we design ways in which unsupervised learning can be used to assist reinforcement learning for robot navigation. We train two end-to-end, and 18 unsupervised-learning-based architectures, and compare them, along with existing approaches, in unseen test cases. We demonstrate our approach working on a real life robot. Our results show that unsupervised learning methods are competitive with end-to-end methods. We also highlight the importance of various components such as input representation, predictive unsupervised learning, and latent features. We make all our models publicly available, as well as training and testing environments, and tools 1. This release also includes OpenAI-gym-compatible environments designed to emulate the training conditions described by other papers, with as much fidelity as possible. Our hope is that this helps in bringing together the field of RL for robot navigation, and allows meaningful comparisons across state-of-the-art methods.",
        "primary_area": "",
        "author": "Daniel Dugas;Juan Nieto;Roland Siegwart;Jen Jen Chung;Daniel Dugas;Juan Nieto;Roland Siegwart;Jen Jen Chung",
        "authorids": "/37086030360;/37085778635;/37281398300;/37085668354;/37086030360;/37085778635;/37281398300;/37085668354",
        "aff": "Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560951/",
        "gs_citation": 71,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4908164304891972469&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561009",
        "title": "Near-Optimal Multi-Robot Motion Planning with Finite Sampling",
        "track": "main",
        "status": "Poster",
        "abstract": "An underlying structure in several sampling-based methods for continuous multi-robot motion planning (MRMP) is the tensor roadmap (PR), which emerges from combining multiple PRM graphs constructed for the individual robots via a tensor product. We study the conditions under which the TR encodes a near-optimal solution for MRMP\u2014satisfying these conditions implies near optimality for a variety of popular planners, including dRRT*, and the discrete methods M* and CBS when applied to the continuous domain. We develop the first finite-sample analysis of this kind, which specifies the number of samples, their deterministic distribution, and magnitude of the connection radii that should be used by each individual PRM graph, to guarantee near-optimality using the TR. This significantly improves upon a previous asymptotic analysis, wherein the number of samples tends to infinity. Our new finite sample-size analysis supports guaranteed high- quality solutions in practice within finite time. To achieve our new result, we first develop a sampling scheme, which we call the staggered grid, for finite-sample motion planning for individual robots, which requires significantly less samples than previous work. We then extend it to the much more involved MRMP setting which requires to account for interactions among multiple robots. Finally, we report on a few experiments that serve as a verification of our theoretical findings and raise interesting questions for further investigation.",
        "primary_area": "",
        "author": "Dror Dayan;Kiril Solovey;Marco Pavone;Dan Halperin;Dror Dayan;Kiril Solovey;Marco Pavone;Dan Halperin",
        "authorids": "/37089000088;/37085671184;/37307912900;/37355669200;/37089000088;/37085671184;/37307912900;/37355669200",
        "aff": "Blavatnik School of Computer Science, Tel-Aviv University, Israel; Aeronautics and Astronautics Department, Stanford University, CA, USA; Aeronautics and Astronautics Department, Stanford University, CA, USA; Blavatnik School of Computer Science, Tel-Aviv University, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561009/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9893123012428401862&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Tel-Aviv University;Stanford University",
        "aff_unique_dep": "Blavatnik School of Computer Science;Aeronautics and Astronautics Department",
        "aff_unique_url": "https://www.tau.ac.il;https://www.stanford.edu",
        "aff_unique_abbr": "TAU;Stanford",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Tel-Aviv;Stanford",
        "aff_country_unique_index": "0;1;1;0",
        "aff_country_unique": "Israel;United States"
    },
    {
        "id": "9560972",
        "title": "Neighborhood Spatial Aggregation based Efficient Uncertainty Estimation for Point Cloud Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Uncertainty estimation for point cloud semantic segmentation is to quantify the confidence degree for the predicted label of points, which is essential for decision-making tasks. This paper proposes a neighborhood spatial aggregation based method, NSA-MC dropout, to achieve efficient uncertainty estimation for point cloud semantic segmentation. Unlike the traditional uncertainty estimation method MC dropout de-pending on repeated inferences, our NSA-MC dropout achieves uncertainty estimation through one-time inference. Specifically, a space-dependent method is designed to sample the model many times by performing stochastic forward pass through the model just once, and it approximates the repeated inferences based sampling process in MC dropout. Besides, a neighborhood spatial aggregation module, called NSA, aggregates neighborhood probabilistic outputs for each point and works with space-dependent sampling to establish output distribution. Finally, we propose an uncertainty-aware framework NSA-MC dropout to capture the uncertainty of prediction results efficiently. Experimental results show that our method obtains comparable performance with MC dropout. More significantly, our NSA-MC dropout has little influence on the efficiency of semantic inference. It is much faster than MC dropout, and the inference time does not establish a coupling relation with the sampling times. Our code is available at https://github.com/chaoqi7/Uncertainty_Estimation_PCSS",
        "primary_area": "",
        "author": "Chao Qi;Jianqin Yin;Huaping Liu;Jun Liu;Chao Qi;Jianqin Yin;Huaping Liu;Jun Liu",
        "authorids": "/37088437493;/37086285976;/37310126400;/37086847579;/37088437493;/37086285976;/37310126400;/37086847579",
        "aff": "Standard and Metrology Research Institute, China Academy of Railway Sciences Corporation Limited, Beijing, China; School of Artificial Intelligence, Beijing University of Posts and Telecommunications, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; City University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560972/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1194515677525457091&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "China Academy of Railway Sciences Corporation Limited;Beijing University of Posts and Telecommunications;Tsinghua University;City University of Hong Kong",
        "aff_unique_dep": "Standard and Metrology Research Institute;School of Artificial Intelligence;Department of Computer Science and Technology;",
        "aff_unique_url": "http://www.carsc.cn;http://www.bupt.edu.cn/;https://www.tsinghua.edu.cn;https://www.cityu.edu.hk",
        "aff_unique_abbr": "CARS;BUPT;THU;CityU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561804",
        "title": "Neural Network Controller for Autonomous Pile Loading Revised",
        "track": "main",
        "status": "Poster",
        "abstract": "We have recently proposed two pile loading controllers that learn from human demonstrations: a neural network (NNet) [1] and a random forest (RF) controller [2]. In the field experiments the RF controller obtained clearly better success rates. In this work, the previous findings are drastically revised by experimenting summer time trained controllers in winter conditions. The winter experiments revealed a need for additional sensors, more training data, and a controller that can take advantage of these. Therefore, we propose a revised neural controller (NNetV2) which has a more expressive structure and uses a neural attention mechanism to focus on important parts of the sensor and control signals. Using the same data and sensors to train and test the three controllers, NNetV2 achieves better robustness against drastically changing conditions and superior success rate. To the best of our knowledge, this is the first work testing a learning-based controller for a heavy-duty machine in drastically varying outdoor conditions and delivering high success rate in winter, being trained in summer.",
        "primary_area": "",
        "author": "Wenyan Yang;Nataliya Strokina;Nikolay Serbenyuk;Joni Pajarinen;Reza Ghabcheloo;Juho Vihonen;Mohammad M. Aref;Joni-Kristian K\u00e4m\u00e4r\u00e4inen;Wenyan Yang;Nataliya Strokina;Nikolay Serbenyuk;Joni Pajarinen;Reza Ghabcheloo;Juho Vihonen;Mohammad M. Aref;Joni-Kristian K\u00e4m\u00e4r\u00e4inen",
        "authorids": "/37088505300;/38548263900;/37088506966;/37398592200;/37298989400;/37401528900;/37544330600;/37268498700;/37088505300;/38548263900;/37088506966;/37398592200;/37298989400;/37401528900;/37544330600;/37268498700",
        "aff": "Computing Sciences, Tampere University, Finland; Computing Sciences, Tampere University, Finland; Automation Technology and Mechanical Engineering, Tampere University; Intelligent Autonomous Systems, Technische Universit\u00e4t, Darmstadt, Germany; Automation Technology and Mechanical Engineering, Tampere University; Cargotec Oyj; Cargotec Oyj; Computing Sciences, Tampere University, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561804/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5479083292656557656&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;0;2;2;0",
        "aff_unique_norm": "Tampere University;Technische Universit\u00e4t Darmstadt;Cargotec",
        "aff_unique_dep": "Computing Sciences;Intelligent Autonomous Systems;",
        "aff_unique_url": "https://www.tuni.fi;https://www.tu-darmstadt.de;https://www.cargotec.com",
        "aff_unique_abbr": ";TUD;Cargotec",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Darmstadt",
        "aff_country_unique_index": "0;0;0;1;0;0;0;0",
        "aff_country_unique": "Finland;Germany"
    },
    {
        "id": "9561733",
        "title": "Neural fidelity warping for efficient robot morphology design",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of optimizing a robot morphology to achieve the best performance for a target task, under computational resource limitations. The evaluation process for each morphological design involves learning a controller for the design, which can consume substantial time and computational resources. To address the challenge of expensive robot morphology evaluation, we present a continuous multi-fidelity Bayesian Optimization framework that efficiently utilizes computational resources via low-fidelity evaluations. We identify the problem of non-stationarity over fidelity space. Our proposed fidelity warping mechanism can learn representations of learning epochs and tasks to model non-stationary covariances between continuous fidelity evaluations which prove challenging for off-the-shelf stationary kernels. Various experiments demonstrate that our method can utilize the low-fidelity evaluations to efficiently search for the optimal robot morphology, outperforming state-of-the-art methods.",
        "primary_area": "",
        "author": "Sha Hu;Zeshi Yang;Greg Mori;Sha Hu;Zeshi Yang;Greg Mori",
        "authorids": "/37088686620;/37088998218;/37279179700;/37088686620;/37088998218;/37279179700",
        "aff": "School of Computing Science, Simon Fraser University, BC, CA; School of Computing Science, Simon Fraser University, BC, CA; School of Computing Science, Simon Fraser University, BC, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561733/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13534412211793626222&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Simon Fraser University",
        "aff_unique_dep": "School of Computing Science",
        "aff_unique_url": "https://www.sfu.ca",
        "aff_unique_abbr": "SFU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "BC",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9560935",
        "title": "NeuralSim: Augmenting Differentiable Simulators with Neural Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Differentiable simulators provide an avenue for closing the sim-to-real gap by enabling the use of efficient, gradient-based optimization algorithms to find the simulation parameters that best fit the observed sensor readings. Nonetheless, these analytical models can only predict the dynamical behavior of systems for which they have been designed. In this work, we study the augmentation of a novel differentiable rigid-body physics engine via neural networks that is able to learn nonlinear relationships between dynamic quantities and can thus model effects not accounted for in traditional simulators. Such augmentations require less data to train and generalize better compared to entirely data-driven models. Through extensive experiments, we demonstrate the ability of our hybrid simulator to learn complex dynamics involving frictional contacts from real data, as well as match known models of viscous friction, and present an approach for automatically discovering useful augmentations. We show that, besides benefiting dynamics modeling, inserting neural networks can accelerate model-based control architectures. We observe a ten-fold speedup when replacing the QP solver inside a model-predictive gait controller for quadruped robots with a neural network, allowing us to significantly improve control delays as we demonstrate in real-hardware experiments. We publish code, additional results and videos from our experiments on our project webpage at https://sites.google.com/usc.edu/neuralsim.",
        "primary_area": "",
        "author": "Eric Heiden;David Millard;Erwin Coumans;Yizhou Sheng;Gaurav S. Sukhatme;Eric Heiden;David Millard;Erwin Coumans;Yizhou Sheng;Gaurav S. Sukhatme",
        "authorids": "/37990849700;/37088996818;/37086455409;/37088999458;/37278934100;/37990849700;/37088996818;/37086455409;/37088999458;/37278934100",
        "aff": "Department of Computer Science, University of Southern California, Los Angeles, USA; Department of Computer Science, University of Southern California, Los Angeles, USA; Robotics at Google, Mountain View, USA; Department of Computer Science, University of Southern California, Los Angeles, USA; G.S. Sukhatme holds concurrent appointments as a Professor at USC and as an Amazon Scholar",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560935/",
        "gs_citation": 189,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12831209110346889172&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Southern California;Google",
        "aff_unique_dep": "Department of Computer Science;Robotics",
        "aff_unique_url": "https://www.usc.edu;https://www.google.com",
        "aff_unique_abbr": "USC;Google",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Los Angeles;Mountain View;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560937",
        "title": "Neuromorphic control for optic-flow-based landing of MAVs using the Loihi processor",
        "track": "main",
        "status": "Poster",
        "abstract": "Neuromorphic processors like Loihi offer a promising alternative to conventional computing modules for endowing constrained systems like micro air vehicles (MAVs) with robust, efficient and autonomous skills such as take-off and landing, obstacle avoidance, and pursuit. However, a major challenge for using such processors on robotic platforms is the reality gap between simulation and the real world. In this study, we present for the very first time a fully embedded application of the Loihi neuromorphic chip prototype in a flying robot. A spiking neural network (SNN) was evolved to compute the thrust command based on the divergence of the ventral optic flow field to perform autonomous landing. Evolution was performed in a Python-based simulator using the PySNN library. The resulting network architecture consists of only 35 neurons distributed among 3 layers. Quantitative analysis between simulation and Loihi reveals a root-mean-square error of the thrust setpoint as low as 0.005 g, along with a 99.8% matching of the spike sequences in the hidden layer, and 99.7% in the output layer. The proposed approach successfully bridges the reality gap, offering important insights for future neuromorphic applications in robotics. Supplementary material is available at https://mavlab.tudelft.nl/loihi/.",
        "primary_area": "",
        "author": "Julien Dupeyroux;Jesse J. Hagenaars;Federico Paredes-Vall\u00e9s;Guido C. H. E. de Croon;Julien Dupeyroux;Jesse J. Hagenaars;Federico Paredes-Vall\u00e9s;Guido C. H. E. de Croon",
        "authorids": "/37086222518;/37088466615;/37088432114;/37698062600;/37086222518;/37088466615;/37088432114;/37698062600",
        "aff": "Faculty of Aerospace Engineering, Micro Air Vehicle Lab, Delft University of Technology, The Netherlands; Faculty of Aerospace Engineering, Micro Air Vehicle Lab, Delft University of Technology, The Netherlands; Faculty of Aerospace Engineering, Micro Air Vehicle Lab, Delft University of Technology, The Netherlands; Faculty of Aerospace Engineering, Micro Air Vehicle Lab, Delft University of Technology, The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560937/",
        "gs_citation": 59,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8860085454930762872&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Delft University of Technology",
        "aff_unique_dep": "Faculty of Aerospace Engineering",
        "aff_unique_url": "https://www.tudelft.nl",
        "aff_unique_abbr": "TU Delft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9561178",
        "title": "No Face-Touch: Exploiting Wearable Devices and Machine Learning for Gesture Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Avoiding face-touches has been one of the most common medical recommendations since the beginning of the COVID-19 pandemic. This work aims at providing people with help in contrasting this widespread, yet noxious habit. The solution we present exploits wearable devices to detect hand motions ending up into a face-touch and promptly notify the user exploiting haptic feedback. To this aim, we propose a recurrent neural network taking as input temporal sequences of accelerometer data acquired by a smartwatch worn by the user. The trained RNN (NFT_RNN) achieves good generalization capabilities to data coming from different users, besides a lower false detections rate with respect to a rule-based detection algorithm. The suggested solution is ready-to-use and large-scale deployable, being portable on smartwatches, fitness bands and DIY devices.",
        "primary_area": "",
        "author": "S. Marullo;T. Lisini Baldi;G. Paolocci;N. D\u2019Aurizio;D. Prattichizzo;S. Marullo;T. Lisini Baldi;G. Paolocci;N. D\u2019Aurizio;D. Prattichizzo",
        "authorids": "/37088231697;/37085368775;/37088397767;/37088396379;/37276309600;/37088231697;/37085368775;/37088397767;/37088396379;/37276309600",
        "aff": "Department of Advanced Robotics (ADVR), Istituto Italiano di Tecnologia, Genova, Italy; Department of Information Engineering and Mathematics, University of Siena, Siena, Italy; Department of Advanced Robotics (ADVR), Istituto Italiano di Tecnologia, Genova, Italy; Department of Advanced Robotics (ADVR), Istituto Italiano di Tecnologia, Genova, Italy; Department of Advanced Robotics (ADVR), Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561178/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14242333665805854405&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Istituto Italiano di Tecnologia;University of Siena",
        "aff_unique_dep": "Department of Advanced Robotics (ADVR);Department of Information Engineering and Mathematics",
        "aff_unique_url": "https://www.iit.it;https://www.unisi.it",
        "aff_unique_abbr": "IIT;",
        "aff_campus_unique_index": "0;1;0;0;0",
        "aff_campus_unique": "Genova;Siena",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9561635",
        "title": "No Need for Interactions: Robust Model-Based Imitation Learning using Neural ODE",
        "track": "main",
        "status": "Poster",
        "abstract": "Interactions with either environments or expert policies during training are needed for most of the current imitation learning (IL) algorithms. For IL problems with no interactions, a typical approach is Behavior Cloning (BC). However, BC-like methods tend to be affected by distribution shift. To mitigate this problem, we come up with a Robust Model-Based Imitation Learning (RMBIL) framework that casts imitation learning as an end-to-end differentiable nonlinear closed-loop tracking problem. RMBIL applies Neural ODE to learn a precise multi-step dynamics and a robust tracking controller via Nonlinear Dynamics Inversion (NDI) algorithm. Then, the learned NDI controller will be combined with a trajectory generator, a conditional VAE, to imitate an expert\u2019s behavior. Theoretical derivation shows that the controller network can approximate an NDI when minimizing the training loss of Neural ODE. Experiments on Mujoco tasks also demonstrate that RMBIL is competitive to the state-of-the-art generative adversarial method (GAIL) and achieves at least 30% performance gain over BC in uneven surfaces.",
        "primary_area": "",
        "author": "HaoChih Lin;Baopu Li;Xin Zhou;Jiankun Wang;Max Q.-H. Meng;HaoChih Lin;Baopu Li;Xin Zhou;Jiankun Wang;Max Q.-H. Meng",
        "authorids": "/37088997754;/37089546507;/37089001054;/37086100720;/37274117000;/37088997754;/37089546507;/37089001054;/37086100720;/37274117000",
        "aff": "ETH Zurich, Switzerland; Baidu Research(USA); Baidu Research(USA); Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Electronic Engineering, The Chinese University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561635/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15365614930983554405&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;3",
        "aff_unique_norm": "ETH Zurich;Baidu;Southern University of Science and Technology;Chinese University of Hong Kong",
        "aff_unique_dep": ";Baidu Research;Department of Electronic and Electrical Engineering;Department of Electronic Engineering",
        "aff_unique_url": "https://www.ethz.ch;https://research.baidu.com;https://www.sustech.edu.cn;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "ETHZ;Baidu Research;SUSTech;CUHK",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Shenzhen;Hong Kong SAR",
        "aff_country_unique_index": "0;1;1;2;2",
        "aff_country_unique": "Switzerland;United States;China"
    },
    {
        "id": "9560762",
        "title": "No-frills Dynamic Planning using Static Planners",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the task of interacting with dynamic environments where the changes in the environment are independent of the agent. We study this through the context of trapping a moving ball with a UR5 robotic arm. Our key contribution is an approach to utilize a static planner for dynamic tasks using a Dynamic Planning add-on; that is, if we can successfully solve a task with a static target, then our approach can solve the same task when the target is moving. Our approach has three key components: an off-the-shelf static planner, a trajectory forecasting network, and a network to predict robot\u2019s estimated time of arrival at any location. We demonstrate the generalization of our approach across environments. More information and videos at https://mlevy2525.github.io/DynamicAddOn/.",
        "primary_area": "",
        "author": "Mara Levy;Vasista Ayyagari;Abhinav Shrivastava;Mara Levy;Vasista Ayyagari;Abhinav Shrivastava",
        "authorids": "/37088999151;/37088998658;/37089272202;/37088999151;/37088998658;/37089272202",
        "aff": "University of Maryland, College Park; University of Maryland, College Park; University of Maryland, College Park",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560762/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:UYY7fat84swJ:scholar.google.com/&scioq=No-frills+Dynamic+Planning+using+Static+Planners&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Maryland",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www/umd.edu",
        "aff_unique_abbr": "UMD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "College Park",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561354",
        "title": "Non-Monotone Energy-Aware Information Gathering for Heterogeneous Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers the problem of planning trajectories for a team of sensor-equipped robots to reduce uncertainty about a dynamical process. Optimizing the trade-off between information gain and energy cost (e.g., control effort, distance travelled) is desirable but leads to a non-monotone objective function in the set of robot trajectories. Therefore, common multi-robot planning algorithms based on techniques such as coordinate descent lose their performance guarantees. Methods based on local search provide performance guarantees for optimizing a non-monotone submodular function, but require access to all robots\u2019 trajectories, making it not suitable for distributed execution. This work proposes a distributed planning approach based on local search and shows how lazy/greedy methods can be adopted to reduce the computation and communication of the approach. We demonstrate the efficacy of the proposed method by coordinating robot teams composed of both ground and aerial vehicles with different sensing/control profiles and evaluate the algorithm\u2019s performance in two target tracking scenarios. Compared to the naive distributed execution of local search, our approach saves up to 60% communication and 80\u201392% computation on average when coordinating up to 10 robots, while outperforming the coordinate descent based algorithm in achieving a desirable trade-off between sensing and energy cost.",
        "primary_area": "",
        "author": "Xiaoyi Cai;Brent Schlotfeldt;Kasra Khosoussi;Nikolay Atanasov;George J. Pappas;Jonathan P. How;Xiaoyi Cai;Brent Schlotfeldt;Kasra Khosoussi;Nikolay Atanasov;George J. Pappas;Jonathan P. How",
        "authorids": "/37087091424;/37086113948;/37085362096;/37670511000;/37281547100;/37276347700;/37087091424;/37086113948;/37085362096;/37670511000;/37281547100;/37276347700",
        "aff": "Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA; Electrical and Computer Engineering Department, University of California, San Diego, La Jolla, CA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561354/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9657592032738981986&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;University of Pennsylvania;University of California, San Diego",
        "aff_unique_dep": "Department of Aeronautics and Astronautics;GRASP Laboratory;Electrical and Computer Engineering Department",
        "aff_unique_url": "https://web.mit.edu;https://www.upenn.edu;https://www.ucsd.edu",
        "aff_unique_abbr": "MIT;UPenn;UCSD",
        "aff_campus_unique_index": "0;1;0;2;1;0",
        "aff_campus_unique": "Cambridge;Philadelphia;La Jolla",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561312",
        "title": "Nonlinear Disturbance Observer-based Robust Motion Control for Multi-joint Series Elastic Actuator-driven Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion control of multi-joint Series Elastic Actuator (SEA)-driven robots still faces challenges including intrinsic oscillatory dynamics, high-order robotic dynamics, low-bandwidth inner loop, and dynamic nonlinearities. In this letter, a nonlinear disturbance observer (NDOB)-based robust controller with the singular perturbation theory is proposed to perform stable and precise motion control of multi-joint SEA-driven robots. First, a fast-time control term is designed according to the singular perturbation theory to stabilize the SEA-level dynamics. Then, for the robot-level dynamics, a NDOB is designed to estimate the effects of unmodeled dynamics and external disturbance. The NDOB is combined with a baseline computed torque controller (CTC) to construct a composite controller NDOB-CTC. In addition, bounded stability is achieved with Lyapunov-type analysis. Finally, the proposed controller was implemented on a 2 DOFs SEA-driven robot. Comparative experiments were conducted for validations.",
        "primary_area": "",
        "author": "Shuaishuai Han;Haoping Wang;Haoyong Yu;Shuaishuai Han;Haoping Wang;Haoyong Yu",
        "authorids": "/37086158834;/37405995600;/37711526800;/37086158834;/37405995600;/37711526800",
        "aff": "School of Automation, Nanjing University of Science & Technology, Nanjing, China; School of Automation, Nanjing University of Science & Technology, Nanjing, China; Department of Biomedical Engineering, National University of Singapore, Singapore, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561312/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13718380040173586274&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Nanjing University of Science & Technology;National University of Singapore",
        "aff_unique_dep": "School of Automation;Department of Biomedical Engineering",
        "aff_unique_url": "http://www.nust.edu.cn;https://www.nus.edu.sg",
        "aff_unique_abbr": "NUST;NUS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nanjing;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "9561568",
        "title": "Nonlinear stiffness allows passive dynamic hopping for one-legged robots with an upright trunk",
        "track": "main",
        "status": "Poster",
        "abstract": "Template models are frequently used to simplify the control dynamics for robot hopping or running. Passive limit cycles can emerge for such systems and be exploited for energy-efficient control. A grand challenge in locomotion is trunk stabilization when the hip is offset from the center of mass (CoM). The swing phase plays a major role in this process due to the moment of inertia of the leg; however, many template models ignore the leg mass. In this work, the authors consider a robot hopper model (RHM) with a rigid trunk and leg plus a hip that is displaced from the CoM. It has been previously shown that no passive limit cycle exists for such a model given a linear hip spring. In this work, we show that passive limit cycles can be found when a nonlinear hip spring is used instead. To the authors\u2019 knowledge, this is the first time that a passive limit cycle has been found for this type of system.",
        "primary_area": "",
        "author": "Dennis Ossadnik;Elisabeth Jensen;Sami Haddadin;Dennis Ossadnik;Elisabeth Jensen;Sami Haddadin",
        "authorids": "/37086601649;/37967991000;/37542865300;/37086601649;/37967991000;/37542865300",
        "aff": "Chair of Robotics Science and Systems Intelligence (RSI), Munich School of Robotics and Machine Intelligence (MSRM), Technical University of Munich, Munich, Germany; Chair of Robotics Science and Systems Intelligence (RSI), Munich School of Robotics and Machine Intelligence (MSRM), Technical University of Munich, Munich, Germany; Chair of Robotics Science and Systems Intelligence (RSI), Munich School of Robotics and Machine Intelligence (MSRM), Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561568/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10104769913150808790&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Chair of Robotics Science and Systems Intelligence (RSI)",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561366",
        "title": "Not your grandmother\u2019s toolbox \u2013 the Robotics Toolbox reinvented for Python",
        "track": "main",
        "status": "Poster",
        "abstract": "For 25 years the Robotics Toolbox for MATLAB\u00ae has been used for teaching and research worldwide. This paper describes its successor \u2013 the Robotics Toolbox for Python. More than just a port, it takes advantage of popular open-source packages and resources to provide platform portability, fast browser-based 3D graphics, quality documentation, fast numerical and symbolic operations, powerful IDEs, shareable and web-browseable notebooks all powered by GitHub and the open-source community. The new Toolbox provides well-known functionality for spatial mathematics (homogeneous transformations, quaternions, triple angles and twists), trajectories, kinematics (zeroth to second order), dynamics and a rich assortment of robot models. In addition, we\u2019ve taken the opportunity to add new capabilities such as branched mechanisms, collision checking, URDF import, and interfaces to ROS. With familiar, simple yet powerful functions; the clarity of Python syntax; but without the complexity of ROS; users from beginner to advanced will find this a powerful open-source toolset for ongoing robotics education and research.",
        "primary_area": "",
        "author": "Peter Corke;Jesse Haviland;Peter Corke;Jesse Haviland",
        "authorids": "/37279654600;/37088698789;/37279654600;/37088698789",
        "aff": "Queensland University of Technology Centre for Robotics (QCR), Brisbane, Australia; Queensland University of Technology Centre for Robotics (QCR), Brisbane, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561366/",
        "gs_citation": 138,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10955874225032236448&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Queensland University of Technology",
        "aff_unique_dep": "Centre for Robotics",
        "aff_unique_url": "https://www.qut.edu.au",
        "aff_unique_abbr": "QUT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Brisbane",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9561773",
        "title": "Nth Order Analytical Time Derivatives of Inverse Dynamics in Recursive and Closed Forms",
        "track": "main",
        "status": "Poster",
        "abstract": "Derivatives of equations of motion describing the rigid body dynamics are becoming increasingly relevant for the robotics community and find many applications in design and control of robotic systems. Controlling robots, and multibody systems comprising elastic components in particular, not only requires smooth trajectories but also the time derivatives of the control forces/torques, hence of the equations of motion (EOM). This paper presents novel nth order time derivatives of the EOM in both closed and recursive forms. While the former provides a direct insight into the structure of these derivatives, the latter leads to their highly efficient implementation for large degree of freedom robotic system.",
        "primary_area": "",
        "author": "Shivesh Kumar;Andreas M\u00fcller;Shivesh Kumar;Andreas M\u00fcller",
        "authorids": "/37085850436;/37085636420;/37085850436;/37085636420",
        "aff": "Robotics Innovation Center, DFKI GmbH, Bremen, Germany; Institute of Robotics, Johannes Kepler University, Linz, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561773/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10191836407317215994&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "DFKI GmbH;Johannes Kepler University",
        "aff_unique_dep": "Robotics Innovation Center;Institute of Robotics",
        "aff_unique_url": "https://www.dfki.de;https://www.jku.at",
        "aff_unique_abbr": "DFKI;JKU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Bremen;Linz",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Germany;Austria"
    },
    {
        "id": "9561301",
        "title": "Numerical Simulation of an Untethered Omni-Directional Star-Shaped Swimming Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Simulating the swimming of soft underwater robot remains challenging due to the absence of an efficient numerical framework that can effectively capture the geometrically nonlinear deformation of soft materials and structures when interacting with a liquid environment. Here, we address this by introducing a discrete differential geometry-based model that incorporates an implicit treatment of the elasticity of soft limbs and a fluid model with three different components: hydrodynamic drag, jetting, and virtual added mass. The physical engine can run faster than real-time on a single thread desktop processor. We experimentally validate this numerical simulation tool by performing tests using an untethered omni-directional star-shaped swimming soft robot that is capable of moving with multiple swimming gaits. Quantitative agreement between experiment and simulation indicates the potential application of such a numerical framework for robot design and for model-based control schemes.",
        "primary_area": "",
        "author": "Xiaonan Huang;Weicheng Huang;Zachary Patterson;Zhijian Ren;M. Khalid Jawed;Carmel Majidi;Xiaonan Huang;Weicheng Huang;Zachary Patterson;Zhijian Ren;M. Khalid Jawed;Carmel Majidi",
        "authorids": "/37086805378;/37088999071;/37088688946;/37088488889;/37088686728;/37589572800;/37086805378;/37088999071;/37088688946;/37088488889;/37088686728;/37589572800",
        "aff": "Department of Mechanical Engineering, Soft Machines Lab, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA, USA; Department of Mechanical Engineering, Soft Machines Lab, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Soft Machines Lab, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical and Aerospace Engineering, University of California, Los Angeles, Los Angeles, CA, USA; Department of Mechanical Engineering, Soft Machines Lab, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561301/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2336874539015372957&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;1;0",
        "aff_unique_norm": "Carnegie Mellon University;University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.cmu.edu;https://www.ucla.edu",
        "aff_unique_abbr": "CMU;UCLA",
        "aff_campus_unique_index": "0;1;0;0;1;0",
        "aff_campus_unique": "Pittsburgh;Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562064",
        "title": "Numerical Simulations of A Novel Force Controller Serially Combining The Admittance and Impedance Controllers",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel force controller that serially combines admittance and impedance controllers. The proposed controller is adaptable to an unknown changeable environment in terms of stiffness, and it is able to achieve high control accuracy and stable operation. First, conventional admittance and impedance controllers are recalled, and based on them, a new force controller is designed. Next, the proposed controller is applied to a one DoF system in contact with an external environment in the case where the contact stiffness is changeable, and compare the behavior of the proposed controller with that of the conventional simple admittance and impedance controllers through numerical simulations. Additionally, the proposed controller is applied to a two DoFs system including some nonlinearities, and proposes a design of the desired anisotropic admittance and impedance parameters to the proposed controller. This effectiveness is also demonstrated through numerical simulation results.",
        "primary_area": "",
        "author": "Takuto Fujiki;Kenji Tahara;Takuto Fujiki;Kenji Tahara",
        "authorids": "/37089001212;/37542756300;/37089001212;/37542756300",
        "aff": "Department of Mechanical Engineering, Kyushu University, Fukuoka, Japan; Department of Mechanical Engineering, Kyushu University, Fukuoka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562064/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6816809150315541151&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Kyushu University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kyushu-u.ac.jp",
        "aff_unique_abbr": "Kyushu U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Fukuoka",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561280",
        "title": "OCR-based Inventory Management Algorithms Robust to Damaged Images",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate and fast inventory management algorithms are essential in the modern distribution industry. However, the configuration process of inventory management algorithms is very expensive, and the direct comprehensive management of inventory procedures is labor intensive and inaccurate. Therefore, in this paper, we propose an optical character recognition (OCR)-based inventory management algorithm to resolve these practical issues. The main purpose of our inventory management algorithm is to automatically inspect whether a list of items and the actual items match. To this end, our method consists of three steps, namely, text detection, text recognition, and text matching. In addition, to expand our algorithm to real-world applications, we propose adversarial training to ensure robustness against various damaged images, including corruption, blur, and inappropriate viewpoints. To train the network, we construct a new inventory management dataset (IMD) consisting of 10,000 sheets in real retail store environments. We verify our algorithm on the public dataset and our new IMD. As a result, we experimentally demonstrate that our method is not only robust against various damaged images but is also easily applicable in both large and small scale distributions stores at a low cost. Our code and dataset is available at https://blog.airlab.re.kr/Deform-and-Recover/.",
        "primary_area": "",
        "author": "Minseok Seo;Daehan Kim;Hyeyoon Kang;Donghyeon Cho;Dong-Geol Choi;Minseok Seo;Daehan Kim;Hyeyoon Kang;Donghyeon Cho;Dong-Geol Choi",
        "authorids": "/37088911458;/37088910428;/37089001218;/37085901990;/38542186000;/37088911458;/37088910428;/37089001218;/37085901990;/38542186000",
        "aff": "Department of Information and Communication Engineering, Hanbat National University, Daejeon, Republic of Korea; Department of Information and Communication Engineering, Hanbat National University, Daejeon, Republic of Korea; Department of Information and Communication Engineering, Hanbat National University, Daejeon, Republic of Korea; Department of Electronics Engineering, Chungnam National University, Daejeon, Republic of Korea; Department of Information and Communication Engineering, Hanbat National University, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561280/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8268923582148937384&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Hanbat National University;Chungnam National University",
        "aff_unique_dep": "Department of Information and Communication Engineering;Department of Electronics Engineering",
        "aff_unique_url": "http://www.hanbat.ac.kr;http://www.cnu.ac.kr",
        "aff_unique_abbr": "HNU;CNU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561516",
        "title": "Object Rearrangement Using Learned Implicit Collision Functions",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic object rearrangement combines the skills of picking and placing objects. When object models are unavailable, typical collision-checking models may be unable to predict collisions in partial point clouds with occlusions, making generation of collision-free grasping or placement trajectories challenging. We propose a learned collision model that accepts scene and query object point clouds and predicts collisions for 6DOF object poses within the scene. We train the model on a synthetic set of 1 million scene/object point cloud pairs and 2 billion collision queries. We leverage the learned collision model as part of a model predictive path integral (MPPI) policy in a tabletop rearrangement task and show that the policy can plan collision-free grasps and placements for objects unseen in training in both simulated and physical cluttered scenes with a Franka Panda robot. The learned model outperforms both traditional pipelines and learned ablations by 9.8% in accuracy on a dataset of simulated collision queries and is 75x faster than the best-performing baseline. Videos and supplementary material are available at https://research.nvidia.com/publication/2021-03_Object-Rearrangement-Using.",
        "primary_area": "",
        "author": "Michael Danielczuk;Arsalan Mousavian;Clemens Eppner;Dieter Fox;Michael Danielczuk;Arsalan Mousavian;Clemens Eppner;Dieter Fox",
        "authorids": "/37086541913;/37085404794;/37571607800;/37284329000;/37086541913;/37085404794;/37571607800;/37284329000",
        "aff": "UC Berkeley; NVIDIA, USA; NVIDIA, USA; Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561516/",
        "gs_citation": 97,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3759461028069961349&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;2",
        "aff_unique_norm": "University of California, Berkeley;NVIDIA;University of Washington",
        "aff_unique_dep": ";NVIDIA;Paul G. Allen School of Computer Science & Engineering",
        "aff_unique_url": "https://www.berkeley.edu;https://www.nvidia.com;https://www.washington.edu",
        "aff_unique_abbr": "UC Berkeley;NV;UW",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Berkeley;;Seattle",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561541",
        "title": "Object-centric Video Prediction without Annotation",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to interact with the world, agents must be able to predict the results of the world\u2019s dynamics. A natural approach to learn about these dynamics is through video prediction, as cameras are ubiquitous and powerful sensors. Direct pixel-to-pixel video prediction is difficult, does not take advantage of known priors, and does not provide an easy interface to utilize the learned dynamics. Object-centric video prediction offers a solution to these problems by taking advantage of the simple prior that the world is made of objects and by providing a more natural interface for control. However, existing object-centric video prediction pipelines require dense object annotations in training video sequences. In this work, we present Object-centric Prediction without Annotation (OPA), an object-centric video prediction method that takes advantage of priors from powerful computer vision models. We validate our method on a dataset comprised of video sequences of stacked objects falling, and demonstrate how to adapt a perception model in an environment through end-to-end video prediction training.",
        "primary_area": "",
        "author": "Karl Schmeckpeper;Georgios Georgakis;Kostas Daniilidis;Karl Schmeckpeper;Georgios Georgakis;Kostas Daniilidis",
        "authorids": "/37086802970;/37086062117;/37270623200;/37086802970;/37086062117;/37270623200",
        "aff": "GRASP Laboratory, Computer and Information Science Department, Univeristy of Pennsylvania, Philadelphia, PA; GRASP Laboratory, Computer and Information Science Department, Univeristy of Pennsylvania, Philadelphia, PA; GRASP Laboratory, Computer and Information Science Department, Univeristy of Pennsylvania, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561541/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6734836116987169804&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Computer and Information Science Department",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561019",
        "title": "Observation Space Matters: Benchmark and Optimization Algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in deep reinforcement learning (deep RL) enable researchers to solve challenging control problems, from simulated environments to real-world robotic tasks. However, deep RL algorithms are known to be sensitive to the problem formulation, including observation spaces, action spaces, and reward functions. There exist numerous choices for observation spaces but they are often designed solely based on prior knowledge due to the lack of established principles. In this work, we conduct benchmark experiments to verify common design choices for observation spaces, such as Cartesian transformation, binary contact flags, a short history, or global positions. Then we propose a search algorithm to find the optimal observation spaces, which examines various candidate observation spaces and removes unnecessary observation channels with a Dropout-Permutation test. We demonstrate that our algorithm significantly improves learning speed compared to manually designed observation spaces. We also analyze the proposed algorithm by evaluating different hyperparameters.",
        "primary_area": "",
        "author": "Joanne Taery Kim;Sehoon Ha;Joanne Taery Kim;Sehoon Ha",
        "authorids": "/37089612084;/37086314268;/37089612084;/37086314268",
        "aff": "Lawrence Livermore National Laboratory, Livermore, CA, USA; Robotics at Google, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561019/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12130938232764045231&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Lawrence Livermore National Laboratory;Google",
        "aff_unique_dep": ";Robotics",
        "aff_unique_url": "https://www.llnl.gov;https://www.google.com",
        "aff_unique_abbr": "LLNL;Google",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Livermore;Mountain View",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561458",
        "title": "Obstacle Avoidance with Kinetic Energy Buffer",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents Kinetic Energy Difference (KED) as a metric for collision proximity. The calculation of KED for differentially driven robots is explained, along with an example obstacle avoidance algorithm that utilizes it. This example algorithm is computationally efficient and simulations show that it is capable of guiding robots with slow dynamics through narrow corridors.",
        "primary_area": "",
        "author": "V. Pitk\u00e4nen;T. Pennanen;A. Tikanm\u00e4ki;J. R\u00f6ning;V. Pitk\u00e4nen;T. Pennanen;A. Tikanm\u00e4ki;J. R\u00f6ning",
        "authorids": "/37086137419;/37088951066;/37571943100;/37280819900;/37086137419;/37088951066;/37571943100;/37280819900",
        "aff": "Biomimetics and Intelligent Systems Group, University of Oulu, Finland; Biomimetics and Intelligent Systems Group, University of Oulu, Finland; Biomimetics and Intelligent Systems Group, University of Oulu, Finland; Biomimetics and Intelligent Systems Group, University of Oulu, Finland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561458/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9425513539640787584&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Oulu",
        "aff_unique_dep": "Biomimetics and Intelligent Systems Group",
        "aff_unique_url": "https://www.oulu.fi",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Finland"
    },
    {
        "id": "9561790",
        "title": "Occupancy Map Inpainting for Online Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we focus on mobile robot navigation in indoor environments where occlusions and field-of-view limitations hinder onboard sensing capabilities. We show that the footprint of a camera mounted on a robot can be drastically improved using learning-based approaches. Specifically, we consider the task of building an occupancy map for autonomous navigation of a robot equipped with a depth camera. In our approach, a local occupancy map is first computed using measurements from the camera directly. Afterwards, an inpainting network adds further information, the occupancy probabilities of unseen grid cells, to the map. A novel aspect of our approach is that rather than direct supervision from ground truth, we combine the information from a second camera with a better field-of-view for supervision. The training focuses on predicting extensions of the sensed data. To test the effectiveness of our approach, we use a robot setup with a single camera placed at 0.5m above the ground. We compare the navigation performance using raw maps from only this camera\u2019s input (baseline) versus using inpainted maps augmented with our network. Our method outperforms the baseline approach even in completely new environments not included in the training set and can yield 21% shorter paths than the baseline approach. A real-time implementation of our method on a mobile robot is also tested in home and office environments.",
        "primary_area": "",
        "author": "Minghan Wei;Daewon Lee;Volkan Isler;Daniel Lee;Minghan Wei;Daewon Lee;Volkan Isler;Daniel Lee",
        "authorids": "/37086455365;/37088998309;/37298487800;/37280609600;/37086455365;/37088998309;/37298487800;/37280609600",
        "aff": "Samsung AI Center New York, New York, NY; Samsung AI Center New York, New York, NY; Samsung AI Center New York, New York, NY; Samsung AI Center New York, New York, NY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561790/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3292368446841771975&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "Samsung AI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560971",
        "title": "OmniHang: Learning to Hang Arbitrary Objects using Contact Point Correspondences and Neural Collision Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we explore whether a robot can learn to hang arbitrary objects onto a diverse set of supporting items such as racks or hooks. Endowing robots with such an ability has applications in many domains such as domestic services, logistics, or manufacturing. Yet, it is a challenging manipulation task due to the large diversity of geometry and topology of everyday objects. In this paper, we propose a system that takes partial point clouds of an object and a supporting item as input and learns to decide where and how to hang the object stably. Our system learns to estimate the contact point correspondences between the object and supporting item to get an estimated stable pose. We then run a deep reinforcement learning algorithm to refine the predicted stable pose. Then, the robot needs to find a collision-free path to move the object from its initial pose to stable hanging pose. To this end, we train a neural network based collision estimator that takes as input partial point clouds of the object and supporting item. We generate a new and challenging, large-scale, synthetic dataset annotated with stable poses of objects hung on various supporting items and their contact point correspondences. In this dataset, we show that our system is able to achieve a 68.3% success rate of predicting stable object poses and has a 52.1% F1 score in terms of finding feasible paths. Supplemental material and videos are available on our project webpage https://sites.google.com/view/hangingobject.",
        "primary_area": "",
        "author": "Yifan You;Lin Shao;Toki Migimatsu;Jeannette Bohg;Yifan You;Lin Shao;Toki Migimatsu;Jeannette Bohg",
        "authorids": "/37088996879;/37086423705;/37086141343;/37591153900;/37088996879;/37086423705;/37086141343;/37591153900",
        "aff": "Department of Computer Science, University of California, Los Angeles, CA, USA; Stanford Artificial Intelligence Lab (SAIL), Stanford University, CA, USA; Stanford Artificial Intelligence Lab (SAIL), Stanford University, CA, USA; Stanford Artificial Intelligence Lab (SAIL), Stanford University, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560971/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1504610479592521624&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of California, Los Angeles;Stanford University",
        "aff_unique_dep": "Department of Computer Science;Artificial Intelligence Lab (SAIL)",
        "aff_unique_url": "https://www.ucla.edu;https://www.stanford.edu",
        "aff_unique_abbr": "UCLA;Stanford",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Los Angeles;Stanford",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561400",
        "title": "On Smooth Time-Optimal Trajectory Planning in Twisted String Actuators",
        "track": "main",
        "status": "Poster",
        "abstract": "Twisted string actuators (TSA) are efficient, compliant cable actuators with high power density that have found their way into many engineering and robotics applications in recent years. They are generally used in the scenarios involving comparatively slow positioning, since quick motions in TSAs often result in large overshoot values, undesired oscillations and loss of cable tension. This work discusses time optimal trajectory generation for point-to-point transitions in TSA. We propose a method to generate smooth trajectories by directly solving an optimal control problem while respecting constraints on motor torque and speed and preventing tension loss on cables. We have conducted an experimental evaluation demonstrating that, in comparison to classical, constrained \u2018bangbang\u2019 transitions, the proposed trajectories result in much faster settling time, nearly-zero overshoot and require almost 60% less motor power for tracking. The proposed method can help TSAs find their way into highly-dynamical applications that have been previously deemed to be too demanding, which include parallel manipulators and antagonistically-controlled systems.",
        "primary_area": "",
        "author": "Simeon Nedelchev;Daniil Kirsanov;Igor Gaponov;Hyeonseok Seong;Jee-Hwan Ryu;Simeon Nedelchev;Daniil Kirsanov;Igor Gaponov;Hyeonseok Seong;Jee-Hwan Ryu",
        "authorids": "/37086580950;/37086568418;/37691627300;/37086158742;/37274994300;/37086580950;/37086568418;/37691627300;/37086158742;/37274994300",
        "aff": "Institute of Robotics and Computer Vision, Innopolis University, Innopolis, Russia; Institute of Robotics and Computer Vision, Innopolis University, Innopolis, Russia; Institute of Robotics and Computer Vision, Innopolis University, Innopolis, Russia; Department of Civil and Environmental Engineering, KAIST, Daejeon, South Korea; Department of Civil and Environmental Engineering, KAIST, Daejeon, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561400/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:x4lVhuV1ayMJ:scholar.google.com/&scioq=On+Smooth+Time-Optimal+Trajectory+Planning+in+Twisted+String+Actuators&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "Innopolis University;KAIST",
        "aff_unique_dep": "Institute of Robotics and Computer Vision;Department of Civil and Environmental Engineering",
        "aff_unique_url": "https://innopolis.ru/en;https://www.kaist.ac.kr",
        "aff_unique_abbr": ";KAIST",
        "aff_campus_unique_index": "0;0;0;1;1",
        "aff_campus_unique": "Innopolis;Daejeon",
        "aff_country_unique_index": "0;0;0;1;1",
        "aff_country_unique": "Russian Federation;South Korea"
    },
    {
        "id": "9560997",
        "title": "On the Effect of Robotic Leg Design on Energy Efficiency",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the effect of alternative leg designs on energy consumption in legged locomotion. Focusing on gaits with constant horizontal velocity and constant height we introduce models of two simplified parallel and serial designs with realistic mechanical and actuation parameters. The analysis yields the distribution of power demands in the leg workspace, leading to useful conclusions related to mechanical power antagonism and actuator electric losses. Mechanical antagonism occurs not only in parallel but also in serial legs causing extensive power waste, since one actuator contributes to the locomotion task and the other consumes power with no contribution to it. Based on the analysis, we propose a new leg design that minimizes the total actuation power consumption criterion given a nominal robot toe trajectory.",
        "primary_area": "",
        "author": "Konstantinos Koutsoukis;Evangelos Papadopoulos;Konstantinos Koutsoukis;Evangelos Papadopoulos",
        "authorids": "/37086198958;/37273090500;/37086198958;/37273090500",
        "aff": "School of Mechanical Engineering, National Technical University of Athens, Athens, Greece; School of Mechanical Engineering, National Technical University of Athens, Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560997/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15765581477058154546&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National Technical University of Athens",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.ntua.gr",
        "aff_unique_abbr": "NTUA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Athens",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9562050",
        "title": "On-line force capability evaluation based on efficient polytope vertex search",
        "track": "main",
        "status": "Poster",
        "abstract": "Ellipsoid-based manipulability measures are often used to characterize the force/velocity task-space capabilities of robots. While computationally simple, this approach largely approximate and underestimate the true capabilities. Force/velocity polytopes appear to be a more appropriate representation to characterize the robot\u2019s task-space capabilities. However, due to the computational complexity of the associated vertex search problem, the polytope approach is mostly restricted to offline use, e.g. as a tool aiding robot mechanical design, robot placement in work-space and offline trajectory planning. In this paper, a novel on-line polytope vertex search algorithm is proposed. It exploits the parallelotope geometry of actuator constraints. The proposed algorithm significantly reduces the complexity and computation time of the vertex search problem in comparison to commonly used algorithms. In order to highlight the on-line capability of the proposed algorithm and its potential for robot control, a challenging experiment with two collaborating Franka Emika Panda robots, carrying a load of 12 kilograms, is proposed. In this experiment, the load distribution is adapted on-line, as a function of the configuration dependant task-space force capability of each robot, in order to avoid, as much as possible, the saturation of their capacity.",
        "primary_area": "",
        "author": "Antun Skuric;Vincent Padois;David Daney;Antun Skuric;Vincent Padois;David Daney",
        "authorids": "/37088366085;/38534363400;/37273442100;/37088366085;/38534363400;/37273442100",
        "aff": "Auctus, Inria / IMS (Univ. Bordeaux / Bordeaux INP / CNRS UMR 5218), Talence, France; Auctus, Inria / IMS (Univ. Bordeaux / Bordeaux INP / CNRS UMR 5218), Talence, France; Auctus, Inria / IMS (Univ. Bordeaux / Bordeaux INP / CNRS UMR 5218), Talence, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562050/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15171445363297106314&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "INRIA",
        "aff_unique_dep": "IMS",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Talence",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561690",
        "title": "One to Many: Adaptive Instrument Segmentation via Meta Learning and Dynamic Online Adaptation in Robotic Surgical Video",
        "track": "main",
        "status": "Poster",
        "abstract": "Surgical instrument segmentation in robot-assisted surgery (RAS) - especially that using learning-based models - relies on the assumption that training and testing videos are sampled from the same domain. However, it is impractical and expensive to collect and annotate sufficient data from every new domain. To greatly increase the label efficiency, we explore a new problem, i.e., adaptive instrument segmentation, which is to effectively adapt one source model to new robotic surgical videos from multiple target domains, only given the annotated instruments in the first frame. We propose MDAL, a meta-learning based dynamic online adaptive learning scheme with a two-stage framework to fast adapt the model parameters on the first frame and partial subsequent frames while predicting the results. MDAL learns the general knowledge of instruments and the fast adaptation ability through the video-specific meta-learning paradigm. The added gradient gate excludes the noisy supervision from pseudo masks for dynamic online adaptation on target videos. We demonstrate empirically that MDAL outperforms other state-of-the-art methods on two datasets (including a real-world RAS dataset). The promising performance on ex-vivo scenes also benefits the downstream tasks such as robot-assisted suturing and camera control.",
        "primary_area": "",
        "author": "Zixu Zhao;Yueming Jin;Bo Lu;Chi-Fai Ng;Qi Dou;Yun-Hui Liu;Pheng-Ann Heng;Zixu Zhao;Yueming Jin;Bo Lu;Chi-Fai Ng;Qi Dou;Yun-Hui Liu;Pheng-Ann Heng",
        "authorids": "/37088904291;/37086369638;/37085991083;/37089000397;/37085465414;/37279412600;/37283077400;/37088904291;/37086369638;/37085991083;/37089000397;/37085465414;/37279412600;/37283077400",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong; The Department of Mechanical and Automation Engineering, T stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; Department of Surgery, The Chinese University of Hong Kong, Hong Kong; The Department of Mechanical and Automation Engineering, T stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; The Department of Mechanical and Automation Engineering, T stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong; Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561690/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11877465135128146936&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;1",
        "aff_unique_norm": "Chinese University of Hong Kong;Chinese Academy of Sciences",
        "aff_unique_dep": "Department of Computer Science and Engineering;Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems",
        "aff_unique_url": "https://www.cuhk.edu.hk;http://www.cas.cn",
        "aff_unique_abbr": "CUHK;CAS",
        "aff_campus_unique_index": "0;0;0;0;0;0;1",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560821",
        "title": "One-Step Ahead Prediction of Angular Momentum about the Contact Point for Control of Bipedal Locomotion: Validation in a LIP-inspired Controller",
        "track": "main",
        "status": "Poster",
        "abstract": "Ultimately, feedback control is about making adjustments using current state information in order to meet an objective in the future. In the control of bipedal locomotion, linear velocity of the center of mass has been widely accepted as the primary variable around which feedback control objectives are formulated. In this paper, we argue that it is easier to predict the one-step ahead evolution of angular momentum about the contact point than it is to make a similar prediction for linear velocity, and hence it provides a superior quantity for feedback control. So as not to confuse the benefits of predicting angular momentum with any other control design decisions, we reformulate the standard LIP model in terms of angular momentum and show how to regulate swing foot touchdown position at the end of the current step so as to meet an angular momentum objective at the end of the next step. We implement the resulting feedback controller on the 20 degree-of-freedom bipedal robot, Cassie Blue, where each leg accounts for nearly one-third of the robot\u2019s total mass of 32 Kg. Under this controller, the robot achieves fast walking, rapid turning while walking, large disturbance rejection, and locomotion on rough terrain.",
        "primary_area": "",
        "author": "Yukai Gong;Jessy Grizzle;Yukai Gong;Jessy Grizzle",
        "authorids": "/37086962231;/37277141500;/37086962231;/37277141500",
        "aff": "College of Engineering and the Robotics Institute, University of Michigan, Ann Arbor, MI, USA; College of Engineering and the Robotics Institute, University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560821/",
        "gs_citation": 49,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14904297971704917712&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "College of Engineering and the Robotics Institute",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561748",
        "title": "Online Connectivity-aware Dynamic Deployment for Heterogeneous Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider the dynamic multi-robot distribution problem where a heterogeneous group of networked robots is tasked to spread out and simultaneously move towards multiple moving task areas while maintaining connectivity. The heterogeneity of the system is characterized by various categories of units and each robot carries different numbers of units per category representing heterogeneous capabilities. Every task area with different importance demands a total number of units contributed by all of the robots within its area. Moreover, we assume the importance and the total number of units requested from each task area is initially unknown. The robots need first to explore, i.e., reach those areas, and then be allocated to the tasks so to fulfill the requirements. The multi-robot distribution problem is formulated as designing controllers to distribute the robots that maximize the overall task fulfillment while minimizing the traveling costs in presence of connectivity constraints. We propose a novel connectivity-aware multi-robot redistribution approach that accounts for dynamic task allocation and connectivity maintenance for a heterogeneous robot team. Such an approach could generate sub-optimal robot controllers so that the amount of total unfulfilled requirements of the tasks weighted by their importance is minimized and robots stay connected at all times. Simulation and numerical results are provided to demonstrate the effectiveness of the proposed approaches.",
        "primary_area": "",
        "author": "Chendi Lin;Wenhao Luo;Katia Sycara;Chendi Lin;Wenhao Luo;Katia Sycara",
        "authorids": "/37089002240;/37085748889;/37268476900;/37089002240;/37085748889;/37268476900",
        "aff": "School of Computer Science, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; School of Computer Science, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; School of Computer Science, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561748/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15124856716981936104&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "School of Computer Science, Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560808",
        "title": "Online DCM Trajectory Adaptation for Push and Stumble Recovery during Humanoid Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a highly efficient Divergent Component of Motion (DCM) reference trajectory generator capable of adapting online to large perturbations acting on the center-of-mass (push recovery) and on the swing foot (stumble recovery). For push recovery, we propose an analytic solution for a footstep adjustment strategy based on the DCM dynamics. The proposed algorithm considers double support phases explicitly and is active throughout the motion, i.e., during both single and double support phases. For stumble recovery, we introduce a continuous DCM trajectory adaptation based on the instantaneous tracking error of the swing foot. Our method is highly efficient, computing a push recovery solution within 10 microseconds on the robot hardware. Furthermore, it achieves robust locomotion for large external perturbations, which we demonstrate in simulations and experiments with the humanoid robot TORO.",
        "primary_area": "",
        "author": "George Mesesan;Johannes Englsberger;Christian Ott;George Mesesan;Johannes Englsberger;Christian Ott",
        "authorids": "/37086066822;/38281295100;/37282440400;/37086066822;/38281295100;/37282440400",
        "aff": "German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560808/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8824734489454323235&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "German Aerospace Center (DLR)",
        "aff_unique_dep": "Institute of Robotics and Mechatronics",
        "aff_unique_url": "https://www.dlr.de",
        "aff_unique_abbr": "DLR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9562110",
        "title": "Online Dynamic Time Warping Algorithm for Human-Robot Imitation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel online algorithm for motion similarity measurements during human-robot interaction (HRI). Specifically, we formulate a Segment-based Online Dynamic Time Warping (SODTW) algorithm that can be used for understanding of repeated and cyclic human motions, in the context of rehabilitation or social interaction. The algorithm can estimate both the human-robot motion similarity and the time delay to initiate motion and combine these values as a metric to adaptively select appropriate robot imitation repertoires. We validated the algorithm offline by post-processing experimental data collected from a cohort of 55 subjects during imitation episodes with our social robot Zeno. Furthermore, we implemented the algorithm online on Zeno and collected further experimental results with 13 human subjects. These results show that the algorithm can reveal important features of human movement including the quality of motion and human reaction time to robot stimuli. Moreover, the robot can adapt to appropriate human motion speeds based on similarity measurements calculated using this algorithm, enabling future adaptive rehabilitation interventions for conditions such as Autism Spectrum Disorders (ASD).",
        "primary_area": "",
        "author": "Nazita Taghavi;Jacob Berdichevsky;Namrata Balakrishnan;Karla C. Welch;Sumit Kumar Das;Dan O. Popa;Nazita Taghavi;Jacob Berdichevsky;Namrata Balakrishnan;Karla C. Welch;Sumit Kumar Das;Dan O. Popa",
        "authorids": "/37088998669;/37088999724;/37088997915;/37971071200;/37088998074;/37283733600;/37088998669;/37088999724;/37088997915;/37971071200;/37088998074;/37283733600",
        "aff": "Louisville Automation & Robotics Research Institute, University of Louisville, KY; Louisville Automation & Robotics Research Institute, University of Louisville, KY; Associated with SLAC National Accelerator Laboratory; Louisville Automation & Robotics Research Institute, University of Louisville, KY; Louisville Automation & Robotics Research Institute, University of Louisville, KY; Louisville Automation & Robotics Research Institute, University of Louisville, KY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562110/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12978087548454104083&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "University of Louisville;SLAC National Accelerator Laboratory",
        "aff_unique_dep": "Louisville Automation & Robotics Research Institute;",
        "aff_unique_url": "https://www.louisville.edu;https://www.slac.stanford.edu",
        "aff_unique_abbr": "UofL;SLAC",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Louisville;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561592",
        "title": "Online Dynamic Trajectory Optimization and Control for a Quadruped Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Legged robot locomotion requires the planning of stable reference trajectories, especially while traversing uneven terrain. The proposed trajectory optimization framework is capable of generating dynamically stable base and footstep trajectories for multiple steps. The locomotion task can be defined with contact locations, base motion or both, making the algorithm suitable for multiple scenarios (e.g., presence of moving obstacles). The planner uses a simplified momentum-based task space model for the robot dynamics, allowing computation times that are fast enough for online replanning. This fast planning capability also enables the quadruped to accommodate for drift and environmental changes. The algorithm is tested on simulation and a real robot across multiple scenarios, which includes uneven terrain, stairs and moving obstacles. The results show that the planner is capable of generating stable trajectories in the real robot even when a box of 15 cm height is placed in front of its path at the last moment.",
        "primary_area": "",
        "author": "Oguzhan Cebe;Carlo Tiseo;Guiyang Xin;Hsiu-chin Lin;Joshua Smith;Michael Mistry;Oguzhan Cebe;Carlo Tiseo;Guiyang Xin;Hsiu-chin Lin;Joshua Smith;Michael Mistry",
        "authorids": "/37086455941;/37085404832;/37085531864;/37085366909;/37086455996;/37542865600;/37086455941;/37085404832;/37085531864;/37085366909;/37086455996;/37542865600",
        "aff": "School of Informatics, Institute of Perception, Action and Behaviour, University of Edinburgh, Edinburgh, United Kingdom; School of Informatics, Institute of Perception, Action and Behaviour, University of Edinburgh, Edinburgh, United Kingdom; School of Informatics, Institute of Perception, Action and Behaviour, University of Edinburgh, Edinburgh, United Kingdom; Department of Electrical and Computer Engineering, School of Computer Science, McGill University; School of Informatics, Institute of Perception, Action and Behaviour, University of Edinburgh, Edinburgh, United Kingdom; School of Informatics, Institute of Perception, Action and Behaviour, University of Edinburgh, Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561592/",
        "gs_citation": 33,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8985000479779381652&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "University of Edinburgh;McGill University",
        "aff_unique_dep": "School of Informatics;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ed.ac.uk;https://www.mcgill.ca",
        "aff_unique_abbr": "Edinburgh;McGill",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Edinburgh;",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "United Kingdom;Canada"
    },
    {
        "id": "9560899",
        "title": "Online Flocking Control of UAVs with Mean-Field Approximation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel approach to the formation controlling of aerial robot swarms that demonstrates the flocking behavior. The proposed method stems from the Unmanned Aerial Vehicle (UAV) dynamics; thus, it prevents any unattainable control inputs from being produced and subsequently leads to feasible trajectories. By modeling the inter-agent relationships using a pairwise energy function, we show that interacting robot swarms constitute a Markov Random Field. Our algorithm builds on the Mean-Field Approximation and incorporates the collective behavioral rules: cohesion, separation, and velocity alignment. We follow a distributed control scheme and show that our method can control a swarm of UAVs to a formation and velocity consensus with real-time collision avoidance. We validate the proposed method with physical and high-fidelity simulation experiments.",
        "primary_area": "",
        "author": "Malintha Fernando;Malintha Fernando",
        "authorids": "/37086939042;/37086939042",
        "aff": "Luddy School of Informatics, Computing, and Engineering, Indiana University, Bloomington, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560899/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15665283255817030291&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Indiana University",
        "aff_unique_dep": "Luddy School of Informatics, Computing, and Engineering",
        "aff_unique_url": "https://www.indiana.edu",
        "aff_unique_abbr": "IU",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Bloomington",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561963",
        "title": "Online Informative Path Planning for Active Information Gathering of a 3D Surface",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an online informative path planning approach for active information gathering on three-dimensional surfaces using aerial robots. Most existing works on surface inspection focus on planning a path offline that can provide full coverage of the surface, which inherently assumes the surface information is uniformly distributed hence ignoring potential spatial correlations of the information field. In this paper, we utilize manifold Gaussian processes (mGPs) with geodesic kernel functions for mapping surface information fields and plan informative paths online in a receding horizon manner. Our approach actively plans information-gathering paths based on recent observations that respect dynamic constraints of the vehicle and a total flight time budget. We provide planning results for simulated temperature modeling for simple and complex 3D surface geometries (a cylinder and an aircraft model). We demonstrate that our informative planning method outperforms traditional approaches such as 3D coverage planning and random exploration, both in reconstruction error and information-theoretic metrics. We also show that by taking spatial correlations of the information field into planning using mGPs, the information gathering efficiency is significantly improved.",
        "primary_area": "",
        "author": "Hai Zhu;Jen Jen Chung;Nicholas R.J. Lawrance;Roland Siegwart;Javier Alonso-Mora;Hai Zhu;Jen Jen Chung;Nicholas R.J. Lawrance;Roland Siegwart;Javier Alonso-Mora",
        "authorids": "/37086618561;/37085668354;/37571923900;/37281398300;/38271697300;/37086618561;/37085668354;/37571923900;/37281398300;/38271697300",
        "aff": "Department of Cognitive Robotics, Delft University of Technology; Autonomous Systems Lab, ETH, Zurich; Autonomous Systems Lab, ETH, Zurich; Autonomous Systems Lab, ETH, Zurich; Department of Cognitive Robotics, Delft University of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561963/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1106192984145756741&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Delft University of Technology;ETH Zurich",
        "aff_unique_dep": "Department of Cognitive Robotics;Autonomous Systems Lab",
        "aff_unique_url": "https://www.tudelft.nl;https://www.ethz.ch",
        "aff_unique_abbr": "TUDelft;ETHZ",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Zurich",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "Netherlands;Switzerland"
    },
    {
        "id": "9562065",
        "title": "Online Recommendation-based Convolutional Features for Scale-Aware Visual Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we develop an online learning-based visual tracking framework that can optimize the target model and estimate the scale variation for object tracking. We propose a recommender-based tracker, which is capable of selecting the representative convolutional neural network (CNN) layers and feature maps autonomously. In addition, the proposed recommender computes the weights of these layers and feature maps. A discriminative target percept of each recommended layer is reconstructed by the weighted sum of the recommended feature maps. Then the target model of the correlation filter is updated by the weighted sum of the target percepts. Thus, a sub-network is extracted from the pre-trained CNN backbone for the tracking process of a specific target. To deal with scale changes, we propose a spatiotemporal-based min-channel method to estimate the target size variation directly from CNN features. Experimental results on 50 benchmark datasets and video data from a rescue drone demonstrate that the proposed tracker is quite competitive with the state-of-the-art CNN-based trackers in terms of accuracy, scale adaptation, and robustness for UAV-related applications.",
        "primary_area": "",
        "author": "Ran Duan;Changhong Fu;Kostas Alexis;Erdal Kayacan;Ran Duan;Changhong Fu;Kostas Alexis;Erdal Kayacan",
        "authorids": "/37086798983;/37086797986;/37546514600;/37595300900;/37086798983;/37086797986;/37546514600;/37595300900",
        "aff": "Department of Aeronautical and Aviation Engineering, Hong Kong Polytechnic University, Hong Kong, China; Department of Aeronautical and Aviation Engineering, Hong Kong Polytechnic University, Hong Kong, China; NTNU, Trondheim, Norway; the Department of Engineering, Artificial Intelligence in Robotics Laboratory (AiR Lab), Aarhus University, Aarhus C, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562065/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13323305750775415038&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Hong Kong Polytechnic University;Norwegian University of Science and Technology;Aarhus University",
        "aff_unique_dep": "Department of Aeronautical and Aviation Engineering;;Department of Engineering, Artificial Intelligence in Robotics Laboratory (AiR Lab)",
        "aff_unique_url": "https://www.polyu.edu.hk;https://www.ntnu.no;https://www.au.dk",
        "aff_unique_abbr": "PolyU;NTNU;AU",
        "aff_campus_unique_index": "0;0;1;2",
        "aff_campus_unique": "Hong Kong;Trondheim;Aarhus C",
        "aff_country_unique_index": "0;0;1;2",
        "aff_country_unique": "China;Norway;Denmark"
    },
    {
        "id": "9560855",
        "title": "Online Trajectory Optimization for Dynamic Aerial Motions of a Quadruped Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents a two part framework for online planning and execution of dynamic aerial motions on a quadruped robot. Motions are planned via a centroidal momentum-based nonlinear optimization that is general enough to produce rich sets of novel dynamic motions based solely on the user-specified contact schedule and desired launch velocity of the robot. Since this nonlinear optimization is not tractable for real-time receding horizon control, motions are planned once via nonlinear optimization in preparation of an aerial motion and then tracked continuously using a variational-based optimal controller that offers robustness to the uncertainties that exist in the real hardware such as modeling error or disturbances. Motion planning typically takes between 0.05-0.15 s, while the optimal controller finds stabilizing feedback inputs at 500 Hz. Experimental results on the MIT Mini Cheetah demonstrate that the framework can reliably produce successful aerial motions such as jumps onto and off of platforms, spins, flips, barrel rolls, and running jumps over obstacles.",
        "primary_area": "",
        "author": "Matthew Chignoli;Sangbae Kim;Matthew Chignoli;Sangbae Kim",
        "authorids": "/37088344884;/37537397200;/37088344884;/37537397200",
        "aff": "Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560855/",
        "gs_citation": 41,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=522866004136667035&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560816",
        "title": "Online velocity fluctuation of off-road wheeled mobile robots: A reinforcement learning approach",
        "track": "main",
        "status": "Poster",
        "abstract": "During the off-road path following of a wheeled mobile robot in presence of poor grip conditions, the longitudinal velocity should be limited in order to maintain safe navigation with limited tracking errors, while at the same time being high enough to minimize travel time. Thus, this paper presents a new approach of online speed fluctuation, capable of limiting the lateral error below a given threshold, while maximizing the longitudinal velocity. This is accomplished using a neural network trained with a reinforcement learning method. This speed modulation is done side-by-side with an existing model-based predictive steering control, using a state estimator and dynamic observers. Simulated and experimental results show a decrease in tracking error, while maintaining a consistent travel time when compared to a classical constant speed method and to a kinematic speed fluctuation method.",
        "primary_area": "",
        "author": "Fran\u00e7ois Gauthier-Clerc;Ashley Hill;Jean Laneurit;Roland Lenain;\u00c9ric Lucet;Fran\u00e7ois Gauthier-Clerc;Ashley Hill;Jean Laneurit;Roland Lenain;\u00c9ric Lucet",
        "authorids": "/37088999051;/37088687917;/38312164600;/37283367600;/37593493000;/37088999051;/37088687917;/38312164600;/37283367600;/37593493000",
        "aff": "Universit\u00e9 Paris-Saclay, CEA, Palaiseau, France; Universit\u00e9 Paris-Saclay, CEA, Palaiseau, France; Inrae, UR TSCF, Centre de Clermont-Ferrand, Universit\u00e9 Clermont Auvergne, Aubi\u00e8re, France; Inrae, UR TSCF, Centre de Clermont-Ferrand, Universit\u00e9 Clermont Auvergne, Aubi\u00e8re, France; Universit\u00e9 Paris-Saclay, CEA, Palaiseau, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560816/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12594194978029215287&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Universit\u00e9 Paris-Saclay;Institut National de Recherche pour l'Agriculture, l'Alimentation et l'Environnement",
        "aff_unique_dep": ";Unit\u00e9 de Recherche Transdisciplinaire en Sciences du Changement et de la Fonctionnalit\u00e9",
        "aff_unique_url": "https://www.universite-paris-saclay.fr;https://www.inrae.fr",
        "aff_unique_abbr": "UPS;INRAE",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Palaiseau;Clermont-Ferrand",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561660",
        "title": "Open-set Intersection Intention Prediction for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Intention prediction is a crucial task for Autonomous Driving (AD). Due to the variety of size and layout of intersections, it is challenging to predict intention of human driver at different intersections, especially unseen and irregular intersections. In this paper, we formulate the prediction of intention at intersections as an open-set prediction problem that requires context specific matching of the target vehicle state and the diverse intersection configurations that are in principle unbounded. We capture map-centric features that correspond to intersection structures under a spatial-temporal graph representation, and use two MAAMs (mutually auxiliary attention module) that cover respectively lane-level and exit-level intentions to predict a target that best matches intersection elements in map-centric feature space. Under our model, attention scores estimate the probability distribution of the open-set intentions that are contextually defined by the structure of the current intersection. The proposed model is trained and evaluated on simulated dataset. Furthermore, the model, trained on simulated dataset and without any fine tuning, is directly validated on in-house real-world dataset collected at 98 real-world intersections and exhibits satisfactory performance, demonstrating the practical viability of our approach.",
        "primary_area": "",
        "author": "Fei Li;Xiangxu Li;Jun Luo;Shiwei Fan;Hongbo Zhang;Fei Li;Xiangxu Li;Jun Luo;Shiwei Fan;Hongbo Zhang",
        "authorids": "/37088644574;/37088647596;/37089002073;/37088637651;/37859161500;/37088644574;/37088647596;/37089002073;/37088637651;/37859161500",
        "aff": "Noah\u2019s Ark Lab, Huawei Technologies Co., Ltd; Noah\u2019s Ark Lab, Huawei Technologies Co., Ltd; Noah\u2019s Ark Lab, Huawei Technologies Co., Ltd; Noah\u2019s Ark Lab, Huawei Technologies Co., Ltd; Noah\u2019s Ark Lab, Huawei Technologies Co., Ltd",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561660/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1443056192399303614&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Noah\u2019s Ark Lab",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561788",
        "title": "OpenBot: Turning Smartphones into Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Current robots are either expensive or make significant compromises on sensory richness, computational power, and communication capabilities. We propose to leverage smartphones to equip robots with extensive sensor suites, powerful computational abilities, state-of-the-art communication channels, and access to a thriving software ecosystem. We design a small electric vehicle that costs $50 and serves as a robot body for standard Android smartphones. We develop a software stack that allows smartphones to use this body for mobile operation and demonstrate that the system is sufficiently powerful to support advanced robotics workloads such as person following and real-time autonomous navigation in unstructured environments. Controlled experiments demonstrate that the presented approach is robust across different smartphones and robot bodies.",
        "primary_area": "",
        "author": "Matthias M\u00fcller;Vladlen Koltun;Matthias M\u00fcller;Vladlen Koltun",
        "authorids": "/37088216388;/37739465900;/37088216388;/37739465900",
        "aff": "Intelligent Systems Lab, Intel; Intelligent Systems Lab, Intel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561788/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14530840274904870908&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Intel",
        "aff_unique_dep": "Intelligent Systems Lab",
        "aff_unique_url": "https://www.intel.com",
        "aff_unique_abbr": "Intel",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560732",
        "title": "Operational Space Control Under Actuator Bandwidth Limitation",
        "track": "main",
        "status": "Poster",
        "abstract": "The actuator bandwidth limitation deteriorates the stability and performance of torque-based robot controllers. Operational space control is especially prone to this problem, since the limited bandwidth of a single actuator can reduce the performance of all related tasks simultaneously. In this article, an intuitive way to penalize low performance actuators is proposed to improve the performance of the operational space controller. The basic concept is to add joint torques only to high performance actuators, when the control bandwidth cannot reach the target level using all actuators. If that is not enough, additional torques are commanded to even higher performance actuators. This procedure can be executed recursively, meaning the controller can achieve almost maximum performance under the actuator bandwidth limitation. The proposed method was experimentally verified using the robot manipulator Franka Emika Panda.",
        "primary_area": "",
        "author": "Hosang Lee;Jaeheung Park;Hosang Lee;Jaeheung Park",
        "authorids": "/37088999968;/37281014000;/37088999968;/37281014000",
        "aff": "Graduate School of Convergence Science and Technology, Seoul National University, Seoul, Republic of Korea; Advanced Institutes of Convergence Technology (AICT), Suwon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560732/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15022904775287113712&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Seoul National University;Advanced Institutes of Convergence Technology",
        "aff_unique_dep": "Graduate School of Convergence Science and Technology;",
        "aff_unique_url": "https://www.snu.ac.kr;",
        "aff_unique_abbr": "SNU;AICT",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Seoul;Suwon",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561278",
        "title": "Operational Space Control for Planar PAN\u20131 Underactuated Manipulators Using Orthogonal Projection and Quadratic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an operational space control formulation for a planar N-link underactuated manipulator (PAN\u20131)1 with a passive first joint subject to actuator constraints (N \u2a7e 3), covering both stabilization and tracking tasks. Such underactuated manipulators have an inherent first-order nonholonomic constraint, allowing us to project their dynamics to a space consistent with the nonholonomic constraint. Based on the constrained dynamics, we can design operational space controllers with respect to tasks assuming that all joints of the manipulator are active. Due to underactuation, we design a Quadratic Programming (QP) based controller to minimize the error between the desired torque commands and available motor torques in the null space of the constraint, as well as involve the constraint of motor outputs. The proposed control framework was demonstrated by stabilization and tracking tasks in simulations with both planar PA2 and PA3 manipulators. Furthermore, we verified the controller experimentally using a planar PA2 robot.",
        "primary_area": "",
        "author": "Xiangyu Chu;Yunxi Tang;Alessandro M. Giordano;Tan Chen;K. W. Samuel Au;Xiangyu Chu;Yunxi Tang;Alessandro M. Giordano;Tan Chen;K. W. Samuel Au",
        "authorids": "/37086437251;/37088920411;/37085390315;/37086128468;/37088483488;/37086437251;/37088920411;/37085390315;/37086128468;/37088483488",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; Institute of Robotics and Mechatronics, German Aerospace Center (DLR), We\u00dfling, Germany; Department of Aerospace and Mechanical Engineering, University of Notre Dame, IN, USA; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561278/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=594225505262125675&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Chinese University of Hong Kong;German Aerospace Center;University of Notre Dame",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;Institute of Robotics and Mechatronics;Department of Aerospace and Mechanical Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.dlr.de;https://www.nd.edu",
        "aff_unique_abbr": "CUHK;DLR;Notre Dame",
        "aff_campus_unique_index": "0;0;1;2;0",
        "aff_campus_unique": "Hong Kong;We\u00dfling;Notre Dame",
        "aff_country_unique_index": "0;0;1;2;0",
        "aff_country_unique": "China;Germany;United States"
    },
    {
        "id": "9561993",
        "title": "Optimal Estimation of the Centroidal Dynamics of Legged Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating the centroidal dynamics of legged robots is crucial in the context of multi-contact locomotion of legged robots. In this paper, we formulate the estimation of centroidal dynamics as a maximum a posteriori problem and we use a differential dynamic programming approach for solving it. The soundness of the proposed approach is first validated on a simulated humanoid robot, where ground truth data is available, enabling error analysis, and then compared to other alternatives of the state of the art, namely an extend Kalman filter and a recursive complementary filter. The results demonstrate that, compared to other approaches, the proposed method reduces the estimation error on the centroidal state in addition to ensuring the dynamics consistency of the state trajectory. Finally, the effectiveness of the proposed method is illustrated on real measurements, obtained from walking experiments with the HRP-2 humanoid robot.",
        "primary_area": "",
        "author": "Fran\u00e7ois Bailly;Justin Carpentier;Philippe Sou\u00e8res;Fran\u00e7ois Bailly;Justin Carpentier;Philippe Sou\u00e8res",
        "authorids": "/37086479176;/37085506841;/37377500300;/37086479176;/37085506841;/37377500300",
        "aff": "LAAS-CNRS, Toulouse, France; Inria, D\u00e9partement d\u2019Informatique de l\u2019ENS, \u00c9cole Normale sup\u00e9rieure, CNRS, PSL Research University, Paris, France; LAAS-CNRS, Toulouse, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561993/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=348017264594538642&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "LAAS-CNRS;INRIA",
        "aff_unique_dep": ";D\u00e9partement d\u2019Informatique de l\u2019ENS",
        "aff_unique_url": "https://www.laas.fr;https://www.inria.fr",
        "aff_unique_abbr": ";Inria",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Toulouse;Paris",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561570",
        "title": "Optimal Multi-Manipulator Arm Placement for Maximal Dexterity during Robotics Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot arm placements are oftentimes a limitation in surgical preoperative procedures, relying on trained staff to evaluate and decide on the optimal positions for the arms. Given new and different patient anatomies, it can be challenging to make an informed choice, leading to more frequently colliding arms or limited manipulator workspaces. In this paper, we develop a method to generate the optimal manipulator base positions for the multi-port da Vinci surgical system that minimizes self-collision and environment-collision, and maximizes the surgeon\u2019s reachability inside the patient. Scoring functions are defined for each criterion so that they may be optimized over. Since for multi-manipulator setups, a large number of free parameters are available to adjust the base positioning of each arm, a challenge becomes how one can expediently assess possible setups. We thus also propose methods that perform fast queries of each measure with the use of a proxy collision-checker. We then develop an optimization method to determine the optimal position using the scoring functions. We evaluate the optimality of the base positions for the robot arms on canonical trajectories, and show that the solution yielded by the optimization program can satisfy each criterion. The metrics and optimization strategy are generalizable to other surgical robotic platforms so that patient-side manipulator positioning may be optimized and solved.",
        "primary_area": "",
        "author": "Mingwei Xu;James Di;Nikhil Das;Michael C. Yip;Mingwei Xu;James Di;Nikhil Das;Michael C. Yip",
        "authorids": "/37089000270;/37088998964;/37088071616;/37085382768;/37089000270;/37088998964;/37088071616;/37085382768",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Computer Science and Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561570/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1124533144614894870&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560853",
        "title": "Optimal Object Placement for Minimum Discontinuity Non-revisiting Coverage Task",
        "track": "main",
        "status": "Poster",
        "abstract": "This work considers the optimal non-revisiting coverage tasks with a single non-redundant manipulator for the case when the object can be positioned at a predefined set of locations within the workcell. The scenario is often encountered in typical industrial settings, for instance when the object presents itself along a conveyor belt and its surface can not be serviced at a single location - the object being large or complex for that endeavour. Given the non-bijective nature of manipulator kinematics between task and joint space, without explicit consideration of joint-space continuity during its construction, a continuous coverage path designed in task-space may easily be truncated into intermittent segments where the manipulator needs to adopt a different configuration to continue the task, resulting in manipulator motions where the end-effector will need to lift off the surface, an altogether undesirable characteristic affecting the quality of the final product for smooth operations on objects such as polishing, painting or deburring. In this work, a novel algorithm to optimally partition the task-space whilst considering the various finite locations where the object may be stationed is proposed that ensures joint-space coverage continuity with minimal lift-offs. Results from the algorithm being challenged to achieve coverage of a number of objects, both in simulation and in real tests with an industrial manipulator, prove the effectiveness of the proposed planner when compared with classical coverage strategies faced with the same problem.",
        "primary_area": "",
        "author": "Tong Yang;Jaime Valls Miro;Yue Wang;Rong Xiong;Tong Yang;Jaime Valls Miro;Yue Wang;Rong Xiong",
        "authorids": "/37089400737;/37411105600;/37089395452;/37271511300;/37089400737;/37411105600;/37089395452;/37271511300",
        "aff": "State Key Laboratory of Industrial Control and Technology, Zhejiang University, P.R. China; Robotis Institue at the University of Technology Sydney (UTS:RI), Sydney, Australia; State Key Laboratory of Industrial Control and Technology, Zhejiang University, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560853/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7510503489055315546&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Zhejiang University;University of Technology Sydney",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology;Robotis Institue",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.uts.edu.au",
        "aff_unique_abbr": "ZJU;UTS",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Sydney",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "China;Australia"
    },
    {
        "id": "9561281",
        "title": "Optimal Online Dispatch for High-Capacity Shared Autonomous Mobility-on-Demand Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "Shared autonomous mobility-on-demand systems hold great promise for improving the efficiency of urban transportation, but are challenging to implement due to the huge scheduling search space and highly dynamic nature of requests. This paper presents a novel optimal schedule pool (OSP) assignment approach to optimally dispatch high-capacity ride-sharing vehicles in real time, including: (1) an incremental search algorithm that can efficiently compute the exact lowest-cost schedule of a ride-sharing trip with a reduced search space; (2) an iterative online re-optimization strategy to dynamically alter the assignment policy for new incoming requests, in order to maximize the service rate. Experimental results based on New York City taxi data show that our proposed approach outperforms the state-of-the-art in terms of service rate and system scalability.",
        "primary_area": "",
        "author": "Cheng Li;David Parker;Qi Hao;Cheng Li;David Parker;Qi Hao",
        "authorids": "/37089000323;/37271264600;/37403530000;/37089000323;/37271264600;/37403530000",
        "aff": "Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; School of Computer Science, University of Birmingham, Birmingham, UK; Research Institute of Trustworthy Autonomous System, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561281/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=708873791301521431&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Southern University of Science and Technology;University of Birmingham",
        "aff_unique_dep": "Department of Computer Science and Engineering;School of Computer Science",
        "aff_unique_url": "https://www.sustech.edu.cn;https://www.birmingham.ac.uk",
        "aff_unique_abbr": "SUSTech;UoB",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Shenzhen;Birmingham",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9561059",
        "title": "Optimal Sequential Stochastic Deployment of Multiple Passenger Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a new algorithm for deploying passenger robots in marsupial robot systems. A marsupial robot system consists of a carrier robot (e.g., a ground vehicle), which is highly capable and has a long mission duration, and at least one passenger robot (e.g., a short-duration aerial vehicle) transported by the carrier. We optimize the performance of passenger robot deployment by proposing an algorithm that reasons over uncertainty by exploiting information about the prior probability distribution of features of interest in the environment. Our algorithm is formulated as a solution to a sequential stochastic assignment problem (SSAP). The key feature of the algorithm is a recurrence relationship that defines a set of observation thresholds that are used to decide when to deploy passenger robots. Our algorithm computes the optimal policy in O(NR) time, where N is the number of deployment decision points and R is the number of passenger robots to be deployed. We conducted drone deployment exploration experiments on real-world data from the DARPA Subterranean challenge to test the SSAP algorithm. Our results show that our deployment algorithm outperforms other competing algorithms, such as the classic secretary approach and baseline partitioning methods, and is comparable to an offline oracle algorithm.",
        "primary_area": "",
        "author": "Chris Yu Hsuan Lee;Graeme Best;Geoffrey A. Hollinger;Chris Yu Hsuan Lee;Graeme Best;Geoffrey A. Hollinger",
        "authorids": "/37089002241;/37085672100;/37543482700;/37089002241;/37085672100;/37543482700",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561059/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8565117322817744369&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561900",
        "title": "Optimal TCP and Robot Base Placement for a Set of Complex Continuous Paths",
        "track": "main",
        "status": "Poster",
        "abstract": "The robot base placement of an industrial robot in flexible production lines is crucial due to the limited workspace of robots, in particular for complex continuous paths that change frequently. Costly and time-consuming repositioning of the robot can be avoided by merely adapting the tool center point (TCP) of the robot, which is the focus of this work. To this end, an algorithm for the optimal TCP placement for a set of tool paths is proposed. This algorithm is based on a fast joint-space path planner which is capable of moving through kinematic singularities and takes into account wide turning ranges of individual robot axes. Furthermore, the proposed concept also applies to the optimal robot base placement. The feasibility of the approach is demonstrated for a trim application in shoe production for a set of 44 complex continuous tool paths.",
        "primary_area": "",
        "author": "Thomas Weingartshofer;Christian Hartl-Nesic;Andreas Kugi;Thomas Weingartshofer;Christian Hartl-Nesic;Andreas Kugi",
        "authorids": "/37088998251;/37088822824;/37282440900;/37088998251;/37088822824;/37282440900",
        "aff": "Automation and Control Institute, TU Wien, Vienna, Austria; Automation and Control Institute, TU Wien, Vienna, Austria; Center for Vision, Automation & Control, AIT Austrian Institute of Technology GmbH, Vienna, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561900/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15511518042642399678&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "TU Wien;AIT Austrian Institute of Technology GmbH",
        "aff_unique_dep": "Automation and Control Institute;Center for Vision, Automation & Control",
        "aff_unique_url": "https://www.tuwien.ac.at;https://www.ait.ac.at",
        "aff_unique_abbr": "TU Wien;AIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Vienna",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9561611",
        "title": "Optimal scaling of dynamic safety zones for collaborative robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a safety control approach based on the online optimal scaling of the size of bounding volumes used as dynamic safety zones for collaborative robotics. Intersection tests between bounding volumes surrounding robot and human allow the safety controller to identify possible collisions. Our proposed approach optimizes online smooth stop trajectories, to be engaged if a potential collision is detected. Unlike other approaches, the robot dynamics and its torque constraints are here considered to plan optimal trajectories that minimize the size of safety zones surrounding the robot. Simulation results on a validated model of a robot with seven degrees-of-freedom verify the feasibility of the proposed approach.",
        "primary_area": "",
        "author": "Lorenzo Scalera;Renato Vidoni;Andrea Giusti;Lorenzo Scalera;Renato Vidoni;Andrea Giusti",
        "authorids": "/37086049800;/37872141500;/37085736984;/37086049800;/37872141500;/37085736984",
        "aff": "Polytechnic Department of Engineering and Architecture, University of Udine, Udine, Italy; Faculty of Science and Technology, Free University of Bozen-Bolzano, Bolzano, Italy; Fraunhofer Italia Research, Bolzano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561611/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12233913714410761032&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Udine;Free University of Bozen-Bolzano;Fraunhofer Italia Research",
        "aff_unique_dep": "Polytechnic Department of Engineering and Architecture;Faculty of Science and Technology;",
        "aff_unique_url": "https://www.uniud.it;https://www.unibz.it;https://www.fraunhofer.it/",
        "aff_unique_abbr": ";UNIBZ;Fraunhofer Italia",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Udine;Bolzano",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9562013",
        "title": "Optimization-Based Visual-Inertial SLAM Tightly Coupled with Raw GNSS Measurements",
        "track": "main",
        "status": "Poster",
        "abstract": "Unlike loose coupling approaches and the EKF-based approaches in the literature, we propose an optimization-based visual-inertial SLAM tightly coupled with raw Global Navigation Satellite System (GNSS) measurements, a first attempt of this kind in the literature to our knowledge. More specifically, reprojection error, IMU pre-integration error and raw GNSS measurement error are jointly minimized within a sliding window, in which the asynchronism between images and raw GNSS measurements is accounted for. In addition, issues such as marginalization, noisy measurements removal, as well as tackling vulnerable situations are also addressed. Experimental results on public dataset in complex urban scenes show that our proposed approach outperforms state-of-the-art visual-inertial SLAM, GNSS single point positioning, as well as a loose coupling approach, including scenes mainly containing low-rise buildings and those containing urban canyons.",
        "primary_area": "",
        "author": "Jinxu Liu;Wei Gao;Zhanyi Hu;Jinxu Liu;Wei Gao;Zhanyi Hu",
        "authorids": "/37086526741;/37066625700;/37281086500;/37086526741;/37066625700;/37281086500",
        "aff": "National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, and With School of Artificial Intelligence, University of Chinese Academy of Sciences, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, and With School of Artificial Intelligence, University of Chinese Academy of Sciences, China; National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences, and With School of Artificial Intelligence, University of Chinese Academy of Sciences, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562013/",
        "gs_citation": 74,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11938103991836340868&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Chinese Academy of Sciences",
        "aff_unique_dep": "National Laboratory of Pattern Recognition, Institute of Automation",
        "aff_unique_url": "http://www.cas.cn",
        "aff_unique_abbr": "CAS",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560759",
        "title": "Optimization-Inspired Controller Design for Transient Legged Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "For robots to leave the safety of the laboratory and explore the world, maneuverability will need to be mastered. However, transient motions, such as rapid acceleration and deceleration, have received little attention in the literature. This is mainly due to the complexity of analyzing these high dimensional systems that have no closed-form solution which makes controller design a non-trivial task. One method is to utilize heuristic control inspired by animal locomotion (or intuition), but these may not be optimal for a given task. Here, we take the novel approach and leverage trajectory optimization methods to enable us to identify heuristic controllers for the task of transient locomotion. Specifically, we investigate acceleration to a steady-state gait as well as decelerating from a steady-state gait to rest. These identified heuristic controllers were then validated on a hybrid pneumatic-electric monopod robot. Our initial results indicate that a Raibert controller is in fact the energy optimal policy for transient maneuvers.",
        "primary_area": "",
        "author": "Callen Fisher;Joshua Van Zyl;Reuben Govender;Amir Patel;Callen Fisher;Joshua Van Zyl;Reuben Govender;Amir Patel",
        "authorids": "/37085623300;/37088997490;/37088997516;/38029333400;/37085623300;/37088997490;/37088997516;/38029333400",
        "aff": "Department of Electrical Engineering, University of Cape Town and Stellenbosch University; Department of Electrical Engineering, University of Cape Town; Department of Mechanical Engineering, University of Cape Town; Department of Electrical Engineering, University of Cape Town and Stellenbosch University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560759/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8578647206986949533&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Cape Town",
        "aff_unique_dep": "Department of Electrical Engineering",
        "aff_unique_url": "https://www.ru.ac.za",
        "aff_unique_abbr": "UCT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cape Town;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Africa"
    },
    {
        "id": "9561062",
        "title": "Optimization-based Trajectory Planning for Tethered Aerial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a non-linear optimization method for trajectory planning of tethered aerial robots. Particularly, the paper addresses the planning problem of an unmanned aerial vehicle (UAV) linked to an unmanned ground vehicle (UGV) by means of a tether. The result is a collision-free trajectory for UAV and tether, assuming the UGV position is static. The optimizer takes into account constraints related to the UAV, UGV and tether positions, obstacles and temporal aspects of the motion such as limited robot velocities and accelerations, and finally the tether state, which is not required to be tense. The problem is formulated in a weighted multi-objective optimization framework. Results from simulated scenarios demonstrate that the approach is able to generate obstacle-free and smooth trajectories for the UAV and tether.",
        "primary_area": "",
        "author": "S. Mart\u00ednez-Rozas;D. Alejo;F. Caballero;L. Merino;S. Mart\u00ednez-Rozas;D. Alejo;F. Caballero;L. Merino",
        "authorids": "/37089001872;/37640474500;/37282357300;/37282385100;/37089001872;/37640474500;/37282357300;/37282385100",
        "aff": "Service Robotics Laboratory, Universidad Pablo de Olavide, Seville, Spain; Service Robotics Laboratory, Universidad Pablo de Olavide, Seville, Spain; Service Robotics Laboratory, Universidad Pablo de Olavide, Seville, Spain; Service Robotics Laboratory, Universidad Pablo de Olavide, Seville, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561062/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6619336771731221597&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Universidad Pablo de Olavide",
        "aff_unique_dep": "Service Robotics Laboratory",
        "aff_unique_url": "https://www.upo.es",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Seville",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9561374",
        "title": "Optimized 3D path planner for steerable catheters with deductive reasoning",
        "track": "main",
        "status": "Poster",
        "abstract": "Keyhole neurosurgery is challenging, due to the complex anatomy of the brain and the inherent risk of damaging vital structures while reaching the surgical target. This paper presents a path planner for safe and effective neurosurgical interventions. The strengths of the proposed framework lay in the integration of multiple risk structures combined into a deductive method for fast and intuitive user interaction, and a modular architecture. The tool is intended to support neurosurgeons at quickly determining the most appropriate surgical trajectory through the brain matter with minimized risk; the user interface guides the user through the decision making process and helps save planning time of neurosurgical interventions. Risk structures and trajectories can be visualized in an intuitive way, thanks to a 3D brain surgery simulator developed with Unity. A qualitative evaluation with clinical experts shows the practical relevance, while a quantitative performance and functionality analysis proves the robustness and effectiveness of the system with respect to literature.",
        "primary_area": "",
        "author": "Alice Segato;Valentina Corbetta;Jessica Zangari;Simona Perri;Francesco Calimeri;Elena De Momi;Alice Segato;Valentina Corbetta;Jessica Zangari;Simona Perri;Francesco Calimeri;Elena De Momi",
        "authorids": "/37088505401;/37087003488;/37088998965;/37089000522;/37085812353;/37947344300;/37088505401;/37087003488;/37088998965;/37089000522;/37085812353;/37947344300",
        "aff": "Department of Electronics, Information and Bioengineering, Politecnico di Milano, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Italy; Department of Mathematics and Computer Science, University of Calabria, Italy; Department of Mathematics and Computer Science, University of Calabria, Italy; Department of Mathematics and Computer Science, University of Calabria, Italy; Department of Electronics, Information and Bioengineering, Politecnico di Milano, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561374/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6583522913095044588&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;0",
        "aff_unique_norm": "Politecnico di Milano;University of Calabria",
        "aff_unique_dep": "Department of Electronics, Information and Bioengineering;Department of Mathematics and Computer Science",
        "aff_unique_url": "https://www.polimi.it;https://www.unical.it",
        "aff_unique_abbr": "Politecnico di Milano;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9561032",
        "title": "Optimized Coverage Planning for UV Surface Disinfection",
        "track": "main",
        "status": "Poster",
        "abstract": "UV radiation has been used as a disinfection strategy to deactivate a wide range of pathogens, but existing irradiation strategies do not ensure sufficient exposure of all environmental surfaces and/or require long disinfection times. We present a near-optimal coverage planner for mobile UV disinfection robots. The formulation optimizes the irradiation time efficiency, while ensuring that a sufficient dosage of radiation is received by each surface. The trajectory and dosage plan are optimized taking collision and light occlusion constraints into account. We propose a two-stage scheme to approximate the solution of the induced NP-hard optimization, and, for efficiency, perform key irradiance and occlusion calculations on a GPU. Empirical results show that our technique achieves more coverage for the same exposure time as strategies for existing UV robots, can be used to compare UV robot designs, and produces near-optimal plans.",
        "primary_area": "",
        "author": "Jo\u00e3o Marcos Correia Marques;Ramya Ramalingam;Zherong Pan;Kris Hauser;Jo\u00e3o Marcos Correia Marques;Ramya Ramalingam;Zherong Pan;Kris Hauser",
        "authorids": "/37087111073;/37089000212;/37086067204;/37543748800;/37087111073;/37089000212;/37086067204;/37543748800",
        "aff": "Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Dept. of Computer Science and the Dept. of Mathematics, Harvey Mudd College, Claremont, CA, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Computer Science, University of Illinois at Urbana-Champaign, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561032/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3318032825852721264&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Harvey Mudd College",
        "aff_unique_dep": "Department of Computer Science;Dept. of Computer Science",
        "aff_unique_url": "https://illinois.edu;https://www.harveymudd.edu",
        "aff_unique_abbr": "UIUC;HMC",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Urbana;Claremont",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560903",
        "title": "Optimized Method for Planning and Controlling the Somersault Motion of Quadruped Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "A method for planning and controlling the somersault motion of a quadruped robot is proposed in this paper. The method divides the somersault motion into 5 stages according to intuitive understanding. Based on the simplified dynamic model, the linear programming method is used to obtain the maximum ground reaction force under the constraints of joint torque and friction cone, and then the optimal leg thrusting trajectory is obtained by double integration of the acceleration. In order to achieve the buffered landing of the robot after somersault, a whole body controller based on null space projection is used to obtain the optimal joint torque under the constraints of the robot\u2019s foot position, torso position and torso posture. The somersault motion control method proposed in this paper has been verified by the dynamics simulation software Webots and quadruped robot platform Yobogo. The results show that the robot can complete stable front flip and back flip under the constraints of joint output torque and foot motion space constraints.",
        "primary_area": "",
        "author": "Teng Chen;Xuewen Rong;Yibin Li;Teng Chen;Xuewen Rong;Yibin Li",
        "authorids": "/37087243805;/37544692600;/37279897500;/37087243805;/37544692600;/37279897500",
        "aff": "Robotics, School of Control Science and Engineering, Shandong University, Jinan, China; Robotics, School of Control Science and Engineering, Shandong University, Jinan, China; Robotics, School of Control Science and Engineering, Shandong University, Jinan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560903/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12721242452786207119&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shandong University",
        "aff_unique_dep": "School of Control Science and Engineering",
        "aff_unique_url": "http://www.sdu.edu.cn",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Jinan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561052",
        "title": "Optimizing Cellular Networks via Continuously Moving Base Stations on Road Networks",
        "track": "main",
        "status": "Poster",
        "abstract": "Although existing cellular network base stations are typically immobile, the recent development of small form factor base stations and self driving cars has enabled the possibility of deploying a team of continuously moving base stations that can reorganize the network infrastructure to adapt to changing network traffic usage patterns. Given such a system of mobile base stations (MBSes) that can freely move on the road, how should their path be planned in an effort to optimize the experience of the users? This paper addresses this question by modeling the problem as a Markov Decision Process where the actions correspond to the MBSes deciding which direction to go at traffic intersections; states corresponds to the position of MBSes; and rewards correspond to minimization of packet loss in the network. A Monte Carlo Tree Search (MCTS)-based anytime algorithm that produces path plans for multiple base stations while optimizing expected packet loss is proposed. Simulated experiments in the city of Verdun, QC, Canada with varying user equipment (UE) densities and random initial conditions show that the proposed approach consistently outperforms myopic planners, and is able to achieve near-optimal performance.",
        "primary_area": "",
        "author": "Yogesh Girdhar;Dmitriy Rivkin;Di Wu;Michael Jenkin;Xue Liu;Gregory Dudek;Yogesh Girdhar;Dmitriy Rivkin;Di Wu;Michael Jenkin;Xue Liu;Gregory Dudek",
        "authorids": "/37546414900;/37088997535;/37085491676;/37269066400;/37089919928;/37274057100;/37546414900;/37088997535;/37085491676;/37269066400;/37089919928;/37274057100",
        "aff": "Samsung AI Center, Montreal, Canada; Samsung AI Center, Montreal, Canada; Samsung AI Center, Montreal, Canada; Samsung AI Center, Montreal, Canada; Samsung AI Center, Montreal, Canada; Samsung AI Center, Montreal, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561052/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4755599325055763077&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "Samsung AI",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Montreal",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561670",
        "title": "Optimizing Keypoint-based Single-Shot Camera-to-Robot Pose Estimation through Shape Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce an optimization method for recent approaches on keypoint-based pose estimation of robotic manipulators utilizing monocular images. The method takes into account the segmented shape of the robot using Convolutional Neural Networks and a keypoint refinement through a set of score values. To this end, the primal 2D keypoint detection is exploited as an initial guess for further shape-based keypoint adjustments. Afterwards, the overall methods incorporates a perspective-n-point algorithm using 3D point correspondences that are derived by forward kinematics. We hereby complement an existing public dataset with annotated segmentations of a Universal Robot UR5 manipulator. The evaluation of the optimization approach shows clearly that noise on the initial key-point detection can be suppressed and minimized. Furthermore, the overall success rate of the perspective transformation can be enhanced towards more than 90%. Thus, the overall methods is applicable for single-shot pose estimation. The evaluation results also show a significant reduction of the standard deviation of the resulting pose estimation. Consequently, the proposed optimization positively affects applicability and precision.",
        "primary_area": "",
        "author": "Jens Lambrecht;Philipp Grosenick;Marvin Meusel;Jens Lambrecht;Philipp Grosenick;Marvin Meusel",
        "authorids": "/37342634600;/37088902585;/37088904080;/37342634600;/37088902585;/37088904080",
        "aff": "Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering and Computer Science, Technische Universit\u00e4t Berlin, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering and Computer Science, Technische Universit\u00e4t Berlin, Berlin, Germany; Chair Industry Grade Networks and Clouds, Faculty of Electrical Engineering and Computer Science, Technische Universit\u00e4t Berlin, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561670/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5290889302104056755&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t Berlin",
        "aff_unique_dep": "Faculty of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.tu-berlin.de",
        "aff_unique_abbr": "TU Berlin",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berlin",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561494",
        "title": "Optimizing Part Placement for Improving Accuracy of Robot-Based Additive Manufacturing",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic manipulators are increasingly being used to perform additive manufacturing. The accuracy of a built part is dependent on the trajectory execution error of the manipulator. For articulated manipulators, the trajectory execution error and achievable build accuracy vary considerably over the workspace. Therefore, the build accuracy depends on where the part is placed in the manipulator workspace. If the part is small compared to the manipulator workspace, its placement can be optimized to improve the accuracy. This paper provides experimental evidence that the placement of the parts changes its build accuracy. We model the trajectory execution error of the manipulator for additive manufacturing. We validate these errors by comparing the predicted errors with the experimental errors. Finally, we present an algorithm to optimize the part placement for improving built part accuracy during robot-based additive manufacturing.",
        "primary_area": "",
        "author": "Prahar M. Bhatt;Ashish Kulkarni;Rishi K. Malhan;Satyandra K. Gupta;Prahar M. Bhatt;Ashish Kulkarni;Rishi K. Malhan;Satyandra K. Gupta",
        "authorids": "/37086936500;/37088996303;/37086537030;/37878971100;/37086936500;/37088996303;/37086537030;/37878971100",
        "aff": "Center for Advanced Manufacturing, University of Southern California, CA, USA; Center for Advanced Manufacturing, University of Southern California, CA, USA; Center for Advanced Manufacturing, University of Southern California, CA, USA; Center for Advanced Manufacturing, University of Southern California, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561494/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4263313199555544440&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Center for Advanced Manufacturing",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561762",
        "title": "Order Matters: Generating Progressive Explanations for Planning Tasks in Human-Robot Teaming",
        "track": "main",
        "status": "Poster",
        "abstract": "Prior work on generating explanations in a planning context has focused on providing the rationale behind an AI agent\u2019s decision-making. While these methods offer the right explanations, they fail to heed the cognitive requirement of understanding an explanation from the explainee or human\u2019s perspective. In this work, we set out to address this issue by considering the order for communicating information in an explanation, or the progressiveness of making explanations. Progression is the notion of building complex concepts on simpler ones, which is known to benefit learning. In this work, we investigate a similar effect when an explanation is composed of multiple parts that are communicated sequentially. The challenge here lies in determining the order for receiving different parts of an explanation that would assist in understanding. Given the sequential nature, a formulation based on goal-based MDP is presented. The reward function of this MDP is learned via inverse reinforcement learning based on training data. We evaluated our approach in an escape-room domain to demonstrate its effectiveness. Upon analyzing the results, it revealed that the desired order arises strongly from both domain-dependent and independence features. This result confirmed our expectation that the process of understanding an explanation for planning tasks was progressive and context dependent. We also showed that the explanations generated using the learned rewards achieved better task performance and simultaneously reduced cognitive load. These results shed light on designing explainable robots across various domains.",
        "primary_area": "",
        "author": "Mehrdad Zakershahrak;Shashank Rao Marpally;Akshay Sharma;Ze Gong;Yu Zhang;Mehrdad Zakershahrak;Shashank Rao Marpally;Akshay Sharma;Ze Gong;Yu Zhang",
        "authorids": "/37086512489;/37088996919;/37088996983;/37086453818;/37086071738;/37086512489;/37088996919;/37088996983;/37086453818;/37086071738",
        "aff": "School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ; School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ; School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ; School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ; School of Computing, Informatics and Decision Systems Engineering, Arizona State University, Tempe, AZ",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561762/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17853419354645059281&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School of Computing, Informatics and Decision Systems Engineering",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561742",
        "title": "Orientation Control of an Electromagnetically Actuated Soft-Tethered Colonoscope Based on 2OR Pseudo-Rigid-Body Model",
        "track": "main",
        "status": "Poster",
        "abstract": "Colorectal cancer incidence has been steadily rising worldwide. Magnetic colonoscopes provide new approaches to conduct colon inspection and treatment. This paper presents a novel electromagnetically actuated soft-tethered colonoscope to achieve precise and stable orientation control. An inflated balloon is designed to eliminate the unpredictable disturbance of the floating tether. A 2OR Pseudo-Rigid-Body (PRB) model of the soft tether is developed to analyze the relationship between the tether deflection and applied force and torque. A closed-loop control framework is constructed with visual position feedback. Experiments are first conducted to validate the assumption of the PRB model and the efficacy of the magnetic field model. Then, trajectory tracking tasks and disturbance rejection tests are performed to validate the feasibility of the proposed solution and closed-loop control. Results show that the colonoscope can stably and accurately orient to the desired orientation with an absolute mean position error of less than 0.5 mm and an average velocity of 3.5 mm/s. The distal tip can quickly re-stabilize to the desired orientation even when a large disturbance exists.",
        "primary_area": "",
        "author": "Yehui Li;Weibing Li;Wenci Xin;Xue Zhang;Yitian Xian;Philip Wai Yan Chiu;Zheng Li;Yehui Li;Weibing Li;Wenci Xin;Xue Zhang;Yitian Xian;Philip Wai Yan Chiu;Zheng Li",
        "authorids": "/37088535100;/37087238169;/37088533289;/37087468458;/37088998568;/37085379340;/38469473900;/37088535100;/37087238169;/37088533289;/37087468458;/37088998568;/37085379340;/38469473900",
        "aff": "Department of Surgery, The Chinese University of Hong Kong, Hong Kong; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China; Department of Surgery, The Chinese University of Hong Kong, Hong Kong; Department of Surgery, The Chinese University of Hong Kong, Hong Kong; Chow Yuk Ho Technology Centre for Innovative Medicine, The Chinese University of Hong Kong, Hong Kong; Department of Surgery and the Chow Yuk Ho Technology Centre for Innovative Medicine, The Chinese University of Hong Kong, Hong Kong; Department of Surgery, Chow Yuk Ho Technology Centre for Innovative Medicine, Li Ka Shing Institute of Health Science, and Multi-Scale Medical Robotics Center Ltd, The Chinese University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561742/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6880590903329414446&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong;Sun Yat-sen University",
        "aff_unique_dep": "Department of Surgery;School of Computer Science and Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;http://www.sysu.edu.cn",
        "aff_unique_abbr": "CUHK;SYSU",
        "aff_campus_unique_index": "0;1;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR;Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562094",
        "title": "Origami-Inspired Snap-through Bistability in Parallel and Curved Mechanisms Through the Inflection of Degree Four Vertexes",
        "track": "main",
        "status": "Poster",
        "abstract": "Origami, the art of folding paper, can impart useful design inspirations to the creation of mechanical structures and mechanisms. Bistability is a useful property for origami designs, which can help compartmentalize different actuations and stiffness tuning regimes. Given the benefits of bistability, we investigated origami designs used to build robots and deployable structures. We show snap-through bistable designs applied to parallel and curved mechanisms, which are of value to robotic mechanical design. The designs proposed were investigated through geometry analysis and stress-strain experiments. The origami designs were modified to show that the mechanical properties of our bistable designs can be modulated. Initial actuation utilized magnetic and tendon-driven mechanisms for the parallel and curved structures, respectively. We anticipate that these bistable snap-through designs can contribute to deployable mechanisms and give such devices additional capabilities in mechanical response tuning.",
        "primary_area": "",
        "author": "Bok Seng Yeow;Catherine Jiayi Cai;Manivannan Sivaperuman Kalairaj;Feng Wen Hoo;Zu Xuan Lee;Janice Chui Shien Tan;Jian Rong Ho;Vienna Minhui Ma;Hui Huang;Hongliang Ren;Bok Seng Yeow;Catherine Jiayi Cai;Manivannan Sivaperuman Kalairaj;Feng Wen Hoo;Zu Xuan Lee;Janice Chui Shien Tan;Jian Rong Ho;Vienna Minhui Ma;Hui Huang;Hongliang Ren",
        "authorids": "/37085776291;/37086246365;/37088918427;/37089001708;/37088997064;/37088998644;/37088996451;/37089000827;/37088915242;/37287561300;/37085776291;/37086246365;/37088918427;/37089001708;/37088997064;/37088998644;/37088996451;/37089000827;/37088915242;/37287561300",
        "aff": "Department of Biomedical Engineering, National University of Singapore, Singapore; Singapore Institute of Manufacturing Technology, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore; Department of Biomedical Engineering, National University of Singapore, Singapore; Singapore Institute of Manufacturing Technology, Singapore; Department of Electronic Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562094/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13831943695625480270&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 20,
        "aff_unique_index": "0;1;0;0;0;0;0;0;1;2",
        "aff_unique_norm": "National University of Singapore;Singapore Institute of Manufacturing Technology;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Biomedical Engineering;;Department of Electronic Engineering",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.simtech.sg;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "NUS;SIMTech;CUHK",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;1",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9560957",
        "title": "Out-of-Distribution Robustness with Deep Recursive Filters",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate state and uncertainty estimation is imperative for mobile robots and self driving vehicles to achieve safe navigation in pedestrian rich environments. A critical component of state and uncertainty estimation for robot navigation is to perform robustly under out-of-distribution noise. Traditional methods of state estimation decouple perception and state estimation making it difficult to operate on noisy, high dimensional data. Here, we describe an approach that combines the expressiveness of deep neural networks with principled approaches to uncertainty estimation found in recursive filters. We particularly focus on techniques that provide better robustness to out-of-distribution noise and demonstrate applicability of our approach on two scenarios: a simple noisy pendulum state estimation problem and real world pedestrian localization using the nuScenes dataset [1]. We show that our approach improves state and uncertainty estimation compared to baselines while achieving approximately 3\u00d7 improvement in computational efficiency.",
        "primary_area": "",
        "author": "Kapil D. Katyal;I-Jeng Wang;Gregory D. Hager;Kapil D. Katyal;I-Jeng Wang;Gregory D. Hager",
        "authorids": "/38228973900;/37089270283;/37276163200;/38228973900;/37089270283;/37276163200",
        "aff": "Dept. of Comp. Sci., Johns Hopkins University, Baltimore, MD, USA; Johns Hopkins University Applied Physics Lab, Laurel, MD, USA; Dept. of Comp. Sci., Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560957/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:y4QqU40rQPYJ:scholar.google.com/&scioq=Out-of-Distribution+Robustness+with+Deep+Recursive+Filters&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Baltimore;Laurel",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560865",
        "title": "Out-of-Plane Corrections for Autonomous Robotic Breast Ultrasound Acquisitions",
        "track": "main",
        "status": "Poster",
        "abstract": "Breast cancer affects one out of eight women. Ultrasound (US) plays an important role in the diagnostic workflow, especially during the biopsy phase, in which tissue is extracted from the lesion for further analysis. The extension from 2D to 3D US acquisitions has multiple benefits including enhanced lesion localization and improved registration with MRI data. Current commercial 3D US systems lack the ability to preserve the breast\u2019s original shape. Robotic US scanners follow tailored trajectories and produce high quality volumes by accurate localization of 2D slices captured with a conventional linear probe. Current methods require a patient specific model to plan the scanning trajectory.In this study we investigate how to change the direction of the scanning trajectory based on US feedback, such that no patient specific model is required to perform a scan. In our method, the scanning trajectory is kept tangent to the breast based on confidence maps of the US images and an estimation of current radius of curvature of the surface. We evaluated our approach on a realistic breast phantom. The robot revolves around the breast without prior knowledge of its shape. In ten scans, the RMS error between the probe\u2019s scanning plane and the breast\u2019s surface normal is 12.6\u00b0 out-of-plane, and 4.3\u00b0 in-plane. A 3D US reconstruction shows the acquired data. This is a step forward to fully autonomous, high quality robotic US volume acquisitions.",
        "primary_area": "",
        "author": "M.K. Welleweerd;A.G. de Groot;V. Groenhuis;F. J. Siepel;S. Stramigioli;M.K. Welleweerd;A.G. de Groot;V. Groenhuis;F. J. Siepel;S. Stramigioli",
        "authorids": "/37088505531;/37088507529;/37085817635;/37085997643;/37282439300;/37088505531;/37088507529;/37085817635;/37085997643;/37282439300",
        "aff": "Robotics and Mechatronics Group, University of Twente, The Netherlands; Robotics and Mechatronics Group, University of Twente, The Netherlands; Robotics and Mechatronics Group, University of Twente, The Netherlands; Robotics and Mechatronics Group, University of Twente, The Netherlands; Bio-Mechatronics and Energy-Efficient Robotics Group, ITMO University, St. Petersburg, The Russian Federation",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560865/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18034301232118541441&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "University of Twente;ITMO University",
        "aff_unique_dep": "Robotics and Mechatronics Group;Bio-Mechatronics and Energy-Efficient Robotics Group",
        "aff_unique_url": "https://www.utwente.nl;https://www.itmo.ru",
        "aff_unique_abbr": ";ITMO",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";St. Petersburg",
        "aff_country_unique_index": "0;0;0;0;1",
        "aff_country_unique": "Netherlands;Russian Federation"
    },
    {
        "id": "9562047",
        "title": "PATHoBot: A Robot for Glasshouse Crop Phenotyping and Intervention",
        "track": "main",
        "status": "Poster",
        "abstract": "We present PATHoBot an autonomous crop surveying and intervention robot for glasshouse environments. The aim of this platform is to autonomously gather high quality data and also estimate key phenotypic parameters. To achieve this we retro-fit an off-the-shelf pipe-rail trolley with an array of multi-modal cameras, navigation sensors and a robotic arm for close surveying tasks and intervention. In this paper we describe PATHoBot design choices made to ensure proper operation in a commercial glasshouse environment. As a surveying platform we collect a number of datasets which include both sweet pepper and tomatoes. We show how PATHoBot enables novel surveillance approaches by first improving our previous work on fruit counting by incorporating wheel odometry and depth information. We find that by introducing re-projection and depth information we are able to achieve an absolute improvement of 20 points over the baseline technique in an \"in the wild\" situation. Finally, we present a 3D mapping case study, further showcasing PATHoBot\u2019s crop surveying capabilities.",
        "primary_area": "",
        "author": "Claus Smitt;Michael Halstead;Tobias Zaenker;Maren Bennewitz;Chris McCool;Claus Smitt;Michael Halstead;Tobias Zaenker;Maren Bennewitz;Chris McCool",
        "authorids": "/37088999928;/37085368005;/37088540533;/37324765000;/38274733400;/37088999928;/37085368005;/37088540533;/37324765000;/38274733400",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562047/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8222103795279725239&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561449",
        "title": "PCMPC: Perception-Constrained Model Predictive Control for Quadrotors with Suspended Loads using a Single Camera and IMU",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we address the Perception\u2013 Constrained Model Predictive Control (PCMPC) and state estimation problems for quadrotors with cable suspended payloads using a single camera and Inertial Measurement Unit (IMU). We design a receding\u2013horizon control strategy for cable suspended payloads directly formulated on the system manifold configuration space SE (3) \u00d7S2. The approach considers the system dynamics, actuator limits and the camera\u2019s Field Of View (FOV) constraint to guarantee the payload\u2019s visibility during motion. The monocular camera, IMU, and vehicle\u2019s motor speeds are combined to provide estimation of the vehicle\u2019s states in 3D space, the payload\u2019s states, the cable\u2019s direction and velocity. The proposed control and state estimation solution runs in real-time at 500 Hz on a small quadrotor equipped with a limited computational unit. The approach is validated through experimental results considering a cable suspended payload trajectory tracking problem at different speeds.",
        "primary_area": "",
        "author": "Guanrui Li;Alex Tunchez;Giuseppe Loianno;Guanrui Li;Alex Tunchez;Giuseppe Loianno",
        "authorids": "/37086455447;/37089001498;/37085496544;/37086455447;/37089001498;/37085496544",
        "aff": "Tandon School of Engineering, The New York University, Brooklyn, NY, USA; Tandon School of Engineering, The New York University, Brooklyn, NY, USA; Tandon School of Engineering, The New York University, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561449/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1628739627187410914&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "Tandon School of Engineering",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brooklyn",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561035",
        "title": "PENet: Towards Precise and Efficient Image Guided Depth Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "Image guided depth completion is the task of generating a dense depth map from a sparse depth map and a high quality image. In this task, how to fuse the color and depth modalities plays an important role in achieving good performance. This paper proposes a two-branch backbone that consists of a color-dominant branch and a depth-dominant branch to exploit and fuse two modalities thoroughly. More specifically, one branch inputs a color image and a sparse depth map to predict a dense depth map. The other branch takes as inputs the sparse depth map and the previously predicted depth map, and outputs a dense depth map as well. The depth maps predicted from two branches are complimentary to each other and therefore they are adaptively fused. In addition, we also propose a simple geometric convolutional layer to encode 3D geometric cues. The geometric encoded backbone conducts the fusion of different modalities at multiple stages, leading to good depth completion results. We further implement a dilated and accelerated CSPN++ to refine the fused depth map efficiently. The proposed full model ranks 1st in the KITTI depth completion online leaderboard at the time of submission. It also infers much faster than most of the top ranked methods. The code of this work is available at https://github.com/JUGGHM/PENet_ICRA2021.",
        "primary_area": "",
        "author": "Mu Hu;Shuling Wang;Bin Li;Shiyu Ning;Li Fan;Xiaojin Gong;Mu Hu;Shuling Wang;Bin Li;Shiyu Ning;Li Fan;Xiaojin Gong",
        "authorids": "/37088887649;/37088888639;/37087232938;/37088999716;/37088997074;/38240763200;/37088887649;/37088888639;/37087232938;/37088999716;/37088997074;/38240763200",
        "aff": "College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China; Department of Turing Solution, Hisil-icon, Huawei, Shanghai, China; Department of Turing Solution, Hisil-icon, Huawei, Shanghai, China; College of Information Science and Electronic Engineering, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561035/",
        "gs_citation": 369,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15267545345722176992&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;1;0",
        "aff_unique_norm": "Zhejiang University;Huawei",
        "aff_unique_dep": "College of Information Science and Electronic Engineering;Department of Turing Solution",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.huawei.com",
        "aff_unique_abbr": "ZJU;Huawei",
        "aff_campus_unique_index": "0;0;0;1;1;0",
        "aff_campus_unique": "Hangzhou;Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560776",
        "title": "PLG-IN: Pluggable Geometric Consistency Loss with Wasserstein Distance in Monocular Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel objective for penalizing geometric inconsistencies and improving the depth and pose estimation performance of monocular camera images. Our objective is designed using the Wasserstein distance between two point clouds, estimated from images with different camera poses. The Wasserstein distance can impose a soft and symmetric coupling between two point clouds, which suitably maintains geometric constraints and results in a differentiable objective. By adding our objective to those of other state-of-the-art methods, we can effectively penalize geometric inconsistencies and obtain highly accurate depth and pose estimations. Our proposed method was evaluated using the KITTI dataset.",
        "primary_area": "",
        "author": "Noriaki Hirose;Satoshi Koide;Keisuke Kawano;Ruho Kondo;Noriaki Hirose;Satoshi Koide;Keisuke Kawano;Ruho Kondo",
        "authorids": "/37574851500;/37086508809;/37088479649;/37089002029;/37574851500;/37086508809;/37088479649;/37089002029",
        "aff": "Toyota Central R&D Labs., INC., Japan; Toyota Central R&D Labs., INC., Japan; Toyota Central R&D Labs., INC., Japan; Toyota Central R&D Labs., INC., Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560776/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12865012356591041193&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Toyota Central R&D Labs., Inc.",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.toyota-global.com/company/profile",
        "aff_unique_abbr": "Toyota R&D",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9562045",
        "title": "POIS: Policy-Oriented Instance Segmentation for Ambidextrous Robot Picking",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots with a parallel-jaw gripper and suction cup is an adaptive and efficient robotic picking system. This paper proposed Policy-Oriented Instance Segmentation (POIS) for ambidextrous robots. POIS can generate a pair of target masks that allows ambidextrous robots to pick in parallel. It takes a depth image and predicts initial mask, center offset, and policy confidence map through three paralleled branches. We incorporate the initial mask with center offset to obtain candidate instances, from which we select masks of target objects for policy execution (decided with policy confidence map). We also provide a dataset that contains 6k synthetic scenes and 100 real scenes for ambidextrous picking. Trained on synthetic scenes, POIS generalizes well in real scene and is capable of handling novel objects in cluttered scenes. Our dataset and video are available at https://bit.ly/3oJj8Tu.",
        "primary_area": "",
        "author": "Guangyun Xu;Yi Tao;Bowen Jiang;Peng Wang;Yongkang Luo;Jun Zhong;Guangyun Xu;Yi Tao;Bowen Jiang;Peng Wang;Yongkang Luo;Jun Zhong",
        "authorids": "/37088999560;/37088996232;/37089000680;/37538869400;/37085483874;/37089001468;/37088999560;/37088996232;/37089000680;/37538869400;/37085483874;/37089001468",
        "aff": "School of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China; Columbia University, New York, NY, USA; Harvey Mudd College, Claremont, CA, USA; CAS Center for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences, Shanghai, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China; Institute of Automation, Chinese Academy of Sciences, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562045/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13578991384901931623&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;3;3",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Columbia University;Harvey Mudd College;Chinese Academy of Sciences",
        "aff_unique_dep": "School of Artificial Intelligence;;;Center for Excellence in Brain Science and Intelligence Technology",
        "aff_unique_url": "http://www.ucas.ac.cn;https://www.columbia.edu;https://www.hmc.edu;http://www.cas.cn",
        "aff_unique_abbr": "UCAS;Columbia;HMC;CAS",
        "aff_campus_unique_index": "0;1;2;3;0;0",
        "aff_campus_unique": "Beijing;New York;Claremont;Shanghai",
        "aff_country_unique_index": "0;1;1;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561554",
        "title": "PSF-LO: Parameterized Semantic Features Based Lidar Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Lidar odometry (LO) is a key technology in numerous reliable and accurate localization and mapping systems of autonomous driving. The state-of-the-art LO methods generally leverage geometric information to perform point cloud registration. Furthermore, obtaining the point cloud semantic information describing the environment more abundantly will facilitate the registration. We present a novel semantic lidar odometry method based on self-designed parameterized seman-tic features (PSFs) to achieve low-drift ego-motion estimation for autonomous vehicle in real time. We first use a convolutional neural network-based algorithm to obtain point-wise semantics from the input laser point cloud, and then use semantic labels to separate road, building, traffic sign and pole-like point cloud and fit them separately to obtain corresponding PSFs. A fast PSF-based matching enables us to refine geometric features (GeFs) registration, thereby reducing the impact of blurred submap surface on the accuracy of GeFs matching. Besides, we design an efficient instance-level method to accurately recognize and remove the dynamic objects while retaining static ones in the semantic point cloud, which are beneficial to further improve the accuracy of LO. We evaluate our method, namely PSF-LO, on the public dataset KITTI Odometry Benchmark and rank #1 among semantic lidar methods with an average translational error of 0.82% in the test dataset.",
        "primary_area": "",
        "author": "Guibin Chen;Bosheng Wang;Xiaoliang Wang;Huanjun Deng;Bing Wang;Shuo Zhang;Guibin Chen;Bosheng Wang;Xiaoliang Wang;Huanjun Deng;Bing Wang;Shuo Zhang",
        "authorids": "/37089000426;/37088999247;/37088423969;/37088996595;/37085487177;/37089002144;/37089000426;/37088999247;/37088423969;/37088996595;/37085487177;/37089002144",
        "aff": "Alibaba DAMO Academy Autonomous Driving Lab, Hangzhou, China; Alibaba DAMO Academy Autonomous Driving Lab, Hangzhou, China; Alibaba DAMO Academy Autonomous Driving Lab, Hangzhou, China; Alibaba DAMO Academy Autonomous Driving Lab, Hangzhou, China; Alibaba DAMO Academy Autonomous Driving Lab, Hangzhou, China; Alibaba DAMO Academy Autonomous Driving Lab, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561554/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15349103267530244024&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Alibaba DAMO Academy",
        "aff_unique_dep": "Autonomous Driving Lab",
        "aff_unique_url": "https://damo.alibaba.com",
        "aff_unique_abbr": "Alibaba DAMO",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561625",
        "title": "Parallel Actuation of Nanorod Swarm and Nanoparticle Swarm to Different Targets",
        "track": "main",
        "status": "Poster",
        "abstract": "After years of development, various swarms of robots have been proposed for many complicated tasks, such as forming patterns, cooperative locomotion, and adapting to different environments. However, controlling microrobotic swarms is still a challenging task owing to the lacking of integrated devices on the small-scale agents, and actuation of multiple microrobotic swarms to different targets under the same global input will be even more difficult. In this work, we present a swarm of nickel nanorods and its diverse locomotion velocity compared with Fe3O4 nanoparticle swarms is implemented for actuating the two swarms to different targets under the same customized oscillating magnetic field. The effects of the magnetic anisotropy of agents on the macroscopic swarm behaviour are analysed theoretically. To prove the strategy, the speeds of the two swarms were characterized through experiments, and demonstrations were conducted to show the capability of driving the two swarms to different locations in the same environment. Furthermore, parallel locomotion of the two swarms towards opposite directions was also achieved on a tilted substrate. This work has proved the feasibility of simultaneously actuating two swarms to diverse targets and promoted fundamental understandings of microrobotic swarms.",
        "primary_area": "",
        "author": "Xingzhou Du;Dongdong Jin;Qianqian Wang;Shihao Yang;Philip Wai Yan Chiu;Li Zhang;Xingzhou Du;Dongdong Jin;Qianqian Wang;Shihao Yang;Philip Wai Yan Chiu;Li Zhang",
        "authorids": "/37086593722;/37085677085;/37086080420;/37088996371;/37088831941;/37085379138;/37086593722;/37085677085;/37086080420;/37088996371;/37088831941;/37085379138",
        "aff": "Chow Yuk Ho Technology Centre for Innovative Medicine, The Chinese University of Hong Kong, Hong Kong, China; Department of Biomedical Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong, China; CUHK T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong, China; CUHK T Stone Robotics Institute, The Chinese University of Hong Kong, Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561625/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1233429921364303522&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Chow Yuk Ho Technology Centre for Innovative Medicine",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561601",
        "title": "Parameterizable and Jerk-Limited Trajectories with Blending for Robot Motion Planning and Spherical Cartesian Waypoints",
        "track": "main",
        "status": "Poster",
        "abstract": "",
        "primary_area": "",
        "author": "Jianjie Lin;Markus Rickert;Alois Knoll;Jianjie Lin;Markus Rickert;Alois Knoll",
        "authorids": "/37088691130;/37681876600;/37276234100;/37088691130;/37681876600;/37276234100",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561601/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3670394326532865079&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6
    },
    {
        "id": "9561181",
        "title": "ParametricNet: 6DoF Pose Estimation Network for Parametric Shapes in Stacked Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "Most industrial parts are parametric and their special properties are not fully explored yet. This paper proposes a new 6DoF pose estimation network for parametric shapes in stacked scenarios (ParametricNet). It treats a parametric shape, instead of a part object, as a category. The keypoints of individual instances are learned with point- wise regression and Hough voting scheme, from which specific parameter values are calculated. Then, the template keypoints are obtained based on the computed parameter values and the parametric shape templates. Finally, the 6DoF pose is estimated by least-square fitting between the individual instance\u2019s and the template\u2019s keypoints & centroid. On the public Sil\u00e9ane dataset, the average of APs of ParametricNet is 96%, compared with 82% for the state-of-the-art method. In addition, a new parametric dataset with four shape templates is constructed, in which the evaluated learning and generalization abilities of ParametricNet outperform the state-of-the-art methods. In particular, for the less symmetric shape, the mAP is improved by over 20%, which is an obvious improvement. Real-world experiments show that our method can grasp parametric shapes with unknown parameter values in stacked scenarios.",
        "primary_area": "",
        "author": "Long Zeng;Wei Jie Lv;Xin Yu Zhang;Yong Jin Liu;Long Zeng;Wei Jie Lv;Xin Yu Zhang;Yong Jin Liu",
        "authorids": "/37087324062;/37089000588;/37089397985;/37279426700;/37087324062;/37089000588;/37089397985;/37279426700",
        "aff": "Department of Advanced Manufacturing, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Department of Advanced Manufacturing, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Department of Advanced Manufacturing, Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Department of Computer Science and Technology, BNRist, MOE Key Laboratory of Pervasive Computing, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561181/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6890035029328989188&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Advanced Manufacturing",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tsinghua",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Shenzhen;Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561995",
        "title": "Partial Information Target Defense Game",
        "track": "main",
        "status": "Poster",
        "abstract": "We formulate a scenario in which an autonomous defender is tasked with intercepting an intruder that tries to reach a circular target region. This is a variant of the target defense problem proposed by Isaacs as a pursuit-evasion game. Unlike the original target guarding problem and its various extensions, we consider the effect of partial information by imposing sensing limitation to the robots. We analyze the game by decomposing it into three game phases: deployment, asymmetric information, and engagement phase. Focusing on a particular parameter regime, we propose a simple defender strategy together with the lower bound on the probability that it wins the game. The defender strategy in each phase is constructed so that the subsequent phase starts in a desired initial configuration. The proposed problem is rich in terms of the parameter regimes that it contains, and thus is expected to be a useful platform in exploring effective control policies.",
        "primary_area": "",
        "author": "Daigo Shishika;Dipankar Maity;Michael Dorothy;Daigo Shishika;Dipankar Maity;Michael Dorothy",
        "authorids": "/37085516690;/37708721600;/37088339197;/37085516690;/37708721600;/37088339197",
        "aff": "Mechanical Engineering Department, George Mason University, Fairfax, VA, USA; Department of the Electrical and Computer Engineering, University of North Carolina, Charlotte, NC, USA; CCDC Army Research Laboratory, Adelphi, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561995/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16158645612394317669&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "George Mason University;University of North Carolina, Charlotte;CCDC Army Research Laboratory",
        "aff_unique_dep": "Mechanical Engineering Department;Department of the Electrical and Computer Engineering;",
        "aff_unique_url": "https://www.gmu.edu;https://www.uncc.edu;",
        "aff_unique_abbr": "GMU;UNCC;",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Fairfax;Charlotte;Adelphi",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561291",
        "title": "Path Optimization for Ground Vehicles in Off-Road Terrain",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for path optimization for ground vehicles in off-road environments at high speeds. This path optimization considers the kinematic constraints of the vehicle. By thinking in the actuator space we can represent such constraints as limits in the space rather than derived properties of the path. In this paper we present an actuator space approach to path optimization for off-road ground vehicles. This is done by representing the path as a list of steering angles over the path length. This transforms the set of kinematic constraints into constraints on the steering angle. We then put this path into a gradient descent solver. This produces paths that are kinematically feasible and optimized in accordance with our cost function. Finally, we tested the system both in simulation and on an off-road vehicle at speeds of 5 m/s.",
        "primary_area": "",
        "author": "Timothy Overbye;Srikanth Saripalli;Timothy Overbye;Srikanth Saripalli",
        "authorids": "/37088504606;/37278939200;/37088504606;/37278939200",
        "aff": "Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA; Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561291/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3635904187111713076&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Texas A&M University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.tamu.edu",
        "aff_unique_abbr": "TAMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "College Station",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561834",
        "title": "Path Planning for a Reconfigurable Robot in Extreme Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, the inspection of extreme environments using mobile robots has gained traction, as robots are able to mitigate the risk placed on humans and at times achieve what humans are unable to. In some scenarios, the robot is required to operate in cluttered environments with highly restricted access through 150 mm diameter ports. The MIRRAX robot has been designed to meet these challenges with the capability of reconfiguring itself to both access environments and navigate through tightly spaced obstacles. The joints used for reconfiguration of the robot introduce additional challenges for path planning due to the significant changes that can occur between adjacent poses. This paper presents a global path planner for MIRRAX. A Voronoi diagram is first used to generate a sparse graph to represent the topology of the environment, which allows for fast, coarse path planning. The coarse path is then refined via a heuristic pose fitting routine to ensure that the path is both collision-free and reduce unnecessary joint angle changes. The planner has been evaluated in simulation, demonstrating the feasibility of generating collision-free paths through narrow pathways for a reconfigurable robot.",
        "primary_area": "",
        "author": "Wei Cheah;Tomas B. Garcia-Nathan;Keir Groves;Simon Watson;Barry Lennox;Wei Cheah;Tomas B. Garcia-Nathan;Keir Groves;Simon Watson;Barry Lennox",
        "authorids": "/37086576110;/37088998984;/37086497192;/38185385000;/37299751200;/37086576110;/37088998984;/37086497192;/38185385000;/37299751200",
        "aff": "Department of Electrical and Electronic Engineering, University of Manchester, UK; Department of Electrical and Electronic Engineering, University of Manchester, UK; Department of Electrical and Electronic Engineering, University of Manchester, UK; Department of Electrical and Electronic Engineering, University of Manchester, UK; Department of Electrical and Electronic Engineering, University of Manchester, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561834/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17473451050146514695&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Manchester",
        "aff_unique_dep": "Department of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.manchester.ac.uk",
        "aff_unique_abbr": "UoM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561626",
        "title": "Path Planning in Uncertain Ocean Currents using Ensemble Forecasts",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a path planning framework for marine robots subject to uncertain ocean currents that exploits data from ensemble forecasting, which is a technique for current prediction used in oceanography. Ensemble forecasts represent a distribution of predicted currents as a set of flow fields that are considered to be equally likely. We show that the typical approach of computing the vector-wise mean and variance over this set can yield meaningless results, and propose an alternative approach that considers each flow field in the ensemble simultaneously. Our framework finds a sequence of vehicle controls that minimises the root-mean-square error distance (RMSE) over the full set of ensemble-induced trajectories. The key to achieving computational efficiency in this approach is our use of Monte Carlo tree search (MCTS) with a specialised heuristic that improves convergence rate while preserving asymptotic optimality and the anytime property. We demonstrate our results using real ensemble forecasts provided by the Australian Bureau of Meteorology, and provide comparisons with the deterministic mean-based approach where we observe RMSE reductions of 92% and 43% in two example scenarios. Further, we argue that the framework can be used in a plan-as-you-go manner where ensemble forecasts change over time. These results help to introduce ensemble forecasts as a viable source of data to improve path planning in marine robotics.",
        "primary_area": "",
        "author": "Chanyeol Yoo;James Ju Heon Lee;Stuart Anstee;Robert Fitch;Chanyeol Yoo;James Ju Heon Lee;Stuart Anstee;Robert Fitch",
        "authorids": "/37086933786;/37088505668;/37601910400;/38466367800;/37086933786;/37088505668;/37601910400;/38466367800",
        "aff": "University of Technology, Sydney, Australia; University of Technology, Sydney, Australia; Department of Defence, Defence Science and Technology Group, Australia; University of Technology, Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561626/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15896811503746126792&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Technology Sydney;Defence Science and Technology Group",
        "aff_unique_dep": ";Department of Defence",
        "aff_unique_url": "https://www.uts.edu.au;https://www.dstgroup.com.au",
        "aff_unique_abbr": "UTS;DST Group",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sydney;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9562018",
        "title": "Peer-Assisted Robotic Learning: A Data-Driven Collaborative Learning Approach for Cloud Robotic Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "A technological revolution is occurring in the field of robotics with the data-driven deep learning technology. However, building datasets for each local robot is laborious. Meanwhile, data islands between local robots make data unable to be utilized collaboratively. To address this issue, the work presents Peer-Assisted Robotic Learning (PARL) in robotics, which is inspired by the peer-assisted learning in cognitive psychology and pedagogy. PARL implements data collaboration with the framework of cloud robotic systems. Both data and models are shared by robots to the cloud after semantic computing and training locally. The cloud converges the data and performs augmentation, integration, and transferring. Finally, fine tune this larger shared dataset in the cloud to local robots. Furthermore, we propose the DAT Network (Data Augmentation and Transferring Network) to implement the data processing in PARL. DAT Network can realize the augmentation of data from multi-local robots. We conduct experiments on a simplified self-driving task for robots (cars). DAT Network has a significant improvement in the augmentation in self-driving scenarios. Along with this, the self-driving experimental results also demonstrate that PARL is capable of improving learning effects with data collaboration of local robots.",
        "primary_area": "",
        "author": "Boyi Liu;Lujia Wang;Xinquan Chen;Lexiong Huang;Dong Han;Cheng-Zhong Xu;Boyi Liu;Lujia Wang;Xinquan Chen;Lexiong Huang;Dong Han;Cheng-Zhong Xu",
        "authorids": "/37087061487;/37406752700;/37088952763;/37089000856;/37088758443;/37278305300;/37087061487;/37406752700;/37088952763;/37089000856;/37088758443;/37278305300",
        "aff": "State Key Laboratory of Internet of Things for Smart City, University of Macau; Shenzhen Institutes of Advanced Technology (SIAT), Chinese Academy of Sciences; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; State Key Laboratory of Internet of Things for Smart City, University of Macau",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562018/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9581898268055785862&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;2;0",
        "aff_unique_norm": "University of Macau;Shenzhen Institute of Advanced Technology;University of Chinese Academy of Sciences",
        "aff_unique_dep": "State Key Laboratory of Internet of Things for Smart City;;",
        "aff_unique_url": "https://www.um.edu.mo;http://www.siat.cas.cn;http://www.ucas.ac.cn",
        "aff_unique_abbr": "UM;SIAT;UCAS",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Macau SAR;Shenzhen;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561904",
        "title": "Perceive, Attend, and Drive: Learning Spatial Attention for Safe Self-Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an end-to-end self-driving network featuring a sparse attention module that learns to automatically attend to important regions of the input. The attention module specifically targets motion planning, whereas prior literature only applied attention in perception tasks. Learning an attention mask directly targeted for motion planning significantly improves the planner safety by performing more focused computation. Furthermore, visualizing the attention improves interpretability of end-to-end self-driving.",
        "primary_area": "",
        "author": "Bob Wei;Mengye Ren;Wenyuan Zeng;Ming Liang;Bin Yang;Raquel Urtasun;Bob Wei;Mengye Ren;Wenyuan Zeng;Ming Liang;Bin Yang;Raquel Urtasun",
        "authorids": "/37089001352;/37086213738;/37087234351;/37087231216;/37399884400;/37269502900;/37089001352;/37086213738;/37087234351;/37087231216;/37399884400;/37269502900",
        "aff": "University of Waterloo; University of Toronto; University of Toronto; Uber ATG; University of Toronto; University of Waterloo",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561904/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12606836739301046659&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;2;1;0",
        "aff_unique_norm": "University of Waterloo;University of Toronto;Uber",
        "aff_unique_dep": ";;Advanced Technologies Group",
        "aff_unique_url": "https://uwaterloo.ca;https://www.utoronto.ca;https://www.uber.com",
        "aff_unique_abbr": "UW;U of T;Uber ATG",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9561947",
        "title": "Performance Metrics Calculation for Assembly Systems with Exponential Reliability Machines",
        "track": "main",
        "status": "Poster",
        "abstract": "Assembly systems are commonly seen in production practice, where multiple components are joined in a manufacturing process to make a final product. In this paper, a decomposition/aggregation-based method is presented to evaluate the performance metrics of assembly systems with machines following the exponential reliability model (either synchronous or asynchronous). In particular, we consider the assembly system with multiple merge operations, each connected to a single external component line. The idea of the proposed method is to decompose the assembly system into a set of virtual serial lines based on the overlapping decomposition technique, evaluate of the starvation and blockage of the merge operations, and recursively update of the virtual machines\u2019 parameters in the thus-obtained serial lines. Then, the performance metrics of the original assembly system can be approximated based on the corresponding machines and buffers in the virtual serial lines. Numerical experiments are carried out to justify the convergence and computational efficiency of the method, as well as to evaluate the approximation accuracy of the proposed algorithm.",
        "primary_area": "",
        "author": "Yishu Bai;Liang Zhang;Yishu Bai;Liang Zhang",
        "authorids": "/37087009471;/37676784900;/37087009471;/37676784900",
        "aff": "Yishu Bai; Liang Zhang",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561947/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17345659051308324877&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9561707",
        "title": "Pheromone-Diffusion-based Conscientious Reactive Path Planning for Road Network Persistent Surveillance",
        "track": "main",
        "status": "Poster",
        "abstract": "Road Network Persistent Surveillance Problem (RPSP) involves path planning for an unmanned ground vehicle (UGV) with detection ability to timely detect the events randomly occurred. The road network is formed by edges and weighted viewpoints, where the UGV must move along the edges. The existing method based on cognitive architecture is inadequate in terms of real-time and effective decision making. To improve the computation efficiency and accuracy of solving RPSP, a new algorithm called Pheromone-Diffusion-based Conscientious Reactive Persistent Surveillance (PD-CRPS) is proposed in this paper. Considering the detection ability of UGV, the monitoring weight, the surveillance effect, and the topology of the road network, a model of pheromone release and diffusion is established to estimate the global uncertainty through the local information around the UGV. The local optimum avoidance technology based on pheromone is designed, and the reactive architecture is used to design the payoff function of decision making. The worst-case computational time complexity of the PD-CRPS is far less than the existing cognitive architecture method. Simulation results show that the PD-CRPS can not only efficiently plan the path of UGV in the road networks with different topologies and observation obstacles, but also improve the calculation accuracy.",
        "primary_area": "",
        "author": "Tong Wang;Gangqi Dong;Panfeng Huang;Tong Wang;Gangqi Dong;Panfeng Huang",
        "authorids": "/37086415812;/37087051941;/37293059500;/37086415812;/37087051941;/37293059500",
        "aff": "National Key Laboratory of Aerospace Flight Dynamics, Northwestern Polytechnical University, Xi\u2019an, China; National Key Laboratory of Aerospace Flight Dynamics, Northwestern Polytechnical University, Xi\u2019an, China; National Key Laboratory of Aerospace Flight Dynamics, Northwestern Polytechnical University, Xi\u2019an, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561707/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2080149659122004426&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Northwestern Polytechnical University",
        "aff_unique_dep": "National Key Laboratory of Aerospace Flight Dynamics",
        "aff_unique_url": "http://www.nwpu.edu.cn",
        "aff_unique_abbr": "NPU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561285",
        "title": "PicoVO: A Lightweight RGB-D Visual Odometry Targeting Resource-Constrained IoT Devices",
        "track": "main",
        "status": "Poster",
        "abstract": "Ego-motion estimation with 3D perception using visual odometry (VO) is known to be robust and economical among the existing odometry techniques. However, existing VO solutions are typically both computation intensive and memory intensive, which dramatically inhibits their deployment in IoT platforms such as robotic vehicles and handheld devices mostly equipped with resource-constrained MCU-level processors. To enable real-time and high-quality VO on these scenarios with thrifty resource budgets, we investigate state-of-the-art edge-based VO (EBVO) and propose an optimization framework called PicoVO that can greatly reduce the amount of computation as well as the memory footprint from the perspectives of both algorithm and implementation. First of all, we revisit the key processing stages of EBVO and propose an EBVO-oriented lightweight edge detector in the pre-processing stage, a sparse-to-dense processing scheme in the tracking stage, and a lightweight key-frame management in the post-processing stage. In addition to the algorithmic optimization, we further develop a dedicated quantization scheme particularly for the 3D feature calculation and Levenberg-Marquardt (LM) solver that are critical to the memory footprint and computation requirements of PicoVO. Evaluation on realistic RGB-D benchmark datasets is conducted on NUCLEO-F767ZI equipped with a 216MHz Cortex-M7 MCU and 512KB RAM. It reveals that PicoVO achieves 33fps@320x240 with high tracking precision comparable to state-of-the-art VOs on PC.",
        "primary_area": "",
        "author": "Yuquan He;Ying Wang;Cheng Liu;Lei Zhang;Yuquan He;Ying Wang;Cheng Liu;Lei Zhang",
        "authorids": "/37089001190;/37859959900;/37858948200;/37406075100;/37089001190;/37859959900;/37858948200;/37406075100",
        "aff": "University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; University of Chinese Academy of Sciences; Jeejio(Ningbo) Technology Co., Ltd",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561285/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16072542893090130588&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Jeejio Technology",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.ucas.ac.cn;",
        "aff_unique_abbr": "UCAS;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Ningbo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561614",
        "title": "Piecewise-Linear Motion Planning amidst Static, Moving, or Morphing Obstacles",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel method for planning shortest length piecewise-linear motions through complex environments punctured with static, moving, or even morphing obstacles. Using a moment optimization approach, we formulate a hierarchy of semidefinite programs that yield increasingly refined lower bounds converging monotonically to the optimal path length. Our global moment optimization approach natively handles continuous time constraints without any need for time discretization. For computational tractability, we derive an iterative motion planner which compares favorably with sampling-based and nonlinear optimization baselines.",
        "primary_area": "",
        "author": "Bachir El Khadir;Jean Bernard Lasserre;Vikas Sindhwani;Bachir El Khadir;Jean Bernard Lasserre;Vikas Sindhwani",
        "authorids": "/37088997444;/37089001500;/37282057000;/37088997444;/37089001500;/37282057000",
        "aff": "IBM Watson Research Center, NY, USA; Laboratoire d\u2019Analyse et d\u2019Architecture des Syst\u00e8mes (LAAS), Institute of Mathematics, University of Toulouse, France; Robotics at Google, New York City, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561614/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14083900919877405322&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "IBM;University of Toulouse;Google",
        "aff_unique_dep": "IBM Watson Research Center;Institute of Mathematics;Robotics",
        "aff_unique_url": "https://www.ibm.com/watson;https://www.univ-toulouse.fr;https://www.google.com",
        "aff_unique_abbr": "IBM Watson;UT;Google",
        "aff_campus_unique_index": "0;2",
        "aff_campus_unique": "Yorktown Heights;;New York City",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;France"
    },
    {
        "id": "9561325",
        "title": "Plane Segmentation in Organized Point Clouds using Flood Fill",
        "track": "main",
        "status": "Poster",
        "abstract": "The segmentation of a point cloud into planar primitives is a popular approach to first-line scene interpretation and is particularly useful in mobile robotics for the extraction of drivable or walkable surfaces and for tabletop segmentation for manipulation purposes. Unfortunately, the planar segmentation task becomes particularly challenging when the point clouds are obtained from an inherently noisy, robot-mounted sensor that is often in motion, therefor requiring real time processing capabilities. We present a real time-capable plane segmentation technique based on a region growing algorithm that exploits the organized structure of point clouds obtained from RGB-D sensors. In order to counteract the sensor noise, we invest into careful selection of seeds that start the region growing and avoid the computation of surface normals whenever possible. We implemented our algorithm in C++ and thoroughly tested it in both simulated and real-world environments where we are able to compare our approach against existing state-of-the-art methods implemented in the Point Cloud Library. The experiments presented here suggest that our approach is accurate and fast, even in the presence of considerable sensor noise.",
        "primary_area": "",
        "author": "Arindam Roychoudhury;Marcell Missura;Maren Bennewitz;Arindam Roychoudhury;Marcell Missura;Maren Bennewitz",
        "authorids": "/37088690601;/37947347600;/37324765000;/37088690601;/37947347600;/37324765000",
        "aff": "Humanoid Robots Lab, University of Bonn, Germany; Humanoid Robots Lab, University of Bonn, Germany; Humanoid Robots Lab, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561325/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18216834703423260460&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Humanoid Robots Lab",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561693",
        "title": "PlaneSegNet: Fast and Robust Plane Estimation Using a Single-stage Instance Segmentation CNN",
        "track": "main",
        "status": "Poster",
        "abstract": "Instance segmentation of planar regions in indoor scenes benefits visual SLAM and other applications such as augmented reality (AR) where scene understanding is required. Existing methods built upon two-stage frameworks show satisfactory accuracy but are limited by low frame rates. In this work, we propose a real-time deep neural architecture that estimates piece-wise planar regions from a single RGB image. Our model employs a variant of a fast single-stage CNN architecture to segment plane instances. Considering the particularity of the target detected, we propose Fast Feature Non-maximum Suppression (FF-NMS) to reduce the suppression errors resulted from overlapping bounding boxes of planes. We also utilize a Residual Feature Augmentation module in the Feature Pyramid Network (FPN) . Our method achieves significantly higher frame-rates and comparable segmentation accuracy against two-stage methods. We automatically label over 70,000 images as ground truth from the Stanford 2D-3D-Semantics dataset. Moreover, we incorporate our method with a state-of-the-art planar SLAM and validate its benefits.",
        "primary_area": "",
        "author": "Yaxu Xie;Jason Rambach;Fangwen Shu;Didier Stricker;Yaxu Xie;Jason Rambach;Fangwen Shu;Didier Stricker",
        "authorids": "/37088886484;/37085659055;/37088887024;/37326112700;/37088886484;/37085659055;/37088887024;/37326112700",
        "aff": "DFKI - German Research Center for Artificial Intelligence, Kaiserslautern, Germany; DFKI - German Research Center for Artificial Intelligence, Kaiserslautern, Germany; DFKI - German Research Center for Artificial Intelligence, Kaiserslautern, Germany; DFKI - German Research Center for Artificial Intelligence, Kaiserslautern, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561693/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3354895382380475424&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "German Research Center for Artificial Intelligence",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.dFKI.de",
        "aff_unique_abbr": "DFKI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Kaiserslautern",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561883",
        "title": "Planning Laser-Forming Folding Motion with Thermal Simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Designing a robot or structure that can fold into a target shape is a process that involves challenges originated from multiple sources. For example, the designer of self-folding robots must consider foldability from geometric and kinematic aspects to avoid self-collisions and undesired deformations. Recent works have shown success in estimating foldability of a design using robot motion planners. However, many foldable structures are actuated using physically coupled reactions, e.g., folding originated from thermal, chemical, or electromagnetic loads. Therefore, a reliable folding process must consider additional constraints that result from these critical and coupled phenomena. This work investigates the idea of efficiently incorporating computationally intensive physics simulations within the folding motion planner to affect the physical folding results. We will use the manufacturing process of laser-forming origami as an example to demonstrate the benefits of considering the physical properties of the foldable structure beyond its kinematics. We show that designs produced by the proposed method can be fabricated more efficiently.",
        "primary_area": "",
        "author": "Yue Hao;Weilin Guan;Edwin A. Peraza Hernandez;Jyh-Ming Lien;Yue Hao;Weilin Guan;Edwin A. Peraza Hernandez;Jyh-Ming Lien",
        "authorids": "/37086942083;/37088998915;/37086590779;/37277182300;/37086942083;/37088998915;/37086590779;/37277182300",
        "aff": "Department of Computer Science, George Mason University, Fairfax, VA, USA; Department of Mechanical and Aerospace Engineering, University of California, Irvine, CA, USA; Department of Mechanical and Aerospace Engineering, University of California, Irvine, CA, USA; Department of Computer Science, George Mason University, Fairfax, VA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561883/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=736257146078629289&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "George Mason University;University of California, Irvine",
        "aff_unique_dep": "Department of Computer Science;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.gmu.edu;https://www.uci.edu",
        "aff_unique_abbr": "GMU;UCI",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Fairfax;Irvine",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561233",
        "title": "Planning for Multi-stage Forceful Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-stage forceful manipulation tasks, such as twisting a nut on a bolt, require reasoning over interlocking constraints over discrete and continuous choices. The robot must choose a sequence of discrete actions, or strategy, such as whether to pick up an object, and the continuous parameters of each of those actions, such as how to grasp that object. In forceful manipulation tasks, the force requirements substantially impact the choices of both strategy and parameters. To enable planning and executing forceful manipulation, we augment an existing task and motion planner with controllers that exert wrenches and constraints that explicitly consider torque and frictional limits. In two domains, opening a childproof bottle and twisting a nut, we demonstrate how the system considers a combinatorial number of strategies and how choosing actions that are robust to parameter variations impacts the choice of strategy. https://mcube.mit.edu/forceful-manipulation/",
        "primary_area": "",
        "author": "Rachel Holladay;Tom\u00e1s Lozano-P\u00e9rez;Alberto Rodriguez;Rachel Holladay;Tom\u00e1s Lozano-P\u00e9rez;Alberto Rodriguez",
        "authorids": "/37085574181;/38273814000;/38194796600;/37085574181;/38273814000;/38194796600",
        "aff": "Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology; Mechanical Engineering Department, Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561233/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11797428459612264152&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561745",
        "title": "Planning on a (Risk) Budget: Safe Non-Conservative Planning in Probabilistic Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning in environments with other agents whose future actions are uncertain often requires compromise between safety and performance. Here our goal is to design efficient planning algorithms with guaranteed bounds on the probability of safety violation, which nonetheless achieve non-conservative performance. To quantify a system\u2019s risk, we define a natural criterion called interval risk bounds (IRBs), which provide a parametric upper bound on the probability of safety violation over a given time interval or task. We present a novel receding horizon algorithm, and prove that it can satisfy a desired IRB. Our algorithm maintains a dynamic risk budget which constrains the allowable risk at each iteration, and guarantees recursive feasibility by requiring a safe set to be reachable by a contingency plan within the budget. We empirically demonstrate that our algorithm is both safer and less conservative than strong baselines in two simulated autonomous driving experiments in scenarios involving collision avoidance with other vehicles, and additionally demonstrate our algorithm running on an autonomous class 8 truck.",
        "primary_area": "",
        "author": "Hung-Jui Huang;Kai-Chi Huang;Michal \u010c\u00e1p;Yibiao Zhao;Ying Nian Wu;Chris L. Baker;Hung-Jui Huang;Kai-Chi Huang;Michal \u010c\u00e1p;Yibiao Zhao;Ying Nian Wu;Chris L. Baker",
        "authorids": "/37088995901;/37088999618;/37705371300;/37087234670;/37089263700;/37087231138;/37088995901;/37088999618;/37705371300;/37087234670;/37089263700;/37087231138",
        "aff": "ISEE AI, Cambridge, Massachusetts, USA; ISEE AI, Cambridge, Massachusetts, USA; ISEE AI, Cambridge, Massachusetts, USA; ISEE AI, Cambridge, Massachusetts, USA; University of California, Los Angeles, California, USA; ISEE AI, Cambridge, Massachusetts, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561745/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11628254800290060397&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "ISEE AI;University of California, Los Angeles",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.ucla.edu",
        "aff_unique_abbr": ";UCLA",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Cambridge;Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562011",
        "title": "Plenary",
        "track": "main",
        "status": "Poster",
        "abstract": "Provides an abstract of the presentation and may include a brief professional biography of the presenter. The complete presentation was not made available for publication as part of the conference proceedings.",
        "primary_area": "",
        "author": "",
        "authorids": "",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562011/",
        "gs_citation": -1,
        "gs_cited_by_link": "",
        "gs_version_total": -1,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 1
    },
    {
        "id": "9561576",
        "title": "Pneumatic actuation-based bidirectional modules with variable stiffness and closed-loop position control",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper extends our previous work on a pneumatic bending module and presents two more modules for rotational and translational motions. In these modules, antagonistic chambers enveloped by rigid shells are adopted to realize bidirectional actuation, and they are characterized by safe actuation, enhanced torque/force output, independent stiffness tuning, and real-time position control. Due to their mechanical modularity, they can be conveniently assembled into robotic systems with multiple degrees of freedom (DoFs) according to different requirements. A complete workflow is presented including the module design, fabrication, theoretical modelling, controller design, and experimental validation. A reconfigurable robotic arm with high dexterity is also assembled using these modules, demonstrating the effectiveness of the proposed modules to develop robotic systems for safe, forceful, and precise tasks.",
        "primary_area": "",
        "author": "Yaohui Chen;Hoam Chung;Bernard Chen;Ho Yi Ping;Yonghang Sun;Yaohui Chen;Hoam Chung;Bernard Chen;Ho Yi Ping;Yonghang Sun",
        "authorids": "/37089612283;/37714823800;/37088507181;/37088995984;/37088505729;/37089612283;/37714823800;/37088507181;/37088995984;/37088505729",
        "aff": "College of Engineering, Huazhong Agricultural University, Wuhan, China; Department of Mechanical and Aerospace Engineering, Monash University, Clayton, VIC, Australia; Department of Mechanical and Aerospace Engineering, Monash University, Clayton, VIC, Australia; Department of Electrical and Computer Systems Engineering, Monash University, Selangor, Malaysia; Department of Electrical and Computer Systems Engineering, Monash University, Clayton, VIC, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561576/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=282271209547709026&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Huazhong Agricultural University;Monash University",
        "aff_unique_dep": "College of Engineering;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "http://www.hzau.edu.cn;https://www.monash.edu",
        "aff_unique_abbr": "HZAU;Monash",
        "aff_campus_unique_index": "0;1;1;2;1",
        "aff_campus_unique": "Wuhan;Clayton;Selangor",
        "aff_country_unique_index": "0;1;1;2;1",
        "aff_country_unique": "China;Australia;Malaysia"
    },
    {
        "id": "9560946",
        "title": "Pneumatic-Mechanical Systems in UAVs: Autonomous Power Line Sensor Unit Deployment",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned Aerial Vehicles (UAVs) have introduced benefits in many areas of the energy sector. Today, power line sensor deployment is manually executed on passive power lines using helicopters, introducing great risks, costs and difficulties for the power distribution companies and the human operators.In this paper, we present a novel modular mechanical system utilizing pneumatic as the actuation source to deploy a sensor unit to a power line using a UAV, with aid of an autonomous alignment algorithm. The results show that the UAV can facilitate the sensor unit, and is capable of deploying it to the power line in an autonomous manner. The works leave opportunity for expanding to further applications in the future.",
        "primary_area": "",
        "author": "Nicolai Iversen;Alja\u017e Kramberger;Oscar Bowen Schofield;Emad Ebeid;Nicolai Iversen;Alja\u017e Kramberger;Oscar Bowen Schofield;Emad Ebeid",
        "authorids": "/37088526272;/37085387168;/37088526037;/38233264800;/37088526272;/37085387168;/37088526037;/38233264800",
        "aff": "SDU UAS Center, The Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Odense, Denmark; SDU Robotics, The Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Odense, Denmark; SDU UAS Center, The Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Odense, Denmark; SDU UAS Center, The Maersk Mc-Kinney Moller Institute, University of Southern Denmark, Odense, Denmark",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560946/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6426373850258342696&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Southern Denmark",
        "aff_unique_dep": "SDU UAS Center, The Maersk Mc-Kinney Moller Institute",
        "aff_unique_url": "https://www.sdu.dk",
        "aff_unique_abbr": "SDU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Odense",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Denmark"
    },
    {
        "id": "9561309",
        "title": "PocoNet: SLAM-oriented 3D LiDAR Point Cloud Online Compression Network",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present PocoNet: Point cloud Online COmpression NETwork to address the task of SLAM-oriented compression. The aim of this task is to select a compact subset of points with high priority to maintain localization accuracy. The key insight is that points with high priority have similar geometric features in SLAM scenarios. Hence, we tackle this task as point cloud segmentation to capture complex geometric information. We calculate observation counts by matching between maps and point clouds and divide them into different priority levels. Trained by labels annotated with such observation counts, the proposed network could evaluate the point-wise priority. Experiments are conducted by integrating our compression module into an existing SLAM system to evaluate compression ratios and localization performances. Experimental results on two different datasets verify the feasibility and generalization of our approach.",
        "primary_area": "",
        "author": "Jinhao Cui;Hao Zou;Xin Kong;Xuemeng Yang;Xiangrui Zhao;Yong Liu;Wanlong Li;Feng Wen;Hongbo Zhang;Jinhao Cui;Hao Zou;Xin Kong;Xuemeng Yang;Xiangrui Zhao;Yong Liu;Wanlong Li;Feng Wen;Hongbo Zhang",
        "authorids": "/37088688571;/37088690615;/37087322070;/37088455828;/37087122595;/37089444129;/37088687641;/37088690190;/37859161500;/37088688571;/37088690615;/37087322070;/37088455828;/37087122595;/37089444129;/37088687641;/37088690190;/37859161500",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Huawei Noah\u2019s Ark Lab, Beijing, China; Huawei Noah\u2019s Ark Lab, Beijing, China; Huawei Noah\u2019s Ark Lab, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561309/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10572189115203151292&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;1;1;1",
        "aff_unique_norm": "Zhejiang University;Huawei",
        "aff_unique_dep": "Institute of Cyber-Systems and Control;Huawei Noah\u2019s Ark Lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.huawei.com/en/ai/noahs-ark-lab",
        "aff_unique_abbr": "ZJU;HNA Lab",
        "aff_campus_unique_index": "0;0;0;0;0;0;1;1;1",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560848",
        "title": "Point Cloud Segmentation via Edge-fused Local Graph Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Traditional convolution for capturing local structures and relationships remains a key technical limit in 3D semantic segmentation, which neglects the certain influence of the adjacent points on the central point in the disordered local point clouds. In this paper, we propose a novel joint-edge graph convolution neural network (JEGCN), which can extract the dynamic features of each local area and transfer the edge information between the vertex pairs to the adjacent vertices. In the proposed graph convolution module, the adjacent vertices are selected with high classification confidence which can guide the central vertex, and then reweight these vertices. Considering the lack of texture features in 3D point clouds, we incorporate 2D image features to adjacent feature propagation to effectively extract the local and global features of point clouds. The experimental results based on ScanNet and S3DIS datasets demonstrate the effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Mengtao Han;Yaochen Li;Liangyu Zuo;Qiao Li;Chi Zhang;Yuanqi Su;Ping Li;Mengtao Han;Yaochen Li;Liangyu Zuo;Qiao Li;Chi Zhang;Yuanqi Su;Ping Li",
        "authorids": "/37088998703;/37715813500;/37088998398;/37089778210;/37085395046;/37075311900;/37089270201;/37088998703;/37715813500;/37088998398;/37089778210;/37085395046;/37075311900;/37089270201",
        "aff": "School of Software Engineering, Xi\u2019an Jiaotong University, Xi\u2019an, China; School of Software Engineering, Xi\u2019an Jiaotong University, Xi\u2019an, China; School of Software Engineering, Xi\u2019an Jiaotong University, Xi\u2019an, China; School of Software Engineering, Xi\u2019an Jiaotong University, Xi\u2019an, China; Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, Xi\u2019an, China; School of Computer Science and Technology, Xi\u2019an Jiaotong University, Xi\u2019an, China; China Academy of Railway Sciences Corporation Limited, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560848/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2955166334875736607&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;1",
        "aff_unique_norm": "Xi'an Jiao Tong University;China Academy of Railway Sciences Corporation Limited",
        "aff_unique_dep": "School of Software Engineering;",
        "aff_unique_url": "http://www.xjtu.edu.cn;http://www.carsc.com.cn",
        "aff_unique_abbr": "XJTU;CARSCL",
        "aff_campus_unique_index": "0;0;0;0;0;0;1",
        "aff_campus_unique": "Xi'an;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561140",
        "title": "Point Set Registration With Semantic Region Association Using Cascaded Expectation Maximization",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a new solution to point set registration, a fundamental geometric problem occurring in many computer vision and robotics applications. We consider the specific case in which the point sets are segmented into semantically annotated parts. Such information may for example come from object detection or instance-level semantic segmentation in a registered RGB image. Existing methods incorporate the additional information to restrict or re-weight the point-pair associations occurring throughout the registration process. We introduce a novel hierarchical association framework for a simultaneous inference of semantic region association likelihoods. The formulation is elegantly solved using cascaded expectation-maximization. We conclude by demonstrating a substantial improvement over existing alternatives on open RGBD datasets.",
        "primary_area": "",
        "author": "Lan Hu;Jiaxin Wei;Zhanpeng Ouyang;Laurent Kneip;Lan Hu;Jiaxin Wei;Zhanpeng Ouyang;Laurent Kneip",
        "authorids": "/37088505304;/37088998413;/37088998024;/37569040300;/37088505304;/37088998413;/37088998024;/37569040300",
        "aff": "Mobile Perception Laboratory, ShanghaiTech University; Mobile Perception Laboratory, ShanghaiTech University; Mobile Perception Laboratory, ShanghaiTech University; Mobile Perception Laboratory, ShanghaiTech University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561140/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17744827227635423157&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "ShanghaiTech University",
        "aff_unique_dep": "Mobile Perception Laboratory",
        "aff_unique_url": "http://www.shanghaitech.edu.cn",
        "aff_unique_abbr": "ShanghaiTech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561387",
        "title": "Pointing at Moving Robots: Detecting Events from Wrist IMU Data",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a practical approach for detecting the event that a human wearing an IMU-equipped bracelet points at a moving robot; the approach uses a learned classifier to verify if the robot motion (as measured by its odometry) matches the wrist motion, and does not require that the relative pose of the operator and robot is known in advance. To train the model and validate the system, we collect datasets containing hundreds of real-world pointing events. Extensive experiments quantify the performance of the classifiers and relevant metrics of the resulting detectors; the approach is implemented in a real-world demonstrator that allows users to land quadrotors by pointing at them.",
        "primary_area": "",
        "author": "Gabriele Abbate;Boris Gromov;Luca M. Gambardella;Alessandro Giusti;Gabriele Abbate;Boris Gromov;Luca M. Gambardella;Alessandro Giusti",
        "authorids": "/37086803059;/38542865300;/37270036000;/38498058400;/37086803059;/38542865300;/37270036000;/38498058400",
        "aff": "Dalle Molle Institute for Artificial Intelligence (IDSIA USI-SUPSI), Lugano, Switzerland; Dalle Molle Institute for Artificial Intelligence (IDSIA USI-SUPSI), Lugano, Switzerland; Dalle Molle Institute for Artificial Intelligence (IDSIA USI-SUPSI), Lugano, Switzerland; Dalle Molle Institute for Artificial Intelligence (IDSIA USI-SUPSI), Lugano, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561387/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=311758071285619780&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Dalle Molle Institute for Artificial Intelligence",
        "aff_unique_dep": "Institute for Artificial Intelligence",
        "aff_unique_url": "https://www.idsia.ch",
        "aff_unique_abbr": "IDSIA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Lugano",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9562069",
        "title": "Poisson Surface Reconstruction for LiDAR Odometry and Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurately localizing in and mapping an environment are essential building blocks of most autonomous systems. In this paper, we present a novel approach for LiDAR odometry and mapping, focusing on improving the mapping quality and at the same time estimating the pose of the vehicle. Our approach performs frame-to-mesh ICP, but in contrast to other SLAM approaches, we represent the map as a triangle mesh computed via Poisson surface reconstruction. We perform the surface reconstruction in a sliding window fashion over a sequence of past scans. In this way, we obtain accurate local maps that are well suited for registration and can also be combined into a global map. This enables us to build a 3D map showing more geometric details than common mapping approaches relying on a truncated signed distance function or surfels. Our experimental evaluation shows quantitatively and qualitatively that our maps offer higher geometric accuracies than these other map representations. We also show that our maps are compact and can be used for LiDAR-based odometry estimation with a novel ray-casting-based data association.",
        "primary_area": "",
        "author": "Ignacio Vizzo;Xieyuanli Chen;Nived Chebrolu;Jens Behley;Cyrill Stachniss;Ignacio Vizzo;Xieyuanli Chen;Nived Chebrolu;Jens Behley;Cyrill Stachniss",
        "authorids": "/37087323326;/37086247697;/37086411047;/37593243900;/37329668600;/37087323326;/37086247697;/37086411047;/37593243900;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562069/",
        "gs_citation": 118,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10803598595065216548&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561982",
        "title": "Policy Transfer via Kinematic Domain Randomization and Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "Transferring reinforcement learning policies trained in physics simulation to the real hardware remains a challenge, known as the \"sim-to-real\" gap. Domain randomization is a simple yet effective technique to address dynamics discrepancies across source and target domains, but its success generally depends on heuristics and trial-and-error. In this work we investigate the impact of randomized parameter selection on policy transferability across different types of domain discrepancies. Contrary to common practice in which kinematic parameters are carefully measured while dynamic parameters are randomized, we found that virtually randomizing kinematic parameters (e.g., link lengths) during training in simulation generally outperforms dynamic randomization. Based on this finding, we introduce a new domain adaptation algorithm that utilizes simulated kinematic parameters variation. Our algorithm, Multi-Policy Bayesian Optimization, trains an ensemble of universal policies conditioned on virtual kinematic parameters and efficiently adapts to the target environment using a limited number of target domain rollouts. We showcase our findings on a simulated quadruped robot in five different target environments covering different aspects of domain discrepancies.",
        "primary_area": "",
        "author": "Ioannis Exarchos;Yifeng Jiang;Wenhao Yu;C. Karen Liu;Ioannis Exarchos;Yifeng Jiang;Wenhao Yu;C. Karen Liu",
        "authorids": "/37089653411;/37089000434;/37085891022;/37088832865;/37089653411;/37089000434;/37085891022;/37088832865",
        "aff": "Department of Computer Science, Stanford University, Stanford, CA; Department of Computer Science, Stanford University, Stanford, CA; Robotics at Google, Mountain View, CA; Department of Computer Science, Stanford University, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561982/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15175917051652433951&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Stanford University;Google",
        "aff_unique_dep": "Department of Computer Science;Robotics",
        "aff_unique_url": "https://www.stanford.edu;https://www.google.com",
        "aff_unique_abbr": "Stanford;Google",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Stanford;Mountain View",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560807",
        "title": "Polyhedral Friction Cone Estimator for Object Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "A polyhedral friction cone is a set of reaction wrenches that an object can experience whilst in contact with its environment. This polyhedron is a powerful tool to control an object\u2019s motion and interaction with the environment. It can be derived analytically, upon knowledge of object and environment geometries, contact point locations and friction coefficients. We propose to estimate the polyhedral friction cone so that a priori knowledge of these quantities is no longer required. Additionally, we introduce a solution to transform the estimated friction cone to avoid re-estimation while the object moves. We present an analysis of the estimated polyhedral friction cone and demonstrate its application for manipulating an object in simulation and with a real robot.",
        "primary_area": "",
        "author": "Morteza Azad;Silvia Cruciani;Michael J. Mathew;Graham Deacon;Guillaume de Chambrier;Morteza Azad;Silvia Cruciani;Michael J. Mathew;Graham Deacon;Guillaume de Chambrier",
        "authorids": "/37077045300;/37086293985;/37086270199;/37086602117;/37089100678;/37077045300;/37086293985;/37086270199;/37086602117;/37089100678",
        "aff": "Robotics Research Team, Ocado Technology, Hatfield, UK; Robotics Research Team, Ocado Technology, Hatfield, UK; Robotics Research Team, Ocado Technology, Hatfield, UK; Robotics Research Team, Ocado Technology, Hatfield, UK; Robotics Research Team, Ocado Technology, Hatfield, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560807/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:n47i5SAp6WcJ:scholar.google.com/&scioq=Polyhedral+Friction+Cone+Estimator+for+Object+Manipulation&hl=en&as_sdt=0,5",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Ocado Technology",
        "aff_unique_dep": "Robotics Research Team",
        "aff_unique_url": "https://technology.ocado.com",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Hatfield",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561890",
        "title": "Pose Estimation for Vehicle-mounted Cameras via Horizontal and Vertical Planes",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose novel solvers for estimating the egomotion of a calibrated camera mounted to a moving vehicle from a single affine correspondence via recovering special homographies. For the first, second and third classes of solvers, the sought plane is expected to be perpendicular to one of the camera axes. For the fourth class, the plane is orthogonal to the ground with unknown normal, e.g., it is a building facade. All methods are solved via a linear system with a small coefficient matrix, thus, being extremely efficient. Both the minimal and over-determined cases can be solved by the proposed solvers. They are tested on synthetic data and on publicly available real-world datasets. The novel methods are more accurate or comparable to the traditional algorithms and are faster when included in state-of-the-art robust estimators. The source code is publicly available[1].",
        "primary_area": "",
        "author": "Istvan Gergo Gal;Daniel Barath;Levente Hajder;Istvan Gergo Gal;Daniel Barath;Levente Hajder",
        "authorids": "/37088999291;/37086108821;/37281914400;/37088999291;/37086108821;/37281914400",
        "aff": "Department of Algorithms and Their Applications, E\u00f6tv\u00f6s Lor\u00e1nd University, Budapest, Hungary; Department of Computer Science, ETH Zurich; Department of Algorithms and Their Applications, E\u00f6tv\u00f6s Lor\u00e1nd University, Budapest, Hungary",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561890/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2608586250777308214&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "E\u00f6tv\u00f6s Lor\u00e1nd University;ETH Zurich",
        "aff_unique_dep": "Department of Algorithms and Their Applications;Department of Computer Science",
        "aff_unique_url": "https://www.elte.hu;https://www.ethz.ch",
        "aff_unique_abbr": "ELTE;ETHZ",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Budapest;",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Hungary;Switzerland"
    },
    {
        "id": "9561713",
        "title": "Position and Orientation Control of Polygonal Objects by Sensorless In-hand Caging Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we propose an approach to manipulate objects by position-controlled robot hands: in-hand caging manipulation. In this method, an object is manipulated based on caging without force sensing or force control. An object is caged by a robot hand throughout manipulation, and we can locate the object around a goal by deformation of the cage without sensing the object configuration. In this paper, we considered 2-D polygonal objects as the targets of in- hand caging manipulation. We also considered some position- controlled hands as the devices to manipulate the objects. A motion planning algorithm for the hands was proposed and applied to planar in-hand caging manipulation. By moving the hands according to the result of the motion planning, it was possible to manipulate the objects without sensing. Our proposed method can be applied to a device such as a part feeder that aligns variously shaped parts in the same pose.",
        "primary_area": "",
        "author": "Shun Komiyama;Yusuke Maeda;Shun Komiyama;Yusuke Maeda",
        "authorids": "/37088999209;/37276980400;/37088999209;/37276980400",
        "aff": "Graduate School of Engineering Science, Yokohama National Univesity, Hodogaya-ku, Japan; Faculty of Engineering, Yokohama National University, Hodogaya-ku, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561713/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2462834900133834550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Yokohama National University",
        "aff_unique_dep": "Graduate School of Engineering Science",
        "aff_unique_url": "https://www.ynu.ac.jp",
        "aff_unique_abbr": "YNU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hodogaya-ku",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561908",
        "title": "Positioning Control for Underactuated Unmanned Surface Vehicles to Resist Environmental Disturbances",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present the positioning control problem for underactuated unmanned surface vehicles (USVs) in the presence of unknown external disturbances, such as the wind, waves, and currents. The three control objectives of positioning control for underactuated USVs are, firstly, to retain a predefined constant distance to a look-ahead point, secondly, to regulate the vehicle heading to point at the look-ahead point and, thirdly, to update the position of the look-ahead point to rotate the USVs. Particularly, a new guidance rule is proposed to update the look-ahead point based on the positioning error such that the predefined desired position is maintained and the vehicle heading is counter to the direction of resultant environmental force at the same time. To illustrate the stability of the positioning control system, the error dynamics driven by the component of resultant environmental force is derived and analyzed. In addition to the simulations, experiments were carried out offshore in the face of wind and waves to verify the validity and effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Yang Qu;Lilong Cai;Yang Qu;Lilong Cai",
        "authorids": "/37088888999;/37288206200;/37088888999;/37288206200",
        "aff": "Department of Mechanical and Aerospace Engineering, School of Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Department of Mechanical and Aerospace Engineering, School of Engineering, The Hong Kong University of Science and Technology, Hong Kong SAR, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561908/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17459486908415350362&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ust.hk",
        "aff_unique_abbr": "HKUST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561044",
        "title": "Power Transmission Design of Fast and Energy-Efficient Stiffness Modulation for Human Power Assistance",
        "track": "main",
        "status": "Poster",
        "abstract": "Compliance in robot actuation provides a solution to perform safe physical human-robot interaction. Conventional compliant actuators (variable stiffness actuators, series elastic actuators) used more than two motors or closed-loop controller to modulate both stiffness and equilibrium position independently. These actuators are complex, lack of energy efficiency, and have limited stiffness range. In conjunction with an active, positive stiffness modulation, implementing a passive negative stiffness element enabled a compact design of the compliant actuator. This paper suggests a power transmission design of fast and energy-efficient stiffness modulation based on this new compliant actuator concept. First, the double slider-crank mechanism made fast stiffness modulation and high energy-efficiency. Second, positioning the leaf spring\u2019s bending location to the center also enabled the fast stiffness modulation speed and wide range stiffness modulation. Third, optimized elliptical cam with compression spring generated negative stiffness in output. We provide theoretical modeling of each mechanical drivetrains and characterization of positive stiffness modulation (range and speed) and negative stiffness with corresponding power consumption experimentally.",
        "primary_area": "",
        "author": "Wonseok Shin;Gunhee Park;Jooyong Lee;Handdeut Chang;Jung Kim;Wonseok Shin;Gunhee Park;Jooyong Lee;Handdeut Chang;Jung Kim",
        "authorids": "/37086493895;/37086918573;/37088998364;/37085537715;/37407273800;/37086493895;/37086918573;/37088998364;/37085537715;/37407273800",
        "aff": "Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea; Department of Mechanical Engineering, Incheon National University, Incheon, Republic of Korea; Korea Advanced Institute of Science and Technology (KAIST), Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561044/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11900707667033772504&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology;Incheon National University",
        "aff_unique_dep": ";Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.inu.ac.kr",
        "aff_unique_abbr": "KAIST;INU",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Daejeon;Incheon",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561395",
        "title": "Practical and Accurate Generation of Energy-Optimal Trajectories for a Planar Quadrotor",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by the limited flight time of batterypowered multi-rotor UAVs, in this paper we address the problem of generating energy-optimal trajectories for a planar quadrotor. More specifically, by considering an accurate electrical model for the brushless DC motors and rest-to-rest maneuvers between two predefined boundary states, we explicitly compute the minimum-energy curves by adopting a free and a fixed end-time optimal control formulation. The numerical solution of these optimal control problems hinges upon a simple yet effective indirect projected gradient method. Simulation experiments illustrate the theory in a variety of realistic flight scenarios.",
        "primary_area": "",
        "author": "Fabio Morbidi;Dominik Pisarski;Fabio Morbidi;Dominik Pisarski",
        "authorids": "/37301270800;/38488587500;/37301270800;/38488587500",
        "aff": "MIS Laboratory, Universit\u00e9 de Picardie Jules Verne, Amiens, France; Institute of Fundamental Technological Research of the Polish Academy of Sciences (IPPT PAN), Warsaw, Poland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561395/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9066485162523363462&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Universit\u00e9 de Picardie Jules Verne;Institute of Fundamental Technological Research",
        "aff_unique_dep": "MIS Laboratory;",
        "aff_unique_url": "https://www.univ-amiens.fr;",
        "aff_unique_abbr": ";IPPT PAN",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Amiens;Warsaw",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "France;Poland"
    },
    {
        "id": "9561101",
        "title": "Precise Jump Planning using Centroidal Dynamics based Bilevel Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with a problem of precise jumping for legged robots: what are the control inputs required to perform a jump that results in a desired landing point? We propose a novel precise jump planning method, formulated as a bilevel optimization problem. The presented formulation exploits certain insights into the jump dynamics, leading to a low-dimensional optimization problem, and allowing fast computation. During the Flight phase of a jump there are no external forces other than gravity acting on the robot, so its centroidal angular momentum (CAM) is conserved, and its center of mass (COM) follows a ballistic trajectory. This trajectory depends solely on COM position and velocity at Liftoff. We define a bilevel optimization problem consisting of a nonlinear upper-level problem, and a lower-level quadratic programming (QP) problem. The upper-level problem selects COM position and velocity at Liftoff that result in a desired landing point, while minimizing CAM at Liftoff. The lower-level problem selects ground reaction forces during Push-Off that achieve desired COM position and velocity at Liftoff. The results are presented on a simulated one-legged robot, but the proposed approach can be extended to bipeds and multi-legged robots.",
        "primary_area": "",
        "author": "Ivo Vatavuk;Zdenko Kova\u010di\u0107;Ivo Vatavuk;Zdenko Kova\u010di\u0107",
        "authorids": "/37088923783;/37354273800;/37088923783;/37354273800",
        "aff": "PhD Student at the Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia; PhD, is a Full Professor at the Faculty of Electrical Engineering and Computing, University of Zagreb, Zagreb, Croatia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561101/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10835615183126688615&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Zagreb",
        "aff_unique_dep": "Faculty of Electrical Engineering and Computing",
        "aff_unique_url": "https://www.unizg.hr",
        "aff_unique_abbr": "UNIZG",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Zagreb",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Croatia"
    },
    {
        "id": "9561222",
        "title": "Precise Multi-Modal In-Hand Pose Estimation using Low-Precision Sensors for Robotic Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "In industrial assembly tasks, the in-hand pose of grasped objects needs to be known with high precision for subsequent manipulation tasks such as insertion. This problem (in-hand-pose estimation) has traditionally been addressed using visual recognition or tactile sensing. On the one hand, while visual recognition can provide efficient pose estimates, it tends to suffer from low precision due to noise, occlusions and calibration errors. On the other hand, tactile fingertip sensors can provide precise complementary information, but their low durability significantly limits their use in real-world applications. To get the best of both worlds, we propose an efficient method for in-hand pose estimation using off-the-shelf cameras and robot wrist force sensors, which requires no precise camera calibration. The key idea is to utilize visual and contact information adaptively to maximally reduce the uncertainty about the in-hand object pose in a Bayesian state estimation framework. As most of the uncertainty can be resolved from visual observations, our approach reduces the number of physical environment interactions while keeping a high pose estimation accuracy. Our experimental evaluation demonstrates that our approach can estimate object poses with sub-mm precision with an off-the-shelf camera and force-torque sensor.",
        "primary_area": "",
        "author": "Felix von Drigalski;Kennosuke Hayashi;Yifei Huang;Ryo Yonetani;Masashi Hamaya;Kazutoshi Tanaka;Yoshihisa Ijiri;Felix von Drigalski;Kennosuke Hayashi;Yifei Huang;Ryo Yonetani;Masashi Hamaya;Kazutoshi Tanaka;Yoshihisa Ijiri",
        "authorids": "/37086063905;/37089001400;/37086336062;/37085641524;/37085532024;/37088507484;/37085621887;/37086063905;/37089001400;/37086336062;/37085641524;/37085532024;/37088507484;/37085621887",
        "aff": "OMRON SINIC X Corporation, Tokyo, Japan; OMRON Corporation, Tokyo, Japan; University of Tokyo, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON Corporation, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561222/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12874840625081252386&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;0;0;1",
        "aff_unique_norm": "OMRON SINIC X Corporation;OMRON Corporation;University of Tokyo",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";https://www.omron.com;https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": ";OMRON;UTokyo",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561617",
        "title": "Predicting Disparity Distributions",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate a novel deep-learning-based approach to estimate uncertainty in stereo disparity prediction networks. Current state-of-the-art methods often formulate disparity prediction as a regression problem with a single scalar output in each pixel. This can be problematic in practical applications as in many cases there might not exist a single well defined disparity, for example in cases of occlusions or at depth-boundaries. While current neural-network-based disparity estimation approaches obtain good performance on benchmarks, the disparity prediction is treated as a black box at inference time. In this paper we show that by formulating the learning problem as a regression with a distribution target, we obtain a robust estimate of the uncertainty in each pixel, while maintaining the performance of the original method. The proposed method is evaluated both on a large-scale standard benchmark, as well on our own data. We also show that the uncertainty estimate significantly improves by maximizing the uncertainty in those pixels that have no well defined disparity during learning.",
        "primary_area": "",
        "author": "Gustav H\u00e4ger;Mikael Persson;Michael Felsberg;Gustav H\u00e4ger;Mikael Persson;Michael Felsberg",
        "authorids": "/37085622318;/37085646930;/37398283600;/37085622318;/37085646930;/37398283600",
        "aff": "Gustav H\u00e4ger; Mikael Persson; Michael Felsberg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561617/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9091990644667226930&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9561768",
        "title": "Predicting the Post-Impact Velocity of a Robotic Arm via Rigid Multibody Models: an Experimental Study",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate post-impact velocity predictions are essential in developing impact-aware manipulation strategies for robots, where contacts are intentionally established at non-zero speed mimicking human manipulation abilities in dynamic grasping and pushing of objects. Starting from the recorded dynamic response of a 7DOF torque-controlled robot that intentionally impacts a rigid surface, we investigate the possibility and accuracy of predicting the post-impact robot velocity from the pre-impact velocity and impact configuration. The velocity prediction is obtained by means of an impact map, derived using the framework of nonsmooth mechanics, that makes use of the known rigid-body robot model and the assumption of a frictionless inelastic impact.The main contribution is proposing a methodology that allows for a meaningful quantitative comparison between the recorded post-impact data, that exhibits a damped oscillatory response after the impact, and the post-impact velocity prediction derived via the readily available rigid-body robot model, that presents no oscillations and that is the one typically obtained via mainstream robot simulator software. The results of this new approach are promising in terms of prediction accuracy and thus relevant for the growing field of impact-aware robot control. The recorded impact data (18 experiments) is made publicly available, together with the numerical routines employed to generate the quantitative comparison, to further stimulate interest/research in this field.",
        "primary_area": "",
        "author": "Ilias Aouaj;Vincent Padois;Alessandro Saccon;Ilias Aouaj;Vincent Padois;Alessandro Saccon",
        "authorids": "/37088999274;/38534363400;/37296911500;/37088999274;/38534363400;/37296911500",
        "aff": "Department of Mechanical Engineering, MSc Project, Eindhoven University of Technology (TU/e), The Netherlands; Auctus, Inria - IMS (Univ. Bordeaux / Bordeaux INP / CNRS UMR 5218), Talence, France; Department of Mechanical Engineering, Eindhoven University of Technology (TU/e), The Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561768/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10563924654495329900&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Eindhoven University of Technology;INRIA",
        "aff_unique_dep": "Department of Mechanical Engineering;IMS",
        "aff_unique_url": "https://www.tue.nl;https://www.inria.fr",
        "aff_unique_abbr": "TU/e;Inria",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Eindhoven;Talence",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Netherlands;France"
    },
    {
        "id": "9560790",
        "title": "Prediction-Based Reachability for Collision Avoidance in Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Safety is an important topic in autonomous driving since any collision may cause serious injury to people and damage to property. Hamilton-Jacobi (HJ) Reachability is a formal method that verifies safety in multi-agent interaction and provides a safety controller for collision avoidance. However, due to the worst-case assumption on the car\u2019s future behaviours, reachability might result in too much conservatism such that the normal operation of the vehicle is badly hindered. In this paper, we leverage the power of trajectory prediction and propose a prediction-based reachability framework to compute safety controllers. Instead of always assuming the worst case, we cluster the car\u2019s behaviors into multiple driving modes, e.g. left turn or right turn. Under each mode, a reachability-based safety controller is designed based on a less conservative action set. For online implementation, we first utilize the trajectory prediction and our proposed mode classifier to predict the possible modes, and then deploy the corresponding safety controller. Through simulations in a T-intersection and an 8-way roundabout, we demonstrate that our prediction-based reachability method largely avoids collision between two interacting cars and reduces the conservatism that the safety controller brings to the car\u2019s original operation.",
        "primary_area": "",
        "author": "Anjian Li;Liting Sun;Wei Zhan;Masayoshi Tomizuka;Mo Chen;Anjian Li;Liting Sun;Wei Zhan;Masayoshi Tomizuka;Mo Chen",
        "authorids": "/37088483094;/37085425729;/37067099600;/37281933000;/37085494765;/37088483094;/37085425729;/37067099600;/37281933000;/37085494765",
        "aff": "School of Computing Science, Simon Fraser University, Burnaby, BC, Canada; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; School of Computing Science, Simon Fraser University, Burnaby, BC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560790/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4217536700350432902&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "Simon Fraser University;University of California, Berkeley",
        "aff_unique_dep": "School of Computing Science;Department of Mechanical Engineering",
        "aff_unique_url": "https://www.sfu.ca;https://www.berkeley.edu",
        "aff_unique_abbr": "SFU;UC Berkeley",
        "aff_campus_unique_index": "0;1;1;1;0",
        "aff_campus_unique": "Burnaby;Berkeley",
        "aff_country_unique_index": "0;1;1;1;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9561599",
        "title": "Prediction-Error Negativity to Assess Singularity Avoidance Strategies in Physical Human-Robot Collaboration",
        "track": "main",
        "status": "Poster",
        "abstract": "In physical human-robot collaboration (pHRC), singularity avoidance strategies are often critical to obtain stable interaction dynamics. It is hypothesised a predictable singularity avoidance strategy is preferred in pHRC as humans tend to maximise predictability when using complex systems. By using an electroencephalogram (EEG), it is possible to assess the predictability of a task through a feature found in event-related potentials (ERP) and called prediction-error negativity (PEN). In this paper, two research questions are addressed. Can a complex pHRC singularity avoidance strategy generate a detectable PEN? Are PEN and human preferences related when comparing different control settings in a singularity avoidance strategy? Fourteen participants compared two different sets of parameters (modes) in a singularity avoidance strategy based on the exponentially damped least-squared (EDLS) method. ERP results are presented in terms of power spectral density (PSD). ERP results were then compared with human preferences to see whether they are related. Results show that the mode that causes PEN is also the one that participants did not like, suggesting that a lack of predictability might have an impact on human preference.",
        "primary_area": "",
        "author": "Stefano Aldini;Avinash K. Singh;Marc Carmichael;Yu-Kai Wang;Dikai Liu;Chin-Teng Lin;Stefano Aldini;Avinash K. Singh;Marc Carmichael;Yu-Kai Wang;Dikai Liu;Chin-Teng Lin",
        "authorids": "/37086936135;/37085625773;/37601543500;/38196048700;/37290601500;/37278412100;/37086936135;/37085625773;/37601543500;/38196048700;/37290601500;/37278412100",
        "aff": "Robotics Institute, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Australian Artificial Intelligence Institute, School of Software, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Robotics Institute, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Australian Artificial Intelligence Institute, School of Software, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Robotics Institute, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia; Australian Artificial Intelligence Institute, School of Software, Faculty of Engineering and Information Technology, University of Technology Sydney, Ultimo, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561599/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15918611932889042580&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "Robotics Institute, Faculty of Engineering and Information Technology",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Ultimo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9560737",
        "title": "Predictive 3D Sonar Mapping of Underwater Environments via Object-specific Bayesian Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent work has achieved dense 3D reconstruction with wide-aperture imaging sonar using a stereo pair of orthogonally oriented sonars. This allows each sonar to observe a spatial dimension that the other is missing, without requiring any prior assumptions about scene geometry. However, this is achieved only in a small region with overlapping fields-of-view, leaving large regions of sonar image observations with an unknown elevation angle. Our work aims to achieve large-scale 3D reconstruction more efficiently using this sensor arrangement. We propose dividing the world into semantic classes to exploit the presence of repeating structures in the subsea environment. We use a Bayesian inference framework to build an understanding of each object class\u2019s geometry when 3D information is available from the orthogonal sonar fusion system, and when the elevation angle of our returns is unknown, our framework is used to infer unknown 3D structure. We quantitatively validate our method in a simulation and use data collected from a real outdoor littoral environment to demonstrate the efficacy of our framework in the field.",
        "primary_area": "",
        "author": "John McConnell;Brendan Englot;John McConnell;Brendan Englot",
        "authorids": "/37827503600;/37601539900;/37827503600;/37601539900",
        "aff": "Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA; Department of Mechanical Engineering, Stevens Institute of Technology, Hoboken, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560737/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11089348318853554158&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stevens Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stevens.edu",
        "aff_unique_abbr": "SIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hoboken",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561193",
        "title": "Predictive Runtime Monitoring for Mobile Robots using Logic-Based Bayesian Intent Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a predictive runtime monitoring framework that forecasts the distribution of future positions of mobile robots in order to detect and avoid impending property violations such as collisions with obstacles or other agents. Our approach uses a restricted class of temporal logic formulas to represent the likely intentions of the agents along with a combination of temporal logic-based optimal cost path planning and Bayesian inference to compute the probability of these intents given the current trajectory of the robot. First, we construct a large but finite hypothesis space of possible intents represented as temporal logic formulas whose atomic propositions are derived from a detailed map of the robot\u2019s workspace. Next, our approach uses real-time observations of the robot\u2019s position to update a distribution over temporal logic formulae that represent its likely intent. This is performed by using a combination of optimal cost path planning and a Boltzmann noisy rationality model. In this manner, we construct a Bayesian approach to evaluating the posterior probability of various hypotheses given the observed states and actions of the robot. Finally, we predict the future position of the robot by drawing posterior predictive samples using a Monte-Carlo method. We evaluate our framework using two different trajectory datasets that contain multiple scenarios implementing various tasks. The results show that our method can predict future positions precisely and efficiently, so that the computation time for generating a prediction is a tiny fraction of the overall time horizon.",
        "primary_area": "",
        "author": "Hansol Yoon;Sriram Sankaranarayanan;Hansol Yoon;Sriram Sankaranarayanan",
        "authorids": "/37088689636;/37409120700;/37088689636;/37409120700",
        "aff": "Department of Computer Science, University of Colorado, Boulder, USA; Department of Computer Science, University of Colorado, Boulder, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561193/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13072279074575012122&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Colorado",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.colorado.edu",
        "aff_unique_abbr": "CU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Boulder",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561515",
        "title": "Preference-Based Learning for User-Guided HZD Gait Generation on Bipedal Walking Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a framework that leverages both control theory and machine learning to obtain stable and robust bipedal locomotion without the need for manual parameter tuning. Traditionally, gaits are generated through trajectory optimization methods and then realized experimentally \u2014 a process that often requires extensive tuning due to differences between the models and hardware. In this work, the process of gait realization via hybrid zero dynamics (HZD) based optimization is formally combined with preference-based learning to systematically realize dynamically stable walking. Importantly, this learning approach does not require a carefully constructed reward function, but instead utilizes human pairwise preferences. The power of the proposed approach is demonstrated through two experiments on a planar biped AMBER-3M: the first with rigid point-feet, and the second with induced model uncertainty through the addition of springs where the added compliance was not accounted for in the gait generation or in the controller. In both experiments, the framework achieves stable, robust, efficient, and natural walking in fewer than 50 iterations with no reliance on a simulation environment. These results demonstrate a promising step in the unification of control theory and learning.",
        "primary_area": "",
        "author": "Maegan Tucker;Noel Csomay-Shanklin;Wen-Loong Ma;Aaron D. Ames;Maegan Tucker;Noel Csomay-Shanklin;Wen-Loong Ma;Aaron D. Ames",
        "authorids": "/37087122493;/37086862522;/37085547381;/37300877900;/37087122493;/37086862522;/37085547381;/37300877900",
        "aff": "Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA; Department of Mechanical and Civil Engineering, California Institute of Technology, Pasadena, CA; Department of Computing and Mathematical Sciences, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561515/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5092812317695398911&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical and Civil Engineering",
        "aff_unique_url": "https://www.caltech.edu",
        "aff_unique_abbr": "Caltech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pasadena",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561785",
        "title": "Priority Patrolling using Multiple Agents",
        "track": "main",
        "status": "Poster",
        "abstract": "The Patrolling Problem is a crucial feature of the surveillance task in defense and other establishments. Most of the works in the literature concentrate on reducing the Idleness value at each location in the environment. However, there are often a few prioritized locations that cannot be left unvisited beyond a certain Time Period. In this paper, we study the problem of Prioritized patrolling - the task of patrolling the given environment using multiple agents while ensuring the prioritized locations are visited within the pre-specified Time Period. We present a novel algorithm, namely, Time Period Based Patrolling (TPBP) algorithm, to solve the prioritized patrolling problem. It determines a sequence of walks for each agent online that complies with the Time Period requirement of the Priority nodes while reducing the Idleness of all the other nodes. We have tested and validated the algorithm using SUMO - a realistic simulator developed for traffic management. Since the existing strategies are not designed for Prioritized Patrolling, we show through comparison that proposed algorithm is required to solve the problem.",
        "primary_area": "",
        "author": "Deepak Mallya;Sumanth Kandala;Leena Vachhani;Arpita Sinha;Deepak Mallya;Sumanth Kandala;Leena Vachhani;Arpita Sinha",
        "authorids": "/37088999977;/37088997288;/37570418900;/37419610500;/37088999977;/37088997288;/37570418900;/37419610500",
        "aff": "Dept. of Systems and Control Engineering, Indian Institute of Technology Bombay, Mumbai, India; Dept. of Mechanical Engineering, Indian Institute of Technology, Mumbai, India; Dept. of Systems and Control Engineering, Indian Institute of Technology Bombay, Mumbai, India; Dept. of Systems and Control Engineering, Indian Institute of Technology Bombay, Mumbai, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561785/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9298799794927372850&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Indian Institute of Technology Bombay;Indian Institute of Technology",
        "aff_unique_dep": "Dept. of Systems and Control Engineering;Dept. of Mechanical Engineering",
        "aff_unique_url": "https://www.iitb.ac.in;https://www.iitb.ac.in",
        "aff_unique_abbr": "IIT Bombay;IIT Bombay",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Mumbai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9561162",
        "title": "Proactive Action Visual Residual Reinforcement Learning for Contact-Rich Tasks Using a Torque-Controlled Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Contact-rich manipulation tasks are commonly found in modern manufacturing settings. However, manually designing a robot controller is considered hard for traditional control methods as the controller requires an effective combination of modalities and vastly different characteristics. In this paper, we first consider incorporating operational space visual and haptic information into a reinforcement learning (RL) method to solve the target uncertainty problems in unstructured environments. Moreover, we propose a novel idea of introducing a proactive action to solve a partially observable Markov decision process (POMDP) problem. With these two ideas, our method can either adapt to reasonable variations in unstructured environments or improve the sample efficiency of policy learning. We evaluated our method on a task that involved inserting a random-access memory (RAM) using a torque-controlled robot and tested the success rates of different baselines used in the traditional methods. We proved that our method is robust and can tolerate environmental variations.",
        "primary_area": "",
        "author": "Yunlei Shi;Zhaopeng Chen;Hongxu Liu;Sebastian Riedel;Chunhui Gao;Qian Feng;Jun Deng;Jianwei Zhang;Yunlei Shi;Zhaopeng Chen;Hongxu Liu;Sebastian Riedel;Chunhui Gao;Qian Feng;Jun Deng;Jianwei Zhang",
        "authorids": "/37088999645;/37404312400;/37088997970;/37085795468;/37088505468;/37088504248;/38248056200;/37281460600;/37088999645;/37404312400;/37088997970;/37085795468;/37088505468;/37088504248;/38248056200;/37281460600",
        "aff": "Agile Robots AG; Department of Informatics, TAMS (Technical Aspects of Multimodal Systems), Universit\u00e4t Hamburg; Technische Universit\u00e4t M\u00fcnchen; Agile Robots AG; Agile Robots AG; Technische Universit\u00e4t M\u00fcnchen; Agile Robots AG; Department of Informatics, TAMS (Technical Aspects of Multimodal Systems), Universit\u00e4t Hamburg",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561162/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4000750383871581310&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;2;0;0;2;0;1",
        "aff_unique_norm": "Agile Robots AG;Universit\u00e4t Hamburg;Technische Universit\u00e4t M\u00fcnchen",
        "aff_unique_dep": ";Department of Informatics;",
        "aff_unique_url": "https://www.agilerobots.com;https://www.uni-hamburg.de;https://www.tum.de",
        "aff_unique_abbr": "Agile Robots;UHH;TUM",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9562115",
        "title": "Proactive Interaction Framework for Intelligent Social Receptionist Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Proactive human-robot interaction (HRI) allows the receptionist robots to actively greet people and offer services based on vision, which has been found to improve acceptability and customer satisfaction. Existing approaches are either based on multi-stage decision processes or based on end-to-end decision models. However, the rule-based approaches require sedulous expert efforts and only handle minimal pre-defined scenarios. On the other hand, existing works with end-to-end models are limited to very general greetings or few behavior patterns (typically less than 10). To address those challenges, we propose a new end-to-end framework, the TransFormer with Visual Tokens for Human-Robot Interaction (TFVT-HRI)1. The proposed framework extracts visual tokens of relative objects from an RGB camera first. To ensure the correct interpretation of the scenario, a transformer decision model is then employed to process the visual tokens, which is augmented with the temporal and spatial information. It predicts the appropriate action to take in each scenario and identifies the right target. Our data is collected from an in-service receptionist robot in an office building, which is then annotated by experts for appropriate proactive behavior. The action set includes 1000+ diverse patterns by combining language, emoji expression, and body motions. We compare our model with other SOTA end-to-end models on both offline test sets and online user experiments in realistic office building environments to validate this framework. It is demonstrated that the decision model achieves SOTA performance in action triggering and selection, resulting in more humanness and intelligence when compared with the previous reactive reception policies.",
        "primary_area": "",
        "author": "Yang Xue;Fan Wang;Hao Tian;Min Zhao;Jiangyong Li;Haiqing Pan;Yueqiang Dong;Yang Xue;Fan Wang;Hao Tian;Min Zhao;Jiangyong Li;Haiqing Pan;Yueqiang Dong",
        "authorids": "/37088996147;/37089851155;/37089000560;/37088999920;/37088998444;/37088998654;/37088996558;/37088996147;/37089851155;/37089000560;/37088999920;/37088998444;/37088998654;/37088996558",
        "aff": "Baidu Natural Language Processing Department; Baidu Natural Language Processing Department; Baidu Research; Baidu AI Interaction Design Lab; Baidu Natural Language Processing Department; Baidu AI Interaction Design Lab; Baidu Natural Language Processing Department",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562115/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14950824778287122621&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Baidu",
        "aff_unique_dep": "Natural Language Processing Department",
        "aff_unique_url": "https://www.baidu.com",
        "aff_unique_abbr": "Baidu",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562038",
        "title": "ProbRobScene: A Probabilistic Specification Language for 3D Robotic Manipulation Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic control tasks are often first run in simulation for the purposes of verification, debugging and data augmentation. Many methods exist to specify what task a robot must complete, but few exist to specify what range of environments a user expects such tasks to be achieved in. ProbRobScene is a probabilistic specification language for describing robotic manipulation environments. Using the language, a user need only specify the relational constraints that must hold between objects in a scene. ProbRobScene then automatically generates scenes which conform to this specification. By combining aspects of probabilistic programming languages and convex geometry, we provide a method for sampling this space of possible environments efficiently. We demonstrate the usefulness of our language by using it to debug a robotic controller in a tabletop robot manipulation environment.",
        "primary_area": "",
        "author": "Craig Innes;Subramanian Ramamoorthy;Craig Innes;Subramanian Ramamoorthy",
        "authorids": "/37088996171;/37529920500;/37088996171;/37529920500",
        "aff": "Craig Innes; Subramanian Ramamoorthy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562038/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17087367472919729504&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9561754",
        "title": "Probabilistic 3D Multi-Modal, Multi-Object Tracking for Autonomous Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "Multi-object tracking is an important ability for an autonomous vehicle to safely navigate a traffic scene. Current state-of-the-art follows the tracking-by-detection paradigm where existing tracks are associated with detected objects through some distance metric. Key challenges to increase tracking accuracy lie in data association and track life cycle management. We propose a probabilistic, multi-modal, multiobject tracking system consisting of different trainable modules to provide robust and data-driven tracking results. First, we learn how to fuse features from 2D images and 3D LiDAR point clouds to capture the appearance and geometric information of an object. Second, we propose to learn a metric that combines the Mahalanobis and feature distances when comparing a track and a new detection in data association. And third, we propose to learn when to initialize a track from an unmatched object detection. Through extensive quantitative and qualitative results, we show that when using the same object detectors our method outperforms state-of-the-art approaches on the NuScenes and KITTI datasets.",
        "primary_area": "",
        "author": "Hsu-Kuang Chiu;Jie Li;Rare\u015f Ambru\u015f;Jeannette Bohg;Hsu-Kuang Chiu;Jie Li;Rare\u015f Ambru\u015f;Jeannette Bohg",
        "authorids": "/37089400484;/37088999723;/37871304500;/37591153900;/37089400484;/37088999723;/37871304500;/37591153900",
        "aff": "Stanford University; Toyota Research Institute; Toyota Research Institute; Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561754/",
        "gs_citation": 306,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1836579218186495879&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Stanford University;Toyota Research Institute",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://www.tri.global",
        "aff_unique_abbr": "Stanford;TRI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561053",
        "title": "Probabilistic Dynamic Crowd Prediction for Social Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel approach that predicts spatially and temporally crowd behaviour for robotic social navigation. Integrating mobile robots into human society involves the fundamental problem of navigation in crowds. A robot should attempt to navigate in a way that is minimally invasive to the humans in its environment. However, planning in a dynamic environment is difficult as the environment must be predicted into the future. This problem has been thoroughly studied considering the behaviour of pedestrians at the level of individuals. Instead, we represent a pedestrian crowd by its macroscopic properties over space, such as density and velocity. With this spatial representation, we propose to learn a convolutional recurrent model to predict these properties into the future. The key design of a probabilistic loss function capturing the crowd's macroscopic properties empowers the spatio-temporal crowd prediction. Using a social invasiveness metric defined on these properties predicted by our convolutional recurrent model, we develop a framework that produces globally-optimal plans in expectation. Extensive results using a realistic pedestrian simulator show the validity and performance of the proposed social navigation approach.",
        "primary_area": "",
        "author": "Stefan H. Kiss;Kavindie Katuwandeniya;Alen Alempijevic;Teresa Vidal-Calleja;Stefan H. Kiss;Kavindie Katuwandeniya;Alen Alempijevic;Teresa Vidal-Calleja",
        "authorids": "/37088995973;/37086555084;/37296706500;/37085384801;/37088995973;/37086555084;/37296706500;/37085384801",
        "aff": "University of Technology, Sydney, NSW, Australia; University of Technology, Sydney, NSW, Australia; University of Technology, Sydney, NSW, Australia; University of Technology, Sydney, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561053/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4380103677853757022&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9561665",
        "title": "Probabilistic Human Motion Prediction via A Bayesian Neural Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Human motion prediction is an important and challenging topic that has promising prospects in efficient and safe human-robot-interaction systems. Currently, the majority of the human motion prediction algorithms are based on deterministic models, which may lead to risky decisions for robots. To solve this problem, we propose a probabilistic model for human motion prediction in this paper. The key idea of our approach is to extend the conventional deterministic motion prediction neural network to a Bayesian one. On one hand, our model could generate several future motions when given an observed motion sequence. On the other hand, by calculating the Epistemic Uncertainty and the Heteroscedastic Aleatoric Uncertainty, our model could tell the robot if the observation has been seen before and also give the optimal result among all possible predictions. We extensively validate our approach on a large scale benchmark dataset Human3.6m. The experiments show that our approach performs better than deterministic methods. We further evaluate our approach in a Human-Robot-Interaction (HRI) scenario. The experimental results show that our approach makes the interaction more efficient and safer.",
        "primary_area": "",
        "author": "Jie Xu;Xingyu Chen;Xuguang Lan;Nanning Zheng;Jie Xu;Xingyu Chen;Xuguang Lan;Nanning Zheng",
        "authorids": "/37087083468;/37085568094;/37270865300;/37271536700;/37087083468;/37085568094;/37270865300;/37271536700",
        "aff": "Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, Xi\u2019an, China; Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, Xi\u2019an, China; Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, Xi\u2019an, China; Institute of Artificial Intelligence and Robotics, Xi\u2019an Jiaotong University, Xi\u2019an, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561665/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6125397982269334105&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Xi'an Jiao Tong University",
        "aff_unique_dep": "Institute of Artificial Intelligence and Robotics",
        "aff_unique_url": "http://www.xjtu.edu.cn",
        "aff_unique_abbr": "XJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Xi'an",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561894",
        "title": "Probabilistic Safety-Assured Adaptive Merging Control for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles face tremendous challenges while interacting with human drivers in different kinds of scenarios. Developing control methods with safety guarantees while performing interactions with uncertainty is an ongoing research goal. In this paper, we present a real-time safe control framework using bi-level optimization with Control Barrier Function (CBF) that enables an autonomous ego vehicle to interact with human-driven cars in ramp merging scenarios with a consistent safety guarantee. In order to explicitly address motion uncertainty, we propose a novel extension of control barrier functions to a probabilistic setting with provable chance-constrained safety and analyze the feasibility of our control design. The formulated bi-level optimization framework entails first choosing the ego vehicle's optimal driving style in terms of safety and primary objective, and then minimally modifying a nominal controller in the context of quadratic programming subject to the probabilistic safety constraints. This allows for adaptation to different driving strategies with a formally provable feasibility guarantee for the ego vehicle's safe controller. Experimental results are provided to demonstrate the effectiveness of our proposed approach.",
        "primary_area": "",
        "author": "Yiwei Lyu;Wenhao Luo;John M. Dolan;Yiwei Lyu;Wenhao Luo;John M. Dolan",
        "authorids": "/37088505262;/37085748889;/37283756800;/37088505262;/37085748889;/37283756800",
        "aff": "Department of Electrical and Computer Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561894/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17969254494937023653&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561979",
        "title": "Probabilistic Scan Matching: Bayesian Pose Estimation from Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Estimating position and orientation change of a mobile platform from two consecutive point clouds provided by a high-resolution sensor is a key problem in autonomous navigation. In particular, scan matching algorithms aim to find the translation and rotation of the platform such that the two point clouds coincide. The association of measurements in point cloud one with measurements in point cloud two is a problem inherent to scan matching. Existing methods perform non-probabilistic data association, i.e., they assume a single association hypothesis. This leads to overconfident pose estimates and reduced estimation accuracy in ambiguous environments. Our probabilistic scan matching approach addresses this issue by considering all association hypotheses with their respective likelihoods. We formulate a holistic Bayesian estimation problem for both data association and pose inference and present the corresponding joint factor graph. Near-optimum maximum a posteriori (MAP) estimates of the sensor pose are computed by performing iterative message passing on the factor graph. Our numerical study shows performance improvements compared to non-probabilistic scan matching methods that are based on the normal distributions transform (NDT) and implicit moving least squares (IMLS).",
        "primary_area": "",
        "author": "Rico Mendrzik;Florian Meyer;Rico Mendrzik;Florian Meyer",
        "authorids": "/37085846189;/38469615800;/37085846189;/38469615800",
        "aff": "Ibeo Autmotive Systems GmbH, Hamburg, Germany; University of California San Diego, San Diego, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561979/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14277103990973661847&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Ibeo Automotive Systems GmbH;University of California, San Diego",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ibeo-as.com;https://ucsd.edu",
        "aff_unique_abbr": ";UCSD",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";San Diego",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9561689",
        "title": "Probabilistic Terrain Estimation for Autonomous Off-Road Driving",
        "track": "main",
        "status": "Poster",
        "abstract": "For autonomous driving in urban environments it is usually assumed that the road is flat. To drive off-road, however, we need a more sophisticated model of the ground surface. While previous work is mapping the terrain along with static obstacles, we propose to separate the tasks and introduce a new approach to probabilistic terrain estimation. It combines recursive Gaussian state estimation with a subsequent maximum a posteriori estimation. This allows us to efficiently accumulate obtained measurements and at the same time get a probabilistic terrain estimate based on a geometric terrain model. This way, also (measurement) uncertainties as well as inter- and extrapolation to unobserved areas are handled stochastically correct. We demonstrate the effectiveness and real-time capability of our approach using real-world data.",
        "primary_area": "",
        "author": "Bianca Forkel;Jan Kallwies;Hans-Joachim Wuensche;Bianca Forkel;Jan Kallwies;Hans-Joachim Wuensche",
        "authorids": "/37088402331;/37086060157;/37393701000;/37088402331;/37086060157;/37393701000",
        "aff": "Institute for Autonomous Systems Technology (TAS) of the Universitat der Bundeswehr M\u00fcnchen, Neubiberg, Germany; Institute for Autonomous Systems Technology (TAS) of the Universitat der Bundeswehr M\u00fcnchen, Neubiberg, Germany; Institute for Autonomous Systems Technology (TAS) of the Universitat der Bundeswehr M\u00fcnchen, Neubiberg, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561689/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2930500554736186583&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Universitat der Bundeswehr M\u00fcnchen",
        "aff_unique_dep": "Institute for Autonomous Systems Technology (TAS)",
        "aff_unique_url": "https://www.unibw.de",
        "aff_unique_abbr": "UniBW",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Neubiberg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561266",
        "title": "Productive Multitasking for Industrial Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "The application of robotic solutions to small-batch production is challenging: economical constraints tend to dramatically limit the time for setting up new batches. Organizing robot tasks into modular software components, called skills, and allowing the assignment of multiple concurrent tasks to a single robot is potentially game-changing. However, due to cycle time constraints, it may be necessary for a skill to take over without waiting on another to terminate, and the available literature lacks a systematic approach in this case. In the present article, we fill the gap by (a) establishing the specifications of skills that can be sequenced with partial executions, (b) proposing an implementation based on the combination of finite-state machines and behavior trees, and (c) demonstrating the benefits of such skills through extensive trials in the environment of ARIAC (Agile Robotics for Industrial Automation Competition).",
        "primary_area": "",
        "author": "D. Wuthier;F. Rovida;M. Fumagalli;V. Kr\u00fcger;D. Wuthier;F. Rovida;M. Fumagalli;V. Kr\u00fcger",
        "authorids": "/37085850488;/37085541867;/37533446100;/37274543000;/37085850488;/37085541867;/37533446100;/37274543000",
        "aff": "Department of Electrical Engineering, Automation and Control, Technical University of Denmark, Kgs. Lyngby, Denmark; RiACT ApS, Copenhagen SV, Denmark; Department of Electrical Engineering, Automation and Control, Technical University of Denmark, Kgs. Lyngby, Denmark; Department of Computer Science, Robotics and Semantic Systems (RSS), Lund University, Lund, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561266/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3164607178116087772&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Technical University of Denmark;RiACT ApS;Lund University",
        "aff_unique_dep": "Department of Electrical Engineering, Automation and Control;;Department of Computer Science, Robotics and Semantic Systems (RSS)",
        "aff_unique_url": "https://www.tu.dk;;https://www.lunduniversity.lu.se",
        "aff_unique_abbr": "DTU;;LU",
        "aff_campus_unique_index": "0;1;0;2",
        "aff_campus_unique": "Kgs. Lyngby;Copenhagen;Lund",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Denmark;Sweden"
    },
    {
        "id": "9561719",
        "title": "Projector-Guided Non-Holonomic Mobile 3D Printing",
        "track": "main",
        "status": "Poster",
        "abstract": "Fused deposition modeling (FDM) using mobile robots instead of the gantry-based 3D printer enables additive manufacturing at a larger scale with higher speed. This introduces challenges including accurate localization, control of the printhead, and design of a stable mobile manipulator with low vibrations and proper degrees of freedom. We proposed and developed a low-cost non-holonomic mobile 3D printing system guided by a projector via learning-based visual servoing. It requires almost no manual calibration of the system parameters. Using a regular top-down projector without any expensive external localization device for pose feedback, this system enabled mobile robots to accurately follow pre-designed millimeter-level printing trajectories with speed control. We evaluate the system in terms of its trajectory accuracy and printing quality compared with original 3D designs. We further demonstrated the potential of this system using two such mobile robots to collaboratively print a 3D object with dimensions of 80 cm \u00d7 30 cm size, which exceeds the limitation of common desktop FDM 3D printers.",
        "primary_area": "",
        "author": "Xuchu Xu;Ziteng Wang;Chen Feng;Xuchu Xu;Ziteng Wang;Chen Feng",
        "authorids": "/37089001375;/37088999647;/37086391326;/37089001375;/37088999647;/37086391326",
        "aff": "New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA; New York University, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561719/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8734904458922702033&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brooklyn",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561156",
        "title": "Proportional and Reachable Cluster Teleoperation of a Distributed Multi-Robot System",
        "track": "main",
        "status": "Poster",
        "abstract": "A remote team of robots may be teleoperated by multiple users to explore unstructured environments and to tackle unforeseen emergencies therein. During a large-scale environmental search, each user may visually observe a unique hazard endangering the remote robot connected to their local robot. Therefore, each user may want to tele-drive the remote robot team to a location different than the target locations of other users. This paper resolves the possible conflicts among the multiple user commands through a distributed clustering algorithm that allocates to each user a number of remote robots proportional to the urgency of their request. A pivotal design challenge in the teleoperation context is to ensure that the remote robots allocated to each user are topologically reachable from the user\u2019s local robot within the induced communication subnetwork. The proposed design overcomes this challenge through a reachability-constrained integer linear program that modulates the interconnections of the remote robots on the fly. A comparative experiment on a platform with 2 local and 12 remote robots validates the practical efficacy of the proposed clustering algorithm.",
        "primary_area": "",
        "author": "Yuan Yang;Daniela Constantinescu;Yang Shi;Yuan Yang;Daniela Constantinescu;Yang Shi",
        "authorids": "/37086995217;/37425419400;/37420083500;/37086995217;/37425419400;/37420083500",
        "aff": "Department of Mechanical Engineering, University of Victoria, Victoria, BC, Canada; Department of Mechanical Engineering, University of Victoria, Victoria, BC, Canada; Department of Mechanical Engineering, University of Victoria, Victoria, BC, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561156/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18088412026247387976&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Victoria",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.uvic.ca",
        "aff_unique_abbr": "UVic",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Victoria",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9562051",
        "title": "Protective Policy Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "Being able to transfer existing skills to new situations is a key capability when training robots to operate in unpredictable real-world environments. A successful transfer algorithm should not only minimize the number of samples that the robot needs to collect in the new environment, but also prevent the robot from damaging itself or the surrounding environment during the transfer process. In this work, we introduce a policy transfer algorithm for adapting robot locomotion skills to novel scenarios while minimizing serious failures. Our algorithm trains two control policies in the training environment: a task policy that is optimized to complete the task of interest, and a protective policy that is dedicated to keep the robot from unsafe events (e.g. falling to the ground). To decide which policy to use during execution, we learn a safety estimator model in the training environment that estimates a continuous safety level of the robot. When used with a set of thresholds, the safety estimator becomes a classifier for switching between the protective policy and the task policy. We evaluate our approach on four simulated robot locomotion problems and show that our method can achieve successful transfer to notably different environments while taking the robot\u2019s safety into consideration.",
        "primary_area": "",
        "author": "Wenhao Yu;C. Karen Liu;Greg Turk;Wenhao Yu;C. Karen Liu;Greg Turk",
        "authorids": "/37085891022;/38240584300;/37334922800;/37085891022;/38240584300;/37334922800",
        "aff": "Georgia Institute of Technology, Atlanta, Georgia, USA; Stanford University, Stanford, California, USA; Georgia Institute of Technology, Atlanta, Georgia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562051/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9938616317977357593&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Stanford University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.gatech.edu;https://www.stanford.edu",
        "aff_unique_abbr": "Georgia Tech;Stanford",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Atlanta;Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561486",
        "title": "Providing Automatic Feedback to Trainees after Automatic Evaluation",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning how to perform precise and controlled gestures is difficult, especially when feedback about made errors is sparse. Therefore, some works try to facilitate learning by providing virtual \"coaches\". Most of them propose to automatically score task quality. But simply assessing quality through a score is not enough. Indeed, it is essential to provide explanations on assigned scores just like experts do when supervising trainees. However when quality assessment is done automatically, such explanations are rare and computing an automatic feedback is complex. In this work, we propose to address this problem by providing an automatic feedback based on neural network explanation. Contrary to previous state of the art methods, which are focused on neural networks explicability for classification tasks, we want to explain network decision on a regression problem (quality score prediction). Thus, we propose to use gradient-based approaches and adapt them to a regression task. Moreover, to address the problem of noise present in sensitivity maps, we propose a solution that leads to more robust gradients. To test our approach, since automatic quality assessment datasets do not contain ground truth about errors position and amplitude, a synthetic dataset representing a simple temporal task has been created, with its associated ground truth. Once the method has been validated on this synthetic dataset, we apply it on real data composed of robotic surgical gestures.",
        "primary_area": "",
        "author": "M\u00e9gane Millan;Catherine Achard;M\u00e9gane Millan;Catherine Achard",
        "authorids": "/37089000017;/37269937300;/37089000017;/37269937300",
        "aff": "CNRS UMR 7222, ISIR, Sorbonne Universite, Paris, France; CNRS UMR 7222, ISIR, Sorbonne Universite, Paris, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561486/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:yYai4T6KVKMJ:scholar.google.com/&scioq=Providing+Automatic+Feedback+to+Trainees+after+Automatic+Evaluation&hl=en&as_sdt=0,33",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Sorbonne Universite",
        "aff_unique_dep": "UMR 7222, ISIR",
        "aff_unique_url": "https://www.sorbonne-universite.fr",
        "aff_unique_abbr": "SU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Paris",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9560856",
        "title": "Proximal Policy Optimization with Relative Pearson Divergence",
        "track": "main",
        "status": "Poster",
        "abstract": "The recent remarkable progress of deep reinforcement learning (DRL) stands on regularization of policy for stable and efficient learning. A popular method, named proximal policy optimization (PPO), has been introduced for this purpose. PPO clips density ratio of the latest and baseline policies with a threshold, while its minimization target is unclear. As another problem of PPO, the symmetric threshold is given numerically while the density ratio itself is in asymmetric domain, thereby causing unbalanced regularization of the policy. This paper therefore proposes a new variant of PPO by considering a regularization problem of relative Pearson (RPE) divergence, so-called PPO-RPE. This regularization yields the clear minimization target, which constrains the latest policy to the baseline one. Through its analysis, the intuitive threshold-based design consistent with the asymmetry of the threshold and the domain of density ratio can be derived. Through four benchmark tasks, PPO-RPE performed as well as or better than the conventional methods in terms of the task performance by the learned policy.",
        "primary_area": "",
        "author": "Taisuke Kobayashi;Taisuke Kobayashi",
        "authorids": "/38542406800;/38542406800",
        "aff": "Division of Information Science, Nara Institute of Science and Technology, Nara, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560856/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8139849236973331288&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Nara Institute of Science and Technology",
        "aff_unique_dep": "Division of Information Science",
        "aff_unique_url": "https://www.nist.go.jp",
        "aff_unique_abbr": "NIST",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Nara",
        "aff_country_unique_index": "0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561610",
        "title": "PuzzleBots: Physical Coupling of Robot Swarms",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot swarms have been shown to improve the ability of individual robots by inter-robot collaboration. In this paper, we present the PuzzleBots - a low-cost robotic swarm system where robots can physically couple with each other to form functional structures with minimum energy consumption while maintaining individual mobility to navigate within the environment. Each robot has knobs and holes along the sides of its body so that the robots can couple by inserting the knobs into the holes. We present the characterization of knob design and the result of gap-crossing behavior with up to nine robots. We show with hardware experiments that the robots are able to couple with each other to cross gaps and decouple to perform individual tasks. We anticipate the PuzzleBots will be useful in unstructured environments as individuals and coupled systems in real-world applications.",
        "primary_area": "",
        "author": "Sha Yi;Zeynep Temel;Katia Sycara;Sha Yi;Zeynep Temel;Katia Sycara",
        "authorids": "/37088506867;/37088689031;/37268476900;/37088506867;/37088689031;/37268476900",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561610/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2881944569014889956&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561084",
        "title": "PyTouch: A Machine Learning Library for Touch Processing",
        "track": "main",
        "status": "Poster",
        "abstract": "With the increased availability of rich tactile sensors, there is an an equally proportional need for open-source and integrated software capable of efficiently and effectively processing raw touch measurements into high-level signals that can be used for control and decision-making. In this paper, we present PyTouch \u2013 the first machine learning library dedicated to the processing of touch sensing signals. PyTouch, is designed to be modular, easy-to-use and provides state-of-the-art touch processing capabilities as a service with the goal of unifying the tactile sensing community by providing a library for building scalable, proven, and performance-validated modules over which applications and research can be built upon. We evaluate PyTouch on real-world data from several tactile sensors on touch processing tasks such as touch detection, slip and object pose estimations. PyTouch is open-sourced at https://github.com/facebookresearch/pytouch.",
        "primary_area": "",
        "author": "Mike Lambeta;Huazhe Xu;Jingwei Xu;Po-Wei Chou;Shaoxiong Wang;Trevor Darrell;Roberto Calandra;Mike Lambeta;Huazhe Xu;Jingwei Xu;Po-Wei Chou;Shaoxiong Wang;Trevor Darrell;Roberto Calandra",
        "authorids": "/37088371431;/37086242886;/37089265693;/37088369982;/37086252778;/37282910600;/38540170300;/37088371431;/37086242886;/37089265693;/37088369982;/37086252778;/37282910600;/38540170300",
        "aff": "Facebook AI Research, Menlo Park, USA; University of California, Berkeley, USA; Shanghai Jiao Tong University, China; Facebook AI Research, Menlo Park, USA; Massachusetts Institute of Technology, USA; University of California, Berkeley, USA; Facebook AI Research, Menlo Park, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561084/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8672305595359479311&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;2;0;3;1;0",
        "aff_unique_norm": "Meta;University of California, Berkeley;Shanghai Jiao Tong University;Massachusetts Institute of Technology",
        "aff_unique_dep": "Facebook AI Research;;;",
        "aff_unique_url": "https://research.facebook.com;https://www.berkeley.edu;https://www.sjtu.edu.cn;https://web.mit.edu",
        "aff_unique_abbr": "FAIR;UC Berkeley;SJTU;MIT",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Menlo Park;Berkeley;",
        "aff_country_unique_index": "0;0;1;0;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9561747",
        "title": "Pylot: A Modular Platform for Exploring Latency-Accuracy Tradeoffs in Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "We present Pylot, a platform for autonomous vehicle (AV) research and development, built with the goal to allow researchers to study the effects of the latency and accuracy of their models and algorithms on the end-to-end driving behavior of an AV. This is achieved through a modular structure enabled by our high-performance dataflow system that represents AV software pipeline components (object detectors, motion planners, etc.) as a dataflow graph of operators which communicate on data streams using timestamped messages. Pylot readily interfaces with popular AV simulators like CARLA, and is easily deployable to real-world vehicles with minimal code changes.To reduce the burden of developing an entire pipeline for evaluating a single component, Pylot provides several state-of-the-art reference implementations for the various components of an AV pipeline. Using these reference implementations, a Pylot-based AV pipeline is able to drive a real vehicle, and attains a high score on the CARLA Autonomous Driving Challenge. We also present several case studies enabled by Pylot, including evidence of a need for context-dependent components, and per-component time allocation. Pylot is open source, with the code available at https://github.com/erdos-project/pylot.",
        "primary_area": "",
        "author": "Ionel Gog;Sukrit Kalra;Peter Schafhalter;Matthew A. Wright;Joseph E. Gonzalez;Ion Stoica;Ionel Gog;Sukrit Kalra;Peter Schafhalter;Matthew A. Wright;Joseph E. Gonzalez;Ion Stoica",
        "authorids": "/37089001450;/37089000748;/37088996832;/37085897886;/37086566024;/37284373600;/37089001450;/37089000748;/37088996832;/37085897886;/37086566024;/37284373600",
        "aff": "UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561747/",
        "gs_citation": 89,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13454392129830208298&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562108",
        "title": "PyraPose: Feature Pyramids for Fast and Accurate Object Pose Estimation under Domain Shift",
        "track": "main",
        "status": "Poster",
        "abstract": "Object pose estimation enables robots to understand and interact with their environments. Training with synthetic data is necessary in order to adapt to novel situations. Unfortunately, pose estimation under domain shift, i.e., training on synthetic data and testing in the real world, is challenging. Deep learning-based approaches currently perform best when using encoder-decoder networks but typically do not generalize to new scenarios with different scene characteristics. We argue that patch-based approaches, instead of encoder-decoder networks, are more suited for synthetic-to-real transfer because local to global object information is better represented. To that end, we present a novel approach based on a specialized feature pyramid network to compute multi-scale features for creating pose hypotheses on different feature map resolutions in parallel. Our single-shot pose estimation approach is evaluated on multiple standard datasets and outperforms the state of the art by up to \u223c35 %. We also perform grasping experiments in the real world to demonstrate the advantage of using synthetic data to generalize to novel environments.",
        "primary_area": "",
        "author": "Stefan Thalhammer;Markus Leitner;Timothy Patten;Markus Vincze;Stefan Thalhammer;Markus Leitner;Timothy Patten;Markus Vincze",
        "authorids": "/37089140542;/37089000063;/37085763735;/37269163100;/37089140542;/37089000063;/37085763735;/37269163100",
        "aff": "Faculty of Electrical Engineering and Information Technology, TU Wien, Vienna, Austria; Faculty of Electrical Engineering and Information Technology, TU Wien, Vienna, Austria; Faculty of Electrical Engineering and Information Technology, TU Wien, Vienna, Austria; Faculty of Electrical Engineering and Information Technology, TU Wien, Vienna, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562108/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17990305301623855589&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "TU Wien",
        "aff_unique_dep": "Faculty of Electrical Engineering and Information Technology",
        "aff_unique_url": "https://www.tuwien.ac.at",
        "aff_unique_abbr": "TU Wien",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Vienna",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9561048",
        "title": "Quantification of Joint Redundancy considering Dynamic Feasibility using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "The robotic joint redundancy for executing a task and the optimal usage of robotic joints given the redundant degrees of freedom are crucial for the performance of a robot. It is therefore of interest to quantify the joint redundancy to better understand the robotic dexterity considering the dynamic feasibility. To this end, model-based approaches have been among the most commonly used methods to quantify the joint redundancy of simple robots analytically. However, this classical approach fails when applied to non-conventional complex robots. In this study, we propose a new method based on a deep reinforcement learning-derived metric, the synergy exploration area (SEA) metric, for the quantification of redundancy with a given dynamic environment. We conducted various experiments with different robotic structures for different tasks, ranging from simple robotic arm manipulation to more complex robotic locomotion. The experimental results show that the SEA metric can effectively quantify the relative joint redundancy over different robotic structures with varying degrees of freedom under unknown dynamic situations.",
        "primary_area": "",
        "author": "Jiazheng Chai;Mitsuhiro Hayashibe;Jiazheng Chai;Mitsuhiro Hayashibe",
        "authorids": "/37087412309;/37586645600;/37087412309;/37586645600",
        "aff": "Department of Robotics, Neuro-Robotics Lab, Graduate School of Engineering, Tohoku University, Sendai, Japan; Department of Robotics, Neuro-Robotics Lab, Graduate School of Engineering, Tohoku University, Sendai, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561048/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:0rEXcU3cYU8J:scholar.google.com/&scioq=Quantification+of+Joint+Redundancy+considering+Dynamic+Feasibility+using+Deep+Reinforcement+Learning&hl=en&as_sdt=0,33",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tohoku University",
        "aff_unique_dep": "Department of Robotics",
        "aff_unique_url": "https://www.tohoku.ac.jp",
        "aff_unique_abbr": "Tohoku U",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Sendai",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9560814",
        "title": "Quasi-LPV Unknown Input Observer with Nonlinear Outputs: Application to Motorcycles",
        "track": "main",
        "status": "Poster",
        "abstract": "The purpose of the present work is the reconstruction of motorcycle lateral dynamics. The main idea is to estimate pertinent states and unknown inputs (rider action) with respect to nonlinear outputs due to motion transformation frames (inertial sensors are away from the local frame). To overcome this issue, we propose a new Unknown Input Observers with variable output matrix. In this paper, we take into account the ground truth measurements provided in the body-fixed frame, parametric uncertainties as well as sensors noise. This step leads to a nonlinear parameter-dependent output equation with unmeasured premise variables in the observer design. The observer synthesis is specified in term of convergence and stability study by considering a quadratic Lyapunov function associated with the Input To State Stability (ISS) property. Sufficient conditions are agreed in terms of Linear Matrix Inequalities (LMIs). Finally, the performances, usefulness and robustness of the proposed approach are assessed throughout an electric Scooter under urban riding scenario.",
        "primary_area": "",
        "author": "L. Nehaoua;M. Fouka;H. Arioui;L. Nehaoua;M. Fouka;H. Arioui",
        "authorids": "/37418690700;/37085994279;/37329188600;/37418690700;/37085994279;/37329188600",
        "aff": "L. Nehaoua; M. Fouka; H. Arioui",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560814/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:H1J1izZsQScJ:scholar.google.com/&scioq=Quasi-LPV+Unknown+Input+Observer+with+Nonlinear+Outputs:+Application+to+Motorcycles&hl=en&as_sdt=0,5",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9562089",
        "title": "RADIATE: A Radar Dataset for Automotive Perception in Bad Weather",
        "track": "main",
        "status": "Poster",
        "abstract": "Datasets for autonomous cars are essential for the development and benchmarking of perception systems. However, most existing datasets are captured with camera and LiDAR sensors in good weather conditions. In this paper, we present the RAdar Dataset In Adverse weaThEr (RADIATE), aiming to facilitate research on object detection, tracking and scene understanding using radar sensing for safe autonomous driving. RADIATE includes 3 hours of annotated radar images with more than 200K labelled road actors in total, on average about 4.6 instances per radar image. It covers 8 different categories of actors in a variety of weather conditions (e.g., sun, night, rain, fog and snow) and driving scenarios (e.g., parked, urban, motorway and suburban), representing different levels of challenge. To the best of our knowledge, this is the first public radar dataset which provides high-resolution radar images on public roads with a large amount of road actors labelled. The data collected in adverse weathers, e.g., fog and snowfall, is unique. Some baseline results of radar based object detection and recognition are given to show that the use of radar data is promising for automotive applications in bad weather, where vision and LiDAR fail. RADIATE also has stereo images, 32-channel LiDAR and GPS data, directed at other applications such as sensor fusion, localisation and mapping. The public dataset can be accessed at http://pro.hw.ac.uk/radiate/.",
        "primary_area": "",
        "author": "Marcel Sheeny;Emanuele De Pellegrin;Saptarshi Mukherjee;Alireza Ahrabian;Sen Wang;Andrew Wallace;Marcel Sheeny;Emanuele De Pellegrin;Saptarshi Mukherjee;Alireza Ahrabian;Sen Wang;Andrew Wallace",
        "authorids": "/37076162900;/37088996904;/37088504663;/38262251000;/37086278300;/37276997600;/37076162900;/37088996904;/37088504663;/38262251000;/37086278300;/37276997600",
        "aff": "Institute of Sensors, Signals and Systems, Heriot-Watt University; Institute of Sensors, Signals and Systems, Heriot-Watt University; Institute of Sensors, Signals and Systems, Heriot-Watt University; Institute of Sensors, Signals and Systems, Heriot-Watt University; Institute of Sensors, Signals and Systems, Heriot-Watt University; Institute of Sensors, Signals and Systems, Heriot-Watt University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562089/",
        "gs_citation": 302,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11607915239346660729&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Heriot-Watt University",
        "aff_unique_dep": "Institute of Sensors, Signals and Systems",
        "aff_unique_url": "https://www.hw.ac.uk",
        "aff_unique_abbr": "HWU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561057",
        "title": "RASCAL: Robotic Arm for Sherds and Ceramics Automated Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "Ceramics are one of the major sources of information about the past for archaeologists, with a typical archaeological dig unearthing 1000\u2019s of pottery fragments (sherds) each day. However, archaeologists often are not allowed to remove these sherds from their home countries. Therefore, logging data (e.g., mass, color, decoration) in the field is the only way to record valuable information about these sherds. Currently, this laborious process is done manually, using up much of the valuable time at a dig site. This project aims to automate the data collection process, freeing up archaeologists to spend their limited time in the field on other tasks, and to create a large-scale digital database of sherd information, allowing archaeologists to take advantage of new computational tools to make discoveries. The contribution of this paper is an automated system, consisting of several reconfigurable data collection stations and a robotic arm to transport objects between stations, that can rapidly generate a large database of archaeological artifacts. We validate our system in simulation, using high-resolution models of sherds. In other contexts, our system may help to expand the use of automation in materials handling, parts sorting, and more.",
        "primary_area": "",
        "author": "Deborah Wang;Brandon Lutz;Peter J. Cobb;Philip Dames;Deborah Wang;Brandon Lutz;Peter J. Cobb;Philip Dames",
        "authorids": "/37088997009;/37088997460;/37088996863;/38547257300;/37088997009;/37088997460;/37088996863;/38547257300",
        "aff": "Department of Mechanical Engineering, Temple University, Philadelphia, PA, USA; Department of Mechanical Engineering, Temple University, Philadelphia, PA, USA; Faculties of Education and Arts, University of Hong Kong, Hong Kong; Department of Mechanical Engineering, Temple University, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561057/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14602607967421603335&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Temple University;University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical Engineering;Faculties of Education and Arts",
        "aff_unique_url": "https://www.temple.edu;https://www.hku.hk",
        "aff_unique_abbr": "Temple;HKU",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Philadelphia;Hong Kong SAR",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9561920",
        "title": "REGNet: REgion-based Grasp Network for End-to-end Grasp Detection in Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Reliable robotic grasping in unstructured environments is a crucial but challenging task. The main problem is to generate the optimal grasp of novel objects from partial noisy observations. This paper presents an end-to-end grasp detection network taking one single-view point cloud as input to tackle the problem. Our network includes three stages: Score Network (SN), Grasp Region Network (GRN), and Refine Network (RN). Specifically, SN regresses point grasp confidence and selects positive points with high confidence. Then GRN conducts grasp proposal prediction on the selected positive points. RN generates more accurate grasps by refining proposals predicted by GRN. To further improve the performance, we propose a grasp anchor mechanism, in which grasp anchors with assigned gripper orientations are introduced to generate grasp proposals. Experiments demonstrate that REGNet achieves a success rate of 79.34% and a completion rate of 96% in real-world clutter, which significantly outperforms several state-of-the-art point-cloud based methods, including GPD, PointNetGPD, and S4G. The code is available at https://github.com/zhaobinglei/REGNet for 3D Grasping.",
        "primary_area": "",
        "author": "Binglei Zhao;Hanbo Zhang;Xuguang Lan;Haoyu Wang;Zhiqiang Tian;Nanning Zheng;Binglei Zhao;Hanbo Zhang;Xuguang Lan;Haoyu Wang;Zhiqiang Tian;Nanning Zheng",
        "authorids": "/37088997791;/37086441588;/37270865300;/37089001422;/37597665600;/37271536700;/37088997791;/37086441588;/37270865300;/37089001422;/37597665600;/37271536700",
        "aff": "Binglei Zhao; Hanbo Zhang; Xuguang Lan; Haoyu Wang; Zhiqiang Tian; Nanning Zheng",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561920/",
        "gs_citation": 104,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3476329694187422&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "1",
        "aff_unique_norm": ";Nanning University",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.nnzu.edu.cn",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";China"
    },
    {
        "id": "9561251",
        "title": "RELLIS-3D Dataset: Data, Benchmarks and Analysis",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic scene understanding is crucial for robust and safe autonomous navigation, particularly so in off-road environments. Recent deep learning advances for 3D semantic segmentation rely heavily on large sets of training data, however existing autonomy datasets either represent urban environments or lack multimodal off-road data. We fill this gap with RELLIS-3D, a multimodal dataset collected in an off-road environment, which contains annotations for 13,556 LiDAR scans and 6,235 images. The data was collected on the Rellis Campus of Texas A&M University, and presents challenges to existing algorithms related to class imbalance and environmental topography. Additionally, we evaluate the current state of the art deep learning semantic segmentation models on this dataset. Experimental results show that RELLIS-3D presents challenges for algorithms designed for segmentation in urban environments. This novel dataset provides the resources needed by researchers to continue to develop more advanced algorithms and investigate new research directions to enhance autonomous navigation in off-road environments. RELLIS-3D is available at https://github.com/unmannedlab/RELLIS-3D",
        "primary_area": "",
        "author": "Peng Jiang;Philip Osteen;Maggie Wigness;Srikanth Saripalli;Peng Jiang;Philip Osteen;Maggie Wigness;Srikanth Saripalli",
        "authorids": "/37088982909;/38251856000;/37085661502;/37278939200;/37088982909;/38251856000;/37085661502;/37278939200",
        "aff": "J. Mike Walker \u201966 Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA; DEVCOM Army Research Laboratory (ARL), Adelphi, MD, USA; DEVCOM Army Research Laboratory (ARL), Adelphi, MD, USA; J. Mike Walker \u201966 Department of Mechanical Engineering, Texas A&M University, College Station, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561251/",
        "gs_citation": 297,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12757793204039699449&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Texas A&M University;DEVCOM Army Research Laboratory",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.tamu.edu;",
        "aff_unique_abbr": "TAMU;ARL",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "College Station;Adelphi",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561409",
        "title": "RGB Matters: Learning 7-DoF Grasp Poses on Monocular RGBD Images",
        "track": "main",
        "status": "Poster",
        "abstract": "General object grasping is an important yet unsolved problem in the field of robotics. Most of the current methods either generate grasp poses with few DoF that fail to cover most of the success grasps, or only take the unstable depth image or point cloud as input which may lead to poor results in some cases. In this paper, we propose RGBD-Grasp, a pipeline that solves this problem by decoupling 7-DoF grasp detection into two sub-tasks where RGB and depth information are processed separately. In the first stage, an encoder-decoder like convolutional neural network Angle-View Net(AVN) is proposed to predict the SO(3) orientation of the gripper at every location of the image. Consequently, a Fast Analytic Searching(FAS) module calculates the opening width and the distance of the gripper to the grasp point. By decoupling the grasp detection problem and introducing the stable RGB modality, our pipeline alleviates the requirement for the high-quality depth image and is robust to depth sensor noise. We achieve state-of-the-art results on GraspNet-1Billion dataset compared with several baselines. Real robot experiments on a UR5 robot with an Intel Realsense camera and a Robotiq two-finger gripper show high success rates for both single object scenes and cluttered scenes. Our code and trained model are available at graspnet.net.",
        "primary_area": "",
        "author": "Minghao Gou;Hao-Shu Fang;Zhanda Zhu;Sheng Xu;Chenxi Wang;Cewu Lu;Minghao Gou;Hao-Shu Fang;Zhanda Zhu;Sheng Xu;Chenxi Wang;Cewu Lu",
        "authorids": "/37088221407;/37089320449;/37088997806;/37088999422;/37088457979;/37085483529;/37088221407;/37089320449;/37088997806;/37088999422;/37088457979;/37085483529",
        "aff": "Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Shanghai Jiao Tong University; Qing Yuan Research Institute and MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561409/",
        "gs_citation": 132,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15700004550966708665&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561560",
        "title": "RGB-D SLAM with Structural Regularities",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes a RGB-D SLAM system specifically designed for structured environments and aimed at improved tracking and mapping accuracy by relying on geometric features that are extracted from the surrounding. Structured environments offer, in addition to points, also an abundance of geometrical features such as lines and planes, which we exploit to design both the tracking and mapping components of our SLAM system. For the tracking part, we explore geometric relationships between these features based on the assumption of a Manhattan World (MW). We propose a decoupling-refinement method based on points, lines, and planes, as well as the use of Manhattan relationships in an additional pose refinement module. For the mapping part, different levels of maps from sparse to dense are reconstructed at a low computational cost. We propose an instance-wise meshing strategy to build a dense map by meshing plane instances independently. The overall performance in terms of pose estimation and reconstruction is evaluated on public benchmarks and shows improved performance compared to state-of-the-art methods. The code is released at https://github.com/yanyan-li/PlanarSLAM.",
        "primary_area": "",
        "author": "Yanyan Li;Raza Yunus;Nikolas Brasch;Nassir Navab;Federico Tombari;Yanyan Li;Raza Yunus;Nikolas Brasch;Nassir Navab;Federico Tombari",
        "authorids": "/37088471090;/37088996793;/37086573901;/37282965500;/37593332100;/37088471090;/37088996793;/37086573901;/37282965500;/37593332100",
        "aff": "Technical University of Munich, Germany; Technical University of Munich, Germany; Technical University of Munich, Germany; Johns Hopkins University, USA; Google Inc",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561560/",
        "gs_citation": 94,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7814053993647356570&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;2",
        "aff_unique_norm": "Technical University of Munich;Johns Hopkins University;Google",
        "aff_unique_dep": ";;Google",
        "aff_unique_url": "https://www.tum.de;https://www.jhu.edu;https://www.google.com",
        "aff_unique_abbr": "TUM;JHU;Google",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;0;0;1;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9561425",
        "title": "RIL: Riemannian Incremental Learning of the Inertial Properties of the Robot Body Schema",
        "track": "main",
        "status": "Poster",
        "abstract": "We transform classical robot inertial parameter identification into an online learning problem by integrating state-of-the-art gradient descent techniques and first-order principles from mechanics and differential geometry. Through this, incremental learning of fully physically feasible inertial properties without requiring any prior information is made possible. This is achieved using a version of Riemannian gradient descent equipped with experience replay that guarantees feasible parameter updates at all times during learning. Analysis of the method's performance are done on a virtual manipulator focusing on the influence that different measurement setups have on the estimation as well as on parameter feasibility and re-learning. Finally, we present experimental results on a real 7 DoF manipulator and evaluate the quality of the generated inverse dynamics torques and the corresponding model error.",
        "primary_area": "",
        "author": "Fernando D\u00edaz Ledezma;Sami Haddadin;Fernando D\u00edaz Ledezma;Sami Haddadin",
        "authorids": "/37088998417;/37542865300;/37088998417;/37542865300",
        "aff": "Chair of Robotics Science and Systems Intelligence, Munich School of Robotics and Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany; Potential Conflict of Interest as Shareholder of Franka Emika GmbH",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561425/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7182761648872622893&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen;Franka Emika GmbH",
        "aff_unique_dep": "Chair of Robotics Science and Systems Intelligence;",
        "aff_unique_url": "https://www.tum.de;https://www.franka.de",
        "aff_unique_abbr": "TUM;Franka Emika",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "M\u00fcnchen;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9562007",
        "title": "ROBIN: a Graph-Theoretic Approach to Reject Outliers in Robust Estimation using Invariants",
        "track": "main",
        "status": "Poster",
        "abstract": "Many estimation problems in robotics, computer vision, and learning require estimating unknown quantities in the face of outliers. Outliers are typically the result of incorrect data association or feature matching, and it is not uncommon to have problems where more than 90% of the measurements used for estimation are outliers. While current approaches for robust estimation (e.g., RANSAC or graduated non-convexity) are able to deal with moderate amounts of outliers, they fail to produce accurate estimates in the presence of many outliers. This paper develops an approach to prune outliers. First, we develop a theory of invariance that allows us to quickly check if a subset of measurements are mutually compatible without explicitly solving the corresponding estimation problem. Second, we develop a graph-theoretic framework, where measurements are modeled as vertices and mutual compatibility is captured by edges in a graph. We generalize existing results showing that the inliers form a clique in this compatibility graph and typically belong to the maximum clique. We also show that in practice the maximum k-core of the compatibility graph provides an approximation of the maximum clique, while being much faster to compute in large problems. The combination of these two contributions leads to ROBIN, our approach to Reject Outliers Based on INvariants, which allows us to quickly prune outliers in generic estimation problems. We demonstrate ROBIN in four geometric perception problems and show it boosts robustness of existing solvers (making them robust to more than 95% outliers), while running in milliseconds in large problems.",
        "primary_area": "",
        "author": "Jingnan Shi;Heng Yang;Luca Carlone;Jingnan Shi;Heng Yang;Luca Carlone",
        "authorids": "/37088823761;/37087413017;/37545784100;/37088823761;/37087413017;/37545784100",
        "aff": "Laboratory for Information & Decision Systems (LIDS), Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory for Information & Decision Systems (LIDS), Massachusetts Institute of Technology, Cambridge, MA, USA; Laboratory for Information & Decision Systems (LIDS), Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562007/",
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1421408944262950831&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Laboratory for Information & Decision Systems (LIDS)",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560840",
        "title": "ROIAL: Region of Interest Active Learning for Characterizing Exoskeleton Gait Preference Landscapes",
        "track": "main",
        "status": "Poster",
        "abstract": "Characterizing what types of exoskeleton gaits are comfortable for users, and understanding the science of walking more generally, require recovering a user\u2019s utility landscape. Learning these landscapes is challenging, as walking trajectories are defined by numerous gait parameters, data collection from human trials is expensive, and user safety and comfort must be ensured. This work proposes the Region of Interest Active Learning (ROIAL) framework, which actively learns each user\u2019s underlying utility function over a region of interest that ensures safety and comfort. ROIAL learns from ordinal and preference feedback, which are more reliable feedback mechanisms than absolute numerical scores. The algorithm\u2019s performance is evaluated both in simulation and experimentally for three non-disabled subjects walking inside of a lower-body exoskeleton. ROIAL learns Bayesian posteriors that predict each exoskeleton user\u2019s utility landscape across four exoskeleton gait parameters. The algorithm discovers both commonalities and discrepancies across users\u2019 gait preferences and identifies the gait parameters that most influenced user feedback. These results demonstrate the feasibility of recovering gait utility landscapes from limited human trials.",
        "primary_area": "",
        "author": "Kejun Li;Maegan Tucker;Erdem B\u0131y\u0131k;Ellen Novoseller;Joel W. Burdick;Yanan Sui;Dorsa Sadigh;Yisong Yue;Aaron D. Ames;Kejun Li;Maegan Tucker;Erdem B\u0131y\u0131k;Ellen Novoseller;Joel W. Burdick;Yanan Sui;Dorsa Sadigh;Yisong Yue;Aaron D. Ames",
        "authorids": "/37088996762;/37087122493;/37086082220;/37088507027;/37265975700;/37086302367;/38234464200;/37085390468;/37300877900;/37088996762;/37087122493;/37086082220;/37088507027;/37265975700;/37086302367;/38234464200;/37085390468;/37300877900",
        "aff": "California Inst. of Technology; California Inst. of Technology; Stanford University; California Inst. of Technology; California Inst. of Technology; Tsinghua University; Stanford University; California Inst. of Technology; California Inst. of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560840/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13018277536176797325&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;0;0;2;1;0;0",
        "aff_unique_norm": "California Institute of Technology;Stanford University;Tsinghua University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.caltech.edu;https://www.stanford.edu;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Caltech;Stanford;THU",
        "aff_campus_unique_index": "0;0;1;0;0;1;0;0",
        "aff_campus_unique": "Pasadena;Stanford;",
        "aff_country_unique_index": "0;0;0;0;0;1;0;0;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9560858",
        "title": "RadarLoc: Learning to Relocalize in FMCW Radar",
        "track": "main",
        "status": "Poster",
        "abstract": "Relocalization is a fundamental task in the field of robotics and computer vision. There is considerable work in the field of deep camera relocalization, which directly estimates poses from raw images. However, learning-based methods have not yet been applied to the radar sensory data. In this work, we investigate how to exploit deep learning to predict global poses from Emerging Frequency-Modulated Continuous Wave (FMCW) radar scans. Specifically, we propose a novel end-to-end neural network with self-attention, termed RadarLoc, which is able to estimate 6-DoF global poses directly. We also propose to improve the localization performance by utilizing geometric constraints between radar scans. We validate our approach on the recently released challenging outdoor dataset Oxford Radar RobotCar. Comprehensive experiments demonstrate that the proposed method outperforms radar-based localization and deep camera relocalization methods by a significant margin.",
        "primary_area": "",
        "author": "Wei Wang;Pedro P. B. de Gusm\u00e3o;Bo Yang;Andrew Markham;Niki Trigoni;Wei Wang;Pedro P. B. de Gusm\u00e3o;Bo Yang;Andrew Markham;Niki Trigoni",
        "authorids": "/37086943823;/37891084600;/37086306785;/37410667900;/37297514400;/37086943823;/37891084600;/37086306785;/37410667900;/37297514400",
        "aff": "Department of Computer Science, University of Oxford, United Kingdom; Department of Computer Science, University of Oxford, United Kingdom; Department of Computing, The Hong Kong Polytechnic University, HKSAR; Department of Computer Science, University of Oxford, United Kingdom; Department of Computer Science, University of Oxford, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560858/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4155587360967364911&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;0",
        "aff_unique_norm": "University of Oxford;Hong Kong Polytechnic University",
        "aff_unique_dep": "Department of Computer Science;Department of Computing",
        "aff_unique_url": "https://www.ox.ac.uk;https://www.polyu.edu.hk",
        "aff_unique_abbr": "Oxford;PolyU",
        "aff_campus_unique_index": "0;0;1;0;0",
        "aff_campus_unique": "Oxford;Hong Kong SAR",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "United Kingdom;China"
    },
    {
        "id": "9561335",
        "title": "Range Image-based LiDAR Localization for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust and accurate, map-based localization is crucial for autonomous mobile systems. In this paper, we exploit range images generated from 3D LiDAR scans to address the problem of localizing mobile robots or autonomous cars in a map of a large-scale outdoor environment represented by a triangular mesh. We use the Poisson surface reconstruction to generate the mesh-based map representation. Based on the range images generated from the current LiDAR scan and the synthetic rendered views from the mesh-based map, we propose a new observation model and integrate it into a Monte Carlo localization framework, which achieves better localization performance and generalizes well to different environments. We test the proposed localization approach on multiple datasets collected in different environments with different LiDAR scanners. The experimental results show that our method can reliably and accurately localize a mobile system in different environments and operate online at the LiDAR sensor frame rate to track the vehicle pose.",
        "primary_area": "",
        "author": "Xieyuanli Chen;Ignacio Vizzo;Thomas L\u00e4be;Jens Behley;Cyrill Stachniss;Xieyuanli Chen;Ignacio Vizzo;Thomas L\u00e4be;Jens Behley;Cyrill Stachniss",
        "authorids": "/37086247697;/37087323326;/37086411637;/37593243900;/37329668600;/37086247697;/37087323326;/37086411637;/37593243900;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561335/",
        "gs_citation": 162,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8956794444208556550&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561706",
        "title": "Range Limited Coverage Control using Air-Ground Multi-Robot Teams",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we investigate how heterogeneous multi-robot systems with different sensing capabilities can observe a domain with an a priori unknown density function. Common coverage control techniques are targeted towards homogeneous teams of robots and do not consider what happens when the sensing capabilities of the robots are vastly different. This work proposes an extension to Lloyd\u2019s algorithm that fuses coverage information from heterogeneous robots with differing sensing capabilities to effectively observe a domain. Namely, we study a bimodal team of robots consisting of aerial and ground agents. In our problem formulation we use aerial robots with coarse domain sensors to approximate the number of ground robots needed within their sensing region to effectively cover it. This information is relayed to ground robots, who perform an extension to Lloyd\u2019s algorithm that balances a locally focused coverage controller with a globally focused distribution controller. The stability of the Lloyd\u2019s algorithm extension is proven and its performance is evaluated through simulation and experiments using the Robotarium, a remotely-accessible, multi-robot testbed.",
        "primary_area": "",
        "author": "Max Rudolph;Sean Wilson;Magnus Egerstedt;Max Rudolph;Sean Wilson;Magnus Egerstedt",
        "authorids": "/37088999897;/37087241901;/37269707500;/37088999897;/37087241901;/37269707500",
        "aff": "Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561706/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17675292048376092070&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561277",
        "title": "Rapid Pose Label Generation through Sparse Representation of Unknown Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Convolutional Neural Networks (CNNs) have been successfully deployed on robots for 6-DoF object pose estimation through visual perception. However, obtaining labeled data on a scale required for the supervised training of CNNs is a difficult task - exacerbated if the object is novel and a 3D model is unavailable. To this end, this work presents an approach for rapidly generating real-world, pose-annotated RGB-D data for unknown objects. Our method not only circumvents the need for a prior 3D object model (textured or otherwise) but also bypasses complicated setups of fiducial markers, turntables, and sensors. With the help of a human user, we first source minimalistic labelings of an ordered set of arbitrarily chosen keypoints over a set of RGB-D videos. Then, by solving an optimization problem, we combine these labels under a world frame to recover a sparse, keypoint-based representation of the object. The sparse representation leads to the development of a dense model and the pose labels for each image frame in the set of scenes. We show that the sparse model can also be efficiently used for scaling to a large number of new scenes. We demonstrate the practicality of the generated labeled dataset by training a CNN based 6-DoF object pose estimator.",
        "primary_area": "",
        "author": "Rohan P. Singh;Mehdi Benallegue;Yusuke Yoshiyasu;Fumio Kanehiro;Rohan P. Singh;Mehdi Benallegue;Yusuke Yoshiyasu;Fumio Kanehiro",
        "authorids": "/37088235406;/37571999700;/37392153300;/37283667500;/37088235406;/37571999700;/37392153300;/37283667500",
        "aff": "University of Tsukuba, Ibaraki, Japan; CNRS-AIST JRL (Joint Robotics Laboratory) IRL, National Institute of Advanced Industrial Science and Technology (AIST), Japan; CNRS-AIST JRL (Joint Robotics Laboratory) IRL, National Institute of Advanced Industrial Science and Technology (AIST), Japan; University of Tsukuba, Ibaraki, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561277/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11500124105068847542&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "University of Tsukuba;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": ";Joint Robotics Laboratory",
        "aff_unique_url": "https://www.tsukuba.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "UT;AIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561588",
        "title": "Rapid Solution of Cosserat Rod Equations via a Nonlinear Partial Observer",
        "track": "main",
        "status": "Poster",
        "abstract": "The Cosserat rod equations are used to model continuum and soft robots. Solving these equations are computationally expensive, particularly due to mixed boundary values and kinematic constraints. In this paper, we present a novel nonlinear observer that can rapidly estimate the solution of the Cosserat rod equations. We present details of the observer design and analyse its convergence and stability. Furthermore, we compare the accuracy and performance of the observer with common solvers used in the literature. Our results show that the proposed observer can significantly improve the computational efficiency of continuum robots\u2019 models and estimates the solution of the Cosserat rod equations 7 times faster than common solvers.",
        "primary_area": "",
        "author": "Balint Thamo;Kev Dhaliwal;Mohsen Khadem;Balint Thamo;Kev Dhaliwal;Mohsen Khadem",
        "authorids": "/37089001416;/37086204046;/37085447737;/37089001416;/37086204046;/37085447737",
        "aff": "Translational Healthcare Technologies Group in the Centre for Inflammation Research, Queen\u2019s Medical Research Institute, Edinburgh, UK; Translational Healthcare Technologies Group in the Centre for Inflammation Research, Queen\u2019s Medical Research Institute, Edinburgh, UK; Translational Healthcare Technologies Group in the Centre for Inflammation Research, Queen\u2019s Medical Research Institute, Edinburgh, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561588/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6948146716849074314&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Queen\u2019s Medical Research Institute",
        "aff_unique_dep": "Centre for Inflammation Research",
        "aff_unique_url": "https://www.qmri.scot",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9560958",
        "title": "Rapidly adapting robot swarms with Swarm Map-based Bayesian Optimisation",
        "track": "main",
        "status": "Poster",
        "abstract": "Rapid performance recovery from unforeseen environmental perturbations remains a grand challenge in swarm robotics. To solve this challenge, we investigate a behaviour adaptation approach, where one searches an archive of controllers for potential recovery solutions. We propose two algorithms: (i) Swarm Map-based Optimisation (SMBO), which selects and evaluates one controller at a time, for a homogeneous swarm, in a centralised fashion; and (ii) Swarm Map-based Optimisation Decentralised (SMBO-Dec), which performs an asynchronous batch-based Bayesian optimisation to simultaneously explore different controllers for groups of robots in the swarm. A simulation study investigates adaptation of a Thymio robot swarm in a collective foraging task. First, we investigate different groups of sensory-motor disturbances, including fault to proximity sensors, ground sensors, or actuators of individual robots, with 100 unique combinations for each type. Second, we investigate changes to the surrounding environment of the swarm, where the number of available resources drops or where one robot disrupts the rest of the swarm; for each such change, we include 30 unique conditions. The viability of SMBO and SMBO-Dec is demonstrated, comparing favourably to variants of random search and gradient descent, and various ablations, and improving performance up to 80% compared to the performance at the time of fault injection within less than 30 evaluations.",
        "primary_area": "",
        "author": "David M. Bossens;Danesh Tarapore;David M. Bossens;Danesh Tarapore",
        "authorids": "/37088822733;/37086275308;/37088822733;/37086275308",
        "aff": "School of Electronics and Computer Science, University of Southampton, Southampton, U.K.; School of Electronics and Computer Science, University of Southampton, Southampton, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560958/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10820169823176202659&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Southampton",
        "aff_unique_dep": "School of Electronics and Computer Science",
        "aff_unique_url": "https://www.southampton.ac.uk",
        "aff_unique_abbr": "Southampton",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Southampton",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561813",
        "title": "Rate Mode Bilateral Teleoperation Based on Passivity Tanks and Variable Admittance Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Bilateral teleoperation under rate mode is known to be a difficult problem in terms of stability, especially when the slave manipulator interacts with a time-varying environment. This paper presents an energy based variable admittance control approach, whose principle combines the monitoring and the regulation of the energy exchanges with a passivity tank. It allows stable interactions with force feedback for any desired inertia, damping and stiffness parameters. Experiments are conducted to assess the efficiency of the proposed approach using an experimental setup with a variable stiffness environment. The obtained results illustrate the ability of the proposed strategy to stabilize a system otherwise unstable, with little effect on the transparency of the teleoperation system.",
        "primary_area": "",
        "author": "Charl\u00e9lie Saudrais;Laurent Barb\u00e9;Bernard Bayle;Charl\u00e9lie Saudrais;Laurent Barb\u00e9;Bernard Bayle",
        "authorids": "/37089001795;/37594506700;/37588627100;/37089001795;/37594506700;/37588627100",
        "aff": "ICube, University of Strasbourg, INSA - CNRS, Strasbourg, France; ICube, University of Strasbourg, INSA - CNRS, Strasbourg, France; ICube, University of Strasbourg, INSA - CNRS, Strasbourg, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561813/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9772972151126065369&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Strasbourg",
        "aff_unique_dep": "ICube",
        "aff_unique_url": "https://www.unistra.fr",
        "aff_unique_abbr": "UNistra",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Strasbourg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561766",
        "title": "ReForm: A Robot Learning Sandbox for Deformable Linear Object Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent advances in machine learning have triggered an enormous interest in using learning-based approaches for robot control and object manipulation. While the majority of existing algorithms are evaluated under the assumption that the involved bodies are rigid, a large number of practical applications contain deformable objects. In this work we focus on Deformable Linear Objects (DLOs) which can be used to model cables, tubes or wires. They are present in many applications such as manufacturing, agriculture and medicine. New methods in robotic manipulation research are often demonstrated in custom environments impeding reproducibility and comparisons of algorithms. We introduce ReForm, a simulation sandbox and a tool for benchmarking manipulation of DLOs. We offer six distinct environments representing important characteristics of deformable objects such as elasticity, plasticity or self-collisions and occlusions. A modular framework is used, enabling design parameters such as the end-effector degrees of freedom, reward function and type of observation. ReForm is a novel robot learning sandbox with which we intend to facilitate testing and reproducibility in manipulation research for DLOs.",
        "primary_area": "",
        "author": "Rita Laezza;Robert Gieselmann;Florian T. Pokorny;Yiannis Karayiannidis;Rita Laezza;Robert Gieselmann;Florian T. Pokorny;Yiannis Karayiannidis",
        "authorids": "/37088996941;/37086547525;/37077268000;/37300987100;/37088996941;/37086547525;/37077268000;/37300987100",
        "aff": "Department of Electrical Engineering, Division of Systems and Control, Chalmers University of Technology, Sweden; Department of Electrical Engineering and Computer Science, Division of of Robotics, Perception and Learning, KTH Royal Institute of Technology, Sweden; Department of Electrical Engineering and Computer Science, Division of of Robotics, Perception and Learning, KTH Royal Institute of Technology, Sweden; Department of Electrical Engineering, Division of Systems and Control, Chalmers University of Technology, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561766/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16524810407629781176&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;0",
        "aff_unique_norm": "Chalmers University of Technology;KTH Royal Institute of Technology",
        "aff_unique_dep": "Department of Electrical Engineering, Division of Systems and Control;Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.chalmers.se;https://www.kth.se",
        "aff_unique_abbr": "Chalmers;KTH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9561315",
        "title": "ReLMoGen: Integrating Motion Generation in Reinforcement Learning for Mobile Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Many Reinforcement Learning (RL) approaches use joint control signals (positions, velocities, torques) as action space for continuous control tasks. We propose to lift the action space to a higher level in the form of subgoals for a motion generator (a combination of motion planner and trajectory executor). We argue that, by lifting the action space and by leveraging sampling-based motion planners, we can efficiently use RL to solve complex, long-horizon tasks that could not be solved with existing RL methods in the original action space. We propose ReLMoGen \u2013 a framework that combines a learned policy to predict subgoals and a motion generator to plan and execute the motion needed to reach these subgoals. To validate our method, we apply ReLMoGen to two types of tasks: 1) Interactive Navigation tasks, navigation problems where interactions with the environment are required to reach the destination, and 2) Mobile Manipulation tasks, manipulation tasks that require moving the robot base. These problems are challenging because they are usually long-horizon, hard to explore during training, and comprise alternating phases of navigation and interaction. Our method is benchmarked on a diverse set of seven robotics tasks in photo-realistic simulation environments. In all settings, ReLMoGen outperforms state-of-the-art RL and Hierarchical RL baselines. ReLMoGen also shows outstanding transferability between different motion generators at test time, indicating a great potential to transfer to real robots. For more information, please visit project website: http://svl.stanford.edu/projects/relmogen.",
        "primary_area": "",
        "author": "Fei Xia;Chengshu Li;Roberto Mart\u00edn-Mart\u00edn;Or Litany;Alexander Toshev;Silvio Savarese;Fei Xia;Chengshu Li;Roberto Mart\u00edn-Mart\u00edn;Or Litany;Alexander Toshev;Silvio Savarese",
        "authorids": "/37086564490;/37087318952;/37085788640;/37085781338;/37300077100;/37298502600;/37086564490;/37087318952;/37085788640;/37085781338;/37300077100;/37298502600",
        "aff": "Stanford University; Stanford University; Stanford University; Nvidia; Robotics at Google; Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561315/",
        "gs_citation": 81,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9155937878626181341&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "Stanford University;NVIDIA;Google",
        "aff_unique_dep": ";NVIDIA Corporation;Robotics",
        "aff_unique_url": "https://www.stanford.edu;https://www.nvidia.com;https://www.google.com",
        "aff_unique_abbr": "Stanford;NVIDIA;Google Robotics",
        "aff_campus_unique_index": "0;0;0;2;0",
        "aff_campus_unique": "Stanford;;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561360",
        "title": "Reachability Analysis for FollowerStopper: Safety Analysis and Experimental Results",
        "track": "main",
        "status": "Poster",
        "abstract": "Motivated by earlier work and the developer of a new algorithm, the FollowerStopper, this article uses reachability analysis to verify the safety of the FollowerStopper algorithm, which is a controller designed for dampening stop-and-go traffic waves. With more than 1100 miles of driving data collected by our physical platform, we validate our analysis results by comparing it to human driving behaviors. The FollowerStopper controller has been demonstrated to dampen stop-and-go traffic waves at low speed, but previous analysis on its relative safety has been limited to upper and lower bounds of acceleration. To expand upon previous analysis, reachability analysis is used to investigate the safety at the speeds it was originally tested and also at higher speeds. Two formulations of safety analysis with different criteria are shown: distance-based and time headway-based. The FollowerStopper is considered safe with distance-based criterion. However, simulation results demonstrate that the FollowerStopper is not representative of human drivers - it follows too closely behind vehicles, specifically at a distance human would deem as unsafe. On the other hand, under the time headway-based safety analysis, the FollowerStopper is not considered safe anymore. A modified FollowerStopper is proposed to satisfy time-based safety criterion. Simulation results of the proposed FollowerStopper shows that its response represents human driver behavior better.",
        "primary_area": "",
        "author": "Fang-Chieh Chou;Marsalis Gibson;Rahul Bhadani;Alexandre M. Bayen;Jonathan Sprinkle;Fang-Chieh Chou;Marsalis Gibson;Rahul Bhadani;Alexandre M. Bayen;Jonathan Sprinkle",
        "authorids": "/37086095707;/37088996448;/37086591485;/37299705000;/37272303000;/37086095707;/37088996448;/37086591485;/37299705000;/37272303000",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, USA; Department of Electrical Engineering, University of California, Berkeley, CA, USA; Department of Electrical and Computer Engineering, The University of Arizona, USA; Department of Electrical Engineering, University of California, Berkeley, CA, USA; Department of Electrical and Computer Engineering, The University of Arizona, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561360/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1276315076978220019&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "University of California, Berkeley;University of Arizona",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.berkeley.edu;https://www.arizona.edu",
        "aff_unique_abbr": "UC Berkeley;UA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561872",
        "title": "Reachability-based Push Recovery for Humanoid Robots with Variable-Height Inverted Pendulum",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies push recovery for humanoid robots based on a variable-height inverted pendulum (VHIP) model. We first develop an approach for treating zero-step capturability of the VHIP with a novel methodology based on Hamilton-Jacobi (HJ) reachability analysis. Such an approach uses the sub-zero level set of a value function to encode capturability of the VHIP, where the value function is obtained by numerically solving a HJ variational inequality offline. Based on this analysis, a simple and effective method for adjusting foothold locations is then devised for cases where the VHIP state is not zero-step capturable. In addition, the HJ reachability analysis naturally induces an optimal control law that allows for rapid planning with the VHIP during push recovery online. To enable use of the strategy with a position-controlled humanoid robot, an associated differential inverse kinematics based tracking controller is employed. The effectiveness of the overall framework is demonstrated with the UBTECH Walker robot in the MuJoCo simulator. Simulation validations show a significant improvement in push robustness as compared to the methods based on the classical linear inverted pendulum model.",
        "primary_area": "",
        "author": "Shunpeng Yang;Hua Chen;Luyao Zhang;Zhefeng Cao;Patrick M. Wensing;Yizhang Liu;Jianxin Pang;Wei Zhang;Shunpeng Yang;Hua Chen;Luyao Zhang;Zhefeng Cao;Patrick M. Wensing;Yizhang Liu;Jianxin Pang;Wei Zhang",
        "authorids": "/37088996360;/37086195529;/37089394969;/37088997694;/37946046300;/37089546087;/37089854598;/37089656248;/37088996360;/37086195529;/37089394969;/37088997694;/37946046300;/37089546087;/37089854598;/37089656248",
        "aff": "Department of Mechanical and Energy Engineering, Southern University of Science and Technology, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, China; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, China; Department of Aerospace and Mechanical Engineering, University of Notre Dame, USA; UBTECH Robotics Inc.; UBTECH Robotics Inc.; Department of Mechanical and Energy Engineering, Southern University of Science and Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561872/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11237778360839211947&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;2;2;0",
        "aff_unique_norm": "Southern University of Science and Technology;University of Notre Dame;UBTECH Robotics Inc.",
        "aff_unique_dep": "Department of Mechanical and Energy Engineering;Department of Aerospace and Mechanical Engineering;",
        "aff_unique_url": "https://www.sustech.edu.cn;https://www.nd.edu;https://www.ubtech.com/",
        "aff_unique_abbr": "SUSTech;Notre Dame;UBTECH",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;1;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561956",
        "title": "Reachable Polyhedral Marching (RPM): A Safety Verification Algorithm for Robotic Systems with Deep Neural Network Components",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a method for computing exact reachable sets for deep neural networks with rectified linear unit (ReLU) activation. Our method is well-suited for use in rigorous safety analysis of robotic perception and control systems with deep neural network components. Our algorithm can compute both forward and backward reachable sets for a ReLU network iterated over multiple time steps, as would be found in a perception-action loop in a robotic system. Our algorithm is unique in that it builds the reachable sets by incrementally enumerating polyhedral cells in the input space, rather than iterating layer-by-layer through the network as in other methods. If an unsafe cell is found, our algorithm can return this result without completing the full reachability computation, thus giving an anytime property that accelerates safety verification. In addition, our method requires less memory during execution compared to existing methods where memory can be a limiting factor. We demonstrate our algorithm on safety verification of the ACAS Xu aircraft advisory system. We find unsafe actions many times faster than the fastest existing method and certify no unsafe actions exist in about twice the time of the existing method. We also compute forward and backward reachable sets for a learned model of pendulum dynamics over a 50 time step horizon in 87s on a laptop computer. Algorithm source code: https://github.com/StanfordMSL/Neural-Network-Reach.",
        "primary_area": "",
        "author": "Joseph A. Vincent;Mac Schwager;Joseph A. Vincent;Mac Schwager",
        "authorids": "/37088998836;/37424620600;/37088998836;/37424620600",
        "aff": "Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561956/",
        "gs_citation": 55,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6239439732156479207&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Aeronautics and Astronautics",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562075",
        "title": "Reaching Pruning Locations in a Vine Using a Deep Reinforcement Learning Policy",
        "track": "main",
        "status": "Poster",
        "abstract": "We outline a neural network-based pipeline for perception, control and planning of a 7 DoF robot for tasks that involve reaching into a dormant grapevine canopy. The proposed system consists of a 6 DoF industrial robot arm and a linear slider that can actuate on an entire grape vine. Our approach uses Convolutional Neural Networks to detect buds in dormant grape vines and a Reinforcement Learning based control strategy to reach desired cut-point locations for pruning tasks. Within this framework, three methodologies are developed and compared to reach the desired locations: the learned policy-based approach (RL), a hybrid method that uses the learned policy and an inverse kinematics solver (RL+IK), and lastly a classical approach commonly used in robotics. We first tested and validated the suitability of the proposed learning methodology in a simulated environment that resembled laboratory conditions. A reaching accuracy of up to 61.90% and 85.71% for the RL and RL+IK approaches respectively was obtained for a vine that the agent observed while learning. When testing in a new vine, the accuracy was up to 66.66% and 76.19% for RL and RL+IK, respectively. The same methods were then deployed on a real system in an end to end procedure: autonomously scan the vine using a vision system, create its model and finally use the learned policy to reach cutting points. The reaching accuracy obtained in these tests was 73.08%.",
        "primary_area": "",
        "author": "Francisco Yandun;Tanvir Parhar;Abhisesh Silwal;David Clifford;Zhiqiang Yuan;Gabriella Levine;Sergey Yaroshenko;George Kantor;Francisco Yandun;Tanvir Parhar;Abhisesh Silwal;David Clifford;Zhiqiang Yuan;Gabriella Levine;Sergey Yaroshenko;George Kantor",
        "authorids": "/37086363686;/37086041333;/37086208291;/37088913415;/37088997000;/37086783437;/37088998091;/37273878300;/37086363686;/37086041333;/37086208291;/37088913415;/37088997000;/37086783437;/37088998091;/37273878300",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Mineral, X - The Moonshot Factory, Mountain View, CA, USA; Mineral, X - The Moonshot Factory, Mountain View, CA, USA; Mineral, X - The Moonshot Factory, Mountain View, CA, USA; Mineral, X - The Moonshot Factory, Mountain View, CA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562075/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10160596516437004709&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;1;1;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Google",
        "aff_unique_dep": "Robotics Institute;The Moonshot Factory",
        "aff_unique_url": "https://www.cmu.edu;https://xdevllc.com",
        "aff_unique_abbr": "CMU;X Dev",
        "aff_campus_unique_index": "0;0;0;1;1;1;1;0",
        "aff_campus_unique": "Pittsburgh;Mountain View",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561985",
        "title": "Reactive Cooperative Manipulation based on Set Primitives and Circular Fields",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the problem of real-time planning in constrained dual-arm manipulation scenarios. Our proposed coupling leverages manipulability information of the cooperative bimanual task-space to a vector-field based planner by means of a repulsive circulatory field, while geometric primitives in Spin(3)\u22c9\u211d3 are explored for flexible task relaxation. Furthermore, the circular field informs the cooperative framework about the safety boundaries which are in turn used to further relax motion constraints within a collision-free ball in Cartesian space. This builds a funnel along the trajectory which can be directly tracked through the proposed switching of task-primitive-priorities. The switching strategy follows an approach that ensures robustness to chattering and continuity in the joint-space. Experiments verify that our framework can run within the inner control loop of Franka Emika Panda robots.",
        "primary_area": "",
        "author": "Riddhiman Laha;Luis F.C. Figueredo;Juraj Vrabel;Abdalla Swikir;Sami Haddadin;Riddhiman Laha;Luis F.C. Figueredo;Juraj Vrabel;Abdalla Swikir;Sami Haddadin",
        "authorids": "/37089002102;/37063909900;/37089001412;/37085861833;/37542865300;/37089002102;/37063909900;/37089001412;/37085861833;/37542865300",
        "aff": "Munich School of Robotics and Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Munich, Germany; Munich School of Robotics and Machine Intelligence, Technische Universit\u00e4t M\u00fcnchen (TUM), Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561985/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1512511223810255247&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Technische Universit\u00e4t M\u00fcnchen",
        "aff_unique_dep": "Munich School of Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561170",
        "title": "Reactive Human-to-Robot Handovers of Arbitrary Objects",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot object handovers have been an actively studied area of robotics over the past decade; however, very few techniques and systems have addressed the challenge of handing over diverse objects with arbitrary appearance, size, shape, and deformability. In this paper, we present a vision-based system that enables reactive human-to-robot handovers of unknown objects. Our approach combines closed-loop motion planning with real-time, temporally consistent grasp generation to ensure reactivity and motion smoothness. Our system is robust to different object positions and orientations, and can grasp both rigid and non-rigid objects. We demonstrate the generalizability, usability, and robustness of our approach on a novel benchmark set of 26 diverse household objects, a user study with six participants handing over a subset of 15 objects, and a systematic evaluation examining different ways of handing objects.",
        "primary_area": "",
        "author": "Wei Yang;Chris Paxton;Arsalan Mousavian;Yu-Wei Chao;Maya Cakmak;Dieter Fox;Wei Yang;Chris Paxton;Arsalan Mousavian;Yu-Wei Chao;Maya Cakmak;Dieter Fox",
        "authorids": "/37069403600;/37085403975;/37085404794;/37088503888;/37409159800;/37284329000;/37069403600;/37085403975;/37085404794;/37088503888;/37409159800;/37284329000",
        "aff": "NVIDIA, USA; NVIDIA, USA; NVIDIA, USA; NVIDIA, USA; University of Washington, USA; University of Washington, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561170/",
        "gs_citation": 94,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17990990783774187962&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;1",
        "aff_unique_norm": "NVIDIA;University of Washington",
        "aff_unique_dep": "NVIDIA;",
        "aff_unique_url": "https://www.nvidia.com;https://www.washington.edu",
        "aff_unique_abbr": "NV;UW",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561958",
        "title": "Reactive Planning for Mobile Manipulation Tasks in Unexplored Semantic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Complex manipulation tasks, such as rearrangement planning of numerous objects, are combinatorially hard problems. Existing algorithms either do not scale well or assume a great deal of prior knowledge about the environment, and few offer any rigorous guarantees. In this paper, we propose a novel hybrid control architecture for achieving such tasks with mobile manipulators. On the discrete side, we enrich a temporal logic specification with mobile manipulation primitives such as moving to a point, and grasping or moving an object. Such specifications are translated to an automaton representation, which orchestrates the physical grounding of the task to mobility or manipulation controllers. The grounding from the discrete to the continuous reactive controller is online and can respond to the discovery of unknown obstacles or decide to push out of the way movable objects that prohibit task accomplishment. Despite the problem complexity, we prove that, under specific conditions, our architecture enjoys provable completeness on the discrete side, provable termination on the continuous side, and avoids all obstacles in the environment. Simulations illustrate the efficiency of our architecture that can handle tasks of increased complexity while also responding to unknown obstacles or unanticipated adverse configurations.",
        "primary_area": "",
        "author": "Vasileios Vasilopoulos;Yiannis Kantaros;George J. Pappas;Daniel E. Koditschek;Vasileios Vasilopoulos;Yiannis Kantaros;George J. Pappas;Daniel E. Koditschek",
        "authorids": "/37085350448;/37085499544;/37281547100;/37275653000;/37085350448;/37085499544;/37281547100;/37275653000",
        "aff": "GRASP Lab, University of Pennsylvania, Philadelphia, PA; GRASP Lab, University of Pennsylvania, Philadelphia, PA; GRASP Lab, University of Pennsylvania, Philadelphia, PA; GRASP Lab, University of Pennsylvania, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561958/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8238923850566995295&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Lab",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561807",
        "title": "Reactive Task and Motion Planning under Temporal Logic Specifications",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a task-and-motion planning (TAMP) algorithm robust against a human operator's cooperative or adversarial interventions. Interventions often invalidate the current plan and require replanning on the fly. Replanning can be computationally expensive and often interrupts seamless task execution. We introduce a dynamically reconfigurable planning methodology with behavior tree-based control strategies toward reactive TAMP, which takes the advantage of previous plans and incremental graph search during temporal logic-based reactive synthesis. Our algorithm also shows efficient recovery functionalities that minimize the number of replanning steps. Finally, our algorithm produces a robust, efficient, and complete TAMP solution. Our experimental results show the algorithm results in superior manipulation performance in both simulated and real-world tasks.",
        "primary_area": "",
        "author": "Shen Li;Daehyung Park;Yoonchang Sung;Julie A. Shah;Nicholas Roy;Shen Li;Daehyung Park;Yoonchang Sung;Julie A. Shah;Nicholas Roy",
        "authorids": "/37086599209;/37085429958;/38235977600;/38252774900;/37274058700;/37086599209;/37085429958;/38235977600;/38252774900;/37274058700",
        "aff": "CSAIL, Massachusetts Institute of Technology, USA; School of Computing, Korea Advanced Institute of Science and Technology, Korea; CSAIL, Massachusetts Institute of Technology, USA; CSAIL, Massachusetts Institute of Technology, USA; CSAIL, Massachusetts Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561807/",
        "gs_citation": 54,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9172080563321198816&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory;School of Computing",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.kaist.ac.kr",
        "aff_unique_abbr": "MIT;KAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "9561553",
        "title": "Real-Time Human Lower Limbs Motion Estimation and Feedback for Potential Applications in Robotic Gait Aid and Training",
        "track": "main",
        "status": "Poster",
        "abstract": "Real-time lower limbs motion or gait measurement is an important part in human-robotic interaction for the control of robotic walkers and rehabilitation devices. Laser range finder or infrared sensor that is mounted on the device has been widely used in applications. Although these sensors can provide accurate horizontal motion information of lower limbs during human walking, it is still difficult to measure the angular motion of lower limbs due to their functional principles. Using inertial measurement units (IMU) can measure the angular motion of lower limbs, but it requires a large amount of IMU units for measurements of all lower limb segments. In this study, a novel method is developed for real-time monitoring lower limbs (shanks and thighs) motion in human walking using just two shank-mounted IMUs. A pose prediction model based on multiple linear regression and Kalman filter is proposed. The root-mean-square error (RMSE) of the thigh orientation and the knee joint angle estimation in sagittal plane are 6.1 \u00b1 1.3 and 6.8 \u00b1 1.4 degs, respectively. The RMSE of the ankle, knee, and hip position estimation are 4.2 \u00b1 1.3, 4.2 \u00b1 1.1 and 3.5 \u00b1 0.9 cm, respectively.",
        "primary_area": "",
        "author": "Lei Wang;Qingguo Li;Jingang Yi;Jinyuan Zhang;Tao Liu;Lei Wang;Qingguo Li;Jingang Yi;Jinyuan Zhang;Tao Liu",
        "authorids": "/37086193482;/37085621176;/37277001600;/37089002284;/37293265800;/37086193482;/37085621176;/37277001600;/37089002284;/37293265800",
        "aff": "State Key Laboratory of Fluid Power and Mechatronic Systems, School of Mechanical Engineering, Zhejiang University, Hangzhou, China; Department of Mechanical and Materials Engineering, Queen\u2019s University, Kingston, Canada; Department of Mechanical and Aerospace Engineering, Rutgers University, NJ, USA; Weldon School of Biomedical Engineering, Purdue University, West Lafayette, IN, USA; State Key Laboratory of Fluid Power and Mechatronic Systems, School of Mechanical Engineering, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561553/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15235941135605400540&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;3;0",
        "aff_unique_norm": "Zhejiang University;Queen\u2019s University;Rutgers University;Purdue University",
        "aff_unique_dep": "School of Mechanical Engineering;Department of Mechanical and Materials Engineering;Department of Mechanical and Aerospace Engineering;Weldon School of Biomedical Engineering",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.queensu.ca;https://www.rutgers.edu;https://www.purdue.edu",
        "aff_unique_abbr": "ZJU;Queen's U;Rutgers;Purdue",
        "aff_campus_unique_index": "0;1;2;3;0",
        "aff_campus_unique": "Hangzhou;Kingston;New Brunswick;West Lafayette",
        "aff_country_unique_index": "0;1;2;2;0",
        "aff_country_unique": "China;Canada;United States"
    },
    {
        "id": "9560749",
        "title": "Real-Time Mesh Extraction from Implicit Functions via Direct Reconstruction of Decision Boundary",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to estimate 3D object shape from a single image is vital to robotics and manufacturing. For instance, it enables iterative trial-and-error in simulated environments. In single-view reconstruction, implicit functions have demonstrated superior results over traditional methods. However, implicit functions suffer from the heavy computation of mesh extraction. This is due to the indirect mesh extraction, where the number of evaluation points grows cubically with resolution. On the other hand, reducing the resolution results in the discretization error of marching cubes (MC). In this work, we aim to perform efficient and accurate mesh extraction from implicit functions. The idea is to directly reconstruct the decision boundary of implicit functions as a mesh by reverse tracing from the output. It eliminates the need for evaluating massive points and error-prone MC. Consequently, we propose implementing an implicit function via a composite function of a flow and Binary-coded Input Neural Network (BCINN). The boundary of BCINN is easily identifiable, and the flow is invertible. Owing to these properties, the decision boundary of the composite function can be directly and efficiently reconstructed. In our experiments, we demonstrate that the proposed method significantly improves runtime/memory efficiency, with results comparable to those of existing methods. Specifically, our method enables real-time high-quality mesh inference from a single image.",
        "primary_area": "",
        "author": "Wataru Kawai;Yusuke Mukuta;Tatsuya Harada;Wataru Kawai;Yusuke Mukuta;Tatsuya Harada",
        "authorids": "/37086261330;/37085501109;/37274148900;/37086261330;/37085501109;/37274148900",
        "aff": "University of Tokyo; RIKEN; RIKEN",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560749/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:ReNy2Ck9hwAJ:scholar.google.com/&scioq=Real-Time+Mesh+Extraction+from+Implicit+Functions+via+Direct+Reconstruction+of+Decision+Boundary&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Tokyo;RIKEN",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.riken.jp",
        "aff_unique_abbr": "UTokyo;RIKEN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561639",
        "title": "Real-Time Trajectory Adaptation for Quadrupedal Locomotion using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a control architecture for real-time adaptation and tracking of trajectories generated using a terrain-aware trajectory optimization solver. This approach enables us to circumvent the computationally exhaustive task of online trajectory optimization, and further introduces a control solution robust to systems modeled with approximated dynamics. We train a policy using deep reinforcement learning (RL) to introduce additive deviations to a reference trajectory in order to generate a feedback-based trajectory tracking system for a quadrupedal robot. We train this policy across a multitude of simulated terrains and ensure its generality by introducing training methods that avoid overfitting and convergence towards local optima. Additionally, in order to capture terrain information, we include a latent representation of the height maps in the observation space of the RL environment as a form of exteroceptive feedback. We test the performance of our trained policy by tracking the corrected set points using a model-based whole-body controller and compare it with the tracking behavior obtained without the corrective feedback in several simulation environments, and show that introducing the corrective feedback results in increase of the success rate from 72.7% to 92.4% for tracking precomputed dynamic long horizon trajectories on flat terrain and from 47.5% to 80.3% on a complex modular uneven terrain. We also show successful transfer of our training approach to the real physical system and further present cogent arguments in support of our framework.",
        "primary_area": "",
        "author": "Siddhant Gangapurwala;Mathieu Geisert;Romeo Orsolino;Maurice Fallon;Ioannis Havoutis;Siddhant Gangapurwala;Mathieu Geisert;Romeo Orsolino;Maurice Fallon;Ioannis Havoutis",
        "authorids": "/37088356748;/37085514664;/37086265101;/37540365100;/37542879900;/37088356748;/37085514664;/37086265101;/37540365100;/37542879900",
        "aff": "Dynamic Robots Systems (DRS) Group, Oxford Robotics Institute, University of Oxford, UK; Dynamic Robots Systems (DRS) Group, Oxford Robotics Institute, University of Oxford, UK; Dynamic Robots Systems (DRS) Group, Oxford Robotics Institute, University of Oxford, UK; Dynamic Robots Systems (DRS) Group, Oxford Robotics Institute, University of Oxford, UK; Dynamic Robots Systems (DRS) Group, Oxford Robotics Institute, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561639/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14269461905227027016&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9562063",
        "title": "Real-time 3D-Lidar, MMW Radar and GPS/IMU fusion based vehicle detection and tracking in unstructured environment",
        "track": "main",
        "status": "Poster",
        "abstract": "To solve the problem of unmanned ground vehicle leader-follower formation transportation in unstructured environment, we propose a novel target detection and tracking method based on multi-sensor fusion perception. Combined with 3D-Lidar, millimeter wave Radar and GPS/IMU, the proposed method can achieve stable target detection and continuous tracking of both static and dynamic vehicles. First, 3D-Lidar is used to detect the geometric model of the leader vehicle to complete the initialization of tracking target and it can also be assisted for target tracking. Then during the movement, the dynamic leader is mainly tracked through millimeter wave Radar as this sensor can keep tracking the same target with a constant index and effectively distinguish dynamic vehicle from other static obstacles according to relative speed estimation. In addition, by using GPS/IMU based integrated navigation, the movement trend of the leader can be derived according to the echo vehicle pose information and the relative position relationship. This is helpful to reduce the region of interest for target tracking and improve the real-time performance. In different unstructured environments, we perform the leader-follower formation transportation experiments for hundreds of kilometers. In rough terrain, the maximum tracking speed can still reach 40km/h and the maximum tracking distance can be up to 100 meters. Experiments show that the proposed method is suitable for vehicle target detection and tracking in unstructured environment. It has good robustness and high real-time performance with an average processing frame rate of 20Hz. The proposed method can be used for the formation transportation of unmanned ground vehicles to reduce labor costs.",
        "primary_area": "",
        "author": "Ning Li;Caixia Lu;Xuewei Yu;Xueyan Liu;Bo Su;Ning Li;Caixia Lu;Xuewei Yu;Xueyan Liu;Bo Su",
        "authorids": "/37086323441;/37088572420;/37088997358;/37089852929;/37086331875;/37086323441;/37088572420;/37088997358;/37089852929;/37086331875",
        "aff": "China North Vehicle Research Institute, Beijing, China; China North Vehicle Research Institute, Beijing, China; China North Vehicle Research Institute, Beijing, China; China North Vehicle Research Institute, Beijing, China; China North Vehicle Research Institute, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562063/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15940333946332703451&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "China North Vehicle Research Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561640",
        "title": "Real-time Friction Estimation for Grip Force Control",
        "track": "main",
        "status": "Poster",
        "abstract": "An important capability of humans when performing dexterous precision gripping tasks is our ability to feel both the weight and slipperiness of an object in real-time, and adjust our grip force accordingly. In this paper, we present for the first time a fully-instrumented version of our PapillArray tactile sensor concept, which can sense grip force, object weight, and incipient slip and friction, all in real-time. We demonstrate the real-time estimation of friction and measurement of 3D force from PapillArray sensors mounted on each finger of a two-finger gripper, combined with a closed-loop grip-force control algorithm that dynamically applies a near-optimal grip force to avoid dropping objects of varying weight and friction. A vertical lifting task was performed using an object with varying weight and friction, and with some common household items. After intentionally adding a 20% safety margin on the target grip force, the actual grip force applied was only 9-30 % greater than that required to avoid slip. Future work will focus on incorporating real-time torque measurement into the grip force feedback control. This will significantly advance the state-of-the-art in artificial tactile sensing and bring us closer to robotic dexterity.",
        "primary_area": "",
        "author": "Heba Khamis;Benjamin Xia;Stephen J. Redmond;Heba Khamis;Benjamin Xia;Stephen J. Redmond",
        "authorids": "/38500652200;/37088575523;/37276764700;/38500652200;/37088575523;/37276764700",
        "aff": "Graduate School of Biomedical Engineering, UNSW Sydney, Sydney, Australia; Graduate School of Biomedical Engineering, UNSW Sydney, Sydney, Australia; UCD School of Electrical and Electronic Engineering, the UCD Centre for Biomedical Engineering, and SFI Insight Centre for Data Analytics, University College Dublin, Dublin, Ireland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561640/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9647093518700612124&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "UNSW Sydney;University College Dublin",
        "aff_unique_dep": "Graduate School of Biomedical Engineering;School of Electrical and Electronic Engineering",
        "aff_unique_url": "https://www.unsw.edu.au;https://www.ucd.ie",
        "aff_unique_abbr": "UNSW;UCD",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Sydney;Dublin",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Australia;Ireland"
    },
    {
        "id": "9561202",
        "title": "Real-time Instance Detection with Fast Incremental Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Object instance detection is a highly relevant task to several robotic applications such as automated order picking, or household and hospital assistance robots. In these applications, a holistic scene labeling is often not required whereas it is sufficient to find a certain object type of interest, e.g. for picking it up. At the same time, large and continuously changing object sets are characteristic in such applications, requiring efficient model update capabilities from the object detector. Today\u2019s monolithic multi-class detectors do not fulfill this criterion for fast and flexible model updates.This paper introduces InstanceNet, an ensemble of efficient single-class instance detectors capable of fast and incremental adaptation to new object sets. Due to a dynamic sampling-based training strategy, accurate detection models for new objects can be obtained within less than 40 minutes on a consumer GPU while only a small percentage of the existing detection models needs to be updated in a very efficient manner. The new detector has been thoroughly evaluated on the basis of a novel dataset of 100 grocery store objects.",
        "primary_area": "",
        "author": "Richard Bormann;Xinjie Wang;Markus V\u00f6lk;Kilian Kleeberger;Jochen Lindermayr;Richard Bormann;Xinjie Wang;Markus V\u00f6lk;Kilian Kleeberger;Jochen Lindermayr",
        "authorids": "/38541025900;/37088506916;/37088690304;/37087323129;/37088996536;/38541025900;/37088506916;/37088690304;/37087323129;/37088996536",
        "aff": "Robot and Assistive Systems Department, Fraunhofer IPA, Stuttgart, Germany; Robot and Assistive Systems Department, Fraunhofer IPA, Stuttgart, Germany; Robot and Assistive Systems Department, Fraunhofer IPA, Stuttgart, Germany; Robot and Assistive Systems Department, Fraunhofer IPA, Stuttgart, Germany; Robot and Assistive Systems Department, Fraunhofer IPA, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561202/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11594620231940433895&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Fraunhofer IPA",
        "aff_unique_dep": "Robot and Assistive Systems Department",
        "aff_unique_url": "https://www.ipa.fraunhofer.de",
        "aff_unique_abbr": "Fraunhofer IPA",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561912",
        "title": "Real-time Obstacle Avoidance with a Virtual Torque Approach for a Robotic Tool in the End Effector",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a real-time obstacle avoidance control scheme for a 6-DOF manipulator with a tool in the end effector. The system consists of environment monitoring, robot-tool segmentation and collision-free motion planning of the manipulator. A Kinect V2 RGB-D camera is used to track obstacles including human and objects in the working environment. The K-D tree algorithm is then adopted to cluster point clouds of the tool and the obstacles. For robot-tool segmentation, we propose a method to model the tool in the end effector and predict its pose in order to solve the camera occlusion problem. For collision-free motion planning, a novel potential field algorithm is proposed to take into consideration of the pose of the tool. A virtual torque approach is proposed and added to the potential field in order to generate a smoother and shorter avoidance motion. The experimental results on a TM5-700 cobot show that the manipulator with a tool in the end effector effectively avoided an obstacle in real time and completed the assigned task. It is shown that the path length with the proposed virtual torque is shortened by 80.43% compared with the case without using the virtual torque.",
        "primary_area": "",
        "author": "Yi-Hung Lee;Kai-Tai Song;Yi-Hung Lee;Kai-Tai Song",
        "authorids": "/37089001499;/37271868000;/37089001499;/37271868000",
        "aff": "Institute of Electrical and Control Engineering, College of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Hsinchu, Taiwan, ROC; Institute of Electrical and Control Engineering, College of Electrical and Computer Engineering, National Yang Ming Chiao Tung University, Hsinchu, Taiwan, ROC",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561912/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16838909484378000333&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "National Yang Ming Chiao Tung University",
        "aff_unique_dep": "Institute of Electrical and Control Engineering",
        "aff_unique_url": "https://www.nctu.edu.tw",
        "aff_unique_abbr": "NYCU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561861",
        "title": "Real-time Optimal Navigation Planning Using Learned Motion Costs",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigation on challenging terrain topographies requires the understanding of robots\u2019 locomotion capabilities to produce optimal solutions. We present an integrated framework for real-time autonomous navigation of mobile robots based on elevation maps. The framework performs rapid global path planning and optimization that is aware of the locomotion capabilities of the robot. A GPU-aided, sampling-based path planner combined with a gradient-based path optimizer provides optimal paths by using a neural network-based locomotion cost predictor which is trained in simulation. We show that our approach is capable of planning and optimizing paths three orders of magnitude faster than RRT* on GPU-enabled hardware, enabling real-time deployment on mobile platforms. We successfully evaluate the framework on the ANYmal C quadrupedal robot in both simulations and real-world environments for path planning tasks on multiple complex terrains.",
        "primary_area": "",
        "author": "Bowen Yang;Lorenz Wellhausen;Takahiro Miki;Ming Liu;Marco Hutter;Bowen Yang;Lorenz Wellhausen;Takahiro Miki;Ming Liu;Marco Hutter",
        "authorids": "/37088996526;/37086200470;/37086454028;/37085398677;/37545251000;/37088996526;/37086200470;/37086454028;/37085398677;/37545251000",
        "aff": "Robotics and Multi-Perception Laboratory, Robotics Institute, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Robotic Systems Lab, ETH Z\u00fcrich, Switzerland; Robotic Systems Lab, ETH Z\u00fcrich, Switzerland; Robotics and Multi-Perception Laboratory, Robotics Institute, The Hong Kong University of Science and Technology, Hong Kong SAR, China; Robotic Systems Lab, ETH Z\u00fcrich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561861/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6657533013482916281&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Hong Kong University of Science and Technology;ETH Zurich",
        "aff_unique_dep": "Robotics and Multi-Perception Laboratory, Robotics Institute;Robotic Systems Lab",
        "aff_unique_url": "https://www.ust.hk;https://www.ethz.ch",
        "aff_unique_abbr": "HKUST;ETHZ",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR;",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "China;Switzerland"
    },
    {
        "id": "9560801",
        "title": "Real-time Robot Path Planning using Rapid Visible Tree",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a new path planning strategy - the Rapid Visible Tree (RVT) algorithm to guide a robot to its goal in a complex environment without dangerous collisions. By fusing the visibility information with the classic tree-based searching method, RVT only takes the noisy points locally acquired from the environment as input and computes the visible region at each location to decide the growing direction of the path tree. Compared with traditional methods, RVT is more efficient, lightweight, and robust. We demonstrate that the RVT algorithm can not only complete the path planning task in real-time but also explore the unknown environment in simulated or real scenes.",
        "primary_area": "",
        "author": "Wen Xing;Aiguo Song;Lifeng Zhu;Wen Xing;Aiguo Song;Lifeng Zhu",
        "authorids": "/37087235207;/37276033000;/37086246211;/37087235207;/37276033000;/37086246211",
        "aff": "State Key Laboratory of Bioelectronics, Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, P.R. China; State Key Laboratory of Bioelectronics, Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, P.R. China; State Key Laboratory of Bioelectronics, Jiangsu Key Lab of Remote Measurement and Control, School of Instrument Science and Engineering, Southeast University, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560801/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9307407602144671144&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Southeast University",
        "aff_unique_dep": "School of Instrument Science and Engineering",
        "aff_unique_url": "https://www.seu.edu.cn/",
        "aff_unique_abbr": "SEU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561393",
        "title": "Real-time Surgical Environment Enhancement for Robot-Assisted Minimally Invasive Surgery Based on Super-Resolution",
        "track": "main",
        "status": "Poster",
        "abstract": "In Robot-Assisted Minimally Invasive Surgery (RAMIS), a camera assistant is normally required to control the position and the zooming ratio of the laparoscope, following the surgeon\u2019s instructions. However, moving the laparoscope frequently may lead to unstable and suboptimal views, while the adjustment of zooming ratio may interrupt the workflow of the surgical operation. To this end, we propose a multi-scale Generative Adversarial Network (GAN)-based video super-resolution method to construct a framework for automatic zooming ratio adjustment. It can provide automatic real-time zooming for high-quality visualization of the Region of Interest (ROI) during the surgical operation. In the pipeline of the framework, the Kernel Correlation Filter (KCF) tracker is used for tracking the tips of the surgical tools, while the Semi-Global Block Matching (SGBM)-based depth estimation and Recurrent Neural Network (RNN)-based context-awareness are employed to determine the upscaling ratio for zooming. The framework is validated with the JIGSAW dataset and Hamlyn Centre Laparoscopic/Endoscopic Video Datasets, with results demonstrating its practicability.",
        "primary_area": "",
        "author": "Ruoxi Wang;Dandan Zhang;Qingbiao Li;Xiao-Yun Zhou;Benny Lo;Ruoxi Wang;Dandan Zhang;Qingbiao Li;Xiao-Yun Zhou;Benny Lo",
        "authorids": "/37088996202;/37086595836;/37089268910;/37085804767;/38183567000;/37088996202;/37086595836;/37089268910;/37085804767;/38183567000",
        "aff": "The Hamlyn Centre for Robotic Surgery, Imperial College London, United Kingdom; The Hamlyn Centre for Robotic Surgery, Imperial College London, United Kingdom; University of Cambridge, United Kingdom; PAII Inc, MA, USA; The Hamlyn Centre for Robotic Surgery, Imperial College London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561393/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2911317627539026788&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Imperial College London;University of Cambridge;PAII Inc",
        "aff_unique_dep": "The Hamlyn Centre for Robotic Surgery;;",
        "aff_unique_url": "https://www.imperial.ac.uk;https://www.cam.ac.uk;",
        "aff_unique_abbr": "Imperial College;Cambridge;",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "London;Cambridge;",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United Kingdom;United States"
    },
    {
        "id": "9561365",
        "title": "Real-time active detection of targets and path planning using UAVs",
        "track": "main",
        "status": "Poster",
        "abstract": "This article proposes a new method that enables Unmanned Aerial Vehicles (UAVs) to actively find targets and shoot photographs of them in an unknown environment, while successfully avoiding surrounding obstacles and planning optimize routes. Owing to the limited computing ability on the UAVs, we obtained the point cloud data of surrounding objects, and selected the best segmentation method of the point cloud to perform real-time semantic segmentation on the collected point cloud data. The point cloud data with semantic attributes were merged into voxels. We reconstruct the real-time distance and angle between the surface of obstacles and the surrounding obstacles through Euclidean Signed Distance Fields (ESDFs), and adjust the gimbal angle and focal length of UAVs and use the two-dimensional image recognition to shoot the photographs of the target precisely. Considering the increasing scale of UAVs power inspections, we can improve the efficiency of fine inspections of power transmission lines by using the method we proposed.",
        "primary_area": "",
        "author": "Fangping Chen;Yuheng Lu;Yunyi Li;Xiaodong Xie;Fangping Chen;Yuheng Lu;Yunyi Li;Xiaodong Xie",
        "authorids": "/37088686273;/37088999061;/37088997728;/37400127200;/37088686273;/37088999061;/37088997728;/37400127200",
        "aff": "School of Information Science and Technology, Peking University, Beijing, China; Yuheng Lu; Yunyi Li; School of Information Science and Technology, Peking University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561365/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8741673599823702008&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Peking University;",
        "aff_unique_dep": "School of Information Science and Technology;",
        "aff_unique_url": "http://www.pku.edu.cn;",
        "aff_unique_abbr": "Peking U;",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China;"
    },
    {
        "id": "9561177",
        "title": "Real-to-Sim Registration of Deformable Soft Tissue with Position-Based Dynamics for Surgical Robot Autonomy",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomy in robotic surgery is very challenging in unstructured environments, especially when interacting with deformable soft tissues. The main difficulty is to generate model-based control methods that account for deformation dynamics during tissue manipulation. Previous works in vision-based perception can capture the geometric changes within the scene, however, model-based controllers integrated with dynamic properties, a more accurate and safe approach, has not been studied before. Considering the mechanic coupling between the robot and the environment, it is crucial to develop a registered, simulated dynamical model. In this work, we propose an online, continuous, real-to-sim registration method to bridge 3D visual perception with position-based dynamics (PBD) modeling of tissues. The PBD method is employed to simulate soft tissue dynamics as well as rigid tool interactions for model-based control. Meanwhile, a vision-based strategy is used to generate 3D reconstructed point cloud surfaces based on real-world manipulation, so as to register and update the simulation. To verify this real-to-sim approach, tissue experiments have been conducted on the da Vinci Research Kit. Our real-to-sim approach successfully reduces registration error online, which is especially important for safety during autonomous control. Moreover, it achieves higher accuracy in occluded areas than fusion-based reconstruction.",
        "primary_area": "",
        "author": "Fei Liu;Zihan Li;Yunhai Han;Jingpei Lu;Florian Richter;Michael C. Yip;Fei Liu;Zihan Li;Yunhai Han;Jingpei Lu;Florian Richter;Michael C. Yip",
        "authorids": "/37088689503;/37089000840;/37088996135;/37088071646;/37086936752;/37085382768;/37088689503;/37089000840;/37088996135;/37088071646;/37086936752;/37085382768",
        "aff": "Advanced Robotics and Controls Lab, University of California San Diego, La Jolla, CA, USA; Advanced Robotics and Controls Lab, University of California San Diego, La Jolla, CA, USA; Advanced Robotics and Controls Lab, University of California San Diego, La Jolla, CA, USA; Advanced Robotics and Controls Lab, University of California San Diego, La Jolla, CA, USA; Advanced Robotics and Controls Lab, University of California San Diego, La Jolla, CA, USA; Advanced Robotics and Controls Lab, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561177/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14776327798746037507&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Advanced Robotics and Controls Lab",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "La Jolla",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561659",
        "title": "Reasoning Operational Decisions for Robots via Time Series Causal Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "Justifying operational decisions for robots is a challenging task as the operator or the robot itself has to understand the underlying physical interaction between the robot and the environment to predict the potential outcome. It is desirable to understand how the decision influences the operational performance in the way of causal relationship for the purpose of explainable decision-making. Here we propose a novel causal inference framework for the discovery and inference on the reasoning of the operational decisions for robots. It unifies both domain knowledge integration and model-free causal inference, allowing a data-driven causal knowledge learning on time series data. The framework is evaluated in the experiments of an underwater robot with complex environmental interactions. The results show that the framework can learn the causal structure and inference model to accurately explain and predict the operation performance with integrated physics.",
        "primary_area": "",
        "author": "Yu Cao;Boyang Li;Qian Li;Adam Stokes;David Ingram;Aristides Kiprakis;Yu Cao;Boyang Li;Qian Li;Adam Stokes;David Ingram;Aristides Kiprakis",
        "authorids": "/37088496422;/37088497335;/37088498523;/37824805800;/37074997600;/38549458500;/37088496422;/37088497335;/37088498523;/37824805800;/37074997600;/38549458500",
        "aff": "School of Engineering, The University of Edinburgh, Edinburgh, United Kingdom; School of Engineering, The University of Edinburgh, Edinburgh, United Kingdom; School of Engineering, The University of Edinburgh, Edinburgh, United Kingdom; School of Engineering, The University of Edinburgh, Edinburgh, United Kingdom; School of Engineering, The University of Edinburgh, Edinburgh, United Kingdom; School of Engineering, The University of Edinburgh, Edinburgh, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561659/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3350184761334892722&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "School of Engineering",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh University",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9560794",
        "title": "Receding-Horizon Perceptive Trajectory Optimization for Dynamic Legged Locomotion with Learned Initialization",
        "track": "main",
        "status": "Poster",
        "abstract": "To dynamically traverse challenging terrain, legged robots need to continually perceive and reason about upcoming features, adjust the locations and timings of future footfalls and leverage momentum strategically. We present a pipeline that enables flexibly-parametrized trajectories for perceptive and dynamic quadruped locomotion to be optimized in an online, receding-horizon manner. The initial guess passed to the optimizer affects the computation needed to achieve convergence and the quality of the solution. We consider two methods for generating good guesses. The first is a heuristic initializer which provides a simple guess and requires significant optimization but is nonetheless suitable for adaptation to upcoming terrain. We demonstrate experiments using the ANYmal C quadruped, with fully onboard sensing and computation, to cross obstacles at moderate speeds using this technique. Our second approach uses latent-mode trajectory regression (LMTR) to imitate expert data\u2014while avoiding invalid interpolations between distinct behaviors\u2014such that minimal optimization is needed. This enables high-speed motions that make more expansive use of the robot\u2019s capabilities. We demonstrate it on flat ground with the real robot and provide numerical trials that progress toward deployment on terrain. These results illustrate a paradigm for advancing beyond short-horizon dynamic reactions, toward the type of intuitive and adaptive locomotion planning exhibited by animals and humans.",
        "primary_area": "",
        "author": "Oliwier Melon;Romeo Orsolino;David Surovik;Mathieu Geisert;Ioannis Havoutis;Maurice Fallon;Oliwier Melon;Romeo Orsolino;David Surovik;Mathieu Geisert;Ioannis Havoutis;Maurice Fallon",
        "authorids": "/37088506627;/37086265101;/37086580632;/37085514664;/37542879900;/37540365100;/37088506627;/37086265101;/37086580632;/37085514664;/37542879900;/37540365100",
        "aff": "Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560794/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10716270422629004766&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561833",
        "title": "Reciprocally Rotating Magnetic Actuation and Automatic Trajectory Following for Wireless Capsule Endoscopy",
        "track": "main",
        "status": "Poster",
        "abstract": "Active wireless capsule endoscopy (WCE) under magnetic actuation is a promising technology to reduce the inspection time and relieve the burden of physicians. In this paper, we propose a reciprocally rotating magnetic actuation method for trajectory following of a capsule and develop its dynamic model. For the trajectory following task, we investigate the closed-loop tracking control strategies based on different controllers to actuate the capsule in the complex environments. The effectiveness of our method is validated in extensive experiments in a simulation environment as well as in an ex-vivo pig colon. The results demonstrate that the proposed method can accurately and efficiently actuate the capsule to follow the desired trajectory in the complex environments, achieving tracking errors on the order of millimeter. Moreover, the experiments on the ex-vivo pig colon show that the proposed reciprocally rotating magnetic actuation method has the potential to reduce the clinical risks and improve the safety and clinical acceptability of this technology.",
        "primary_area": "",
        "author": "Yangxin Xu;Keyu Li;Ziqi Zhao;Fei Meng;Li Liu;Max Q.-H. Meng;Yangxin Xu;Keyu Li;Ziqi Zhao;Fei Meng;Li Liu;Max Q.-H. Meng",
        "authorids": "/37086799174;/37087244178;/37087246176;/37089000240;/37086313226;/37274117000;/37086799174;/37087244178;/37087246176;/37089000240;/37086313226;/37274117000",
        "aff": "Department of Electronic Engineering, The Chinese University of Hong Kong, China; Department of Electronic Engineering, The Chinese University of Hong Kong, China; Department of Electronic and Electrical Engineering, The Southern University of Science and Technology, Shenzhen, China; Department of Electronic Engineering, The Chinese University of Hong Kong, China; Shenzhen Research Institute of the Chinese University of Hong Kong, Shenzhen, China; Department of Electronic and Electrical Engineering, Southern University of Science and Technology in Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561833/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16430174320407684500&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;1",
        "aff_unique_norm": "Chinese University of Hong Kong;Southern University of Science and Technology",
        "aff_unique_dep": "Department of Electronic Engineering;Department of Electronic and Electrical Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.sustech.edu.cn",
        "aff_unique_abbr": "CUHK;SUSTech",
        "aff_campus_unique_index": "0;0;1;0;1;1",
        "aff_campus_unique": "Hong Kong;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561856",
        "title": "Recognizing Orientation Slip in Human Demonstrations",
        "track": "main",
        "status": "Poster",
        "abstract": "Manipulations of a constrained object often use a non-rigid grasp that allows the object to rotate relative to the end effector. This orientation slip strategy is often present in natural human demonstrations, yet it is generally overlooked in methods to identify constraints from such demonstrations. In this paper, we present a method to model and recognize prehensile orientation slip in human demonstrations of constrained interactions. Using only observations of an end effector, we can detect the type of constraint, parameters of the constraint, and orientation slip properties. Our method uses a novel hierarchical model selection method that is informed by multiple origins of physics-based evidence. A study with eight participants shows that orientation slip occurs in natural demonstrations and confirms that it can be detected by our method.",
        "primary_area": "",
        "author": "Michael Hagenow;Bolun Zhang;Bilge Mutlu;Michael Zinn;Michael Gleicher;Michael Hagenow;Bolun Zhang;Bilge Mutlu;Michael Zinn;Michael Gleicher",
        "authorids": "/37088814469;/37088945717;/38569363200;/37282367400;/37282585700;/37088814469;/37088945717;/38569363200;/37282367400;/37282585700",
        "aff": "Department of Mechanical Engineering, University of Wisconsin\u2013Madison, Madison, USA; Department of Mechanical Engineering, University of Wisconsin\u2013Madison, Madison, USA; Department of Computer Sciences, University of Wisconsin\u2013Madison, Madison, USA; Department of Mechanical Engineering, University of Wisconsin\u2013Madison, Madison, USA; Department of Computer Sciences, University of Wisconsin\u2013Madison, Madison, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561856/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8120592495903037051&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Wisconsin\u2013Madison",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW\u2013Madison",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561546",
        "title": "Reconstructing Interactive 3D Scenes by Panoptic Mapping and CAD Model Alignments",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we rethink the problem of scene reconstruction from an embodied agent\u2019s perspective: While the classic view focuses on the reconstruction accuracy, our new perspective emphasizes the underlying functions and constraints such that the reconstructed scenes provide actionable information for simulating interactions with agents. Here, we address this challenging problem by reconstructing an interactive scene using RGB-D data stream, which captures (i) the semantics and geometry of objects and layouts by a 3D volumetric panoptic mapping module, and (ii) object affordance and contextual relations by reasoning over physical common sense among objects, organized by a graph-based scene representation. Crucially, this reconstructed scene replaces the object meshes in the dense panoptic map with part-based articulated CAD models for finer-grained robot interactions. In the experiments, we demonstrate that (i) our panoptic mapping module outperforms previous state-of-the-art methods, (ii) a high-performant physical reasoning procedure that matches, aligns, and replaces objects\u2019 meshes with best-fitted CAD models, and (iii) reconstructed scenes are physically plausible and naturally afford actionable interactions; without any manual labeling, they are seamlessly imported to ROS-based simulators and virtual environments for complex robot task executions.1",
        "primary_area": "",
        "author": "Muzhi Han;Zeyu Zhang;Ziyuan Jiao;Xu Xie;Yixin Zhu;Song-Chun Zhu;Hangxin Liu;Muzhi Han;Zeyu Zhang;Ziyuan Jiao;Xu Xie;Yixin Zhu;Song-Chun Zhu;Hangxin Liu",
        "authorids": "/37088998702;/37086938580;/37085784268;/37086273323;/37086172463;/37281407500;/37086274715;/37088998702;/37086938580;/37085784268;/37086273323;/37086172463;/37281407500;/37086274715",
        "aff": "Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA); Statistics Department, UCLA Center for Vision, Cognition, Learning, and Autonomy (VCLA)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561546/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16417081843145576561&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Statistics Department",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561043",
        "title": "Recovering Stress Distribution on Deformable Tissue for a Magnetic Actuated Insertable Laparoscopic Surgical Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "Fully insertable laparoscopic cameras represent a promising future of minimally invasive surgery. The most characteristic technology adopted on these devices is transabdominal anchoring and actuation based on magnetic coupling. However, few have paid adequate attention to the safety concerns. As the camera is anchored against the interior abdominal wall without any force feedback, the patient is being exposed to a high risk of getting injured by inappropriate stress on the tissue. We have recovered the camera-tissue interaction force via a non-invasive approach in our previous work. Aiming to access the stress distribution, this paper presents a viscoelastic camera-tissue interaction model, which establishes explicit relations between the contact force and the stress distribution on the tissue. For the first time, a geometric constraint between the contact angle and the tissue indentation is introduced, which helps make the multivariable model solvable. Ex-vivo experiments on porcine abdomen tissue facilitated by non-invasive force measurement validate effectiveness of the model. This work lays foundation for improving control and surgical safety of using a magnetic actuated insertable laparoscopic surgical camera.",
        "primary_area": "",
        "author": "Ning Li;Gregory J. Mancini;Amy Chandler;Jindong Tan;Ning Li;Gregory J. Mancini;Amy Chandler;Jindong Tan",
        "authorids": "/37085904656;/37085417618;/37088996398;/37065245900;/37085904656;/37085417618;/37088996398;/37065245900",
        "aff": "Department of Mechanical, Aerospace and Biomedical Engineering, University of Tennessee, Knoxville, TN, USA; Graduate School of Medicine, University of Tennessee, Knoxville, TN, USA; Department of Mechanical, Aerospace and Biomedical Engineering, University of Tennessee, Knoxville, TN, USA; Department of Mechanical, Aerospace and Biomedical Engineering, University of Tennessee, Knoxville, TN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561043/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17037568607369942855&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Tennessee",
        "aff_unique_dep": "Department of Mechanical, Aerospace and Biomedical Engineering",
        "aff_unique_url": "https://www.utk.edu",
        "aff_unique_abbr": "UT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Knoxville",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560905",
        "title": "Reduced Dynamics and Control for an Autonomous Bicycle",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose the reduced model for the full dynamics of a bicycle and analyze its nonlinear behavior under a proportional control law for steering. Based on the Gibbs-Appell equations for the Whipple bicycle, we obtain a second-order nonlinear ordinary differential equation (ODE) that governs the bicycle\u2019s controlled motion. Two types of equilibrium points for the governing equation are found, which correspond to the bicycle\u2019s uniform straight forward and circular motions, respectively. By applying the Hurwitz criterion to the linearized equation, we find that the steer coefficient must be negative, consistent with the human\u2019s intuition of turning toward a fall. Under this condition, a critical angular velocity of the rear wheel exists, above which the uniform straight forward motion is stable, and slightly below which a pair of symmetrical stable uniform circular motions will occur. These theoretical findings are verified by both numerical simulations and experiments performed on a powered autonomous bicycle.",
        "primary_area": "",
        "author": "Jiaming Xiong;Bo Li;Ruihan Yu;Daolin Ma;Wei Wang;Caishan Liu;Jiaming Xiong;Bo Li;Ruihan Yu;Daolin Ma;Wei Wang;Caishan Liu",
        "authorids": "/37088998740;/37089000604;/37088999531;/37086410541;/37085846590;/37088998419;/37088998740;/37089000604;/37088999531;/37086410541;/37085846590;/37088998419",
        "aff": "College of Engineering, Peking University; School of Mechanical Engineering and Automation, Beihang University; College of Engineering, Peking University; Mechanical Engineering Department, Massachusetts Institute of Technology; School of Mechanical Engineering and Automation, Beihang University; College of Engineering, Peking University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560905/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1986069545771327515&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;1;0",
        "aff_unique_norm": "Peking University;Beihang University;Massachusetts Institute of Technology",
        "aff_unique_dep": "College of Engineering;School of Mechanical Engineering and Automation;Mechanical Engineering Department",
        "aff_unique_url": "http://www.pku.edu.cn;http://www.buaa.edu.cn;https://web.mit.edu",
        "aff_unique_abbr": "Peking U;Beihang;MIT",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9562026",
        "title": "Reducing the Deployment-Time Inference Control Costs of Deep Reinforcement Learning Agents via an Asymmetric Architecture",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning (DRL) has been demonstrated to provide promising results in several challenging decision making and control tasks. However, the required inference costs of deep neural networks (DNNs) could prevent DRL from being applied to mobile robots which cannot afford high energy-consuming computations. To enable DRL methods to be affordable in such energy-limited platforms, we propose an asymmetric architecture that reduces the overall inference costs via switching between a computationally expensive policy and an economic one. The experimental results evaluated on a number of representative benchmark suites for robotic control tasks demonstrate that our method is able to reduce the inference costs while retaining the agent\u2019s overall performance.",
        "primary_area": "",
        "author": "Chin-Jui Chang;Yu-Wei Chu;Chao-Hsien Ting;Hao-Kang Liu;Zhang-Wei Hong;Chun-Yi Lee;Chin-Jui Chang;Yu-Wei Chu;Chao-Hsien Ting;Hao-Kang Liu;Zhang-Wei Hong;Chun-Yi Lee",
        "authorids": "/37088996843;/37088997741;/37088996139;/37088997867;/37088998870;/37089775852;/37088996843;/37088997741;/37088996139;/37088997867;/37088998870;/37089775852",
        "aff": "Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu, Taiwan; Department of Computer Science, Elsa Lab, National Tsing Hua University, Hsinchu, Taiwan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562026/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11807301552695348089&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "National Tsing Hua University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.nthu.edu.tw",
        "aff_unique_abbr": "NTHU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561153",
        "title": "Reduction of Ground Impact of a Powered Exoskeleton by Shock Absorption Mechanism on the Shank",
        "track": "main",
        "status": "Poster",
        "abstract": "Powered exoskeletons for people with paraplegia are subjected to repetitive and large impacts due to the repeated ground contacts. The repetitive impact forces not only deteriorate the wear comfort but also cause a serious damage to the muscles and bones of the human wearing the powered exoskeleton. To address this issue, a novel shock absorption mechanism for powered exoskeletons that can reduce the peak of ground reaction force up to 28% is designed in this paper. The designed absorption mechanism is integrated into the WalkON Suit, a powered exoskeleton for people with paraplegia and verified by experimental results with a human subject in this paper also.",
        "primary_area": "",
        "author": "Jeongsu Park;Daeho Lee;Kyeong-Won Park;Kyoungchul Kong;Jeongsu Park;Daeho Lee;Kyeong-Won Park;Kyoungchul Kong",
        "authorids": "/37088690382;/37088998327;/37088687129;/37410344000;/37088690382;/37088998327;/37088687129;/37410344000",
        "aff": "Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea; Department of Mechanical Engineering, Korea Advanced Institute of Science and Technology, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561153/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14703193415433418085&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561797",
        "title": "Referring Image Segmentation via Language-Driven Attention",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper aims to tackle the problem of referring image segmentation, which is targeted at reasoning the region of interest referred by a query natural language sentence. One key issue to address the referring image segmentation is how to establish the cross-modal representation for encoding the two modalities, namely, the query sentence and the input image. Most existing methods are designed to concatenate the features from each modality or to gradually encode the cross-modal representation concerning each word\u2019s effect. In contrast, our approach leverages the correlation between the two modalities for constructing the cross-modal representation. To make the resulting cross-modal representation more discriminative for the segmentation task, we propose a novel mechanism of language-driven attention to encode the cross-modal representation for reflecting the attention between every single visual element and the entire query sentence. The proposed mechanism, named as Language-Driven Attention (LDA), first decouples the cross-modal correlation to channel-attention and spatial-attention and then integrates the two attentions for obtaining the cross-modal representation. The channel attention and the spatial attention respectively reveal how sensitive each channel or each pixel of a particular feature map is with respect to the query sentence. With a proper fusion of the two kinds of feature attention, the proposed LDA model can effectively guide the generation of the final cross-modal representation. The resulting representation is further strengthened for capturing the multi-receptive-field and multi-level-semantic for the intended segmentation. We assess our referring image segmentation model on four public benchmark datasets, and the experimental results show that our model achieves state-of-the-art performance",
        "primary_area": "",
        "author": "Ding-Jie Chen;He-Yen Hsieh;Tyng-Luh Liu;Ding-Jie Chen;He-Yen Hsieh;Tyng-Luh Liu",
        "authorids": "/37085406557;/37089404998;/37280956300;/37085406557;/37089404998;/37280956300",
        "aff": "Institute of Information Science, Academia Sinica, Taiwan; Institute of Information Science, Academia Sinica, Taiwan; Taiwan AI Labs",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561797/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8653873300655738206&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Academia Sinica;Taiwan AI Labs",
        "aff_unique_dep": "Institute of Information Science;",
        "aff_unique_url": "https://www.sinica.edu.tw;https://www.taiwanailabs.tw",
        "aff_unique_abbr": "AS;TAI Labs",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Taiwan",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561376",
        "title": "Region-Based Planning for 3D Within-Hand-Manipulation via Variable Friction Robot Fingers and Extrinsic Contacts",
        "track": "main",
        "status": "Poster",
        "abstract": "Attempts to achieve robotic Within-Hand-Manipulation (WIHM) generally utilize either high-DOF robotic hands with elaborate sensing apparatus or multi-arm robotic systems. In prior work we presented a simple robot hand with variable friction robot fingers, which allow a low-complexity approach to within-hand object translation and rotation, though this manipulation was limited to planar actions. In this work we extend the capabilities of this system to 3D manipulation with a novel region-based WIHM planning algorithm and utilizing extrinsic contacts. The ability to modulate finger friction enhances extrinsic dexterity for three-dimensional WIHM, and allows us to operate in the quasi-static level. The region-based planner automatically generates 3D manipulation sequences with a modified A* formulation that navigates the contact regions between the fingers and the object surface to reach desired regions. Central to this method is a set of object-motion primitives (i.e. within-hand sliding, rotation and pivoting), which can easily be achieved via changing contact friction. A wide range of goal regions can be achieved via this approach, which is demonstrated via real robot experiments following a standardized in-hand manipulation benchmarking protocol.",
        "primary_area": "",
        "author": "Alp Sahin;Adam J. Spiers;Berk Calli;Alp Sahin;Adam J. Spiers;Berk Calli",
        "authorids": "/37088922092;/38514763300;/37681653300;/37088922092;/38514763300;/37681653300",
        "aff": "Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, MA, USA; Electrical and Electronic Engineering Department, Imperial College London, London, United Kingdom; Robotics Engineering Program, Worcester Polytechnic Institute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561376/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4899825974487604457&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Worcester Polytechnic Institute;Imperial College London",
        "aff_unique_dep": "Robotics Engineering Program;Electrical and Electronic Engineering Department",
        "aff_unique_url": "https://www.wpi.edu;https://www.imperial.ac.uk",
        "aff_unique_abbr": "WPI;Imperial College",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Worcester;London",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9561138",
        "title": "Regularizing Action Policies for Smooth Control with Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "A critical problem with the practical utility of controllers trained with deep Reinforcement Learning (RL) is the notable lack of smoothness in the actions learned by the RL policies. This trend often presents itself in the form of control signal oscillation and can result in poor control, high power consumption, and undue system wear. We introduce Conditioning for Action Policy Smoothness (CAPS), an effective yet intuitive regularization on action policies, which offers consistent improvement in the smoothness of the learned state-to-action mappings of neural network controllers, reflected in the elimination of high-frequency components in the control signal. Tested on a real system, improvements in controller smoothness on a quadrotor drone resulted in an almost 80% reduction in power consumption while consistently training flight-worthy controllers. Project website: http://ai.bu.edu/caps",
        "primary_area": "",
        "author": "Siddharth Mysore;Bassel Mabsout;Renato Mancuso;Kate Saenko;Siddharth Mysore;Bassel Mabsout;Renato Mancuso;Kate Saenko",
        "authorids": "/37089000800;/37088997187;/37085344669;/37298968800;/37089000800;/37088997187;/37085344669;/37298968800",
        "aff": "Department of Computer Science, Boston University, Boston, MA; Department of Computer Science, Boston University, Boston, MA; Department of Computer Science, Boston University, Boston, MA; Department of Computer Science, Boston University, Boston, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561138/",
        "gs_citation": 106,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18205010383901614898&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Boston University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.bu.edu",
        "aff_unique_abbr": "BU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Boston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561223",
        "title": "Reinforced iLQR: A Sample-Efficient Robot Locomotion Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot locomotion is a major challenge in robotics. Model-based approaches are vulnerable to model errors, and incur high computation overhead resulted from long control horizon. Model-free approaches are trained with a large number of training samples, which are expensive to obtain. In this paper, we develop a hybrid control and learning framework, called Reinforced iLQR (RiLQR), which combines the advantages of model-based iLQR control with model-free RL policy learning to simultaneously achieve high sample efficiency, low computation overhead, and high robustness against model errors in robot locomotion. Through extensive evaluation on the Mujoco platform, we demonstrate that RiLQR outperforms the state-of-the-art model-based and model-free baselines by big margins in a set of tasks with different complexities.",
        "primary_area": "",
        "author": "Tongyu Zong;Liyang Sun;Yong Liu;Tongyu Zong;Liyang Sun;Yong Liu",
        "authorids": "/37086357659;/37086698770;/37292039600;/37086357659;/37086698770;/37292039600",
        "aff": "Electrical and Computer Engineering Department, Tandon School of Engineering, New York University, Brooklyn, NY, USA; Electrical and Computer Engineering Department, Tandon School of Engineering, New York University, Brooklyn, NY, USA; Electrical and Computer Engineering Department, Tandon School of Engineering, New York University, Brooklyn, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561223/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12355639423869580945&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "New York University",
        "aff_unique_dep": "Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.nyu.edu",
        "aff_unique_abbr": "NYU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Brooklyn",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561903",
        "title": "Reinforcement Learning Based Temporal Logic Control with Maximum Probabilistic Satisfaction",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a model-free reinforcement learning (RL) algorithm to synthesize a control policy that maximizes the satisfaction probability of complex tasks, which are expressed by linear temporal logic (LTL) specifications. Due to the consideration of environment and motion uncertainties, we model the robot motion as a probabilistic labeled Markov decision process (PL-MDP) with unknown transition probabilities and probabilistic labeling functions. The LTL task specification is converted to a limit deterministic generalized B\u00fcchi automaton (LDGBA) with several accepting sets to maintain dense rewards during learning. The novelty of applying LDGBA is to construct an embedded LDGBA (E-LDGBA) by designing a synchronous tracking-frontier function, which enables the record of non-visited accepting sets of LDGBA at each round of the repeated visiting pattern, to overcome the difficulties of directly applying conventional LDGBA. With appropriate dependent reward and discount functions, rigorous analysis shows that any method, which optimizes the expected discount return of the RL-based approach, is guaranteed to find the optimal policy to maximize the satisfaction probability of the LTL specifications. A model-free RL-based motion planning strategy is developed to generate the optimal policy in this paper. The effectiveness of the RL-based control synthesis is demonstrated via simulation and experimental results.",
        "primary_area": "",
        "author": "Mingyu Cai;Shaoping Xiao;Baoluo Li;Zhiliang Li;Zhen Kan;Mingyu Cai;Shaoping Xiao;Baoluo Li;Zhiliang Li;Zhen Kan",
        "authorids": "/37088336733;/37088944204;/37089000547;/37089000805;/37545883400;/37088336733;/37088944204;/37089000547;/37089000805;/37545883400",
        "aff": "Department of Mechanical Engineering, The University of Iowa, Iowa City, IA, USA; Department of Mechanical Engineering, The University of Iowa, Iowa City, IA, USA; Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China; Department of Automation, University of Science and Technology of China, Hefei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561903/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15600220591863830730&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;1",
        "aff_unique_norm": "University of Iowa;University of Science and Technology of China",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Automation",
        "aff_unique_url": "https://www.uiowa.edu;http://www.ustc.edu.cn",
        "aff_unique_abbr": "UIowa;USTC",
        "aff_campus_unique_index": "0;0;1;1;1",
        "aff_campus_unique": "Iowa City;Hefei",
        "aff_country_unique_index": "0;0;1;1;1",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9560927",
        "title": "Reinforcement Learning Control of A Novel Magnetic Actuated Flexible-joint Robotic Camera System for Single Incision Laparoscopic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes the control of a novel Magnetic Actuated Flexible-joint Robotic Surgical (MAFRS) camera system with four degrees of freedom (4-DOF) for single incision laparoscopic surgery. Based on the idea of motion decoupling, we designed a novel MAFRS system which is consists of an external driving device and a motor-free insertable wireless robotic device with a hollow flexible joint. Due to the problems of abdominal wall obstruction and variability in abdominal wall thickness during the actual application of the MAFRS system, as well as the existence of multiple permanent magnets and magnetically conductive media, high- precision position and attitude control of the insertable device without onboard motors has always been a challenge. We use the external driving device to generate a magnetic field to control the position and attitude of the internal robotic device. Aiming at the automatic precise tilt motion control of the novel MAFRS camera system, we have developed a closed-loop control scheme using the Deep Deterministic Policy Gradient (DDPG) algorithm. By referring to the damping characteristics of human muscles, a virtual-muscle method is proposed to eliminate the chattering problem of the MAFRS camera at specific angles. The experimental investigations indicate that the internal robotic device can be effectively controlled under different abdominal wall thicknesses. The tilt motion control accuracy is within 0.5\u00b0, and it has good adaptability and antiinterference performance.",
        "primary_area": "",
        "author": "Dong Xu;Yuanlin Zhang;Wenshuai Tan;Hongxing Wei;Dong Xu;Yuanlin Zhang;Wenshuai Tan;Hongxing Wei",
        "authorids": "/37714618300;/37088883670;/37087007070;/37540070400;/37714618300;/37088883670;/37087007070;/37540070400",
        "aff": "School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Automation Science and Electrical Engineering, Beihang University, Beijing, China; School of Mechanical Engineering and Automation, Beihang University, Beijing, China; School of Mechanical Engineering and Automation, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560927/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10995438345005246241&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Beihang University",
        "aff_unique_dep": "School of Automation Science and Electrical Engineering",
        "aff_unique_url": "http://www.buaa.edu.cn",
        "aff_unique_abbr": "BUAA",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562006",
        "title": "Reinforcement Learning for Autonomous Driving with Latent State Inference and Spatial-Temporal Relationships",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep reinforcement learning (DRL) provides a promising way for learning navigation in complex autonomous driving scenarios. However, identifying the subtle cues that can indicate drastically different outcomes remains an open problem with designing autonomous systems that operate in human environments. In this work, we show that explicitly inferring the latent state and encoding spatial-temporal relationships in a reinforcement learning framework can help address this difficulty. We encode prior knowledge on the latent states of other drivers through a framework that combines the reinforcement learner with a supervised learner. In addition, we model the influence passing between different vehicles through graph neural networks (GNNs). The proposed framework significantly improves performance in the context of navigating T-intersections compared with state-of-the-art baseline approaches.",
        "primary_area": "",
        "author": "Xiaobai Ma;Jiachen Li;Mykel J. Kochenderfer;David Isele;Kikuo Fujimura;Xiaobai Ma;Jiachen Li;Mykel J. Kochenderfer;David Isele;Kikuo Fujimura",
        "authorids": "/37085782899;/37086309095;/37596929200;/37086124264;/37269959700;/37085782899;/37086309095;/37596929200;/37086124264;/37269959700",
        "aff": "Stanford University; University of California, Berkeley; Stanford University; Honda Research Institute, US; Honda Research Institute, US",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562006/",
        "gs_citation": 80,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=846274084131473473&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;2;2",
        "aff_unique_norm": "Stanford University;University of California, Berkeley;Honda Research Institute",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.stanford.edu;https://www.berkeley.edu;https://honda-ri.com",
        "aff_unique_abbr": "Stanford;UC Berkeley;HRI",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Stanford;Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561440",
        "title": "Reinforcement Learning for Orientation Estimation Using Inertial Sensors with Performance Guarantee",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a deep reinforcement learning (DRL) algorithm for orientation estimation using inertial sensors combined with a magnetometer. Lyapunov\u2019s method in control theory is employed to prove the convergence of orientation estimation errors. The estimator gains and a Lyapunov function are parametrised by deep neural networks and learned from samples based on the theoretical results. The DRL estimator is compared with three well-known orientation estimation methods on both numerical simulations and real dataset collected from commercially available sensors. The results show that the proposed algorithm is superior for arbitrary estimation initialisation and can adapt to a drastic angular velocity profile for which other algorithms can be hardly applicable. To the best of our knowledge, this is the first DRL-based orientation estimation method with an estimation error boundedness guarantee.",
        "primary_area": "",
        "author": "Liang Hu;Yujie Tang;Zhipeng Zhou;Wei Pan;Liang Hu;Yujie Tang;Zhipeng Zhou;Wei Pan",
        "authorids": "/37086497663;/37088999709;/37088999687;/37088467306;/37086497663;/37088999709;/37088999687;/37088467306",
        "aff": "School of Computer Science and Electronic Engineering, University of Essex, UK; Department of Cognitive Robotics, Delft University of Technology, Netherlands; Department of Cognitive Robotics, Delft University of Technology, Netherlands; Department of Cognitive Robotics, Delft University of Technology, Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561440/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13508989734452094033&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "University of Essex;Delft University of Technology",
        "aff_unique_dep": "School of Computer Science and Electronic Engineering;Department of Cognitive Robotics",
        "aff_unique_url": "https://www.essex.ac.uk;https://www.tudelft.nl",
        "aff_unique_abbr": "Essex;TU Delft",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "United Kingdom;Netherlands"
    },
    {
        "id": "9560769",
        "title": "Reinforcement Learning for Robust Parameterized Locomotion Control of Bipedal Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Developing robust walking controllers for bipedal robots is a challenging endeavor. Traditional model-based locomotion controllers require simplifying assumptions and careful modelling; any small errors can result in unstable control. To address these challenges for bipedal locomotion, we present a model-free reinforcement learning framework for training robust locomotion policies in simulation, which can then be transferred to a real bipedal Cassie robot. To facilitate sim-to-real transfer, domain randomization is used to encourage the policies to learn behaviors that are robust across variations in system dynamics. The learned policies enable Cassie to perform a set of diverse and dynamic behaviors, while also being more robust than traditional controllers and prior learning-based methods that use residual control. We demonstrate this on versatile walking behaviors such as tracking a target walking velocity, walking height, and turning yaw. (Video1)",
        "primary_area": "",
        "author": "Zhongyu Li;Xuxin Cheng;Xue Bin Peng;Pieter Abbeel;Sergey Levine;Glen Berseth;Koushil Sreenath;Zhongyu Li;Xuxin Cheng;Xue Bin Peng;Pieter Abbeel;Sergey Levine;Glen Berseth;Koushil Sreenath",
        "authorids": "/37088691308;/37089260506;/37086454470;/37542877900;/37085481973;/37085864638;/37563179200;/37088691308;/37089260506;/37086454470;/37542877900;/37085481973;/37085864638;/37563179200",
        "aff": "University of California, Berkeley, CA, USA; University of California, Berkeley, CA, USA; University of California, Berkeley, CA, USA; University of California, Berkeley, CA, USA; University of California, Berkeley, CA, USA; University of California, Berkeley, CA, USA; University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560769/",
        "gs_citation": 287,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11398998058630843025&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561028",
        "title": "Relational Graph Learning on Visual and Kinematics Embeddings for Accurate Gesture Recognition in Robotic Surgery",
        "track": "main",
        "status": "Poster",
        "abstract": "Automatic surgical gesture recognition is fundamentally important to enable intelligent cognitive assistance in robotic surgery. With recent advancement in robot-assisted minimally invasive surgery, rich information including surgical videos and robotic kinematics can be recorded, which provide complementary knowledge for understanding surgical gestures. However, existing methods either solely adopt uni-modal data or directly concatenate multi-modal representations, which can not sufficiently exploit the informative correlations inherent in visual and kinematics data to boost gesture recognition accuracies. In this regard, we propose a novel online approach of multi-modal relational graph network (i.e., MRG-Net) to dynamically integrate visual and kinematics information through interactive message propagation in the latent feature space. In specific, we first extract embeddings from video and kinematics sequences with temporal convolutional networks and LSTM units. Next, we identify multi-relations in these multi-modal embeddings and leverage them through a hierarchical relational graph learning module. The effectiveness of our method is demonstrated with state-of-the-art results on the public JIGSAWS dataset, outperforming current uni-modal and multi-modal methods on both suturing and knot typing tasks. Furthermore, we validated our method on in-house visual-kinematics datasets collected with da Vinci Research Kit (dVRK) platforms in two centers, with consistent promising performance achieved. Our code and data are released at: https://www.cse.cuhk.edu.hk/~yhlong/mrgnet.html.",
        "primary_area": "",
        "author": "Yonghao Long;Jie Ying Wu;Bo Lu;Yueming Jin;Mathias Unberath;Yun-Hui Liu;Pheng Ann Heng;Qi Dou;Yonghao Long;Jie Ying Wu;Bo Lu;Yueming Jin;Mathias Unberath;Yun-Hui Liu;Pheng Ann Heng;Qi Dou",
        "authorids": "/37088902647;/37086575838;/37085991083;/37086369638;/37085410714;/37279412600;/37283077400;/37085465414;/37088902647;/37086575838;/37085991083;/37086369638;/37085410714;/37279412600;/37283077400;/37085465414",
        "aff": "Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong; Department of Computer Science and Engineering, The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561028/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2077288259014841681&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561884",
        "title": "Relational Navigation Learning in Continuous Action Space among Crowds",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, a novel navigation learning method in continuous action space among crowds based on relational graph is proposed which can be directly deployed on differential-drive mobile robots without any change. More specifically, in order to increase generalization ability in crowd sizes, Graph Convolutional Network (GCN) is at first adopted to extract the relationships between robot and pedestrians. Then the relation features are further utilized as the inputs of the pedestrian state prediction network, the actor network, and the critic network. To efficiently and safely learn the navigation policy, all networks are pretrained through imitating ORCA which is a state-of-the-art algorithm in crowd navigation, and then a model-based reinforcement learning (RL) method which combines the model prediction and the clipped advantage-weighted regression is proposed to finetune the networks. Finally, simulation experiments are performed and it\u2019s verified that the proposed learning method performs significantly better than ORCA and the other state-of-the-art RL methods.",
        "primary_area": "",
        "author": "Xueyou Zhang;Wei Xi;Xian Guo;Yongchun Fang;Bin Wang;Wulong Liu;Jianye Hao;Xueyou Zhang;Wei Xi;Xian Guo;Yongchun Fang;Bin Wang;Wulong Liu;Jianye Hao",
        "authorids": "/37086935688;/37088963088;/37085448334;/37293583100;/37089545154;/37088758367;/38008836600;/37086935688;/37088963088;/37085448334;/37293583100;/37089545154;/37088758367;/38008836600",
        "aff": "Institute of Robotics and Automatic Information System, College of Artificial Intelligence, Nankai University, China; Institute of Robotics and Automatic Information System, College of Artificial Intelligence, Nankai University, China; Institute of Robotics and Automatic Information System, College of Artificial Intelligence, Nankai University, China; Institute of Robotics and Automatic Information System, College of Artificial Intelligence, Nankai University, China; Noah's Ark Lab, Huawei Technologies, China; Noah's Ark Lab, Huawei Technologies, China; Noah's Ark Lab, Huawei Technologies, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561884/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=290431201918496546&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;1;1",
        "aff_unique_norm": "Nankai University;Huawei",
        "aff_unique_dep": "College of Artificial Intelligence;Noah's Ark Lab",
        "aff_unique_url": "http://www.nankai.edu.cn;https://www.huawei.com",
        "aff_unique_abbr": "Nankai;Huawei",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560747",
        "title": "Remote-Center-of-Motion Recommendation toward Brain Needle Intervention Using Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Brain needle intervention is a specific diagnosis and therapy procedure in brain disorders, such as brain tumors and Parkinson\u2019s disease. Preoperative needle path planning is a vital step to guarantee the patient\u2019s safety and reduce lesions. For positioning accuracy in the CT/MRI environment, we have developed a novel needle intervention robot in our previous work. Because the robot is currently designed for the rigid needle, the task of preoperative path-planning is to search for an optimal Remote Center of Motion (RCM) for needle insertion. Therefore, this work proposes an RCM recommendation system using deep reinforcement learning. Considering the robot kinematics, this system takes the following criteria/constraints into consideration: clinical obstacle (blood vessels, tissues) avoidance (COA), mechanically inverse kinematics (MIK) and mechanically less motion (MLM) for the robot. We design a reward function to combine the above three criteria based on their corresponding importance level and utilize proximal policy optimization (PPO) as the main agent of reinforcement learning (RL). RL methods are proved to be competent in searching the RCM, which satisfies the above criteria simultaneously. On the one hand, the results present that RL agents obtain the success rate of finishing the designed task at 93%, which has reached the human level in the tests. On the other hand, the RL agents have the remarkable capability of combining more complex criteria/constraints in future work.",
        "primary_area": "",
        "author": "Huxin Gao;Xiao Xiao;Liang Qiu;Max Q.-H. Meng;Nicolas Kon Kam King;Hongliang Ren;Huxin Gao;Xiao Xiao;Liang Qiu;Max Q.-H. Meng;Nicolas Kon Kam King;Hongliang Ren",
        "authorids": "/37088379696;/37086545706;/37086564321;/37274117000;/37086365786;/37287561300;/37088379696;/37086545706;/37086564321;/37274117000;/37086365786;/37287561300",
        "aff": "NUS (Suzhou) Research Institute, Suzhou, China; Department of Biomedical Engineering, National University of Singapore, Singapore; NUS (Suzhou) Research Institute, Suzhou, China; Department of Electronic Engineering, The Chinese University of Hong Kong; Department of Surgery, National University of Singapore, Singapore; NUS (Suzhou) Research Institute, Suzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560747/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14944273212475373605&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "National University of Singapore;Chinese University of Hong Kong",
        "aff_unique_dep": "Research Institute;Department of Electronic Engineering",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "NUS;CUHK",
        "aff_campus_unique_index": "0;0;2;0",
        "aff_campus_unique": "Suzhou;;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9560811",
        "title": "Replay Overshooting: Learning Stochastic Latent Dynamics with the Extended Kalman Filter",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents replay overshooting (RO), an algorithm that uses properties of the extended Kalman filter (EKF) to learn nonlinear stochastic latent dynamics models suitable for long-horizon prediction. We build upon overshooting methods used to train other prediction models and recover a novel variational learning objective. Further, we use RO to extend another objective that acts as a surrogate for the true log-likelihood, and show that this objective empirically yields better models than the variational one. We evaluate RO on two tasks: prediction of synthetic video frames of a swinging motorized pendulum and prediction of the planar position of various objects being pushed by a real manipulator (MIT Push Dataset). Our model outperforms several other prediction models on both quantitative and qualitative metrics.",
        "primary_area": "",
        "author": "Albert H. Li;Philipp Wu;Monroe Kennedy;Albert H. Li;Philipp Wu;Monroe Kennedy",
        "authorids": "/37086453130;/37088996542;/37089500447;/37086453130;/37088996542;/37089500447",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Covariant, Emeryville, CA, USA; Department of Mechanical Engineering, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560811/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2592502988271182994&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Stanford University;Covariant",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.stanford.edu;",
        "aff_unique_abbr": "Stanford;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Stanford;Emeryville",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560733",
        "title": "Representation Matters: Improving Perception and Exploration for Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Projecting high-dimensional environment observations into lower-dimensional structured representations can considerably improve data-efficiency for reinforcement learning in domains with limited data such as robotics. Can a single generally useful representation be found? In order to answer this question, it is important to understand how the representation will be used by the agent and what properties such a good representation should have. In this paper we systematically evaluate a number of common learnt and hand-engineered representations in the context of three robotics tasks: lifting, stacking and pushing of 3D blocks. The representations are evaluated in two use-cases: as input to the agent, or as a source of auxiliary tasks. Furthermore, the value of each representation is evaluated in terms of three properties: dimensionality, observability and disentanglement. We can significantly improve performance in both use-cases and demonstrate that some representations can perform commensurate to simulator states as agent inputs. Finally, our results challenge common intuitions by demonstrating that: 1) dimensionality strongly matters for task generation, but is negligible for inputs, 2) observability of task-relevant aspects mostly affects the input representation use-case, and 3) disentanglement leads to better auxiliary tasks, but has only limited benefits for input representations. This work serves as a step towards a more systematic understanding of what makes a good representation for control in robotics, enabling practitioners to make more informed choices for developing new learned or hand-engineered representations.",
        "primary_area": "",
        "author": "Markus Wulfmeier;Arunkumar Byravan;Tim Hertweck;Irina Higgins;Ankush Gupta;Tejas Kulkarni;Malcolm Reynolds;Denis Teplyashin;Roland Hafner;Thomas Lampe;Martin Riedmiller;Markus Wulfmeier;Arunkumar Byravan;Tim Hertweck;Irina Higgins;Ankush Gupta;Tejas Kulkarni;Malcolm Reynolds;Denis Teplyashin;Roland Hafner;Thomas Lampe;Martin Riedmiller",
        "authorids": "/37086199678;/37085466102;/37088997002;/37089000779;/37089268950;/37085643314;/37088996140;/37088995944;/37700945200;/37086719504;/37284689800;/37086199678;/37085466102;/37088997002;/37089000779;/37089268950;/37085643314;/37088996140;/37088995944;/37700945200;/37086719504;/37284689800",
        "aff": "DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom; DeepMind, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560733/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2216147056692820997&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 22,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "DeepMind",
        "aff_unique_dep": "",
        "aff_unique_url": "https://deepmind.com",
        "aff_unique_abbr": "DeepMind",
        "aff_campus_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561384",
        "title": "Reset-Free Reinforcement Learning via Multi-Task Learning: Learning Dexterous Manipulation Behaviors without Human Intervention",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement Learning (RL) algorithms can in principle acquire complex robotic skills by learning from large amounts of data in the real world, collected via trial and error. However, most RL algorithms use a carefully engineered setup in order to collect data, requiring human supervision and intervention to provide episodic resets. This is particularly evident in challenging robotics problems, such as dexterous manipulation. To make data collection scalable, such applications require reset-free algorithms that are able to learn autonomously, without explicit instrumentation or human intervention. Most prior work in this area handles single-task learning. However, we might also want robots that can perform large repertoires of skills. At first, this would appear to only make the problem harder. However, the key observation we make in this work is that an appropriately chosen multi-task RL setting actually alleviates the reset-free learning challenge, with minimal additional machinery required. In effect, solving a multi-task problem can directly solve the reset-free problem since different combinations of tasks can serve to perform resets for other tasks. By learning multiple tasks together and appropriately sequencing them, we can effectively learn all of the tasks together reset-free. This type of multi-task learning can effectively scale reset-free learning schemes to much more complex problems, as we demonstrate in our experiments. We propose a simple scheme for multi-task learning that tackles the reset-free learning problem, and show its effectiveness at learning to solve complex dexterous manipulation tasks in both hardware and simulation without any explicit resets. This work shows the ability to learn in-hand manipulation behaviors in the real world with RL without any human intervention.",
        "primary_area": "",
        "author": "Abhishek Gupta;Justin Yu;Tony Z. Zhao;Vikash Kumar;Aaron Rovinsky;Kelvin Xu;Thomas Devlin;Sergey Levine;Abhishek Gupta;Justin Yu;Tony Z. Zhao;Vikash Kumar;Aaron Rovinsky;Kelvin Xu;Thomas Devlin;Sergey Levine",
        "authorids": "/37085516247;/37088998060;/37088998362;/37077886400;/37088997834;/37089000064;/38511171800;/37085481973;/37085516247;/37088998060;/37088998362;/37077886400;/37088997834;/37089000064;/38511171800;/37085481973",
        "aff": "UC Berkeley; UC Berkeley; UC Berkeley; University of Washington; UC Berkeley; UC Berkeley; UC Berkeley; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561384/",
        "gs_citation": 118,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3599103681625497878&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;1;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley;University of Washington",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.washington.edu",
        "aff_unique_abbr": "UC Berkeley;UW",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560862",
        "title": "Residual Model Learning for Microrobot Control",
        "track": "main",
        "status": "Poster",
        "abstract": "A majority of microrobots are constructed using compliant materials that are difficult to model analytically, limiting the utility of traditional model-based controllers. Challenges in data collection on microrobots and large errors between simulated models and real robots make current model-based learning and sim-to-real transfer methods difficult to apply. We propose a novel framework residual model learning (RML) that leverages approximate models to substantially reduce the sample complexity associated with learning an accurate robot model. We show that using RML, we can learn a model of the Harvard Ambulatory MicroRobot (HAMR) using just 12 seconds of passively collected interaction data. The learned model is accurate enough to be leveraged as \"proxy-simulator\" for learning walking and turning behaviors using model-free reinforcement learning algorithms. RML provides a general framework for learning from extremely small amounts of interaction data, and our experiments with HAMR clearly demonstrate that RML substantially outperforms existing techniques.",
        "primary_area": "",
        "author": "Joshua Gruenstein;Tao Chen;Neel Doshi;Pulkit Agrawal;Joshua Gruenstein;Tao Chen;Neel Doshi;Pulkit Agrawal",
        "authorids": "/37089002155;/37089000331;/37085537968;/37085611190;/37089002155;/37089000331;/37085537968;/37085611190",
        "aff": "Improbable AI Lab, which is part of the Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA; Improbable AI Lab, which is part of the Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA; Department of Mechanical Engineering, Massachusetts Institute of Technology, Cambridge, MA; Improbable AI Lab, which is part of the Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560862/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2203530248574122940&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561836",
        "title": "Residual Squeeze-and-Excitation Network with Multi-scale Spatial Pyramid Module for Fast Robotic Grasping Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes an efficient, fully convolutional neural network to generate robotic grasps by using 300\u00d7300 depth images as input. Specifically, a residual squeeze-and-excitation network (RSEN) is introduced for deep feature extraction. Following the RSEN block, a multi-scale spatial pyramid module (MSSPM) is developed to obtain multi-scale contextual information. The outputs of each RSEN block and MSSPM are combined as inputs for hierarchical feature fusion. Then, the fused global features are upsampled to perform pixel-wise learning for grasping pose estimation. The experimental results on Cornell and Jacquard grasping datasets indicate that the proposed method has a fast inference speed of 5ms while achieving high grasp detection accuracy of 96.4% and 94.8% on Cornell and Jacquard, respectively, which strikes a balance between accuracy and running speed. Our method also gets a 90% physical grasp success rate with a UR5 robot arm.",
        "primary_area": "",
        "author": "Hu Cao;Guang Chen;Zhijun Li;Jianjie Lin;Alois Knoll;Hu Cao;Guang Chen;Zhijun Li;Jianjie Lin;Alois Knoll",
        "authorids": "/37088505645;/38251904000;/37309823400;/37088691130;/37276234100;/37088505645;/38251904000;/37309823400;/37088691130;/37276234100",
        "aff": "State Key Laboratory of Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences; State Key Laboratory of Management and Control of Complex Systems, Institute of Automation, Chinese Academy of Sciences; University of Science and Technology of China, China; Chair of Robotics, Artificial Intelligence and Real-Time Systems, Technische Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany; Chair of Robotics, Artificial Intelligence and Real-Time Systems, Technische Universit\u00e4t M\u00fcnchen, M\u00fcnchen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561836/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10904210937197749368&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;2",
        "aff_unique_norm": "Chinese Academy of Sciences;University of Science and Technology of China;Technische Universit\u00e4t M\u00fcnchen",
        "aff_unique_dep": "Institute of Automation;;Chair of Robotics, Artificial Intelligence and Real-Time Systems",
        "aff_unique_url": "http://www.ia.cas.cn;http://www.ustc.edu.cn;https://www.tum.de",
        "aff_unique_abbr": "CAS;USTC;TUM",
        "aff_campus_unique_index": "1;1",
        "aff_campus_unique": ";M\u00fcnchen",
        "aff_country_unique_index": "0;0;0;1;1",
        "aff_country_unique": "China;Germany"
    },
    {
        "id": "9561999",
        "title": "Resilient Collision-tolerant Navigation in Confined Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This work presents the design and autonomous navigation policy of the Resilient Micro Flyer, a new type of collision-tolerant robot tailored to fly through extremely confined environments and manhole-sized tubes. The robot maintains a low weight (<500g) and implements a combined rigid-compliant design through the integration of elastic flaps around its stiff collision-tolerant frame. These passive flaps ensure compliant collisions, contact sensing and smooth navigation in contact with the environment. Focusing on resilient autonomy, capable of running on resource-constrained hardware, we demonstrate the beneficial role of compliant collisions for the reliability of the onboard visual-inertial odometry and propose a safe navigation policy that exploits both collision-avoidance using lightweight time-of-flight sensing and adaptive control in response to collisions. The robot further realizes an explicit manhole navigation mode that exploits the direct mechanical feedback provided by the flaps and a special navigation strategy to self-align inside manholes with non-straight geometry. Comprehensive experimental studies are presented to evaluate, both individually and as a whole, how resilience is achieved based on the robot design and its navigation scheme.",
        "primary_area": "",
        "author": "Paolo De Petris;Huan Nguyen;Mihir Kulkarni;Frank Mascarich;Kostas Alexis;Paolo De Petris;Huan Nguyen;Mihir Kulkarni;Frank Mascarich;Kostas Alexis",
        "authorids": "/37089002113;/37088471319;/37088998874;/37086409687;/37546514600;/37089002113;/37088471319;/37088998874;/37086409687;/37546514600",
        "aff": "NTNU, Trondheim, Norway; NTNU, Trondheim, Norway; University of Nevada, Reno, NV, USA; University of Nevada, Reno, NV, USA; NTNU, Trondheim, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561999/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18235162661050268582&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Norwegian University of Science and Technology;University of Nevada, Reno",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.ntnu.no;https://www.unr.edu",
        "aff_unique_abbr": "NTNU;UNR",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Trondheim;Reno",
        "aff_country_unique_index": "0;0;1;1;0",
        "aff_country_unique": "Norway;United States"
    },
    {
        "id": "9561531",
        "title": "Restoring Force Design of Active Self-healing Tension Transmission System and Application to Tendon-driven Legged Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-healing function is a promising approach for damage management of high-load robot applications such as legged robots. Although the function is getting major in soft robotics, its application to life-sized \"stiff\" robots is of relatively minor interest. Although the authors have devised several self-healing tensile modules for tendon-driven robots, the design guideline to satisfy the large load endurance and large stroke is still unclear. The paper focuses on the parametric design for unleaked liquid-assisted healing of low melting point alloy structure. The method was validated with a benchtop module test. Moreover, the module enabled tendon-driven monopod testbed to perform squat motion three times after the landing impact fracture and the self-healing sequence, which was never accomplished.",
        "primary_area": "",
        "author": "Shinsuke Nakashima;Kento Kawaharazuka;Manabu Nishiura;Yuki Asano;Yohei Kakiuchi;Kei Okada;Koji Kawasaki;Masayuki Inaba;Shinsuke Nakashima;Kento Kawaharazuka;Manabu Nishiura;Yuki Asano;Yohei Kakiuchi;Kei Okada;Koji Kawasaki;Masayuki Inaba",
        "authorids": "/37086104250;/37086101930;/37088690295;/38238750500;/38242437800;/37280639000;/37085684621;/37286658200;/37086104250;/37086101930;/37088690295;/38238750500;/38242437800;/37280639000;/37085684621;/37286658200",
        "aff": "Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan; TOYOTA MOTOR CORPORATION; Department of Mechano-Infomatics, The University of Tokyo, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561531/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5185709964173851775&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;1;0",
        "aff_unique_norm": "University of Tokyo;Toyota Motor Corporation",
        "aff_unique_dep": "Department of Mechano-Infomatics;",
        "aff_unique_url": "https://www.u-tokyo.ac.jp;https://www.toyota-global.com",
        "aff_unique_abbr": "UTokyo;Toyota",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo;",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561157",
        "title": "RetinaGAN: An Object-aware Approach to Sim-to-Real Transfer",
        "track": "main",
        "status": "Poster",
        "abstract": "The success of deep reinforcement learning (RL) and imitation learning (IL) in vision-based robotic manipulation typically hinges on the expense of large scale data collection. With simulation, data to train a policy can be collected efficiently at scale, but the visual gap between sim and real makes deployment in the real world difficult. We introduce RetinaGAN, a generative adversarial network (GAN) approach to adapt simulated images to realistic ones with object-detection consistency. RetinaGAN is trained in an unsupervised manner without task loss dependencies, and preserves general object structure and texture in adapted images. We evaluate our method on three real world tasks: grasping, pushing, and door opening. RetinaGAN improves upon the performance of prior sim-to-real methods for RL-based object instance grasping and continues to be effective even in the limited data regime. When applied to a pushing task in a similar visual domain, RetinaGAN demonstrates transfer with no additional real data requirements. We also show our method bridges the visual gap for a novel door opening task using imitation learning in a new visual domain. Visit the project website at retinagan.github.io",
        "primary_area": "",
        "author": "Daniel Ho;Kanishka Rao;Zhuo Xu;Eric Jang;Mohi Khansari;Yunfei Bai;Daniel Ho;Kanishka Rao;Zhuo Xu;Eric Jang;Mohi Khansari;Yunfei Bai",
        "authorids": "/37267934200;/37085665583;/37089405343;/37086455574;/37088456107;/37086454356;/37267934200;/37085665583;/37089405343;/37086455574;/37088456107;/37086454356",
        "aff": "Everyday Robots, X The Moonshot Factory, Mountain View, CA, USA; Robotics at Google, Mountain View, CA, USA; University of California, Berkeley, Berkeley, CA, USA; Robotics at Google, Mountain View, CA, USA; Everyday Robots, X The Moonshot Factory, Mountain View, CA, USA; Everyday Robots, X The Moonshot Factory, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561157/",
        "gs_citation": 115,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5240059540001185588&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;0",
        "aff_unique_norm": "Google;University of California, Berkeley",
        "aff_unique_dep": "Everyday Robots;",
        "aff_unique_url": "https://xdev.llc;https://www.berkeley.edu",
        "aff_unique_abbr": "X Dev;UC Berkeley",
        "aff_campus_unique_index": "0;0;1;0;0;0",
        "aff_campus_unique": "Mountain View;Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560987",
        "title": "Retrieval and Localization with Observation Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Accurate visual re-localization is very critical to many artificial intelligence applications, such as augmented reality, virtual reality, robotics and autonomous driving. To accomplish this task, we propose an integrated visual re-localization method called RLOCS by combining image retrieval, semantic consistency and geometry verification to achieve accurate estimations. The localization pipeline is designed as a coarse-to-fine paradigm. In the retrieval part, we cascade the architecture of ResNet101-GeM-ArcFace and employ DBSCAN followed by spatial verification to obtain a better initial coarse pose. We design a module called observation constraints, which combines geometry information and semantic consistency for filtering outliers. Comprehensive experiments are conducted on open datasets, including retrieval on R-Oxford5k and R-Paris6k, semantic segmentation on Cityscapes, localization on Aachen Day-Night and InLoc. By creatively modifying separate modules in the total pipeline, our method achieves many performance improvements on the challenging localization benchmarks.",
        "primary_area": "",
        "author": "Yuhao Zhou;Huanhuan Fan;Shuang Gao;Yuchen Yang;Xudong Zhang;Jijunnan Li;Yandong Guo;Yuhao Zhou;Huanhuan Fan;Shuang Gao;Yuchen Yang;Xudong Zhang;Jijunnan Li;Yandong Guo",
        "authorids": "/37088998069;/37089400706;/37088995862;/37088996325;/37088687401;/37088999430;/37087008648;/37088998069;/37089400706;/37088995862;/37088996325;/37088687401;/37088999430;/37087008648",
        "aff": "OPPO Research Institute, Shanghai, China; OPPO Research Institute, Shanghai, China; OPPO Research Institute, Shanghai, China; OPPO Research Institute, Shanghai, China; OPPO Research Institute, Shanghai, China; OPPO Research Institute, Shanghai, China; OPPO Research Institute, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560987/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12985766266164382524&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "OPPO Research Institute",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.oppo.com",
        "aff_unique_abbr": "OPPO RI",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560897",
        "title": "Reward Conditioned Neural Movement Primitives for Population-Based Variational Policy Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper aims to study the reward-based policy exploration problem in a supervised learning approach and enable robots to form complex movement trajectories in challenging reward settings and search spaces. For this, the experience of the robot, which can be bootstrapped from demonstrated trajectories, is used to train a novel Neural Processes-based deep network that samples from its latent space and generates the required trajectories given desired rewards. Our framework can generate progressively improved trajectories by sampling them from high reward landscapes, increasing the reward gradually. Variational inference is used to create a stochastic latent space to sample varying trajectories in generating a population of trajectories given target rewards. We benefit from Evolutionary Strategies and propose a novel crossover operation, which is applied in the self-organized latent space of the individual policies, allowing blending of the individuals that might address different factors in the reward function. Using a number of tasks that require sequential reaching to multiple points or passing through gaps between objects, we showed that our method provides stable learning progress and significantly higher sample efficiency compared to a number of state-of-the-art robotic reinforcement learning methods. Finally, we show the real-world suitability of our method through real robot execution involving obstacle avoidance.",
        "primary_area": "",
        "author": "M. Tuluhan Akbulut;Utku Bozdogan;Ahmet Tekden;Emre Ugur;M. Tuluhan Akbulut;Utku Bozdogan;Ahmet Tekden;Emre Ugur",
        "authorids": "/37088999445;/37089000682;/37086881827;/37947264700;/37088999445;/37089000682;/37086881827;/37947264700",
        "aff": "Department of Computer Engineering, Bogazici University, Turkey; Department of Computer Engineering, Bogazici University, Turkey; Department of Computer Engineering, Bogazici University, Turkey; Department of Computer Engineering, Bogazici University, Turkey",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560897/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3681150880128639895&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Bogazici University",
        "aff_unique_dep": "Department of Computer Engineering",
        "aff_unique_url": "https://www.boun.edu.tr",
        "aff_unique_abbr": "BU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "T\u00fcrkiye"
    },
    {
        "id": "9561927",
        "title": "Reward Machines for Vision-Based Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep Q learning (DQN) has enabled robot agents to accomplish vision based tasks that seemed out of reach. Despite recent success stories, there are still several sources of computational complexity that challenge the performance of DQN. We place the focus on vision manipulation tasks, where the correct action selection is often predicated on a small number of pixels. We observe that in some of these tasks DQN does not converge to the optimal Q function, and their values do not separate well optimal and suboptimal actions. In consequence, the policies obtained with DQN tend to be brittle and manifest a low success rate, especially in long horizon tasks. In this work we show the benefits of Reward Machines (RMs) for Deep Q learning (DQRM) in vision based robot manipulation tasks. Reward machines decompose the task at an abstract level, inform the agent about their current stage along task completion, and guide them via dense rewards. We show that RMs help DQN learn the optimal Q values in each abstract state. Their policies are more robust, manifest higher success rate, and are learned with fewer training steps compared with DQN. The benefits of RMs are more evident in long-horizon tasks, where we show that DQRM is able to learn good-quality policies with six times times fewer training steps than DQN, even when this is equipped with dense reward shaping.",
        "primary_area": "",
        "author": "Alberto Camacho;Jacob Varley;Andy Zeng;Deepali Jain;Atil Iscen;Dmitry Kalashnikov;Alberto Camacho;Jacob Varley;Andy Zeng;Deepali Jain;Atil Iscen;Dmitry Kalashnikov",
        "authorids": "/37088996745;/37085632898;/37086217185;/37087325315;/37085362056;/37279222800;/37088996745;/37085632898;/37086217185;/37087325315;/37085362056;/37279222800",
        "aff": "Robotics at Google, New York; Robotics at Google, New York; Robotics at Google, New York; Robotics at Google, New York; Robotics at Google, New York; Robotics at Google, New York",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561927/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3350046206125200975&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Google",
        "aff_unique_dep": "Robotics",
        "aff_unique_url": "https://www.google.com",
        "aff_unique_abbr": "Google Robotics",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560871",
        "title": "Risk-Aware Decision Making for Service Robots to Minimize Risk of Patient Falls in Hospitals",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning under uncertainty is a crucial capability for autonomous systems to operate reliably in uncertain and dynamic environments. The concern of safety becomes even more critical in healthcare settings where robots interact with human patients. In this paper, we propose a novel risk-aware planning framework to minimize the risk of falls by providing a patient with an assistive device. Our approach combines learning-based prediction with model-based control to plan for the fall prevention task. This provides advantages compared to end-to-end learning methods in which the robot's performance is limited to specific scenarios, or purely model-based approaches that use relatively simple function approximators and are prone to high modeling errors. We compare various risk metrics and the results from simulated scenarios show that using the proposed cost function, the robot can plan interventions to avoid high fall score events.",
        "primary_area": "",
        "author": "Roya Sabbagh Novin;Amir Yazdani;Andrew Merryweather;Tucker Hermans;Roya Sabbagh Novin;Amir Yazdani;Andrew Merryweather;Tucker Hermans",
        "authorids": "/37085576685;/37086578140;/37086281901;/38230909600;/37085576685;/37086578140;/37086281901;/38230909600",
        "aff": "Department of Mechanical Engineering and Utah Robotics Center, University of Utah, Salt Lake City, Utah, USA; Department of Mechanical Engineering and Utah Robotics Center, University of Utah, Salt Lake City, Utah, USA; Department of Mechanical Engineering and Utah Robotics Center, University of Utah, Salt Lake City, Utah, USA; School of Computing and Utah Robotics Center, University of Utah, Salt Lake City, Utah, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560871/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12537655724878518797&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Utah",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.utah.edu",
        "aff_unique_abbr": "U of U",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Salt Lake City",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560962",
        "title": "Risk-Conditioned Distributional Soft Actor-Critic for Risk-Sensitive Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Modern navigation algorithms based on deep reinforcement learning (RL) show promising efficiency and robustness. However, most deep RL algorithms operate in a risk-neutral manner, making no special attempt to shield users from relatively rare but serious outcomes, even if such shielding might cause little loss of performance. Furthermore, such algorithms typically make no provisions to ensure safety in the presence of inaccuracies in the models on which they were trained, beyond adding a cost-of-collision and some domain randomization while training, in spite of the formidable complexity of the environments in which they operate. In this paper, we present a novel distributional RL algorithm that not only learns an uncertainty-aware policy, but can also change its risk measure without expensive fine-tuning or retraining. Our method shows superior performance and safety over baselines in partially- observed navigation tasks. We also demonstrate that agents trained using our method can adapt their policies to a wide range of risk measures at run-time.",
        "primary_area": "",
        "author": "Jinyoung Choi;Christopher Dance;Jung-Eun Kim;Seulbin Hwang;Kyung-Sik Park;Jinyoung Choi;Christopher Dance;Jung-Eun Kim;Seulbin Hwang;Kyung-Sik Park",
        "authorids": "/37086937006;/37088506073;/37088506777;/37088999285;/37086937707;/37086937006;/37088506073;/37088506777;/37088999285;/37086937707",
        "aff": "Naver Labs, Gyeonggi-do, South Korea; Naver Labs Europe, Meylan, France; Naver Labs, Gyeonggi-do, South Korea; Naver Labs, Gyeonggi-do, South Korea; Naver Labs, Gyeonggi-do, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560962/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6577626341074960259&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "NAVER LABS;NAVER LABS Europe",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.navercorp.com/en/labs;https://labs.naver.com",
        "aff_unique_abbr": "Naver Labs;NLE",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Meylan",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "South Korea;France"
    },
    {
        "id": "9561710",
        "title": "Robot Action Diagnosis and Experience Correction by Falsifying Parameterised Execution Models",
        "track": "main",
        "status": "Poster",
        "abstract": "When faced with an execution failure, an intelligent robot should be able to identify the likely reasons for the failure and adapt its execution policy accordingly. This paper addresses the question of how to utilise knowledge about the execution process, expressed in terms of learned constraints, in order to direct the diagnosis and experience acquisition process. In particular, we present two methods for creating a synergy between failure diagnosis and execution model learning. We first propose a method for diagnosing execution failures of parameterised action execution models, which searches for action parameters that violate a learned precondition model. We then develop a strategy that uses the results of the diagnosis process for generating synthetic data that are more likely to lead to successful execution, thereby increasing the set of available experiences to learn from. The diagnosis and experience correction methods are evaluated for the problem of handle grasping, such that we experimentally demonstrate the effectiveness of the diagnosis algorithm and show that corrected failed experiences can contribute towards improving the execution success of a robot.",
        "primary_area": "",
        "author": "Alex Mitrevski;Paul G. Pl\u00f6ger;Gerhard Lakemeyer;Alex Mitrevski;Paul G. Pl\u00f6ger;Gerhard Lakemeyer",
        "authorids": "/37086062289;/37344552000;/38533030900;/37086062289;/37344552000;/38533030900",
        "aff": "Department of Computer Science, Hochschule Bonn-Rhein-Sieg, Sankt Augustin, Germany; Department of Computer Science, Hochschule Bonn-Rhein-Sieg, Sankt Augustin, Germany; Department of Computer Science, RWTH Aachen University, Aachen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561710/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8697582058694966557&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Hochschule Bonn-Rhein-Sieg;RWTH Aachen University",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.h-brs.de;https://www.rwth-aachen.de",
        "aff_unique_abbr": ";RWTH",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Sankt Augustin;Aachen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561180",
        "title": "Robot Arm Motion Planning Based on Geodesics",
        "track": "main",
        "status": "Poster",
        "abstract": "Naturally, finding joint trajectories for robotic manipulators involves competing optimization goals. On the one hand, the end-effector should move along a predictable and short path while on the other hand joint movement and acceleration should be kept to a minimum. Obstacles in the workspace or joint limits complicate the situation even further. Constructing a metric that makes undesired configurations more expensive to travel through, we equip the joint space with a notion of cost. The motion planning task then reduces to the problem of finding cheapest paths connecting two configurations \u2013 so-called geodesics. We show how to construct suitable metrics for a variety of typical scenarios and present an efficient algorithm for the computation of the corresponding geodesics. Our approach makes it very easy to balance different optimization goals and produces natural and smooth manipulator movement.",
        "primary_area": "",
        "author": "Mario Laux;Andreas Zell;Mario Laux;Andreas Zell",
        "authorids": "/37089000145;/37276583400;/37089000145;/37276583400",
        "aff": "Department of Computer Science, Chair of Cognitive Systems, University of T\u00fcbingen, T\u00fcbingen, Germany; Department of Computer Science, Chair of Cognitive Systems, University of T\u00fcbingen, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561180/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11391898355509346581&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of T\u00fcbingen",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.uni-tuebingen.de",
        "aff_unique_abbr": "Uni T\u00fcbingen",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561405",
        "title": "Robot Development and Path Planning for Indoor Ultraviolet Light Disinfection",
        "track": "main",
        "status": "Poster",
        "abstract": "Regular irradiation of indoor environments with ultraviolet C (UVC) light has become a regular task for many in-door settings as a result of COVID-19, but current robotic systems attempting to automate it suffer from high costs and inefficient irradiation. In this paper, we propose a purpose-made inexpensive robotic platform with off-the-shelf components and standard navigation software that, with a novel algorithm for finding optimal irradiation locations, addresses both shortcomings to offer affordable and efficient solutions for UVC irradiation. We demonstrate in simulations the efficacy of the algorithm and show a prototypical run of the autonomous integrated robotic system in an indoor environment. In our sample instances, our proposed algorithm reduces the time needed by roughly 30% while it increases the coverage by a factor of 35% (when compared to the best possible placement of a static light).",
        "primary_area": "",
        "author": "Jonathan Conroy;Christopher Thierauf;Parker Rule;Evan Krause;Hugo Akitaya;Andrei Gonczi;Matias Korman;Matthias Scheutz;Jonathan Conroy;Christopher Thierauf;Parker Rule;Evan Krause;Hugo Akitaya;Andrei Gonczi;Matias Korman;Matthias Scheutz",
        "authorids": "/37088997603;/37088545899;/37088998310;/38488950700;/37088996474;/37089002137;/37089002161;/37269589600;/37088997603;/37088545899;/37088998310;/38488950700;/37088996474;/37089002137;/37089002161;/37269589600",
        "aff": "Tufts University, MA, USA; Tufts University, MA, USA; Tufts University, MA, USA; Tufts University, MA, USA; University of Massachusetts Lowell, MA, USA; Tufts University, MA, USA; Siemens Electronic Design Automation, OR, USA; Tufts University, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561405/",
        "gs_citation": 26,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18053833276126955185&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;1;0;2;0",
        "aff_unique_norm": "Tufts University;University of Massachusetts Lowell;Siemens",
        "aff_unique_dep": ";;Electronic Design Automation",
        "aff_unique_url": "https://www.tufts.edu;https://www.uml.edu;https://www.siemens.com",
        "aff_unique_abbr": "Tufts;UMass Lowell;Siemens",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Lowell;OR",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561292",
        "title": "Robot Interaction Studio: A Platform for Unsupervised HRI",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots hold great potential for supporting exercise and physical therapy, but such systems are often cumbersome to set up and require expert supervision. We aim to solve these concerns by combining Captury Live, a real-time markerless motion-capture system, with a Rethink Robotics Baxter Research Robot to create the Robot Interaction Studio. We evaluated this platform for unsupervised human-robot interaction (HRI) through a 75-minute-long user study with seven adults who were given minimal instructions and no feedback about their actions. The robot used sounds, facial expressions, facial colors, head motions, and arm motions to sequentially present three categories of cues in randomized order while constantly rotating its face screen to look at the user. Analysis of the captured user motions shows that the cue type significantly affected the distance subjects traveled and the amount of time they spent within the robot\u2019s reachable workspace, in alignment with the design of the cues. Heat map visualizations of the recorded user hand positions confirm that users tended to mimic the robot\u2019s arm poses. Despite some initial frustration, taking part in this study did not significantly change user opinions of the robot. We reflect on the advantages of the proposed approach to unsupervised HRI as well as the limitations and possible future extensions of our system.",
        "primary_area": "",
        "author": "Mayumi Mohan;Cara M. Nunez;Katherine J. Kuchenbecker;Mayumi Mohan;Cara M. Nunez;Katherine J. Kuchenbecker",
        "authorids": "/37075659700;/37086377274;/37297463900;/37075659700;/37086377274;/37297463900",
        "aff": "Haptic Intelligence Department, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Bioengineering and Mechanical Engineering Departments, Stanford University, CA, USA; Haptic Intelligence Department, Max Planck Institute for Intelligent Systems, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561292/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2466414125724280113&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;Stanford University",
        "aff_unique_dep": "Haptic Intelligence Department;Bioengineering and Mechanical Engineering Departments",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.stanford.edu",
        "aff_unique_abbr": "MPI-IS;Stanford",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Stuttgart;Stanford",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9560901",
        "title": "Robot Learning of 6 DoF Grasping using Model-based Adaptive Primitives",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot learning is often simplified to planar manipulation due to its data consumption. Then, a common approach is to use a fully-convolutional neural network (FCNN) to estimate the reward of grasp primitives. In this work, we extend this approach by parametrizing the two remaining, lateral degrees of freedom (DoFs) of the primitives. We apply this principle to the task of 6 DoF bin picking: We introduce a model-based controller to calculate angles that avoid collisions, maximize the grasp quality while keeping the uncertainty small. As the controller is integrated into the training, our hybrid approach is able to learn about and exploit the model-based controller. After real-world training of 27 000 grasp attempts, the robot is able to grasp known objects with a success rate of over 92 % in dense clutter. Grasp inference takes less than 50 ms. In further real-world experiments, we evaluate grasp rates in a range of scenarios including its ability to generalize to unknown objects. We show that the system is able to avoid collisions, enabling grasps that would not be possible without primitive adaption.",
        "primary_area": "",
        "author": "Lars Berscheid;Christian Friedrich;Torsten Kr\u00f6ger;Lars Berscheid;Christian Friedrich;Torsten Kr\u00f6ger",
        "authorids": "/37085380166;/37085812903;/37283223400;/37085380166;/37085812903;/37283223400",
        "aff": "Karlsruhe Institute of Technology (KIT), Germany; SCHUNK GmbH & Co. KG, Lauffen am Neckar, Germany; Karlsruhe Institute of Technology (KIT), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560901/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6435402850638652442&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology;SCHUNK GmbH & Co. KG",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.kit.edu;https://www.schunk.com",
        "aff_unique_abbr": "KIT;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561080",
        "title": "Robot Motion Control with Compressive Feedback",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot motion control aims to generate control inputs for a robotic system to track a planned trajectory. Feedback provided by sensors plays an essential role in motion control by improving system performance when external disturbances and/or initial errors exist. However, feedback signals, such as images are often of a large size, which imposes a heavy computational burden on the system. In this paper, a new robot motion control scheme is proposed based on compressive feedback to improve feedback rate. The controller is designed in non-vector space using compressive feedback. As an application, visual servoing is formulated under the proposed framework by considering a feedback image as a set, instead of a traditional feature vector. Experiments are conducted to validate the proposed scheme.",
        "primary_area": "",
        "author": "Congjian Li;Song Wang;Siyu Wang;Sheng Bi;Yisheng Guan;Ning Xi;Congjian Li;Song Wang;Siyu Wang;Sheng Bi;Yisheng Guan;Ning Xi",
        "authorids": "/37086076234;/37086815217;/37086357351;/37392469800;/37402001000;/37274126400;/37086076234;/37086815217;/37086357351;/37392469800;/37402001000;/37274126400",
        "aff": "Faculty of Engineering, The University of Hong Kong, Hong Kong; Faculty of Engineering, The University of Hong Kong, Hong Kong; Faculty of Engineering, The University of Hong Kong, Hong Kong; Faculty of Engineering, The University of Hong Kong, Hong Kong; Biomimetic and Intelligent Robotics Lab (BIRL), Guangdong University Of Technology, Guangzhou, China; Faculty of Engineering, The University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561080/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4033659729949305980&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "University of Hong Kong;Guangdong University of Technology",
        "aff_unique_dep": "Faculty of Engineering;Biomimetic and Intelligent Robotics Lab (BIRL)",
        "aff_unique_url": "https://www.hku.hk;",
        "aff_unique_abbr": "HKU;",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Hong Kong SAR;Guangzhou",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560921",
        "title": "Robot Motion Planning with Human-Like Motion Patterns based on Human Arm Movement Primitive Chains",
        "track": "main",
        "status": "Poster",
        "abstract": "A novel motion planning method is proposed to generate human-like motion for anthropomorphic robot arms. Its highlight is to consider the robot arm to be human-like not only in its configuration but also in its motion patterns. To achieve this, the intrinsic mechanisms of human arm motion generation are transferred to robot motion planning. First, human arm motion is modeled using human arm motion primitives. The mechanisms of human arm motion generation are dissected from a large number of motion samples, reflected in the types, sequencing and quantification rules/laws of the primitives. Next, the human arm motion patterns are studied based on primitive chains. Finally, a new motion planning method is built that autonomously performs motion pattern decisions, motion time allocation, and joint trajectory generation. The proposed method is validated by a motion planning app and a robot simulation.",
        "primary_area": "",
        "author": "Shiqiu Gong;Jing Zhao;Biyun Xie;Shiqiu Gong;Jing Zhao;Biyun Xie",
        "authorids": "/37088839706;/37089397147;/37848979900;/37088839706;/37089397147;/37848979900",
        "aff": "College of Mechanical Engineering and Applied Electronics Technology, Beijing University of Technology, China; College of Mechanical Engineering and Applied Electronics Technology, Beijing University of Technology, China; Department of Electrical and Computer Engineering, University of Kentucky, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560921/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3174274115839574695&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Beijing University of Technology;University of Kentucky",
        "aff_unique_dep": "College of Mechanical Engineering and Applied Electronics Technology;Department of Electrical and Computer Engineering",
        "aff_unique_url": "http://www.bjut.edu.cn;https://www.uky.edu",
        "aff_unique_abbr": "BJUT;UK",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9560893",
        "title": "Robot Navigation in Constrained Pedestrian Environments using Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Navigating fluently around pedestrians is a necessary capability for mobile robots deployed in human environments, such as buildings and homes. While research on social navigation has focused mainly on the scalability with the number of pedestrians in open spaces, typical indoor environments present the additional challenge of constrained spaces such as corridors and doorways that limit maneuverability and influence patterns of pedestrian interaction. We present an approach based on reinforcement learning (RL) to learn policies capable of dynamic adaptation to the presence of moving pedestrians while navigating between desired locations in constrained environments. The policy network receives guidance from a motion planner that provides waypoints to follow a globally planned trajectory, whereas RL handles the local interactions. We explore a compositional principle for multi-layout training and find that policies trained in a small set of geometrically simple layouts successfully generalize to more complex unseen layouts that exhibit composition of the structural elements available during training. Going beyond walls-world like domains, we show transfer of the learned policy to unseen 3D reconstructions of two real environments. These results support the applicability of the compositional principle to navigation in real-world buildings and indicate promising usage of multi-agent simulation within reconstructed environments for tasks that involve interaction. https://ai.stanford.edu/\u223ccdarpino/socialnavconstrained/",
        "primary_area": "",
        "author": "Claudia P\u00e9rez-D\u2019Arpino;Can Liu;Patrick Goebel;Roberto Mart\u00edn-Mart\u00edn;Silvio Savarese;Claudia P\u00e9rez-D\u2019Arpino;Can Liu;Patrick Goebel;Roberto Mart\u00edn-Mart\u00edn;Silvio Savarese",
        "authorids": "/38270722900;/37088998529;/37086575569;/37085788640;/37298502600;/38270722900;/37088998529;/37086575569;/37085788640;/37298502600",
        "aff": "Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; Department of Computer Science, Stanford University; Department of Computer Science, Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560893/",
        "gs_citation": 98,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9945280680649242543&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561206",
        "title": "Robot Program Parameter Inference via Differentiable Shadow Program Inversion",
        "track": "main",
        "status": "Poster",
        "abstract": "Challenging manipulation tasks can be solved effectively by combining individual robot skills, which must be parameterized for the concrete physical environment and task at hand. This is time-consuming and difficult for human programmers, particularly for force-controlled skills. To this end, we present Shadow Program Inversion (SPI), a novel approach to infer optimal skill parameters directly from data. SPI leverages unsupervised learning to train an auxiliary differentiable program representation (\"shadow program\") and realizes parameter inference via gradient-based model inversion. Our method enables the use of efficient first-order optimizers to infer optimal parameters for originally non-differentiable skills, including many skill variants currently used in production. SPI zero-shot generalizes across task objectives, meaning that shadow programs do not need to be retrained to infer parameters for different task variants. We evaluate our methods on three different robots and skill frameworks in industrial and household scenarios. Code and examples are available at https://innolab.artiminds.com/icra2021.",
        "primary_area": "",
        "author": "Benjamin Alt;Darko Katic;Rainer J\u00e4kel;Asil Kaan Bozcuoglu;Michael Beetz;Benjamin Alt;Darko Katic;Rainer J\u00e4kel;Asil Kaan Bozcuoglu;Michael Beetz",
        "authorids": "/37088995866;/37089002032;/37542755100;/37085664845;/37279125900;/37088995866;/37089002032;/37542755100;/37085664845;/37279125900",
        "aff": "ArtiMinds Robotics, Karlsruhe, Germany; ArtiMinds Robotics, Karlsruhe, Germany; ArtiMinds Robotics, Karlsruhe, Germany; Institute for Artificial Intelligence (IAI), University of Bremen, Germany; Institute for Artificial Intelligence (IAI), University of Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561206/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18009472287261116994&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "ArtiMinds Robotics;University of Bremen",
        "aff_unique_dep": ";Institute for Artificial Intelligence (IAI)",
        "aff_unique_url": ";https://www.uni-bremen.de",
        "aff_unique_abbr": ";Uni Bremen",
        "aff_campus_unique_index": "0;0;0;1;1",
        "aff_campus_unique": "Karlsruhe;Bremen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561545",
        "title": "Robot in a China Shop: Using Reinforcement Learning for Location-Specific Navigation Behaviour",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots need to be able to work in multiple different environments. Even when performing similar tasks, different behaviour should be deployed to best fit the current environment. In this paper, We propose a new approach to navigation, where it is treated as a multi-task learning problem. This enables the robot to learn to behave differently in visual navigation tasks for different environments while also learning shared expertise across environments. We evaluated our approach in both simulated environments as well as real-world data. Our method allows our system to converge with a 26% reduction in training time, while also increasing accuracy.",
        "primary_area": "",
        "author": "Bian Xihan;Oscar Mendez;Simon Hadfield;Bian Xihan;Oscar Mendez;Simon Hadfield",
        "authorids": "/37089000191;/37710939600;/38232557500;/37089000191;/37710939600;/38232557500",
        "aff": "Bian Xihan; Oscar Mendez; Simon Hadfield",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561545/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1024875946627657655&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9561678",
        "title": "Robot-Safe Impacts with Soft Contacts Based on Learned Deformations",
        "track": "main",
        "status": "Poster",
        "abstract": "Safely generating impacts with robots is challenging due to subsequent discontinuous velocity and high impact forces. We aim at increasing the impact velocity \u2013 the robot\u2019s relative speed prior to contact \u2013 such that impact-tasks like grabbing and boxing are made with the highest allowable speed performance when needed. Previous works addressed this problem for rigid bodies\u2019 impacts. This letter proposes a control paradigm for generating intentional impacts with deformable contacts that incorporates hardware and task constraints. Based on data-driven learning of the shock-absorbing soft dynamics and a novel mapping of joint-space limits to contact-space, we devise a constrained model-predictive control to maximize the intentional impact within a feasible, robot-safe level. Our approach is assessed with real-robot experiments on the redundant Panda manipulator, demonstrating high pre-impact velocities (up to 0.9 m/s) of a rigid end-effector on soft objects and an end-effector soft suction-pump on rigid or deformable objects.",
        "primary_area": "",
        "author": "Niels Dehio;Abderrahmane Kheddar;Niels Dehio;Abderrahmane Kheddar",
        "authorids": "/37085760535;/37293875300;/37085760535;/37293875300",
        "aff": "LIRMM, Interactive Digital Humans group, CNRS-University of Montpellier, France; CNRS-AIST Joint Robotics Laboratory, IRL, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561678/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8297811644929758859&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "CNRS-University of Montpellier;CNRS-AIST Joint Robotics Laboratory",
        "aff_unique_dep": "Interactive Digital Humans group;Joint Robotics Laboratory",
        "aff_unique_url": "https://www.univ-montp2.fr;",
        "aff_unique_abbr": "UM;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "France;Japan"
    },
    {
        "id": "9560815",
        "title": "Robot-supervised Learning of Crop Row Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose an approach for robot-supervised learning that automates label generation for semantic segmentation with Convolutional Neural Networks (CNNs) for crop row detection in a field. Using a training robot equipped with RTK GNSS and RGB camera, we train a neural network that can later be used for pure vision-based navigation. We test our approach on an agri-robot in a strawberry field and successfully train crop row segmentation without any hand-drawn image labels. Our main finding is that the resulting segmentation output of the CNN shows better performance than the noisy labels it was trained on. Finally, we conduct open-loop field trials with our agri-robot and show that row-following based on the segmentation result is accurate enough for closed-loop guidance. We conclude that training with noisy segmentation labels is a promising approach for learning vision-based crop row following.",
        "primary_area": "",
        "author": "Marianne Bakken;Vignesh Raja Ponnambalam;Richard J. D. Moore;Jon Glenn Omholt Gjevestad;P\u00e5l Johan From;Marianne Bakken;Vignesh Raja Ponnambalam;Richard J. D. Moore;Jon Glenn Omholt Gjevestad;P\u00e5l Johan From",
        "authorids": "/37086801050;/37088416332;/37088998425;/37088998463;/37088996647;/37086801050;/37088416332;/37088998425;/37088998463;/37088996647",
        "aff": "SINTEF Digital, Oslo, Norway; Norwegian University of Life Sciences, \u00c5s, Norway; SINTEF Digital, Oslo, Norway; Norwegian University of Life Sciences, \u00c5s, Norway; Norwegian University of Life Sciences, \u00c5s, Norway",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560815/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15668209592255714512&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;1",
        "aff_unique_norm": "SINTEF Digital;Norwegian University of Life Sciences",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.sintef.no;https://www.nmbu.no",
        "aff_unique_abbr": ";NMBU",
        "aff_campus_unique_index": "0;1;0;1;1",
        "aff_campus_unique": "Oslo;\u00c5s",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Norway"
    },
    {
        "id": "9561876",
        "title": "Robot-to-image Registration with Geometric Marker for CT-guided Robotic Needle Insertion",
        "track": "main",
        "status": "Poster",
        "abstract": "A computed tomography (CT)-guided robotic needle requires registration to transfer coordinates between the robot and CT image for accurate insertion. In our previous work, we proposed a geometric marker that allows direct registration between a CT image and robot and demonstrated its proof of concept. In this paper, we present a registration algorithm for calculating the six-degrees-of-freedom error of one CT scan, and we demonstrated the registration with our needle insertion robot. We obtained its geometric shape from differences between multiple images, which we converted into the coordinate axes of the marker, to calculate the posture of the marker. Since the algorithm uses changes in the cross-sectional shapes of images, it can be adapted for markers of different sizes. In the evaluation, the registration error for insertion by the CT-guided robotic needle with the proposed algorithm was calculated to be 1.8 mm and 0.35\u00b0. The accuracy of the proposed algorithm is sufficient for lower abdominal insertion and shows its potential for clinical applications. When the markers are half the size of the original, the rotational error is the same as the original, but the positional error is about half. This suggested the possibility of miniaturizing the marker.",
        "primary_area": "",
        "author": "Iori Ikeda;Kai Sekine;Ryosuke Tsumura;Hiroyasu Iwata;Iori Ikeda;Kai Sekine;Ryosuke Tsumura;Hiroyasu Iwata",
        "authorids": "/37088999997;/37088997243;/37085879374;/37326645800;/37088999997;/37088997243;/37085879374;/37326645800",
        "aff": "Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Graduate School of Creative Science and Engineering, Waseda University, Tokyo, Japan; Global Robot Academia Laboratory, Waseda University, Tokyo, Japan; Faculty of Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561876/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:TTwjzNr_db4J:scholar.google.com/&scioq=Robot-to-image+Registration+with+Geometric+Marker+for+CT-guided+Robotic+Needle+Insertion&hl=en&as_sdt=0,14",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Graduate School of Creative Science and Engineering",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561991",
        "title": "Robotic Cardinal Vein Microinjection of Zebrafish Larvae Based on 3D Positioning",
        "track": "main",
        "status": "Poster",
        "abstract": "Zebrafish (Danio Rerio) larvae have long been an important model organism for biomedicine and drug discovery. It is difficult to deliver the external materials into the circulatory system by conventional exposing administration, while vein microinjection is more efficient but more challenging. In this paper, a robotic cardinal vein microinjection system was presented for zebrafish larvae. The key points of injection pipette during penetration were analyzed, and their 3D positions were identified online by combining motion analysis and visual calibration. 3D path planning of the pipette tip was designed automatedly before injection. The injection system was evaluated by injecting green fluorescent microspheres into 20 zebrafish larvae. The experiment results show that the fluorescent microspheres spread rapidly in the blood circulation system after injection, achieving a success rate of 85.0% and a survival rate of 94.1%. The superior performance provided by the system will significantly facilitate tumor xenografts and canner studies on zebrafish.",
        "primary_area": "",
        "author": "Mingzhu Sun;Lu Li;Yatong Yao;Yiwen Wang;Huiying Gong;Qian Gao;Dongyan Chen;Xin Zhao;Mingzhu Sun;Lu Li;Yatong Yao;Yiwen Wang;Huiying Gong;Qian Gao;Dongyan Chen;Xin Zhao",
        "authorids": "/37536498500;/37089261412;/37088942165;/37089002311;/37088941945;/37088998485;/37088999909;/37293143500;/37536498500;/37089261412;/37088942165;/37089002311;/37088941945;/37088998485;/37088999909;/37293143500",
        "aff": "Institute of Robotics and Automatic Information System (IRAIS) and the Tianjin Key Laboratory of Intelligent Robotic (tjKLIR), Nankai University, China; Institute of Robotics and Automatic Information System (IRAIS) and the Tianjin Key Laboratory of Intelligent Robotic (tjKLIR), Nankai University, China; Institute of Robotics and Automatic Information System (IRAIS) and the Tianjin Key Laboratory of Intelligent Robotic (tjKLIR), Nankai University, China; Institute of Robotics and Automatic Information System (IRAIS) and the Tianjin Key Laboratory of Intelligent Robotic (tjKLIR), Nankai University, China; Institute of Robotics and Automatic Information System (IRAIS) and the Tianjin Key Laboratory of Intelligent Robotic (tjKLIR), Nankai University, China; Department of Histology and Embryology, Tianjin Key Laboratory of Tumor Microenvironment and Neurovascular Regulation, School of Medicine, Nankai University, China; Department of Histology and Embryology, Tianjin Key Laboratory of Tumor Microenvironment and Neurovascular Regulation, School of Medicine, Nankai University, China; Institute of Robotics and Automatic Information System (IRAIS) and the Tianjin Key Laboratory of Intelligent Robotic (tjKLIR), Nankai University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561991/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=717714334138086152&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Nankai University",
        "aff_unique_dep": "Institute of Robotics and Automatic Information System (IRAIS)",
        "aff_unique_url": "http://www.nankai.edu.cn",
        "aff_unique_abbr": "Nankai",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561600",
        "title": "Robotic Electrospinning Actuated by Non-Circular Joint Continuum Manipulator for Endoluminal Therapy",
        "track": "main",
        "status": "Poster",
        "abstract": "Electrospinning has exhibited excellent benefits to treat the trauma for tissue engineering due to its produced micro/nano fibrous structure. It can effectively adhere to the tissue surface for long-term continuous therapy. This paper develops a robotic electrospinning platform for endoluminal therapy. The platform consists of a continuum manipulator, the electrospinning device, and the actuation unit. The continuum manipulator has two bending sections to facilitate the steering of the tip needle for a controllable spinning direction. Non-circular joint profile is carefully designed to enable a constant length of the centreline of a continuum manipulator for stable fluid transmission inside it. Experiments are performed on a bronchus phantom, and the steering ability and bending limitation in each direction are also investigated. The endoluminal electrospinning is also fulfilled by a trajectory following and points targeting experiments. The effective adhesive area of the produced fibre is also illustrated. The proposed robotic electrospinning shows its feasibility to precisely spread more therapeutic drug to construct fibrous structure for potential endoluminal treatments.",
        "primary_area": "",
        "author": "Zicong Wu;Chuqian Lou;Zhu Jin;Shaoping Huang;Ning Liu;Yun Zou;Mirko Kovac;Anzhu Gao;Guang-Zhong Yang;Zicong Wu;Chuqian Lou;Zhu Jin;Shaoping Huang;Ning Liu;Yun Zou;Mirko Kovac;Anzhu Gao;Guang-Zhong Yang",
        "authorids": "/37088406835;/37089002000;/37088506567;/37086543846;/37085817193;/37085849314;/37089308285;/38027228000;/37276270800;/37088406835;/37089002000;/37088506567;/37086543846;/37085817193;/37085849314;/37089308285;/38027228000;/37276270800",
        "aff": "Institute of Medical Robotics and Department of Bioengineering, Shanghai Jiao Tong University, Shanghai, P. R. China; Imperial College London and Empa-Swiss Federal Laboratories for Materials Science and Technology; Institute of Medical Robotics and Department of Bioengineering, Shanghai Jiao Tong University, Shanghai, P. R. China; Institute of Medical Robotics and Department of Bioengineering, Shanghai Jiao Tong University, Shanghai, P. R. China; Precision Robotics (Hong Kong) Limited, Hong Kong, China; Institute of Medical Robotics and Department of Bioengineering, Shanghai Jiao Tong University, Shanghai, P. R. China; Aerial Robotics Laboratory, Imperial College London, London, United Kingdom; Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai, China; Institute of Medical Robotics, Shanghai Jiao Tong University, Shanghai, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561600/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:CKIaBhZ8-4IJ:scholar.google.com/&scioq=Robotic+Electrospinning+Actuated+by+Non-Circular+Joint+Continuum+Manipulator+for+Endoluminal+Therapy&hl=en&as_sdt=0,33",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1;0;0;2;0;1;3;0",
        "aff_unique_norm": "Shanghai Jiao Tong University;Imperial College London;Precision Robotics;Shanghai Engineering Research Center of Intelligent Control and Management",
        "aff_unique_dep": "Institute of Medical Robotics and Department of Bioengineering;;;",
        "aff_unique_url": "https://www.sjtu.edu.cn;https://www.imperial.ac.uk;;",
        "aff_unique_abbr": "SJTU;Imperial;;",
        "aff_campus_unique_index": "0;1;0;0;0;1;0",
        "aff_campus_unique": "Shanghai;London;",
        "aff_country_unique_index": "0;1;0;0;0;0;1;0;0",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9560956",
        "title": "Robotic Grasping of Fully-Occluded Objects using RF Perception",
        "track": "main",
        "status": "Poster",
        "abstract": "We present the design, implementation, and evaluation of RF-Grasp, a robotic system that can grasp fully-occluded objects in unknown and unstructured environments. Unlike prior systems that are constrained by the line-of-sight perception of vision and infrared sensors, RF-Grasp employs RF (Radio Frequency) perception to identify and locate target objects through occlusions, and perform efficient exploration and complex manipulation tasks in non-line-of-sight settings.RF-Grasp relies on an eye-in-hand camera and batteryless RFID tags attached to objects of interest. It introduces two main innovations: (1) an RF-visual servoing controller that uses the RFID\u2019s location to selectively explore the environment and plan an efficient trajectory toward an occluded target, and (2) an RF-visual deep reinforcement learning network that can learn and execute efficient, complex policies for decluttering and grasping.We implemented and evaluated an end-to-end physical prototype of RF-Grasp. We demonstrate it improves success rate and efficiency by up to 40-50% over a state-of-the-art baseline. We also demonstrate RF-Grasp in novel tasks such mechanical search of fully-occluded objects behind obstacles, opening up new possibilities for robotic manipulation. Qualitative results (videos) available at rfgrasp.media.mit.edu",
        "primary_area": "",
        "author": "Tara Boroushaki;Junshan Leng;Ian Clester;Alberto Rodriguez;Fadel Adib;Tara Boroushaki;Junshan Leng;Ian Clester;Alberto Rodriguez;Fadel Adib",
        "authorids": "/37088998484;/37088998764;/37088999200;/38194796600;/37088835850;/37088998484;/37088998764;/37088999200;/38194796600;/37088835850",
        "aff": "Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560956/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6949167291690941415&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562046",
        "title": "Robotic Grasping through Combined Image-Based Grasp Proposal and 3D Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel approach to robotic grasp planning using both a learned grasp proposal network and a learned 3D shape reconstruction network. Our system generates 6-DOF grasps from a single RGB-D image of the target object, which is provided as input to both networks. By using the geometric reconstruction to refine the candidate grasp produced by the grasp proposal network, our system is able to accurately grasp both known and unknown objects, even when the grasp location on the object is not visible in the input image.This paper presents the network architectures, training procedures, and grasp refinement method that comprise our system. Experiments demonstrate the efficacy of our system at grasping both known and unknown objects (91% success rate in a physical robot environment, 84% success rate in a simulated environment). We additionally perform ablation studies that show the benefits of combining a learned grasp proposal with geometric reconstruction for grasping, and also show that our system outperforms several baselines in a grasping task.",
        "primary_area": "",
        "author": "Daniel Yang;Tarik Tosun;Benjamin Eisner;Volkan Isler;Daniel Lee;Daniel Yang;Tarik Tosun;Benjamin Eisner;Volkan Isler;Daniel Lee",
        "authorids": "/37086574333;/37085336253;/37087324209;/37298487800;/37280609600;/37086574333;/37085336253;/37087324209;/37298487800;/37280609600",
        "aff": "Samsung AI Center NY, New York, NY; Samsung AI Center NY, New York, NY; Samsung AI Center NY, New York, NY; Samsung AI Center NY, New York, NY; Samsung AI Center NY, New York, NY",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562046/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15024528223922487706&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Samsung",
        "aff_unique_dep": "AI Center",
        "aff_unique_url": "https://www.samsung.com/global/innovation/ai-research/",
        "aff_unique_abbr": "SAC NY",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New York",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561786",
        "title": "Robotic Guide Dog: Leading a Human with Leash-Guided Hybrid Physical Interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "An autonomous robot that is able to physically guide humans through narrow and cluttered spaces could be a big boon to the visually-impaired. Most prior robotic guiding systems are based on wheeled platforms with large bases with actuated rigid guiding canes. The large bases and the actuated arms limit these prior approaches from operating in narrow and cluttered environments. We propose a method that introduces a quadrupedal robot with a leash to enable the robot-guidinghuman system to change its intrinsic dimension (by letting the leash go slack) in order to fit into narrow spaces. We propose a hybrid physical Human Robot Interaction model that involves leash tension to describe the dynamical relationship in the robot-guiding-human system. This hybrid model is utilized in a mixed-integer programming problem to develop a reactive planner that is able to utilize slack-taut switching to guide a blind-folded person to safely travel in a confined space. The proposed leash-guided robot framework is deployed on a Mini Cheetah quadrupedal robot and validated in experiments (Video 1)",
        "primary_area": "",
        "author": "Anxing Xiao;Wenzhe Tong;Lizhi Yang;Jun Zeng;Zhongyu Li;Koushil Sreenath;Anxing Xiao;Wenzhe Tong;Lizhi Yang;Jun Zeng;Zhongyu Li;Koushil Sreenath",
        "authorids": "/37088981835;/37089001875;/37088987506;/37086963288;/37088691308;/37563179200;/37088981835;/37089001875;/37088987506;/37086963288;/37088691308;/37563179200",
        "aff": "Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA; Department of Mechanical Engineering, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561786/",
        "gs_citation": 116,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5499944487621686198&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561619",
        "title": "Robotic Imitation of Human Assembly Skills Using Hybrid Trajectory and Force Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic assembly tasks involve complex and low-clearance insertion trajectories with varying contact forces at different stages. While the nominal motion trajectory can be easily obtained from human demonstrations through kinesthetic teaching, teleoperation, simulation, among other methods, the force profile is harder to obtain especially when a real robot is unavailable. It is difficult to obtain a realistic force profile in simulation even with physics engines. Such simulated force profiles tend to be unsuitable for the actual robotic assembly due to the reality gap and uncertainty in the assembly process. To address this problem, we present a combined learning-based framework to imitate human assembly skills through hybrid trajectory learning and force learning. The main contribution of this work is the development of a framework that combines hierarchical imitation learning, to learn the nominal motion trajectory, with a reinforcement learning-based force control scheme to learn an optimal force control policy. To further improve the imitation learning part, we develop a hierarchical architecture, following the idea of goal-conditioned imitation learning, to generate the trajectory learning policy on the skill level offline. Through experimental validations, we corroborate that the proposed learning-based framework is robust to uncertainty in the assembly task, can generate high-quality trajectories, and can find suitable force control policies, which adapt to the task\u2019s force requirements more efficiently.",
        "primary_area": "",
        "author": "Yan Wang;Cristian C. Beltran-Hernandez;Weiwei Wan;Kensuke Harada;Yan Wang;Cristian C. Beltran-Hernandez;Weiwei Wan;Kensuke Harada",
        "authorids": "/37088340332;/37086823072;/37085689483;/37277067400;/37088340332;/37086823072;/37085689483;/37277067400",
        "aff": "Department of Systems Innovation, Graduate School of Engineering Science, Osaka University, Japan; Department of Systems Innovation, Graduate School of Engineering Science, Osaka University, Japan; Department of Systems Innovation, Graduate School of Engineering Science, Osaka University, Japan; National Institute of Advanced Industrial Science and Technology, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561619/",
        "gs_citation": 31,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10873639720955903323&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Osaka University;National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Department of Systems Innovation, Graduate School of Engineering Science;",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.aist.go.jp",
        "aff_unique_abbr": "Osaka U;AIST",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Osaka;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9560904",
        "title": "Robotic Indoor Scene Captioning from Streaming Video",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots are usually equipped with cameras to explore the indoor scene and it is expected that the robot can well describe the scene with natural language. Although some great success has been achieved in image and video captioning technology, especially on many public datasets, the caption generated from indoor scene video is still not informative and coherent enough. In this paper, we propose the problem of Indoor Scene Captioning from Streaming Video, which aims at generating a more accurate and informative caption from streaming video. To solve this problem, we firstly design an algorithm to organize the visual information of the indoor scene into a scene graph, and then implement a scene graph guided captioning method, which takes the scene graph and video frames as input to generate the caption from the video streaming. The proposed framework is evaluated both on the AI2THOR dataset and a real-world robotic platform, demonstrating the effectiveness of the framework.",
        "primary_area": "",
        "author": "Xinghang Li;Di Guo;Huaping Liu;Fuchun Sun;Xinghang Li;Di Guo;Huaping Liu;Fuchun Sun",
        "authorids": "/37089001510;/37085360957;/37310126400;/37279269000;/37089001510;/37085360957;/37310126400;/37279269000",
        "aff": "Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China; Department of Computer Science and Technology, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560904/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10798795196239516101&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Tsinghua University",
        "aff_unique_dep": "Department of Computer Science and Technology",
        "aff_unique_url": "https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "THU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561317",
        "title": "Robotic Information Gathering using Semantic Language Instructions",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a framework that uses language instructions to define the constraints and objectives for robots gathering information about their environment. Designing autonomous robotic sampling missions requires deep knowledge of both autonomy systems and scientific domain expertise. Language commands provide an intuitive interface for operators to give complex instructions to robots. The key insight we leverage is using topological constraints to define routing directions from the language instruction such as \u2018route to the left of the island.\u2019 This work introduces three main contributions: a framework to map language instructions to constraints and rewards for robot planners, a topology constrained information gathering algorithm, and an automatic semantic feature detection algorithm for upwelling fronts. Our work improves on existing methods by not requiring training data with language instruction to planner constraint pairs, allowing new robotic domains such as marine robotics to use our method. This paper provides results demonstrating our framework producing correct constraints for 84.6% of instructions, from a systematically generated corpus of over 1.1 million instructions We also demonstrate the framework producing robot plans from language instructions for real-world scientific sampling missions with the Slocum underwater glider.",
        "primary_area": "",
        "author": "Ian C. Rankin;Seth McCammon;Geoffrey A. Hollinger;Ian C. Rankin;Seth McCammon;Geoffrey A. Hollinger",
        "authorids": "/37088999093;/37086071053;/37543482700;/37088999093;/37086071053;/37543482700",
        "aff": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, United States; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, United States; Collaborative Robotics and Intelligent Systems (CoRIS) Institute, Oregon State University, Corvallis, OR, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561317/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10997599564894745539&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems (CoRIS) Institute",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Corvallis",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561698",
        "title": "Robotic Micromanipulation for Active Pin Alignment in Electronic Soldering Industry",
        "track": "main",
        "status": "Poster",
        "abstract": "In the context of robotic high-precision soldering, we propose an image-based pin alignment control method based on active plastic deformation. The plastic deformation is a well-known failure mechanism in most situations, which includes a phenomenon that the objects do not return original state. Here, in contrast to this convention, we utilize the plastic deformation of the metal pin to do pin alignment for improving the quality of the solder joint. To address this, we embed the springback compensation into the image-based pin alignment controller. Lastly, the proposed strategy is successfully demonstrated and evaluated in a practical modified robotic manipulation system. The result shows that the alignment error is less than 20\u00b5m, which is far less than pin alignment without considering plastic deformation and elastic recovery. This work considers active plastic deformation and spontaneous elastic recovery of soft object, which would greatly promote the use of robotics in micromanufacturing and microfabrication in lad and industry, especially for soft objects.",
        "primary_area": "",
        "author": "Hao Ren;Xinyu Wu;Wanfeng Shang;Hao Ren;Xinyu Wu;Wanfeng Shang",
        "authorids": "/37086593201;/37293518700;/37887033400;/37086593201;/37293518700;/37887033400",
        "aff": "University of Chinese Academy of Sciences, Beijing, China; Chinese Academy of Sciences, Shenzhen Institute of Advanced Technology, Shenzhen, China; Chinese Academy of Sciences, Shenzhen Institute of Advanced Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561698/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15103193359979939265&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "University of Chinese Academy of Sciences;Chinese Academy of Sciences",
        "aff_unique_dep": ";Shenzhen Institute of Advanced Technology",
        "aff_unique_url": "http://www.ucas.ac.cn;http://www.siat.ac.cn",
        "aff_unique_abbr": "UCAS;CAS",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Beijing;Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560761",
        "title": "Robotic Slicing of Fruits and Vegetables: Modeling the Effects of Fracture Toughness and Knife Geometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Slicing is an important skill for a robot to learn as it is more efficient and results in less deformation in comparison with cutting by pressing. Cutting experiments with foods have indicated that the ease of slicing is caused by a decrease in fracture toughness. In this paper, we formally characterize this decrease based on the work needed to maintain the critical strain for fracture. Forces generating fracture and deformation and overcoming friction are predicted using the finite element method (FEM) and based on fracture mechanics. Extending our previous work [1] on cutting by pressing with a straight knife edge, we model general slicing and knife geometry (i.e., a curved edge). Experiments over potatoes and eggplants have demonstrated the accurate modeling of the overall cutting force during slicing, which could be leveraged for control of cutting by the robot to demonstrate human-level skills in the near future.",
        "primary_area": "",
        "author": "Prajjwal Jamdagni;Yan-Bin Jia;Prajjwal Jamdagni;Yan-Bin Jia",
        "authorids": "/37087325098;/37273296400;/37087325098;/37273296400",
        "aff": "Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560761/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15704380031548394158&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Iowa State University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.iastate.edu",
        "aff_unique_abbr": "ISU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Ames",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561630",
        "title": "Robots of the Lost Arc: Self-Supervised Learning to Dynamically Manipulate Fixed-Endpoint Cables",
        "track": "main",
        "status": "Poster",
        "abstract": "We explore how high-speed robot arm motions can dynamically manipulate ropes and cables to vault over obstacles, knock objects from pedestals, and weave between obstacles. In this paper, we propose a self-supervised learning framework that enables a UR5 robot to perform these three tasks. The framework finds a 3D apex point for the robot arm, which, together with a task-specific trajectory function, defines an arcing motion that dynamically manipulates the cable to perform a task with varying obstacle and target locations. The trajectory function computes minimum-jerk motions that are constrained to remain within joint limits and to travel through the 3D apex point by repeatedly solving quadratic programs to find the shortest and fastest feasible motion. We experiment with 5 physical cables with different thickness and mass and compare performance against two baselines in which a human chooses the apex point. Results suggest that a baseline with a fixed apex across the three tasks achieves respective success rates of 51.7 %, 36.7 %, and 15.0 %, and a baseline with human-specified, task-specific apex points achieves 66.7 %, 56.7 %, and 15.0 % success rate respectively, while the robot using the learned apex point can achieve success rates of 81.7 % in vaulting, 65.0 % in knocking, and 60.0 % in weaving. Code, data, and supplementary materials are available at https://sites.google.com/berkeley.edu/dynrope/home.",
        "primary_area": "",
        "author": "Harry Zhang;Jeffrey Ichnowski;Daniel Seita;Jonathan Wang;Huang Huang;Ken Goldberg;Harry Zhang;Jeffrey Ichnowski;Daniel Seita;Jonathan Wang;Huang Huang;Ken Goldberg",
        "authorids": "/37088504385;/38541287200;/37086012763;/37089001305;/37088985585;/37273026700;/37088504385;/38541287200;/37086012763;/37089001305;/37088985585;/37273026700",
        "aff": "AUTOLab, UC Berkeley (automation.berkeley.edu); AUTOLab, UC Berkeley (automation.berkeley.edu); AUTOLab, UC Berkeley (automation.berkeley.edu); AUTOLab, UC Berkeley (automation.berkeley.edu); AUTOLab, UC Berkeley (automation.berkeley.edu); AUTOLab, UC Berkeley (automation.berkeley.edu)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561630/",
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14769508188280437800&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "AUTOLab",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561272",
        "title": "Robust & Asymptotically Locally Optimal UAV-Trajectory Generation Based on Spline Subdivision",
        "track": "main",
        "status": "Poster",
        "abstract": "Generating locally optimal UAV-trajectories is challenging due to the non-convex constraints of collision avoidance and actuation limits. We present the first local, optimization-based UAV-trajectory generator that simultane-ously guarantees validity and asymptotic optimality for known environments. Validity: Given a feasible initial guess, our algo-rithm guarantees the satisfaction of all constraints throughout the process of optimization. Asymptotic Optimality: We use an asymptotic exact piecewise approximation of the trajectory with an automatically adjustable resolution of its discretization. The trajectory converges under refinement to the first-order stationary point of the exact non-convex programming problem. Our method has additional practical advantages including joint optimality in terms of trajectory and time-allocation, and robustness to challenging environments as demonstrated in our experiments.",
        "primary_area": "",
        "author": "Ruiqi Ni;Teseo Schneider;Daniele Panozzo;Zherong Pan;Xifeng Gao;Ruiqi Ni;Teseo Schneider;Daniele Panozzo;Zherong Pan;Xifeng Gao",
        "authorids": "/37089001402;/37087234335;/37860546800;/37086067204;/37088506715;/37089001402;/37087234335;/37860546800;/37086067204;/37088506715",
        "aff": "Department of Computer Science, Florida State University; Department of Computer Science, New York University; Department of Computer Science, New York University; Department of Computer Science, University of Illinois Urbana-Champaign; Department of Computer Science, Florida State University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561272/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9361098789589832613&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;0",
        "aff_unique_norm": "Florida State University;New York University;University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.fsu.edu;https://www.nyu.edu;https://illinois.edu",
        "aff_unique_abbr": "FSU;NYU;UIUC",
        "aff_campus_unique_index": "1;1;2",
        "aff_campus_unique": ";New York;Urbana-Champaign",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560888",
        "title": "Robust 360-8PA: Redesigning The Normalized 8-point Algorithm for 360-FoV Images",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a novel preconditioning strategy for the classic 8-point algorithm (8-PA) for estimating an essential matrix from 360-FoV images (i.e., equirectangular images) in spherical projection. To alleviate the effect of uneven key-feature distributions and outlier correspondences, which can potentially decrease the accuracy of an essential matrix, our method optimizes a non-rigid transformation to deform a spherical camera into a new spatial domain, defining a new constraint and a more robust and accurate solution for an essential matrix. Through several experiments using random synthetic points, 360-FoV, and fish-eye images, we demonstrate that our normalization can increase the camera pose accuracy about 20% without significantly overhead the computation time. In addition, we present further benefits of our method through both a constant weighted least-square optimization that improves further the well known Gold Standard Method (GSM) (i.e., the non-linear optimization by using epipolar errors); and a relaxation of the number of RANSAC iterations, both showing that our normalization outcomes a more reliable, robust, and accurate solution.",
        "primary_area": "",
        "author": "Bolivar Solarte;Chin-Hsuan Wu;Kuan-Wei Lu;Yi-Hsuan Tsai;Wei-Chen Chiu;Min Sun;Bolivar Solarte;Chin-Hsuan Wu;Kuan-Wei Lu;Yi-Hsuan Tsai;Wei-Chen Chiu;Min Sun",
        "authorids": "/37088504484;/37089001531;/37089001469;/37085759166;/37086286145;/37085873757;/37088504484;/37089001531;/37089001469;/37085759166;/37086286145;/37085873757",
        "aff": "National Tsing Hua University; National Tsing Hua University; National Tsing Hua University; NEC Labs America; National Chiao Tung University; National Tsing Hua University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560888/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=744581715783498828&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;2;0",
        "aff_unique_norm": "National Tsing Hua University;NEC Labs America;National Chiao Tung University",
        "aff_unique_dep": ";;",
        "aff_unique_url": "https://www.nthu.edu.tw;https://www.nec-labs.com;https://www.nctu.edu.tw",
        "aff_unique_abbr": "NTHU;NEC LA;NCTU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Taiwan;",
        "aff_country_unique_index": "0;0;0;1;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561513",
        "title": "Robust Adaptive Synchronization of Interconnected Heterogeneous Quadrotors Transporting a Cable-Suspended Load",
        "track": "main",
        "status": "Poster",
        "abstract": "We tackle the problem of multiple quadrotors transporting a cable-suspended point-mass load. The quadrotors are treated as a virtual leader-follower algorithm, where a multi-layer graph encapsulates the communication and physical interaction. On the one hand, the communication stands for the approach of following the reference trajectory of a virtual leader. On the other hand, the load exerts a distributed tension force on each cable which is modeled as the well-known spring-damping system to each quadrotor establishing an interconnected dynamic. We assume cables are stretchable and have neglectable mass. Both objectives are accomplished through a Model Reference Adaptive Control approach with a robust modification that treats uncertainties and perturbations given by error in parameters, noise in the signal, and the wind drag forces. We prove stability based on Lyapunov approach and the results are shown through simulation.",
        "primary_area": "",
        "author": "G. A. Cardona;M. Arevalo-Castiblanco;D. Tellez-Castro;J. Calderon;E. Mojica-Nava;G. A. Cardona;M. Arevalo-Castiblanco;D. Tellez-Castro;J. Calderon;E. Mojica-Nava",
        "authorids": "/37085799776;/37086945099;/37085878924;/37086344270;/38275046400;/37085799776;/37086945099;/37085878924;/37086344270;/38275046400",
        "aff": "AIR-Lab, Lehigh University, PA, USA; Universidad Nacional de Colombia, Bogota, Colombia; Universidad Nacional de Colombia, Bogota, Colombia; Bethune Cookman University, Daytona, FL; Universidad Nacional de Colombia, Bogota, Colombia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561513/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8304029315920176358&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;2;1",
        "aff_unique_norm": "Lehigh University;Universidad Nacional de Colombia;Bethune-Cookman University",
        "aff_unique_dep": "AIR-Lab;;",
        "aff_unique_url": "https://www.lehigh.edu;https://www.unal.edu.co;https://www.cookman.edu",
        "aff_unique_abbr": "Lehigh;UNAL;BCU",
        "aff_campus_unique_index": "0;1;1;2;1",
        "aff_campus_unique": "Bethlehem;Bogota;Daytona",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "United States;Colombia"
    },
    {
        "id": "9561201",
        "title": "Robust Distributed Estimation of the Algebraic Connectivity for Networked Multi-robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "The connectivity of distributed networked multi-robot systems is a crucial operational specification, since the involved robots interact/communicate locally only with their immediate neighbors. Thus, in this work, we propose a distributed algorithm to estimate the algebraic connectivity of the underlying communication graph, which stands as a valid connectivity metric. Our method establishes robustness and fast convergence properties that can be adjusted independently via the appropriate selection of certain design parameters. Finally, we confirm the theoretical findings through simulated paradigms and verify the superiority of our method against a well-established solution of the related literature.",
        "primary_area": "",
        "author": "Ioanna Malli;Charalampos P. Bechlioulis;Kostas J. Kyriakopoulos;Ioanna Malli;Charalampos P. Bechlioulis;Kostas J. Kyriakopoulos",
        "authorids": "/37088999881;/37396608300;/38181756700;/37088999881;/37396608300;/38181756700",
        "aff": "Control Systems Lab, School of Mechanical Engineering, National Technical University of Athens, Greece; Control Systems Lab, School of Mechanical Engineering, National Technical University of Athens, Greece; Control Systems Lab, School of Mechanical Engineering, National Technical University of Athens, Greece",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561201/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=279267304461112146&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "National Technical University of Athens",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.ntua.gr",
        "aff_unique_abbr": "NTUA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Greece"
    },
    {
        "id": "9561381",
        "title": "Robust Frequency-Based Structure Extraction",
        "track": "main",
        "status": "Poster",
        "abstract": "State of the art mapping algorithms can produce high-quality maps. However, they are still vulnerable to clutter and outliers which can affect map quality and in consequence hinder the performance of a robot, and further map processing for semantic understanding of the environment. This paper presents ROSE, a method for building-level structure detection in robotic maps. ROSE exploits the fact that indoor environments usually contain walls and straight-line elements along a limited set of orientations. Therefore metric maps often have a set of dominant directions. ROSE extracts these directions and uses this information to segment the map into structure and clutter through filtering the map in the frequency domain (an approach substantially underutilised in the mapping applications). Removing the clutter in this way makes wall detection (e.g. using the Hough transform) more robust. Our experiments demonstrate that (1) the application of ROSE for decluttering can substantially improve structural feature retrieval (e.g., walls) in cluttered environments, (2) ROSE can successfully distinguish between clutter and structure in the map even with substantial amount of noise and (3) ROSE can numerically assess the amount of structure in the map.",
        "primary_area": "",
        "author": "Tomasz Piotr Kucner;Matteo Luperto;Stephanie Lowry;Martin Magnusson;Achim J. Lilienthal;Tomasz Piotr Kucner;Matteo Luperto;Stephanie Lowry;Martin Magnusson;Achim J. Lilienthal",
        "authorids": "/37085646558;/37085688878;/37085549670;/37584850000;/37273127300;/37085646558;/37085688878;/37085549670;/37584850000;/37273127300",
        "aff": "MRO Lab of the AASS Research Centre, \u00d6rebro University, Sweden; Applied Intelligent System Lab (AISLab), Universit\u00e0 degli Studi di Milano, Milano, Italy; MRO Lab of the AASS Research Centre, \u00d6rebro University, Sweden; MRO Lab of the AASS Research Centre, \u00d6rebro University, Sweden; MRO Lab of the AASS Research Centre, \u00d6rebro University, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561381/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7719699039310629970&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "\u00d6rebro University;Universit\u00e0 degli Studi di Milano",
        "aff_unique_dep": "MRO Lab of the AASS Research Centre;Applied Intelligent System Lab (AISLab)",
        "aff_unique_url": "https://www.oru.se;https://www.unimi.it",
        "aff_unique_abbr": ";UniMi",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Milano",
        "aff_country_unique_index": "0;1;0;0;0",
        "aff_country_unique": "Sweden;Italy"
    },
    {
        "id": "9561968",
        "title": "Robust High-Transparency Haptic Exploration for Dexterous Telemanipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic teleoperation provides human-in-the-loop capabilities of complex manipulation tasks in dangerous or remote environments, such as for planetary exploration or nuclear decommissioning. This work proposes a novel telemanipulation architecture using a passive Fractal Impedance Controller (FIC), which does not depend upon an active viscous component for guaranteeing stability. Compared to a traditional impedance controller in ideal conditions (no delays and maximum communication bandwidth), our proposed method yields higher transparency in interaction and demonstrates superior dexterity and capability in our telemanipulation test scenarios. We also validate its performance with extreme delays up to 1 s and communication bandwidths as low as 10 Hz. All results validate a consistent stability when using the proposed controller in challenging conditions, regardless of operator expertise.",
        "primary_area": "",
        "author": "Keyhan Kouhkiloui Babarahmati;Carlo Tiseo;Quentin Rouxel;Zhibin Li;Michael Mistry;Keyhan Kouhkiloui Babarahmati;Carlo Tiseo;Quentin Rouxel;Zhibin Li;Michael Mistry",
        "authorids": "/37086453340;/37085404832;/37085642431;/37857029500;/37542865600;/37086453340;/37085404832;/37085642431;/37857029500;/37542865600",
        "aff": "School of Informatics, University of Edinburgh; School of Informatics, University of Edinburgh; School of Informatics, University of Edinburgh; School of Informatics, University of Edinburgh; School of Informatics, University of Edinburgh",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561968/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10049077366384193005&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Edinburgh",
        "aff_unique_dep": "School of Informatics",
        "aff_unique_url": "https://www.ed.ac.uk",
        "aff_unique_abbr": "Edinburgh",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Edinburgh",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561596",
        "title": "Robust Improvement in 3D Object Landmark Inference for Semantic Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent works on semantic Simultaneous Localization and Mapping (SLAM) utilizing object landmarks have shown superiority in terms of robustness and accuracy in tracking and localization. 3D object landmarks represented by a cubic or quadric surface are inferred from 2D object bounding boxes which are typically captured from multiple views by an object detector. Nevertheless, bounding box noises and small camera baseline may lead to an inaccurate 3D object landmark inference. Inspired by the dual quadric enveloping property, in this work, we introduce the horizontal support assumption to constrain rotation w.r.t. roll and pitch for a quadric representation. As the result, we reduce the number of quadric parameters and narrow down the solution space, and ultimately produce a relatively accurate inference. Extensive experimental evaluations under both simulated and real scenarios are conducted in this paper. Quantitative results demonstrate that our approach outperforms the state-of-the-art.",
        "primary_area": "",
        "author": "Xubin Lin;Yirui Yang;Li He;Weinan Chen;Yisheng Guan;Hong Zhang;Xubin Lin;Yirui Yang;Li He;Weinan Chen;Yisheng Guan;Hong Zhang",
        "authorids": "/37086355958;/37088996332;/37086300847;/37086099846;/37402001000;/37089261800;/37086355958;/37088996332;/37086300847;/37086099846;/37402001000;/37089261800",
        "aff": "Biomimetic and Intelligent Robotics Lab (BIRL), Guangdong University of Technology, Guangzhou, China; Biomimetic and Intelligent Robotics Lab (BIRL), Guangdong University of Technology, Guangzhou, China; Biomimetic and Intelligent Robotics Lab (BIRL), Guangdong University of Technology, Guangzhou, China; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China; Biomimetic and Intelligent Robotics Lab (BIRL), Guangdong University of Technology, Guangzhou, China; Department of Electronic and Electrical Engineering, Southern University of Science and Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561596/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9787908210366567632&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;1",
        "aff_unique_norm": "Guangdong University of Technology;Southern University of Science and Technology",
        "aff_unique_dep": "Biomimetic and Intelligent Robotics Lab (BIRL);Department of Electronic and Electrical Engineering",
        "aff_unique_url": ";https://www.sustech.edu.cn",
        "aff_unique_abbr": ";SUSTech",
        "aff_campus_unique_index": "0;0;0;1;0;1",
        "aff_campus_unique": "Guangzhou;Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560892",
        "title": "Robust Iterative Learning Control for Pneumatic Muscle with State Constraint and Model Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel iterative learning control (ILC) scheme for precise state tracking of pneumatic muscle (PM) actuators. Two critical issues are considered in our scheme: 1) state constraints on PM position and velocity; 2) uncertainties of the PM model. Based on the three-element form, a PM model is constructed that takes both parametric and nonparametric uncertainties into consideration. By introducing the composite energy function (CEF) approach incorporated with a barrier Lyapunov function (BLF), full state constraints of PM will not be violated and uncertainties are effectively compensated. Through rigorous analysis, we show that under proposed ILC scheme, uniform convergence of PM state tracking errors are guaranteed. Simulation results validate the performance of the proposed scheme.",
        "primary_area": "",
        "author": "Kun Qian;Zhenghong Li;Ahmed Asker;Zhiqiang Zhang;Shengquan Xie;Kun Qian;Zhenghong Li;Ahmed Asker;Zhiqiang Zhang;Shengquan Xie",
        "authorids": "/165761201524246;/37085726884;/37085539047;/37537888200;/37833367900;/165761201524246;/37085726884;/37085539047;/37537888200;/37833367900",
        "aff": "Institute of Rehabilitation Engineering, Binzhou Medical University, Yantai, China; Institute of Rehabilitation Engineering, Binzhou Medical University, Yantai, China; Institute of Rehabilitation Engineering, Binzhou Medical University, Yantai, China; Institute of Rehabilitation Engineering, Binzhou Medical University, Yantai, China; Institute of Rehabilitation Engineering, Binzhou Medical University, Yantai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560892/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10576593478103714223&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Binzhou Medical University",
        "aff_unique_dep": "Institute of Rehabilitation Engineering",
        "aff_unique_url": "http://www.bzmu.edu.cn",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Yantai",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561534",
        "title": "Robust Landing Stabilization of Humanoid Robot on Uneven Terrain via Admittance Control and Heel Strike Motion",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses robust landing stabilization in humanoid locomotion on uneven terrain. The core idea is to find a configuration of the robot that results in small impulsive force when an unexpected obstacle is encountered, and to adjust post-contact reference for swing foot with which the pose of the foot is stabilized on the obstacle. This can be achieved by walking with heel strike motion (validated by the impact map analysis) and by employing hybrid admittance control combining the admittance control with reset of post-contact reference, embedded into the momentum-based whole-body control framework. The validity of the proposed algorithm is verified by simulation with a physics engine.",
        "primary_area": "",
        "author": "Joonhee Jo;Gyunghoon Park;Yonghwan Oh;Joonhee Jo;Gyunghoon Park;Yonghwan Oh",
        "authorids": "/38242649600;/37085453532;/37289677900;/38242649600;/37085453532;/37289677900",
        "aff": "Department of HCI & Robotics, University of Science and Technology(UST), Daejeon, Korea; School of Electrical and Computer Engineering, University of Seoul, Seoul, Korea; Center for Intelligent & Interactive Robotics, Korea Institute of Science and Technology (KIST), Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561534/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9549372242030301426&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "University of Science and Technology;University of Seoul;Korea Institute of Science and Technology",
        "aff_unique_dep": "Department of HCI & Robotics;School of Electrical and Computer Engineering;Center for Intelligent & Interactive Robotics",
        "aff_unique_url": "https://www.ust.ac.kr;http://www.useoul.edu;https://www.kist.re.kr",
        "aff_unique_abbr": "UST;UoS;KIST",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Daejeon;Seoul",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561174",
        "title": "Robust Monocular Visual-Inertial Depth Completion for Embedded Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we augment our prior state-of-the-art visual-inertial odometry (VIO) system, OpenVINS [1], to produce accurate dense depth by filling in sparse depth estimates (depth completion) from VIO with image guidance \u2013 all while focusing on enabling real-time performance of the full VIO+depth system on embedded devices. We show that noisy depth values with varying sparsity produced from a VIO system can not only hurt the accuracy of predicted dense depth maps, but also make them considerably worse than those from an image-only depth network with the same underlying architecture. We investigate this sensitivity on both an outdoor simulated and indoor handheld RGB-D dataset, and present simple yet effective solutions to address these shortcomings of depth completion networks. The key changes to our state-of-the-art VIO system required to provide high quality sparse depths for the network while still enabling efficient state estimation on embedded devices are discussed. A comprehensive computational analysis is performed over different embedded devices to demonstrate the efficiency and accuracy of the proposed VIO depth completion system.",
        "primary_area": "",
        "author": "Nathaniel Merrill;Patrick Geneva;Guoquan Huang;Nathaniel Merrill;Patrick Geneva;Guoquan Huang",
        "authorids": "/37087322112;/37086125563;/37077670600;/37087322112;/37086125563;/37077670600",
        "aff": "Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA; Robot Perception and Navigation Group (RPNG), University of Delaware, Newark, DE, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561174/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10930483001417236777&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Delaware",
        "aff_unique_dep": "Robot Perception and Navigation Group",
        "aff_unique_url": "https://www.udel.edu",
        "aff_unique_abbr": "UD",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Newark",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561406",
        "title": "Robust Motion Averaging under Maximum Correntropy Criterion",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, the motion averaging method has been introduced as an effective means to solve the multi-view registration problem. This method aims to recover global motions from a set of relative motions, where the original method is sensitive to outliers due to using the Frobenius norm error in the optimization. Accordingly, this paper proposes a novel robust motion averaging method based on the maximum correntropy criterion (MCC). Specifically, the correntropy measure is used instead of utilizing Frobenius norm error to improve the robustness of motion averaging against outliers. According to the half-quadratic technique, the correntropy measure based optimization problem can be solved by the alternating minimization procedure, which includes operations of weight assignment and weighted motion averaging. Further, we design a selection strategy of adaptive kernel width to take advantage of correntropy. Experimental results on benchmark data sets illustrate that our method has superior performance on accuracy and robustness for multi-view registration. What\u2019s more, it can be applied to robot mapping.",
        "primary_area": "",
        "author": "Jihua Zhu;Jie Hu;Huimin Lu;Badong Chen;Zhongyu Li;Yaochen Li;Jihua Zhu;Jie Hu;Huimin Lu;Badong Chen;Zhongyu Li;Yaochen Li",
        "authorids": "/37085344784;/37088997348;/37533922000;/37406619700;/37085374717;/37715813500;/37085344784;/37088997348;/37533922000;/37406619700;/37085374717;/37715813500",
        "aff": "",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561406/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11192214174677231331&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12
    },
    {
        "id": "9560743",
        "title": "Robust Navigation for Racing Drones based on Imitation Learning and Modularization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a vision-based modularized drone racing navigation system that uses a customized convolutional neural network (CNN) for the perception module to produce high-level navigation commands and then leverages a state-of-the-art planner and controller to generate low-level control commands, thus exploiting the advantages of both data- based and model-based approaches. Unlike the state-of-the-art method, which only takes the current camera image as the CNN input, we further add the latest three estimated drone states as part of the inputs. Our method outperforms the state-of-the-art method in various track layouts and offers two switchable navigation behaviors with a single trained network. The CNN-based perception module is trained to imitate an expert policy that automatically generates ground truth navigation commands based on the pre-computed global trajectories. Owing to the extensive randomization and our modified dataset aggregation (DAgger) policy during data collection, our navigation system, which is purely trained in simulation with synthetic textures, successfully operates in environments with randomly-chosen photo-realistic textures without further fine-tuning.",
        "primary_area": "",
        "author": "Tianqi Wang;Dong Eui Chang;Tianqi Wang;Dong Eui Chang",
        "authorids": "/37087408317;/37086484468;/37087408317;/37086484468",
        "aff": "Control Laboratory, School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Republic of Korea; Control Laboratory, School of Electrical Engineering, Korea Advanced Institute of Science and Technology, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560743/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10028493396594828701&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Advanced Institute of Science and Technology",
        "aff_unique_dep": "School of Electrical Engineering",
        "aff_unique_url": "https://www.kaist.ac.kr",
        "aff_unique_abbr": "KAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9560917",
        "title": "Robust Optimization-based Motion Planning for high-DOF Robots under Sensing Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion planning for high degree-of-freedom (DOF) robots is challenging, especially when acting in complex environments under sensing uncertainty. While there is significant work on how to plan under state uncertainty for low-DOF robots, existing methods cannot be easily translated into the high-DOF case, due to the complex geometry of the robot\u2019s body and its environment. In this paper, we present a method that enhances optimization-based motion planners to produce robust trajectories for high-DOF robots for convex obstacles. Our approach introduces robustness into planners that are based on sequential convex programming: We reformulate each convex subproblem as a robust optimization problem that \"protects\" the solution against deviations due to sensing uncertainty. The parameters of the robust problem are estimated by sampling from the distribution of noisy obstacles, and performing a first-order approximation of the signed distance function. The original merit function is updated to account for the new costs of the robust formulation at every step. The effectiveness of our approach is demonstrated on two simulated experiments that involve a full body square robot, that moves in randomly generated scenes, and a 7-DOF Fetch robot, performing tabletop operations. The results show nearly zero probability of collision for a reasonable range of the noise parameters for Gaussian and Uniform uncertainty.",
        "primary_area": "",
        "author": "Carlos Quintero-Pe\u00f1a;Anastasios Kyrillidis;Lydia E. Kavraki;Carlos Quintero-Pe\u00f1a;Anastasios Kyrillidis;Lydia E. Kavraki",
        "authorids": "/37088997672;/37713417100;/37279015600;/37088997672;/37713417100;/37279015600",
        "aff": "Dept. of Computer Science, Rice University, Houston, TX, USA; Dept. of Computer Science, Rice University, Houston, TX, USA; Dept. of Computer Science, Rice University, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560917/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16937208999044459619&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rice University",
        "aff_unique_dep": "Dept. of Computer Science",
        "aff_unique_url": "https://www.rice.edu",
        "aff_unique_abbr": "Rice",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562105",
        "title": "Robust Place Recognition using an Imaging Lidar",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a methodology for robust, real-time place recognition using an imaging lidar, which yields image-quality high-resolution 3D point clouds. Utilizing the intensity readings of an imaging lidar, we project the point cloud and obtain an intensity image. ORB feature descriptors are extracted from the image and encoded into a bag-of-words vector. The vector, used to identify the point cloud, is inserted into a database that is maintained by DBoW for fast place recognition queries. The returned candidate is further validated by matching visual feature descriptors. To reject matching outliers, we apply PnP, which minimizes the reprojection error of visual features\u2019 positions in Euclidean space with their correspondences in 2D image space, using RANSAC. Combining the advantages from both camera and lidar-based place recognition approaches, our method is truly rotation-invariant, and can tackle reverse revisiting and upside down revisiting. The proposed method is evaluated on datasets gathered from a variety of platforms over different scales and environments. Our implementation and datasets are available at https://git.io/image-lidar.",
        "primary_area": "",
        "author": "Tixiao Shan;Brendan Englot;F\u00e1bio Duarte;Carlo Ratti;Daniela Rus;Tixiao Shan;Brendan Englot;F\u00e1bio Duarte;Carlo Ratti;Daniela Rus",
        "authorids": "/37085681623;/37601539900;/37086125892;/37590016800;/37279652300;/37085681623;/37601539900;/37086125892;/37590016800;/37279652300",
        "aff": "Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, USA; Department of Mechanical Engineering, Stevens Institute of Technology, USA; Department of Urban Studies and Planning, Massachusetts Institute of Technology, USA; Department of Urban Studies and Planning, Massachusetts Institute of Technology, USA; Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562105/",
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15356404266887638847&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Stevens Institute of Technology",
        "aff_unique_dep": "Computer Science & Artificial Intelligence Laboratory;Department of Mechanical Engineering",
        "aff_unique_url": "https://web.mit.edu;https://www.stevens.edu",
        "aff_unique_abbr": "MIT;SIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560989",
        "title": "Robust Planning with Emergent Human-like Behavior for Agents Traveling in Groups",
        "track": "main",
        "status": "Poster",
        "abstract": "To enable robots to smoothly interact with humans during their travels together as a group, robots need the ability to adapt their motions under environmental changes and ensure all group members\u2019 routes are feasible. To achieve this ability, robots require knowledge of the final destination and the subgoals in between. In practice, such information is seldom shared explicitly among group members, and may be frequently updated. Under this uncertain setting, maintaining travel efficiency and behavior appropriateness becomes a challenge. Previous literature approached the problem by generating compliant coordinating motions inspired by human groups, with subgoal uncertainty remaining isolated from the plan evaluation process. We show that such coordination can lead the robot to \"bad\" transient states where inefficient planning and lost tracking may incur. We propose to resolve the problem by formulating the coordinating motion as a Bayesian stochastic game, to plan for the robot as a group member, in the meanwhile considering the long-term effect of uncertainty during path coordination. We show that the approach improves travel efficiency and partner tracking robustness, by preventing assertive decisions during the inference update process. Moreover, the approach presents \"agency\", in the sense that it can generate human-like motions, which can be applied and contribute to the pedestrian simulation literature; the approach also affords variants from the human-like motions to generate robot behaviors based on sensing capabilities, contributing to the methodology of robot behavior design.",
        "primary_area": "",
        "author": "Shih-Yun Lo;Elaine Schaertl Short;Andrea L. Thomaz;Shih-Yun Lo;Elaine Schaertl Short;Andrea L. Thomaz",
        "authorids": "/37087323268;/37401757800;/37296354000;/37087323268;/37401757800;/37296354000",
        "aff": "the University of Texas at Austin; Tufts University; the University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560989/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12825143783986709205&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Texas at Austin;Tufts University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.utexas.edu;https://www.tufts.edu",
        "aff_unique_abbr": "UT Austin;Tufts",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561218",
        "title": "Robust SRIF-based LiDAR-IMU Localization for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a tightly-coupled multi-sensor fusion architecture for autonomous vehicle applications, which achieves centimetre-level accuracy and high robustness in various scenarios. In order to realize robust and accurate point-cloud feature matching we propose a novel method for extracting structural, highly discriminative features from LiDAR point clouds. For high frequency motion prediction and noise propagation, we use incremental on-manifold IMU pre-integration. We also adopt a multi-frame sliding window square root inverse filter, so that the system maintains numerically stable results under the premise of limited power consumption. To verify our methodology, we test the fusion algorithm in multiple applications and platforms equipped with a LiDAR-IMU system. Our results demonstrate that our fusion framework attains state-of-the-art localization accuracy, high robustness and a good generalization ability.",
        "primary_area": "",
        "author": "Kun Li;Zhanpeng Ouyang;Lan Hu;Dayang Hao;Laurent Kneip;Kun Li;Zhanpeng Ouyang;Lan Hu;Dayang Hao;Laurent Kneip",
        "authorids": "/37088996728;/37088998024;/37088505304;/37089001503;/37569040300;/37088996728;/37088998024;/37088505304;/37089001503;/37569040300",
        "aff": "Alibaba Group, Damo Academy; Mobile Perception Lab, SIST, ShanghaiTech; Mobile Perception Lab, SIST, ShanghaiTech; Alibaba Group, Damo Academy; Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561218/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16380262661299661834&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;2",
        "aff_unique_norm": "Alibaba Group;ShanghaiTech University;Shanghai Engineering Research Center of Intelligent Vision and Imaging",
        "aff_unique_dep": "Damo Academy;School of Information Science and Technology;",
        "aff_unique_url": "https://www.alibaba.com;http://www.shanghaitech.edu.cn;",
        "aff_unique_abbr": "Alibaba;ShanghaiTech;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561176",
        "title": "Robust Semantic Map Matching Algorithm Based on Probabilistic Registration Model",
        "track": "main",
        "status": "Poster",
        "abstract": "The matching and fusing of local maps generated by multiple robots can greatly enhance the performance of relative localization and collaborative mapping. Currently, existing semantic matching methods are partly based on classical iterative closet point (ICP), which typically fail in cases with large initial error. What\u2019s more, current semantic matching algorithms have high computation complexity in optimizing the transformation matrix. To address the challenge of map matching with large initial error, this paper proposes a novel semantic map matching algorithm with large convergence region. The key novelty of this work is the designing of the initial transformation optimization algorithm and the probabilistic registration model to increase the convergence region. To reduce the initial error before the iteration process, the initial transformation matrix is optimized by estimating the credibility of the data association. At the same time, a factor reflecting the uncertainty of the initial error is calculated and introduced to the formulation of the probabilistic registration model, thereby accelerating the convergence process. The proposed algorithm is performed on public datasets and compared with existing methods, demonstrating the significant improvement in terms of matching accuracy and robustness.",
        "primary_area": "",
        "author": "Qingxiang Zhang;Meiling Wang;Yufeng Yue;Qingxiang Zhang;Meiling Wang;Yufeng Yue",
        "authorids": "/37089002259;/37406965500;/37086172414;/37089002259;/37406965500;/37086172414",
        "aff": "School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561176/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=253032768289000479&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Beijing Institute of Technology",
        "aff_unique_dep": "School of Automation",
        "aff_unique_url": "http://www.bit.edu.cn",
        "aff_unique_abbr": "BIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561616",
        "title": "Robust Skin-Feature Tracking in Free-Hand Video from Smartphone or Robot-Held Camera, to Enable Clinical-Tool Localization and Guidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Our novel skin-feature visual-tracking algorithm enables anatomic vSLAM and (by extension) localization of clinical tools relative to the patient\u2019s body. Tracking naturally occurring features is challenging due to patient uniqueness, deformability, and lack of an accurate a-priori 3D geometric model. Our method (i) tracks skin features in a smartphone-camera video sequence, (ii) performs anatomic Simultaneous Localization And Mapping (SLAM) of camera motion relative to the patient\u2019s 3D skin surface, and (iii) utilizes existing visual methods to track clinical tool(s) relative to the patient\u2019s reconstructed 3D skin surface. (We demonstrate tracking of a simulated ultrasound probe relative to the patient by using an Apriltag visual fiducial). Our skin-feature tracking method utilizes the Fourier-Mellin Transform for robust performance, which we incorporated and extend an existing Phase Only Correlation (POC) based algorithm to be suitable for our application of free-hand smartphone video, wherein the distance of the camera fluctuates relative to the patient. Our SLAM approach further utilizes Structure from Motion and Bundle Adjustment to achieve an accurate 3D model of the human body with minimal drift-error in camera trajectory. We believe this to be the first freehand smartphone-camera tracking of natural skin features for anatomic tracking of surgical tools, ultrasound probe, etc.",
        "primary_area": "",
        "author": "Chun-Yin Huang;John Galeotti;Chun-Yin Huang;John Galeotti",
        "authorids": "/37088997917;/38558753600;/37088997917;/38558753600",
        "aff": "Biomedical Engineering Department, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561616/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5168978146783098484&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Biomedical Engineering Department",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561118",
        "title": "Robust Trajectory Planning with Parametric Uncertainties",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we extend the previously introduced notion of closed-loop state sensitivity by introducing the concept of input sensitivity and by showing how to exploit it in a trajectory optimization framework. This allows to generate an optimal reference trajectory for a robot that minimizes the state and input sensitivities against uncertainties in the model parameters, thus producing inherently robust motion plans. We parametrize the reference trajectories with B\u00e9ziers curves and discuss how to consider linear and nonlinear constraints in the optimization process (e.g., input saturations). The whole machinery is validated via an extensive statistical campaign that clearly shows the interest of the proposed methodology.",
        "primary_area": "",
        "author": "Pascal Brault;Quentin Delamare;Paolo Robuffo Giordano;Pascal Brault;Quentin Delamare;Paolo Robuffo Giordano",
        "authorids": "/37089308665;/37086301982;/37544316400;/37089308665;/37086301982;/37544316400",
        "aff": "CNRS, Univ Rennes, Inria, IRISA, Campus de Beaulieu, Rennes Cedex, France; CNRS, Univ Rennes, Inria, IRISA, Campus de Beaulieu, Rennes Cedex, France; CNRS, Univ Rennes, Inria, IRISA, Campus de Beaulieu, Rennes Cedex, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561118/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13962064408364969468&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "CNRS",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.cnrs.fr",
        "aff_unique_abbr": "CNRS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Rennes",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561537",
        "title": "Robust Underwater Visual SLAM Fusing Acoustic Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose an approach for robust visual Simultaneous Localisation and Mapping (SLAM) in underwater environments leveraging acoustic, inertial and altimeter/depth sensors. Underwater visual SLAM is challenging due to factors including poor visibility caused by suspended particles in water, a lack of light and insufficient texture in the scene. Because of this, many state-of-the-art approaches rely on acoustic sensing instead of vision for underwater navigation.Building on the sparse visual SLAM system ORB-SLAM2, this paper proposes to improve the robustness of camera pose estimation in underwater environments by leveraging acoustic odometry, which derives a drifting estimate of the 6-DoF robot pose from fusion of a Doppler Velocity Log (DVL), a gyroscope and an altimeter or depth sensor. Acoustic odometry estimates are used as motion priors and we formulate pose residuals that are integrated within the camera pose tracking, local and global bundle adjustment procedures of ORB-SLAM2.The original design of ORB-SLAM2 supports a single map and it enters relocalisation when tracking is lost. This is a significant problem for scenarios where a robot does a continuous scanning motion without returning to a previously visited location. One of our main contributions is to enable the system to create a new map whenever it encounters a new scene where visual odometry can work. This new map is connected with its predecessor in a common graph using estimates from the proposed acoustic odometry. Experimental results on two underwater vehicles demonstrate the increased robustness of our approach compared to baseline ORB-SLAM2 in both controlled, uncontrolled and field environments.",
        "primary_area": "",
        "author": "Elizabeth Vargas;Raluca Scona;Jonatan Scharff Willners;Tomasz Luczynski;Yu Cao;Sen Wang;Yvan R. Petillot;Elizabeth Vargas;Raluca Scona;Jonatan Scharff Willners;Tomasz Luczynski;Yu Cao;Sen Wang;Yvan R. Petillot",
        "authorids": "/37086453255;/37086019206;/37086222444;/37085646043;/37089401809;/37086278300;/37282015500;/37086453255;/37086019206;/37086222444;/37085646043;/37089401809;/37086278300;/37282015500",
        "aff": "School of Engineering & Physical Sciences, Heriot-Watt University, UK; School of Engineering & Physical Sciences, Heriot-Watt University, UK; School of Engineering & Physical Sciences, Heriot-Watt University, UK; School of Engineering & Physical Sciences, Heriot-Watt University, UK; School of Engineering, University of Edinburgh, UK; School of Engineering & Physical Sciences, Heriot-Watt University, UK; School of Engineering & Physical Sciences, Heriot-Watt University, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561537/",
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13319041866003216957&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "Heriot-Watt University;University of Edinburgh",
        "aff_unique_dep": "School of Engineering & Physical Sciences;School of Engineering",
        "aff_unique_url": "https://www.hw.ac.uk;https://www.ed.ac.uk",
        "aff_unique_abbr": "HWU;Edinburgh",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561539",
        "title": "Robust localization for planar moving robot in changing environment: A perspective on density of correspondence and depth",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual localization for planar moving robot is important to various indoor service robotic applications. To handle the textureless areas and frequent human activities in indoor environments, a novel robust visual localization algorithm which leverages dense correspondence and sparse depth for planar moving robot is proposed. The key component is a minimal solution which computes the absolute camera pose with one 3D-2D correspondence and one 2D-2D correspondence. The advantages are obvious in two aspects. First, the robustness is enhanced as the sample set for pose estimation is maximal by utilizing all correspondences with or without depth. Second, no extra effort for dense map construction is required to exploit dense correspondences for handling textureless and repetitive texture scenes. That is meaningful as building a dense map is computational expensive especially in large scale. Moreover, a probabilistic analysis among different solutions is presented and an automatic solution selection mechanism is designed to maximize the success rate by selecting appropriate solutions in different environmental characteristics. Finally, a complete visual localization pipeline considering situations from the perspective of correspondence and depth density is summarized and validated on both simulation and public real-world indoor localization dataset.",
        "primary_area": "",
        "author": "Yanmei Jiao;Lilu Liu;Bo Fu;Xiaqing Ding;Minhang Wang;Yue Wang;Rong Xiong;Yanmei Jiao;Lilu Liu;Bo Fu;Xiaqing Ding;Minhang Wang;Yue Wang;Rong Xiong",
        "authorids": "/37086475262;/37088997987;/37087325170;/37086331151;/37088662584;/37072299700;/37271511300;/37086475262;/37088997987;/37087325170;/37086331151;/37088662584;/37072299700;/37271511300",
        "aff": "State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; Application Innovate Lab, Huawei Incorporated Company, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China; State Key Laboratory of Industrial Control and Technology, Zhejiang University, Hangzhou, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561539/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7753506429432144645&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;0;0",
        "aff_unique_norm": "Zhejiang University;Huawei",
        "aff_unique_dep": "State Key Laboratory of Industrial Control and Technology;Application Innovate Lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.huawei.com",
        "aff_unique_abbr": "ZJU;Huawei",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hangzhou;",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560890",
        "title": "Route Coverage Testing for Autonomous Vehicles via Map Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous vehicles (AVs) play an important role in transforming our transportation systems and relieving traffic congestion. To guarantee their safety, AVs must be sufficiently tested before they are deployed to public roads. Existing testing often focuses on AVs\u2019 collision avoidance on a given route. There is little work on the systematic testing for AVs\u2019 route planning and tracking on a map. In this paper, we propose CROUTE, a novel testing method based on a new AV testing criterion called route coverage. First, the map is modeled as a labeled Petri net, where roads, junctions, and traffic signs are modeled as places, transitions, and labels, respectively. Second, based on the Petri net, we define junctions\u2019 topology features and route features for junction classification. The topology feature describes the topology of roads forming the junction, and the route feature identifies the actions that a vehicle can take to follow a route. They can characterize route types on a map. Hence, route coverage measures how many route types are covered. We then propose a systematic method that aims to cover all route types for a well-designed AV system with a small number of test cases. We implement and evaluate CROUTE on Baidu Apollo running with the LGSVL simulator. We carry out testing on the map from a section of San Francisco and find six different types of issues in Apollo. The experiment results show the validity of route coverage and the efficiency of CROUTE.",
        "primary_area": "",
        "author": "Yun Tang;Yuan Zhou;Fenghua Wu;Yang Liu;Jun Sun;Wuling Huang;Gang Wang;Yun Tang;Yuan Zhou;Fenghua Wu;Yang Liu;Jun Sun;Wuling Huang;Gang Wang",
        "authorids": "/37088999726;/37085401730;/37088997494;/37537575300;/37424029200;/37651478700;/37404549600;/37088999726;/37085401730;/37088997494;/37537575300;/37424029200;/37651478700;/37404549600",
        "aff": "Alibaba-NTU Joint Research Institute, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computer Science and Engineering, Nanyang Technological University, Singapore; School of Computing and Information Systems, Singapore Management University, Singapore; Alibaba Group, Alibaba DAMO Academy, China; Alibaba Group, Alibaba DAMO Academy, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560890/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12057175055094293712&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;2",
        "aff_unique_norm": "Nanyang Technological University;Singapore Management University;Alibaba Group",
        "aff_unique_dep": "Alibaba-NTU Joint Research Institute;School of Computing and Information Systems;Alibaba DAMO Academy",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.smu.edu.sg;https://www.alibaba.com",
        "aff_unique_abbr": "NTU;SMU;Alibaba",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Singapore",
        "aff_country_unique_index": "0;0;0;0;0;1;1",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9561314",
        "title": "S2P2: Self-Supervised Goal-Directed Path Planning Using RGB-D Data for Robotic Wheelchairs",
        "track": "main",
        "status": "Poster",
        "abstract": "Path planning is a fundamental capability for autonomous navigation of robotic wheelchairs. With the impressive development of deep-learning technologies, imitation learning-based path planning approaches have achieved effective results in recent years. However, the disadvantages of these approaches are twofold: 1) they may need extensive time and labor to record expert demonstrations as training data; and 2) existing approaches could only receive high-level commands, such as turning left/right. These commands could be less sufficient for the navigation of mobile robots (e.g., robotic wheelchairs), which usually require exact poses of goals. We contribute a solution to this problem by proposing S2P2, a self-supervised goal-directed path planning approach. Specifically, we develop a pipeline to automatically generate planned path labels given as input RGB-D images and poses of goals. Then, we present a best-fit regression plane loss to train our data-driven path planning model based on the generated labels. Our S2P2 does not need pre-built maps, but it can be integrated into existing map-based navigation systems through our framework. Experimental results show that our S2P2 outperforms traditional path planning algorithms, and increases the robustness of existing map-based navigation systems. Our project page is available at https://sites.google.com/view/s2p2.",
        "primary_area": "",
        "author": "Hengli Wang;Yuxiang Sun;Rui Fan;Ming Liu;Hengli Wang;Yuxiang Sun;Rui Fan;Ming Liu",
        "authorids": "/37086939511;/37085435479;/37085892666;/37085398677;/37086939511;/37085435479;/37085892666;/37085398677",
        "aff": "Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, China; Department of Mechanical Engineering, The Hong Kong Polytechnic University, Hong Kong; Department of Ophthalmology, The University of California San Diego, La Jolla, CA, United States; Department of Electronic and Computer Engineering, The Hong Kong University of Science and Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561314/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5489651864260745616&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Hong Kong Polytechnic University;University of California, San Diego",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;Department of Mechanical Engineering;Department of Ophthalmology",
        "aff_unique_url": "https://www.ust.hk;https://www.polyu.edu.hk;https://ucsd.edu",
        "aff_unique_abbr": "HKUST;PolyU;UCSD",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Hong Kong SAR;La Jolla",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561305",
        "title": "S3Net: 3D LiDAR Sparse Semantic Segmentation Network",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic Segmentation is a crucial component in the perception systems of many applications, such as robotics and autonomous driving that rely on accurate environmental perception and understanding. In literature, several approaches are introduced to attempt LiDAR semantic segmentation task, such as projection-based (range-view or birds-eye-view), and voxel-based approaches. However, they either abandon the valuable 3D topology and geometric relations and suffer from information loss introduced in the projection process or are inefficient. Therefore, there is a need for accurate models capable of processing the 3D driving-scene point cloud in 3D space. In this paper, we propose S3Net, a novel convolutional neural network for LiDAR point cloud semantic segmentation. It adopts an encoder-decoder backbone that consists of Sparse Intra-channel Attention Module (SIntraAM), and Sparse Inter-channel Attention Module (SInterAM) to emphasize the fine details of both within each feature map and among nearby feature maps. To extract the global contexts in deeper layers, we introduce Sparse Residual Tower based upon sparse convolution that suits varying sparsity of LiDAR point cloud. In addition, geo-aware anisotrophic loss is leveraged to emphasize the semantic boundaries and penalize the noise within each predicted regions, leading to a robust prediction. Our experimental results show that the proposed method leads to a large improvement (12%) compared to its baseline counterpart (MinkNet42 [1]) on SemanticKITTI [2] test set and achieves state-of-the-art mIoU accuracy of semantic segmentation approaches.",
        "primary_area": "",
        "author": "Ran Cheng;Ryan Razani;Yuan Ren;Liu Bingbing;Ran Cheng;Ryan Razani;Yuan Ren;Liu Bingbing",
        "authorids": "/37088997657;/37086404456;/37088997700;/38257785200;/37088997657;/37086404456;/37088997700;/38257785200",
        "aff": "Huawei Noah\u2019s Ark Lab, Toronto, Canada; Huawei Noah\u2019s Ark Lab, Toronto, Canada; Huawei Noah\u2019s Ark Lab, Toronto, Canada; Huawei Noah\u2019s Ark Lab, Toronto, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561305/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6841335798038251085&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Huawei Noah\u2019s Ark Lab",
        "aff_unique_url": "https://www.huawei.com/en/ai/noahs-ark-lab",
        "aff_unique_abbr": "HNA Lab",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9560884",
        "title": "SA-LOAM: Semantic-aided LiDAR SLAM with Loop Closure",
        "track": "main",
        "status": "Poster",
        "abstract": "LiDAR-based SLAM system is admittedly more accurate and stable than others, while its loop closure detection is still an open issue. With the development of 3D semantic segmentation for point cloud, semantic information can be obtained conveniently and steadily, essential for high-level intelligence and conductive to SLAM. In this paper, we present a novel semantic-aided LiDAR SLAM with loop closure based on LOAM, named SA-LOAM, which leverages semantics in odometry as well as loop closure detection. Specifically, we propose a semantic-assisted ICP, including semantically matching, downsampling and plane constraint, and integrates a semantic graph-based place recognition method in our loop closure detection module. Benefitting from semantics, we can improve the localization accuracy, detect loop closures effectively, and construct a global consistent semantic map even in large-scale scenes. Extensive experiments on KITTI and Ford Campus dataset show that our system significantly improves baseline performance, has generalization ability to unseen data and achieves competitive results compared with state-of-the-art methods.",
        "primary_area": "",
        "author": "Lin Li;Xin Kong;Xiangrui Zhao;Wanlong Li;Feng Wen;Hongbo Zhang;Yong Liu;Lin Li;Xin Kong;Xiangrui Zhao;Wanlong Li;Feng Wen;Hongbo Zhang;Yong Liu",
        "authorids": "/37088997380;/37087322070;/37087122595;/37088687641;/37088690190;/37859161500;/37066946100;/37088997380;/37087322070;/37087122595;/37088687641;/37088690190;/37859161500;/37066946100",
        "aff": "Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China; Huawei Noah\u2019s Ark Lab, Beijing, China; Huawei Noah\u2019s Ark Lab, Beijing, China; Huawei Noah\u2019s Ark Lab, Beijing, China; Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, P. R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560884/",
        "gs_citation": 110,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14759082026633411986&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;1;0",
        "aff_unique_norm": "Zhejiang University;Huawei",
        "aff_unique_dep": "Institute of Cyber-Systems and Control;Huawei Noah\u2019s Ark Lab",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.huawei.com/en/ai/noahs-ark-lab",
        "aff_unique_abbr": "ZJU;HNA Lab",
        "aff_campus_unique_index": "0;0;0;1;1;1;0",
        "aff_campus_unique": "Hangzhou;Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561397",
        "title": "SCT-CNN: A Spatio-Channel-Temporal Attention CNN for Grasp Stability Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, tactile sensing has attracted great interest for robotic manipulation. Predicting if a grasp will be stable or not, i.e. if the grasped object will drop out of the gripper while being lifted, can aid robust robotic grasping. Previous methods paid equal attention to all regions of the tactile data matrix or all time-steps in the tactile sequence, which may include irrelevant or redundant information. In this paper, we propose to equip Convolutional Neural Networks with spatial-channel and temporal attention mechanisms (SCT attention CNN) to predict future grasp stability. To the best of our knowledge, this is the first time to use attention mechanisms for predicting grasp stability only relying on tactile information. We implement our experiments with 52 daily objects. Moreover, we compare different spatio-temporal models and attention mechanisms as an empirical study. We found a significant accuracy improvement of up to 5% when using SCT attention. We believe that attention mechanisms can also improve the performance of other tactile learning tasks in the future, such as slip detection and hardness perception.",
        "primary_area": "",
        "author": "Gang Yan;Alexander Schmitz;Satoshi Funabashi;Sophon Somlor;Tito Pradhono Tomo;Shigeki Sugano;Gang Yan;Alexander Schmitz;Satoshi Funabashi;Sophon Somlor;Tito Pradhono Tomo;Shigeki Sugano",
        "authorids": "/37086935752;/37587110100;/37085727304;/37085510233;/37085618711;/37274050800;/37086935752;/37587110100;/37085727304;/37085510233;/37085618711;/37274050800",
        "aff": "Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan; Dept. of Modern Mechanical Engineering, Faculty of Science and Engineering, Waseda University, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561397/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7563059434043999800&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Waseda University",
        "aff_unique_dep": "Dept. of Modern Mechanical Engineering",
        "aff_unique_url": "https://www.waseda.jp/top",
        "aff_unique_abbr": "Waseda",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561512",
        "title": "SD-DefSLAM: Semi-Direct Monocular SLAM for Deformable and Intracorporeal Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Conventional SLAM techniques strongly rely on scene rigidity to solve data association, ignoring dynamic parts of the scene. In this work we present Semi-Direct DefSLAM (SD-DefSLAM), a novel monocular deformable SLAM method able to map highly deforming environments, built on top of DefSLAM [1]. To robustly solve data association in challenging deforming scenes, SD-DefSLAM combines direct and indirect methods: an enhanced illumination-invariant Lucas-Kanade tracker for data association, geometric Bundle Adjustment for pose and deformable map estimation, and bag-of-words based on feature descriptors for camera relocalization. Dynamic objects are detected and segmented-out using a CNN trained for the specific application domain.We thoroughly evaluate our system in two public datasets. The mandala dataset is a SLAM benchmark with increasingly aggressive deformations. The Hamlyn dataset contains intracorporeal sequences that pose serious real-life challenges beyond deformation like weak texture, specular reflections, surgical tools and occlusions. Our results show that SD-DefSLAM outperforms DefSLAM in point tracking, reconstruction accuracy and scale drift thanks to the improvement in all the data association steps, being the first system able to robustly perform SLAM inside the human body.",
        "primary_area": "",
        "author": "Juan J. G\u00f3mez-Rodr\u00edguez;Jos\u00e9 Lamarca;Javier Morlana;Juan D. Tard\u00f3s;Jos\u00e9 M. M. Montiel;Juan J. G\u00f3mez-Rodr\u00edguez;Jos\u00e9 Lamarca;Javier Morlana;Juan D. Tard\u00f3s;Jos\u00e9 M. M. Montiel",
        "authorids": "/37088999448;/37086004285;/37088996111;/37351680900;/37274019300;/37088999448;/37086004285;/37088996111;/37351680900;/37274019300",
        "aff": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Aragon (I3A), Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Aragon (I3A), Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Aragon (I3A), Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Aragon (I3A), Universidad de Zaragoza, Zaragoza, Spain; Instituto de Investigaci\u00f3n en Ingenier\u00eda de Aragon (I3A), Universidad de Zaragoza, Zaragoza, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561512/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3671346253239689249&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Universidad de Zaragoza",
        "aff_unique_dep": "Instituto de Investigaci\u00f3n en Ingenier\u00eda de Aragon (I3A)",
        "aff_unique_url": "https://www.unizar.es",
        "aff_unique_abbr": "UniZar",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zaragoza",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9561328",
        "title": "SMMR-Explore: SubMap-based Multi-Robot Exploration System with Multi-robot Multi-target Potential Field Exploration Method",
        "track": "main",
        "status": "Poster",
        "abstract": "Collaborative exploration in an unknown environment without external positioning under limited communication is an essential task for multi-robot applications. For inter-robot positioning, various Distributed Simultaneous Localization and Mapping (DSLAM) systems share the Place Recognition (PR) descriptors and sensor data to estimate the relative pose between robots and merge robots\u2019 maps. As maps are constantly shared among robots in exploration, we design a map-based DSLAM framework, which only shares the submaps, eliminating the transfer of PR descriptors and sensor data. Our framework saves 30% of total communication traffic. For exploration, each robot is assigned to get much unknown information about environments with paying little travel cost. As the number of sampled points increases, the goal would change back and forth among sampled frontiers, leading to the downgrade in exploration efficiency and the overlap of trajectories. We propose an exploration strategy based on Multi-robot Multi-target Potential Field (MMPF), which can eliminate goal\u2019s back-and-forth changes, boosting the exploration efficiency by 1.03 \u00d7\u223c1.62 \u00d7 with 3 % \u223c 40 % travel cost saved. Our SubMap-based Multi-robot Exploration method (SMMR-Explore) is evaluated on both Gazebo simulator and real robots. The simulator and the exploration framework are published as an open-source ROS project at https://github.com/efc-robot/SMMR-Explore.",
        "primary_area": "",
        "author": "Jincheng Yu;Jianming Tong;Yuanfan Xu;Zhilin Xu;Haolin Dong;Tianxiang Yang;Yu Wang;Jincheng Yu;Jianming Tong;Yuanfan Xu;Zhilin Xu;Haolin Dong;Tianxiang Yang;Yu Wang",
        "authorids": "/37086203732;/37088995863;/37088526163;/37088419653;/37088876585;/37088890526;/37293645500;/37086203732;/37088995863;/37088526163;/37088419653;/37088876585;/37088890526;/37293645500",
        "aff": "Department of Electronic Engineering, Tsinghua University, Beijing, China; Georgia Institute of Technology, GA, USA; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China; Department of Electronic Engineering, Tsinghua University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561328/",
        "gs_citation": 76,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=282732969844974382&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;0;0;0;0",
        "aff_unique_norm": "Tsinghua University;Georgia Institute of Technology",
        "aff_unique_dep": "Department of Electronic Engineering;",
        "aff_unique_url": "https://www.tsinghua.edu.cn;https://www.gatech.edu",
        "aff_unique_abbr": "THU;Georgia Tech",
        "aff_campus_unique_index": "0;1;0;0;0;0;0",
        "aff_campus_unique": "Beijing;Georgia",
        "aff_country_unique_index": "0;1;0;0;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561061",
        "title": "SMT-Based Optimal Deployment of Mobile Rechargers",
        "track": "main",
        "status": "Poster",
        "abstract": "Efficient recharging is an essential requirement for autonomous mobile robots. In an indoor robotic application, charging stations can be installed offline. However, frequent trips to the charging stations cause inefficiency in the performance of the mobile robots. In an outdoor environment, a charging station cannot even be installed easily. We propose a framework and algorithms for enabling a group of mobile wireless rechargers to fulfill the energy requirement of autonomous mobile robots in a workspace efficiently. Our algorithm finds the optimal trajectories for the mobile rechargers in such a way that once there is a need for a recharge, the robots do not need to spend significant time and energy to get access to a recharger. Our algorithm is based on a reduction of the problems to Satisfiability Modulo Theory (SMT) solving problems. We present extensive experimental results to show that the optimal trajectories for mobile rechargers can be generated successfully for different types of robots and workspaces within a reasonable time. Moreover, a comparison with the performance of static charging stations establishes that mobile rechargers are more effective in terms of allowing the autonomous robot to continue their work for a longer time.",
        "primary_area": "",
        "author": "Tanmoy Kundu;Indranil Saha;Tanmoy Kundu;Indranil Saha",
        "authorids": "/37086455111;/37542496500;/37086455111;/37542496500",
        "aff": "Department of Computer Science and Engineering, Indian Institute of Technology Kanpur; Department of Computer Science and Engineering, Indian Institute of Technology Kanpur",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561061/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13626483995929368802&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Indian Institute of Technology Kanpur",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.iitk.ac.in",
        "aff_unique_abbr": "IIT Kanpur",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Kanpur",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9561020",
        "title": "SQRP: Sensing Quality-aware Robot Programming System for Non-expert Programmers",
        "track": "main",
        "status": "Poster",
        "abstract": "Robot programming typically makes use of a set of mechanical skills that is acquired by machine learning. Because there is in general no guarantee that machine learning produces robot programs that are free of surprising behavior, the safe execution of a robot program must utilize monitoring modules that take sensor data as inputs in real time to ensure the correctness of the skill execution. Owing to the fact that sensors and monitoring algorithms are usually subject to physical restrictions and that effective robot programming is sensitive to the selection of skill parameters, these considerations may lead to different sensor input qualities such as the view coverage of a vision system that determines whether a skill can be successfully deployed in performing a task. Choosing improper skill parameters may cause the monitoring modules to delay or miss the detection of important events such as a mechanical failure. These failures may reduce the throughput in robotic manufacturing and could even cause a destructive system crash. To address above issues, we propose a sensing quality-aware robot programming system that automatically computes the sensing qualities as a function of the robot\u2019s environment and uses the information to guide non-expert users to select proper skill parameters in the programming phase. We demonstrate our system framework on a 6DOF robot arm for an object pick-up task.",
        "primary_area": "",
        "author": "Yi-Hsuan Hsieh;Pei-Chi Huang;Aloysius K Mok;Yi-Hsuan Hsieh;Pei-Chi Huang;Aloysius K Mok",
        "authorids": "/37086464966;/37900068600;/37268069000;/37086464966;/37900068600;/37268069000",
        "aff": "Department of Computer Science, University of Texas at Austin; Department of Computer Science, University of Nebraska, Omaha; Department of Computer Science, University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561020/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8751772076720182475&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Texas at Austin;University of Nebraska",
        "aff_unique_dep": "Department of Computer Science;Department of Computer Science",
        "aff_unique_url": "https://www.utexas.edu;https://www.unomaha.edu",
        "aff_unique_abbr": "UT Austin;UNO",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Austin;Omaha",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560925",
        "title": "SSCNav: Confidence-Aware Semantic Scene Completion for Visual Semantic Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper focuses on visual semantic navigation, the task of producing actions for an active agent to navigate to a specified target object category in an unknown environment. To complete this task, the algorithm should simultaneously locate and navigate to an instance of the category. In comparison to the traditional point goal navigation, this task requires the agent to have a stronger contextual prior to indoor environments. We introduce SSCNav, an algorithm that explicitly models scene priors using a confidence-aware semantic scene completion module to complete the scene and guide the agent's navigation planning. Given a partial observation of the environment, SSC-Nav first infers a complete scene representation with semantic labels for the unobserved scene together with a confidence map associated with its own prediction. Then, a policy network infers the action from the scene completion result and confidence map. Our experiments demonstrate that the proposed scene completion module improves the efficiency of the downstream navigation policies. Code and data: https://sscnav.cs.columbia.edu/",
        "primary_area": "",
        "author": "Yiqing Liang;Boyuan Chen;Shuran Song;Yiqing Liang;Boyuan Chen;Shuran Song",
        "authorids": "/37088996125;/37089001188;/37085613509;/37088996125;/37089001188;/37085613509",
        "aff": "Columbia Unviersity; Columbia Unviersity; Columbia Unviersity",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560925/",
        "gs_citation": 72,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1302628381138302019&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561349",
        "title": "Safe and Efficient Model-free Adaptive Control via Bayesian Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Adaptive control approaches yield high-performance controllers when a precise system model or suitable parametrizations of the controller are available. Existing data-driven approaches for adaptive control mostly augment standard model-based methods with additional information about uncertainties in the dynamics or about disturbances. In this work, we propose a purely data-driven, model-free approach for adaptive control. Tuning low-level controllers based solely on system data raises concerns on the underlying algorithm safety and computational performance. Thus, our approach builds on GOOSE, an algorithm for safe and sample-efficient Bayesian optimization. We introduce several computational and algorithmic modifications in GOOSE that enable its practical use on a rotational motion system. We numerically demonstrate for several types of disturbances that our approach is sample efficient, outperforms constrained Bayesian optimization in terms of safety, and achieves the performance optima computed by grid evaluation. We further demonstrate the proposed adaptive control approach experimentally on a rotational motion system.",
        "primary_area": "",
        "author": "Christopher K\u00f6nig;Matteo Turchetta;John Lygeros;Alisa Rupenyan;Andreas Krause;Christopher K\u00f6nig;Matteo Turchetta;John Lygeros;Alisa Rupenyan;Andreas Krause",
        "authorids": "/37088996959;/37086465712;/37301174800;/37088339059;/37542827400;/37088996959;/37086465712;/37301174800;/37088339059;/37542827400",
        "aff": "Inspire AG, Zurich, Switzerland; Learning & Adaptive Systems group, ETH Zurich, Switzerland; Automatic Control Laboratory, ETH Zurich, Switzerland; Automatic Control Laboratory, ETH Zurich, Switzerland; Learning & Adaptive Systems group, ETH Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561349/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8173713272307154050&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;1",
        "aff_unique_norm": "Inspire AG;ETH Zurich",
        "aff_unique_dep": ";Learning & Adaptive Systems group",
        "aff_unique_url": ";https://www.ethz.ch",
        "aff_unique_abbr": ";ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561981",
        "title": "Safe, Passive Control for Mechanical Systems with Application to Physical Human-Robot Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a novel safe, passive, and robust control law for mechanical systems. The proposed approach addresses safety from a physical human-robot interaction perspective, where a robot must not only stay inside a pre-defined region, but respect velocity constraints and ensure passivity with respect to external perturbations that may arise from a human or the environment. The proposed control is written in closed-form, behaves well even during singular configurations, and allows any nominal control law to be applied inside the operating region as long as the safety requirements (e.g., velocity) are adhered to. The proposed method is implemented on a 6-DOF robot to demonstrate its effectiveness during a physical human-robot interaction task.",
        "primary_area": "",
        "author": "Wenceslao Shaw Cortez;Christos K. Verginis;Dimos V. Dimarogonas;Wenceslao Shaw Cortez;Christos K. Verginis;Dimos V. Dimarogonas",
        "authorids": "/37086262758;/37085751745;/37282084700;/37086262758;/37085751745;/37282084700",
        "aff": "School of EECS, Royal Institute of Technology (KTH), Stockholm, Sweden; School of EECS, Royal Institute of Technology (KTH), Stockholm, Sweden; School of EECS, Royal Institute of Technology (KTH), Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561981/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9591369468406498225&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Royal Institute of Technology (KTH)",
        "aff_unique_dep": "School of EECS",
        "aff_unique_url": "https://www.kth.se",
        "aff_unique_abbr": "KTH",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stockholm",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9561504",
        "title": "Safety Uncertainty in Control Barrier Functions using Gaussian Processes",
        "track": "main",
        "status": "Poster",
        "abstract": "For a dynamical system, safety is typically guaranteed by constraining the system states within a set defined a priori. A popular approach is to use control barrier functions (CBFs) that encode safety using a smooth function. However, typical constructions of the smooth function do not account for any notion of safety uncertainty for the system inside the safe set. Although, one can formulate uncertainty in the dynamics of the model in a CBF framework, observability of unmodeled dynamics is difficult, particularly in an online setting. Addressing these drawbacks, we present a novel formulation for synthesizing the CBF smooth function by taking into account safety uncertainty using online measurements of the system states. This uncertainty is encoded by computing the posterior variance using Gaussian processes conditioned on past measurement states. Our approach only requires observability of system states rather than the system dynamics. By incorporating safety uncertainty, the safe set can be dynamically expanded or compressed. This is achieved by computing a local safety map online at the present location and identifying samples with minimal safety exceeding the current safety limit. As more data is collected, the safety margin increases. Hence, these minimally safe exploratory samples can be used to expand the current safe set incrementally. We validate our approach experimentally by expanding an initial safe set, along x and y positions independently, for a quadrotor with safety. The experiment video can be seen at: https://youtu.be/9qvOf1UpRPw.",
        "primary_area": "",
        "author": "Mouhyemen Khan;Tatsuya Ibuki;Abhijit Chatterjee;Mouhyemen Khan;Tatsuya Ibuki;Abhijit Chatterjee",
        "authorids": "/37088487713;/37572237900;/37273696200;/37088487713;/37572237900;/37273696200",
        "aff": "School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA; Department of Electronics and Bioinformatics, School of Science and Technology, Meiji University, Kanagawa, Japan; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561504/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5838234375231095117&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Georgia Institute of Technology;Meiji University",
        "aff_unique_dep": "School of Electrical and Computer Engineering;Department of Electronics and Bioinformatics",
        "aff_unique_url": "https://www.gatech.edu;https://www.meiji.ac.jp",
        "aff_unique_abbr": "Georgia Tech;Meiji",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Atlanta;Kanagawa",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9561525",
        "title": "Safety With Limited Range Sensing Constraints For Fixed Wing Aircraft",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we discuss how to use a barrier function that is subject to kinematic constraints and limited sensing in order to guarantee that fixed wing unmanned aerial vehicles (UAVs) will maintain safe distances from each other at all times despite being subject to sensing constraints. Prior work has shown that a barrier function can be used to guarantee safe system operation when the state can be sensed at all times. However, we show that this construction does not guarantee safety when the UAVs are subject to limited range sensing. To resolve this issue, we introduce a method for constructing a new barrier function that accommodates limited sensing range from a previously existing barrier function that may not necessarily accommodate limited range sensing. We show that, under appropriate conditions, the newly constructed barrier function ensures system safety even in the presence of limited range sensing. We demonstrate the contribution of this paper in a simulated scenario of 20 fixed wing aircraft where the vehicles are able to maintain safe distances from each other even though the vehicles are subject to limited range sensing.",
        "primary_area": "",
        "author": "Eric Squires;Rohit Konda;Pietro Pierpaoli;Samuel Coogan;Magnus Egerstedt;Eric Squires;Rohit Konda;Pietro Pierpaoli;Samuel Coogan;Magnus Egerstedt",
        "authorids": "/37086496145;/37089545355;/37085665565;/38232457300;/37269707500;/37086496145;/37089545355;/37085665565;/38232457300;/37269707500",
        "aff": "Georgia Tech Research Institute; University of California Santa Barbara, Santa Barbara, California; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA; School of Electrical and Computer Engineering, Georgia Institute of Technology, Atlanta, GA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561525/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10062909865526074674&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;2",
        "aff_unique_norm": "Georgia Tech Research Institute;University of California, Santa Barbara;Georgia Institute of Technology",
        "aff_unique_dep": ";;School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gtri.gatech.edu;https://www.ucsb.edu;https://www.gatech.edu",
        "aff_unique_abbr": "GTRI;UCSB;Georgia Tech",
        "aff_campus_unique_index": "1;2;2;2",
        "aff_campus_unique": ";Santa Barbara;Atlanta",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560979",
        "title": "Saliency Features for 3D CAD-Data in the Context of Sampling-Based Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we consider disassembly scenarios for real-world 3D CAD-data, where each component is defined by a triangle mesh. For a fast construction of collision-free disassembly paths, common approaches use sampling-based rigid body motion planning which is well studied in the literature. One fact that has so far received little attention is that in industrial disassembly scenarios components are often attached to each other with flexible fastening elements like clips. In the planning process, the fastening elements show the following characteristics: 1) They can cause complex non-linear disassembly paths. 2) They are often deformable. 3) They are usually modeled in a relaxed state and as an unknown part of the rigid mesh. That leads to the problem that unavoidable collisions occur during the planning process. Hence, the localization of the fastening elements and the integration of this information into the motion planning process is crucial for an automatic disassembly.We present a new geometric solution to extract salient features of 3D meshes which is specialized to find the fastening elements within the otherwise rigid mesh. Our approach measures a vertex-based surface feature using a local Gauss map in combination with a local thickness computation of the mesh. We compare our surface feature to state-of-the-art mesh saliency methods on various examples. Further, we integrate this measure of per-vertex saliency into a motion planning process and demonstrate the effectiveness of our result on real-world planning scenarios from the automotive industry.",
        "primary_area": "",
        "author": "Robert Hegewald;Nicola Wolpert;Elmar Sch\u00f6mer;Robert Hegewald;Nicola Wolpert;Elmar Sch\u00f6mer",
        "authorids": "/37088998118;/37085352554;/37331462600;/37088998118;/37085352554;/37331462600",
        "aff": "Digital Factory Body in White & Validation, Mercedes-Benz AG, Germany; Department: Geomatics, Computer Science and Mathematics, University of Applied Science, Stuttgart, Germany; Department: Physics, Mathematics and Computer Science, Johannes Gutenberg - University, Mainz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560979/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14208955265605462706&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Mercedes-Benz AG;University of Applied Sciences Stuttgart;Johannes Gutenberg University Mainz",
        "aff_unique_dep": "Digital Factory Body in White & Validation;Department of Geomatics, Computer Science and Mathematics;Department of Physics, Mathematics and Computer Science",
        "aff_unique_url": "https://www.mercedes-benz.com;https://www.hft-stuttgart.de;https://www.jgu.de",
        "aff_unique_abbr": "MBAG;HFT Stuttgart;JGU",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Stuttgart;Mainz",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561842",
        "title": "Sample Efficient Reinforcement Learning via Model-Ensemble Exploration and Exploitation",
        "track": "main",
        "status": "Poster",
        "abstract": "Model-based deep reinforcement learning has achieved success in various domains that require high sample efficiencies, such as Go and robotics. However, there are some remaining issues, such as planning efficient explorations to learn more accurate dynamic models, evaluating the uncertainty of the learned models, and more rational utilization of models. To mitigate these issues, we present MEEE, a model-ensemble method that consists of optimistic exploration and weighted exploitation. During exploration, unlike prior methods directly selecting the optimal action that maximizes the expected accumulative return, our agent first generates a set of action candidates and then seeks out the optimal action that takes both expected return and future observation novelty into account. During exploitation, different discounted weights are assigned to imagined transition tuples according to their model uncertainty respectively, which will prevent model predictive error propagation in agent training. Experiments on several challenging continuous control benchmark tasks demonstrated that our approach outperforms other model-free and model-based state-of-the-art methods, especially in sample complexity.",
        "primary_area": "",
        "author": "Yao Yao;Li Xiao;Zhicheng An;Wanpeng Zhang;Dijun Luo;Yao Yao;Li Xiao;Zhicheng An;Wanpeng Zhang;Dijun Luo",
        "authorids": "/37089403584;/37088635351;/37088997345;/37088485976;/37088499385;/37089403584;/37088635351;/37088997345;/37088485976;/37088499385",
        "aff": "Tencent AI Lab, Shenzhen, China; TBSI, Tsinghua Shenzhen International Graduate School, Tsinghua University, Shenzhen, China; Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China; Tencent AI Lab, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561842/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2105562434726334493&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "Tencent;Tsinghua University",
        "aff_unique_dep": "AI Lab;TBSI, Tsinghua Shenzhen International Graduate School",
        "aff_unique_url": "https://ai.tencent.com;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "Tencent AI Lab;THU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560764",
        "title": "Sample-efficient Reinforcement Learning in Robotic Table Tennis",
        "track": "main",
        "status": "Poster",
        "abstract": "Reinforcement learning (RL) has achieved some impressive recent successes in various computer games and simulations. Most of these successes are based on having large numbers of episodes from which the agent can learn. In typical robotic applications, however, the number of feasible attempts is very limited. In this paper we present a sample-efficient RL algorithm applied to the example of a table tennis robot. In table tennis every stroke is different, with varying placement, speed and spin. An accurate return therefore has to be found depending on a high-dimensional continuous state space. To make learning in few trials possible the method is embedded into our robot system. In this way we can use a one-step environment. The state space depends on the ball at hitting time (position, velocity, spin) and the action is the racket state (orientation, velocity) at hitting. An actor-critic based deterministic policy gradient algorithm was developed for accelerated learning. Our approach performs competitively both in a simulation and on the real robot in a number of challenging scenarios. Accurate results are obtained without pre-training in under 200 episodes of training. The video presenting our experiments is available at https://youtu.be/uRAtdoL6Wpw.",
        "primary_area": "",
        "author": "Jonas Tebbe;Lukas Krauch;Yapeng Gao;Andreas Zell;Jonas Tebbe;Lukas Krauch;Yapeng Gao;Andreas Zell",
        "authorids": "/37086806680;/37088998811;/37086806943;/37276583400;/37086806680;/37088998811;/37086806943;/37276583400",
        "aff": "Computer Science Department, Cognitive Systems Group, University of Tuebingen, Tuebingen, Germany; Computer Science Department, Cognitive Systems Group, University of Tuebingen, Tuebingen, Germany; Computer Science Department, Cognitive Systems Group, University of Tuebingen, Tuebingen, Germany; Computer Science Department, Cognitive Systems Group, University of Tuebingen, Tuebingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560764/",
        "gs_citation": 42,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8324704222038530310&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Tuebingen",
        "aff_unique_dep": "Computer Science Department, Cognitive Systems Group",
        "aff_unique_url": "https://www.uni-tuebingen.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tuebingen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561244",
        "title": "Scalable Active Information Acquisition for Multi-Robot Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel highly scalable nonmyopic planning algorithm for multi-robot Active Information Acquisition (AIA) tasks. AIA scenarios include target localization and tracking, active SLAM, surveillance, environmental monitoring and others. The objective is to compute control policies for multiple robots which minimize the accumulated uncertainty of a static hidden state over an a priori unknown horizon. The majority of existing AIA approaches are centralized and, therefore, face scaling challenges. To mitigate this issue, we propose an online algorithm that relies on decomposing the AIA task into local tasks via a dynamic space-partitioning method. The local subtasks are formulated online and require the robots to switch between exploration and active information gathering roles depending on their functionality in the environment. The switching process is tightly integrated with optimizing information gathering giving rise to a hybrid control approach. We show that the proposed decomposition-based algorithm is probabilistically complete for homogeneous sensor teams and under linearity and Gaussian assumptions. We provide extensive simulation results showing that the proposed algorithm can address large-scale estimation tasks that are computationally challenging to solve using existing centralized approaches.",
        "primary_area": "",
        "author": "Yiannis Kantaros;George J. Pappas;Yiannis Kantaros;George J. Pappas",
        "authorids": "/37085499544;/37281547100;/37085499544;/37281547100",
        "aff": "GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA; GRASP Laboratory, University of Pennsylvania, Philadelphia, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561244/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12186390433579653785&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "GRASP Laboratory",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561550",
        "title": "Scalable Coverage Path Planning of Multi-Robot Teams for Monitoring Non-Convex Areas",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel multi-robot coverage path planning (CPP) algorithm - aka SCoPP - that provides a time-efficient solution, with workload balanced plans for each robot in a multi-robot system, based on their initial states. This algorithm accounts for discontinuities (e.g., no-fly zones) in a specified area of interest, and provides an optimized ordered list of way-points per robot using a discrete, computationally efficient, nearest neighbor path planning algorithm. This algorithm involves five main stages, which include the transformation of the user\u2019s input as a set of vertices in geographical coordinates, discretization, load-balanced partitioning, auctioning of conflict cells in a discretized space, and a path planning procedure. To evaluate the effectiveness of the primary algorithm, a multi-unmanned aerial vehicle (UAV) post-flood assessment application is considered, and the performance of the algorithm is tested on three test maps of varying sizes. Additionally, our method is compared with a state-of-the-art method created by Guasella et al. Further analyses on scalability and computational time of SCoPP are conducted. The results show that SCoPP is superior in terms of mission completion time; its computing time is found to be under 2 mins for a large map covered by a 150-robot team, thereby demonstrating its computationally scalability.",
        "primary_area": "",
        "author": "Leighton Collins;Payam Ghassemi;Ehsan T. Esfahani;David Doermann;Karthik Dantu;Souma Chowdhury;Leighton Collins;Payam Ghassemi;Ehsan T. Esfahani;David Doermann;Karthik Dantu;Souma Chowdhury",
        "authorids": "/37089001996;/37085518637;/37945498100;/37271030100;/37328608800;/37086117851;/37089001996;/37085518637;/37945498100;/37271030100;/37328608800;/37086117851",
        "aff": "Department of Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA; Department of Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA; Department of Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA; Department of Computer Science and Engineering, University at Buffalo, Buffalo, NY, USA; Department of Computer Science and Engineering, University at Buffalo, Buffalo, NY, USA; Department of Mechanical and Aerospace Engineering, University at Buffalo, Buffalo, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561550/",
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4673699467674148300&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University at Buffalo",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.buffalo.edu",
        "aff_unique_abbr": "UB",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Buffalo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561561",
        "title": "Scalable Learning of Safety Guarantees for Autonomous Systems using Hamilton-Jacobi Reachability",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous systems like aircraft and assistive robots often operate in scenarios where guaranteeing safety is critical. Methods like Hamilton-Jacobi reachability can provide guaranteed safe sets and controllers for such systems. However, often these same scenarios have unknown or uncertain environments, system dynamics, or predictions of other agents. As the system is operating, it may learn new knowledge about these uncertainties and should therefore update its safety analysis accordingly. However, work to learn and update safety analysis is limited to small systems of about two dimensions due to the computational complexity of the analysis. In this paper we synthesize several techniques to speed up computation: decomposition, warm-starting, and adaptive grids. Using this new framework we can update safe sets by one or more orders of magnitude faster than prior work, making this technique practical for many realistic systems. We demonstrate our results on simulated 2D and 10D near-hover quadcopters operating in a windy environment.",
        "primary_area": "",
        "author": "Sylvia Herbert;Jason J. Choi;Suvansh Sanjeev;Marsalis Gibson;Koushil Sreenath;Claire J. Tomlin;Sylvia Herbert;Jason J. Choi;Suvansh Sanjeev;Marsalis Gibson;Koushil Sreenath;Claire J. Tomlin",
        "authorids": "/37086011005;/37088919874;/37088998408;/37088996448;/37563179200;/37271692600;/37086011005;/37088919874;/37088998408;/37088996448;/37563179200;/37271692600",
        "aff": "Sylvia Herbert; Jason J. Choi; Suvansh Sanjeev; Marsalis Gibson; Koushil Sreenath; Claire J. Tomlin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561561/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16159959180744497394&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9561478",
        "title": "Scalable POMDP Decision-Making Using Circulant Controllers",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel policy representation for partially observable Markov decision processes (POMDPs) called circulant controllers and a provably efficient gradient-based algorithm for them. A formal mathematical description is provided that leverages circulant matrices for the controller\u2019s stochastic node transitions. This structure is particularly effective for capturing decision-making patterns found in real-world domains with repeated periodic behaviors that adapt their cycles based on observation. This includes domains such as bipedal walking over varied terrain, pick-and-place tasks in warehouses, and home healthcare monitoring and medicine delivery in household environments. A performant gradient-based algorithm is presented with a detailed theoretical analysis, formally proving the algorithm\u2019s improved performance, as well as circulant controllers\u2019 structural properties. Experiments on these domains demonstrate that the proposed controller algorithm outperforms other state-of-the-art POMDP controller algorithms. The proposed novel controller approach is demonstrated on an actual robot performing a navigation task in a real household environment.",
        "primary_area": "",
        "author": "Kyle Hollins Wray;Kenneth Czuprynski;Kyle Hollins Wray;Kenneth Czuprynski",
        "authorids": "/37086208879;/37088997154;/37086208879;/37088997154",
        "aff": "Kyle Hollins Wray; Kenneth Czuprynski",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561478/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=64728233599391151&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9561203",
        "title": "Scalable Recursive Distributed Collaborative State Estimation for Aided Inertial Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel approach to recover outdated cross-covariance between correlated agents at the moment they perform joint observations. This allows to render Collaborative State Estimation (CSE) fully distributed, with communication only required for the moment of joint observation and most importantly, it significantly reduces the maintenance effort in case of high frequent propagation sensors. These properties make the approach suitable to a wide range of multi-robot applications. In our evaluation on a Quaternion-based Error-State Extended Kalman Filter (Q-ESEKF) using an Inertial Measurement Unit (IMU) as propagation sensor at a rate of 200Hz, we showed a significant speedup against our previous approach for maintaining a couple of interdependence. We compared the approach in total against four different approaches on both, a simulation and on a real-world dataset for Micro Aerial Vehicles (MAVs). Video: https://youtu.be/xkljfwbhMP0",
        "primary_area": "",
        "author": "Roland Jung;Stephan Weiss;Roland Jung;Stephan Weiss",
        "authorids": "/37087323495;/37535323400;/37087323495;/37535323400",
        "aff": "Karl Popper School on Networked Autonomous Aerial Vehicles (KPK-NAV), University of Klagenfurt, Austria; Control of Networked Systems Group, University of Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561203/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16267653767634331202&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Klagenfurt",
        "aff_unique_dep": "Karl Popper School on Networked Autonomous Aerial Vehicles (KPK-NAV)",
        "aff_unique_url": "https://www.uni-klagenfurt.at",
        "aff_unique_abbr": "Uni Klagenfurt",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9561198",
        "title": "Scoring Graspability based on Grasp Regression for Better Grasp Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Grasping objects is one of the most important abilities that a robot needs to master in order to interact with its environment. Current state-of-the-art methods rely on deep neural networks trained to jointly predict a graspability score together with a regression of an offset with respect to grasp reference parameters. However, these two predictions are performed independently, which can lead to a decrease in the actual graspability score when applying the predicted offset. Therefore, in this paper, we extend a state-of-the-art neural network with a scorer that evaluates the graspability of a given position, and introduce a novel loss function which correlates regression of grasp parameters with graspability score. We show that this novel architecture improves performance from 82.13% for a state-of-the-art grasp detection network to 85.74% on Jacquard dataset. When the learned model is transferred onto a real robot, the proposed method correlating graspability and grasp regression achieves a 92.4% rate compared to 88.1% for the baseline trained without the correlation.",
        "primary_area": "",
        "author": "Amaury Depierre;Emmanuel Dellandr\u00e9a;Liming Chen;Amaury Depierre;Emmanuel Dellandr\u00e9a;Liming Chen",
        "authorids": "/37086577812;/37391554000;/37292793900;/37086577812;/37391554000;/37292793900",
        "aff": "Ecole Centrale de Lyon, LIRIS, CNRS UMR 5205, University of Lyon, France; Ecole Centrale de Lyon, LIRIS, CNRS UMR 5205, University of Lyon, France; Ecole Centrale de Lyon, LIRIS, CNRS UMR 5205, University of Lyon, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561198/",
        "gs_citation": 36,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7397366169308915078&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Ecole Centrale de Lyon",
        "aff_unique_dep": "LIRIS, CNRS UMR 5205",
        "aff_unique_url": "https://www.ec-lyon.fr",
        "aff_unique_abbr": "ECL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561657",
        "title": "Screw theory-based stiffness analysis for a fluidic-driven soft robotic manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robotic manipulators have been created and investigated for a number of applications due to their advantages over rigid robots. In minimally invasive surgery, for instance, soft robots have successfully demonstrated a number of benefits due to the compliant and flexible nature of the material they are made of. However, these type of robots struggle with performing tasks that require on-demand stiffness i.e. exerting higher forces to the surrounding environment. A number of semi-active and active mechanisms have been investigated to change and control the stiffness of soft robotic manipulators. Embedding these mechanisms in soft manipulators for spacerestricted applications can be challenging though.To better understand the inherent passive stiffness properties of soft manipulators, we propose a screw theory-based stiffness analysis for fluidic-driven continuum soft robotic manipulators. First, we derive the forward kinematics based on a parameter-based piece-wise constant curvature model. It is worth noting, our stiffness analysis can be conducted based on any freespace forward kinematic model. Then our stiffness analysis and mapping methodology is conducted based on screw theory. Initial results of our approach demonstrate the feasibility comparing computational and experimental data.",
        "primary_area": "",
        "author": "Jialei Shi;Julio C. Frantz;Azadeh Shariati;Ali Shiva;Jian S Dai;Daniel Martins;Helge A. Wurdemann;Jialei Shi;Julio C. Frantz;Azadeh Shariati;Ali Shiva;Jian S Dai;Daniel Martins;Helge A. Wurdemann",
        "authorids": "/37088996767;/37086101091;/37090019645;/37085713560;/37398454800;/37997322900;/37991827000;/37088996767;/37086101091;/37090019645;/37085713560;/37398454800;/37997322900;/37991827000",
        "aff": "Department of Mechanical Engineering, University College London, UK; Department of Mechanical Engineering, Federal University of Santa Catarina, Brazil; Department of Mechanical Engineering, University College London, UK; Department of Informatics, King\u2019s College London, UK; Department of Informatics, King\u2019s College London, UK; Department of Mechanical Engineering, Federal University of Santa Catarina, Brazil; Department of Mechanical Engineering, University College London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561657/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10178436121068445083&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;0;2;2;1;0",
        "aff_unique_norm": "University College London;Federal University of Santa Catarina;King\u2019s College London",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Mechanical Engineering;Department of Informatics",
        "aff_unique_url": "https://www.ucl.ac.uk;https://www.ufsc.br;https://www.kcl.ac.uk",
        "aff_unique_abbr": "UCL;UFSC;KCL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;0;0;1;0",
        "aff_country_unique": "United Kingdom;Brazil"
    },
    {
        "id": "9561132",
        "title": "ScrewNet: Category-Independent Articulation Model Estimation From Depth Images Using Screw Theory",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots in human environments will need to interact with a wide variety of articulated objects such as cabinets, drawers, and dishwashers while assisting humans in performing day-to-day tasks. Existing methods either require objects to be textured or need to know the articulation model category a priori for estimating the model parameters for an articulated object. We propose ScrewNet, a novel approach that estimates an object\u2019s articulation model directly from depth images without requiring a priori knowledge of the articulation model category. ScrewNet uses screw theory to unify the representation of different articulation types and perform category-independent articulation model estimation. We evaluate our approach on two benchmarking datasets and three real-world objects and compare its performance with a current state-of-the-art method. Results demonstrate that ScrewNet can successfully estimate the articulation models and their parameters for novel objects across articulation model categories with better on average accuracy than the prior state-of-the-art method.",
        "primary_area": "",
        "author": "Ajinkya Jain;Rudolf Lioutikov;Caleb Chuck;Scott Niekum;Ajinkya Jain;Rudolf Lioutikov;Caleb Chuck;Scott Niekum",
        "authorids": "/37088686012;/37085362450;/37085907116;/37395003900;/37088686012;/37085362450;/37085907116;/37395003900",
        "aff": "Personal Autonomous Robotics Lab (PeARL), The University of Texas at Austin; Personal Autonomous Robotics Lab (PeARL), The University of Texas at Austin; Personal Autonomous Robotics Lab (PeARL), The University of Texas at Austin; Personal Autonomous Robotics Lab (PeARL), The University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561132/",
        "gs_citation": 96,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12116866749428368960&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Texas at Austin",
        "aff_unique_dep": "Personal Autonomous Robotics Lab (PeARL)",
        "aff_unique_url": "https://www.utexas.edu",
        "aff_unique_abbr": "UT Austin",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Austin",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560852",
        "title": "Search-Based Online Trajectory Planning for Car-like Robots in Highly Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a search-based partial motion planner for generating feasible trajectories of car-like robots in highly dynamic environments. The planner searches for smooth, safe, and near-time-optimal trajectories by exploring a state graph built on motion primitives. To enable fast online planning, we propose an efficient path searching algorithm based on the aggregation and pruning of motion primitives. We then propose a fast collision checking algorithm that takes into account the motions of moving obstacles. The algorithm linearizes relative motions between the robot and obstacles, and then checks collisions by calculating a point-line distance. Benefiting from the fast searching and collision checking algorithms, the planner can effectively explore the state-time space to generate near-time-optimal solutions. Experiments show that the proposed method can generate feasible trajectories within milliseconds while maintaining a higher success rate than up-to-date methods, which significantly demonstrates its advantages.",
        "primary_area": "",
        "author": "Jiahui Lin;Tong Zhou;Delong Zhu;Jianbang Liu;Max Q.-H. Meng;Jiahui Lin;Tong Zhou;Delong Zhu;Jianbang Liu;Max Q.-H. Meng",
        "authorids": "/37088997220;/37086578215;/37086137408;/37088998181;/37274117000;/37088997220;/37086578215;/37086137408;/37088998181;/37274117000",
        "aff": "Department of Electronic Engineering, The Chinese University of Hong Kong, China; Department of Electronic Engineering, The Chinese University of Hong Kong, China; Department of Electronic Engineering, The Chinese University of Hong Kong, China; Department of Electronic Engineering, The Chinese University of Hong Kong, China; Department of Electronic Engineering, Chinese University of Hong Kong, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560852/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13477537248881654547&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electronic Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Hong Kong;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561310",
        "title": "Search-based Planning for Active Sensing in Goal-Directed Coverage Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "Path planning for robotic coverage is the task of determining a collision-free robot trajectory that observes all points of interest in an environment. Robots employed for such tasks are often capable of exercising active control over onboard observational sensors during navigation. We address the problem of planning robot and sensor trajectories that maximize information gain in such tasks, where the robot needs to cover points of interest with its sensor footprint. Search-based planners in general guarantee completeness and provable bounds on sub-optimality with respect to an underlying graph discretization. However, searching for kinodynamically feasible paths in the joint space of robot and sensor state variables with standard search is computationally expensive. We propose two alternative search-based approaches to this problem. The first solves for robot and sensor trajectories independently in decoupled state spaces while maintaining a history of sensor headings during the search. The second is a two-step approach that first quickly computes a solution in decoupled state spaces and then refines it by searching its local neighborhood in the joint space for a better solution. We evaluate our approaches in simulation with a kinodynamically constrained unmanned aerial vehicle performing coverage over a 2D environment and show their benefits.",
        "primary_area": "",
        "author": "Tushar Kusnur;Dhruv Mauria Saxena;Maxim Likhachev;Tushar Kusnur;Dhruv Mauria Saxena;Maxim Likhachev",
        "authorids": "/37086579092;/37086188218;/37309318800;/37086579092;/37086188218;/37309318800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561310/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9581592010618738872&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560969",
        "title": "Search-based Planning of Dynamic MAV Trajectories Using Local Multiresolution State Lattices",
        "track": "main",
        "status": "Poster",
        "abstract": "Search-based methods that use motion primitives can incorporate the system\u2019s dynamics into the planning and thus generate dynamically feasible MAV trajectories that are globally optimal. However, searching high-dimensional state lattices is computationally expensive. Local multiresolution is a commonly used method to accelerate spatial path planning. While paths within the vicinity of the robot are represented at high resolution, the representation gets coarser for more distant parts. In this work, we apply the concept of local multiresolution to high-dimensional state lattices that include velocities and accelerations. Experiments show that our proposed approach significantly reduces planning times. Thus, it increases the applicability to large dynamic environments, where frequent replanning is necessary.",
        "primary_area": "",
        "author": "Daniel Schleich;Sven Behnke;Daniel Schleich;Sven Behnke",
        "authorids": "/37088599582;/37295987100;/37088599582;/37295987100",
        "aff": "Autonomous Intelligent Systems group, University of Bonn, Germany; Autonomous Intelligent Systems group, University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560969/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14989268185197570441&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "Autonomous Intelligent Systems group",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9560940",
        "title": "Secure Planning Against Stealthy Attacks via Model-Free Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We consider the problem of security-aware planning in an unknown stochastic environment, in the presence of attacks on control signals (i.e., actuators) of the robot. We model the attacker as an agent who has the full knowledge of the controller as well as the employed intrusion-detection system and who wants to prevent the controller from performing tasks while staying stealthy. We formulate the problem as a stochastic game between the attacker and the controller and present an approach to express the objective of such an agent and the controller as a combined linear temporal logic (LTL) formula. We then show that the planning problem, described formally as the problem of satisfying an LTL formula in a stochastic game, can be solved via model-free reinforcement learning when the environment is completely unknown. Finally, we illustrate and evaluate our methods on two robotic planning case studies.",
        "primary_area": "",
        "author": "Alper Kamil Bozkurt;Yu Wang;Miroslav Pajic;Alper Kamil Bozkurt;Yu Wang;Miroslav Pajic",
        "authorids": "/37088507578;/37085560879;/37294788600;/37088507578;/37085560879;/37294788600",
        "aff": "Duke University, Durham, NC, USA; Duke University, Durham, NC, USA; Duke University, Durham, NC, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560940/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16142732073442770076&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Duke University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.duke.edu",
        "aff_unique_abbr": "Duke",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Durham",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561523",
        "title": "Self-Guided Instance-Aware Network for Depth Completion and Enhancement",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth completion aims at inferring a dense depth image from sparse depth measurement since glossy, transparent or distant surface cannot be scanned properly by the sensor. Most of existing methods directly interpolate the missing depth measurements based on pixel-wise image content and the corresponding neighboring depth values. Consequently, this leads to blurred boundaries or inaccurate structure of object. To address these problems, we propose a novel self-guided instance-aware network (SG-IANet) that: (1) utilize self-guided mechanism to extract instance-level features that is needed for depth restoration, (2) exploit the geometric and context information into network learning to conform to the underlying constraints for edge clarity and structure consistency, (3) regularize the depth estimation and mitigate the impact of noise by instance-aware learning, and (4) train with synthetic data only by domain randomization to bridge the reality gap. Extensive experiments on synthetic and real world dataset demonstrate that our proposed method outperforms previous works. Further ablation studies give more insights into the proposed method and demonstrate the generalization capability of our model.",
        "primary_area": "",
        "author": "Zhongzhen Luo;Fengjia Zhang;Guoyi Fu;Jiajie Xu;Zhongzhen Luo;Fengjia Zhang;Guoyi Fu;Jiajie Xu",
        "authorids": "/37088996492;/37088998749;/37089002188;/37088996311;/37088996492;/37088998749;/37089002188;/37088996311",
        "aff": "Epson Research, Markham, Ontario, Canada; University of Toronto, Toronto, Ontario, Canada; Epson Research, Markham, Ontario, Canada; University of Toronto, Toronto, Ontario, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561523/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8057899283523146565&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "Epson Research;University of Toronto",
        "aff_unique_dep": ";",
        "aff_unique_url": ";https://www.utoronto.ca",
        "aff_unique_abbr": ";U of T",
        "aff_campus_unique_index": "0;1;0;1",
        "aff_campus_unique": "Markham;Toronto",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561411",
        "title": "Self-Imitation Learning by Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Imitation learning (IL) enables robots to acquire skills quickly by transferring expert knowledge, which is widely adopted in reinforcement learning (RL) to initialize exploration. However, in long-horizon motion planning tasks, a challenging problem in deploying IL and RL methods is how to generate and collect massive, broadly distributed data such that these methods can generalize effectively. In this work, we solve this problem using our proposed approach called self-imitation learning by planning (SILP), where demonstration data are collected automatically by planning on the visited states from the current policy. SILP is inspired by the observation that successfully visited states in the early reinforcement learning stage are collision-free nodes in the graph-search based motion planner, so we can plan and relabel robot's own trials as demonstrations for policy learning. Due to these self-generated demonstrations, we relieve the human operator from the laborious data preparation process required by IL and RL methods in solving complex motion planning tasks. The evaluation results show that our SILP method achieves higher success rates and enhances sample efficiency compared to selected baselines, and the policy learned in simulation performs well in a real-world placement task with changing goals and obstacles.",
        "primary_area": "",
        "author": "Sha Luo;Hamidreza Kasaei;Lambert Schomaker;Sha Luo;Hamidreza Kasaei;Lambert Schomaker",
        "authorids": "/37088518161;/37088515518;/37270051900;/37088518161;/37088515518;/37270051900",
        "aff": "Department of Artificial Intelligence, University of Groningen, the Netherlands; Department of Artificial Intelligence, University of Groningen, the Netherlands; Department of Artificial Intelligence, University of Groningen, the Netherlands",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561411/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17105187309308606912&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Groningen",
        "aff_unique_dep": "Department of Artificial Intelligence",
        "aff_unique_url": "https://www.rug.nl",
        "aff_unique_abbr": "RUG",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Netherlands"
    },
    {
        "id": "9561407",
        "title": "Self-Organized Evasive Fountain Maneuvers with a Bioinspired Underwater Robot Collective",
        "track": "main",
        "status": "Poster",
        "abstract": "Several animal species self-organize into large groups to leverage vital behaviors such as foraging, construction, or predator evasion. With the advancement of robotics and automation, engineered multi-agent systems have been inspired to achieve similarly high degrees of scalable, robust, and adaptable autonomy through decentralized and dynamic coordination. So far however, they have been most successfully demonstrated above ground or with partial assistance from central controllers and external tracking. Here we demonstrate an underwater robot collective that realizes full spatiotemporal coordination. Using the example of fish-inspired evasive maneuvers, our robots display alignment, formation control, and coordinated escape, enabled by real-time on-board multi-robot tracking and local decision making. Accompanied by a custom simulator, this robotic platform advances the physically- validated development of algorithms for collective behaviors and future applications including collective exploration, tracking and capture, or environmental sampling.",
        "primary_area": "",
        "author": "Florian Berlinger;Paula Wulkop;Radhika Nagpal;Florian Berlinger;Paula Wulkop;Radhika Nagpal",
        "authorids": "/37086054307;/37086550781;/37286742900;/37086054307;/37086550781;/37286742900",
        "aff": "John A. Paulson School of Engineering and Applied Science, Harvard University, Cambridge, Massachusetts; John A. Paulson School of Engineering and Applied Science, Harvard University, Cambridge, Massachusetts; John A. Paulson School of Engineering and Applied Science, Harvard University, Cambridge, Massachusetts",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561407/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10954733007409478331&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Harvard University",
        "aff_unique_dep": "John A. Paulson School of Engineering and Applied Science",
        "aff_unique_url": "https://www.harvard.edu",
        "aff_unique_abbr": "Harvard",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561508",
        "title": "Self-Supervised Learning for Monocular Depth Estimation on Minimally Invasive Surgery Scenes",
        "track": "main",
        "status": "Poster",
        "abstract": "Self-supervised learning algorithms that compute depth map from monocular videos have achieved remarkable performance on urban scenes and have been applied extensively. These techniques still face significant challenges, however, when applied directly to endoscopic videos because of the brightness variations from frame to frame and inadequate representation learning during the training phase. Inspired by the optical flow for motion alignment between adjacent frames, we design a AFNet with structural stability loss and residual-based smoothness loss to learn the appearance flow across adjacent frames, which handles the brightness inconsistency issue efficaciously. In addition, we propose a novel self-attention mechanism named feature scaling module to alleviate the inadequate representation learning problem. In a comparison study to the current state-of-the-art self-supervised methods explored for urban videos on the SCARED dataset, the developed model surpasses existing methods by a large margin.",
        "primary_area": "",
        "author": "Shuwei Shao;Zhongcai Pei;Weihai Chen;Baochang Zhang;Xingming Wu;Dianmin Sun;David Doermann;Shuwei Shao;Zhongcai Pei;Weihai Chen;Baochang Zhang;Xingming Wu;Dianmin Sun;David Doermann",
        "authorids": "/37088998446;/37592042000;/37279188000;/37405129100;/37539925400;/37087228600;/37271030100;/37088998446;/37592042000;/37279188000;/37405129100;/37539925400;/37087228600;/37271030100",
        "aff": "Beihang University, Beijing, China; Beihang University, Beijing, China; Beihang University, Beijing, China; Shenzhen Academy of Aerospace Technology, Shenzhen, China; Beihang University, Beijing, China; Shandong Cancer Hospital, Shandong University, Jinan, China; University at Buffalo, Buffalo, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561508/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8162230870260764891&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;2;3",
        "aff_unique_norm": "Beihang University;Shenzhen Academy of Aerospace Technology;Shandong University;University at Buffalo",
        "aff_unique_dep": ";;Shandong Cancer Hospital;",
        "aff_unique_url": "http://www.buaa.edu.cn/;;http://www.sdu.edu.cn;https://www.buffalo.edu",
        "aff_unique_abbr": "BUAA;;SDU;UB",
        "aff_campus_unique_index": "0;0;0;1;0;2;3",
        "aff_campus_unique": "Beijing;Shenzhen;Jinan;Buffalo",
        "aff_country_unique_index": "0;0;0;0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561701",
        "title": "Self-Supervised Learning of Lidar Segmentation for Autonomous Indoor Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a self-supervised learning approach for the semantic segmentation of lidar frames. Our method is used to train a deep point cloud segmentation architecture without any human annotation. The annotation process is automated with the combination of simultaneous localization and mapping (SLAM) and ray-tracing algorithms. By performing multiple navigation sessions in the same environment, we are able to identify permanent structures, such as walls, and disentangle short-term and long-term movable objects, such as people and tables, respectively. New sessions can then be performed using a network trained to predict these semantic labels. We demonstrate the ability of our approach to improve itself over time, from one session to the next. With semantically filtered point clouds, our robot can navigate through more complex scenarios, which, when added to the training pool, help to improve our network predictions. We provide insights into our network predictions and show that our approach can also improve the performances of common localization techniques.",
        "primary_area": "",
        "author": "Hugues Thomas;Ben Agro;Mona Gridseth;Jian Zhang;Timothy D. Barfoot;Hugues Thomas;Ben Agro;Mona Gridseth;Jian Zhang;Timothy D. Barfoot",
        "authorids": "/37088643515;/37088997437;/37072345900;/37086568802;/37283734000;/37088643515;/37088997437;/37072345900;/37086568802;/37283734000",
        "aff": "University of Toronto Institute for Aerospace Studies (UTIAS), Dufferin St, Ontario, Canada; University of Toronto Institute for Aerospace Studies (UTIAS), Dufferin St, Ontario, Canada; University of Toronto Institute for Aerospace Studies (UTIAS), Dufferin St, Ontario, Canada; Apple Inc.; University of Toronto Institute for Aerospace Studies (UTIAS), Dufferin St, Ontario, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561701/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14927032015786211936&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of Toronto Institute for Aerospace Studies;Apple",
        "aff_unique_dep": "Institute for Aerospace Studies;Apple Inc.",
        "aff_unique_url": "https://utias.utoronto.ca;https://www.apple.com",
        "aff_unique_abbr": "UTIAS;Apple",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Toronto;",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9560860",
        "title": "Self-Supervised Motion Retargeting with Safety Guarantee",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present self-supervised shared latent embedding (S3LE), a data-driven motion retargeting method that enables the generation of natural motions in humanoid robots from motion capture data or RGB videos. While it requires paired data consisting of human poses and their corresponding robot configurations, it significantly alleviates the necessity of time-consuming data-collection via novel paired data generating processes. Our self-supervised learning procedure consists of two steps: automatically generating paired data to bootstrap the motion retargeting, and learning a projection-invariant mapping to handle the different expressivity of humans and humanoid robots. Furthermore, our method guarantees that the generated robot pose is collision-free and satisfies position limits by utilizing nonparametric regression in the shared latent space. We demonstrate that our method can generate expressive robotic motions from both the CMU motion capture database and YouTube videos.",
        "primary_area": "",
        "author": "Sungjoon Choi;Min Jae Song;Hyemin Ahn;Joohyung Kim;Sungjoon Choi;Min Jae Song;Hyemin Ahn;Joohyung Kim",
        "authorids": "/37085405040;/37089002173;/37085492273;/37085576403;/37085405040;/37089002173;/37085492273;/37085576403",
        "aff": "Department of Artificial Intelligence, Korea University, Seoul, Korea; Courant Institute of Mathematical Sciences, New York University, New York, NY, USA; Chair of Human-Centered Assistive Robotics, Technical University of Munich, Munich, Germany; Electrical and Computer Engineering, University of Illinois Urbana-Champaign, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560860/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3250590807909161556&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Korea University;New York University;Technical University of Munich;University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Artificial Intelligence;Courant Institute of Mathematical Sciences;Chair of Human-Centered Assistive Robotics;Electrical and Computer Engineering",
        "aff_unique_url": "https://www.korea.ac.kr;https://www.nyu.edu;https://www.tum.de;https://illinois.edu",
        "aff_unique_abbr": "KU;NYU;TUM;UIUC",
        "aff_campus_unique_index": "0;1;2;3",
        "aff_campus_unique": "Seoul;New York;Munich;Urbana",
        "aff_country_unique_index": "0;1;2;1",
        "aff_country_unique": "South Korea;United States;Germany"
    },
    {
        "id": "9561699",
        "title": "Self-Supervised Person Detection in 2D Range Data using a Calibrated Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning is the essential building block of state-of-the-art person detectors in 2D range data. However, only a few annotated datasets are available for training and testing these deep networks, potentially limiting their performance when deployed in new environments or with different LiDAR models. We propose a method, which uses bounding boxes from an image-based detector (e.g. Faster R-CNN) on a calibrated camera to automatically generate training labels (called pseudo-labels) for 2D LiDAR-based person detectors. Through experiments on the JackRabbot dataset with two detector models, DROW3 and DR-SPAAM, we show that self-supervised detectors, trained or fine-tuned with pseudolabels, outperform detectors trained only on a different dataset. Combined with robust training techniques, the self-supervised detectors reach a performance close to the ones trained using manual annotations of the target dataset. Our method is an effective way to improve person detectors during deployment without any additional labeling effort, and we release our source code to support relevant robotic applications.",
        "primary_area": "",
        "author": "Dan Jia;Mats Steinweg;Alexander Hermans;Bastian Leibe;Dan Jia;Mats Steinweg;Alexander Hermans;Bastian Leibe",
        "authorids": "/37088688308;/37088996148;/37085358298;/37298473000;/37088688308;/37088996148;/37085358298;/37298473000",
        "aff": "Visual Computing Institute, RWTH Aachen University; Visual Computing Institute, RWTH Aachen University; Visual Computing Institute, RWTH Aachen University; Visual Computing Institute, RWTH Aachen University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561699/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12097252075758856314&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "RWTH Aachen University",
        "aff_unique_dep": "Visual Computing Institute",
        "aff_unique_url": "https://www.rwth-aachen.de",
        "aff_unique_abbr": "RWTH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Aachen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561063",
        "title": "Self-supervised Learning of LiDAR Odometry for Robotic Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Reliable robot pose estimation is a key building block of many robot autonomy pipelines, with LiDAR localization being an active research domain. In this work, a versatile self-supervised LiDAR odometry estimation method is presented, in order to enable the efficient utilization of all available LiDAR data while maintaining real-time performance. The proposed approach selectively applies geometric losses during training, being cognizant of the amount of information that can be extracted from scan points. In addition, no labeled or ground-truth data is required, hence making the presented approach suitable for pose estimation in applications where accurate ground-truth is difficult to obtain. Furthermore, the presented network architecture is applicable to a wide range of environments and sensor modalities without requiring any network or loss function adjustments. The proposed approach is thoroughly tested for both indoor and outdoor real-world applications through a variety of experiments using legged, tracked and wheeled robots, demonstrating the suitability of learning-based LiDAR odometry for complex robotic applications.",
        "primary_area": "",
        "author": "Julian Nubert;Shehryar Khattak;Marco Hutter;Julian Nubert;Shehryar Khattak;Marco Hutter",
        "authorids": "/37088229353;/37086181358;/37545251000;/37088229353;/37086181358;/37545251000",
        "aff": "Max Planck ETH Center for Learning Systems, Germany/Switzerland; Robotic Systems Lab, ETH Z\u00fcrich; Robotic Systems Lab, ETH Z\u00fcrich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561063/",
        "gs_citation": 53,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6829009958053453315&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Max Planck ETH Center for Learning Systems;ETH Zurich",
        "aff_unique_dep": "Center for Learning Systems;Robotic Systems Lab",
        "aff_unique_url": ";https://www.ethz.ch",
        "aff_unique_abbr": ";ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1",
        "aff_country_unique": "Unknown;Switzerland"
    },
    {
        "id": "9560831",
        "title": "SelfDeco: Self-Supervised Monocular Depth Completion in Challenging Indoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel algorithm for self-supervised monocular depth completion. Our approach is based on training a neural network that requires only sparse depth measurements and corresponding monocular video sequences without dense depth labels. Our self-supervised algorithm is designed for challenging indoor environments with textureless regions, glossy and transparent surfaces, moving people, longer and diverse depth ranges and scenes captured by complex ego-motions. Our novel architecture leverages both deep stacks of sparse convolution blocks to extract sparse depth features and pixel-adaptive convolutions to fuse image and depth features. We compare with existing approaches in NYUv2, KITTI and NAVERLABS indoor datasets, and observe 5 - 34 % improvements in root- means-square error (RMSE) reduction.",
        "primary_area": "",
        "author": "Jaehoon Choi;Dongki Jung;Yonghan Lee;Deokhwa Kim;Dinesh Manocha;Donghwan Lee;Jaehoon Choi;Dongki Jung;Yonghan Lee;Deokhwa Kim;Dinesh Manocha;Donghwan Lee",
        "authorids": "/37089319189;/37088996964;/37089001508;/37088888616;/37267825600;/37088886388;/37089319189;/37088996964;/37089001508;/37088888616;/37267825600;/37088886388",
        "aff": "University of Maryland; NAVER Labs; NAVER Labs; NAVER Labs; University of Maryland; NAVER Labs",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560831/",
        "gs_citation": 27,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13222034303751406122&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;1;0;1",
        "aff_unique_norm": "University of Maryland;NAVER LABS",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www/umd.edu;https://labs.naver.com",
        "aff_unique_abbr": "UMD;NAVER Labs",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;1;1;0;1",
        "aff_country_unique": "United States;South Korea"
    },
    {
        "id": "9561986",
        "title": "Semantic Feature Mining for 3D Object Classification and Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Deep learning on 3D point clouds has drawn much attention, due to its large variety of applications in intelligent perception for automated and robotic systems. Unlike structured 2D images, it is challenging to extract features and implement convolutional networks over these unordered points. Although a number of previous works achieved high accuracies for point cloud recognition, they tend to process local point information in such a way that semantic information is not fully encoded. In this paper, we propose a deep neural network for 3D point cloud processing that utilizes effective feature aggregation methods emphasizing both generalizability and relevance. In particular, our method uses fixed-radius grouping for pooling layers and spherical kernel convolution for semantics mining. To address the issue of gradient degradation and memory consumption of a deep network, a parallel feature feed-forward mechanism and bottleneck layers are implemented to reduce the number of parameters. Experiments show that our algorithm achieves state-of-the-art results and competitive accuracy in both classification and part segmentation while maintaining an efficient architecture.",
        "primary_area": "",
        "author": "Weihao Lu;Dezong Zhao;Cristiano Premebida;Wen-Hua Chen;Daxin Tian;Weihao Lu;Dezong Zhao;Cristiano Premebida;Wen-Hua Chen;Daxin Tian",
        "authorids": "/37089002096;/37072970900;/37589826700;/37279192700;/37406931400;/37089002096;/37072970900;/37589826700;/37279192700;/37406931400",
        "aff": "School of Engineering, University of Glasgow, Glasgow, UK; School of Engineering, University of Glasgow, Glasgow, UK; Institute of Systems and Robotics, University of Coimbra, Coimbra, Portugal; Department of Aeronautical and Automotive Engineering, Loughborough University, Loughborough, UK; School of Transportation Science and Engineering, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561986/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16468824401954507528&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;3",
        "aff_unique_norm": "University of Glasgow;University of Coimbra;Loughborough University;Beihang University",
        "aff_unique_dep": "School of Engineering;Institute of Systems and Robotics;Department of Aeronautical and Automotive Engineering;School of Transportation Science and Engineering",
        "aff_unique_url": "https://www.gla.ac.uk;https://www.uc.pt;https://www.lboro.ac.uk;http://www.buaa.edu.cn",
        "aff_unique_abbr": "UofG;;Lboro;Beihang",
        "aff_campus_unique_index": "0;0;1;2;3",
        "aff_campus_unique": "Glasgow;Coimbra;Loughborough;Beijing",
        "aff_country_unique_index": "0;0;1;0;2",
        "aff_country_unique": "United Kingdom;Portugal;China"
    },
    {
        "id": "9561812",
        "title": "Semantic Reinforced Attention Learning for Visual Place Recognition",
        "track": "main",
        "status": "Poster",
        "abstract": "Large-scale visual place recognition (VPR) is inherently challenging because not all visual cues in the image are beneficial to the task. In order to highlight the task-relevant visual cues in the feature embedding, the existing attention mechanisms are either based on artificial rules or trained in a thorough data-driven manner. To fill the gap between the two types, we propose a novel Semantic Reinforced Attention Learning Network (SRALNet), in which the inferred attention can benefit from both semantic priors and data-driven fine-tuning. The contribution lies in two-folds. (1) To suppress misleading local features, an interpretable local weighting scheme is proposed based on hierarchical feature distribution. (2) By exploiting the interpretability of the local weighting scheme, a semantic constrained initialization is proposed so that the local attention can be reinforced by semantic priors. Experiments demonstrate that our method outperforms state-of-the-art techniques on city-scale VPR benchmark datasets.",
        "primary_area": "",
        "author": "Guohao Peng;Yufeng Yue;Jun Zhang;Zhenyu Wu;Xiaoyu Tang;Danwei Wang;Guohao Peng;Yufeng Yue;Jun Zhang;Zhenyu Wu;Xiaoyu Tang;Danwei Wang",
        "authorids": "/37087049757;/37086172414;/37086009222;/37088406849;/37088405212;/37279547600;/37087049757;/37086172414;/37086009222;/37088406849;/37088405212;/37279547600",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Automation, Beijing Institute of Technology, Beijing, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561812/",
        "gs_citation": 70,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2749886575865322208&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;0;0;0",
        "aff_unique_norm": "Nanyang Technological University;Beijing Institute of Technology",
        "aff_unique_dep": "School of Electrical and Electronic Engineering;School of Automation",
        "aff_unique_url": "https://www.ntu.edu.sg;http://www.bit.edu.cn",
        "aff_unique_abbr": "NTU;BIT",
        "aff_campus_unique_index": "0;1;0;0;0;0",
        "aff_campus_unique": "Singapore;Beijing",
        "aff_country_unique_index": "0;1;0;0;0;0",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9561532",
        "title": "Semantic SLAM with Autonomous Object-Level Data Association",
        "track": "main",
        "status": "Poster",
        "abstract": "It is often desirable to capture and map semantic information of an environment during simultaneous localization and mapping (SLAM). Such semantic information can enable a robot to better distinguish places with similar low-level geometric and visual features and perform high-level tasks that use semantic information about objects to be manipulated and environments to be navigated. While semantic SLAM has gained increasing attention, there is little research on semantic-level data association based on semantic objects, i.e., object-level data association. In this paper, we propose a novel object-level data association algorithm based on bag of words algorithm [1], formulated as a maximum weighted bipartite matching problem. With object-level data association solved, we develop a quadratic-programming-based semantic object initialization scheme using dual quadric and introduce additional constraints to improve the success rate of object initialization. The integrated semantic-level SLAM system can achieve high-accuracy object-level data association and real-time semantic mapping as demonstrated in the experiments. The online semantic map building and semantic-level localization capabilities facilitate semantic-level mapping and task planning in a priori unknown environment.",
        "primary_area": "",
        "author": "Zhentian Qian;Kartik Patath;Jie Fu;Jing Xiao;Zhentian Qian;Kartik Patath;Jie Fu;Jing Xiao",
        "authorids": "/37088518635;/37086366242;/37085509060;/37278646600;/37088518635;/37086366242;/37085509060;/37278646600",
        "aff": "Department of Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA; Department of Robotics Engineering, Worcester Polytechnic Institute, Worcester, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561532/",
        "gs_citation": 48,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12363583368151255323&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Worcester Polytechnic Institute",
        "aff_unique_dep": "Department of Robotics Engineering",
        "aff_unique_url": "https://www.wpi.edu",
        "aff_unique_abbr": "WPI",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Worcester",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560736",
        "title": "Semantic and Geometric Modeling with Neural Message Passing in 3D Scene Graphs for Hierarchical Mechanical Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Searching for objects in indoor organized environments such as homes or offices is part of our everyday activities. When looking for a desired object, we reason about the rooms and containers the object is likely to be in; the same type of container will have a different probability of containing the target depending on which room it is in. We also combine geometric and semantic information to infer what container is best to search, or what other objects are best to move, if the target object is hidden from view. We use a 3D scene graph representation to capture the hierarchical, semantic, and geometric aspects of this problem. To exploit this representation in a search process, we introduce Hierarchical Mechanical Search (HMS), a method that guides an agent\u2019s actions towards finding a target object specified with a natural language description. HMS is based on a novel neural network architecture that uses neural message passing of vectors with visual, geometric, and linguistic information to allow HMS to process data across layers of the graph while combining semantic and geometric cues. HMS is trained on 1000 3D scene graphs and evaluated on a novel dataset of 500 3D scene graphs with dense placements of semantically related objects in storage locations, and is shown to be significantly better than several baselines at finding objects. It is also close to the oracle policy in terms of the median number of actions required. Additional qualitative results can be found at https://ai.stanford.edu/mech-search/hms",
        "primary_area": "",
        "author": "Andrey Kurenkov;Roberto Mart\u00edn-Mart\u00edn;Jeff Ichnowski;Ken Goldberg;Silvio Savarese;Andrey Kurenkov;Roberto Mart\u00edn-Mart\u00edn;Jeff Ichnowski;Ken Goldberg;Silvio Savarese",
        "authorids": "/37085704818;/37085788640;/38541287200;/37273026700;/37298502600;/37085704818;/37085788640;/38541287200;/37273026700;/37298502600",
        "aff": "Stanford University; Stanford University; University of California, Berkeley; University of California, Berkeley; Stanford University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560736/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15275900370375615782&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;1;0",
        "aff_unique_norm": "Stanford University;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.stanford.edu;https://www.berkeley.edu",
        "aff_unique_abbr": "Stanford;UC Berkeley",
        "aff_campus_unique_index": "0;0;1;1;0",
        "aff_campus_unique": "Stanford;Berkeley",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561077",
        "title": "Semantically Guided Multi-View Stereo for Dense 3D Road Mapping",
        "track": "main",
        "status": "Poster",
        "abstract": "Compared to widely used LiDAR-based mapping in autonomous driving field, image-based mapping method has the advantages of low cost, high resolution, and no need for complex calibration. However, the image-based 3D mapping depends heavily on the texture richness and always leaves holes and outliers in low-textured areas, such as the road surface. To this end, this paper proposed a novel semantically guided Multi-View Stereo method for dense 3D road mapping, which integrates semantic information into PatchMatch-based MVS pipeline and uses image semantic segmentation as soft constraints in neighbor views selection, depth-map initialization, depth propagation, and depth-map completion. Experimental results on public and our own datasets show that, with the help of semantics, the proposed method achieves superior completeness with comparable accuracy for 3D road mapping compared to state-of-the-art MVS methods.",
        "primary_area": "",
        "author": "Mingzhe Lv;Diantao Tu;Xincheng Tang;Yuqian Liu;Shuhan Shen;Mingzhe Lv;Diantao Tu;Xincheng Tang;Yuqian Liu;Shuhan Shen",
        "authorids": "/37088999361;/37089001615;/37088996122;/37089735340;/37397055200;/37088999361;/37089001615;/37088996122;/37089735340;/37397055200",
        "aff": "CASIA-SenseTime Research Group; CASIA-SenseTime Research Group; School of Automation and Electrical Engineering, University of Science and Technology Beijing, Beijing, China; SenseTime Research, Hangzhou, China; CASIA-SenseTime Research Group",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561077/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10275158279750016694&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;0",
        "aff_unique_norm": "Chinese Academy of Sciences;University of Science and Technology Beijing;SenseTime Research",
        "aff_unique_dep": "CASIA-SenseTime Research Group;School of Automation and Electrical Engineering;",
        "aff_unique_url": "http://www.casia.ac.cn;http://www.ustb.edu.cn;https://www.sensetime.com",
        "aff_unique_abbr": "CASIA;USTB;SenseTime",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Beijing;Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561863",
        "title": "Semantically-Aware Strategies for Stereo-Visual Robotic Obstacle Avoidance",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile robots in unstructured, mapless environments must rely on an obstacle avoidance module to navigate safely. The standard avoidance techniques estimate the locations of obstacles with respect to the robot but are unaware of the obstacles\u2019 identities. Consequently, the robot cannot take advantage of semantic information about obstacles when making decisions about how to navigate. We propose an obstacle avoidance module that combines visual instance segmentation with a depth map to classify and localize objects in the scene. The system avoids obstacles differentially, based on the identity of the objects: for example, the system is more cautious in response to unpredictable objects such as humans. The system can also navigate closer to harmless obstacles and ignore obstacles that pose no collision danger, enabling it to navigate more efficiently. We validate our approach in two simulated environments: one terrestrial and one underwater. Results indicate that our approach is feasible and can enable more efficient navigation strategies.",
        "primary_area": "",
        "author": "Jungseok Hong;Karin de Langis;Cole Wyethv;Christopher Walaszek;Junaed Sattar;Jungseok Hong;Karin de Langis;Cole Wyethv;Christopher Walaszek;Junaed Sattar",
        "authorids": "/37088505608;/37088504599;/37088997818;/37089000179;/37546394500;/37088505608;/37088504599;/37088997818;/37089000179;/37546394500",
        "aff": "Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota\u2013Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota\u2013Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota\u2013Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota\u2013Twin Cities, Minneapolis, MN, USA; Department of Computer Science and Engineering, Minnesota Robotics Institute, University of Minnesota\u2013Twin Cities, Minneapolis, MN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561863/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13244704929426660519&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Minnesota\u2013Twin Cities",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.umn.edu",
        "aff_unique_abbr": "UMN",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Minneapolis",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561609",
        "title": "Semi-Infinite Programming with Complementarity Constraints for Pose Optimization with Pervasive Contact",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel computational model to address the problem that contact is an infinite phenomena involving continuous regions of interaction. The problem is cast as a semi-infinite program with complementarity constraints (SIPCC). Rather than pre-discretize contacting surfaces into a finite number of contact points, we use semi-infinite programming (SIP) techniques that operate on the underlying continuous geometry, but dynamically determine a finite number of constraints that are most relevant to solving the problem. Then we solve the series of problems whose solutions converge toward one that contains a true optimum of the original SIPCC. We apply the model to a grasping pose optimization problem for a gripper and a humanoid robot, and our model enables the robots to find a feasible pose to hold (non-)convex objects while ensuring force and torque balance.",
        "primary_area": "",
        "author": "Mengchao Zhang;Kris Hauser;Mengchao Zhang;Kris Hauser",
        "authorids": "/37089001334;/37543748800;/37089001334;/37543748800",
        "aff": "Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign; Department of Computer Science, University of Illinois at Urbana-Champaign",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561609/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1376456516169847527&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Mechanical Science and Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana-Champaign",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561896",
        "title": "Sensing via Collisions: a Smart Cage for Quadrotors with Applications to Self-Localization",
        "track": "main",
        "status": "Poster",
        "abstract": "Applications of micro unmanned aerial vehicles (UAVs) are gradually expanding into complex urban and natural environments. Despite noticeable progress, flying robots in obstacle-rich environments is still challenging. On-board processing for detecting and avoiding obstacles is possible, but at a significant computational expense, and with significant limitations (e.g., for obstacles with small cross sections, such as wires). A low-cost alternative is to mitigate physical contacts through a cage or other similar protective devices. In this paper, we propose to transform these passive protective devices into functional sensors: we introduce a suspended rim combined with a central base measuring the relative displacement of the rim; we provide a full mechanical design, and derive solutions to the inverse kinematics for recovering the collision direction in real time. As a proof of concept, we show the benefits of this novel form of sensing by embedding it in a traditional particle filter for self-localization in a known environment; our experiments show that localization is possible with a minimal sacrifice in payload capacity.",
        "primary_area": "",
        "author": "Cheng Liu;Roberto Tron;Cheng Liu;Roberto Tron",
        "authorids": "/37088998472;/37398528900;/37088998472;/37398528900",
        "aff": "Department of Mechanical Engineering, Boston University, Mall, MA, United States; Department of Mechanical Engineering, Boston University, Mall, MA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561896/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17871865798596824825&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Boston University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.bu.edu",
        "aff_unique_abbr": "BU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Mall",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561442",
        "title": "Sensor Placement for Globally Optimal Coverage of 3D-Embedded Surfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "We carry out a structural and algorithmic study of a mobile sensor coverage optimization problem targeting 2D surfaces embedded in a 3D workspace. The investigated settings model multiple important applications including camera net- work deployment for surveillance, geological monitoring/survey of 3D terrains, and UVC-based surface disinfection for the prevention of the spread of disease agents (e.g., SARS-CoV-2). Under a unified general \"sensor coverage\" problem, three concrete formulations are examined, focusing on optimizing visibility, single-best coverage quality, and cumulative quality, respectively. After demonstrating the computational intractability of all these formulations, we describe approximation schemes and mathematical programming models for near-optimally solving them. The effectiveness of our methods is thoroughly evaluated under realistic and practical scenarios.",
        "primary_area": "",
        "author": "Si Wei Feng;Kai Gao;Jie Gong;Jingjin Yu;Si Wei Feng;Kai Gao;Jie Gong;Jingjin Yu",
        "authorids": "/37087233222;/37088997464;/37089099385;/37536570700;/37087233222;/37088997464;/37089099385;/37536570700",
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Civil and Environmental Engineering, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561442/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9444197954313777729&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561824",
        "title": "Serverless Architecture for Service Robot Management System",
        "track": "main",
        "status": "Poster",
        "abstract": "We have developed service robot management system to facilitate effective collaboration between multiple units and types of robots in operation. This system is implemented by serverless architecture on cloud and using cellular based IoT communication. So it has not only usual cloud system advantage that it is not necessary to prepare dedicated server and network equipment, but it reduces management efforts of servers. We have tested the system with robots in a public facility, and successfully confirmed its performance and functionality.",
        "primary_area": "",
        "author": "Kenji Nishimiya;Yuta Imai;Kenji Nishimiya;Yuta Imai",
        "authorids": "/37087762521;/37089001424;/37087762521;/37089001424",
        "aff": "Honda R&D Co., Ltd, Saitama, Japan; Soracom Inc, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561824/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15604298350691763073&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Honda R&D Co., Ltd;Soracom Inc",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.honda.com;https://soracom.io",
        "aff_unique_abbr": "Honda R&D;",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Tokyo",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561571",
        "title": "Serverless Multi-Query Motion Planning for Fog Robotics",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots in semi-structured environments such as homes and warehouses sporadically require computation of high-dimensional motion plans. Cloud and fog-based parallelization of motion planning can speed up planning. This can be further made efficient by the use of \"serverless\" on-demand computing as opposed to always-on high end computers. This paper explores parallelizing the computation of a sampling-based multi-query motion planner based on asymptotically-optimal Probabilistic Road Maps (PRM*) using the simultaneous execution of 100s of cloud-based serverless functions. We propose an algorithm to overcome the communication and bandwidth limitations of serverless computing and use different work-sharing techniques to further optimize the cost and run time. Additionally, we provide proofs of probabilistic completeness and asymptotic optimality. In experiments on synthetic benchmarks and on a physical Fetch robot performing a sequence of decluttering motions, we observe up to a 50x speedup relative to a 4 core edge computer with only a marginally higher cost.",
        "primary_area": "",
        "author": "Raghav Anand;Jeffrey Ichnowski;Chenggang Wu;Joseph M. Hellerstein;Joseph E. Gonzalez;Ken Goldberg;Raghav Anand;Jeffrey Ichnowski;Chenggang Wu;Joseph M. Hellerstein;Joseph E. Gonzalez;Ken Goldberg",
        "authorids": "/37088419786;/38541287200;/37086504487;/38183421000;/37086566024;/37273026700;/37088419786;/38541287200;/37086504487;/38183421000;/37086566024;/37273026700",
        "aff": "University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561571/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2826285290699066648&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561072",
        "title": "Shape Sensor Using Magnetic Induction with Frequency Sweeping for Medical Catheters",
        "track": "main",
        "status": "Poster",
        "abstract": "Shape sensors are important for safer and more dexterous manipulation of the medical catheters. Among the electromagnetic based shape sensors, a voice coil shape sensor measures the variation of a mutual inductance between the coils placed along the tube due to the bending of the tube. Owing to the design flexibility of a voice coil, it offers the small size without the external magnetic field generator outside patient body. This paper presents an improved voice coil shape sensor in terms of modeling and measurement. Analytic model that incorporates the bending of an exciter coils is used to improve the accuracy of the sensor and band-pass filter is applied to simplify the measurements. Bending angle from sensors placed in multiple locations can be measured through a single channel from frequency sweep input. The simulation and experimental results verify the improvement and demonstrate that the sensor system can reconstruct a shape of a catheter placed through larynx.",
        "primary_area": "",
        "author": "Jiyun Jeon;Chunwoo Kim;Jiyun Jeon;Chunwoo Kim",
        "authorids": "/37085621009;/37086175980;/37085621009;/37086175980",
        "aff": "Center for Healthcare Robotics, Korea Institute Science and Technology (KIST), Seoul, Korea; Center for Healthcare Robotics, Korea Institute Science and Technology (KIST), Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561072/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11242236573288672889&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Korea Institute Science and Technology",
        "aff_unique_dep": "Center for Healthcare Robotics",
        "aff_unique_url": "https://www.kist.re.kr",
        "aff_unique_abbr": "KIST",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Seoul",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9560894",
        "title": "Shape-Based Transfer of Generic Skills",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a new, data-efficient approach for skill transfer to novel objects, accounting for known categorical shape variation. A low-dimensional shape representation embedding is learned from a set of deformations, sampled between known objects within a category. This latent representation is mapped to a set of control parameters that result in successful execution of a category-level skill on that object. This method generalizes a learned manipulation policy to unseen objects with few training examples. We demonstrate this approach on pouring from cups and scooping with spatulas, where there is complex, nonlinear variation of successful control parameters across objects.",
        "primary_area": "",
        "author": "Skye Thompson;Leslie Pack Kaelbling;Tomas Lozano-Perez;Skye Thompson;Leslie Pack Kaelbling;Tomas Lozano-Perez",
        "authorids": "/37088997113;/37269373600;/38273814000;/37088997113;/37269373600;/38273814000",
        "aff": "MIT CSAIL; MIT CSAIL; MIT CSAIL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560894/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10093017987371040726&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT CSAIL",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561607",
        "title": "Shaped Policy Search for Evolutionary Strategies using Waypoints",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we try to improve exploration in Blackbox methods, particularly Evolution strategies (ES), when applied to Reinforcement Learning (RL) problems where intermediate waypoints/subgoals are available. Since Evolutionary strategies are highly parallelizable, instead of extracting just a scalar cumulative reward, we use the state-action pairs from the trajectories obtained during rollouts/evaluations, to learn the dynamics of the agent. The learnt dynamics are then used in the optimization procedure to speed-up training. Lastly, we show how our proposed approach is universally applicable by presenting results from experiments conducted on Carla driving and UR5 robotic arm simulators.",
        "primary_area": "",
        "author": "Kiran Lekkala;Laurent Itti;Kiran Lekkala;Laurent Itti",
        "authorids": "/37089000113;/37282718300;/37089000113;/37282718300",
        "aff": "Department of Computer Science, ILab, University of Southern California, USA; Department of Computer Science, Psychology and NGP, ILab, University of Southern California",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561607/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=803194520289642710&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561333",
        "title": "Shaping Rewards for Reinforcement Learning with Imperfect Demonstrations using Generative Models",
        "track": "main",
        "status": "Poster",
        "abstract": "The potential benefits of model-free reinforcement learning to real robotics systems are limited by its uninformed exploration that leads to slow convergence, lack of data-efficiency, and unnecessary interactions with the environment. To address these drawbacks we propose a method that combines reinforcement and imitation learning by shaping the reward function with a state-and-action-dependent potential that is trained from demonstration data, using a generative model. We show that this accelerates policy learning by specifying high-value areas of the state and action space that are worth exploring first. Unlike the majority of existing methods that assume optimal demonstrations and incorporate the demonstration data as hard constraints on policy optimization, we instead incorporate demonstration data as advice in the form of a reward shaping potential trained as a generative model of states and actions. In particular, we examine both normalizing flows and Generative Adversarial Networks to represent these potentials. We show that, unlike many existing approaches that incorporate demonstrations as hard constraints, our approach is unbiased even in the case of suboptimal and noisy demonstrations. We present an extensive range of simulations, as well as experiments on the Franka Emika 7DOF arm, to demonstrate the practicality of our method.",
        "primary_area": "",
        "author": "Yuchen Wu;Melissa Mozifian;Florian Shkurti;Yuchen Wu;Melissa Mozifian;Florian Shkurti",
        "authorids": "/37089001629;/37086453258;/37706697200;/37089001629;/37086453258;/37706697200",
        "aff": "Department of Computer Science, University of Toronto Robotics Institute, and Vector Institute; Mobile Robotics Lab (MRL) at the School of Computer Science, McGill University, Montr\u00e9al, Canada; Department of Computer Science, University of Toronto Robotics Institute, and Vector Institute",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561333/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1112592020146398616&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Toronto;McGill University",
        "aff_unique_dep": "Department of Computer Science;School of Computer Science",
        "aff_unique_url": "https://www.utoronto.ca;https://www.mcgill.ca",
        "aff_unique_abbr": "U of T;McGill",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Toronto;Montr\u00e9al",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561918",
        "title": "Shared Autonomy for Teleoperated Driving: A Real-Time Interactive Path Planning Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Teleoperation deals with extraordinary situations where an external operator takes over the control of an autonomous vehicle. Especially in complex urban scenarios, this may cause a too high workload for the human operator, resulting in suboptimal solutions. This contribution presents a teleoperation paradigm to raise the autonomy level of teleoperated driving, while the operator still remains the main decision-maker in all driving tasks. The introduced approach generates collision-free paths using LiDAR sensor information and suggests them to the operator. Therefore, a new hybrid path planning method has been developed, which searches and clusters in the first phase all feasible paths in the environment using a modified Rapidly-Exploring-Random Tree (RRT). In the second phase, the path selected by the operator is optimized online by a modified CHOMP algorithm. Real driving experiments confirm the effectiveness of the approach and highlight both the achieved driving safety and real time capability.",
        "primary_area": "",
        "author": "Dmitrij Schitz;Shuai Bao;Dominik Rieth;Harald Aschemann;Dmitrij Schitz;Shuai Bao;Dominik Rieth;Harald Aschemann",
        "authorids": "/37087042887;/37088996013;/37085386300;/37293829400;/37087042887;/37088996013;/37085386300;/37293829400",
        "aff": "Chair of Mechatronics, University of Rostock, Rostock, Germany; Department of Mechanical Engineering, Technical University Munich, Garching, Germany; BMW Group, Munich, Germany; Chair of Mechatronics, University of Rostock, Rostock, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561918/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8068723021759824744&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Rostock;Technical University Munich;BMW Group",
        "aff_unique_dep": "Chair of Mechatronics;Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.uni-rostock.de;https://www.tum.de;https://www.bmwgroup.com",
        "aff_unique_abbr": ";TUM;BMW",
        "aff_campus_unique_index": "0;1;2;0",
        "aff_campus_unique": "Rostock;Garching;Munich",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561623",
        "title": "Shared Control of Robot-Robot Collaborative Lifting with Agent Postural and Force Ergonomic Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans show specialized strategies for efficient collaboration. Transferring similar strategies to humanoid robots can improve their capability to interact with other agents, leading the way to complex collaborative scenarios with multiple agents acting on a shared environment. In this paper we present a control framework for robot-robot collaborative lifting. The proposed shared controller takes into account the joint action of both the robots thanks to a centralized controller that communicates with them, and solves the whole-system optimization. Efficient collaboration is ensured by taking into account the ergonomic requirements of the robots through the optimization of posture and contact forces. The framework is validated in an experimental scenario with two iCub humanoid robots performing different payload lifting sequences.",
        "primary_area": "",
        "author": "Lorenzo Rapetti;Yeshasvi Tirupachuri;Alberto Ranavolo;Tomohiro Kawakami;Takahide Yoshiike;Daniele Pucci;Lorenzo Rapetti;Yeshasvi Tirupachuri;Alberto Ranavolo;Tomohiro Kawakami;Takahide Yoshiike;Daniele Pucci",
        "authorids": "/37087238330;/37086076224;/37088418590;/37088504439;/37682554700;/37706167200;/37087238330;/37086076224;/37088418590;/37088504439;/37682554700;/37706167200",
        "aff": "Machine Learning and Optimisation, The University of Manchester, Manchester, United Kingdom; Dynamic Interaction Control at Istituto Italiano di Tecnologia, Center for Robotics Technologies, Genova, Italy; Department of Occupational and Environmental Medicine, Epidemiology and Hygiene, INAIL, Roma, Italy; Honda R&D Co., Ltd., Saitama, Japan; Honda R&D Co., Ltd., Saitama, Japan; Dynamic Interaction Control at Istituto Italiano di Tecnologia, Center for Robotics Technologies, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561623/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5449237600172873104&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;3;1",
        "aff_unique_norm": "University of Manchester;Istituto Italiano di Tecnologia;INAIL;Honda R&D Co., Ltd.",
        "aff_unique_dep": "Machine Learning and Optimisation;Center for Robotics Technologies;Department of Occupational and Environmental Medicine, Epidemiology and Hygiene;",
        "aff_unique_url": "https://www.manchester.ac.uk;https://www.iit.it;https://www.inail.it;https://www.honda.com",
        "aff_unique_abbr": "UoM;IIT;;Honda R&D",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Manchester;Genova;",
        "aff_country_unique_index": "0;1;1;2;2;1",
        "aff_country_unique": "United Kingdom;Italy;Japan"
    },
    {
        "id": "9561013",
        "title": "Shared control strategy for needle insertion into deformable tissue using inverse Finite Element simulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper deals with the problem of needle steering in deformable tissues subject to physiological motions. A novel shared control method is proposed, which combines an automatic needle steering algorithm with the motions applied by the radiologist, in order to place the needle tip at the desired location. The core motivation is to leave potentially dangerous decisions and actions to the practitioner, whereas complex non-intuitive manipulations of the needle are performed automatically, in particular to compensate for breathing motions. The most original part of the present work lies in the method used to combine user inputs with a closed-loop automatic needle steering control method based on inverse Finite Element simulations. The method is evaluated with a realistic virtual environment using 2D X-ray projection images. The results are compared with those obtained with a fully teleoperated system, on the one hand, and with a fully automatic solution, on the other hand. These experiments show that the shared control solution allows for a better needle tip placement when only projection imaging is available.",
        "primary_area": "",
        "author": "Paul Baksic;Hadrien Courtecuisse;Bernard Bayle;Paul Baksic;Hadrien Courtecuisse;Bernard Bayle",
        "authorids": "/37088506213;/37569822600;/37588627100;/37088506213;/37569822600;/37588627100",
        "aff": "ICube Laboratory, UMR 7357, CNRS, University of Strasbourg, Strasbourg, France; ICube Laboratory, UMR 7357, CNRS, University of Strasbourg, Strasbourg, France; ICube Laboratory, UMR 7357, CNRS, University of Strasbourg, Strasbourg, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561013/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16734978437424407487&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Strasbourg",
        "aff_unique_dep": "ICube Laboratory",
        "aff_unique_url": "https://www.unistra.fr",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Strasbourg",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561488",
        "title": "Siame-se(3): regression in se(3) for end-to-end visual servoing",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we propose a deep architecture and the associated learning strategy for end-to-end direct visual servoing. The considered approach allows to sequentially predict, in se(3), the velocity of a camera mounted on the robot\u2019s end-effector for positioning tasks. Positioning is achieved with high precision despite large initial errors in both cartesian and image spaces. Training is fully done in simulation, alleviating the burden of data collection. We demonstrate the efficiency of our method in experiments in both simulated and real-world environments. We also show that the proposed approach is able to handle multiple scenes.",
        "primary_area": "",
        "author": "Samuel Felton;\u00c9lisa Fromont;Eric Marchand;Samuel Felton;\u00c9lisa Fromont;Eric Marchand",
        "authorids": "/37089308455;/38234506600;/37269970500;/37089308455;/38234506600;/37269970500",
        "aff": "Inria, CNRS IRISA, Univ Rennes, Rennes, France; Inria, CNRS IRISA, Univ Rennes, Rennes, France; Inria, CNRS IRISA, Univ Rennes, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561488/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9509026249629122786&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "INRIA",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9560756",
        "title": "Siamese Anchor Proposal Network for High-Speed Aerial Tracking",
        "track": "main",
        "status": "Poster",
        "abstract": "In the domain of visual tracking, most deep learning-based trackers highlight the accuracy but casting aside efficiency. Therefore, their real-world deployment on mobile platforms like the unmanned aerial vehicle (UAV) is impeded. In this work, a novel two-stage Siamese network-based method is proposed for aerial tracking, i.e., stage-1 for high-quality anchor proposal generation, stage-2 for refining the anchor proposal. Different from anchor-based methods with numerous pre-defined fixed-sized anchors, our no-prior method can 1) increase the robustness and generalization to different objects with various sizes, especially to small, occluded, and fast-moving objects, under complex scenarios in light of the adaptive anchor generation, 2) make calculation feasible due to the substantial decrease of anchor numbers. In addition, compared to anchor-free methods, our framework has better performance owing to refinement at stage-2. Comprehensive experiments on three benchmarks have proven the superior performance of our approach, with a speed of \u223c200 frames/s.",
        "primary_area": "",
        "author": "Changhong Fu;Ziang Cao;Yiming Li;Junjie Ye;Chen Feng;Changhong Fu;Ziang Cao;Yiming Li;Junjie Ye;Chen Feng",
        "authorids": "/37086797986;/37088997696;/37087323806;/37088917418;/37086391326;/37086797986;/37088997696;/37087323806;/37088917418;/37086391326",
        "aff": "School of Mechanical Engineering, Tongji University, Shanghai, China; School of Automotive Studies, Tongji University, Shanghai, China; Tandon School of Engineering, New York University, New York, NY, United States; School of Mechanical Engineering, Tongji University, Shanghai, China; Tandon School of Engineering, New York University, New York, NY, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560756/",
        "gs_citation": 94,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15421552007013352589&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;1",
        "aff_unique_norm": "Tongji University;New York University",
        "aff_unique_dep": "School of Mechanical Engineering;Tandon School of Engineering",
        "aff_unique_url": "https://www.tongji.edu.cn;https://www.nyu.edu",
        "aff_unique_abbr": "Tongji;NYU",
        "aff_campus_unique_index": "0;0;1;0;1",
        "aff_campus_unique": "Shanghai;New York",
        "aff_country_unique_index": "0;0;1;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9560929",
        "title": "Signal Temporal Logic Synthesis as Probabilistic Inference",
        "track": "main",
        "status": "Poster",
        "abstract": "We reformulate the signal temporal logic (STL) synthesis problem as a maximum a-posteriori (MAP) inference problem. To this end, we introduce the notion of random STL (RSTL), which extends deterministic STL with random predicates. This new probabilistic extension naturally leads to a synthesis-as-inference approach. The proposed method allows for differentiable, gradient-based synthesis while extending the class of possible uncertain semantics. We demonstrate that the proposed framework scales well with GPU-acceleration, and present realistic applications of uncertain semantics in robotics that involve target tracking and the use of occupancy grids.",
        "primary_area": "",
        "author": "Ki Myung Brian Lee;Chanyeol Yoo;Robert Fitch;Ki Myung Brian Lee;Chanyeol Yoo;Robert Fitch",
        "authorids": "/37086938150;/37086933786;/38466367800;/37086938150;/37086933786;/38466367800",
        "aff": "University of Technology Sydney, Ultimo, NSW, Australia; University of Technology Sydney, Ultimo, NSW, Australia; University of Technology Sydney, Ultimo, NSW, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560929/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15269982469447354311&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ultimo",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9561814",
        "title": "Sim-to-Real Learning of All Common Bipedal Gaits via Periodic Reward Composition",
        "track": "main",
        "status": "Poster",
        "abstract": "We study the problem of realizing the full spectrum of bipedal locomotion on a real robot with sim-to-real reinforcement learning (RL). A key challenge of learning legged locomotion is describing different gaits, via reward functions, in a way that is intuitive for the designer and specific enough to reliably learn the gait across different initial random seeds or hyperparameters. A common approach is to use reference motions (e.g. trajectories of joint positions) to guide learning. However, finding high-quality reference motions can be difficult and the trajectories themselves narrowly constrain the space of learned motion. At the other extreme, reference-free reward functions are often underspecified (e.g. move forward) leading to massive variance in policy behavior, or are the product of significant reward-shaping via trial-and-error, making them exclusive to specific gaits. In this work, we propose a reward-specification framework based on composing simple probabilistic periodic costs on basic forces and velocities. We instantiate this framework to define a parametric reward function with intuitive settings for all common bipedal gaits - standing, walking, hopping, running, and skipping. Using this function we demonstrate successful sim-to-real transfer of the learned gaits to the bipedal robot Cassie, as well as a generic policy that can transition between all of the two-beat gaits.",
        "primary_area": "",
        "author": "Jonah Siekmann;Yesh Godse;Alan Fern;Jonathan Hurst;Jonah Siekmann;Yesh Godse;Alan Fern;Jonathan Hurst",
        "authorids": "/37088997435;/37088833560;/37353413400;/37267365600;/37088997435;/37088833560;/37353413400;/37267365600",
        "aff": "Collaborative Robotics and Intelligent Systems, Institute Oregon State University; Collaborative Robotics and Intelligent Systems, Institute Oregon State University; Collaborative Robotics and Intelligent Systems, Institute Oregon State University; Collaborative Robotics and Intelligent Systems, Institute Oregon State University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561814/",
        "gs_citation": 200,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3103524721796281464&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Oregon State University",
        "aff_unique_dep": "Collaborative Robotics and Intelligent Systems",
        "aff_unique_url": "https://oregonstate.edu",
        "aff_unique_abbr": "OSU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561302",
        "title": "Sim-to-Real Visual Grasping via State Representation Learning Based on Combining Pixel-Level and Feature-Level Domain Adaptation",
        "track": "main",
        "status": "Poster",
        "abstract": "In this study, we present a method to grasp diverse unseen real-world objects using an off-policy actor-critic deep reinforcement learning (RL) with the help of a simulation and the use of as little real-world data as possible. Actor-critic deep RL is unstable and difficult to tune when a raw image is given as an input. Therefore, we use state representation learning (SRL) to make actor-critic RL feasible for visual grasping tasks. Meanwhile, to reduce visual reality gap between simulation and reality, we also employ a typical pixel-level domain adaptation that can map simulated images to realistic ones. In our method, as the SRL model is a common preprocessing module for simulated and real-world data, we perform SRL using real and adapted images. This pixel-level domain adaptation enables the robot to learn grasping skills in a real environment using small amounts of real-world data. However, the controller trained in the simulation should adapt to the real world efficiently. Hence, we propose a method combining a typical pixel-level domain adaptation and the proposed SRL model, where we perform SRL based on a feature-level domain adaptation. In evaluations of vision-based robotics grasping tasks, we show that the proposed method achieves a substantial improvement over a method that only employs a pixel-level or domain adaptation.",
        "primary_area": "",
        "author": "Youngbin Park;Sang Hyoung Lee;Il Hong Suh;Youngbin Park;Sang Hyoung Lee;Il Hong Suh",
        "authorids": "/37600943000;/38241379300;/37385851500;/37600943000;/38241379300;/37385851500",
        "aff": "Department of Electronics and Computer Engineering, Hanyang University, Korea; Innovative Smart Manufacturing R&D Department, Korea Institute of Industrial Technology; CogAplex Co., Ltd",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561302/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8562615543215095641&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Hanyang University;Korea Institute of Industrial Technology;CogAplex Co., Ltd",
        "aff_unique_dep": "Department of Electronics and Computer Engineering;Innovative Smart Manufacturing R&D Department;",
        "aff_unique_url": "http://www.hanyang.ac.kr;http://www.kiot.or.kr;",
        "aff_unique_abbr": "HYU;KIOT;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "South Korea;"
    },
    {
        "id": "9561969",
        "title": "Sim-to-Real for Robotic Tactile Sensing via Physics-Based Simulation and Learned Latent Projections",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile sensing is critical for robotic grasping and manipulation of objects under visual occlusion. However, in contrast to simulations of robot arms and cameras, current simulations of tactile sensors have limited accuracy, speed, and utility. In this work, we develop an efficient 3D finite element method (FEM) model of the SynTouch BioTac sensor using an open-access, GPU-based robotics simulator. Our simulations closely reproduce results from an experimentally-validated model in an industry-standard, CPU-based simulator, but at 75x the speed. We then learn latent representations for simulated BioTac deformations and real-world electrical output through self-supervision, as well as projections between the latent spaces using a small supervised dataset. Using these learned latent projections, we accurately synthesize real-world BioTac electrical output and estimate contact patches, both for unseen contact interactions. This work contributes an efficient, freely-accessible FEM model of the BioTac and comprises one of the first efforts to combine self-supervision, cross-modal transfer, and sim-to-real transfer for tactile sensors.",
        "primary_area": "",
        "author": "Yashraj Narang;Balakumar Sundaralingam;Miles Macklin;Arsalan Mousavian;Dieter Fox;Yashraj Narang;Balakumar Sundaralingam;Miles Macklin;Arsalan Mousavian;Dieter Fox",
        "authorids": "/37085801324;/37086455625;/37086938482;/37085404794;/37284329000;/37085801324;/37086455625;/37086938482;/37085404794;/37284329000",
        "aff": "NVIDIA Corporation, Seattle, USA; NVIDIA Corporation, Seattle, USA; NVIDIA Corporation, Seattle, USA; NVIDIA Corporation, Seattle, USA; Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561969/",
        "gs_citation": 69,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1277590635649399643&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;1",
        "aff_unique_norm": "NVIDIA;University of Washington",
        "aff_unique_dep": "NVIDIA Corporation;Paul G. Allen School of Computer Science & Engineering",
        "aff_unique_url": "https://www.nvidia.com;https://www.washington.edu",
        "aff_unique_abbr": "NVIDIA;UW",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Seattle",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561731",
        "title": "SimGAN: Hybrid Simulator Identification for Domain Adaptation via Adversarial Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "As learning-based approaches progress towards automating robot controllers design, transferring learned policies to new domains with different dynamics (e.g. sim-to-real transfer) still demands manual effort. This paper introduces SimGAN, a framework to tackle domain adaptation by identifying a hybrid physics simulator to match the simulated trajectories to the ones from the target domain, using a learned discriminative loss to address the limitations associated with manual loss design. Our hybrid simulator combines neural networks and traditional physics simulation to balance expressiveness and generalizability, and alleviates the need for a carefully selected parameter set in System ID. Once the hybrid simulator is identified via adversarial reinforcement learning, it can be used to refine policies for the target domain, without the need to interleave data collection and policy refinement. We show that our approach outperforms multiple strong baselines on six robotic locomotion tasks for domain adaptation.",
        "primary_area": "",
        "author": "Yifeng Jiang;Tingnan Zhang;Daniel Ho;Yunfei Bai;C. Karen Liu;Sergey Levine;Jie Tan;Yifeng Jiang;Tingnan Zhang;Daniel Ho;Yunfei Bai;C. Karen Liu;Sergey Levine;Jie Tan",
        "authorids": "/37089000434;/37088504200;/37267934200;/37086454356;/38240584300;/37085481973;/37086455820;/37089000434;/37088504200;/37267934200;/37086454356;/38240584300;/37085481973;/37086455820",
        "aff": "Computer Science Department, Stanford University, Stanford, CA, USA; Robotics at Google, Mountain View, CA, USA; Everyday Robots, X The Moonshot Factory, Mountain View, CA, USA; Everyday Robots, X The Moonshot Factory, Mountain View, CA, USA; Computer Science Department, Stanford University, Stanford, CA, USA; EECS, University of California, Berkeley, Berkeley, CA, USA; Robotics at Google, Mountain View, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561731/",
        "gs_citation": 78,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=986362846409493209&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;1;1;1;0;2;1",
        "aff_unique_norm": "Stanford University;Google;University of California, Berkeley",
        "aff_unique_dep": "Computer Science Department;Robotics;EECS",
        "aff_unique_url": "https://www.stanford.edu;https://www.google.com;https://www.berkeley.edu",
        "aff_unique_abbr": "Stanford;Google;UC Berkeley",
        "aff_campus_unique_index": "0;1;1;1;0;2;1",
        "aff_campus_unique": "Stanford;Mountain View;Berkeley",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561666",
        "title": "SimNet: Learning Reactive Self-driving Simulations from Real-world Observations",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work we present a simple end-to-end trainable machine learning system capable of realistically simulating driving experiences. This can be used for verification of self-driving system performance without relying on expensive and time-consuming road testing. In particular, we frame the simulation problem as a Markov Process, leveraging deep neural networks to model both state distribution and transition function. These are trainable directly from the existing raw observations without the need of any handcrafting in the form of plant or kinematic models. All that is needed is a dataset of historical traffic episodes. Our formulation allows the system to construct never seen scenes that unfold realistically reacting to the self-driving car\u2019s behaviour. We train our system directly from 1,000 hours of driving logs and measure both realism, reactivity of the simulation as the two key properties of the simulation. At the same time we apply the method to evaluate performance of a recently proposed state-of-the-art ML planning system [1] trained from human driving logs. We discover this planning system is prone to previously unreported causal confusion issues that are difficult to test by non-reactive simulation. To the best of our knowledge, this is the first work that directly merges highly realistic data-driven simulations with a closed loop evaluation for self-driving vehicles. We make the data, code, and pre-trained models publicly available to further stimulate simulation development.",
        "primary_area": "",
        "author": "Luca Bergamini;Yawei Ye;Oliver Scheel;Long Chen;Chih Hu;Luca Del Pero;B\u0142a\u017cej Osi\u0144ski;Hugo Grimmett;Peter Ondruska;Luca Bergamini;Yawei Ye;Oliver Scheel;Long Chen;Chih Hu;Luca Del Pero;B\u0142a\u017cej Osi\u0144ski;Hugo Grimmett;Peter Ondruska",
        "authorids": "/37086039957;/37088998185;/37086455649;/37089059167;/37088997499;/37075867600;/37088504220;/37076422900;/37085460486;/37086039957;/37088998185;/37086455649;/37089059167;/37088997499;/37075867600;/37088504220;/37076422900;/37085460486",
        "aff": "Luca Bergamini; Yawei Ye; Oliver Scheel; Long Chen; Chih Hu; Luca Del Pero; B\u0142a\u017cej Osi\u0144ski; Hugo Grimmett; Peter Ondruska",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561666/",
        "gs_citation": 115,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6152100131912819819&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Luca Bergamini;Yawei Ye;",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";;",
        "aff_unique_abbr": ";;",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9562023",
        "title": "Simple But Effective Redundant Odometry for Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust and reliable ego-motion is a key component of most autonomous mobile systems. Many odometry estimation methods have been developed using different sensors such as cameras or LiDARs. In this work, we present a resilient approach that exploits the redundancy of multiple odometry algorithms using a 3D LiDAR scanner and a monocular camera to provide reliable state estimation for autonomous vehicles. Our system utilizes a stack of odometry algorithms that run in parallel. It chooses from them the most promising pose estimation considering sanity checks using dynamic and kinematic constraints of the vehicle as well as a score computed between the current LiDAR scan and a locally built point cloud map. In this way, our method can exploit the advantages of different existing ego-motion estimating approaches. We evaluate our method on the KITTI Odometry dataset. The experimental results suggest that our approach is resilient to failure cases and achieves an overall better performance than individual odometry methods employed by our system.",
        "primary_area": "",
        "author": "Andrzej Reinke;Xieyuanli Chen;Cyrill Stachniss;Andrzej Reinke;Xieyuanli Chen;Cyrill Stachniss",
        "authorids": "/37085853228;/37086247697;/37329668600;/37085853228;/37086247697;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562023/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14926500807699909379&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561122",
        "title": "Simulation of Vision-based Tactile Sensors using Physics based Rendering",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile sensing has seen a rapid adoption with the advent of vision-based tactile sensors. Vision-based tactile sensors provide high resolution, compact and inexpensive data to perform precise in-hand manipulation and human-robot interaction. However, the simulation of tactile sensors is still a challenge. In this paper, we built the first fully general optical tactile simulation system for a GelSight sensor using physics based rendering techniques. We propose physically accurate light models and show in-depth analysis of individual components of our simulation pipeline. Our system outperforms previous simulation techniques qualitatively and quantitative on image similarity metrics. Our code and experimental data is open-sourced at \\color{Fuchsia} {\\text{project page}}\\color{Fuchsia} {\\text{project page}} project page.",
        "primary_area": "",
        "author": "Arpit Agarwal;Timothy Man;Wenzhen Yuan;Arpit Agarwal;Timothy Man;Wenzhen Yuan",
        "authorids": "/37089000833;/37088996754;/37085486405;/37089000833;/37088996754;/37085486405",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Mechanical Engineering, Carnegie Mellon University, Pittsburgh, PA, USA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561122/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2416382537108075990&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561422",
        "title": "Simultaneous Estimation and Modeling of Robotic Systems with Non-Gaussian State Belief",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper develops a probabilistic simultaneous estimation and modeling (SEAM) framework for estimating a robot\u2019s state and correcting its motion model parameters. This is done by incorporating model uncertainty in state prediction and correcting parameters via optimization. In the proposed technique, belief about a state being estimated is represented by arbitrary multi-dimensional non-Gaussian probability distribution functions. The approach is validated in proof-of-concept for second-order simulated systems whose models are poorly estimated. Given sufficient state observations, the proposed framework reliably reduces and usually converges model parameter error. In comparison with existing advanced estimators, robotic state estimation is enhanced under this framework when model uncertainty is high and state belief is highly unstructured and non-Gaussian. This work holds promise for challenging robotic localization, estimation, and prediction problems across many complex domains.",
        "primary_area": "",
        "author": "J. Josiah Steckenrider;J. Josiah Steckenrider",
        "authorids": "/37086319773;/37086319773",
        "aff": "Department of Civil and Mechanical Engineering, United States Military Academy, West Point, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561422/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=961294932946438976&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "United States Military Academy",
        "aff_unique_dep": "Department of Civil and Mechanical Engineering",
        "aff_unique_url": "https://www.usma.edu",
        "aff_unique_abbr": "USMA",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "West Point",
        "aff_country_unique_index": "0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561964",
        "title": "Simultaneous Multi-Level Descriptor Learning and Semantic Segmentation for Domain-Specific Relocalization",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a semi-supervised framework for multi-level description learning aiming for robust and accurate camera relocalization across large perception variations. Our proposed network, namely DLSSNet, simultaneously learns weakly-supervised semantic segmentation and local feature description in the hierarchy. Therefore, the augmented descriptors, trained in an end-to-end manner, provide a more stable high-level representation for local feature dis-ambiguity. To facilitate end-to-end semantic description learning, the descriptor segmentation module is proposed to jointly learn semantic descriptors and cluster centers using standard semantic segmentation loss. We show that our model can be easily fine-tuned for domain-specific usage without any further semantic annotations, instead, requiring only 2D-2D pixel correspondences. The learned descriptors, trained with our proposed pipeline, can boost the cross-season localization performance against other state-of-the-arts.",
        "primary_area": "",
        "author": "Xiaolong Wu;Yiye Chen;C\u00e9dric Pradalier;Patricio A. Vela;Xiaolong Wu;Yiye Chen;C\u00e9dric Pradalier;Patricio A. Vela",
        "authorids": "/37086493433;/37089001985;/37279005400;/37329553400;/37086493433;/37089001985;/37279005400;/37329553400",
        "aff": "School of Electrical and Computer Engineering, Atlanta, GA, United States; School of Electrical and Computer Engineering, Atlanta, GA, United States; School of Electrical and Computer Engineering, Atlanta, GA, United States; School of Electrical and Computer Engineering, Atlanta, GA, United States",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561964/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=797654364755122413&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "School of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561293",
        "title": "Simultaneous Precision Assembly of Multiple Objects through Coordinated Micro-robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Simultaneous assembly of multiple objects is a key technology to form solid connections among objects to get compact structures in precision assembly and micro-assembly. Dramatically different from traditional assembly of two objects, the interaction among multiple objects is more complicated on analysis and control. During simultaneous assembly of multiple objects, there are multiple mutually effected contact surfaces, and multiple force sensors are needed to perceive the interaction status. In this paper, a coordinated micro-robot manipulation strategy is proposed for simultaneous assembly problem, which is based on microscopic vision and force information. Taking simultaneous assembly of three objects as an instance, the proposed method is well articulated, including calibration of assembly system, force analysis for each contacting surface, and insertion control strategy for assembly process. The proposed method is applicable also to case with more objects. Experiment results demonstrate effectiveness of the proposed method.",
        "primary_area": "",
        "author": "Song Liu;Yuyu Jia;You-Fu Li;Yao Guo;Haojian Lu;Song Liu;Yuyu Jia;You-Fu Li;Yao Guo;Haojian Lu",
        "authorids": "/37089083036;/37088961912;/37279884400;/37089609733;/37086072763;/37089083036;/37088961912;/37279884400;/37089609733;/37086072763",
        "aff": "ShanghaiTech Automation and Robotics Center, School of Information Science and Technology, ShanghaiTech University, Shanghai, China; ShanghaiTech Automation and Robotics Center, School of Information Science and Technology, ShanghaiTech University, Shanghai, China; Department of Mechanical Engineering, City University of Hong Kong, Kowloon, Hong Kong; Institute of Medical Robotics, Shanghai Jiaotong University, Shanghai, China; State Key Laboratory of Industrial Control and Technology, and Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561293/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=281350758975634436&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;2;3",
        "aff_unique_norm": "ShanghaiTech University;City University of Hong Kong;Shanghai Jiao Tong University;Zhejiang University",
        "aff_unique_dep": "School of Information Science and Technology;Department of Mechanical Engineering;Institute of Medical Robotics;State Key Laboratory of Industrial Control and Technology, Institute of Cyber-Systems and Control",
        "aff_unique_url": "http://www.shanghaitech.edu.cn;https://www.cityu.edu.hk;https://www.sjtu.edu.cn;http://www.zju.edu.cn",
        "aff_unique_abbr": "ShanghaiTech;CityU;SJTU;ZJU",
        "aff_campus_unique_index": "0;0;1;0;2",
        "aff_campus_unique": "Shanghai;Hong Kong SAR;Hangzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560938",
        "title": "Simultaneous haptic guidance and learning of task parameters during robotic teleoperation \u2013 a geometrical approach",
        "track": "main",
        "status": "Poster",
        "abstract": "Haptic guidance can improve accuracy and dexterity during the teleoperation of a robot, but only if the model of the task used to provide the assistance is accurate. In medical robotics, the registration of a task from pre-operative planning from medical images to the robot\u2019s task-space can be erroneous. Additionally, the deformability of the environment can require online correction of a planned task. Therefore, we propose a method to update the geometry and the registration of a pathfollowing task online. This model is simultaneously used to physically guide the user during the teleoperation. Experimental results obtained on a haptic interface show the validity of the approach for a simulated 2D task.",
        "primary_area": "",
        "author": "Thibault Poignonec;Florent Nageotte;Nabil Zemiti;Bernard Bayle;Thibault Poignonec;Florent Nageotte;Nabil Zemiti;Bernard Bayle",
        "authorids": "/37088432296;/37564083700;/37294253000;/37588627100;/37088432296;/37564083700;/37294253000;/37588627100",
        "aff": "ICube Laboratory, University of Strasbourg, Strasbourg, France; ICube Laboratory, University of Strasbourg, Strasbourg, France; LIRMM, University of Montpellier, CNRS, Montpellier, France; ICube Laboratory, University of Strasbourg, Strasbourg, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560938/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13304991564493717354&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Strasbourg;University of Montpellier",
        "aff_unique_dep": "ICube Laboratory;LIRMM",
        "aff_unique_url": "https://www.unistra.fr;https://www.univ-montp2.fr",
        "aff_unique_abbr": ";UM",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Strasbourg;Montpellier",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561839",
        "title": "Situational Confidence Assistance for Lifelong Shared Autonomy",
        "track": "main",
        "status": "Poster",
        "abstract": "Shared autonomy enables robots to infer user intent and assist in accomplishing it. But when the user wants to do a new task that the robot does not know about, shared autonomy will hinder their performance by attempting to assist them with something that is not their intent. Our key idea is that the robot can detect when its repertoire of intents is insufficient to explain the user's input, and give them back control. This then enables the robot to observe unhindered task execution, learn the new intent behind it, and add it to this repertoire. We demonstrate with both a case study and a user study that our proposed method maintains good performance when the human's intent is in the robot's repertoire, outperforms prior shared autonomy approaches when it isn't, and successfully learns new skills, enabling efficient lifelong learning for confidence-based shared autonomy.",
        "primary_area": "",
        "author": "Matthew Zurek;Andreea Bobu;Daniel S. Brown;Anca D. Dragan;Matthew Zurek;Andreea Bobu;Daniel S. Brown;Anca D. Dragan",
        "authorids": "/37089000395;/37088414876;/38478370100;/37960625200;/37089000395;/37088414876;/38478370100;/37960625200",
        "aff": "EECS, UC Berkeley; EECS, UC Berkeley; EECS, UC Berkeley; EECS, UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561839/",
        "gs_citation": 34,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17710446362797831248&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Electrical Engineering and Computer Sciences",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561495",
        "title": "Sliding Mode Control of the Semi-active Hover Backpack Based on the Bioinspired Skyhook Damper Model",
        "track": "main",
        "status": "Poster",
        "abstract": "It is inevitable for human to bear the gravitational and inertial force when carrying loads. The impact force exerted on human body is originated from the inertial force which can increase the energy expenditure and cause injury to human body. This paper proposes a semi-active hover backpack with controllable air damper to minimize the inertial force. The skyhook damper model of hover backpack is established which is the dynamic target of the practical backpack. Sliding mode control is designed to eliminate the tracking error and the effectiveness of the control method is analyzed. Simulation and experiment are conducted and comparative results are stated. The results demonstrate that the semi-active hover backpack with sliding mode control can reduce the inertial force.",
        "primary_area": "",
        "author": "Bin Zhang;Tao Liu;Wu Fan;Jinyuan Zhang;Bin Zhang;Tao Liu;Wu Fan;Jinyuan Zhang",
        "authorids": "/37085880290;/37293265800;/37088457421;/37089002284;/37085880290;/37293265800;/37088457421;/37089002284",
        "aff": "State Key Laboratory of Fluid Power and Mechatronic System, School of Mechanical Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Fluid Power and Mechatronic System, School of Mechanical Engineering, Zhejiang University, Hangzhou, China; State Key Laboratory of Fluid Power and Mechatronic System, School of Mechanical Engineering, Zhejiang University, Hangzhou, China; Weldon School of Biomedical Engineering, Purdue University, West Lafayette, IN, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561495/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15011143300924906174&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "Zhejiang University;Purdue University",
        "aff_unique_dep": "School of Mechanical Engineering;Weldon School of Biomedical Engineering",
        "aff_unique_url": "http://www.zju.edu.cn;https://www.purdue.edu",
        "aff_unique_abbr": "ZJU;Purdue",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Hangzhou;West Lafayette",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561867",
        "title": "Sliding on Manifolds: Geometric Attitude Control with Quaternions",
        "track": "main",
        "status": "Poster",
        "abstract": "This work proposes a quaternion-based sliding variable that describes exponentially convergent error dynamics for any forward complete desired attitude trajectory. The proposed sliding variable directly operates on the non-Euclidean space formed by quaternions and explicitly handles the double covering property to enable global attitude tracking when used in feedback. In-depth analysis of the sliding variable is provided and compared to others in the literature. Several feedback controllers including nonlinear PD, robust, and adaptive sliding control are then derived. Simulation results of a rigid body with uncertain dynamics demonstrate the effectiveness and superiority of the approach.",
        "primary_area": "",
        "author": "Brett T. Lopez;Jean-Jacques E. Slotine;Brett T. Lopez;Jean-Jacques E. Slotine",
        "authorids": "/37085654767;/37282157700;/37085654767;/37282157700",
        "aff": "Nonlinear Systems Laboratory, Massachusetts Institute of Technology, Cambridge, MA; Nonlinear Systems Laboratory, Massachusetts Institute of Technology, Cambridge, MA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561867/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5047355706752678113&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Nonlinear Systems Laboratory",
        "aff_unique_url": "https://web.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561294",
        "title": "Small Autonomous Robot Actuator (SARA): A Solar-Powered Wireless MEMS Gripper",
        "track": "main",
        "status": "Poster",
        "abstract": "Solar-powered actuation of a 15 mN electrostatic MEMS gripper was demonstrated while wirelessly triggered by IEEE 802.15.4 RF signals. The solar-powered gripper was shown to actuate at a rate of 640 um/s. The complete system is composed of three capacitors and three chips: MEMS gripper, microprocessor/crystal-free radio, and solar cell array/high voltage buffer. Control signals for the electrostatic inchworm motors originate from the 3\u00d72\u00d70.3 mm3 chip with an ARM Cortex-M0 microprocessor and are passed through 119 V high voltage buffers. Power for all components, including the crystal-free radio, microprocessor, and 119 V buffers, is supplied by a multi-output array of solar cells on a CMOS SOI chip under 200 mW/cm2 irradiation.",
        "primary_area": "",
        "author": "Alex Moreno;Austin Patel;Daniel Teal;Hani C. Gomez;Andrew Fearing;Jan S. Rentmeister;Jason Stauth;Kristofer Pister;Alex Moreno;Austin Patel;Daniel Teal;Hani C. Gomez;Andrew Fearing;Jan S. Rentmeister;Jason Stauth;Kristofer Pister",
        "authorids": "/37087527300;/37088574445;/37088358646;/37086953573;/37088574812;/37086136783;/37301368300;/37283742700;/37087527300;/37088574445;/37088358646;/37086953573;/37088574812;/37086136783;/37301368300;/37283742700",
        "aff": "Electrical Engineering & Computer Sciences Department, Berkeley Sensor & Actuator Center, University of California, Berkeley, USA; Electrical Engineering & Computer Sciences Department, Berkeley Sensor & Actuator Center, University of California, Berkeley, USA; Electrical Engineering & Computer Sciences Department, Berkeley Sensor & Actuator Center, University of California, Berkeley, USA; Electrical Engineering & Computer Sciences Department, Berkeley Sensor & Actuator Center, University of California, Berkeley, USA; Electrical Engineering & Computer Sciences Department, Berkeley Sensor & Actuator Center, University of California, Berkeley, USA; Thayer School of Engineering, Dartmouth College, Hanover, NH, USA; Thayer School of Engineering, Dartmouth College, Hanover, NH, USA; Electrical Engineering & Computer Sciences Department, Berkeley Sensor & Actuator Center, University of California, Berkeley, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561294/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11839309635525009418&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;1;0",
        "aff_unique_norm": "University of California, Berkeley;Dartmouth College",
        "aff_unique_dep": "Electrical Engineering & Computer Sciences Department;Thayer School of Engineering",
        "aff_unique_url": "https://www.berkeley.edu;https://engineering.dartmouth.edu",
        "aff_unique_abbr": "UC Berkeley;Dartmouth",
        "aff_campus_unique_index": "0;0;0;0;0;1;1;0",
        "aff_campus_unique": "Berkeley;Hanover",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560797",
        "title": "Smile Like You Mean It: Driving Animatronic Robotic Face with Learned Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Ability to generate intelligent and generalizable facial expressions is essential for building human-like social robots. At present, progress in this field is hindered by the fact that each facial expression needs to be programmed by humans. In order to adapt robot behavior in real time to different situations that arise when interacting with human subjects, robots need to be able to train themselves without requiring human labels, as well as make fast action decisions and generalize the acquired knowledge to diverse and new contexts. We addressed this challenge by designing a physical animatronic robotic face with soft skin and by developing a vision-based self-supervised learning framework for facial mimicry. Our algorithm does not require any knowledge of the robot's kinematic model, camera calibration or predefined expression set. By decomposing the learning process into a generative model and an inverse model, our framework can be trained using a single motor babbling dataset. Comprehensive evaluations show that our method enables accurate and diverse face mimicry across diverse human subjects.",
        "primary_area": "",
        "author": "Boyuan Chen;Yuhang Hu;Lianfeng Li;Sara Cummings;Hod Lipson;Boyuan Chen;Yuhang Hu;Lianfeng Li;Sara Cummings;Hod Lipson",
        "authorids": "/37086319227;/37088996976;/37088997347;/37089001028;/37278575000;/37086319227;/37088996976;/37088997347;/37089001028;/37278575000",
        "aff": "Columbia University; Columbia University; Columbia University; Columbia University; Columbia University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560797/",
        "gs_citation": 39,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3507515228037965466&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560982",
        "title": "Smooth Path Planning for Continuum Arms",
        "track": "main",
        "status": "Poster",
        "abstract": "Continuum arms, with their mix of compliance, payload, safety, and manipulability, are perfectly suited to serve as co-robots, and their applications range from industry and manufacturing to human healthcare. Their hyper-redundancy serves as their most significant challenge for path planning and path planning approaches commonly used with rigid-link robots, such as inverse kinematics, that fail to provide reliable trajectories for continuum arms. We propose an Inverse Kinematics-based approach to address the limitations of previously-proposed Kinematics-based approaches. Using this new approach, we are able to efficiently generate very rich sets of configurations, which, in turn, lead to smooth path planning for such continuum manipulators. To validate the smoothness of the paths generated by our approach, we apply dynamics constraints to the generated trajectories. We show that, when tracked by a controller, the paths that are generated using the proposed approach are much smoother than previously-proposed Kinematics-based approaches: The proposed approach allows the continuum arm to traverse the trajectories very accurately and in time less than half of that taken by previous (reliable) path planning approaches.",
        "primary_area": "",
        "author": "Brandon H. Meng;Isuru S. Godage;Iyad Kanj;Brandon H. Meng;Isuru S. Godage;Iyad Kanj",
        "authorids": "/37086843091;/37946220700;/37284504800;/37086843091;/37946220700;/37284504800",
        "aff": "School of Computing, DePaul University, Chicago, IL, USA; School of Computing, DePaul University, Chicago, IL, USA; School of Computing, DePaul University, Chicago, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560982/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12464718341759497937&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "DePaul University",
        "aff_unique_dep": "School of Computing",
        "aff_unique_url": "https://www.depaul.edu",
        "aff_unique_abbr": "DePaul",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Chicago",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560804",
        "title": "Smooth-RRT*: Asymptotically Optimal Motion Planning for Mobile Robots under Kinodynamic Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Nowadays, various algorithms based on the Rapidly-exploring Random Tree (RRT) methods are utilized to solve motion planning problems. Based on the RRT*, we developed a novel reconnection method that enables the planner to directly generate a smooth curved trajectory. Meanwhile, kinodynamic constraints of the robots are considered to generate the control input, which improves the feasibility of the algorithm. The trajectory planned by the Smooth-RRT* is significantly suitable for the non-holonomic robots. Planning tests are conducted in four scenarios to demonstrate performance of the proposed algorithm in comparison with the original RRT* and kinodynamic-RRT (Kino-RRT). Smooth-RRT* yields shorter and smoother planned path in all the scenarios compared with the Kino-RRT. It finds a solution with fewer expansion nodes than the RRT* under the same time consumption. The results demonstrate that the proposed algorithm can generate a smooth trajectory satisfied with the kinodynamic constraints and ensure the asymptotic optimality.",
        "primary_area": "",
        "author": "Yiting Kang;Zhi Yang;Riya Zeng;Qi Wu;Yiting Kang;Zhi Yang;Riya Zeng;Qi Wu",
        "authorids": "/37086462506;/37088998200;/37086462548;/37086461631;/37086462506;/37088998200;/37086462548;/37086461631",
        "aff": "School of Mechanical Engineering, University of Science and Technology Beijing, Beijing, China; School of Mechanical Engineering, University of Science and Technology Beijing, Beijing, China; School of Mechanical Engineering, University of Science and Technology Beijing, Beijing, China; Beijing Electric Vehicle Co.,Ltd., Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560804/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8640714388806192668&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Science and Technology Beijing;Beijing Electric Vehicle Co., Ltd.",
        "aff_unique_dep": "School of Mechanical Engineering;",
        "aff_unique_url": "http://www.ustb.edu.cn;",
        "aff_unique_abbr": "USTB;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561897",
        "title": "Social Navigation for Mobile Robots in the Emergency Department",
        "track": "main",
        "status": "Poster",
        "abstract": "The emergency department (ED) is a safety-critical environment in which healthcare workers (HCWs) are overburdened, overworked, and have limited resources, especially during the COVID-19 pandemic. One way to address this problem is to explore the use of robots that can support clinical teams, e.g., to deliver materials or restock supplies. However, due to EDs being overcrowded, and the cognitive overload HCWs experience, robots need to understand various levels of patient acuity so they avoid disrupting care delivery. In this paper, we introduce the Safety-Critical Deep Q-Network (SafeDQN) system, a new acuity-aware navigation system for mobile robots. SafeDQN is based on two insights about care in EDs: high-acuity patients tend to have more HCWs in attendance and those HCWs tend to move more quickly. We compared SafeDQN to three classic navigation methods, and show that it generates the safest, quickest path for mobile robots when navigating in a simulated ED environment. We hope this work encourages future exploration of social robots that work in safety-critical, human-centered environments, and ultimately help to improve patient outcomes and save lives.",
        "primary_area": "",
        "author": "Angelique M. Taylor;Sachiko Matsumoto;Wesley Xiao;Laurel D. Riek;Angelique M. Taylor;Sachiko Matsumoto;Wesley Xiao;Laurel D. Riek",
        "authorids": "/37089108186;/37088998488;/37088997570;/38548291500;/37089108186;/37088998488;/37088997570;/38548291500",
        "aff": "Computer Science and Engineering, UC San Diego, USA; Computer Science and Engineering, UC San Diego, USA; Computer Science and Engineering, UC San Diego, USA; Computer Science and Engineering, UC San Diego, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561897/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10781722871355537198&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Computer Science and Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561582",
        "title": "Social-STAGE: Spatio-Temporal Multi-Modal Future Trajectory Forecast",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper considers the problem of multi-modal future trajectory forecast with ranking. Here, multi-modality and ranking refer to the multiple plausible path predictions and the confidence in those predictions, respectively. We propose Social-STAGE, Social interaction-aware Spatio-Temporal multi-Attention Graph convolution network with novel Evaluation for multi-modality. Our main contributions include analysis and formulation of multi-modality with ranking using interaction and multi-attention, and introduction of new metrics to evaluate the diversity and associated confidence of multi-modal predictions. We evaluate our approach on existing public datasets ETH and UCY and show that the proposed algorithm outperforms the state of the arts on these datasets.",
        "primary_area": "",
        "author": "Srikanth Malla;Chiho Choi;Behzad Dariush;Srikanth Malla;Chiho Choi;Behzad Dariush",
        "authorids": "/37086934253;/37086937192;/37444121400;/37086934253;/37086937192;/37444121400",
        "aff": "Honda Research Institute USA, San Jose, CA, USA; Honda Research Institute USA, San Jose, CA, USA; Honda Research Institute USA, San Jose, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561582/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9211148096396924103&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Honda Research Institute USA",
        "aff_unique_dep": "",
        "aff_unique_url": "https://honda-ri.com",
        "aff_unique_abbr": "HRI USA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "San Jose",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561434",
        "title": "Soft Hybrid Aerial Vehicle via Bistable Mechanism",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned aerial vehicles have been demonstrated successfully in a variety of tasks, including surveying and sampling tasks over large areas. These vehicles can take many forms. Quadrotors\u2019 agility and ability to hover makes them well suited for navigating potentially tight spaces, while fixed wing aircraft are capable of efficient flight over long distances. Hybrid aerial vehicles (HAVs) attempt to achieve both of these benefits by exhibiting multiple modes; however, morphing HAVs typically require extra actuators which add mass, reducing both agility and efficiency. We propose a morphing HAV with folding wings that exhibits both a quadrotor and a fixed wing mode without requiring any extra actuation. This is achieved by leveraging the motion of a bistable mechanism at the center of the aircraft to drive folding of the wing using only the existing motors and the inertia of the system. We optimize both the bistable mechanism and the folding wing using a topology optimization approach. The resulting mechanisms were fabricated on a 3D printer and replaced the frame of an existing quadrotor. Our prototype successfully transitions between both modes and our experiments demonstrate that the behavior of the fabricated prototype is consistent with that of the simulation.",
        "primary_area": "",
        "author": "Xuan Li;Jessica McWilliams;Minchen Li;Cynthia Sung;Chenfanfu Jiang;Xuan Li;Jessica McWilliams;Minchen Li;Cynthia Sung;Chenfanfu Jiang",
        "authorids": "/37089001484;/37086294614;/37088998707;/37086639646;/37086078633;/37089001484;/37086294614;/37088998707;/37086639646;/37086078633",
        "aff": "University of Pennsylvania and the Department of Mathematics, SIG Center for Computer Graphics, University of California, Los Angeles; General Robotics, Automation, Sensing & Perception (GRASP) Lab, University of Pennsylvania; University of Pennsylvania and the Department of Mathematics, SIG Center for Computer Graphics, University of California, Los Angeles; General Robotics, Automation, Sensing & Perception (GRASP) Lab, University of Pennsylvania; University of Pennsylvania and the Department of Mathematics, SIG Center for Computer Graphics, University of California, Los Angeles",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561434/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6176568771106704259&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "Department of Mathematics",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560999",
        "title": "Soft Robot Optimal Control Via Reduced Order Finite Element Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Finite element methods have been successfully used to develop physics-based models of soft robots that capture the nonlinear dynamic behavior induced by continuous deformation. These high-fidelity models are therefore ideal for designing controllers for complex dynamic tasks such as trajectory optimization and trajectory tracking. However, finite element models are also typically very high-dimensional, which makes real-time control challenging. In this work we propose an approach for finite element model-based control of soft robots that leverages model order reduction techniques to significantly increase computational efficiency. In particular, a constrained optimal control problem is formulated based on a nonlinear reduced order finite element model and is solved via sequential convex programming. This approach is demonstrated through simulation of a cable-driven soft robot for a constrained trajectory tracking task, where a 9768-dimensional finite element model is used for controller design.",
        "primary_area": "",
        "author": "Sander Tonkens;Joseph Lorenzetti;Marco Pavone;Sander Tonkens;Joseph Lorenzetti;Marco Pavone",
        "authorids": "/37089000808;/37086596679;/37307912900;/37089000808;/37086596679;/37307912900",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, CA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA; Department of Aeronautics and Astronautics, Stanford University, Stanford, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560999/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5929674704178420370&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Stanford University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stanford.edu",
        "aff_unique_abbr": "Stanford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Stanford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562008",
        "title": "Soft-Jig-Driven Assembly Operations",
        "track": "main",
        "status": "Poster",
        "abstract": "To design a general-purpose assembly robot system that can handle objects of various shapes, we propose a soft jig that fits to the shapes of assembly parts. The functionality of the soft jig is based on a jamming gripper developed in the field of soft robotics. The soft jig has a bag covered with a malleable silicone membrane, which has high friction, elongation, and contraction rates for keeping parts fixed. The bag is filled with glass beads to achieve a jamming transition. We propose a method to configure parts-fixing on the soft jig based on contact relations, reachable directions, and the center of gravity of the parts that are fixed on the jig. The usability of the soft jig was evaluated in terms of the fixing performance and versatility for various shapes and postures of parts.",
        "primary_area": "",
        "author": "Takuya Kiyokawa;Tatsuya Sakuma;Jun Takamatsu;Tsukasa Ogasawara;Takuya Kiyokawa;Tatsuya Sakuma;Jun Takamatsu;Tsukasa Ogasawara",
        "authorids": "/37086694759;/37086581398;/37324010500;/37269488400;/37086694759;/37086581398;/37324010500;/37269488400",
        "aff": "Division of Information Science, Robotics Laboratory, Nara Institute of Science and Technology (NAIST), Japan; Division of Information Science, Robotics Laboratory, Nara Institute of Science and Technology (NAIST), Japan; Division of Information Science, Robotics Laboratory, Nara Institute of Science and Technology (NAIST), Japan; Division of Information Science, Robotics Laboratory, Nara Institute of Science and Technology (NAIST), Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562008/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6914147438459800846&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nara Institute of Science and Technology",
        "aff_unique_dep": "Division of Information Science, Robotics Laboratory",
        "aff_unique_url": "https://www.naist.jp",
        "aff_unique_abbr": "NAIST",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9562087",
        "title": "SoftMP: Attentive feature pooling for joint local feature detection and description for place recognition in changing environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual place recognition is the task of finding matchings of images that show the same place in the world. Combinations of appearance changes (e.g. changing illumination or weather) and geometric changes (e.g. viewpoint changes or occlusions) challenge existing approaches. Learning-based local image feature pipelines are a promising approach to this type of problem. We present a novel attentive feature pooling method that can be used to train a CNN to jointly detect and describe local image features. It can be trained on small or moderately sized datasets with weak supervision in a classification training setup (e.g. we use a set of 24k images of publicly available web-camera images in our experiments). We propose to use a joint loss function that combines the cross-entropy loss for the classification task with a mean squared error in order to increase the repeatability of feature detections. We show how the approach can be integrated in a place recognition pipeline and run experiments on several standard place recognition datasets. Despite the small training dataset, we demonstrate a 15% improvement in the average performance compared to the best of a number of compared state-of-the-art approaches, and, probably more importantly, a 3x improvement in the worst-case performance. Open source code is available.",
        "primary_area": "",
        "author": "Fangming Yuan;Peer Neubert;Stefan Schubert;Peter Protzel;Fangming Yuan;Peer Neubert;Stefan Schubert;Peter Protzel",
        "authorids": "/37089000296;/37600009900;/37086245725;/37330206000;/37089000296;/37600009900;/37086245725;/37330206000",
        "aff": "Faculty of Electrical Engineering and Automation Technology, Chemnitz University of Technology, Chemnitz, Germany; Faculty of Electrical Engineering and Automation Technology, Chemnitz University of Technology, Chemnitz, Germany; Faculty of Electrical Engineering and Automation Technology, Chemnitz University of Technology, Chemnitz, Germany; Faculty of Electrical Engineering and Automation Technology, Chemnitz University of Technology, Chemnitz, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562087/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15962718155798932585&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Chemnitz University of Technology",
        "aff_unique_dep": "Faculty of Electrical Engineering and Automation Technology",
        "aff_unique_url": "https://www.tu-chemnitz.de",
        "aff_unique_abbr": "TUC",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Chemnitz",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561435",
        "title": "Solving Markov Decision Processes with Partial State Abstractions",
        "track": "main",
        "status": "Poster",
        "abstract": "Autonomous systems often use approximate planners that exploit state abstractions to solve large MDPs in real-time decision-making problems. However, these planners can eliminate details needed to produce effective behavior in autonomous systems. We therefore propose a novel model, a partially abstract MDP, with a set of abstract states that each compress a set of ground states to condense irrelevant details and a set of ground states that expand from a set of expanded abstract states to retain relevant details. This papers offers (1) a definition of a partially abstract MDP that (2) generalizes its ground MDP and its abstract MDP and exhibits bounded optimality depending on its abstract MDP along with (3) a lazy algorithm for planning and execution in autonomous systems. The result is a scalable approach that computes near-optimal solutions to large problems in minutes rather than hours.",
        "primary_area": "",
        "author": "Samer B. Nashed;Justin Svegliato;Matteo Brucato;Connor Basich;Rod Grupen;Shlomo Zilberstein;Samer B. Nashed;Justin Svegliato;Matteo Brucato;Connor Basich;Rod Grupen;Shlomo Zilberstein",
        "authorids": "/37086198158;/37072711700;/37089001624;/37087105976;/37283681700;/37285091900;/37086198158;/37072711700;/37089001624;/37087105976;/37283681700;/37285091900",
        "aff": "College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA; College of Information and Computer Sciences, University of Massachusetts, Amherst, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561435/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16343329156163833862&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Massachusetts Amherst",
        "aff_unique_dep": "College of Information and Computer Sciences",
        "aff_unique_url": "https://www.umass.edu",
        "aff_unique_abbr": "UMass Amherst",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Amherst",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562053",
        "title": "Sparse Multilevel Roadmaps for High-Dimensional Robotic Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Sparse roadmaps are important to compactly represent state spaces, to determine problems to be infeasible and to terminate in finite time. However, sparse roadmaps do not scale well to high-dimensional planning problems. In prior work, we showed improved planning performance on high-dimensional planning problems by using multilevel abstractions to simplify state spaces. In this work, we generalize sparse roadmaps to multilevel abstractions by developing a novel algorithm, the sparse multilevel roadmap planner (SMLR). To this end, we represent multilevel abstractions using the language of fiber bundles, and generalize sparse roadmap planners by using the concept of restriction sampling with visibility regions. We argue SMLR to be probabilistically complete and asymptotically near-optimal by inheritance from sparse roadmap planners. In evaluations, we outperform sparse roadmap planners on challenging planning problems, in particular problems which are high-dimensional, contain narrow passages or are infeasible. We thereby demonstrate sparse multilevel roadmaps as an efficient tool for feasible and infeasible high-dimensional planning problems.",
        "primary_area": "",
        "author": "Andreas Orthey;Marc Toussaint;Andreas Orthey;Marc Toussaint",
        "authorids": "/37077150400;/37528418600;/37077150400;/37528418600",
        "aff": "Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Technical University of Berlin, Berlin, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562053/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18183217831154064525&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems;Technical University of Berlin",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.mpi-is.mpg.de;https://www.tu-berlin.de",
        "aff_unique_abbr": "MPI-IS;TUB",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Stuttgart;Berlin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9560961",
        "title": "Sparsity-Inducing Optimal Control via Differential Dynamic Programming",
        "track": "main",
        "status": "Poster",
        "abstract": "Optimal control is a popular approach to synthesize highly dynamic motion. Commonly, L2 regularization is used on the control inputs in order to minimize energy used and to ensure smoothness of the control inputs. However, for some systems, such as satellites, the control needs to be applied in sparse bursts due to how the propulsion system operates. In this paper, we study approaches to induce sparsity in optimal control solutions\u2014namely via smooth L1 and Huber regularization penalties. We apply these loss terms to state-of-the-art Differential Dynamic Programming (DDP)-based solvers to create a family of sparsity-inducing optimal control methods. We analyze and compare the effect of the different losses on inducing sparsity, their numerical conditioning, their impact on convergence, and discuss hyperparameter settings. We demonstrate our method in simulation and hardware experiments on canonical dynamics systems, control of satellites, and the NASA Valkyrie humanoid robot. We provide an implementation of our method and all examples for reproducibility on GitHub.",
        "primary_area": "",
        "author": "Traiko Dinev;Wolfgang Merkt;Vladimir Ivan;Ioannis Havoutis;Sethu Vijayakumar;Traiko Dinev;Wolfgang Merkt;Vladimir Ivan;Ioannis Havoutis;Sethu Vijayakumar",
        "authorids": "/37088686256;/37086118415;/37085552022;/37542879900;/37295595500;/37088686256;/37086118415;/37085552022;/37542879900;/37295595500",
        "aff": "Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK; Oxford Robotics Institute, University of Oxford, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560961/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1945679657033712560&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 12,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Oxford Robotics Institute",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561264",
        "title": "Spatial Graph Regularized Multi-kernel Subtask Cross-correlation Tracker",
        "track": "main",
        "status": "Poster",
        "abstract": "Some impressing multi-kernel or multi-task correlation filter trackers only focus on boosting the discrimination of multi-channel features, or exploiting the interdependence among different tasks. However, the cooperation and complementary of both technologies are missed, and the spatial structure among or inside target regions is also ignored. Therefore, this paper proposes a spatial graph regularized hierarchical subtask multi-kernel cross-correlation tracker (GHMK) via Gaussian process regression view, which enjoys the merits of multi-subtask multi-kernel learning and Gaussian process regression to jointly learn kernel cross-correlation filters, and makes them complement and boost each other. The interdependence and discrimination among multi-kernel multi-subtask are jointly exploited by group structure sparsity, which is also used to evaluate spatial feature selection. The spatial graph is constructed via cross similarity to maintain the geometric structure among or inside hierarchy subtasks. Besides, the developed model is general, and provides a unified solution from GPR for CF trackers without boundary effect. Comprehensive experiments demonstrate its favorable and competitive performance against the state-of-the-art trackers.",
        "primary_area": "",
        "author": "Baojie Fan;Baojie Fan",
        "authorids": "/37528678800;/37528678800",
        "aff": "Automation College, NJUPT",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561264/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:9mdFLOnz6noJ:scholar.google.com/&scioq=Spatial+Graph+Regularized+Multi-kernel+Subtask+Cross-correlation+Tracker&hl=en&as_sdt=0,5",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 2,
        "aff_unique_index": "0",
        "aff_unique_norm": "Nanjing University of Posts and Telecommunications",
        "aff_unique_dep": "Automation College",
        "aff_unique_url": "http://www.njupt.edu.cn/",
        "aff_unique_abbr": "NJUPT",
        "aff_country_unique_index": "0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561359",
        "title": "Spatial Intention Maps for Multi-Agent Mobile Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to communicate intention enables decentralized multi-agent robots to collaborate while performing physical tasks. In this work, we present spatial intention maps, a new intention representation for multi-agent vision-based deep reinforcement learning that improves coordination between decentralized mobile manipulators. In this representation, each agent\u2019s intention is provided to other agents, and rendered into an overhead 2D map aligned with visual observations. This synergizes with the recently proposed spatial action maps framework, in which state and action representations are spatially aligned, providing inductive biases that encourage emergent cooperative behaviors requiring spatial coordination, such as passing objects to each other or avoiding collisions. Experiments across a variety of multi-agent environments, including heterogeneous robot teams with different abilities (lifting, pushing, or throwing), show that incorporating spatial intention maps improves performance for different mobile manipulation tasks while significantly enhancing cooperative behaviors.",
        "primary_area": "",
        "author": "Jimmy Wu;Xingyuan Sun;Andy Zeng;Shuran Song;Szymon Rusinkiewicz;Thomas Funkhouser;Jimmy Wu;Xingyuan Sun;Andy Zeng;Shuran Song;Szymon Rusinkiewicz;Thomas Funkhouser",
        "authorids": "/37088997075;/37088996176;/37086217185;/37085613509;/37273654100;/37283059800;/37088997075;/37088996176;/37086217185;/37085613509;/37273654100;/37283059800",
        "aff": "Google; Princeton University; Google; Columbia University; Princeton University; Google",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561359/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16469615298461305828&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;2;1;0",
        "aff_unique_norm": "Google;Princeton University;Columbia University",
        "aff_unique_dep": "Google;;",
        "aff_unique_url": "https://www.google.com;https://www.princeton.edu;https://www.columbia.edu",
        "aff_unique_abbr": "Google;Princeton;Columbia",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Mountain View;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560895",
        "title": "Spatial Reasoning from Natural Language Instructions for Robot Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots that can manipulate objects in unstructured environments and collaborate with humans can benefit immensely by understanding natural language. We propose a pipelined architecture of two stages to perform spatial reasoning on the text input. All the objects in the scene are first localized, and then the instruction for the robot in natural language and the localized co-ordinates are mapped to the start and end co-ordinates corresponding to the locations where the robot must pick up and place the object respectively. We show that representing the localized objects by quantizing their positions to a binary grid is preferable to representing them as a list of 2D co-ordinates. We also show that attention improves generalization and can overcome biases in the dataset. The proposed method is used to pick-and-place playing cards using a robot arm.",
        "primary_area": "",
        "author": "Sagar Gubbi Venkatesh;Anirban Biswas;Raviteja Upadrashta;Vikram Srinivasan;Partha Talukdar;Bharadwaj Amrutur;Sagar Gubbi Venkatesh;Anirban Biswas;Raviteja Upadrashta;Vikram Srinivasan;Partha Talukdar;Bharadwaj Amrutur",
        "authorids": "/37087323447;/37088996765;/37085368187;/37089001740;/38236229300;/37370284100;/37087323447;/37088996765;/37085368187;/37089001740;/38236229300;/37370284100",
        "aff": "Department of Electrical and Communication Engineering, Indian Institute of Science, Bangalore, India; Department of Computational and Data Sciences, Indian Institute of Science, Bangalore, India; Robert Bosch Center for Cyber Physical Systems, Indian Institute of Science, Bangalore, India; Department of Electrical and Communication Engineering, Indian Institute of Science, Bangalore, India; Department of Computational and Data Sciences, Indian Institute of Science, Bangalore, India; Department of Electrical and Communication Engineering, Indian Institute of Science, Bangalore, India",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560895/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5117665126795261745&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Indian Institute of Science",
        "aff_unique_dep": "Department of Electrical and Communication Engineering",
        "aff_unique_url": "https://www.iisc.ac.in",
        "aff_unique_abbr": "IISc",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Bangalore",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "India"
    },
    {
        "id": "9561899",
        "title": "Spatial and Temporal Splitting Heuristics for Multi-Robot Motion Planning",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we systematically examine the application of spatio-temporal splitting heuristics to the Multi-Robot Motion Planning (MRMP) problem in a graph-theoretic setting: a problem known to be NP-hard to optimally solve. Following the divide-and-conquer principle, we design multiple spatial and temporal splitting schemes that can be applied to any existing MRMP algorithm, including integer programming solvers and Enhanced Conflict Based Search, in an orthogonal manner. The combination of a good baseline MRMP algorithm with a proper splitting heuristic proves highly effective, allowing the resolution of problems 10+ times than what is possible previously, as corroborated by extensive numerical evaluations. Notably, spatial partition of problem fusing with the temporal splitting heuristic and the enhanced conflict based search (ECBS) algorithm increases the scalability of ECBS on large and challenging DAO maps by 5\u201315 folds with negligible impact on solution optimality.",
        "primary_area": "",
        "author": "Teng Guo;Shuai D. Han;Jingjin Yu;Teng Guo;Shuai D. Han;Jingjin Yu",
        "authorids": "/37088998158;/37086094452;/37536570700;/37088998158;/37086094452;/37536570700",
        "aff": "Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA; Department of Computer Science, Rutgers, the State University of New Jersey, Piscataway, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561899/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16968291258714246416&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Rutgers, the State University of New Jersey",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Piscataway",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561461",
        "title": "Spectral Temporal Graph Neural Network for Trajectory Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "An effective understanding of the contextual environment and accurate motion forecasting of surrounding agents is crucial for the development of autonomous vehicles and social mobile robots. This task is challenging since the behavior of an autonomous agent is not only affected by its own intention, but also by the static environment and surrounding dynamically interacting agents. Previous works focused on utilizing the spatial and temporal information in time domain while not sufficiently taking advantage of the cues in frequency domain. To this end, we propose a Spectral Temporal Graph Neural Network (SpecTGNN), which can capture inter-agent correlations and temporal dependency simultaneously in frequency domain in addition to time domain. SpecTGNN operates on both an agent graph with dynamic state information and an environment graph with the features extracted from context images in two streams. The model integrates graph Fourier transform, spectral graph convolution and temporal gated convolution to encode history information and forecast future trajectories. Moreover, we incorporate a multi-head spatio-temporal attention mechanism to mitigate the effect of error propagation in a long time horizon. We demonstrate the performance of SpecTGNN on two public trajectory prediction benchmark datasets, which achieves state-of-the-art performance in terms of prediction accuracy.",
        "primary_area": "",
        "author": "Defu Cao;Jiachen Li;Hengbo Ma;Masayoshi Tomizuka;Defu Cao;Jiachen Li;Hengbo Ma;Masayoshi Tomizuka",
        "authorids": "/37088688568;/37086309095;/37086547315;/37281933000;/37088688568;/37086309095;/37086547315;/37281933000",
        "aff": "Peking University, China; University of California, Berkeley, USA; University of California, Berkeley, USA; University of California, Berkeley, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561461/",
        "gs_citation": 86,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1392732895228566013&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Peking University;University of California, Berkeley",
        "aff_unique_dep": ";",
        "aff_unique_url": "http://www.pku.edu.cn;https://www.berkeley.edu",
        "aff_unique_abbr": "Peking U;UC Berkeley",
        "aff_campus_unique_index": "1;1;1",
        "aff_campus_unique": ";Berkeley",
        "aff_country_unique_index": "0;1;1;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561838",
        "title": "Spherical Magnetic Joint for Inverted Locomotion of Multi-Legged Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a spherical magnetic joint for the inverted locomotion of a multi-legged robot. The permanent magnet\u2019s spherical shape allows the robot to attach its foot to a steel surface without energy consumption. However, the robot\u2019s inverted locomotion requires foot flexibility for placement and gait construction of the robot. Therefore, the spherical magnetic joint mechanism was designed and implemented for the robot feet to deal with angular placement. For decoupling the foot from the steel surface, the attractive force is adjusted by tilting the adjustable sleeve mechanism at an adequate angle between the surface and foot tip. Experimental results show that the spherical magnetic joint can maintain the attractive force at any angle, and the sleeve mechanism can reduce 20% of the reaction force for pulling the legs from the steel surfaces. Furthermore, the designed gait for inverted locomotion with a spherical magnetic joint was tested and compared to prove the concept of the spherical magnetic joint and sleeve mechanism.",
        "primary_area": "",
        "author": "Harn Sison;Photchara Ratsamee;Manabu Higashida;Tomohiro Mashita;Yuki Uranishi;Haruo Takemura;Harn Sison;Photchara Ratsamee;Manabu Higashida;Tomohiro Mashita;Yuki Uranishi;Haruo Takemura",
        "authorids": "/37086428230;/38467126100;/37688927200;/37272119500;/37669830300;/37269924100;/37086428230;/38467126100;/37688927200;/37272119500;/37669830300;/37269924100",
        "aff": "Cyber Media Center, Osaka University, Japan; Cyber Media Center, Osaka University, Japan; Cyber Media Center, Osaka University, Japan; Cyber Media Center, Osaka University, Japan; Cyber Media Center, Osaka University, Japan; Cyber Media Center, Osaka University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561838/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2818023068698127767&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Osaka University",
        "aff_unique_dep": "Cyber Media Center",
        "aff_unique_url": "https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561078",
        "title": "Spherical Multi-Modal Place Recognition for Heterogeneous Sensor Systems",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a robust end-to-end multi-modal pipeline for place recognition where the sensor systems can differ from the map building to the query. Our approach operates directly on images and LiDAR scans without requiring any local feature extraction modules. By projecting the sensor data onto the unit sphere, we learn a multi-modal descriptor of partially overlapping scenes using a spherical convolutional neural network. The employed spherical projection model enables the support of arbitrary LiDAR and camera systems readily without losing information. Loop closure candidates are found using a nearest-neighbor lookup in the embedding space. We tackle the problem of correctly identifying the closest place by correlating the candidates\u2019 power spectra, obtaining a confidence value per prospect. Our estimate for the correct place corresponds then to the candidate with the highest confidence. We evaluate our proposal w.r.t. state-of-the-art approaches in place recognition using real-world data acquired using different sensors. Our approach can achieve a recall that is up to 10% and 5% higher than for a LiDAR- and vision-based system, respectively, when the sensor setup differs between model training and deployment. Additionally, our place selection can correctly identify up to 95% matches from the candidate set.",
        "primary_area": "",
        "author": "Lukas Bernreiter;Lionel Ott;Juan Nieto;Roland Siegwart;Cesar Cadena;Lukas Bernreiter;Lionel Ott;Juan Nieto;Roland Siegwart;Cesar Cadena",
        "authorids": "/37086451179;/38251784400;/37085778635;/37281398300;/37593590400;/37086451179;/38251784400;/37085778635;/37281398300;/37593590400",
        "aff": "Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561078/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5097657085377033580&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Zurich",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9560896",
        "title": "SplatPlanner: Efficient Autonomous Exploration via Permutohedral Frontier Filtering",
        "track": "main",
        "status": "Poster",
        "abstract": "We address the problem of autonomous exploration of unknown environments using a Micro Aerial Vehicle (MAV) equipped with an active depth sensor. As such, the task consists in mapping the gradually discovered environment while planning the envisioned trajectories in real-time, using on-board computation only. To do so, we present SplatPlanner, an end-to-end autonomous planner that is based on a novel Permutohedral Frontier Filtering (PFF) which relies on a combination of highly efficient operations stemming from bilateral filtering using permutohedral lattices to guide the entire exploration. In particular, our PFF is computationally linear in input size, nearly parameter-free, and aggregates spatial information about frontier-neighborhoods into density scores in one single step. Comparative experiments made on simulated environments of increasing complexity show our method consistently outperforms recent state-of-the-art methods in terms of computational efficiency, exploration speed and qualitative coverage of scenes. Finally, we also display the practical capabilities of our end-to-end system in a challenging real-flight scenario.",
        "primary_area": "",
        "author": "Anthony Brunel;Amine Bourki;C\u00e9dric Demonceaux;Olivier Strauss;Anthony Brunel;Amine Bourki;C\u00e9dric Demonceaux;Olivier Strauss",
        "authorids": "/37089001764;/37086149064;/37265984700;/37327035000;/37089001764;/37086149064;/37265984700;/37327035000",
        "aff": "Gambi-M R&D, Paris, France; Gambi-M R&D, Paris, France; VIBOT EMR CNRS 6000, ImViA, Universit\u00e9 Bour-gogne Franche-Comt\u00e9 (UBFC), Le Creusot, France; LIRMM, Univ. Montpellier, CNRS, Montpellier, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560896/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1811146340747179853&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;2",
        "aff_unique_norm": "Gambi-M R&D;Universit\u00e9 Bour-gogne Franche-Comt\u00e9;Laboratoire d'Informatique, de Robotique et de Micro\u00e9lectronique de Montpellier",
        "aff_unique_dep": ";ImViA;",
        "aff_unique_url": ";;https://www.lirmm.fr",
        "aff_unique_abbr": ";UBFC;LIRMM",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Le Creusot;Montpellier",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9560775",
        "title": "SpringExo, a spring-based exoskeleton for providing knee assistance: Design, Characterization and Feasibility Study",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the design and preliminary evaluation of a portable spring-based knee exoskeleton, the SpringExo, which is designed to provide assistance to the leg while minimizing interference with the natural leg movement. Traditional rigid exoskeletons are unable to accurately align with a user\u2019s anatomical joints. In addition, the user\u2019s natural motion pattern is likely to change due to the constraints of the rigid exoskeleton. Though some textile-based soft exosuits and cable-driven soft exoskeletons have been developed to achieve better alignment with human\u2019s biological joints, forces applied by the cables have to be sustained by human skeleton and joints. SpringExo, in comparison, uses a coil spring which the user wears around the thigh and shank, and does not require alignment with the joints. The spring stores energy and provides minimal interference during elastic deformation. A key feature of the SpringExo is that the springs store energy during the flexion phase and release this energy to assist the knee extension in the extension phase. We conducted human subjects study to verify its biomechanical and physiological effects on the user during stair ascent. Results from a six-subject study showed that the device did not interfere with the natural joint angles and assisted knee extension during stair ascent. However, further redesign and optimization are needed on the actuation system to offset SpringExo\u2019s drawback of hindering knee flexion.",
        "primary_area": "",
        "author": "Dongbao Sui;Biing-Chwen Chang;Rand Hidayah;Yanhe Zhu;Sunil K. Agrawal;Dongbao Sui;Biing-Chwen Chang;Rand Hidayah;Yanhe Zhu;Sunil K. Agrawal",
        "authorids": "/37088377700;/37086616570;/37086478360;/37406132600;/37281455400;/37088377700;/37086616570;/37086478360;/37406132600;/37281455400",
        "aff": "State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; Department of Mechanical Engineering, Columbia University, New York, NY, USA; Department of Mechanical Engineering, Columbia University, New York, NY, USA; State Key Laboratory of Robotics and System, Harbin Institute of Technology, Harbin, China; Department of Rehabilitation and Regenerative Medicine, Columbia University, New York, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560775/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8277912222732474388&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;1",
        "aff_unique_norm": "Harbin Institute of Technology;Columbia University",
        "aff_unique_dep": "State Key Laboratory of Robotics and System;Department of Mechanical Engineering",
        "aff_unique_url": "http://www.hit.edu.cn/;https://www.columbia.edu",
        "aff_unique_abbr": "HIT;Columbia",
        "aff_campus_unique_index": "0;1;1;0;1",
        "aff_campus_unique": "Harbin;New York",
        "aff_country_unique_index": "0;1;1;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561822",
        "title": "StRETcH: a Soft to Resistive Elastic Tactile Hand",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft optical tactile sensors enable robots to manipulate deformable objects by capturing important features such as high-resolution contact geometry and estimations of object compliance. This work presents a variable stiffness soft tactile end-effector called StRETcH, a Soft to Resistive Elastic Tactile Hand, that is easily manufactured and integrated with a robotic arm. An elastic membrane is suspended between two robotic fingers, and a depth sensor capturing the deformations of the elastic membrane enables sub-millimeter accurate estimates of contact geometries. The parallel-jaw gripper varies the stiffness of the membrane by uniaxially stretching it, which controllably modulates StRETcH\u2019s effective modulus from approximately 4kPa to 9kPa. This work uses StRETcH to reconstruct the contact geometry of rigid and deformable objects, estimate the stiffness of four balloons filled with different substances, and manipulate dough into a desired shape.",
        "primary_area": "",
        "author": "Carolyn Matl;Josephine Koe;Ruzena Bajcsy;Carolyn Matl;Josephine Koe;Ruzena Bajcsy",
        "authorids": "/37087324669;/37089000786;/37298488400;/37087324669;/37089000786;/37298488400",
        "aff": "Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA; Department of Electrical Engineering and Computer Science, University of California, Berkeley, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561822/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10570288092339201329&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Berkeley",
        "aff_unique_dep": "Department of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.berkeley.edu",
        "aff_unique_abbr": "UC Berkeley",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560886",
        "title": "Stabilizing Neural Control Using Self-Learned Almost Lyapunov Critics",
        "track": "main",
        "status": "Poster",
        "abstract": "The lack of stability guarantee restricts the practical use of learning-based methods in core control problems in robotics. We develop new methods for learning neural control policies and neural Lyapunov critic functions in the modelfree reinforcement learning (RL) setting. We use sample-based approaches and the Almost Lyapunov function conditions to estimate the region of attraction and invariance properties through the learned Lyapunov critic functions. The methods enhance stability of neural controllers for various nonlinear systems including automobile and quadrotor control.",
        "primary_area": "",
        "author": "Ya-Chien Chang;Sicun Gao;Ya-Chien Chang;Sicun Gao",
        "authorids": "/37089000572;/37088349203;/37089000572;/37088349203",
        "aff": "Department of Computer Science and Engineering, UC, San Diego, USA; Department of Computer Science and Engineering, UC, San Diego, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560886/",
        "gs_citation": 67,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8411382868104618509&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, San Diego",
        "aff_unique_dep": "Department of Computer Science and Engineering",
        "aff_unique_url": "https://www.ucsd.edu",
        "aff_unique_abbr": "UCSD",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "San Diego",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561363",
        "title": "Stable, Sensor-less and Compliance-less Module Connection for Automated Construction System of a Modularized Rail Structure",
        "track": "main",
        "status": "Poster",
        "abstract": "Unmanned robots have been proposed for the decommissioning of Fukushima Dai-ichi Nuclear Power Plant. To achieve efficient movement of robots in the high-radiation environment, we propose an \u201cautomated construction system of a modularized rail structure.\u201d In the high-radiation environment, the rail structure must be constructed by a remotely controlled robot using minimal sensors. In addition, a compliant mechanism that allows small misalignments is not feasible in the module connection task due to multiple load conditions. Therefore, this study aims to achieve stable, sensor-less, and compliance-less construction using a remotely controlled robot. To achieve this goal, a geometrical model of a connection mechanism is generated and used for contact analysis of the kinematic chain transition. An analysis of the relative angle and distance between the connection surfaces of the modules effectively illustrates the conditions of connection success and failure. Based on the analysis results, the design is modified to stabilize the connection task and employed to update the constructor robot. Thus, the stability of the module connection is improved, even under various load conditions.",
        "primary_area": "",
        "author": "Mari Yasuda;Rui Fukui;Shin\u2019ichi Warisawa;Mari Yasuda;Rui Fukui;Shin\u2019ichi Warisawa",
        "authorids": "/37089001831;/37328184200;/37279811100;/37089001831;/37328184200;/37279811100",
        "aff": "Department of Human and Engineered Environmental Studies, Graduate School of Frontier Sciences, the University of Tokyo, Kashiwa city, Chiba, Japan; Department of Human and Engineered Environmental Studies, Graduate School of Frontier Sciences, the University of Tokyo, Kashiwa city, Chiba, Japan; Department of Human and Engineered Environmental Studies, Graduate School of Frontier Sciences, the University of Tokyo, Kashiwa city, Chiba, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561363/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16236816585900705372&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Tokyo",
        "aff_unique_dep": "Department of Human and Engineered Environmental Studies",
        "aff_unique_url": "https://www.u-tokyo.ac.jp",
        "aff_unique_abbr": "UTokyo",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Kashiwa",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9562004",
        "title": "Stair Climbing Capability-Based Dimensional Synthesis for the Multi-legged Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Staircase is a typical obstacle for the legged robot to overcome in buildings. This paper studies the stair climbing capability-based dimensional synthesis for a hexapod legged robot, i.e., exploring how to determine the leg length and the longitudinal body length concerning the target staircase in the mechanical design stage. In climbing a staircase, leg-staircase interference is one of the predominant issues. The three possible interference cases are illustrated in detail with a 2-DOF (degree of freedom) leg mechanism and the staircase size, based on the predefined tripod gait sequence. The mathematical relationships between the leg length, longitudinal body length, and the target staircase size are derived. The leg length and the body length are finally determined with the target staircase size. The virtual simulations and prototype experiments verify the effectiveness of the dimensional synthesis for the hexapod robot.",
        "primary_area": "",
        "author": "Huayang Li;Chenkun Qi;Xianbao Chen;Liheng Mao;Yue Zhao;Feng Gao;Huayang Li;Chenkun Qi;Xianbao Chen;Liheng Mao;Yue Zhao;Feng Gao",
        "authorids": "/37087243561;/37529382400;/37085460058;/37088999392;/37090017873;/37400836800;/37087243561;/37529382400;/37085460058;/37088999392;/37090017873;/37400836800",
        "aff": "School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China; School of Mechanical Engineering, Shanghai Jiao Tong University, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562004/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12704959696978955654&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "School of Mechanical Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561067",
        "title": "Star Topology based Interaction for Robust Trajectory Forecasting in Dynamic Scene",
        "track": "main",
        "status": "Poster",
        "abstract": "Motion prediction of multiple agents in a dynamic scene is a crucial component in many real applications, including intelligent monitoring and autonomous driving. Due to the complex interactions among the agents and their interactions with the surrounding scene, accurate trajectory prediction is still a great challenge. In this paper, we propose a new method for robust trajectory prediction of multiple intelligent agents in a dynamic scene. The input of the method includes the observed trajectories of all agents, and optionally, the planning of the ego-agent and the surrounding high definition map at every time steps. Given observed trajectories, an efficient approach in a star computational topology is utilized to compute both the spatiotemporal interaction features and the current interaction features between the agents, where the time complexity scales linearly to the number of agents. Moreover, on an autonomous vehicle, the proposed prediction method can make use of the planning of ego-agent to improve the modeling of the interaction between surrounding agents. To increase the robustness to upstream perception noises, at the training stage, we randomly mask out the input data, a.k.a. the points on the observed trajectories of agents and the lane sequence. Experiments on autonomous driving and pedestrian-walking datasets demonstrate that the proposed method is not only effective when the planning of ego-agent and the high definition map are provided, but also achieves state-of-the-art performance with only the observed trajectories.",
        "primary_area": "",
        "author": "Yanliang Zhu;Dongchun Ren;Deheng Qian;Mingyu Fan;Xin Li;Huaxia Xia;Yanliang Zhu;Dongchun Ren;Deheng Qian;Mingyu Fan;Xin Li;Huaxia Xia",
        "authorids": "/37086798364;/37086800405;/37086798523;/38541180900;/37089001631;/37088755529;/37086798364;/37086800405;/37086798523;/38541180900;/37089001631;/37088755529",
        "aff": "Center for Autonomous Vehicles, Meituan, Beijing, China; Center for Autonomous Vehicles, Meituan, Beijing, China; Center for Autonomous Vehicles, Meituan, Beijing, China; Center for Autonomous Vehicles, Meituan, Beijing, China; Center for Autonomous Vehicles, Meituan, Beijing, China; Center for Autonomous Vehicles, Meituan, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561067/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10587617447476810199&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Meituan",
        "aff_unique_dep": "Center for Autonomous Vehicles",
        "aff_unique_url": "https://www.meituan.com",
        "aff_unique_abbr": "Meituan",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560948",
        "title": "State Estimation for Hybrid Wheeled-Legged Robots Performing Mobile Manipulation Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a general state estimation framework fusing multiple sensor information for hybrid wheeled-legged robots performing mobile manipulation tasks. At the core of the state estimator is a novel unified odometry for hybrid locomotion which can seamlessly maintain tracking and has no need to switch between stepping and rolling modes. To the best of our knowledge, the proposed odometry is the first work in this area. It is calculated based on the robot kinematics and instantaneous contact points of wheels with sensor inputs from IMU, joint encoders, joint torque sensors estimating wheel contact status, as well as RGB-D camera detecting geometric features of the terrain (e.g. elevation and surface normal vector). Subsequently, the odometry output is utilized as the motion model of a 3D Lidar map-based Monte Carlo Localization module for drift-free state estimation. As part of the framework, visual localization is integrated to provide high precision guidance for the robot movement relative to an object of interest. The proposed approach was verified thoroughly by two experiments conducted on the Pholus robot with OptiTrack measurements as ground truth.",
        "primary_area": "",
        "author": "Yangwei You;Samuel Cheong;Tai Pang Chen;Yuda Chen;Kun Zhang;Cihan Acar;Fon Lin Lai;Albertus Hendrawan Adiwahono;Keng Peng Tee;Yangwei You;Samuel Cheong;Tai Pang Chen;Yuda Chen;Kun Zhang;Cihan Acar;Fon Lin Lai;Albertus Hendrawan Adiwahono;Keng Peng Tee",
        "authorids": "/37085753674;/37089001082;/37089000285;/37089001743;/37089269944;/37088854551;/37088758006;/37546317700;/37275857100;/37085753674;/37089001082;/37089000285;/37089001743;/37089269944;/37088854551;/37088758006;/37546317700;/37275857100",
        "aff": "Institute for Infocomm Research, Agency for Science, Technology and Research (A*Star), Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research (A*Star), Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research (A*Star), Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research (A*Star), Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research (A*Star), Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research (A*Star), Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research (A*Star), Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research (A*Star), Singapore; Institute for Infocomm Research, Agency for Science, Technology and Research (A*Star), Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560948/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1747460342657042687&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Agency for Science, Technology and Research",
        "aff_unique_dep": "Institute for Infocomm Research",
        "aff_unique_url": "https://www.a-star.edu.sg",
        "aff_unique_abbr": "A*Star",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9561296",
        "title": "States and Contact Forces Estimation for a Fabric-Reinforced Inflatable Soft Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots can operate effectively inside confined spaces because their soft bodies can adapt to accommodate the geometry around them. When they interact with the environment, the presence of contact forces can dramatically change the dynamics of the robots. If a soft robot is in contact and the contact force is not known, the control action is still targeted for a free robot. Hence the robot may perform improper actions. Because a soft robot is deformable, it is quite challenging to determine the contact forces and the system states from sensor measurements. This paper proposes an observer design to estimate the states of a fabric-reinforced inflatable soft robot as well as the external contact forces. The soft robot is represented by the disc-thread model which results in a set of ordinary differential equations (ODEs). A linear parameter-varying (LPV) system including some subsystems is formed to represent the nonlinear robot. The observer is based on the sliding mode approach and includes a set of sub-observers corresponding to the subsystems in the LPV system. The observer is validated through simulations and an experiment. The simulation results show that the observer can estimate the angular positions and their rate of changes as well as assumed contact forces with no error in steady states. The experiment results display good tracking of the robot\u2019s configurations compared to the ground truth data from the motion tracking system.",
        "primary_area": "",
        "author": "Phuc D.H. Bui;Joshua A. Schultz;Phuc D.H. Bui;Joshua A. Schultz",
        "authorids": "/37088472127;/37890321900;/37088472127;/37890321900",
        "aff": "Department of Mechanical Engineering, The University of Tulsa, Tulsa, OK, USA; Department of Mechanical Engineering, The University of Tulsa, Tulsa, OK, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561296/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7813755216352771996&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Tulsa",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.utulsa.edu",
        "aff_unique_abbr": "TU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tulsa",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560998",
        "title": "Steering Induced Roll Quantification During Ship Turning Circle Manoeuvre",
        "track": "main",
        "status": "Poster",
        "abstract": "A well known and well-studied feature of boats\u2019 dynamic is the effect of steering-induced roll. This property is used by a technique called Rudder Roll Stabilization (RRS) to stabilise ships in waves in order to make the navigation safer and more pleasant. This technique is based on the generation of induced roll. Because of its specific application, studies have been limited to commercial vessels using a Single Propeller-Rudder System (SPRS). This study not only broadens the technique to any propulsion and steering mechanisms that can be used with RRS by introducing the thrust asymmetry, but it also incorporates the effect of the centrifugal forces that were previously left off. To prove the capabilities of the new concept, a test is effectuated employing an RC demonstrator fitted with a Differential Jet Pump System (DJPS), performing a turning circle test manoeuvre.",
        "primary_area": "",
        "author": "Nathanael Esnault;Nitish Patel;Jon Tunnicliffe;Nathanael Esnault;Nitish Patel;Jon Tunnicliffe",
        "authorids": "/37088997995;/37289690500;/37089001272;/37088997995;/37289690500;/37089001272",
        "aff": "Faculty of Engineering, Electrical and Computer Engineering, The University of Auckland, Auckland, New Zealand; Faculty of Engineering, Electrical and Computer Engineering, The University of Auckland, Auckland, New Zealand; Faculty of Science, River Science, The University of Auckland, New Zealand",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560998/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2574672312740401679&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Auckland",
        "aff_unique_dep": "Electrical and Computer Engineering",
        "aff_unique_url": "https://www.auckland.ac.nz",
        "aff_unique_abbr": "UoA",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Auckland;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "New Zealand"
    },
    {
        "id": "9562027",
        "title": "Stereo Object Matching Network",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a stereo object matching method that exploits both 2D contextual information from images as well as 3D object-level information. Unlike existing stereo matching methods that exclusively focus on the pixel-level correspondence between stereo images within a volumetric space (i.e., cost volume), we exploit this volumetric structure in a different manner. The cost volume explicitly encompasses 3D information along its disparity axis, therefore it is a privileged structure that can encapsulate the 3D contextual information from objects. However, it is not straightforward since the disparity values map the 3D metric space in a non-linear fashion. Thus, we present two novel strategies to handle 3D objectness in the cost volume space: selective sampling (RoISelect) and 2D-3D fusion (fusion-by-occupancy), which allow us to seamlessly incorporate 3D object-level information and achieve accurate depth performance near the object boundary regions. Our depth estimation achieves competitive performance in the KITTI dataset and the Virtual-KITTI 2.0 dataset.",
        "primary_area": "",
        "author": "Jaesung Choe;Kyungdon Joo;Francois Rameau;In So Kweon;Jaesung Choe;Kyungdon Joo;Francois Rameau;In So Kweon",
        "authorids": "/37088838123;/37085436130;/37892103100;/37088996794;/37088838123;/37085436130;/37892103100;/37088996794",
        "aff": "Division of the Future Vehicle, KAIST, Daejeon, Republic of Korea; Department of Computer Science, Artificial Intelligence Graduate School, UNIST, Ulsan, Republic of Korea; School of Electrical Engineering, KAIST, Daejeon, Republic of Korea; School of Electrical Engineering, KAIST, Daejeon, Republic of Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562027/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16196452475077490419&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "KAIST;UNIST",
        "aff_unique_dep": "Division of the Future Vehicle;Department of Computer Science, Artificial Intelligence Graduate School",
        "aff_unique_url": "https://www.kaist.ac.kr;https://www.unist.ac.kr",
        "aff_unique_abbr": "KAIST;UNIST",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Daejeon;Ulsan",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561557",
        "title": "Stereo-augmented Depth Completion from a Single RGB-LiDAR image",
        "track": "main",
        "status": "Poster",
        "abstract": "Depth completion is an important task in computer vision and robotics applications, which aims at predicting accurate dense depth from a single RGB-LiDAR image. Convolutional neural networks (CNNs) have been widely used for depth completion to learn a mapping function from sparse to dense depth. However, recent methods do not exploit any 3D geometric cues during the inference stage and mainly rely on sophisticated CNN architectures. In this paper, we present a cascade and geometrically inspired learning framework for depth completion, consisting of three stages: view extrapolation, stereo matching, and depth refinement. The first stage extrapolates a virtual (right) view using a single RGB (left) and its LiDAR data. We then mimic the binocular stereo-matching, and as a result, explicitly encode geometric constraints during depth completion. This stage augments the final refinement process by providing additional geometric reasoning. We also introduce a distillation framework based on teacher-student strategy to effectively train our network. Knowledge from a teacher model privileged with real stereo pairs is transferred to the student through feature distillation. Experimental results on KITTI depth completion benchmark demonstrate that the proposed method is superior to state-of-the-art methods.",
        "primary_area": "",
        "author": "Keunhoon Choi;Somi Jeong;Youngjung Kim;Kwanghoon Sohn;Keunhoon Choi;Somi Jeong;Youngjung Kim;Kwanghoon Sohn",
        "authorids": "/37088997637;/37086340873;/37085429625;/37287181100;/37088997637;/37086340873;/37085429625;/37287181100",
        "aff": "School of Electrical and Electronic Engineering, Yonsei University, Seoul, Korea; School of Electrical and Electronic Engineering, Yonsei University, Seoul, Korea; Agency for Defense Development (ADD), Daejeon, Korea; School of Electrical and Electronic Engineering, Yonsei University, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561557/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14093346876302325300&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Yonsei University;Agency for Defense Development",
        "aff_unique_dep": "School of Electrical and Electronic Engineering;",
        "aff_unique_url": "https://www.yonsei.ac.kr;https://www.add.re.kr",
        "aff_unique_abbr": "Yonsei;ADD",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Seoul;Daejeon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561661",
        "title": "Strobe: An Acceleration Meta-algorithm for Optimizing Robot Paths using Concurrent Interleaved Sub-Epoch Pods",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present a meta-algorithm intended to accelerate many existing path optimization algorithms. The central idea of our work is to strategically break up a waypoint path into consecutive groupings called \"pods,\" then optimize over various pods concurrently using parallel processing. Each pod is assigned a color, either blue or red, and the path is divided in such a way that adjacent pods of the same color have an appropriate buffer of the opposite color between them, reducing the risk of interference between concurrent computations. We present a path splitting algorithm to create blue and red pod groupings and detail steps for a meta-algorithm that optimizes over these pods in parallel. We assessed how our method works on a testbed of simulated path optimization scenarios using various optimization tasks and characterize how it scales with additional threads. We also compared our meta-algorithm on these tasks to other parallelization schemes. Our results show that our method more effectively utilizes concurrency compared to the alternatives, both in terms of speed and optimization quality.",
        "primary_area": "",
        "author": "Daniel Rakita;Bilge Mutlu;Michael Gleicher;Daniel Rakita;Bilge Mutlu;Michael Gleicher",
        "authorids": "/37085893032;/38569363200;/37282585700;/37085893032;/38569363200;/37282585700",
        "aff": "Department of Computer Sciences, University of Wisconsin\u2013Madison, Madison, USA; Department of Computer Sciences, University of Wisconsin\u2013Madison, Madison, USA; Department of Computer Sciences, University of Wisconsin\u2013Madison, Madison, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561661/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:rpi0yS3wA8sJ:scholar.google.com/&scioq=Strobe:+An+Acceleration+Meta-algorithm+for+Optimizing+Robot+Paths+using+Concurrent+Interleaved+Sub-Epoch+Pods&hl=en&as_sdt=0,33",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Wisconsin\u2013Madison",
        "aff_unique_dep": "Department of Computer Sciences",
        "aff_unique_url": "https://www.wisc.edu",
        "aff_unique_abbr": "UW\u2013Madison",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Madison",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561283",
        "title": "Structure Reconstruction Using Ray-Point-Ray Features: Representation and Camera Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Straight line features have been increasingly utilized in visual SLAM and 3D reconstruction systems. The straight lines\u2019 parameterization, parallel constraint, and coplanar constraint are studied in many recent works. In this paper, we explore the novel intersection constraint of straight lines for structure reconstruction. First, a minimum parameterized representation of ray-point-ray (RPR) structures is proposed to represent the intersection of two straight lines in the 3D space. Second, an efficient solver is designed for the camera pose estimation, which leverages the perpendicularity and intersection of straight lines. Third, we build a stereo visual odometry based on RPR features and evaluate it on the simulation and real datasets. The experimental results verify that the intersection constraints from RPR can effectively improve the accuracy and efficiency of line-based SLAM and reconstruction system.",
        "primary_area": "",
        "author": "Yijia He;Xiangyue Liu;Xiao Liu;Ji Zhao;Yijia He;Xiangyue Liu;Xiao Liu;Ji Zhao",
        "authorids": "/37085847838;/37088999661;/37088690042;/37963498600;/37085847838;/37088999661;/37088690042;/37963498600",
        "aff": "School of Software, Beihang University, Beijing, China; School of Software, Beihang University, Beijing, China; Megvii (Face++) Technology Inc., Beijing, China; School of Software, Beihang University, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561283/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15619076511124094169&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1+2;0",
        "aff_unique_norm": "Beihang University;MEGVII;Technology Inc.",
        "aff_unique_dep": "School of Software;;",
        "aff_unique_url": "http://www.buaa.edu.cn;https://www.megvii.com;",
        "aff_unique_abbr": "BUAA;Megvii;",
        "aff_campus_unique_index": "0;0;;0",
        "aff_campus_unique": "Beijing;",
        "aff_country_unique_index": "0;0;0+0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561249",
        "title": "SuPer Deep: A Surgical Perception Framework for Robotic Tissue Manipulation using Deep Learning for Feature Extraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic automation in surgery requires precise tracking of surgical tools and mapping of deformable tissue. Previous works on surgical perception frameworks require significant effort in developing features for surgical tool and tissue tracking. In this work, we overcome the challenge by exploiting deep learning methods for surgical perception. We integrated deep neural networks, capable of efficient feature extraction, into the tissue tracking and surgical tool tracking processes. By leveraging transfer learning, the deep-learning-based approach requires minimal training data and reduced feature engineering efforts to fully perceive a surgical scene. The framework was tested on three publicly available datasets, which use the da Vinci\u00ae Surgical System, for comprehensive analysis. Experimental results show that our framework achieves state-of-the-art tracking performance in a surgical environment by utilizing deep learning for feature extraction.",
        "primary_area": "",
        "author": "Jingpei Lu;Ambareesh Jayakumari;Florian Richter;Yang Li;Michael C. Yip;Jingpei Lu;Ambareesh Jayakumari;Florian Richter;Yang Li;Michael C. Yip",
        "authorids": "/37088071646;/37088997973;/37086936752;/37405707100;/37085382768;/37088071646;/37088997973;/37086936752;/37405707100;/37085382768",
        "aff": "Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA; School of Computer Science and Technology, East China Normal University, Shanghai, China; Department of Electrical and Computer Engineering, University of California San Diego, La Jolla, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561249/",
        "gs_citation": 79,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7365692262518653809&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "University of California, San Diego;East China Normal University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;School of Computer Science and Technology",
        "aff_unique_url": "https://www.ucsd.edu;http://www.ecnu.edu.cn",
        "aff_unique_abbr": "UCSD;ECNU",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "La Jolla;Shanghai",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9561163",
        "title": "Subsequent Keyframe Generation for Visual Servoing",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we study the problem of autonomous and reliable positioning of a camera w.r.t. an object when only this latter is known but not the rest of the scene. We propose to combine the advantages and efficiency of a visual servoing scheme and the generalization ability of a generative adversarial network. The paper describes how to efficiently create a synthetic dataset in order to train a network that predicts an intermediate visual keyframe between two images. Subsequent predictions are used as visual features to autonomously converge towards the desired pose even for large displacements. We show that the proposed method can be used without any prior knowledge on the scene appearance except for the object itself, while being robust to various lighting conditions and specular surfaces. We provide experimental results, both in simulation and using a real service robot platform to validate and evaluate the effectiveness, robustness, and accuracy of our approach.",
        "primary_area": "",
        "author": "Nathan Crombez;Jocelyn Buisson;Zhi Yan;Yassine Ruichek;Nathan Crombez;Jocelyn Buisson;Zhi Yan;Yassine Ruichek",
        "authorids": "/37085633763;/37089308196;/37086432956;/37284281500;/37085633763;/37089308196;/37086432956;/37284281500",
        "aff": "CIAD Laboratory, Universit\u00e9 Bourgogne Franche-Comt\u00e9, UTBM, Belfort, France; CIAD Laboratory, Universit\u00e9 Bourgogne Franche-Comt\u00e9, UTBM, Belfort, France; CIAD Laboratory, Universit\u00e9 Bourgogne Franche-Comt\u00e9, UTBM, Belfort, France; CIAD Laboratory, Universit\u00e9 Bourgogne Franche-Comt\u00e9, UTBM, Belfort, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561163/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6914632948395924999&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Universit\u00e9 Bourgogne Franche-Comt\u00e9",
        "aff_unique_dep": "CIAD Laboratory",
        "aff_unique_url": "https://www.ubfc.fr",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Belfort",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561033",
        "title": "Surface Robots based on S-Isothermic Surfaces",
        "track": "main",
        "status": "Poster",
        "abstract": "Surface robots can have many applications due to multiple degrees of freedom. Accordingly, many open research questions arise due to the limited number of realized cases and insufficient theory foundation. For a surface robot that performs deformations with shear deformation, the inner product calculation in a local coordinate system on the robot generally depends on the shear angle. However, the shear angle cannot be accurately measured, making it difficult to control the robot with coordinate transformation. We present herein a geometric robot with coordinates that are as locally orthogonal as possible. This robot is embodied by adding thickness to a special circle group, called the S-isothermic surface. We propose the utilization of inverse kinematics in S-isothermic-surface robots and demonstrate the results of actual realization.",
        "primary_area": "",
        "author": "Noriyasu Iwamoto;Hiroaki Arai;Atsushi Nishikawa;Noriyasu Iwamoto;Hiroaki Arai;Atsushi Nishikawa",
        "authorids": "/37085560254;/37089001033;/37357105100;/37085560254;/37089001033;/37357105100",
        "aff": "Faculty of Textile Science and Technology, Shinshu University, Ueda, Nagano, Japan; Department of Biomedical Engineering, Shinshu University, Ueda, Nagano, Japan; Graduate School of Engineering Science, Osaka University, Toyonaka, Osaka, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561033/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7955077112114248907&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Shinshu University;Osaka University",
        "aff_unique_dep": "Faculty of Textile Science and Technology;Graduate School of Engineering Science",
        "aff_unique_url": "https://www.shinshu-u.ac.jp;https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "Shinshu U;Osaka U",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Ueda;Toyonaka",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561803",
        "title": "Surgical Gesture Recognition Based on Bidirectional Multi-Layer Independently RNN with Explainable Spatial Feature Extraction",
        "track": "main",
        "status": "Poster",
        "abstract": "Minimally invasive surgery mainly consists of a series of sub-tasks, which can be decomposed into basic gestures or contexts. As a prerequisite of autonomic operation, surgical gesture recognition can assist motion planning and decision-making, and build up context-aware knowledge to improve the surgical robot control quality. In this work, we aim to develop an effective surgical gesture recognition approach with an explainable feature extraction process.A Bidirectional Multi-Layer independently RNN (BMLindRNN) model is proposed in this paper, while spatial feature extraction is implemented via fine-tuning of a Deep Convolutional Neural Network (DCNN) model constructed based on the VGG architecture. To eliminate the black-box effects of DCNN, Gradient-weighted Class Activation Mapping (Grad-CAM) is employed. It can provide explainable results by showing the regions of the surgical images that have a strong relationship with the surgical gesture classification results.The proposed method was evaluated based on the suturing task with data obtained from the public available JIGSAWS database. Comparative studies were conducted to verify the proposed framework. Results indicated that the testing accuracy for the suturing task based on our proposed method is 87.13%, which outperforms most of the state-of-the-art algorithms.",
        "primary_area": "",
        "author": "Dandan Zhang;Ruoxi Wang;Benny Lo;Dandan Zhang;Ruoxi Wang;Benny Lo",
        "authorids": "/37086595836;/37088996202;/38183567000;/37086595836;/37088996202;/38183567000",
        "aff": "The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom; The Hamlyn Centre for Robotic Surgery, Imperial College London, London, United Kingdom",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561803/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5997722402263560941&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Imperial College London",
        "aff_unique_dep": "The Hamlyn Centre for Robotic Surgery",
        "aff_unique_url": "https://www.imperial.ac.uk",
        "aff_unique_abbr": "Imperial College",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561574",
        "title": "Switching Control in Two-Wheeled Self-Balancing Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "A two-wheeled self-balancing robot is a statically unstable non-linear system with strong coupling dynamics. Common practices in the development of control systems for such robots are either to linearise the region of application to be used with linear controllers or to use complex nonlinear controllers such as Fuzzy logic, Sliding Mode, and Neural Networks. Nonetheless, in this paper, we are proposing a novel to this field concept of switching control that would adjust its approach depending on the evaluation of the current states. The performance of the proposed controller was assessed against exemplary solely linear and solely non-linear controllers in simulated tests. The tested were evaluated against dynamic criteria (distance traveled, max. angular deviation, etc.), control criteria (settling time, % overshoot, etc.), and environmental criterion of energy consumption. The results showed an interesting behavior of the proposed controller, with superior performance in many cases.",
        "primary_area": "",
        "author": "Nikita Murasovs;Maria Elena Giannaccini;Sumeet S. Aphale;Nikita Murasovs;Maria Elena Giannaccini;Sumeet S. Aphale",
        "authorids": "/37089000877;/37078539400;/37297321600;/37089000877;/37078539400;/37297321600",
        "aff": "School of Engineering, University of Aberdeen, Aberdeen, UK; School of Engineering, University of Aberdeen, Aberdeen, UK; School of Engineering, University of Aberdeen, Aberdeen, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561574/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5228457440174355933&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Aberdeen",
        "aff_unique_dep": "School of Engineering",
        "aff_unique_url": "https://www.abdn.ac.uk",
        "aff_unique_abbr": "Aberdeen",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Aberdeen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561851",
        "title": "Synergetic Effect between Limbs and Spine Dynamics in Quadruped Walking Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Biological observations on tetrapods locomotion deduce that anti-phase synchronization (APS) between fore and rear parts is beneficial for achieving a high-speed walking. On the other hand, theoretical analysis and experimental studies on quadruped robots suggest that a flexible spine potentially improves the gait efficiency and adaptability via smoothing the ground collisions. However, these two mechanisms have never been placed together by a comprehensive investigation in terms of their synergetic effect. Namely, an advanced principle is still lacking in combining the APS and the spine flexibility for quadruped walking robots. To address this issue, we construct a mathematical model for a quadruped dynamic walker under different spine conditions. First, the APS effect is generated via entrainment-based control method under a rigid spine condition. Then, flexible spines realized by three kinds of springs are compared with the rigid one via theoretical analysis. The results suggest that the APS mechanism and the flexible spine can be synergized via an appropriate deformation control. The theoretical findings not only uncover locomotion control mechanisms for quadruped walking robots, but also provide additional understandings of tetrapods dynamic walking from a mechanical engineering point of view.",
        "primary_area": "",
        "author": "Longchuan Li;Shugen Ma;Isao Tokuda;Fumihiko Asano;Makoto Nokata;Yang Tian;Liang Du;Longchuan Li;Shugen Ma;Isao Tokuda;Fumihiko Asano;Makoto Nokata;Yang Tian;Liang Du",
        "authorids": "/37086240920;/37280187400;/38241778000;/37278753600;/37325259400;/37085347588;/37087006997;/37086240920;/37280187400;/38241778000;/37278753600;/37325259400;/37085347588;/37087006997",
        "aff": "Faculty of Science and Engineering, Ritsumeikan University, Shiga, Japan; Faculty of Science and Engineering, Ritsumeikan University, Shiga, Japan; Faculty of Science and Engineering, Ritsumeikan University, Shiga, Japan; School of Information Science, Japan Advanced Institute of Science and Technology, Ishikawa, Japan; Faculty of Science and Engineering, Ritsumeikan University, Shiga, Japan; Faculty of Science and Engineering, Ritsumeikan University, Shiga, Japan; Faculty of Science and Engineering, Ritsumeikan University, Shiga, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561851/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3573829827453495863&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;0;0;0",
        "aff_unique_norm": "Ritsumeikan University;Japan Advanced Institute of Science and Technology",
        "aff_unique_dep": "Faculty of Science and Engineering;School of Information Science",
        "aff_unique_url": "https://www.ritsumei.ac.jp;https://www.jaist.ac.jp",
        "aff_unique_abbr": "Ritsumeikan;JAIST",
        "aff_campus_unique_index": "0;0;0;1;0;0;0",
        "aff_campus_unique": "Shiga;Ishikawa",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9562041",
        "title": "TORNADO-Net: mulTiview tOtal vaRiatioN semAntic segmentation with Diamond inceptiOn module",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic segmentation of point clouds is a key component of scene understanding for robotics and autonomous driving. In this paper, we introduce TORNADO-Net - a neural network for 3D LiDAR point cloud semantic segmentation. We incorporate a multi-view (bird-eye and range) projection feature extraction with an encoder-decoder ResNet architecture with a novel diamond context block. Current projection-based methods do not take into account that neighboring points usually belong to the same class. To better utilize this local neighbourhood information and reduce noisy predictions, we introduce a combination of Total Variation, Lov\u00e1sz-Softmax, and Weighted Cross-Entropy losses. We also take advantage of the fact that the LiDAR data encompasses 360\u25e6 field of view and use circular padding. We demonstrate state-of-the-art results on the SemanticKITTI dataset and also provide thorough quantitative evaluations and ablation results.",
        "primary_area": "",
        "author": "Martin Gerdzhev;Ryan Razani;Ehsan Taghavi;Liu Bingbing;Martin Gerdzhev;Ryan Razani;Ehsan Taghavi;Liu Bingbing",
        "authorids": "/37089001111;/37086404456;/37077023400;/38257785200;/37089001111;/37086404456;/37077023400;/38257785200",
        "aff": "Huawei Noah\u2019s Ark Lab, Canada; Huawei Noah\u2019s Ark Lab, Canada; Huawei Noah\u2019s Ark Lab, Canada; Huawei Noah\u2019s Ark Lab, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562041/",
        "gs_citation": 101,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3645913147436135974&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Huawei Noah\u2019s Ark Lab",
        "aff_unique_url": "https://www.huawei.com/en/ai/noahs-ark-lab",
        "aff_unique_abbr": "HNAL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561081",
        "title": "TRANS-AM: Transfer Learning by Aggregating Dynamics Models for Soft Robotic Assembly",
        "track": "main",
        "status": "Poster",
        "abstract": "Practical industrial assembly scenarios often require robotic agents to adapt their skills to unseen tasks quickly. While transfer reinforcement learning (RL) could enable such quick adaptation, much prior work has to collect many samples from source environments to learn target tasks in a model-free fashion, which still lacks sample efficiency on a practical level. In this work, we develop a novel transfer RL method named TRANSfer learning by Aggregating dynamics Models (TRANS-AM). TRANS-AM is based on model-based RL (MBRL) for its high-level sample efficiency, and only requires dynamics models to be collected from source environments. Specifically, it learns to aggregate source dynamics models adaptively in an MBRL loop to better fit the state-transition dynamics of target environments and execute optimal actions there. As a case study to show the effectiveness of this proposed approach, we address a challenging contact-rich peg-in-hole task with variable hole orientations using a soft robot. Our evaluations with both simulation and real-robot experiments demonstrate that TRANS-AM enables the soft robot to accomplish target tasks with fewer episodes compared when learning the tasks from scratch.",
        "primary_area": "",
        "author": "Kazutoshi Tanaka;Ryo Yonetani;Masashi Hamaya;Robert Lee;Felix von Drigalski;Yoshihisa Ijiri;Kazutoshi Tanaka;Ryo Yonetani;Masashi Hamaya;Robert Lee;Felix von Drigalski;Yoshihisa Ijiri",
        "authorids": "/37088507484;/37085641524;/37085532024;/37088507437;/37088526282;/37085621887;/37088507484;/37085641524;/37085532024;/37088507437;/37088526282;/37085621887",
        "aff": "OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan; OMRON SINIC X Corporation, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561081/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12829534445523386118&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "OMRON SINIC X Corporation",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9560923",
        "title": "TSDF++: A Multi-Object Formulation for Dynamic Object Tracking and Reconstruction",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to simultaneously track and reconstruct multiple objects moving in the scene is of the utmost importance for robotic tasks such as autonomous navigation and interaction. Virtually all of the previous attempts to map multiple dynamic objects have evolved to store individual objects in separate reconstruction volumes and track the relative pose between them. While simple and intuitive, such formulation does not scale well with respect to the number of objects in the scene and introduces the need for an explicit occlusion handling strategy. In contrast, we propose a map representation that allows maintaining a single volume for the entire scene and all the objects therein. To this end, we introduce a novel multi-object TSDF formulation that can encode multiple object surfaces at any given location in the map. In a multiple dynamic object tracking and reconstruction scenario, our representation allows maintaining accurate reconstruction of surfaces even while they become temporarily occluded by other objects moving in their proximity. We evaluate the proposed TSDF++ formulation on a public synthetic dataset and demonstrate its ability to preserve reconstructions of occluded surfaces when compared to the standard TSDF map representation. Code is available at https://github.com/ethz-asl/tsdf-plusplus.",
        "primary_area": "",
        "author": "Margarita Grinvald;Federico Tombari;Roland Siegwart;Juan Nieto;Margarita Grinvald;Federico Tombari;Roland Siegwart;Juan Nieto",
        "authorids": "/37086574261;/37593332100;/37281398300;/37085778635;/37086574261;/37593332100;/37281398300;/37085778635",
        "aff": "Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Google, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland; Autonomous Systems Lab, ETH Zurich, Zurich, Switzerland",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560923/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16512671114880131262&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "ETH Zurich;Google",
        "aff_unique_dep": "Autonomous Systems Lab;Google",
        "aff_unique_url": "https://www.ethz.ch;https://www.google.ch",
        "aff_unique_abbr": "ETHZ;Google",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Zurich;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561164",
        "title": "TT-SLAM: Dense Monocular SLAM for Planar Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper proposes a novel visual SLAM method with dense planar reconstruction using a monocular camera: TT-SLAM. The method exploits planar template-based trackers (TT) to compute camera poses and reconstructs a multi-planar scene representation. Multiple homographies are estimated simultaneously by clustering a set of template trackers supported by superpixelized regions. Compared to RANSAC-based multiple homographies method [1], data association and keyframe selection issues are handled by the continuous nature of template trackers. A non-linear optimization process is applied to all the homographies to improve the precision in pose estimation. Experiments show that the proposed method outperforms RANSAC-based multiple homographies method [1] as well as other dense method SLAM techniques such as LSD-SLAM or DPPTAM, and competes with keypoint-based techniques like ORB-SLAM while providing dense planar reconstructions of the environment.",
        "primary_area": "",
        "author": "Xi Wang;Marc Christie;Eric Marchand;Xi Wang;Marc Christie;Eric Marchand",
        "authorids": "/37086529410;/38241597200;/37269970500;/37086529410;/38241597200;/37269970500",
        "aff": "Univ Rennes, Inria, CNRS, Irisa, France; Univ Rennes, Inria, CNRS, Irisa, France; Univ Rennes, Inria, CNRS, Irisa, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561164/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1465728484918316725&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 10,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Rennes",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.univ-rennes1.fr",
        "aff_unique_abbr": "Univ Rennes",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9562060",
        "title": "Tactile SLAM: Real-time inference of shape and pose from planar pushing",
        "track": "main",
        "status": "Poster",
        "abstract": "Tactile perception is central to robot manipulation in unstructured environments. However, it requires contact, and a mature implementation must infer object models while also accounting for the motion induced by the interaction. In this work, we present a method to estimate both object shape and pose in real-time from a stream of tactile measurements. This is applied towards tactile exploration of an unknown object by planar pushing. We consider this as an online SLAM problem with a nonparametric shape representation. Our formulation of tactile inference alternates between Gaussian process implicit surface regression and pose estimation on a factor graph. Through a combination of local Gaussian processes and fixed-lag smoothing, we infer object shape and pose in real-time. We evaluate our system across different objects in both simulated and real-world planar pushing tasks.",
        "primary_area": "",
        "author": "Sudharshan Suresh;Maria Bauza;Kuan-Ting Yu;Joshua G. Mangelson;Alberto Rodriguez;Michael Kaess;Sudharshan Suresh;Maria Bauza;Kuan-Ting Yu;Joshua G. Mangelson;Alberto Rodriguez;Michael Kaess",
        "authorids": "/37086609669;/37086003399;/37086198405;/37086109836;/38194796600;/37324200400;/37086609669;/37086003399;/37086198405;/37086109836;/38194796600;/37324200400",
        "aff": "Robotics Institute, Carnegie Mellon University; Mechanical Engineering Department, Massachusetts Institute of Technology; XYZ Robotics; Electrical and Computer Engineering Department, Brigham Young University; Mechanical Engineering Department, Massachusetts Institute of Technology; Robotics Institute, Carnegie Mellon University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562060/",
        "gs_citation": 62,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11151631233838870355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;1;0",
        "aff_unique_norm": "Carnegie Mellon University;Massachusetts Institute of Technology;XYZ Robotics;Brigham Young University",
        "aff_unique_dep": "Robotics Institute;Mechanical Engineering Department;;Electrical and Computer Engineering Department",
        "aff_unique_url": "https://www.cmu.edu;https://web.mit.edu;;https://www.byu.edu",
        "aff_unique_abbr": "CMU;MIT;;BYU",
        "aff_campus_unique_index": "0;1;1;0",
        "aff_campus_unique": "Pittsburgh;Cambridge;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States;"
    },
    {
        "id": "9561646",
        "title": "Tactile-RL for Insertion: Generalization to Objects of Unknown Geometry",
        "track": "main",
        "status": "Poster",
        "abstract": "Object insertion is a classic contact-rich manipulation task. The task remains challenging, especially when considering general objects of unknown geometry, which significantly limits the ability to understand the contact configuration between the object and the environment. We study the problem of aligning the object and environment with a tactile-based feedback insertion policy. The insertion process is modeled as an episodic policy that iterates between insertion attempts followed by pose corrections. We explore different mechanisms to learn such a policy based on Reinforcement Learning. The key contribution of this paper is to demonstrate that it is possible to learn a tactile insertion policy that generalizes across different object geometries, and an ablation study of the key design choices for the learning agent: 1) the type of learning scheme: supervised vs. reinforcement learning; 2) the type of learning schedule: unguided vs. curriculum learning ; 3) the type of sensing modality: force/torque vs. tactile; and 4) the type of tactile representation: tactile RGB vs. tactile flow. We show that the optimal configuration of the learning agent (RL + curriculum + tactile flow) exposed to 4 training objects yields an closed-loop insertion policy that inserts 4 novel objects with over 85.0% success rate and within 3~4 consecutive attempts. Comparisons between F/T and tactile sensing, shows that while an F/T-based policy learns more efficiently, a tactile-based policy provides better generalization. See supplementary video and results at https://sites.google.com/view/tactileinsertion.",
        "primary_area": "",
        "author": "Siyuan Dong;Devesh K. Jha;Diego Romeres;Sangwoon Kim;Daniel Nikovski;Alberto Rodriguez;Siyuan Dong;Devesh K. Jha;Diego Romeres;Sangwoon Kim;Daniel Nikovski;Alberto Rodriguez",
        "authorids": "/37086249096;/37072717800;/37086098761;/37088997798;/37284684700;/38194796600;/37086249096;/37072717800;/37086098761;/37088997798;/37284684700;/38194796600",
        "aff": "Massachusetts Institute of Technology; Mitsubishi Electric Research Laboratories; Mitsubishi Electric Research Laboratories; Massachusetts Institute of Technology; Mitsubishi Electric Research Laboratories; Massachusetts Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561646/",
        "gs_citation": 144,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13527931086517521635&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;1;0;1;0",
        "aff_unique_norm": "Massachusetts Institute of Technology;Mitsubishi Electric Research Laboratories",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://web.mit.edu;https://www.merl.com",
        "aff_unique_abbr": "MIT;MERL",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561357",
        "title": "Tailored Magnetic Torsion Springs for Miniature Magnetic Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Magnetic torsion springs are capable of producing unique and useful torque-displacement responses that are not possible with elastic springs. Millimeter-scale magnetically-actuated robots, which are gaining increasing interest in biomedical applications, would benefit from the use of magnetic torsion springs. However, existing magnetic torsion springs are difficult to fabricate at that scale and can only produce sinusoid-like responses. Here we show that the magnets embedded in the links of a robot for actuation purposes can also be leveraged to produce torsion spring-like behavior. This Simultaneous Magnetic Actuation and Restoring Torque (SMART) spring design can enable switching or pop-up behaviour in millimeter-scale magnetically-actuated mechanisms. A novel analytical model, validated both numerically and experimentally, is used to design constant-stiffness and nonlinear bistable SMART springs. These springs are integrated into a novel 3.5 mm diameter magnetic robot manipulator.",
        "primary_area": "",
        "author": "Cameron Forbrigger;Adam Schonewille;Eric Diller;Cameron Forbrigger;Adam Schonewille;Eric Diller",
        "authorids": "/37086690194;/37088704984;/37542880000;/37086690194;/37088704984;/37542880000",
        "aff": "Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON; Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON; Department of Mechanical and Industrial Engineering, University of Toronto, Toronto, ON",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561357/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7696262610549596534&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Toronto",
        "aff_unique_dep": "Department of Mechanical and Industrial Engineering",
        "aff_unique_url": "https://www.utoronto.ca",
        "aff_unique_abbr": "U of T",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Toronto",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9560785",
        "title": "Target-targeted Domain Adaptation for Unsupervised Semantic Segmentation",
        "track": "main",
        "status": "Poster",
        "abstract": "Semantic segmentation has attracted increasing attention due to its important role in self-driving, and it is often realized by supervised learning with large number of well labeled maps. However, the labeled images are hard to be obtained in most circumstances, and the common way for unsupervised semantic segmentation is usually implemented by transferring the knowledge from source supervised domain to target unsupervised domain. Most researches focus on encouraging target predictions to be closer to the source ones through a weight-sharing network, and achieve certain performance. However, these methods often suffer from the domain shift problem that the networks are often trained towards the source domain and lead to performance degradation. In this paper, we propose a target-targeted domain adaptation approach by focusing the training on target domain. Our model consists of two components: the Image-to-image Translation (IIT) module to translate the source image to target domain and the Target-targeted Segmentation Adaptation (TSA) module to focus the semantic segmentation on target domain. The IIT module deals with image space alignment while the TSA module bridges the domain gap at the segmentation map level. In addition, we design a closed-loop learning to promote each other by employing feedback from TSA to IIT. Extensive experiments on GTA5 and SYNTHIA to Cityscapes demonstrate the effectiveness of our method in domain adaptation of unsupervised semantic segmentation.",
        "primary_area": "",
        "author": "Xiaohong Zhang;Haofeng Zhang;Jianfeng Lu;Ling Shao;Jingyu Yang;Xiaohong Zhang;Haofeng Zhang;Jianfeng Lu;Ling Shao;Jingyu Yang",
        "authorids": "/37088803262;/37085367323;/37085338575;/38265369400;/37280205200;/37088803262;/37085367323;/37085338575;/38265369400;/37280205200",
        "aff": "School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; Inception Institute of Artificial Intelligence (IIAI), Abu Dhabi, United Arab Emirates; School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560785/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3958038297316510763&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;0",
        "aff_unique_norm": "Nanjing University of Science and Technology;Inception Institute of Artificial Intelligence",
        "aff_unique_dep": "School of Computer Science and Engineering;",
        "aff_unique_url": "http://www.nust.edu.cn;",
        "aff_unique_abbr": "NUST;IIAI",
        "aff_campus_unique_index": "0;0;0;1;0",
        "aff_campus_unique": "Nanjing;Abu Dhabi",
        "aff_country_unique_index": "0;0;0;1;0",
        "aff_country_unique": "China;United Arab Emirates"
    },
    {
        "id": "9560936",
        "title": "Targetless Multiple Camera-LiDAR Extrinsic Calibration using Object Pose Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a targetless method for calibrating the extrinsic parameters among multiple cameras and a LiDAR sensor using object pose estimation. Contrast to previous targetless methods requiring certain geometric features, the proposed method exploits any objects of unspecified shapes in the scene to estimate the calibration parameters in single-scan configuration. Semantic objects in the scene are initially segmented from each modal measurement. Using multiple images, a 3D point cloud is reconstructed up-to-scale. By registering the up-to-scale point cloud to the LiDAR point cloud, we achieve an initial calibration and find correspondences between point cloud segments and image object segments. For each point cloud segment, a 3D mesh model is reconstructed. Based on the correspondence information, the color appearance model for the mesh can be elaborately generated with corresponding object instance segment within the images. Starting from the initial calibration, the calibration is gradually refined by using an object pose estimation technique with the appearance models associated with the 3D mesh models. The experimental results confirmed that the proposed framework achieves multimodal calibrations successfully in a single shot. The proposed method can be effectively applied for extrinsic calibration for plenoptic imaging systems of dozens of cameras in single-scan configuration without specific targets.",
        "primary_area": "",
        "author": "Byung-Hyun Yoon;Hyeon-Woo Jeong;Kang-Sun Choi;Byung-Hyun Yoon;Hyeon-Woo Jeong;Kang-Sun Choi",
        "authorids": "/37088575526;/37088576717;/38238342800;/37088575526;/37088576717;/38238342800",
        "aff": "Future Convergence Engineering, I.P.C.E., Korea University of Technology and Education, South Korea; Future Convergence Engineering, I.P.C.E., Korea University of Technology and Education, South Korea; Future Convergence Engineering, I.P.C.E., Korea University of Technology and Education, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560936/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5167377319266228736&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Korea University of Technology and Education",
        "aff_unique_dep": "Future Convergence Engineering, I.P.C.E.",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9560877",
        "title": "Task Autocorrection for Immersive Teleoperation",
        "track": "main",
        "status": "Poster",
        "abstract": "Teleoperating robotic arms is a challenging task that requires years of training to master. It is mentally demanding, as the operator must internally compute transformations, or rely on muscle memory, to perform even the simplest tasks. Alternative methods that rely on embodiment \u2013the immersive, first person experience of controlling the robot from its point of view are recently becoming more popular, thanks to the emergence of mixed reality devices. These methods create an intuitive experience by tracking the users motions, and retargetting them to the robot. However, even recent hardware fails at achieving total immersion, due to inherent discrepancies such as latency, imperfect tracking, and the differences between human and robot motor systems. Thus, performing even simple pick-and-place tasks with these systems, while more intuitive, is still cumbersome, and far from the level of human performance.In this paper we propose an immersive system that aims to bridge this gap. The system tracks the user\u2019s motion and retargets them to the robot as usual, but it also detects the user\u2019s intent, that is, the task they wish to perform. Based on this knowledge, the system can autocorrect the motion when it is about to fail, in a seamless manner, such that the task is successfully performed. We evaluate the efficacy of our autocorrection system in a user study. The results show a statistically significant performance improvement in terms of operation accuracy and time.",
        "primary_area": "",
        "author": "Chenyang Wang;Simon Huber;Stelian Coros;Roi Poranne;Chenyang Wang;Simon Huber;Stelian Coros;Roi Poranne",
        "authorids": "/37088997364;/37086961842;/37077396200;/37085580542;/37088997364;/37086961842;/37077396200;/37085580542",
        "aff": "Dept. of Information Technology and Electrical Engineering, ETH, Zurich, Switzerland; Department of Computer Science, ETH, Zurich, Switzerland; Department of Computer Science, ETH, Zurich, Switzerland; Department of Computer Science, University of Haifa, Haifa, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560877/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13168717857881774637&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "ETH Zurich;University of Haifa",
        "aff_unique_dep": "Dept. of Information Technology and Electrical Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.ethz.ch;https://www.haifa.ac.il",
        "aff_unique_abbr": "ETH;UoH",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Zurich;Haifa",
        "aff_country_unique_index": "0;0;0;1",
        "aff_country_unique": "Switzerland;Israel"
    },
    {
        "id": "9561680",
        "title": "Task Planning with a Weighted Functional Object-Oriented Network",
        "track": "main",
        "status": "Poster",
        "abstract": "In reality, there is still much to be done for robots to be able to perform manipulation actions with full autonomy. Complicated manipulation tasks, such as cooking, may still require a person to perform some actions that are very risky for a robot to perform. On the other hand, some other actions may be very risky for a human with physical disabilities to perform. Therefore, it is necessary to balance the workload of a robot and a human based on their limitations while minimizing the effort needed from a human in a collaborative robot (cobot) set-up. This paper proposes a new version of our functional object-oriented network (FOON) that integrates weights in its functional units to reflect a robot\u2019s chance of successfully executing an action of that functional unit. The paper also presents a task planning algorithm for the weighted FOON to allocate manipulation action load to the robot and human to achieve optimal performance while minimizing human effort. Through a number of experiments, this paper shows several successful cases in which using the proposed weighted FOON and the task planning algorithm allow a robot and a human to successfully complete complicated tasks together with higher success rates than a robot doing them alone.",
        "primary_area": "",
        "author": "David Paulius;Kelvin Sheng Pei Dong;Yu Sun;David Paulius;Kelvin Sheng Pei Dong;Yu Sun",
        "authorids": "/37086208693;/37089001046;/37291603500;/37086208693;/37089001046;/37291603500",
        "aff": "Technical University of Munich and University of Illinois, Urbana Champaign; Technical University of Munich and University of Illinois, Urbana Champaign; Leads the Robot Perception and Action Lab (RPAL), Which is a Part of the Department of Computer Science & Engineering, University of South Florida, Tampa, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561680/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9843501755842424375&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Technical University of Munich;University of South Florida",
        "aff_unique_dep": ";Department of Computer Science & Engineering",
        "aff_unique_url": "https://www.tum.de;https://www.usf.edu",
        "aff_unique_abbr": "TUM;USF",
        "aff_campus_unique_index": "0;0;1",
        "aff_campus_unique": "Munich;Tampa",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "Germany;United States"
    },
    {
        "id": "9561076",
        "title": "Task-Driven Deep Image Enhancement Network for Autonomous Driving in Bad Weather",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual perception in autonomous driving is a crucial part of a vehicle to navigate safely and sustainably in different traffic conditions. However, in bad weather such as heavy rain and haze, the performance of visual perception is greatly affected by several degrading effects. Recently, deep learning-based perception methods have addressed multiple degrading effects to reflect real-world bad weather cases but have shown limited success due to 1) high computational costs for deployment on mobile devices and 2) poor relevance between image enhancement and visual perception in terms of the model ability. To solve these issues, we propose a task-driven image enhancement network connected to the high-level vision task, which takes in an image corrupted by bad weather as input. Specifically, we introduce a novel low memory network to reduce most of the layer connections of dense blocks for less memory and computational cost while maintaining high performance. We also introduce a new task-driven training strategy to robustly guide the high-level task model suitable for both high-quality restoration of images and highly accurate perception. Experiment results demonstrate that the proposed method improves the performance among lane and 2D object detection, and depth estimation largely under adverse weather in terms of both low memory and accuracy.",
        "primary_area": "",
        "author": "Younkwan Lee;Jihyo Jeon;Yeongmin Ko;Byunggwan Jeon;Moongu Jeon;Younkwan Lee;Jihyo Jeon;Yeongmin Ko;Byunggwan Jeon;Moongu Jeon",
        "authorids": "/37086534149;/37088649343;/37086488058;/37088999811;/37666359200;/37086534149;/37088649343;/37086488058;/37088999811;/37666359200",
        "aff": "Machine Learning & Vision Laboratory, Gwangju Institute of Science and Technology (GIST), Gwangju, South Korea; Korea Culture Technology Institute (KCTI), Gwangju, South Korea; Machine Learning & Vision Laboratory, Gwangju Institute of Science and Technology (GIST), Gwangju, South Korea; Machine Learning & Vision Laboratory, Gwangju Institute of Science and Technology (GIST), Gwangju, South Korea; Korea Culture Technology Institute (KCTI), Gwangju, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561076/",
        "gs_citation": 35,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=594860212757562135&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;1",
        "aff_unique_norm": "Gwangju Institute of Science and Technology;Korea Culture Technology Institute",
        "aff_unique_dep": "Machine Learning & Vision Laboratory;",
        "aff_unique_url": "https://www.gist.ac.kr;",
        "aff_unique_abbr": "GIST;KCTI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Gwangju",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561260",
        "title": "Task-Invariant Learning of Continuous Joint Kinematics during Steady-State and Transient Ambulation Using Ultrasound Sensing",
        "track": "main",
        "status": "Poster",
        "abstract": "Natural control of limb motion is continuous and progressively adaptive to individual intent. While intuitive interfaces have the potential to rely on the neuromuscular input by the user for continuous adaptation, continuous volitional control of assistive devices that can generalize across various tasks has not been addressed. In this study, we propose a method to use spatiotemporal ultrasound features of the rectus femoris and vastus intermedius muscles of able-bodied individuals for task-invariant learning of continuous knee kinematics during steady-state and transient ambulation. The task-invariant learning paradigm was statistically evaluated against a task-specific paradigm for the steady-state (1) level-walk, (2) incline, (3) decline, (4) stair ascent, and (5) stair descent ambulation tasks. The transitions between steady-state stair ambulation and level-ground walking were also investigated. It was observed that the continuous knee kinematics can be learned using a task-invariant learning paradigm with statistically comparable accuracy to a task-specific paradigm. Statistical analysis further revealed that incorporating the temporal ultrasound features significantly improves the accuracy of continuous estimations (p < 0.05). The average root mean square errors (RMSEs) of knee angle and angular velocity estimation were 7.06\u00b0 and 53.1\u00b0/sec, respectively, for the task-invariant learning compared to 6.00\u00b0 and 51.8\u00b0/sec for the task-specific models. High accuracy of continuous task-invariant paradigms overcome the barrier of task-specific control schemes and motivate the implementation of direct volitional control of lower-limb assistive devices using ultrasound sensing, which may eventually enhance the intuitiveness and functionality of these devices towards a \"free form\" control approach.",
        "primary_area": "",
        "author": "M. Hassan Jahanandish;Kaitlin G. Rabe;Abhishek Srinivas;Nicholas P. Fey;Kenneth Hoyt;M. Hassan Jahanandish;Kaitlin G. Rabe;Abhishek Srinivas;Nicholas P. Fey;Kenneth Hoyt",
        "authorids": "/37086919835;/37086922993;/37088998761;/37085470083;/37300295400;/37086919835;/37086922993;/37088998761;/37085470083;/37300295400",
        "aff": "The Bioengineering and Mechanical Engineering Departments, University of Texas at Dallas, Richardson, TX, USA; Department of Biomedical Engineering, University of Texas at Austin, Austin, TX, USA; The Bioengineering and Mechanical Engineering Departments, University of Texas at Dallas, Richardson, TX, USA; Department of Mechanical Engineering, University of Texas at Austin, Austin, TX, USA; Department of Bioengineering, University of Texas at Dallas, Richardson, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561260/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17706354580516481073&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;1;0",
        "aff_unique_norm": "University of Texas at Dallas;University of Texas at Austin",
        "aff_unique_dep": "Bioengineering and Mechanical Engineering Departments;Department of Biomedical Engineering",
        "aff_unique_url": "https://www.utdallas.edu;https://www.utexas.edu",
        "aff_unique_abbr": "UT Dallas;UT Austin",
        "aff_campus_unique_index": "0;1;0;1;0",
        "aff_campus_unique": "Richardson;Austin",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560902",
        "title": "Task-Space Decomposed Motion Planning Framework for Multi-Robot Loco-Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a novel task-space decomposed motion planning framework for multi-robot simultaneous locomotion and manipulation. When several manipulators hold an object, closed-chain kinematic constraints are formed, and it will make the motion planning problems challenging by inducing lower-dimensional singularities. Unfortunately, the constrained manifold will be even more complicated when the manipulators are equipped with mobile bases. We address the problem by introducing a dual-resolution motion planning framework which utilizes a convex task region decomposition method, with each resolution tuned to efficient computation for their respective roles. Concretely, this dual-resolution approach enables a global planner to explore the low-dimensional decomposed task-space regions toward the goal, then a local planner computes a path in high-dimensional constrained configuration space. We demonstrate the proposed method in several simulations, where the robot team transports the object toward the goal in the obstacle-rich environments.",
        "primary_area": "",
        "author": "Xiaoyu Zhang;Lei Yan;Tin Lun Lam;Sethu Vijayakumar;Xiaoyu Zhang;Lei Yan;Tin Lun Lam;Sethu Vijayakumar",
        "authorids": "/37088635147;/37085460620;/37571111600;/37295595500;/37088635147;/37085460620;/37571111600;/37295595500",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), Shenzhen, China; School of Informatics, University of Edinburgh, Edinburgh, U.K.; Chinese University of Hong Kong, Shenzhen, China; AIRS",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560902/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11639045948120611071&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Shenzhen Institute of Artificial Intelligence and Robotics for Society;University of Edinburgh;Chinese University of Hong Kong;Atmospheric InfraRed Sounder",
        "aff_unique_dep": "Artificial Intelligence and Robotics for Society;School of Informatics;;",
        "aff_unique_url": ";https://www.ed.ac.uk;https://www.cuhk.edu.cn;https://airs.jpl.nasa.gov",
        "aff_unique_abbr": "AIRS;Edinburgh;CUHK;AIRS",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Shenzhen;Edinburgh;",
        "aff_country_unique_index": "0;1;0;2",
        "aff_country_unique": "China;United Kingdom;United States"
    },
    {
        "id": "9561629",
        "title": "TaskNet: A Neural Task Planner for Autonomous Excavator",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel task planner - TaskNet for an autonomous excavator based on a data-driven method, which plans feasible task-level sequence by learning from demonstration data. Given a high-level excavation objective, our TaskNet planner can decompose it into sub-tasks, each of which can be further decomposed into task primitives with specifications. We train our TaskNet using an excavation trace generator and evaluate its performance using a 3D physically-based terrain and excavator simulator. As compared to imitation learning-based methods, the experimental results show that TaskNet can effectively learn task decomposition strategies. The resulting sequences of task primitives can be used as inputs by any excavator motion planner for generating feasible joint-level trajectories. We further validate TaskNet on a state-of-the-art autonomous excavator hardware and software system. The 49-ton autonomous excavator can successfully perform material loading tasks.",
        "primary_area": "",
        "author": "Jinxin Zhao;Liangjun Zhang;Jinxin Zhao;Liangjun Zhang",
        "authorids": "/37088764030;/37088642847;/37088764030;/37088642847",
        "aff": "Baidu Research Institute, Sunnyvale, CA, USA; Baidu Research Institute, Sunnyvale, CA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561629/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2073029945905042596&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Baidu",
        "aff_unique_dep": "Baidu Research Institute",
        "aff_unique_url": "https://research.baidu.com",
        "aff_unique_abbr": "Baidu RI",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Sunnyvale",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561114",
        "title": "Teaching Robotic and Biomechatronic Concepts with a Gripper Design Project and a Grasping and Manipulation Competition",
        "track": "main",
        "status": "Poster",
        "abstract": "Lecturers of Engineering courses around the world are struggling to increase the engagement of students through the introduction of appropriate hands-on activities and assignments. In Biomechatronics and Robotics courses these assignments typically focus on how certain devices are designed, modelled, fabricated, or controlled. The hardware for these assignments is usually purchased by some external vendor and the students only get the chance to analyze it or program it, so as to execute a useful task (e.g., programming mobile robots to perform path following tasks). Student engagement can be increased by instructing the students to prepare the hardware for their assignment. This also increases the sense of ownership of the project outcomes. In this paper, we present how a robotic gripper / hand design project and the introduction of a grasping and manipulation competition as a course assignment, can significantly increase the student engagement and their understanding of the taught concepts. The presented best practices have been trialed over the last four years in two different courses (one undergraduate and one postgraduate) of the Department of Mechanical Engineering at the University of Auckland in New Zealand. For the particular assignment the students were asked to fully develop a robotic gripper or hand from scratch using a single actuator (only the actuator and the power electronics were provided). The performance of the developed devices was assessed through the participation in a grasping and manipulation competition. All the details of the proposed assignment are presented, hoping that they could help other lecturers and teachers to prepare similar activities.",
        "primary_area": "",
        "author": "Minas Liarokapis;George P. Kontoudis;Minas Liarokapis;George P. Kontoudis",
        "authorids": "/38558084100;/37085624593;/38558084100;/37085624593",
        "aff": "Department of Mechanical Engineering, New Dexterity Research Group, Faculty of Engineering, The University of Auckland, New Zealand; Bradley Department of Electrical and Computer Engineering, Virginia Tech, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561114/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1689292516901490704&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Auckland;Virginia Tech",
        "aff_unique_dep": "Department of Mechanical Engineering;Bradley Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.auckland.ac.nz;https://www.vt.edu",
        "aff_unique_abbr": "UoA;VT",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Auckland;",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "New Zealand;United States"
    },
    {
        "id": "9561082",
        "title": "Team Assignment for Heterogeneous Multi-Robot Sensor Coverage through Graph Representation Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Sensor coverage is the critical multi-robot problem of maximizing the detection of events in an environment through the deployment of multiple robots. Large multi-robot systems are often composed of simple robots that are typically not equipped with a complete set of sensors, so teams with comprehensive sensing abilities are required to properly cover an area. Robots also exhibit multiple forms of relationships (e.g., communication connections or spatial distribution) that need to be considered when assigning robot teams for sensor coverage. To address this problem, in this paper we introduce a novel formulation of sensor coverage by multi-robot systems with heterogeneous relationships as a graph representation learning problem. We propose a principled approach based on the mathematical framework of regularized optimization to learn a unified representation of the multi-robot system from the graphs describing the heterogeneous relationships and to identify the learned representation\u2019s underlying structure in order to assign the robots to teams. To evaluate the proposed approach, we conduct extensive experiments on simulated multi-robot systems and a physical multi-robot system as a case study, demonstrating that our approach is able to effectively assign teams for heterogeneous multi-robot sensor coverage.",
        "primary_area": "",
        "author": "Brian Reily;Hao Zhang;Brian Reily;Hao Zhang",
        "authorids": "/37088504746;/37085545929;/37088504746;/37085545929",
        "aff": "Department of Computer Science, Human-Centered Robotics Lab, Colorado School of Mines, Golden, CO; Department of Computer Science, Human-Centered Robotics Lab, Colorado School of Mines, Golden, CO",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561082/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6912345381176054355&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Colorado School of Mines",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.mines.edu",
        "aff_unique_abbr": "CSM",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Golden",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561498",
        "title": "Temperature Compensated 3D Printed Strain Sensor for Advanced Manufacturing Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Additive Manufacturing, has evolved beyond prototyping to manufacturing end-products. The authors are involved in developing a large-scale extrusion-based 3D printer to print mining equipment - a Gravity Separation Spiral, and embedding sensors to monitor the operational conditions re-motely. This paper presents a temperature-compensated strain sensor that can be 3D printed inline within large-scale 3D printed equipment. The sensor is printed using conductive carbon filament and embedded in a Polylactic acid (PLA) base. A half-bridge setup is proposed to reduce the impact of temperature variations. Temperature-controlled tests have been conducted with the proposed half-bridge and compared with a non-temperature compensated quarter-bridge setup. Results show that the half-bridge configuration reduces the temperature impact on the strain measurement significantly (68%) compared to the quarter-bridge, in the range of 25-40 \u00b0C. Deflection testing conducted on the printed sensor shows a near-linear relationship between bending strain and voltage. Multiple bending cycles have shown that there is no significant hysteresis. ANSYS simulations are used to accurately estimate the internal temperature since embedding a temperature sensor would affect the structural integrity. Although carbon black material is naturally brittle, steps have been taken in the design to avoid undesirable cracking. Results from laser microscopy analysis of the printed traces showed no crack defects.",
        "primary_area": "",
        "author": "Nuwan Munasinghe;John Masangkay;Gavin Paul;Nuwan Munasinghe;John Masangkay;Gavin Paul",
        "authorids": "/37088395596;/37088998335;/37541865000;/37088395596;/37088998335;/37541865000",
        "aff": "Centre for Autonomous Systems, University of Technology Sydney (UTS), Sydney, Australia; Centre for Autonomous Systems, University of Technology Sydney (UTS), Sydney, Australia; Centre for Autonomous Systems, University of Technology Sydney (UTS), Sydney, Australia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561498/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18339797294787786479&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Technology Sydney",
        "aff_unique_dep": "Centre for Autonomous Systems",
        "aff_unique_url": "https://www.uts.edu.au",
        "aff_unique_abbr": "UTS",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Sydney",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Australia"
    },
    {
        "id": "9561763",
        "title": "Temporal Anticipation and Adaptation Methods for Fluent Human-Robot Teaming",
        "track": "main",
        "status": "Poster",
        "abstract": "As robots work with human teams, they will be expected to fluently coordinate with them. While people are adept at coordination and real-time adaptation, robots still lack this skill. In this paper, we introduce TANDEM: Temporal Anticipation and Adaptation for Machines, a series of neurobiologically-inspired algorithms that enable robots to fluently coordinate with people. TANDEM leverages a humanlike understanding of external and internal temporal changes to facilitate coordination. We experimentally validated the approach via a human-robot collaborative drumming task across tempo-changing rhythmic conditions. We found that an adaptation process alone enables a robot to achieve human-level performance. Moreover, by combining anticipatory knowledge along with an adaptation process, robots can potentially perform such tasks better than people. We hope this work will enable researchers to create robots more sensitive to changes in team dynamics.",
        "primary_area": "",
        "author": "Tariq Iqbal;Laurel D. Riek;Tariq Iqbal;Laurel D. Riek",
        "authorids": "/37399391100;/38548291500;/37399391100;/38548291500",
        "aff": "School of Engineering and Applied Science, University of Virginia, USA; Computer Science and Engineering, University of California, San Diego, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561763/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4226393942070267518&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "University of Virginia;University of California, San Diego",
        "aff_unique_dep": "School of Engineering and Applied Science;Computer Science and Engineering",
        "aff_unique_url": "https://www.virginia.edu;https://www.ucsd.edu",
        "aff_unique_abbr": "UVA;UCSD",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Charlottesville;San Diego",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561808",
        "title": "Test-Time Training for Deformable Multi-Scale Image Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "Registration is a fundamental task in medical robotics and is often a crucial step for many downstream tasks such as motion analysis, intra-operative tracking and image segmentation. Popular registration methods such as ANTs and NiftyReg optimize objective functions for each pair of images from scratch, which are time-consuming for 3D and sequential images with complex deformations. Recently, deep learning-based registration approaches such as VoxelMorph have been emerging and achieve competitive performance. In this work, we construct a test-time training for deep deformable image registration to improve the generalization ability of conventional learning-based registration model. We design multi-scale deep networks to consecutively model the residual deformations, which is effective for high variational deformations. Extensive experiments validate the effectiveness of multi-scale deep registration with test-time training based on Dice coefficient for image segmentation and mean square error (MSE), normalized local cross-correlation (NLCC) for tissue dense tracking tasks.",
        "primary_area": "",
        "author": "Wentao Zhu;Yufang Huang;Daguang Xu;Zhen Qian;Wei Fan;Xiaohui Xie;Wentao Zhu;Yufang Huang;Daguang Xu;Zhen Qian;Wei Fan;Xiaohui Xie",
        "authorids": "/37088400334;/37088401665;/37087079136;/37290649800;/37086375754;/37086382662;/37088400334;/37088401665;/37087079136;/37290649800;/37086375754;/37086382662",
        "aff": "Kuaishou Technology; Cornell University; NVIDIA; Tencent; Tencent; University of California, Irvine",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561808/",
        "gs_citation": 32,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6326490607378414181&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;3;3;4",
        "aff_unique_norm": "Kuaishou Technology;Cornell University;NVIDIA;Tencent;University of California, Irvine",
        "aff_unique_dep": ";;NVIDIA Corporation;Tencent Holdings Limited;",
        "aff_unique_url": "https://www.kuaishou.com;https://www.cornell.edu;https://www.nvidia.com;https://www.tencent.com;https://www.uci.edu",
        "aff_unique_abbr": "Kuaishou;Cornell;NVIDIA;Tencent;UCI",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Irvine",
        "aff_country_unique_index": "0;1;1;0;0;1",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561464",
        "title": "The Effect of Input Signals Time-Delay on Stabilizing Traffic with Autonomous Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper extends the results in [1] considering time delays in Standard Car Following models (CFMs). In [1], connected vehicles are characterized with CFMs models and controlled using linear string analysis to stabilize single-lane car following of human-driven vehicles (HDVs). In this paper, we revisit stability and safety conditions for traffic considering time delays due to lags in the input signals. We perform plant stability and string stability analysis to derive these conditions. Then we obtain the optimal number of HDVs that can be stabilized using one autonomous vehicle. Numerical simulations are provided to implement a case study on Intelligent Driver Model to discuss the influence of time delays that arise on HDVs and the autonomous vehicle on optimal number of HDVs that can be stabilized using one autonomous vehicle.",
        "primary_area": "",
        "author": "Isam Al-Darabsah;Mohammad Al Janaideh;Sue Ann Campbell;Isam Al-Darabsah;Mohammad Al Janaideh;Sue Ann Campbell",
        "authorids": "/37086064930;/37542671600;/37089001382;/37086064930;/37542671600;/37089001382",
        "aff": "Department of Applied Mathematics, University of Waterloo, Waterloo, ON, Canada; Department of Mechanical Engineering, Memorial University, St. John\u2019s, NL, Canada; Department of Applied Mathematics, University of Waterloo, Waterloo, ON, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561464/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:4JuTL3-ocjQJ:scholar.google.com/&scioq=The+Effect+of+Input+Signals+Time-Delay+on+Stabilizing+Traffic+with+Autonomous+Vehicles&hl=en&as_sdt=0,5",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Waterloo;Memorial University",
        "aff_unique_dep": "Department of Applied Mathematics;Department of Mechanical Engineering",
        "aff_unique_url": "https://uwaterloo.ca;https://www.mun.ca",
        "aff_unique_abbr": "UW;MUN",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Waterloo;St. John\u2019s",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9560760",
        "title": "The Effects of Robot Cognitive Reliability and Social Positioning on Child-Robot Team Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "Human collaboration is more likely to lead to cognitive growth when all group-members are actively involved in the collaborative process. However, there are cases that intragroup relationships need support. In this paper, we present an autonomous robotic system designed to interact with a pair of children in a problem-solving setting, aiming to understand how the robot behaviour impacts the group-members\u2019 social dynamics. We developed an autonomous system with the Haru robot which we evaluated with an experimental study with 5-8yo children (N =84) to test the impact of the robot\u2019s cognitive reliability and social positioning on human-to-human social dynamics, task performance and help-seeking behaviour. All participants took part in a baseline session (without the robot), an intervention (with the robot in a turn-taking setting) and an evaluation session (with a robot in a voluntary interaction setting). Results indicate that children who interacted with the reliable robot had a better task performance but children who interacted with the unreliable robot exhibited more task-related social interactions. Based on the results, we propose an interaction design concept which combines the set of the evaluated robot behaviours for an adaptive targeted support of child-robot teaming.",
        "primary_area": "",
        "author": "V. Charisi;L. Merino;M. Escobar;F. Caballero;R. Gomez;E. G\u00f3mez;V. Charisi;L. Merino;M. Escobar;F. Caballero;R. Gomez;E. G\u00f3mez",
        "authorids": "/37085802786;/37282385100;/37296880800;/37282357300;/37979526500;/37287104700;/37085802786;/37282385100;/37296880800;/37282357300;/37979526500;/37287104700",
        "aff": "European Commission Joint Research Centre, Seville, Spain; Service Robotics Laboratory, University Pablo de Olavide, Seville, Spain; European Commission Joint Research Centre, Seville, Spain; Service Robotics Laboratory, University Pablo de Olavide, Seville, Spain; Honda Research Institute Japan, Tokyo, Japan; European Commission Joint Research Centre, Seville, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560760/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2114914764730158089&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;0;1;2;0",
        "aff_unique_norm": "European Commission Joint Research Centre;University Pablo de Olavide;Honda Research Institute Japan",
        "aff_unique_dep": ";Service Robotics Laboratory;",
        "aff_unique_url": "https://ec.europa.eu/jrc;https://www.upo.es;https://www.honda-ri.jp/english/",
        "aff_unique_abbr": "EC JRC;;HRI-JP",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Seville;Tokyo",
        "aff_country_unique_index": "0;0;0;0;1;0",
        "aff_country_unique": "Spain;Japan"
    },
    {
        "id": "9561102",
        "title": "The Fluid Field SLIP Model: Terrestrial-Aquatic Dynamic Legged Locomotion",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes the development of a single reduced-order dynamic model that captures running on land, running while submerged, and for the first time swimming on the surface of water. By capturing the effect of fluid forces on both the body and the leg, the Spring-Loaded Inverted Pendulum (SLIP) model is extended to operate in amphibious and aquatic regimes. Three distinct stable motion patterns, or dog-paddle type gaits are identified when swimming at the air-water interface. The model shows that, for surfaces swimming, alteration of the leg stroke frequency and length produces gaits that are either smooth and efficient or are vertically oscillatory and exhibit rapid disturbance rejection. Furthermore, when the model is examined at the physical parameter values corresponding to dogs (specifically Labrador Retrievers), the animal-based control parameters demonstrate nearly optimal performance.",
        "primary_area": "",
        "author": "Max P. Austin;Jonathan E. Clark;Max P. Austin;Jonathan E. Clark",
        "authorids": "/37086355499;/37533408500;/37086355499;/37533408500",
        "aff": "FAMU/FSU College of Engineering, Tallahassee, FL; FAMU/FSU College of Engineering, Tallahassee, FL",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561102/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14973832252727666177&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Florida A&M University - Florida State University College of Engineering",
        "aff_unique_dep": "College of Engineering",
        "aff_unique_url": "http://www.famu-fsu.edu",
        "aff_unique_abbr": "FAMU/FSU CoE",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tallahassee",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561336",
        "title": "The KIT Gripper: A Multi-Functional Gripper for Disassembly Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "We introduce a multi-functional robotic gripper equipped with a set of actions required for disassembly of electromechanical devices. The gripper consists of a robot arm with 5 degrees of freedom (DoF) for manipulation and a jaw gripper with a 1-DoF rotation joint and a 1-DoF closing joint. The system enables manipulation in 7 DoF and offers the ability to reposition objects in hand and to perform tasks that usually require bimanual systems. The sensor system of the gripper includes relative and absolute joint encoders, force and pressure sensors to provide feedback about interaction forces, a tool- mounted camera for screw detection and precise placement of the tool tip using image-based visual servoing. We present a data-driven method for estimating joint torques based on the output voltage and motor speed. Further, we provide methods for teaching disassembly actions based on human demonstration, their representation as movement primitives and execution based on sensory feedback. We provide quantitative results regarding positioning and torque estimation accuracy, disassembly success rate and qualitative results regarding the successful disassembly of hard disc drives.",
        "primary_area": "",
        "author": "Cornelius Klas;Felix Hundhausen;Jianfeng Gao;Christian R. G. Dreher;Stefan Reither;You Zhou;Tamim Asfour;Cornelius Klas;Felix Hundhausen;Jianfeng Gao;Christian R. G. Dreher;Stefan Reither;You Zhou;Tamim Asfour",
        "authorids": "/37088721742;/37086581259;/37086604791;/37086313722;/37088999339;/37086046566;/37295529100;/37088721742;/37086581259;/37086604791;/37086313722;/37088999339;/37086046566;/37295529100",
        "aff": "Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany; Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology, Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561336/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2413034306735137348&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0;0;0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561715",
        "title": "The Reachable Set of a Drone: Exploring the Position Isochrones for a Quadcopter",
        "track": "main",
        "status": "Poster",
        "abstract": "Quadcopters are increasingly popular for robotics applications. Being able to efficiently calculate the set of positions reachable by a quadcopter within a time budget enables collision avoidance and pursuit-evasion strategies.This paper examines the set of positions reachable by a quadcopter within a specified time limit using a simplified 2D model for quadcopter dynamics. This popular model is used to determine the set of candidate optimal control sequences to build the full 3D reachable set. We calculate the analytic equations that exactly bound the set of positions reachable in a given time horizon for all initial conditions. To further increase calculation speed, we use these equations to derive tight upper and lower spherical bounds on the reachable set.",
        "primary_area": "",
        "author": "Mohammad M. Sultan;Daniel Biediger;Bernard Li;Aaron T. Becker;Mohammad M. Sultan;Daniel Biediger;Bernard Li;Aaron T. Becker",
        "authorids": "/37089000286;/37086325072;/37089000666;/37588897100;/37089000286;/37086325072;/37089000666;/37588897100",
        "aff": "Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561715/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=730901014089286138&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Houston",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.uh.edu",
        "aff_unique_abbr": "UH",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Houston",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561133",
        "title": "The Resh Programming Language for Multirobot Orchestration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper describes Resh, a new, statically typed, interpreted programming language and associated runtime for orchestrating multirobot systems. The main features of Resh are: (1) It offloads much of the tedious work of programming such systems away from the programmer and into the language runtime; (2) It is based on a small set of temporal and locational operators; and (3) It is not restricted to specific robot types or tasks. The Resh runtime consists of three engines that collaborate to run a Resh program using the available robots in their current environment. This paper describes both Resh and its runtime and gives examples of its use.",
        "primary_area": "",
        "author": "Martin Carroll;Kedar S. Namjoshi;Itai Segall;Martin Carroll;Kedar S. Namjoshi;Itai Segall",
        "authorids": "/37085824254;/37282566000;/37572047200;/37085824254;/37282566000;/37572047200",
        "aff": "Nokia Bell Labs, Murray Hill, N.J.; Nokia Bell Labs, Murray Hill, N.J.; Nokia Bell Labs, Murray Hill, N.J.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561133/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10412899042954514404&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Nokia Bell Labs",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.nokia.com bell-labs/",
        "aff_unique_abbr": "Nokia Bell Labs",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Murray Hill",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560774",
        "title": "The Robot Household Marathon Experiment",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we present an experiment, designed to investigate and evaluate the scalability and the robustness aspects of mobile manipulation. The experiment involves performing variations of mobile pick and place actions and opening/closing environment containers in a human household. The robot is expected to act completely autonomously for extended periods of time. We discuss the scientific challenges raised by the experiment as well as present our robotic system that can address these challenges and successfully perform all the tasks of the experiment. We present empirical results and the lessons learned as well as discuss where we hit limitations.",
        "primary_area": "",
        "author": "Gayane Kazhoyan;Simon Stelter;Franklin Kenghagho Kenfack;Sebastian Koralewski;Michael Beetz;Gayane Kazhoyan;Simon Stelter;Franklin Kenghagho Kenfack;Sebastian Koralewski;Michael Beetz",
        "authorids": "/37086314230;/37086156090;/37088998470;/37086026637;/37279125900;/37086314230;/37086156090;/37088998470;/37086026637;/37279125900",
        "aff": "Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany; Institute for Artificial Intelligence, University of Bremen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560774/",
        "gs_citation": 46,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1019780514656267206&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Bremen",
        "aff_unique_dep": "Institute for Artificial Intelligence",
        "aff_unique_url": "https://www.uni-bremen.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Bremen",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561718",
        "title": "The Value of Planning for Infinite-Horizon Model Predictive Control",
        "track": "main",
        "status": "Poster",
        "abstract": "Model Predictive Control (MPC) is a classic tool for optimal control of complex, real-world systems. Although it has been successfully applied to a wide range of challenging tasks in robotics, it is fundamentally limited by the prediction horizon, which, if too short, will result in myopic decisions. Recently, several papers have suggested using a learned value function as the terminal cost for MPC. If the value function is accurate, it effectively allows MPC to reason over an infinite horizon. Unfortunately, Reinforcement Learning (RL) solutions to value function approximation can be difficult to realize for robotics tasks. In this paper, we suggest a more efficient method for value function approximation that applies to goal-directed problems, like reaching and navigation. In these problems, MPC is often formulated to track a path or trajectory returned by a planner. However, this strategy is brittle in that unexpected perturbations to the robot will require replanning, which can be costly at runtime. Instead, we show how the intermediate data structures used by modern planners can be interpreted as an approximate value function. We show that that this value function can be used by MPC directly, resulting in more efficient and resilient behavior at runtime.",
        "primary_area": "",
        "author": "Nathan Hatch;Byron Boots;Nathan Hatch;Byron Boots",
        "authorids": "/37089001834;/37085459219;/37089001834;/37085459219",
        "aff": "Nathan Hatch; Byron Boots",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561718/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7180404786070612395&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "1",
        "aff_unique_norm": ";Byron Boots",
        "aff_unique_dep": ";",
        "aff_unique_url": ";",
        "aff_unique_abbr": ";",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9561739",
        "title": "The dynamic effect of mechanical losses of transmissions on the equation of motion of legged robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Industrial manipulators do not collapse under their own weight when powered off due to the friction in their joints. Although these mechanism are effective for stiff position control of pick-and-place, they are inappropriate for legged robots that must rapidly regulate compliant interactions with the environment. However, no metric exists to quantify the robot\u2019s performance degradation due to mechanical losses in the actuators and transmissions. This paper provides a fundamental formulation that uses the mechanical efficiency of transmissions to quantify the effect of power losses in the mechanical transmissions on the dynamics of a whole robotic system. We quantitatively demonstrate the intuitive fact that the apparent inertia of the robots increase in the presence of joint friction. We also show that robots that employ high gear ratio and low efficiency transmissions can statically sustain more substantial external loads. We expect that the framework presented here will provide the fundamental tools for designing the next generation of legged robots that can effectively interact with the world.",
        "primary_area": "",
        "author": "Youngwoo Sim;Joao Ramos;Youngwoo Sim;Joao Ramos",
        "authorids": "/37086326431;/37085375922;/37086326431;/37085375922",
        "aff": "Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA; Department of Mechanical Science and Engineering, University of Illinois at Urbana-Champaign, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561739/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13720383515952811351&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Mechanical Science and Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562111",
        "title": "There and Back Again: Learning to Simulate Radar Data for Real-World Applications",
        "track": "main",
        "status": "Poster",
        "abstract": "Simulating realistic radar data has the potential to significantly accelerate the development of data-driven approaches to radar processing. However, it is fraught with difficulty due to the notoriously complex image formation process. Here we propose to learn a radar sensor model capable of synthesising faithful radar observations based on simulated elevation maps. In particular, we adopt an adversarial approach to learning a forward sensor model from unaligned radar examples. In addition, modelling the backward model encourages the output to remain aligned to the world state through a cyclical consistency criterion. The backward model is further constrained to predict elevation maps from real radar data that are grounded by partial measurements obtained from corresponding lidar scans. Both models are trained in a joint optimisation. We demonstrate the efficacy of our approach by evaluating a down-stream segmentation model trained purely on simulated data in a real-world deployment. This achieves performance within four percentage points of the same model trained entirely on real data.",
        "primary_area": "",
        "author": "Rob Weston;Oiwi Parker Jones;Ingmar Posner;Rob Weston;Oiwi Parker Jones;Ingmar Posner",
        "authorids": "/37086936297;/37088690104;/37601368300;/37086936297;/37088690104;/37601368300",
        "aff": "Applied Artificial Intelligence Lab (A2I), University of Oxford; Applied Artificial Intelligence Lab (A2I), University of Oxford; Applied Artificial Intelligence Lab (A2I), University of Oxford",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562111/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16794761007505075317&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Oxford",
        "aff_unique_dep": "Applied Artificial Intelligence Lab (A2I)",
        "aff_unique_url": "https://www.ox.ac.uk",
        "aff_unique_abbr": "Oxford",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Oxford",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561621",
        "title": "There and Back Again: Self-supervised Multispectral Correspondence Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Across a wide range of applications, from autonomous vehicles to medical imaging, multi-spectral images provide an opportunity to extract additional information not present in color images. One of the most important steps in making this information readily available is the accurate estimation of dense correspondences between different spectra.Due to the nature of cross-spectral images, most correspondence solving techniques for the visual domain are simply not applicable. Furthermore, most cross-spectral techniques utilize spectra-specific characteristics to perform the alignment. In this work, we aim to address the dense correspondence estimation problem in a way that generalizes to more than one spectrum. We do this by introducing a novel cycle-consistency metric that allows us to self-supervise. This, combined with our spectra-agnostic loss functions, allows us to train the same network across multiple spectra.We demonstrate our approach on the challenging task of dense RGB-FIR correspondence estimation. We also show the performance of our unmodified network on the cases of RGB-NIR and RGB-RGB, where we achieve higher accuracy than similar self-supervised approaches. Our work shows that cross-spectral correspondence estimation can be solved in a common framework that learns to generalize alignment across spectra.",
        "primary_area": "",
        "author": "Celyn Walters;Oscar Mendez;Mark Johnson;Richard Bowden;Celyn Walters;Oscar Mendez;Mark Johnson;Richard Bowden",
        "authorids": "/37087323095;/37710939600;/37089000738;/37268872100;/37087323095;/37710939600;/37089000738;/37268872100",
        "aff": "Centre for Vision, Speech and Signal Processing (CVSSP), University of Surrey, UK; Centre for Vision, Speech and Signal Processing (CVSSP), University of Surrey, UK; Centre for Vision, Speech and Signal Processing (CVSSP), University of Surrey, UK; Centre for Vision, Speech and Signal Processing (CVSSP), University of Surrey, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561621/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17468866198189563987&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 11,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Surrey",
        "aff_unique_dep": "Centre for Vision, Speech and Signal Processing (CVSSP)",
        "aff_unique_url": "https://www.surrey.ac.uk",
        "aff_unique_abbr": "Surrey",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561549",
        "title": "Three-dimensional Positioning of the Micropipette for Intracytoplasmic Sperm Injection",
        "track": "main",
        "status": "Poster",
        "abstract": "ICSI (Intracytoplasmic sperm injection) is one of the most effective treatments for severe male infertility. During the implementation of the ICSI, it is necessary to perform the three-dimensional positioning of the tip of the glass injection micropipette. At present, the process is mainly controlled by skilled operators. Such manual operation is time-consuming and likely to cause micropipette damage or even serious damage to the oocyte membrane due to the inaccurate positioning. In this paper, an automatic system was developed for micropipette positioning. The microscopic positioning is carried out by autofocusing and planar positioning. A search strategy based on Dynamic Curve Fitting (DCF) was proposed to avoid local extremum issues due to the noises during the autofocusing. The proposed search strategy is adaptive to different focus algorisms, making the design of autofocusing becomes simpler. Besides, we proposed a planar positioning algorithm that can quickly and accurately obtain the tip position of the micropipette at the focusing plane. Finally, the visual servo control is employed to move the micropipette to the center of the vision. The experimental results demonstrated that the DCF method can accurately (mean error: 3 \u03bcm) find the focusing plane when applying random Gaussian noise with a mean value of 0 and a variance of 1 to the focus measure. By contrast, both the hill-climbing search method and the Fibonacci search method cannot work properly. The tip positioning algorithm provides a real-time in-plane tip positioning at a frame rate of 40 Hz with an average accuracy of 11 \u03bcm.",
        "primary_area": "",
        "author": "Weikang Hu;Haoyue Liang;Jianjie Li;Zhen Zhan;Yi Zhang;Chengzhi Hu;Weikang Hu;Haoyue Liang;Jianjie Li;Zhen Zhan;Yi Zhang;Chengzhi Hu",
        "authorids": "/37088999327;/37088998531;/37088998687;/37089001805;/37089854468;/38025900900;/37088999327;/37088998531;/37088998687;/37089001805;/37089854468;/38025900900",
        "aff": "Department of Mechanical Engineering and Energy, Southern University of Science and Technology, China; Department of Mechanical Engineering and Energy, Southern University of Science and Technology, China; Department of Mechanical Engineering and Energy, Southern University of Science and Technology, China; Department of Mechanical Engineering and Energy, Southern University of Science and Technology, China; Department of Mechanical Engineering and Energy, Southern University of Science and Technology, China; Guangdong Provincial Key Laboratory of Human-Augmentation and Rehabilitation Robotics in Universities, Southern University of Science and Technology, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561549/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2294982385274493168&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Southern University of Science and Technology",
        "aff_unique_dep": "Department of Mechanical Engineering and Energy",
        "aff_unique_url": "https://www.sustech.edu.cn",
        "aff_unique_abbr": "SUSTech",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561099",
        "title": "Three-dimensional Terrain Aware Autonomous Exploration for Subterranean and Confined Spaces",
        "track": "main",
        "status": "Poster",
        "abstract": "Despite the advances in autonomous navigation and motion planning, there are still several challenges to overcome, especially for confined or underground spaces. Confined scenarios present challenges such as lack of global or accurate external localization, uneven and slippery terrains, and multilevel stages. Exploring and mapping unknown unstructured environments is a fundamental step into the safe and efficient accomplishment of real-world tasks such as search and rescue missions or the autonomous inspection of dangerous areas. This paper proposes a novel three-dimensional autonomous exploration method for ground robots that considers the terrain traversability combined with the frontier expected information gain as a metric for the next best frontier selection in GPS-denied, confined spaces. Safe paths for navigation and frontier extraction are calculated iteratively from multiple 3D map representations such as octrees and meshes. Results in realistic simulated underground scenarios from the DARPA subterranean challenge demonstrate the technique's feasibility, achieving a more reliable and faster exploration rate over competing approaches.",
        "primary_area": "",
        "author": "H\u00e9ctor Azp\u00farua;Mario F. M. Campos;Douglas G. Macharet;H\u00e9ctor Azp\u00farua;Mario F. M. Campos;Douglas G. Macharet",
        "authorids": "/37085559988;/37266947700;/37590114800;/37085559988;/37266947700;/37590114800",
        "aff": "Instituto Tecnol\u00f3gico Vale (ITV), Ouro Preto, Brazil; Department of Computer Science, Computer Vision and Robotics Laboratory (VeRLab), Universidade Federal de Minas Gerais, MG, Brazil; Department of Computer Science, Computer Vision and Robotics Laboratory (VeRLab), Universidade Federal de Minas Gerais, MG, Brazil",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561099/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16173310492974673200&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;1",
        "aff_unique_norm": "Instituto Tecnol\u00f3gico Vale;Universidade Federal de Minas Gerais",
        "aff_unique_dep": ";Department of Computer Science",
        "aff_unique_url": ";http://www.ufmg.br",
        "aff_unique_abbr": "ITV;UFMG",
        "aff_campus_unique_index": "0;1;1",
        "aff_campus_unique": "Ouro Preto;MG",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Brazil"
    },
    {
        "id": "9560930",
        "title": "Thrust Enhancement of Wave-driven Unmanned Surface Vehicle by using Asymmetric Foil",
        "track": "main",
        "status": "Poster",
        "abstract": "In the Wave-driven unmanned surface vehicles (WUSVs), oscillating-foils are the most straightforward and widely used wave energy conversion mechanism. In this paper, a kind of novel asymmetric foil is proposed, which improves the wave energy-converting efficiency to provide a more significant thrust in every wave cycle. We break down the movement of the foils in the wave and build the corresponding kinetic model to analyze their working effectiveness numerically. Through computational fluid dynamic (CFD) simulations, we determine the optimal values of critical parameters of the foils, which are suitable for a wide range of wave conditions. The thrust enhancement of the asymmetric foil is verified in both CFD simulations and hydrodynamic experiments, and the result shows a similar enhancement trend. Comparing with the traditional symmetric foil, our asymmetric foil can provide at least 13.75% more thrust to the WUSVs.",
        "primary_area": "",
        "author": "Yan Gao;Lyucheng Xie;Tin Lun Lam;Yan Gao;Lyucheng Xie;Tin Lun Lam",
        "authorids": "/37088996835;/37088996514;/37571111600;/37088996835;/37088996514;/37571111600",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society; Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560930/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10631535645286401686&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Shenzhen Institute of Artificial Intelligence and Robotics for Society",
        "aff_unique_dep": "",
        "aff_unique_url": "http://www.siarfs.org/",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561217",
        "title": "Tight Integration of Feature-based Relocalization in Monocular Direct Visual Odometry",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper we propose a framework for inte-grating map-based relocalization into online direct visual odometry. To achieve map-based relocalization for direct methods, we integrate image features into Direct Sparse Odometry (DSO) and rely on feature matching to associate online visual odometry (VO) with a previously built map. The integration of the relocalization poses is threefold. Firstly, they are incorporated as pose priors in the direct image alignment of the front-end tracking. Secondly, they are tightly integrated into the back-end bundle adjustment. Thirdly, an online fusion module is further proposed to combine relative VO poses and global relocalization poses in a pose graph to estimate keyframe-wise smooth and globally accurate poses. We evaluate our method on two multi-weather datasets showing the benefits of integrating different handcrafted and learned features and demonstrating promising improvements on camera tracking accuracy.",
        "primary_area": "",
        "author": "Mariia Gladkova;Rui Wang;Niclas Zeller;Daniel Cremers;Mariia Gladkova;Rui Wang;Niclas Zeller;Daniel Cremers",
        "authorids": "/37088999478;/37086238740;/37085527099;/37282875300;/37088999478;/37086238740;/37085527099;/37282875300",
        "aff": "Artisense GmbH; Artisense GmbH; Artisense GmbH; Artisense GmbH",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561217/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2012346570165509950&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Artisense",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "Artisense",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561547",
        "title": "Tightly-Coupled Multi-Sensor Fusion for Localization with LiDAR Feature Maps",
        "track": "main",
        "status": "Poster",
        "abstract": "Robust and accurate pose estimation in long-term localization is crucial to autonomous driving. In this paper, we dealt with absolute localization with a LiDAR feature map and multi-sensor measurements. We proposed a tightly-coupled fusion method with fixed-lag smoothing. A sliding window of recently maintained states is estimated by minimizing a joint cost function. This cost function includes residuals of global LiDAR registration and relative kinematic constraints from an IMU and wheel encoders. In addition, we enhance the robustness of our method by improving LiDAR registration. To achieve this goal, LiDAR feature maps with a hybrid of geometric and normal distribution features are constructed and exploited. The effectiveness of the proposed method is verified in several challenging test sequences over 200km. The experimental results demonstrate that the proposed method achieves accurate localization and high robustness in challenging scenarios even when the LiDAR observation is degraded.",
        "primary_area": "",
        "author": "Liangliang Pan;Kaijin Ji;Ji Zhao;Liangliang Pan;Kaijin Ji;Ji Zhao",
        "authorids": "/37088997255;/37086486962;/37963498600;/37088997255;/37086486962;/37963498600",
        "aff": "TuSimple, Beijing, China; TuSimple, Beijing, China; TuSimple, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561547/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3054526098629688147&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "TuSimple",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562042",
        "title": "Tightly-Coupled Perception and Navigation of Heterogeneous Land-Air Robots in Complex Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "In unstructured and unknown environments, heterogeneous robots must be able to perceive the environment, coordinate with each other and complete tasks collaboratively with onboard sensors. In this paper, a tightly-coupled perception and navigation framework is proposed for heterogeneous land-air robots, which forms a closed loop of perception-navigation for heterogeneous robots. The key novelty of this work is the proposing of a unified framework to formulate the cooperative mapping and navigation problem, as well as the derivation of high-level coordination strategy and low-level goal-oriented navigation within a fully integrated approach. To provide a comprehensive understanding of the environment, a flexible probabilistic map fusion algorithm is applied to merge local maps generated by hybrid robots. The proposed UAV-UGV hybrid system is validated in challenging experiments, proving its robustness and effectiveness in practical tasks.",
        "primary_area": "",
        "author": "Yufeng Yue;Mingxing Wen;Yosmar Putra;Meiling Wang;Danwei Wang;Yufeng Yue;Mingxing Wen;Yosmar Putra;Meiling Wang;Danwei Wang",
        "authorids": "/37086172414;/37086451677;/37085657681;/37406965500;/37279547600;/37086172414;/37086451677;/37085657681;/37406965500;/37279547600",
        "aff": "School of Automation, Beijing Institute of Technology, Beijing, China; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; School of Automation, Beijing Institute of Technology, Beijing, China; School of Automation, Beijing Institute of Technology, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562042/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10481163422009255779&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;0;0",
        "aff_unique_norm": "Beijing Institute of Technology;Nanyang Technological University",
        "aff_unique_dep": "School of Automation;School of Electrical and Electronic Engineering",
        "aff_unique_url": "http://www.bit.edu.cn;https://www.ntu.edu.sg",
        "aff_unique_abbr": "BIT;NTU",
        "aff_campus_unique_index": "0;1;1;0;0",
        "aff_campus_unique": "Beijing;Singapore",
        "aff_country_unique_index": "0;1;1;0;0",
        "aff_country_unique": "China;Singapore"
    },
    {
        "id": "9561702",
        "title": "Time and Energy Optimized Trajectory Generation for Multi-Agent Constellation Changes",
        "track": "main",
        "status": "Poster",
        "abstract": "Planning the simultaneous movement of multiple agents represents a challenging coordination problem, and ideally safety and efficiency are jointly addressed. This paper introduces a planning algorithm for fast and energy-efficient trajectories with reduced collision potential from a start to an end constellation. This new approach combines trajectory approximation based on model predictive control, collision avoidance with potential fields, and flight energy optimization with minimum snap trajectories. Our approach results in unprecedented transition times and success rates with less energy consumption, as shown in simulation and real experiments with 16 drones.",
        "primary_area": "",
        "author": "Paul Ladinig;Bernhard Rinner;Stephan Weiss;Paul Ladinig;Bernhard Rinner;Stephan Weiss",
        "authorids": "/37086545919;/37267881100;/37535323400;/37086545919;/37267881100;/37535323400",
        "aff": "Control of Networked Systems Group, University of Klagenfurt, Austria; Institute of Networked and Embedded Systems, University of Klagenfurt, Austria; Control of Networked Systems Group, University of Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561702/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5703519752763760221&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Klagenfurt",
        "aff_unique_dep": "Control of Networked Systems Group",
        "aff_unique_url": "https://www.uni-klagenfurt.at",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9561930",
        "title": "Time-Domain Passivity-based Controller with an Optimal Two-channel Lawrence Telerobotic Architecture",
        "track": "main",
        "status": "Poster",
        "abstract": "The time-domain passivity approach has been proposed in the literature in a variety of formats to guarantee the stability of teleoperation leader-follower systems. The conventional use of the proposed technique utilizes the control effort at the follower side as the force feedback to be sent back to the user at the leader\u2019s side. However, this has resulted in transparency problems, especially when the follower dynamics are not negligible. On the other hand, four-channel and three-channel Lawrence architectures have been investigated widely in the literature to maximize the transparency of the system when, in most advanced cases, stability is guaranteed using wave-variables. However, wave-variables are historically known for their transparency deterioration problems. In this paper, we propose a two-layer approach taking advantage of the fusion of (a) a more optimal derivation of Lawrence telerobotic architecture (utilizing only two channels), and (b) a two-port time-domain passivity stabilizer while comparing the performance with a one-port passivity stabilizer. The two-channel derivation of the Lawrence architecture allows for implementing a two-port time domain passivity approach, which is investigated in this paper. The performance of this is compared systematically through a multi-objective approach by analyzing dissipated energy besides force and velocity errors for a wide range of time delays and frequencies of excitation. The paper gives a comprehensive view of the efficacy of two-port versus one-port time-domain passivity control when combined with the two-channel derivation of Lawrence architecture.",
        "primary_area": "",
        "author": "Navid Feizi;Smrithi Thudi;Rajni V. Patel;S. Farokh Atashzar;Navid Feizi;Smrithi Thudi;Rajni V. Patel;S. Farokh Atashzar",
        "authorids": "/37086131797;/37088814298;/37271878600;/37088998271;/37086131797;/37088814298;/37271878600;/37088998271",
        "aff": "School of Biomedical Engineering, University of Western Ontario, Canada; Department of Mechanical and Aerospace Engineering, New York University, USA; Department of Electrical and Computer Engineering and the Department of Surgery, University of Western Ontario, Canada; Department of Mechanical and Aerospace Engineering and the Department of Electrical and Computer Engineering, New York University, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561930/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17703478240004799141&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;1",
        "aff_unique_norm": "University of Western Ontario;New York University",
        "aff_unique_dep": "School of Biomedical Engineering;Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.uwo.ca;https://www.nyu.edu",
        "aff_unique_abbr": "UWO;NYU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0;1",
        "aff_country_unique": "Canada;United States"
    },
    {
        "id": "9561972",
        "title": "Time-Optimal Multi-Quadrotor Trajectory Planning for Pesticide Spraying",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we investigate the problem of generating time-optimal trajectories automatically for spraying pesticides to infected regions with varying degree of infections in an agricultural field using a collection of quad-rotors that have limited pesticide carrying capacity but are capable of refilling from the pesticide tanks stationed across the field. We consider the time of traversal between points, time for changing the direction of traversal, and time for spraying and refilling, explicitly in the problem formulation, and generate trajectories for the multiple quad-rotors to execute in parallel such that the total energy (time) for completion of the task is minimized. We present two methods namely, multiple traveling salesman based time-optimal trajectory generation, and clustering based de-compositional time-optimal trajectory generation, respectively. In the first method, our approach consists of reducing the time-optimal trajectory generation problem for the multiple quad-rotors to a version of the multiple traveling salesman problem on a weighted graph, and then encoding the problem into a mixed integer linear programming problem. In the second method, our approach consists of first decomposing the infected regions into k clusters corresponding to the k robots, placing each quad-rotor at the center of the corresponding clusters, and finally, independently solving time-optimal trajectory generation problem for each quad-rotor using the first method. We have implemented both the approaches and performed experimental comparison. We observe that the first method provides an optimal strategy, while the second method provides a sub-optimal strategy. However, the second method is computationally more efficient, and the loss of optimality is minimal, hence, it provides a better trade-off between the computational complexity and the optimality constraints.",
        "primary_area": "",
        "author": "Ratan Lal;Pavithra Prabhakar;Ratan Lal;Pavithra Prabhakar",
        "authorids": "/37085628327;/37671515300;/37085628327;/37671515300",
        "aff": "Kansas State University, Manhattan, Kansas, USA; Kansas State University, Manhattan, Kansas, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561972/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8234744996259867082&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Kansas State University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.k-state.edu",
        "aff_unique_abbr": "K-State",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Manhattan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561913",
        "title": "Time-Varying Model Predictive Control for Highly Dynamic Motions of Quadrupedal Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Obtaining highly dynamic motions in robots is a difficult task. In recent years, sophistication in mechanical design, improved algorithms, and high computational power allows new robots to perform natural gaits and dynamic motions such as backflips. Offline optimization is often necessary to obtain good performance in those difficult motions. However, when an athlete does a backflip, he will adapt \u201conline\u201d to any change, and that is shown in the robustness of the movements. One of the biggest challenges in robotics is to perform those movements using online optimization with the dynamics of the robot. Here, we present an approach to deal with complicated tasks using online optimization. We obtain 90\u00b0 rotational jumps and jumps over sloped terrain in the Mini-Cheetah hardware, and online-optimized backflips, sideflips, and frontflips in a real-time physical simulator with full-body dynamics.",
        "primary_area": "",
        "author": "Gabriel Garc\u00eda;Robert Griffin;Jerry Pratt;Gabriel Garc\u00eda;Robert Griffin;Jerry Pratt",
        "authorids": "/37290886800;/37085631429;/37283041800;/37290886800;/37085631429;/37283041800",
        "aff": "The Florida Institute for Human and Machine Cognition, Pensacola, FL, USA; The Florida Institute for Human and Machine Cognition, Pensacola, FL, USA; The Florida Institute for Human and Machine Cognition, Pensacola, FL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561913/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3074441323531504741&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Florida Institute for Human and Machine Cognition",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Pensacola",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561590",
        "title": "Tiny Robot Learning (tinyRL) for Source Seeking on a Nano Quadcopter",
        "track": "main",
        "status": "Poster",
        "abstract": "We present fully autonomous source seeking onboard a highly constrained nano quadcopter, by contributing application-specific system and observation feature design to enable inference of a deep-RL policy onboard a nano quadcopter. Our deep-RL algorithm finds a high-performance solution to a challenging problem, even in presence of high noise levels and generalizes across real and simulation environments with different obstacle configurations. We verify our approach with simulation and in-field testing on a Bitcraze CrazyFlie using only the cheap and ubiquitous Cortex-M4 microcontroller unit. The results show that by end-to-end application-specific system design, our contribution consumes almost three times less additional power, as compared to a competitive learning-based navigation approach onboard a nano quadcopter. Thanks to our observation space, which we carefully design within the resource constraints, our solution achieves a 94% success rate in cluttered and randomized test environments, as compared to the previously achieved 80%. We also compare our strategy to a simple finite state machine (FSM), geared towards efficient exploration, and demonstrate that our policy is more robust and resilient at obstacle avoidance as well as up to 70% more efficient in source seeking. To this end, we contribute a cheap and lightweight end- to-end tiny robot learning (tinyRL) solution, running onboard a nano quadcopter, that proves to be robust and efficient in a challenging task.",
        "primary_area": "",
        "author": "Bardienus P. Duisterhof;Srivatsan Krishnan;Jonathan J. Cruz;Colby R. Banbury;William Fu;Aleksandra Faust;Guido C. H. E. de Croon;Vijay Janapa Reddi;Bardienus P. Duisterhof;Srivatsan Krishnan;Jonathan J. Cruz;Colby R. Banbury;William Fu;Aleksandra Faust;Guido C. H. E. de Croon;Vijay Janapa Reddi",
        "authorids": "/37089000405;/37086569394;/37088980933;/37088998321;/37089001666;/37077144300;/37698062600;/37086157898;/37089000405;/37086569394;/37088980933;/37088998321;/37089001666;/37077144300;/37698062600;/37086157898",
        "aff": "Delft University of Technology; Harvard University; Harvard University; Harvard University; Harvard University; Robotics at Google; Delft University of Technology; Harvard University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561590/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13660604919616481920&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;1;2;0;1",
        "aff_unique_norm": "Delft University of Technology;Harvard University;Google",
        "aff_unique_dep": ";;Robotics",
        "aff_unique_url": "https://www.tudelft.nl;https://www.harvard.edu;https://www.google.com",
        "aff_unique_abbr": "TU Delft;Harvard;Google Robotics",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Mountain View",
        "aff_country_unique_index": "0;1;1;1;1;1;0;1",
        "aff_country_unique": "Netherlands;United States"
    },
    {
        "id": "9560945",
        "title": "Toward Force Estimation in Robot-Assisted Surgery using Deep Learning with Vision and Robot State",
        "track": "main",
        "status": "Poster",
        "abstract": "Knowledge of interaction forces during teleoperated robot-assisted surgery could be used to enable force feedback to users and evaluate tissue handling skill. However, direct force sensing at the end-effector is challenging because it requires biocompatible, sterilizable, and cost-effective sensors. Vision-based neural networks are a promising approach for providing useful force estimates, though questions remain about generalization to new scenarios and real-time inference. We present a force estimation neural network that uses RGB images and robot state as inputs. Using a self-collected dataset, we compared the network to variants that included only a single input type, and evaluated how they generalized to new viewpoints, workspace positions, materials, and tools. We found that the vision-only network was sensitive to shifts in viewpoints, while networks with state inputs were sensitive to vertical shifts in workspace. The network with both state and vision inputs had the highest accuracy for an unseen tool, while the state-only network was most accurate for an unseen material. Through feature removal studies, we found that using only force features produced better accuracy than using only kinematic features as input. The network with both state and vision inputs outperformed a physics-based model in accuracy for seen material. It showed comparable accuracy but faster computation times than a recurrent neural network, making it better suited for real-time applications.",
        "primary_area": "",
        "author": "Zonghe Chua;Anthony M. Jarc;Allison M. Okamura;Zonghe Chua;Anthony M. Jarc;Allison M. Okamura",
        "authorids": "/37088506881;/38666586800;/37276156400;/37088506881;/38666586800;/37276156400",
        "aff": "Department of Mechanical Engineering, Stanford University, Stanford, CA; Intuitive Surgical Inc., Sunnyvale, CA; Department of Mechanical Engineering, Stanford University, Stanford, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560945/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11052892521582323314&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Stanford University;Intuitive Surgical Inc.",
        "aff_unique_dep": "Department of Mechanical Engineering;",
        "aff_unique_url": "https://www.stanford.edu;https://www.intuitivesurgical.com",
        "aff_unique_abbr": "Stanford;Intuitive Surgical",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Stanford;Sunnyvale",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561089",
        "title": "Toward Impact-resilient Quadrotor Design, Collision Characterization and Recovery Control to Sustain Flight after Collisions",
        "track": "main",
        "status": "Poster",
        "abstract": "Collision detection and recovery for aerial robots remain a challenge because of the limited space for sensors and local stability of the flight controller. We introduce a novel collision-resilient quadrotor that features a compliant arm design to enable free flight while allowing for one passive degree of freedom to absorb shocks. We further propose a novel collision detection and characterization method based on Hall sensors, as well as a new recovery control method to generate and track a smooth trajectory after a collision occurs. Experimental results demonstrate that the robot can detect and recover from high-speed collisions with various obstacles such as walls and poles. Moreover, it can survive collisions that are hard to detect with existing methods based on IMU data and contact models, for example, when colliding with unstructured surfaces, or being hit by a moving obstacle while hovering.",
        "primary_area": "",
        "author": "Zhichao Liu;Konstantinos Karydis;Zhichao Liu;Konstantinos Karydis",
        "authorids": "/37088505148;/38252121900;/37088505148;/38252121900",
        "aff": "Dept. of Electrical and Computer Engineering, University of California, Riverside; Dept. of Electrical and Computer Engineering, University of California, Riverside",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561089/",
        "gs_citation": 40,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6302682266497937500&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of California, Riverside",
        "aff_unique_dep": "Dept. of Electrical and Computer Engineering",
        "aff_unique_url": "https://www.ucr.edu",
        "aff_unique_abbr": "UCR",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Riverside",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562012",
        "title": "Toward Robust and Efficient Online Adaptation for Deep Stereo Depth Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Although deep neural networks have achieved state-of-the-art performance for stereo depth estimation, they can suffer from a significant drop in accuracy when tested on images from novel domains. Recent work has shown that self-supervised online adaptation is a promising approach for closing this performance gap. In this work, we address three unsolved challenges for online adaptation. First, we propose a method for detecting novel environments, allowing us to trigger adaptation and notify downstream systems that depth predictions are unreliable. We find that the feature similarity scores from our deep stereo network can be leveraged for out-of-distribution (OOD) detection, providing the necessary starting criterion for adaptation. Next, we use online validation to terminate adaptation when it stops improving performance, allowing us to free up computational resources. Finally, we demonstrate that existing methods for continuous adaptation cause catastrophic forgetting of the training domain. By augmenting adaptation with experience replay, we retain high accuracy in the training domain while rapidly improving performance in novel environments. In sum, these three contributions form the basis of a more robust and efficient deep stereo system that can recognize and adapt to new environments without forgetting.",
        "primary_area": "",
        "author": "Milo Knowles;Valentin Peretroukhin;W. Nicholas Greene;Nicholas Roy;Milo Knowles;Valentin Peretroukhin;W. Nicholas Greene;Nicholas Roy",
        "authorids": "/37088999812;/37085447063;/37085781116;/37274058700;/37088999812;/37085447063;/37085781116;/37274058700",
        "aff": "Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA; Computer Science and Artificial Intelligence Laboratory (CSAIL), Massachusetts Institute of Technology, Cambridge, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562012/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5324569762048769258&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory (CSAIL)",
        "aff_unique_url": "https://www.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561594",
        "title": "Toward a Unified Framework for Point Set Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "Point set registration plays a critical role in robotics and computer vision. Early methods considered registration as a purely geometric problem, presenting excellent extensibility for various tasks due to their explicit handling of correspondences; statistical methods were later introduced to handle noise. However, the two categories of algorithms have evolved independently without sharing much in common. In this paper, we leverage the concept of information geometry to theoretically unify the two classes together by interpreting them as the same operation but in different spaces associated with respective metrics. Moreover, based on the proposed unification, we also develop a novel bandwidth estimation strategy to solve the long-standing problem of statistical registration algorithms, and demonstrate its theoretical and practical advantages over deterministic annealing, the most commonly used technique. We also present a case study to show how geometric and statistical approaches can benefit from each other.",
        "primary_area": "",
        "author": "Feiran Li;Kent Fujiwara;Yasuyuki Matsushita;Feiran Li;Kent Fujiwara;Yasuyuki Matsushita",
        "authorids": "/37088483953;/37088454929;/37279541200;/37088483953;/37088454929;/37279541200",
        "aff": "Osaka University; LINE Corporation; Osaka University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561594/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2234187702939914202&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Osaka University;LINE Corporation",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.osaka-u.ac.jp;https://www.linecorp.com",
        "aff_unique_abbr": "Osaka U;LINE",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561975",
        "title": "Toward intraoperative endomicroscopy with a GPU-accelerated deformable video mosaicking algorithm",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the limited field of view (FOV), the probe-based confocal laser endomicroscopy (pCLE) imaging system remains challenging to be widely used in clinic. Existing video mosaicking approaches are usually troubled by poor real-time capability and sensitivity to tissue deformations and intensity fluctuations. In this paper, a novel pCLE mosaicking algorithm that simultaneously implements rigid probe motion tracking and inter-frame tissue deformation correction is proposed. The sum of conditional variance (SCV) metric with low calculational complexity and intensity variation invariance is embedded into the reconstruction of pCLE mosaics. We also deduce the derivatives of the SCV metric with respect to transformation variables to enhance the robustness of numerical solutions. Moreover, a parallel acceleration mechanism that maximally exploits the resources of graphics processing unit (GPU) is designed to boost mosaicking efficiency. Experiments on lens tissue paper and swine tissue highlight the excellent mosaicking accuracy of the proposed method in this field. It is also verified that the mosaic-king rate of the proposed method exceeds 14 frames per second (fps), which can keep up with the acquisition rate of most pCLE imaging systems (8 fps~12 fps). Benefiting from finer mosaics and faster speed, the proposed algorithm has high potential to achieve large and accurate mosaicking for intraoperative endomicroscopy.",
        "primary_area": "",
        "author": "Lun Gong;Siyang Zuo;Lun Gong;Siyang Zuo",
        "authorids": "/37088468906;/37085492756;/37088468906;/37085492756",
        "aff": "Key Laboratory of Mechanism Theory and Equipment Design of Ministry of Education, Tianjin University, Tianjin, China; Key Laboratory of Mechanism Theory and Equipment Design of Ministry of Education, Tianjin University, Tianjin, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561975/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11468822349204053068&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Tianjin University",
        "aff_unique_dep": "Key Laboratory of Mechanism Theory and Equipment Design",
        "aff_unique_url": "http://www.tju.edu.cn",
        "aff_unique_abbr": "Tianjin University",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Tianjin",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561756",
        "title": "Towards Adjoint Sensing and Acting Schemes and Interleaving Task Planning for Robust Robot Plan",
        "track": "main",
        "status": "Poster",
        "abstract": "Robots operating in open environments expect to have robust plans to achieve tasks successfully under environment uncertainties. However, both partial observability and dynamics of environment states have significantly decreased the robustness of task achievement, making robot task planning much more challenging. The partially observable states require the robot to obtain observations for optimally acting of the task goal. Also, state dynamics expects the robot to continuously observe surroundings for acting safely. Both challenges practically demand the purposeful and tight interactions between robot state-changing actuating actions and sensor-based observation actions. This paper proposes a novel model of Adjoint Sensing and Acting (ASA) that explicitly defines two parallel and sequential interaction schemes between actuating and observation actions, as well as an extended Behavior Tree for a concrete implementation of above schemes. We further propose an interleaving task planning approach for planning ASA-style plans, which integrates a deliberative POMDP planner for pursuing task goals, and a reactive Behavior Tree executive for fast responding to unexpected events. We experimentally demonstrate that ASA interaction schemes are practical and applicable to model and plan the open environment robot tasks. The plans from the interleaving task planning approach are both reactive in run-time response and efficient in task achievement.",
        "primary_area": "",
        "author": "Shuo Yang;Xinjun Mao;Shuo Wang;Huaiyu Xiao;Yuanzhou Xue;Shuo Yang;Xinjun Mao;Shuo Wang;Huaiyu Xiao;Yuanzhou Xue",
        "authorids": "/37085620576;/37089908728;/37087012739;/37088996190;/37088996151;/37085620576;/37089908728;/37087012739;/37088996190;/37088996151",
        "aff": "Key Laboratory of Software Engineering for Complex Systems, College of Computer, National University of Defense Technology; Key Laboratory of Software Engineering for Complex Systems, College of Computer, National University of Defense Technology; Key Laboratory of Software Engineering for Complex Systems, College of Computer, National University of Defense Technology; Key Laboratory of Software Engineering for Complex Systems, College of Computer, National University of Defense Technology; Key Laboratory of Software Engineering for Complex Systems, College of Computer, National University of Defense Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561756/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8913025768270727189&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "National University of Defense Technology",
        "aff_unique_dep": "College of Computer",
        "aff_unique_url": "http://www.nudt.edu.cn/",
        "aff_unique_abbr": "NUDT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560779",
        "title": "Towards Collision Detection, Localization and Force Estimation for a Soft Cable-driven Robot Manipulator",
        "track": "main",
        "status": "Poster",
        "abstract": "Soft robots have been applied widely to various constrained scenarios due to the advantages over traditional rigid manipulators such as softness, deformability and adaptability to constrained surroundings. To make full use of this merit, this paper proposes a method that integrates collision detection, localization and force estimation for a cable-driven soft manipulator without any prior geometrical knowledge of its surroundings. First of all, a collision detection algorithm is presented based upon Cosserat-rod statics by a threshold method through using the cable tension and the shape information, which are obtained by the load cells and the Vicon system, respectively. Secondly, a collision localization and force estimation method is proposed through optimizing the discrepancy between the actual and the theoretical shapes. Finally, experiments are carried out to validate these algorithms. The experimental results demonstrate that the site, the magnitude as well as the direction can be estimated.",
        "primary_area": "",
        "author": "Yuxin Wang;Hesheng Wang;Fan Xu;Junzhi Yu;Weidong Chen;Yun-Hui Liu;Yuxin Wang;Hesheng Wang;Fan Xu;Junzhi Yu;Weidong Chen;Yun-Hui Liu",
        "authorids": "/37088423907;/37292567100;/37086550869;/37278401500;/37279187800;/37279412600;/37088423907;/37292567100;/37086550869;/37278401500;/37279187800;/37279412600",
        "aff": "Department of Automation, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Institute of Medical Robotics, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai, China; Department of Automation, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Institute of Medical Robotics, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai, China; Department of Automation, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Institute of Medical Robotics, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai, China; Department of Advanced Manufacturing and Robotics, College of Engineering, Peking University, Beijing, China; Department of Automation, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Institute of Medical Robotics, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560779/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16306049956895405855&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;2",
        "aff_unique_norm": "Shanghai Jiao Tong University;Peking University;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Automation;Department of Advanced Manufacturing and Robotics;Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.sjtu.edu.cn;http://www.pku.edu.cn;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "SJTU;Peking U;CUHK",
        "aff_campus_unique_index": "0;0;0;1;0;2",
        "aff_campus_unique": "Shanghai;Beijing;Hong Kong SAR",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561388",
        "title": "Towards Efficient Multiview Object Detection with Adaptive Action Prediction",
        "track": "main",
        "status": "Poster",
        "abstract": "Active vision is a desirable perceptual feature for robots. Existing approaches usually make strong assumptions about the task and environment, thus are less robust and efficient. This study proposes an adaptive view planning approach to boost the efficiency and robustness of active object detection. We formulate the multi-object detection task as an active multiview object detection problem given the initial location of the objects. Next, we propose a novel adaptive action prediction (A2P) method built on a deep Q-learning network with a dueling architecture. The A2P method is able to perform view planning based on visual information of multiple objects; and adjust action ranges according to the task status. Evaluated on the AVD dataset, A2P leads to 21.9% increase in detection accuracy in unfamiliar environments, while improving efficiency by 22.7%. On the T-LESS dataset, multi-object detection boosts efficiency by more than 30% while achieving equivalent detection accuracy.",
        "primary_area": "",
        "author": "Qianli Xu;Fen Fang;Nicolas Gauthier;Wenyu Liang;Yan Wu;Liyuan Li;Joo-Hwee Lim;Qianli Xu;Fen Fang;Nicolas Gauthier;Wenyu Liang;Yan Wu;Liyuan Li;Joo-Hwee Lim",
        "authorids": "/37673813200;/37087139941;/37088477763;/37598507800;/37085344977;/37280694300;/37276358500;/37673813200;/37087139941;/37088477763;/37598507800;/37085344977;/37280694300;/37276358500",
        "aff": "Institute for Infocomm Research, A*Star, Singapore; Institute for Infocomm Research, A*Star, Singapore; Institute for Infocomm Research, A*Star, Singapore; Institute for Infocomm Research, A*Star, Singapore; Institute for Infocomm Research, A*Star, Singapore; Institute for Infocomm Research, A*Star, Singapore; Institute for Infocomm Research, A*Star, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561388/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5517055732780972197&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;0;0;0",
        "aff_unique_norm": "Institute for Infocomm Research",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.i2r.a-star.edu.sg",
        "aff_unique_abbr": "I2R",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "Singapore"
    },
    {
        "id": "9561356",
        "title": "Towards In-Field Phenotyping Exploiting Differentiable Rendering with Self-Consistency Loss",
        "track": "main",
        "status": "Poster",
        "abstract": "In modern agriculture, measuring phenotypic traits helps breeders monitor plant growth, increase yield, and provide food, feed, and fiber. Traditional phenotyping requires intensive manual work, partially being intrusive. In this paper, we investigate the challenge of measuring phenotypic traits in an automated fashion through mobile robots operating in field environments. In particular, we want to measure plants from images acquired by mobile robots instead of using data from a static scanning environment. We propose to use a differentiable rendering approach to deform a generic 3D template of a plant to fit the observation recorded by a robot while ensuring a coherent deformation of the plant template. The experiments presented in this paper suggest that our approach allows for 3D reconstruction of different plant species at different growth stages using single images. From that model, we can compute important phenotypic traits, such as the leaf area index.",
        "primary_area": "",
        "author": "Federico Magistri;Nived Chebrolu;Jens Behley;Cyrill Stachniss;Federico Magistri;Nived Chebrolu;Jens Behley;Cyrill Stachniss",
        "authorids": "/37086805350;/37086411047;/37593243900;/37329668600;/37086805350;/37086411047;/37593243900;/37329668600",
        "aff": "University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany; University of Bonn, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561356/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17263564125763074717&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Bonn",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.uni-bonn.de",
        "aff_unique_abbr": "UBonn",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561024",
        "title": "Towards Real-Time Interaction with Industrial Robots in the Creative Industries",
        "track": "main",
        "status": "Poster",
        "abstract": "This research provides an overview of the challenges towards realizing interactive (near) real-time control of industrial robots within the context of creative industries. Within this field, there an increasing interest in the use of industrial robots for non-standard fabrication, building upon accessible, flow-based visual programming environments.Where robotics middleware is focused on communication, these software tools focus primarily on computational geometry within design software, with the goal of enabling mass-customization and individualization by linking parametric design with toolpath generation and robot simulation.Realizing interactive processes within such environments is challenging, as they form directed dataflows minimizing opportunities for recursive applications and are limited to non-real-time capable operating systems. A series of realized projects is presented that benefits from the advanced geometrical methods provided by the creative industries\u2019 flow-based programming, while at the same time implementing strategies that enable cyclical dataflows and interaction. Novel software interfaces have allowed for fluent interaction with existing robot technologies, even from non-real-time capable environments.",
        "primary_area": "",
        "author": "Johannes Braumann;Karl Singline;Johannes Braumann;Karl Singline",
        "authorids": "/37088999529;/37088996712;/37088999529;/37088996712",
        "aff": "Creative Robotics, University of Arts and Industrial Design Linz, and the Association for Robots in Architecture; Creative Robotics, University of Arts and Industrial Design Linz",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561024/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4530316055226236252&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Arts and Industrial Design Linz",
        "aff_unique_dep": "Creative Robotics",
        "aff_unique_url": "https://www.universitaet-kuelinz.at",
        "aff_unique_abbr": "UAK",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Linz",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9561743",
        "title": "Towards Real-time Semantic RGB-D SLAM in Dynamic Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Most of the existing visual SLAM methods heavily rely on a static world assumption and easily fail in dynamic environments. Some recent works eliminate the influence of dynamic objects by introducing deep learning-based semantic information to SLAM systems. However such methods suffer from high computational cost and cannot handle unknown objects. In this paper, we propose a real-time semantic RGBD SLAM system for dynamic environments that is capable of detecting both known and unknown moving objects. To reduce the computational cost, we only perform semantic segmentation on keyframes to remove known dynamic objects, and maintain a static map for robust camera tracking. Furthermore, we propose an efficient geometry module to detect unknown moving objects by clustering the depth image into a few regions and identifying the dynamic regions via their reprojection errors. The proposed method is evaluated on public datasets and realworld conditions. To the best of our knowledge, it is one of the first semantic RGB-D SLAM systems that run in real-time on a low-power embedded platform and provide high localization accuracy in dynamic environments.",
        "primary_area": "",
        "author": "Tete Ji;Chen Wang;Lihua Xie;Tete Ji;Chen Wang;Lihua Xie",
        "authorids": "/37086453384;/37089398088;/37274139300;/37086453384;/37089398088;/37274139300",
        "aff": "School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore; Chen Wang is with the Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; School of Electrical and Electronic Engineering, Nanyang Technological University, Singapore",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561743/",
        "gs_citation": 88,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3486035198898867618&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Nanyang Technological University;Carnegie Mellon University",
        "aff_unique_dep": "School of Electrical and Electronic Engineering;Robotics Institute",
        "aff_unique_url": "https://www.ntu.edu.sg;https://www.cmu.edu",
        "aff_unique_abbr": "NTU;CMU",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Singapore;Pittsburgh",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Singapore;United States"
    },
    {
        "id": "9562037",
        "title": "Towards Robust GNSS Positioning and Real-time Kinematic Using Factor Graph Optimization",
        "track": "main",
        "status": "Poster",
        "abstract": "Global navigation satellite systems (GNSS) are one of the utterly popular sources for providing globally referenced positioning for autonomous systems. However, the performance of the GNSS positioning is significantly challenged in urban canyons, due to the signal reflection and blockage from buildings. Given the fact that the GNSS measurements are highly environmentally dependent and time-correlated, the conventional filtering-based method for GNSS positioning cannot simultaneously explore the time-correlation among historical measurements. As a result, the filtering-based estimator is sensitive to unexpected outlier measurements. In this paper, we present a factor graph-based formulation for GNSS positioning and real-time kinematic (RTK). The formulated factor graph framework effectively explores the time-correlation of pseudorange, carrier-phase, and doppler measurements, and leads to the non-minimal state estimation of the GNSS receiver. The feasibility of the proposed method is evaluated using datasets collected in challenging urban canyons of Hong Kong and significantly improved positioning accuracy is obtained, compared with the filtering-based estimator.",
        "primary_area": "",
        "author": "Weisong Wen;Li-Ta Hsu;Weisong Wen;Li-Ta Hsu",
        "authorids": "/37086390590;/37085610699;/37086390590;/37085610699",
        "aff": "Hong Kong Polytechnic University, Hong Kong; Hong Kong Polytechnic University, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562037/",
        "gs_citation": 106,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2735599268973304936&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Hong Kong Polytechnic University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.polyu.edu.hk",
        "aff_unique_abbr": "PolyU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Hong Kong SAR",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561782",
        "title": "Towards Robust One-shot Task Execution using Knowledge Graph Embeddings",
        "track": "main",
        "status": "Poster",
        "abstract": "Requiring multiple demonstrations of a task plan presents a burden to end-users of robots. However, robustly executing tasks plans from a single end-user demonstration is an ongoing challenge in robotics. We address the problem of one-shot task execution, in which a robot must generalize a single demonstration or prototypical example of a task plan to a new execution environment. Our approach integrates task plans with domain knowledge to infer task plan constituents for new execution environments. Our experimental evaluations show that our knowledge representation makes more relevant generalizations that result in significantly higher success rates over tested baselines. We validated the approach on a physical platform, which resulted in the successful generalization of initial task plans to 38 of 50 execution environments with errors resulting from autonomous robot operation included.",
        "primary_area": "",
        "author": "Angel Daruna;Lakshmi Nair;Weiyu Liu;Sonia Chernova;Angel Daruna;Lakshmi Nair;Weiyu Liu;Sonia Chernova",
        "authorids": "/37085616620;/37086936432;/37088504929;/37283184200;/37085616620;/37086936432;/37088504929;/37283184200",
        "aff": "Georgia Institute of Technology, Atlanta, GA; Georgia Institute of Technology, Atlanta, GA; Georgia Institute of Technology, Atlanta, GA; Georgia Institute of Technology, Atlanta, GA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561782/",
        "gs_citation": 21,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5676928031985256263&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Georgia Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.gatech.edu",
        "aff_unique_abbr": "Georgia Tech",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561003",
        "title": "Towards Robust Planar Translations using Delta-manipulator Arrays",
        "track": "main",
        "status": "Poster",
        "abstract": "Distributed manipulators - consisting of a set of actuators or robots working cooperatively to achieve a manipulation task - are robust and flexible tools for performing a range of planar manipulation skills. One novel example is the delta array, a distributed manipulator composed of a grid of delta robots, capable of performing dexterous manipulation tasks using strategies incorporating both dynamic and static contact. Hand-designing effective distributed control policies for such a manipulator can be complex and time consuming, given the high-dimensional action space and unfamiliar system dynamics. In this paper, we examine the principles guiding development and control of such a delta array for a planar translation task. We explore policy learning as a robust cooperative control approach, allowing for smooth manipulation of a range of objects, showing improved accuracy and efficiency over baseline human-designed policies.",
        "primary_area": "",
        "author": "Skye Thompson;Pragna Mannam;Zeynep Temel;Oliver Kroemer;Skye Thompson;Pragna Mannam;Zeynep Temel;Oliver Kroemer",
        "authorids": "/37088997113;/37088996626;/37088689031;/37593222300;/37088997113;/37088996626;/37088689031;/37593222300",
        "aff": "CSAIL, Massachusetts Institute of Technology, Cambridge, MA, USA; Carnegie Mellon University, The Robotics Institute, Pittsburgh, PA, USA; Carnegie Mellon University, The Robotics Institute, Pittsburgh, PA, USA; Carnegie Mellon University, The Robotics Institute, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561003/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17963940248453905508&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;1;1",
        "aff_unique_norm": "Massachusetts Institute of Technology;Carnegie Mellon University",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory (CSAIL);The Robotics Institute",
        "aff_unique_url": "https://www.csail.mit.edu;https://www.cmu.edu",
        "aff_unique_abbr": "MIT;CMU",
        "aff_campus_unique_index": "0;1;1;1",
        "aff_campus_unique": "Cambridge;Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561622",
        "title": "Towards Safe Motion Planning in Human Workspaces: A Robust Multi-agent Approach",
        "track": "main",
        "status": "Poster",
        "abstract": "It is becoming increasingly feasible for robots to share a workspace with humans. However, for them to do so safely while maintaining agile performance, they need the ability to smoothly handle the dynamics and uncertainty caused by human motions. Markov Decision Processes (MDPs) serve as a common framework to formulate robot planning problems. However, because of its single-agent formulation, such planner cannot account for human reaction when evaluating robot actions. The robot can thus suffer from unsafe motions and move in ways that are hard for nearby humans to understand. To resolve this, we instead model robot planning in human workspaces as a Stochastic Game, and contribute a robust planning algorithm, which enables the robot to account for its prediction errors in human responses to prevent collision, while not losing agility, opposed to traditional maximin optimization techniques, by applying maximin operation only at \"critical states\". We validate the approach under partial knowledge of pedestrian behaviors, and show that our approach encounters zero collision despite imperfect prediction, while improving path efficiency, compared to baselines.",
        "primary_area": "",
        "author": "Shih-Yun Lo;Benito Fernandez;Peter Stone;Andrea L. Thomaz;Shih-Yun Lo;Benito Fernandez;Peter Stone;Andrea L. Thomaz",
        "authorids": "/37087323268;/37342269600;/37269574900;/37296354000;/37087323268;/37342269600;/37269574900;/37296354000",
        "aff": "University of Texas at Austin; University of Texas at Austin; Sony AI; University of Texas at Austin",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561622/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11730705547423035222&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of Texas at Austin;Sony",
        "aff_unique_dep": ";Sony AI",
        "aff_unique_url": "https://www.utexas.edu;https://www.sony.com",
        "aff_unique_abbr": "UT Austin;Sony AI",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9561113",
        "title": "Towards a Multi-imager Compatible Continuum Robot with Improved Dynamics Driven by Modular SMA",
        "track": "main",
        "status": "Poster",
        "abstract": "Most existing surgical robots employ straight rigid instruments and are not compatible with imaging modalities, especially magnetic resonance imaging (MRI) that presents restrictive constraints on the robot and actuator materials. Employing continuum distal end effector and fulfilling multi-imager compatibility will potentially lead to wide adoption of surgical robots in intraoperative image-guided minimally invasive surgery (MIS). This paper introduces a 3-dimensional (3D) printed polyamide continuum robot with 2-degree of freedom, driven by modular shape memory alloy (SMA) spring actuators that enable real-time distal manipulation in 3D workspace. The multi-imager compatibility is conditionally satisfied by utilizing no ferromagnetic materials and MRI-conditional actuators in the robotic system. The use of modular SMA allows repeatable configuration setting, easy integration with active cooling strategies, and facilitates the creation of a sterile barrier between the end effector module and the actuation module. Detailed design of the robot, kinematics modeling and actuator modeling are discussed in the paper. We experimentally verified the robot kinematics and evaluated the dynamic performance of the continuum robot. It features an operating bandwidth of 0.12 Hz at -3 dB and a root-mean-square error of 0.98 mm under model predictive control when tracking sinusoidal signals, both with \u00b110 mm amplitude (distal bending angle of \u00b180\u25e6). As a demonstration, the robot was used as a flexible endoscope manipulator and steered under inputs from a joystick to show its real-time performance.",
        "primary_area": "",
        "author": "Qingpeng Ding;Yongkang Lu;Andre Kyme;Shing Shin Cheng;Qingpeng Ding;Yongkang Lu;Andre Kyme;Shing Shin Cheng",
        "authorids": "/37087466874;/37088928392;/37398213900;/37085474625;/37087466874;/37088928392;/37398213900;/37085474625",
        "aff": "Department of Mechanical and Automation Engineering, CUHK T Stone Robotics Institute, The Chinese University of Hong Kong; Department of Mechanical and Automation Engineering, CUHK T Stone Robotics Institute, The Chinese University of Hong Kong; School of Biomedical Engineering, The University of Sydney, Sydney, NSW, Australia; Shun Hing Institute of Advanced Engineering and Multi-Scale Medical Robotics Center, The Chinese University of Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561113/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16758912692661777096&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "Chinese University of Hong Kong;University of Sydney",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering;School of Biomedical Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk;https://www.sydney.edu.au",
        "aff_unique_abbr": "CUHK;USYD",
        "aff_campus_unique_index": "0;0;1;0",
        "aff_campus_unique": "Hong Kong SAR;Sydney",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "China;Australia"
    },
    {
        "id": "9561207",
        "title": "Towards an Online RRT-based Path Planning Algorithm for Ackermann-steering Vehicles",
        "track": "main",
        "status": "Poster",
        "abstract": "It is challenging to develop an online path planning algorithm for Ackermann-steering vehicles to find collision-free and kinematically-feasible paths, that is efficient for dense environments, adaptable to various environments, and suitable for environments with narrow passages. In this paper, we propose a kinematically constrained RRT-based path planning algorithm integrating with a trajectory parameter space (TP-space) with three novel improvements to meet the above requirements. In specific, we introduce a new way to choose candidate nodes to expand the tree for an RRT-based algorithm, which can significantly increase the success rate of the expansion and improve the efficiency of the algorithm. We also introduce a procedure to incrementally adjust the step size for the expansion, which enables the algorithm to automatically adapt to various environments. At last, we integrate rapidly-exploring random vines (RRV) with a TP-space to handle kinematic constraints and improve the performance of the algorithm to expand the tree through a narrow passage. We also prove that the algorithm is probabilistic complete and asymptotically near-optimal. An ablation study shows that all three improvements can notably improve the performance of the RRT-based path planning algorithm. We also evaluate the algorithm in various environments. The experimental results show that our algorithm achieves competitive performance compared with the state-of-the-art. The source code is available at https://github.com/PengJieb/fastbkrrt.",
        "primary_area": "",
        "author": "Jie Peng;Yu\u2019An Chen;Yifan Duan;Yu Zhang;Jianmin Ji;Yanyong Zhang;Jie Peng;Yu\u2019An Chen;Yifan Duan;Yu Zhang;Jianmin Ji;Yanyong Zhang",
        "authorids": "/37088996658;/37089920466;/37086559317;/37090021868;/38100458700;/37279961200;/37088996658;/37089920466;/37086559317;/37090021868;/38100458700;/37279961200",
        "aff": "School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China; School of Computer Science and Technology, University of Science and Technology of China, Hefei, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561207/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14102696361249623444&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "University of Science and Technology of China",
        "aff_unique_dep": "School of Computer Science and Technology",
        "aff_unique_url": "http://www.ustc.edu.cn",
        "aff_unique_abbr": "USTC",
        "aff_campus_unique_index": "0;0;0;0;0;0",
        "aff_campus_unique": "Hefei",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561448",
        "title": "Towards efficient human-robot cooperation for socially-aware robot navigation in human-populated environments: the SNAPE framework",
        "track": "main",
        "status": "Poster",
        "abstract": "It is widely accepted that in the future, robots will cooperate with humans in everyday tasks. Robots interacting with humans will require social awareness when performing their tasks which will require navigation. While navigating, robots should aim to avoid distressing people in order to maximize their chance of social acceptance. For instance, avoiding getting too close to people or disrupting interactions. Most research approaches these problems by planning socially accepted paths, however, in everyday situations, there are many examples where a simple path planner cannot solve all of the predicted robots\u2019 navigation problems. For instance, requesting permission to interrupt a conversation if an alternative path cannot be determined requires deliberative skills. This article presents the Social Navigation framework for Autonomous robots in Populated Environments (SNAPE), where different software agents are integrated within a robotics cognitive architecture. SNAPE addresses action planning aimed at social-awareness navigation in realistic situations: it plans socially accepted paths and conversations to negotiate its trajectory to reach targets. In this article, the framework is evaluated in different use-cases where the robot, during its navigation, has to interact with different people in order to reach its goal. The results show that participants report that the robot\u2019s behavior was realistic and human-like.",
        "primary_area": "",
        "author": "A. Vega-Magro;R. Gondkar;L.J. Manso;P. N\u00fa\u00f1ez;A. Vega-Magro;R. Gondkar;L.J. Manso;P. N\u00fa\u00f1ez",
        "authorids": "/37086328777;/37089001911;/37085590710;/38362484300;/37086328777;/37089001911;/37085590710;/38362484300",
        "aff": "Robotics and Artificial Vision Lab. RoboLab Group, University of Extremadura, Spain; Pune Institute of Computer Technology, Pune University, India; College of Engineering and Physical Sciences, Aston University, Birmingham, UK; Robotics and Artificial Vision Lab. RoboLab Group, University of Extremadura, Spain",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561448/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9431509758819461018&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;0",
        "aff_unique_norm": "University of Extremadura;Pune University;Aston University",
        "aff_unique_dep": "Robotics and Artificial Vision Lab;Pune Institute of Computer Technology;College of Engineering and Physical Sciences",
        "aff_unique_url": "https://www.unex.es;https://www.puneuniversity.ac.in;https://www.aston.ac.uk",
        "aff_unique_abbr": ";Pune Univ;Aston",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Pune;Birmingham",
        "aff_country_unique_index": "0;1;2;0",
        "aff_country_unique": "Spain;India;United Kingdom"
    },
    {
        "id": "9561350",
        "title": "Towards integrated tactile sensorimotor control in anthropomorphic soft robotic hands",
        "track": "main",
        "status": "Poster",
        "abstract": "In this work, we report on how a sense of touch can be used to control an underactuated anthropomorphic robot hand, based on an integration that respects the hand\u2019s mechanical functionality. Our focus is on integrating the sensorimotor control of the Pisa/IIT SoftHand, an anthropomorphic soft robot hand designed around the principle of adaptive synergies, with the BRL tactile fingertip (TacTip), a soft biomimetic optical tactile sensor. We consider: (i) closed-loop tactile control to establish a light contact on an unknown held object, based on the structural similarity of the tactile image; and (ii) controlling the estimated pose of a held object, using a convolutional neural network approach developed for other TacTip sensors. Accurate control was found for a range of hard and soft objects (to sub-millimetre accuracy and a few degrees). Overall, this gives a foundation to endow soft robotic hands with human-like touch, with implications for autonomous grasping, manipulation, human-robot interaction and prosthetics.",
        "primary_area": "",
        "author": "Nathan F. Lepora;Chris Ford;Andrew Stinchcombe;Alfred Brown;John Lloyd;Manuel G. Catalano;Matteo Bianchi;Benjamin Ward-Cherrier;Nathan F. Lepora;Chris Ford;Andrew Stinchcombe;Alfred Brown;John Lloyd;Manuel G. Catalano;Matteo Bianchi;Benjamin Ward-Cherrier",
        "authorids": "/37399610200;/37089000013;/37085667415;/37088996425;/37089123940;/37544547800;/37394737700;/37085617128;/37399610200;/37089000013;/37085667415;/37088996425;/37089123940;/37544547800;/37394737700;/37085617128",
        "aff": "Department of Engineering Mathematics, Bristol Robotics Laboratory, University of Bristol, U.K.; Department of Engineering Mathematics, Bristol Robotics Laboratory, University of Bristol, U.K.; Department of Engineering Mathematics, Bristol Robotics Laboratory, University of Bristol, U.K.; Department of Engineering Mathematics, Bristol Robotics Laboratory, University of Bristol, U.K.; Department of Engineering Mathematics, Bristol Robotics Laboratory, University of Bristol, U.K.; Centro di Ricerca E. Piaggio e Dipartimento di Ingegneria Dell\u2019Informazione, Universit di Pisa, Pisa, Italia; Istituto Italiano di Tecnologia, Genova, Italia; Department of Engineering Mathematics, Bristol Robotics Laboratory, University of Bristol, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561350/",
        "gs_citation": 29,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=30223505062741245&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;0;0;0;0;1;2;0",
        "aff_unique_norm": "University of Bristol;Universit di Pisa;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Engineering Mathematics;Dipartimento di Ingegneria Dell\u2019Informazione;",
        "aff_unique_url": "https://www.bristol.ac.uk;https://www.unipi.it;https://www.iit.it",
        "aff_unique_abbr": "UoB;;IIT",
        "aff_campus_unique_index": "0;0;0;0;0;1;2;0",
        "aff_campus_unique": "Bristol;Pisa;Genova",
        "aff_country_unique_index": "0;0;0;0;0;1;1;0",
        "aff_country_unique": "United Kingdom;Italy"
    },
    {
        "id": "9562003",
        "title": "Towards providing explanations for robot motion planning",
        "track": "main",
        "status": "Poster",
        "abstract": "Recent research in AI ethics has put forth explainability as an essential principle for AI algorithms. However, it is still unclear how this is to be implemented in practice for specific classes of algorithms\u2014such as motion planners. In this paper we unpack the concept of explanation in the context of motion planning, introducing a new taxonomy of kinds and purposes of explanations in this context. We focus not only on explanations of failure (previously addressed in motion planning literature) but also on contrastive explanations\u2014which explain why a trajectory A was returned by a planner, instead of a different trajectory B expected by the user. We develop two explainable motion planners, one based on optimization, the other on sampling, which are capable of answering failure and constrastive questions. We use simulation experiments and a user study to motivate a technical and social research agenda.",
        "primary_area": "",
        "author": "Martim Brand\u00e3o;Gerard Canal;Senka Krivi\u0107;Daniele Magazzeni;Martim Brand\u00e3o;Gerard Canal;Senka Krivi\u0107;Daniele Magazzeni",
        "authorids": "/38542529000;/37085687945;/38547942700;/37396815200;/38542529000;/37085687945;/38547942700;/37396815200",
        "aff": "King's College, London, UK; King's College, London, UK; King's College, London, UK; King's College, London, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562003/",
        "gs_citation": 37,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11128876455893293567&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "King's College London",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.kcl.ac.uk",
        "aff_unique_abbr": "KCL",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "London",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561322",
        "title": "Towards the Unification of System Design and Motion Synthesis for High-Performance Hopping Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic hopping requires high performance and precision, due to its extreme interactions with the environment. Designing a system that will perform optimally, or even stably, for this motion primitive is a significant challenge. In previous work, it was shown that designing a robot with two springs (one in series and one in parallel with the actuator) could dramatically improve performance. However, selecting these springs was an intricate process since their dynamics were tightly coupled, and accomplished through trial and error. This work presents a general optimization framework for interconnected systems that designs the time-based hopping motion, while also designing the shape of nonlinear springs on the robot to yield efficient hopping. Utilizing this method, hopping motions and spring designs were generated simultaneously and experimentally verified on a novel hopping robot.",
        "primary_area": "",
        "author": "Eric Ambrose;Wen-Loong Ma;Aaron D. Ames;Eric Ambrose;Wen-Loong Ma;Aaron D. Ames",
        "authorids": "/37086010769;/37085547381;/37300877900;/37086010769;/37085547381;/37300877900",
        "aff": "Department of Mechanical Engineering; Department of Mechanical Engineering; Faculty of the Department of Control and Dynamical Systems, California Institute of Technology, Pasadena, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561322/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6644465795187220450&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;1",
        "aff_unique_norm": "Mechanical Engineering;California Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering;Department of Control and Dynamical Systems",
        "aff_unique_url": ";https://www.caltech.edu",
        "aff_unique_abbr": ";Caltech",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Pasadena",
        "aff_country_unique_index": "1",
        "aff_country_unique": ";United States"
    },
    {
        "id": "9561760",
        "title": "Tracking 6-DoF Object Motion from Events and Frames",
        "track": "main",
        "status": "Poster",
        "abstract": "Event cameras are promising devices for low latency tracking and high-dynamic range imaging. In this paper, we propose a novel approach for 6 degree-of-freedom (6-DoF) object motion tracking that combines measurements of event and frame-based cameras. We formulate tracking from high rate events with a probabilistic generative model of the event measurement process of the object. On a second layer, we refine the object trajectory in slower rate image frames through direct image alignment. We evaluate the accuracy of our approach in several object tracking scenarios with synthetic data, and also perform experiments with real data.",
        "primary_area": "",
        "author": "Haolong Li;Joerg Stueckler;Haolong Li;Joerg Stueckler",
        "authorids": "/37088996982;/37088215404;/37088996982;/37088215404",
        "aff": "Embodied Vision Group, Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany; Embodied Vision Group, Max Planck Institute for Intelligent Systems, T\u00fcbingen, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561760/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5831149746658113389&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Max Planck Institute for Intelligent Systems",
        "aff_unique_dep": "Embodied Vision Group",
        "aff_unique_url": "https://www.mpituebingen.mpg.de",
        "aff_unique_abbr": "MPI-IS",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "T\u00fcbingen",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561012",
        "title": "Tracking Partially-Occluded Deformable Objects while Enforcing Geometric Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to manipulate a deformable object, such as rope or cloth, in unstructured environments, robots need a way to estimate its current shape. However, tracking the shape of a deformable object can be challenging because of the object\u2019s high flexibility, (self-)occlusion, and interaction with obstacles. Building a high-fidelity physics simulation to aid in tracking is difficult for novel environments. Instead we focus on tracking the object based on RGBD images and geometric motion estimates and obstacles. Our key contributions over previous work in this vein are: 1) A better way to handle severe occlusion by using a motion model to regularize the tracking estimate; and 2) The formulation of convex geometric constraints, which allow us to prevent self-intersection and penetration into known obstacles via a post-processing step. These contributions allow us to outperform previous methods by a large margin in terms of accuracy in scenarios with severe occlusion and obstacles.",
        "primary_area": "",
        "author": "Yixuan Wang;Dale McConachie;Dmitry Berenson;Yixuan Wang;Dale McConachie;Dmitry Berenson",
        "authorids": "/37089002307;/37086401419;/37542925700;/37089002307;/37086401419;/37542925700",
        "aff": "University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA; University of Michigan, Ann Arbor, MI, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561012/",
        "gs_citation": 57,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14660196671677115442&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Michigan",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.umich.edu",
        "aff_unique_abbr": "UM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Ann Arbor",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561362",
        "title": "Trajectory Optimisation in Learned Multimodal Dynamical Systems via Latent-ODE Collocation",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a two-stage method to perform trajectory optimisation in multimodal dynamical systems with unknown nonlinear stochastic transition dynamics. The method finds trajectories that remain in a preferred dynamics mode where possible and in regions of the transition dynamics model that have been observed and can be predicted confidently. The first stage leverages a Mixture of Gaussian Process Experts method to learn a predictive dynamics model from historical data. Importantly, this model learns a gating function that indicates the probability of being in a particular dynamics mode at a given state location. This gating function acts as a coordinate map for a latent Riemannian manifold on which shortest trajectories are solutions to our trajectory optimisation problem. Based on this intuition, the second stage formulates a geometric cost function, which it then implicitly minimises by projecting the trajectory optimisation onto the second-order geodesic ODE; a classic result of Riemannian geometry. A set of collocation constraints are derived that ensure trajectories are solutions to this ODE, implicitly solving the trajectory optimisation problem.",
        "primary_area": "",
        "author": "Aidan Scannell;Carl Henrik Ek;Arthur Richards;Aidan Scannell;Carl Henrik Ek;Arthur Richards",
        "authorids": "/37089002017;/38230612800;/37299756300;/37089002017;/38230612800;/37299756300",
        "aff": "University of Bristol; University of Cambridge; University of Bristol",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561362/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12395300707810330790&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "University of Bristol;University of Cambridge",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.bristol.ac.uk;https://www.cam.ac.uk",
        "aff_unique_abbr": "Bristol;Cambridge",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561556",
        "title": "Trajectory Optimization for Manipulation of Deformable Objects: Assembly of Belt Drive Units",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel trajectory optimization formulation to solve the robotic assembly of the belt drive unit. Robotic manipulations involving contacts and deformable objects are challenging in both dynamic modeling and trajectory planning. For modeling, variations in the belt tension and contact forces between the belt and the pulley could dramatically change the system dynamics. For trajectory planning, it is computationally expensive to plan trajectories for such hybrid dynamical systems as it usually requires planning for discrete modes separately. In this work, we formulate the belt drive unit assembly task as a trajectory optimization problem with complementarity constraints to avoid explicitly imposing contact mode sequences. The problem is solved as a mathematical program with complementarity constraints (MPCC) to obtain feasible and efficient assembly trajectories. We validate the proposed method both in simulations with a physics engine and in real-world experiments with a robotic manipulator.",
        "primary_area": "",
        "author": "Shiyu Jin;Diego Romeres;Arvind Ragunathan;Devesh K. Jha;Masayoshi Tomizuka;Shiyu Jin;Diego Romeres;Arvind Ragunathan;Devesh K. Jha;Masayoshi Tomizuka",
        "authorids": "/37087321850;/37086098761;/37089001723;/37072717800;/37281933000;/37087321850;/37086098761;/37089001723;/37072717800;/37281933000",
        "aff": "University of California, Berkeley; Mitsubishi Electric Research Laboratories; Mitsubishi Electric Research Laboratories; Mitsubishi Electric Research Laboratories; University of California, Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561556/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17189557760238821606&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;1;1;0",
        "aff_unique_norm": "University of California, Berkeley;Mitsubishi Electric Research Laboratories",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.merl.com",
        "aff_unique_abbr": "UC Berkeley;MERL",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562014",
        "title": "Transition Motion Planning for Multi-Limbed Vertical Climbing Robots Using Complementarity Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to achieve autonomous vertical wall climbing, the transition phase from the ground to the wall requires extra consideration inevitably. This paper focuses on the contact sequence planner to transition between flat terrain and vertical surfaces for multi-limbed climbing robots. To overcome the transition phase, it requires planning both multicontact and contact wrenches simultaneously which makes it difficult. Instead of using a predetermined contact sequence, we consider various motions on different environment setups via modeling contact constraints and limb switchability as complementarity conditions. Two safety factors for toe sliding and motor over-torque are the main tuning parameters for different contact sequences. By solving as a nonlinear program (NLP), we can generate several feasible sequences of foot placements and contact forces to avoid failure cases. We verified feasibility with demonstrations on the hardware SiLVIA, a sixlegged robot capable of vertically climbing between two walls by bracing itself in-between using only friction.",
        "primary_area": "",
        "author": "Jingwen Zhang;Xuan Lin;Dennis W Hong;Jingwen Zhang;Xuan Lin;Dennis W Hong",
        "authorids": "/37087323024;/37085891795;/37575333900;/37087323024;/37085891795;/37575333900",
        "aff": "Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles, CA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles, CA; Department of Mechanical and Aerospace Engineering, Robotics and Mechanisms Laboratory (RoMeLa), University of California, Los Angeles, CA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562014/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4785397142377078879&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of California, Los Angeles",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.ucla.edu",
        "aff_unique_abbr": "UCLA",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Los Angeles",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561895",
        "title": "Tree Search-based Task and Motion Planning with Prehensile and Non-prehensile Manipulation for Obstacle Rearrangement in Clutter",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a tree search-based planning algorithm for a robot manipulator to rearrange objects and grasp a target in a dense space. We consider environments where tasks cannot be completed with prehensile planning only. As assuming that a manipulator is only allowed to grasp from the top, we aim to minimize the number of rearrangement actions and the total execution time, which affects the efficiency of manipulation. The proposed search algorithm determines the optimal sequence of object rearrangement with prehensile and non-prehensile grasping until grasping a target. For non-prehensile grasping, a heuristic function is employed to model frictions and contacts between objects and a table. Experimental results in a realistic simulated environment show that the proposed algorithm can reduce the number of rearranged obstacles up to 27% and the total execution time up to 15% with 14 objects compared to the previous work.",
        "primary_area": "",
        "author": "Jinhwi Lee;Changjoo Nam;Jonghyeon Park;Changhwan Kim;Jinhwi Lee;Changjoo Nam;Jonghyeon Park;Changhwan Kim",
        "authorids": "/37086921318;/37086294341;/37367641100;/37292328800;/37086921318;/37086294341;/37367641100;/37292328800",
        "aff": "Graduate School of Hanyang University, Seoul, Korea; Division of Information and Communication Engineering, Inha University, Incheon, Korea; Division of Mechanical Engineering, Hanyang University, Seoul, Korea; Korea Institute of Science and Technology, Seoul, Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561895/",
        "gs_citation": 25,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13699206277403759570&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "Hanyang University;Inha University;Korea Institute of Science and Technology",
        "aff_unique_dep": "Graduate School;Division of Information and Communication Engineering;",
        "aff_unique_url": "http://www.hanyang.ac.kr;https://www.inha.edu;https://www.kist.re.kr",
        "aff_unique_abbr": "HYU;Inha U;KIST",
        "aff_campus_unique_index": "0;1;0;0",
        "aff_campus_unique": "Seoul;Incheon",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561649",
        "title": "Two-Stage Clustering of Human Preferences for Action Prediction in Assembly Tasks",
        "track": "main",
        "status": "Poster",
        "abstract": "To effectively assist human workers in assembly tasks a robot must proactively offer support by inferring their preferences in sequencing the task actions. Previous work has focused on learning the dominant preferences of human workers for simple tasks largely based on their intended goal. However, people may have preferences at different resolutions: they may share the same high-level preference for the order of the sub-tasks but differ in the sequence of individual actions. We propose a two-stage approach for learning and inferring the preferences of human operators based on the sequence of sub-tasks and actions. We conduct an IKEA assembly study and demonstrate how our approach is able to learn the dominant preferences in a complex task. We show that our approach improves the prediction of human actions through cross-validation. Lastly we show that our two-stage approach improves the efficiency of task execution in an online experiment and demonstrate its applicability in a real-world robot-assisted IKEA assembly.",
        "primary_area": "",
        "author": "Heramb Nemlekar;Jignesh Modi;Satyandra K. Gupta;Stefanos Nikolaidis;Heramb Nemlekar;Jignesh Modi;Satyandra K. Gupta;Stefanos Nikolaidis",
        "authorids": "/37086933305;/37088918612;/37878971100;/37643766400;/37086933305;/37088918612;/37878971100;/37643766400",
        "aff": "University of Southern California, USA; University of Southern California, USA; University of Southern California, USA; University of Southern California, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561649/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5669062890821591246&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Southern California",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.usc.edu",
        "aff_unique_abbr": "USC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561752",
        "title": "Two-Stage Trajectory Optimization for Flapping Flight with Data-Driven Models",
        "track": "main",
        "status": "Poster",
        "abstract": "Underactuated robots often require involved routines for trajectory planning due to their complex dynamics. Flapping-wing aerial vehicles have unsteady aerodynamics and periodic gaits that complicate the planning procedure. In this paper, we improve upon existing methods for flight planning by introducing a two-stage optimization routine to plan flapping flight trajectories. The first stage solves a trajectory optimization problem with a data-driven fixed-wing approximation model trained with experimental flight data. The solution to this is used as the initial guess for a second stage optimization using a flapping-wing model trained with the same flight data. We demonstrate the effectiveness of this approach with a bat robot in both simulation and experimental flight results. The speed of convergence, the dependency on the initial guess, and the quality of the solution are improved, and the robot is able to track the optimized trajectory of a dive maneuver.",
        "primary_area": "",
        "author": "Jonathan Hoff;Joohyung Kim;Jonathan Hoff;Joohyung Kim",
        "authorids": "/37087321873;/37085576403;/37087321873;/37085576403",
        "aff": "Coordinated Science Laboratory and Department of Electrical and Computer Engineering, University of Illinois Urbana-Champaign, Urbana, IL, USA; Coordinated Science Laboratory and Department of Electrical and Computer Engineering, University of Illinois Urbana-Champaign, Urbana, IL, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561752/",
        "gs_citation": 4,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8401012186262570252&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Illinois Urbana-Champaign",
        "aff_unique_dep": "Department of Electrical and Computer Engineering",
        "aff_unique_url": "https://illinois.edu",
        "aff_unique_abbr": "UIUC",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Urbana",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561308",
        "title": "Two-stream 2D/3D Residual Networks for Learning Robot Manipulations from Human Demonstration Videos",
        "track": "main",
        "status": "Poster",
        "abstract": "Learning manipulation skills from observing human demonstration videos is a promising aspect for intelligent robotic systems. Recent advances in video to command provide an end-to-end approach to translate a video into robot plans. However, the general video captioning methods focus more on the understanding of the full frame, while they lack the consideration of the spatio-temporal features in videos. In this paper, we proposed the two-stream 2D/3D residual networks for robots to learn manipulation tasks from human demonstration videos. We integrate spatial features with 2D residual network and temporal features with 3D residual network as inputs for RNN layers. An encoder-decoder architecture is then used to encode the spatio-temporal features and sequentially generate the command words. Experimental results on an extended manipulation dataset show that our approach outperforms the state-of-the-art methods. Real-world experiments results on a Baxter robotic arm indicate that our method could produce more accurate commands from video demonstrations.",
        "primary_area": "",
        "author": "Xin Xu;Kun Qian;Bo Zhou;Shenghao Chen;Yitong Li;Xin Xu;Kun Qian;Bo Zhou;Shenghao Chen;Yitong Li",
        "authorids": "/37089001361;/37543700600;/37957753600;/37088758811;/37088997697;/37089001361;/37543700600;/37957753600;/37088758811;/37088997697",
        "aff": "School of Automation, Southeast University and the Key Laboratory of Measurement and Control of CSE, Ministry of Education, Nanjing, China; School of Automation, Southeast University and the Key Laboratory of Measurement and Control of CSE, Ministry of Education, Nanjing, China; School of Automation, Southeast University and the Key Laboratory of Measurement and Control of CSE, Ministry of Education, Nanjing, China; School of Automation, Southeast University and the Key Laboratory of Measurement and Control of CSE, Ministry of Education, Nanjing, China; School of Automation, Southeast University and the Key Laboratory of Measurement and Control of CSE, Ministry of Education, Nanjing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561308/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5611936608259650654&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Southeast University",
        "aff_unique_dep": "School of Automation",
        "aff_unique_url": "https://www.seu.edu.cn/",
        "aff_unique_abbr": "SEU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Nanjing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561688",
        "title": "UAV Target-Selection: 3D Pointing Interface System for Large-Scale Environment",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a 3D pointing interface application to signal a UAV\u2019s target in a large-scale environment. This system enables UAVs equipped with a monocular camera to determine which window of a building is selected by a human user in large-scale indoor or outdoor environments. The 3D pointing interface consists of three parts: YOLO, Open- Pose, and ORB-SLAM. YOLO detects the target objects, e.g., windows, OpenPose extracts the user pose, and ORB-SLAM builds a scale-dependent 3D map, a set of 3D sparse feature points. To obtain the visual scale, it performs a calibration step with the user standing in front of the UAV at a certain distance. We detail how we chose the gesture, localize and detect objects, and transform between coordinate systems. The real- world experiment results showed that the 3D pointing interface obtained a 0.73 F1-score average and a 0.58 F1-Score at the maximum distance of 25 meters between UAV and building.",
        "primary_area": "",
        "author": "Anna C. S. Medeiros;Photchara Ratsamee;Jason Orlosky;Yuki Uranishi;Manabu Higashida;Haruo Takemura;Anna C. S. Medeiros;Photchara Ratsamee;Jason Orlosky;Yuki Uranishi;Manabu Higashida;Haruo Takemura",
        "authorids": "/37089000046;/38467126100;/37073565700;/37669830300;/37688927200;/37269924100;/37089000046;/38467126100;/37073565700;/37669830300;/37688927200;/37269924100",
        "aff": "Cyber Media Center, Osaka University, Japan; Cyber Media Center, Osaka University, Japan; Cyber Media Center, Osaka University, Japan; Cyber Media Center, Osaka University, Japan; Cyber Media Center, Osaka University, Japan; Cyber Media Center, Osaka University, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561688/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11636427556555879096&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Osaka University",
        "aff_unique_dep": "Cyber Media Center",
        "aff_unique_url": "https://www.osaka-u.ac.jp",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9560780",
        "title": "ULT-model: Towards a one-legged unified locomotion template model for forward hopping with an upright trunk",
        "track": "main",
        "status": "Poster",
        "abstract": "While many advancements have been made in the development of template models for describing upright-trunk locomotion, the majority of the effort has been focused on the stance phase. In this paper, we develop a new compact dynamic model as a first step toward a fully unified locomotion template model (ULT-model) of an upright-trunk forward hopping system, which will also require a unified control law in the next step. We demonstrate that all locomotion subfunctions are enabled by adding just a point foot mass and a parallel leg actuator to the well-known trunk SLIP model and that a stable limit cycle can be achieved. This brings us closer toward the ultimate goal of enabling closed-loop dynamics for anchor matching and thus achieving simple, efficient, robust and stable upright-trunk gait control, as observed in biological systems.",
        "primary_area": "",
        "author": "Dennis Ossadnik;Elisabeth Jensen;Sami Haddadin;Dennis Ossadnik;Elisabeth Jensen;Sami Haddadin",
        "authorids": "/37086601649;/37967991000;/37542865300;/37086601649;/37967991000;/37542865300",
        "aff": "Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany; Munich School of Robotics and Machine Intelligence, Technical University of Munich, Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560780/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3737860032423789203&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Technical University of Munich",
        "aff_unique_dep": "Munich School of Robotics and Machine Intelligence",
        "aff_unique_url": "https://www.tum.de",
        "aff_unique_abbr": "TUM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Munich",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561051",
        "title": "UMLE: Unsupervised Multi-discriminator Network for Low Light Enhancement",
        "track": "main",
        "status": "Poster",
        "abstract": "Low-light image enhancement is a complex and vital task including, recovering color and texture details from low-light images. For automated driving, low-light scenarios will have severe implications for vision-based applications. To address this problem, we propose a real-time unsupervised generative adversarial network (GAN) with multiple discriminators. It includes a multi-scale discriminator, a texture discriminator, and a color discriminator to evaluate images from different perspectives. Furthermore, considering the uneven illumination distribution of images and the different information contained in the channels, we adopte a feature fusion attention module to combine channel attention with pixel attention to extract image features. Experiments show that our method outperforms state-of-the-art methods in qualitative and quantitative evaluation and provides visible improvements in SLAM localization effects.",
        "primary_area": "",
        "author": "Yangyang Qu;Kai Chen;Chao Liu;Yongsheng Ou;Yangyang Qu;Kai Chen;Chao Liu;Yongsheng Ou",
        "authorids": "/37087245196;/37085906757;/37089393368;/37264969100;/37087245196;/37085906757;/37089393368;/37264969100",
        "aff": "CAS Key Laboratory of Human-Machine Intelligence Synergic Systems, Shenzhen Institutes of Advanced Technology, Shenzhen, China; CAS Key Laboratory of Human-Machine Intelligence Synergic Systems, Shenzhen Institutes of Advanced Technology, Shenzhen, China; CAS Key Laboratory of Human-Machine Intelligence Synergic Systems, Shenzhen Institutes of Advanced Technology, Shenzhen, China; CAS Key Laboratory of Human-Machine Intelligence Synergic Systems, Shenzhen Institutes of Advanced Technology, Shenzhen, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561051/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3813951458836096035&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shenzhen Institute of Advanced Technology",
        "aff_unique_dep": "CAS Key Laboratory of Human-Machine Intelligence Synergic Systems",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenzhen",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561962",
        "title": "UPSLAM: Union of Panoramas SLAM",
        "track": "main",
        "status": "Poster",
        "abstract": "We present an empirical investigation of a new mapping system based on a graph of panoramic depth images. Panoramic images e\ufb03ciently capture range measurements taken by a spinning lidar sensor, recording fine detail on the order of a few centimeters within maps of expansive scope on the order of tens of millions of cubic meters. The flexibility of the system is demonstrated by running the same mapping software against data collected by hand-carrying a paired lidar and IMU around a laboratory space at walking pace, moving them outdoors through a campus environment at running pace, driving the sensors on a small wheeled vehicle on- and off-road, flying the sensors through a forest, carrying them on the back of a legged robot navigating an underground coal mine, and mounting them on the roof of a car driven on public roads. The full 3D maps are built online with a median update time of less than ten milliseconds on an embedded NVIDIA Jetson AGX Xavier system.",
        "primary_area": "",
        "author": "Anthony Cowley;Ian D. Miller;Camillo Jose Taylor;Anthony Cowley;Ian D. Miller;Camillo Jose Taylor",
        "authorids": "/37265334100;/37086928894;/37277248500;/37265334100;/37086928894;/37277248500",
        "aff": "GRASP Laboratory, School of Engineering and Applied Sciences, University of Pennsylvania, Philadelphia, PA; GRASP Laboratory, School of Engineering and Applied Sciences, University of Pennsylvania, Philadelphia, PA; GRASP Laboratory, School of Engineering and Applied Sciences, University of Pennsylvania, Philadelphia, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561962/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2769462144784212124&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Pennsylvania",
        "aff_unique_dep": "School of Engineering and Applied Sciences",
        "aff_unique_url": "https://www.upenn.edu",
        "aff_unique_abbr": "UPenn",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Philadelphia",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561208",
        "title": "UVIP: Robust UWB aided Visual-Inertial Positioning System for Complex Indoor Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Indoor positioning without GPS is a challenge task, especially, in complex scenes or when sensors fail. In this paper, we develop an ultra-wideband aided visual-inertial positioning system (UVIP) which aims to achieve accurate and robust positioning results in complex indoor environments. To this end, a point-line-based stereo visual-inertial odometry (PL-sVIO) is firstly designed to improve the positioning accuracy in structured or low-textured scenarios by making use of line features. Secondly, a loop closure method is proposed to suppress the drift of PL-sVIO based on image patch features described by a CNN for handing the situation of a large environment and viewpoint variation. Thirdly, an accurate relocalization approach is presented for the case when the visual sensor fails. In this scheme, a top-to-down matching strategy from image to point and line features is presented to improve relocalization performance. Finally, the UWB sensor is combined with the visual-inertial system to further improve the accuracy and robustness of the positioning system and provide the results in a fixed reference frame. Thus, desirable real-time positioning results are derived for complex indoor scenes. Evaluations on challenging public datasets and real-world experiments are conducted to demonstrate that the proposed UVIP can provide more accurate and robust positioning results in complex indoor environments, even in the case when the visual sensor fails or in the absence of UWB anchors.",
        "primary_area": "",
        "author": "Bo Yang;Jun Li;Hong Zhang;Bo Yang;Jun Li;Hong Zhang",
        "authorids": "/37086433969;/37086679680;/37280789900;/37086433969;/37086679680;/37280789900",
        "aff": "School of Artificial Intelligence, Nanjing University of Information Science & Technology, Nanjing, China; School of Computer and Electronic Information, Nanjing Normal University, Nanjing, China; University of Alberta, AB, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561208/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1199168298120243091&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Nanjing University of Information Science & Technology;Nanjing Normal University;University of Alberta",
        "aff_unique_dep": "School of Artificial Intelligence;School of Computer and Electronic Information;",
        "aff_unique_url": "http://www.nuist.edu.cn;http://www.nju.edu.cn;https://www.ualberta.ca",
        "aff_unique_abbr": "NUIST;NNU;UAlberta",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Nanjing;",
        "aff_country_unique_index": "0;0;1",
        "aff_country_unique": "China;Canada"
    },
    {
        "id": "9562031",
        "title": "UWB Indoor Global Localisation for Nonholonomic Robots with Unknown Offset Compensation",
        "track": "main",
        "status": "Poster",
        "abstract": "The problem addressed in this paper is the localisation of a mobile robot using a combination of on-board sensors and Ultra-Wideband (UWB) beacons. Specifically, we consider a scenario in which a mobile robot travels across an area infrastructured with a small number of UWB anchors. The presence of obstacles in the environment introduces an offset in the measurements of the distance between the robot and the UWB anchors causing a degradation in the localisation performance. By using a discrete\u2013time formulation of the system dynamics, we show that, under mild condition, the trajectories can be observed and the offset can be estimated in a finite number of steps. Besides being interesting in its on right, the global observability results offer a clear pathway towards the definition of a new generation of estimation algorithms.",
        "primary_area": "",
        "author": "Daniele Fontanelli;Farhad Shamsfakhr;Paolo Bevilacqua;Luigi Palopoli;Daniele Fontanelli;Farhad Shamsfakhr;Paolo Bevilacqua;Luigi Palopoli",
        "authorids": "/37398642200;/37088439054;/37085888306;/37268097200;/37398642200;/37088439054;/37085888306;/37268097200",
        "aff": "Dept. of Industrial Engineering, University of Trento, Trento, Italy; Dept. of Industrial Engineering, University of Trento, Trento, Italy; Dept. of Engineering and Computer Science, University of Trento, Trento, Italy; Dept. of Engineering and Computer Science, University of Trento, Trento, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562031/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12683300453004148866&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Trento",
        "aff_unique_dep": "Dept. of Industrial Engineering",
        "aff_unique_url": "https://www.unitn.it",
        "aff_unique_abbr": "UniTN",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Trento",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Italy"
    },
    {
        "id": "9561866",
        "title": "Ultrasound Doppler Imaging and Navigation of Collective Magnetic Cell Microrobots in Blood",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose ultrasound Doppler imaging and magnetic navigation of collective cell microrobots in whole blood. Cell microrobots are cultured using stem cells and iron microparticles, they have spheroidal structures and can be actuated under external magnetic fields. A collective of cell microrobots can be reversibly gathered and spread due to the tunable magnetic interaction, and are able to exhibit collective motion in whole blood under rotating magnetic fields. Simulation results indicate that the induced blood flow around the collective pattern affects the motion of red blood cells (RBCs), and experimental results show that Doppler signals are observed when emitting ultrasound waves to the microrobots. The induced Doppler signals are affected by the input field frequency and the ultrasound parameters (pulse repetition frequency). Due to the induced three-dimensional blood flow, Doppler signals can be observed when the imaging plane is above the collective microrobots, which enables indirect localization when performing navigation on an uneven surface. Our study investigates a strategy for pattern formation and navigation of collective microrobots under ultrasound Doppler imaging, demonstrating that the integration of collective control approach and medical imaging holds great potential for real-time active delivery tasks.",
        "primary_area": "",
        "author": "Qianqian Wang;Yuan Tian;Xingzhou Du;Kai-Fung Chan;Li Zhang;Qianqian Wang;Yuan Tian;Xingzhou Du;Kai-Fung Chan;Li Zhang",
        "authorids": "/37086080420;/37089001392;/37086593722;/37086593501;/37085379138;/37086080420;/37089001392;/37086593722;/37086593501;/37085379138",
        "aff": "Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong, China; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong (CUHK), Hong Kong, China; Department Biomedical Engineering, The Chinese University of Hong Kong, Hong Kong, China; Chow Yuk Ho Technology Centre for Innovative Medicine, The Chinese University of Hong Kong, Hong Kong, China; CUHK T Stone Robotics Institute, The Chinese University of Hong Kong, Shatin NT, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561866/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16427107379785088394&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.cuhk.edu.hk",
        "aff_unique_abbr": "CUHK",
        "aff_campus_unique_index": "0;0;0;0;1",
        "aff_campus_unique": "Hong Kong;Shatin NT",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561358",
        "title": "Uncertainty-Aware Fast Curb Detection Using Convolutional Networks in Point Clouds",
        "track": "main",
        "status": "Poster",
        "abstract": "Curb detection is an essential function of autonomous vehicles in urban areas. However, curbs are difficult to detect in complex urban environments in which many dynamic objects exist. Additionally, curbs appear in a variety of shapes and sizes. Previous studies have been based on the traditional pipeline, which consists of the extraction and aggregation of hand-crafted features that are then fed to classifiers. However, this sequential process is inefficient and designing the hand-crafted features is a complex process. Recently, this kind of process has been replaced by Deep Neural Networks (DNN), in which classifiers and features are learned from large-scale data. Very few works have exploited DNN for the curb detection problem. Most works use multi-modal sensor-based methods that combine images and accumulated 3D point clouds from LIDAR. However, these approaches require synchronization and calibration between sensors. In addition, they do not quantify the uncertainty of their predictions for autonomous system safety. In this paper, we present a two-stage DNN-based curb detection method that includes uncertainty quantification. An autoencoder-based network predicts the curbs, and then conditional neural processes rectify the predictions with uncertainty estimations. The experimental results show that our approach achieves high accuracy and recall in complex areas. We also constructed a large-scale dataset to create benchmarks consisting of approximately 5,224 scans with bird\u2019s-eye view labels collected from urban areas. To the best of our knowledge, there are no public datasets for DNN-based curb detectors. The benchmarks and datasets are publicly available at https://github.com/YounghwaJung/curb_detection_DNN.",
        "primary_area": "",
        "author": "Younghwa Jung;Mingu Jeon;Chan Kim;Seung-Woo Seo;Seong-Woo Kim;Younghwa Jung;Mingu Jeon;Chan Kim;Seung-Woo Seo;Seong-Woo Kim",
        "authorids": "/37088477860;/37088997960;/37089001231;/37271925900;/37537386000;/37088477860;/37088997960;/37089001231;/37271925900;/37537386000",
        "aff": "Seoul National University, South Korea; Seoul National University, South Korea; Seoul National University, South Korea; Seoul National University, South Korea; Seoul National University, South Korea",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561358/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16500122166957628876&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Seoul National University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.snu.ac.kr",
        "aff_unique_abbr": "SNU",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "South Korea"
    },
    {
        "id": "9561974",
        "title": "Uncertainty-aware Non-linear Model Predictive Control for Human-following Companion Robot",
        "track": "main",
        "status": "Poster",
        "abstract": "For a companion robot that follows a person as an assistant, predicting human walking is important to produce a proactive movement that is helpful to maintain an appropriate area decided by the human personal space. However, fully trusting the prediction may result in obstructing human walking because it is not always accurate. Hence, we consider the estimation of uncertainty (i.e., entropy) of the prediction to enable the robot to move without causing overconfident motion and without being late for the person it follows. To consider this uncertainty of the prediction to the controller, we introduce a reliability value that changes based on the entropy of the prediction. This value expresses the extent the controller should trust the prediction result, and it affects the cost function of our controller. We propose an uncertainty-aware robot controller based on nonlinear model predictive control to realize natural human-followings. We found that our uncertainty-aware control system can produce an appropriate robot movement, such as not obstructing the human walking and avoiding delay, in both simulations using actual human walking data and real-robot experiments.",
        "primary_area": "",
        "author": "Shunichi Sekiguchi;Ayanori Yorozu;Kazuhiro Kuno;Masaki Okada;Yutaka Watanabe;Masaki Takahashi;Shunichi Sekiguchi;Ayanori Yorozu;Kazuhiro Kuno;Masaki Okada;Yutaka Watanabe;Masaki Takahashi",
        "authorids": "/37088996551;/37085523671;/37088998867;/37089000973;/37089000802;/37275389800;/37088996551;/37085523671;/37088998867;/37089000973;/37089000802;/37275389800",
        "aff": "School of Science for Open and Environmental Systems, Graduate School of Science and Technology, Keio University, Yokohama, Japan; School of Science for Open and Environmental Systems, Graduate School of Science and Technology, Keio University, Yokohama, Japan; EQUOS Research Co., Ltd., Aichi, Japan; EQUOS Research Co., Ltd., Aichi, Japan; EQUOS Research Co., Ltd., Aichi, Japan; Department of System Design Engineering, Faculty of Science and Technology, Keio University, Yokohama, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561974/",
        "gs_citation": 16,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8819079920867558394&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;1;0",
        "aff_unique_norm": "Keio University;EQUOS Research Co., Ltd.",
        "aff_unique_dep": "School of Science for Open and Environmental Systems;",
        "aff_unique_url": "https://www.keio.ac.jp;",
        "aff_unique_abbr": "Keio;",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Yokohama;",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561728",
        "title": "Uncertainty-aware Self-supervised Target-mass Grasping of Granular Foods",
        "track": "main",
        "status": "Poster",
        "abstract": "Food packing industry workers typically pick a target amount of food by hand from a food tray and place them in containers. Since menus are diverse and change frequently, robots must adapt and learn to handle new foods in a short time-span. Learning to grasp a specific amount of granular food requires a large training dataset, which is challenging to collect reasonably quickly. In this study, we propose ways to reduce the necessary amount of training data by augmenting a deep neural network with models that estimate its uncertainty through self-supervised learning. To further reduce human effort, we devise a data collection system that automatically generates labels. We build on the idea that we can grasp sufficiently well if there is at least one low-uncertainty (high-confidence) grasp point among the various grasp point candidates. We evaluate the methods we propose in this work on a variety of granular foods-coffee beans, rice, oatmeal and peanuts, each of which has a different size, shape and material properties such as volumetric mass density or friction. For these foods, we show significantly improved grasp accuracy of user-specified target masses using smaller datasets by incorporating uncertainty.",
        "primary_area": "",
        "author": "Kuniyuki Takahashi;Wilson Ko;Avinash Ummadisingu;Shin-ichi Maeda;Kuniyuki Takahashi;Wilson Ko;Avinash Ummadisingu;Shin-ichi Maeda",
        "authorids": "/37086937050;/37089000992;/37088690436;/37325826000;/37086937050;/37089000992;/37088690436;/37325826000",
        "aff": "Associated with Preferred Networks, Inc; Associated with Preferred Networks, Inc; Associated with Preferred Networks, Inc; Associated with Preferred Networks, Inc",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561728/",
        "gs_citation": 28,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5042050244025000106&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Preferred Networks, Inc",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.preferred-networks.com",
        "aff_unique_abbr": "PFN",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9562077",
        "title": "Uncertainty-aware deep learning for robot touch: Application to Bayesian tactile servo control",
        "track": "main",
        "status": "Poster",
        "abstract": "This work investigates uncertainty-aware deep learning (DL) in tactile robotics based on a general framework introduced recently for robot vision. For a test scenario, we consider optical tactile sensing in combination with DL to estimate the edge pose as a feedback signal to servo around various 2D test objects. We demonstrate that uncertainty-aware DL can improve the pose estimation over deterministic DL methods. The system estimates the uncertainty associated with each prediction, which is used along with temporal coherency to improve the predictions via a Kalman filter, and hence improve the tactile servo control. The robot is able to robustly follow all of the presented contour shapes to reduce not only the error by a factor of two but also smooth the trajectory from the undesired noisy behaviour caused by previous deterministic networks. In our view, as the field of tactile robotics matures in its use of DL, the estimation of uncertainty will become a key component in the control of physically interactive tasks in complex environments.",
        "primary_area": "",
        "author": "Manuel Floriano V\u00e1zquez;Nathan F. Lepora;Manuel Floriano V\u00e1zquez;Nathan F. Lepora",
        "authorids": "/37089002139;/37399610200;/37089002139;/37399610200",
        "aff": "University of Bristol; Department of Engineering Mathematics, Bristol Robotics Laboratory, University of Bristol, Bristol, U.K.",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562077/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6491798056610125872&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Bristol",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.bristol.ac.uk",
        "aff_unique_abbr": "Bristol",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Bristol",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9562032",
        "title": "Underwater Stability of a Morphable Aerial-Aquatic Quadrotor With Variable Thruster Angles",
        "track": "main",
        "status": "Poster",
        "abstract": "The design of aerial-aquatic multirotors can benefit from thruster rotation so that the thrusters can act directly in the lateral directions of surge and sway when submerged. This allows much more effective locomotion underwater as opposed to the aerial configuration where rotational acceleration is used to direct small components of thrust in the lateral directions. However, the introduction of lateral thruster components by rotating the thrusters about their respective arm axes creates additional coupled moment terms. Here, the dynamics of this design is analysed to show that critical angles of thruster rotation can achieve stable surge and sway movements while also decoupling lateral from rotational movements.",
        "primary_area": "",
        "author": "Yu Herng Tan;Ben M. Chen;Yu Herng Tan;Ben M. Chen",
        "authorids": "/37086150770;/38520079900;/37086150770;/38520079900",
        "aff": "Department of Electrical and Computer Engineering, National University of Singapore, Singapore; Department of Mechanical and Automation Engineering, Chinese University of Hong Kong, Shatin, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562032/",
        "gs_citation": 13,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7939773836866074745&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "National University of Singapore;Chinese University of Hong Kong",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Mechanical and Automation Engineering",
        "aff_unique_url": "https://www.nus.edu.sg;https://www.cuhk.edu.hk",
        "aff_unique_abbr": "NUS;CUHK",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Hong Kong SAR",
        "aff_country_unique_index": "0;1",
        "aff_country_unique": "Singapore;China"
    },
    {
        "id": "9561892",
        "title": "Uniform Complete Observability of Mass and Rotational Inertial Parameters in Adaptive Identification of Rigid-Body Plant Dynamics",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper addresses the long-standing open problem of observability of mass and inertia plant parameters in the adaptive identification (AID) of second-order nonlinear models of 6 degree-of-freedom rigid-body dynamical systems subject to externally applied forces and moments. Although stable methods for AID of plant parameters for this class of systems, as well numerous approaches to stable model-based direct adaptive trajectory-tracking control of such systems, have been reported, these studies have been unable to prove analytically that the adaptive parameter estimates converge to the true plant parameter values. This paper reports necessary and sufficient conditions for the uniform complete observability (UCO) of 6-DOF plant inertial parameters for a stable adaptive identifier for this class of systems. When the UCO condition is satisfied, the adaptive parameter estimates are shown to converge to the true plant parameter values. To the best of our knowledge this is the first reported proof for this class of systems of UCO of plant parameters and for convergence of adaptive parameter estimates to true parameter values.We also report a numerical simulation study of this AID approach which shows that (a) the UCO condition can be met for fully-actuated plants as well as underactuated plants with the proper choice of control input and (b) convergence of adaptive parameter estimates to the true parameter values. We conjecture that this approach can be extended to include other parameters that appear rigid body plant models including parameters for drag, buoyancy, added mass, bias, and actuators.",
        "primary_area": "",
        "author": "Tyler M. Paine;Louis L. Whitcomb;Tyler M. Paine;Louis L. Whitcomb",
        "authorids": "/37086581894;/37283591700;/37086581894;/37283591700",
        "aff": "Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA; Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561892/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14388110926036404439&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Johns Hopkins University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.jhu.edu",
        "aff_unique_abbr": "JHU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Baltimore",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561716",
        "title": "Uniform Object Rearrangement: From Complete Monotone Primitives to Efficient Non-Monotone Informed Search",
        "track": "main",
        "status": "Poster",
        "abstract": "Object rearrangement is a widely-applicable and challenging task for robots. Geometric constraints must be carefully examined to avoid collisions and combinatorial issues arise as the number of objects increases. This work studies the algorithmic structure of rearranging uniform objects, where robot-object collisions do not occur but object-object collisions have to be avoided. The objective is minimizing the number of object transfers under the assumption that the robot can manipulate one object at a time. An efficiently computable decomposition of the configuration space is used to create a \"region graph\", which classifies all continuous paths of equivalent collision possibilities. Based on this compact but rich representation, a complete dynamic programming primitive DFSDP performs a recursive depth first search to solve monotone problems quickly, i.e., those instances that do not require objects to be moved first to an intermediate buffer. DFSDP is extended to solve single-buffer, non-monotone instances, given a choice of an object and a buffer. This work utilizes these primitives as local planners in an informed search framework for more general, non-monotone instances. The search utilizes partial solutions from the primitives to identify the most promising choice of objects and buffers. Experiments demonstrate that the proposed solution returns near-optimal paths with higher success rate, even for challenging non-monotone instances, than other leading alternatives.",
        "primary_area": "",
        "author": "Rui Wang;Kai Gao;Daniel Nakhimovich;Jingjin Yu;Kostas E. Bekris;Rui Wang;Kai Gao;Daniel Nakhimovich;Jingjin Yu;Kostas E. Bekris",
        "authorids": "/37088013751;/37088997464;/37088995936;/37536570700;/37282424700;/37088013751;/37088997464;/37088995936;/37536570700;/37282424700",
        "aff": "Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA; Department of Computer Science, Rutgers University, NJ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561716/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2956096561368390015&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Rutgers University",
        "aff_unique_dep": "Department of Computer Science",
        "aff_unique_url": "https://www.rutgers.edu",
        "aff_unique_abbr": "Rutgers",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "New Brunswick",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561527",
        "title": "Unsupervised Feature Learning for Manipulation with Contrastive Domain Randomization",
        "track": "main",
        "status": "Poster",
        "abstract": "Robotic tasks such as manipulation with visual inputs require image features that capture the physical properties of the scene, e.g., the position and configuration of objects. Recently, it has been suggested to learn such features in an unsupervised manner from simulated, self-supervised, robot interaction; the idea being that high-level physical properties are well captured by modern physical simulators, and their representation from visual inputs may transfer well to the real world. In particular, learning methods based on noise contrastive estimation have shown promising results. To robustify the simulation-to-real transfer, domain randomization (DR) was suggested for learning features that are invariant to irrelevant visual properties such as textures or lighting. In this work, however, we show that a naive application of DR to unsupervised learning based on contrastive estimation does not promote invariance, as the loss function maximizes mutual information between the features and both the relevant and irrelevant visual properties. We propose a simple modification of the contrastive loss to fix this, exploiting the fact that we can control the simulated randomization of visual properties. Our approach learns physical features that are significantly more robust to visual domain variation, as we demonstrate using both rigid and non-rigid objects.",
        "primary_area": "",
        "author": "Carmel Rabinovitz;Niko Grupen;Aviv Tamar;Carmel Rabinovitz;Niko Grupen;Aviv Tamar",
        "authorids": "/37086640615;/37089000218;/37086002269;/37086640615;/37089000218;/37086002269",
        "aff": "Department of Electrical Engineering, Technion, Israel; Department of Computer Science, Cornell University, NY, USA; Department of Electrical Engineering, Technion, Israel",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561527/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3343255023270175285&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Technion;Cornell University",
        "aff_unique_dep": "Department of Electrical Engineering;Department of Computer Science",
        "aff_unique_url": "https://www.technion.ac.il;https://www.cornell.edu",
        "aff_unique_abbr": "Technion;Cornell",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Ithaca",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "Israel;United States"
    },
    {
        "id": "9561572",
        "title": "Unsupervised Learning of 3D Scene Flow from Monocular Camera",
        "track": "main",
        "status": "Poster",
        "abstract": "Scene flow represents the motion of points in the 3D space, which is the counterpart of the optical flow that represents the motion of pixels in the 2D image. However, it is difficult to obtain the ground truth of scene flow in the real scenes, and recent studies are based on synthetic data for training. Therefore, how to train a scene flow network with unsupervised methods based on real-world data shows crucial significance. A novel unsupervised learning method for scene flow is proposed in this paper, which utilizes the images of two consecutive frames taken by monocular camera without the ground truth of scene flow for training. Our method realizes the goal that training scene flow network with real-world data, which bridges the gap between training data and test data and broadens the scope of available data for training. Unsupervised learning of scene flow in this paper mainly consists of two parts: (i) depth estimation and camera pose estimation, and (ii) scene flow estimation based on four different loss functions. Depth estimation and camera pose estimation obtain the depth maps and camera pose between two consecutive frames, which provide further information for the next scene flow estimation. After that, we used depth consistency loss, dynamic-static consistency loss, Chamfer loss, and Laplacian regularization loss to carry out unsupervised training of the scene flow network. To our knowledge, this is the first paper that realizes the unsupervised learning of 3D scene flow from monocular camera. The experiment results on KITTI show that our method for unsupervised learning of scene flow meets great performance compared to traditional methods Iterative Closest Point (ICP) and Fast Global Registration (FGR). The source code is available at: https://github.com/IRMVLab/3DUnMonoFlow.",
        "primary_area": "",
        "author": "Guangming Wang;Xiaoyu Tian;Ruiqi Ding;Hesheng Wang;Guangming Wang;Xiaoyu Tian;Ruiqi Ding;Hesheng Wang",
        "authorids": "/37086937116;/37088997106;/37088997844;/37292567100;/37086937116;/37088997106;/37088997844;/37292567100",
        "aff": "Department of Automation, Institute of Medical Robotics, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai, China; Department of Automation, Institute of Medical Robotics, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai, China; Department of Automation, Institute of Medical Robotics, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai, China; Department of Automation, Institute of Medical Robotics, Shanghai Engineering Research Center of Intelligent Control and Management, Shanghai Jiao Tong University, Key Laboratory of System Control and Information Processing of Ministry of Education, Key Laboratory of Marine Intelligent Equipment and System of Ministry of Education, Shanghai, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561572/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8369286937876685708&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Shanghai Jiao Tong University",
        "aff_unique_dep": "Department of Automation",
        "aff_unique_url": "https://www.sjtu.edu.cn",
        "aff_unique_abbr": "SJTU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shanghai",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561753",
        "title": "Unsupervised Motion Estimation of Vehicles Using ICP",
        "track": "main",
        "status": "Poster",
        "abstract": "Anticipating the motion of dynamic objects is critical for making intelligent decisions navigating through an environment while avoiding collisions. In this work, we propose a CNN model that estimates 3D motion of objects using sequences of monocular images. We show that we can train this model without using any manual annotations by using Iterative Closest Points (ICP) to align pointclouds of an object at different points in time. We compare our unsupervised approach to a model that was trained using ground truth supervision, on the KITTI tracking dataset. We further improve our model by training our model on a larger dataset, which would otherwise not be possible due to the lack of ground truth data. We also compare our approach with a 3D object detector that estimates motion using a simple tracking scheme.",
        "primary_area": "",
        "author": "Tom Roussel;Tinne Tuytelaars;Luc Van Eycken;Tom Roussel;Tinne Tuytelaars;Luc Van Eycken",
        "authorids": "/37085994793;/37282935100;/37282883600;/37085994793;/37282935100;/37282883600",
        "aff": "ESAT-PSI, KU Leuven; ESAT-PSI, KU Leuven; ESAT-PSI, KU Leuven",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561753/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:c1zu4L8lnNUJ:scholar.google.com/&scioq=Unsupervised+Motion+Estimation+of+Vehicles+Using+ICP&hl=en&as_sdt=0,5",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "KU Leuven",
        "aff_unique_dep": "ESAT-PSI",
        "aff_unique_url": "https://www.kuleuven.be",
        "aff_unique_abbr": "KU Leuven",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Belgium"
    },
    {
        "id": "9561700",
        "title": "Using Euler Curves to Model Continuum Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the continuous and flexible nature of continuum robot backbones and the infinite number of parameters required to represent them in configuration space, modeling them accurately and in real-time is challenging. While the constant curvature assumption provides a simple alternative, it is limited in its capabilities as it cannot account for external tip forces. In cases where the backbone deviates from the constant curvature backbone, Euler curves are an interesting alternative for modeling continuum robots. In this paper, we show that a linear approximation of the backbone curvature is sufficiently accurate for estimating the shape of a robot subject to external tip forces. Next, we propose a numerical static model for tendon-driven continuum robots experiencing in-plane external tip forces. In this model, we use Euler arc splines to circumvent the limitations of standard numerical integration schemes required to calculate these curves. The system reduces to solving two nonlinear equations, allowing fast approximation of the backbone shape. The proposed model is validated experimentally on a robot prototype. Average tip error of 3.07% of the robot length is obtained for an average computation time of 0.51 ms.",
        "primary_area": "",
        "author": "Priyanka Rao;Quentin Peyron;Jessica Burgner-Kahrs;Priyanka Rao;Quentin Peyron;Jessica Burgner-Kahrs",
        "authorids": "/37088999633;/37086428635;/37085433359;/37088999633;/37086428635;/37085433359",
        "aff": "Department of Mathematical & Computational Sciences, Continuum Robotics Laboratory, University of Toronto Mississauga, Mississauga, Canada; Department of Mathematical & Computational Sciences, Continuum Robotics Laboratory, University of Toronto Mississauga, Mississauga, Canada; Department of Mathematical & Computational Sciences, Continuum Robotics Laboratory, University of Toronto Mississauga, Mississauga, Canada",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561700/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8823266675737251439&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "University of Toronto Mississauga",
        "aff_unique_dep": "Department of Mathematical & Computational Sciences",
        "aff_unique_url": "https://www.utm.utoronto.ca",
        "aff_unique_abbr": "UTM",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Mississauga",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Canada"
    },
    {
        "id": "9561853",
        "title": "Using Reinforcement Learning to Create Control Barrier Functions for Explicit Risk Mitigation in Adversarial Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Air Combat is a high-risk activity carried out by trained professionals operating sophisticated equipment. During this activity, a number of trade-offs have to be made, such as the balance between risk and efficiency. A policy that minimizes risk could have very low efficiency, and one that maximizes efficiency may involve very high risk.In this study, we use Reinforcement Learning (RL) to create Control Barrier Functions (CBF) that captures the current risk, in terms of worst-case future separation between the aircraft and an enemy missile. CBFs are usually designed manually as closed-form expressions, but for a complex system such as a guided missile, this is not possible. Instead, we solve an RL problem using high fidelity simulation models to find value functions with CBF properties, that can then be used to guarantee safety in real air combat situations. We also provide a theoretical analysis of what family of RL problems result in value functions that can be used as CBFs in this way.The proposed approach allows the pilot in an air combat scenario to set the exposure level deemed acceptable and continuously monitor the risk related to his/her own safety. Given input regarding acceptable risk, the system limits the choices of the pilot to those that guarantee future satisfaction of the provided bound.",
        "primary_area": "",
        "author": "Edvards Scukins;Petter \u00d6gren;Edvards Scukins;Petter \u00d6gren",
        "authorids": "/37086599798;/37275141600;/37086599798;/37275141600",
        "aff": "Aeronautics Division, SAAB, Link\u00f6ping, Sweden; Robotics, Perception and Learning Lab., School of Electrical Engineering and Computer Science, Royal Institute of Technology (KTH), Stockholm, Sweden",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561853/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6095147809741744045&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Saab;Royal Institute of Technology (KTH)",
        "aff_unique_dep": "Aeronautics Division;School of Electrical Engineering and Computer Science",
        "aff_unique_url": "https://www.saab.com;https://www.kth.se",
        "aff_unique_abbr": "SAAB;KTH",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Link\u00f6ping;Stockholm",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "Sweden"
    },
    {
        "id": "9561792",
        "title": "Using depth information and colour space variations for improving outdoor robustness for instance segmentation of cabbage",
        "track": "main",
        "status": "Poster",
        "abstract": "Image-based yield detection in agriculture could raise harvest efficiency and cultivation performance of farms. Following this goal, this research focuses on improving instance segmentation of field crops under varying environmental conditions. Five data sets of cabbage plants were recorded under varying lighting outdoor conditions. The images were acquired using a commercial mono camera. Additionally, depth information was generated out of the image stream with Structure-from-Motion (SfM). A Mask R-CNN was used to detect and segment the cabbage heads. The influence of depth information and different colour space representations were analysed. The results showed that depth combined with colour information leads to a segmentation accuracy increase of 7.1%. By describing colour information by colour spaces using light and saturation information combined with depth information, additional segmentation improvements of 16.5% could be reached. The CIELAB colour space combined with a depth information layer showed the best results achieving a mean average precision of 75.",
        "primary_area": "",
        "author": "Nils L\u00fcling;David Reiser;Alexander Stana;H.W. Griepentrog;Nils L\u00fcling;David Reiser;Alexander Stana;H.W. Griepentrog",
        "authorids": "/37089000087;/37087324132;/37088998458;/37087321713;/37089000087;/37087324132;/37088998458;/37087321713",
        "aff": "Institute of Agricultural Engineering, University of Hohenheim, Stuttgart, Germany; Institute of Agricultural Engineering, University of Hohenheim, Stuttgart, Germany; Institute of Agricultural Engineering, University of Hohenheim, Stuttgart, Germany; Institute of Agricultural Engineering, University of Hohenheim, Stuttgart, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561792/",
        "gs_citation": 18,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13563554479118309284&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Hohenheim",
        "aff_unique_dep": "Institute of Agricultural Engineering",
        "aff_unique_url": "https://www.uni-hohenheim.de",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Stuttgart",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561597",
        "title": "VIC-Net: Voxelization Information Compensation Network for Point Cloud 3D Object Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Voxel-based methods have been widely used in point cloud 3D object detection. These methods usually transform points into voxels while suffering from information loss during point cloud voxelization. To address this problem, we propose a novel one-stage Voxelization Information Compensation Network (VIC-Net), which has the ability of loss-free feature extraction. The whole framework consists of a point branch for geometry detail extraction and a voxel branch for efficient proposals generation. Firstly, PointNet++ is adopted to efficiently encode geometry structure features from the raw point clouds. Then based on the encoded point features, two Point2Voxel (P2V) feature fusion modules are proposed to fuse point features with a voxel backbone, including Local P2V and Multi-Scale P2V. The P2V modules respectively integrate local detail features and multi-scale semantic contexts into a sparse voxel backbone. Thirdly, an auxiliary reconstruction loss is employed on the point branch to explicitly guide the point backbone to be aware of real geometry structures. In addition, we extend VIC-Net to a two-stage approach, namely VIC-RCNN, which further utilizes the fine geometry features to refine object locations. Experiments on the KITTI dataset demonstrate that our proposed VIC-Net outperforms other onestage methods and our two-stage method VIC-RCNN achieves new state-of-the-art performance.",
        "primary_area": "",
        "author": "Tianyuan Jiang;Nan Song;Huanyu Liu;Ruihao Yin;Ye Gong;Jian Yao;Tianyuan Jiang;Nan Song;Huanyu Liu;Ruihao Yin;Ye Gong;Jian Yao",
        "authorids": "/37088996978;/37088999211;/37088997778;/37089001418;/37088995950;/37085387191;/37088996978;/37088999211;/37088997778;/37089001418;/37088995950;/37085387191",
        "aff": "School of Remote Sensing and Information Engineering, Wuhan University, P.R. China; School of Remote Sensing and Information Engineering, Wuhan University, P.R. China; Momenta; Momenta; School of Remote Sensing and Information Engineering, Wuhan University, P.R. China; School of Remote Sensing and Information Engineering, Wuhan University, P.R. China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561597/",
        "gs_citation": 45,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11017905253946178221&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;1;0;0",
        "aff_unique_norm": "Wuhan University;Momenta",
        "aff_unique_dep": "School of Remote Sensing and Information Engineering;",
        "aff_unique_url": "http://www.whu.edu.cn/;https://www.momenta.cn",
        "aff_unique_abbr": "WHU;Momenta",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9560898",
        "title": "VID-Fusion: Robust Visual-Inertial-Dynamics Odometry for Accurate External Force Estimation",
        "track": "main",
        "status": "Poster",
        "abstract": "Recently, quadrotors are gaining significant attention in aerial transportation and delivery. In these scenarios, an accurate estimation of the external force is as essential as the six degree-of-freedom (DoF) pose since it is of vital importance for planning and control of the vehicle. To this end, we propose a tightly-coupled Visual-Inertial-Dynamics (VID) system that simultaneously estimates the external force applied to the quadrotor along with the six DoF pose. Our method builds on the state-of-the-art optimization-based Visual-Inertial system [1], with a novel deduction of the dynamics and external force factor extended from VIMO [2]. Utilizing the proposed dynamics and external force factor, our estimator robustly and accurately estimates the external force even when it varies widely. Moreover, since we explicitly consider the influence of the external force, when compared with VIMO [2] and VINS-Mono [1], our method shows comparable and superior pose accuracy, even when the external force ranges from neglectable to significant. The robustness and effectiveness of the proposed method are validated by extensive real-world experiments and application scenario simulation. We will release an open-source package of this method along with datasets with ground truth force measurements for the reference of the community.",
        "primary_area": "",
        "author": "Ziming Ding;Tiankai Yang;Kunyi Zhang;Chao Xu;Fei Gao;Ziming Ding;Tiankai Yang;Kunyi Zhang;Chao Xu;Fei Gao",
        "authorids": "/37088968067;/37089001320;/37089000368;/37404060100;/37086045143;/37088968067;/37089001320;/37089000368;/37404060100;/37086045143",
        "aff": "National Engineering Research Center for Industrial Automation, Ningbo Institute, Ningbo, China; National Engineering Research Center for Industrial Automation, Ningbo Institute, Ningbo, China; National Engineering Research Center for Industrial Automation, Ningbo Institute, Ningbo, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560898/",
        "gs_citation": 38,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9317034527749748346&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;1;1",
        "aff_unique_norm": "National Engineering Research Center for Industrial Automation;Zhejiang University",
        "aff_unique_dep": ";Huzhou Institute",
        "aff_unique_url": ";https://www.zju.edu.cn",
        "aff_unique_abbr": ";ZJU",
        "aff_campus_unique_index": "0;0;0;1;1",
        "aff_campus_unique": "Ningbo;Huzhou",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9562103",
        "title": "VINS-Motion: Tightly-coupled Fusion of VINS and Motion Constraint",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we develop a novel visual-inertial navigation system with motion constraint (VINS-Motion), which extends the visual-inertial navigation system (VINS) to incorporate vehicle motion constraints for improving the autonomous vehicles localization accuracy. Besides the prior information, IMU measurement residual, and visual measurement residual utilized in VINS, vehicle orientation/velocity constraint is first exploited to constitute motion residual. We minimize the sum of priors and Mahalanobis norms of three kinds of residuals to obtain a maximum posteriori estimation, thus increasing system consistency and accuracy. Stop detection is also added to help eliminate the abnormal jitter of the estimated poses during stopping, thus ensuring reasonability of the trajectory. The pro-posed approach is validated on public datasets and compared against state-of-the-art algorithms, which demonstrates that VINS-Motion achieves significantly higher positioning accuracy.",
        "primary_area": "",
        "author": "Zhelin Yu;Lidong Zhu;Guoyu Lu;Zhelin Yu;Lidong Zhu;Guoyu Lu",
        "authorids": "/37087128406;/37276567000;/37086529299;/37087128406;/37276567000;/37086529299",
        "aff": "Chester F. Carlson Center for Imaging Science, Rochester Institute of Technology, USA; National Key Lab of Science and Technology on Communications, University of Electronic Science and Technology of China; Chester F. Carlson Center for Imaging Science, Rochester Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562103/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3885703858620712933&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Rochester Institute of Technology;University of Electronic Science and Technology of China",
        "aff_unique_dep": "Chester F. Carlson Center for Imaging Science;National Key Lab of Science and Technology on Communications",
        "aff_unique_url": "https://www.rit.edu;https://www.uestc.edu.cn",
        "aff_unique_abbr": "RIT;UESTC",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9561382",
        "title": "VINSEval: Evaluation Framework for Unified Testing of Consistency and Robustness of Visual-Inertial Navigation System Algorithms",
        "track": "main",
        "status": "Poster",
        "abstract": "The research community presented significant advances in many different Visual-Inertial Navigation System (VINS) algorithms to localize mobile robots or hand-held devices in a 3D environment. While authors of the algorithms of-ten do compare to, at that time, existing competing approaches, their comparison methods, rigor, depth, and repeatability at later points in time have a large spread. Further, with existing simulators and photo-realistic frameworks, the user is not able to easily test the sensitivity of the algorithm under examination with respect to specific environmental conditions and sensor specifications. Rather, tests often include unwillingly many polluting effects falsifying the analysis and interpretations. In addition, edge cases and corresponding failure modes often remain undiscovered due to the limited breadth of the test sequences. Our unified evaluation framework allows, in a fully automated fashion, a reproducible analysis of different VINS methods with respect to specific environmental and sensor parameters. The analyses per parameter are done over a multitude of test sets to obtain both statistically valid results and an average over other, potentially polluting effects with respect to the one parameter under test to mitigate biased interpretations. The automated performance results per method over all tested parameters are then summarized in unified radar charts for a fair comparison across authors and institutions.",
        "primary_area": "",
        "author": "Alessandro Fornasier;Martin Scheiber;Alexander Hardt-Stremayr;Roland Jung;Stephan Weiss;Alessandro Fornasier;Martin Scheiber;Alexander Hardt-Stremayr;Roland Jung;Stephan Weiss",
        "authorids": "/37088685957;/37087323697;/37086579419;/37087323495;/37535323400;/37088685957;/37087323697;/37086579419;/37087323495;/37535323400",
        "aff": "Control of Networked Systems, University of Klagenfurt, Austria; Control of Networked Systems, University of Klagenfurt, Austria; Control of Networked Systems, University of Klagenfurt, Austria; Control of Networked Systems, University of Klagenfurt, Austria; Control of Networked Systems, University of Klagenfurt, Austria",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561382/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15448455457713898277&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Klagenfurt",
        "aff_unique_dep": "Control of Networked Systems",
        "aff_unique_url": "https://www.uni-klagenfurt.at",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Austria"
    },
    {
        "id": "9561230",
        "title": "VOLDOR+SLAM: For the times when feature-based or direct methods are not good enough",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a dense-indirect SLAM system using external dense optical flows as input. We extend the recent probabilistic visual odometry model VOLDOR [1], by incorporating the use of geometric priors to 1) robustly bootstrap estimation from monocular capture, while 2) seamlessly supporting stereo and/or RGB-D input imagery. Our customized back-end tightly couples our intermediate geometric estimates with an adaptive priority scheme managing the connectivity of an incremental pose graph. We leverage recent advances in dense optical flow methods to achieve accurate and robust camera pose estimates, while constructing fine-grain globally-consistent dense environmental maps. Our open source implementation [https://github.com/htkseason/VOLDOR] operates online at around 15 FPS on a single GTX1080Ti GPU.",
        "primary_area": "",
        "author": "Zhixiang Min;Enrique Dunn;Zhixiang Min;Enrique Dunn",
        "authorids": "/37088458304;/37276347800;/37088458304;/37276347800",
        "aff": "Stevens Institute of Technology; Stevens Institute of Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561230/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15185756229009837889&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stevens Institute of Technology",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.stevens.edu",
        "aff_unique_abbr": "SIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561776",
        "title": "Validation of a Novel Parallel-Actuated Shoulder Exoskeleton Robot for the Characterization of Human Shoulder Impedance",
        "track": "main",
        "status": "Poster",
        "abstract": "This study validates the effectiveness of a recently developed parallel-actuated shoulder exoskeleton robot for the purpose of characterizing the neuromuscular properties of the human shoulder joint. In particular, shoulder mechanical impedance was quantified, which can be represented by a 2nd order system consisting of spring, damper and inertia. The shoulder exoskeleton robot, which utilizes a new type of 4-bar spherical parallel manipulator (4B-SPM), has inherently low inertia and as a result can provide fast perturbations that are often essential for characterizing neuromuscular properties. The robot was first evaluated by using a physical shoulder mockup with adjustable and known spring and mass properties. The results of the mockup test confirmed the reliability of the robot for the characterization of the mockup properties. Stiffness of the tested springs was accurately quantified with an error of less than 1.6 Nm/rad in any of the tested conditions. A pilot study with 5 human subjects further confirmed that the robot could be successfully used to quantify multi-dimensional human shoulder impedance in both pitch and yaw directions with high reliability (R2 > 0.97). The average human shoulder stiffness and damping at around the neutral arm posture under low muscle activation (< 5% maximum voluntary contraction) were 30.9 Nm/rad and 3.0 Nms/rad, respectively.",
        "primary_area": "",
        "author": "Dongjune Chang;Justin Hunt;John Atkins;Hyunglae Lee;Dongjune Chang;Justin Hunt;John Atkins;Hyunglae Lee",
        "authorids": "/37088998518;/37086454811;/37088997416;/37085768762;/37088998518;/37086454811;/37088997416;/37085768762",
        "aff": "School for Engineering of Matter, Transport and Energy, Arizona State University, Tempe, AZ, USA; School for Engineering of Matter, Transport and Energy, Arizona State University, Tempe, AZ, USA; School for Engineering of Matter, Transport and Energy, Arizona State University, Tempe, AZ, USA; School for Engineering of Matter, Transport and Energy, Arizona State University, Tempe, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561776/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14891953027797922717&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "School for Engineering of Matter, Transport and Energy",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Tempe",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561087",
        "title": "Vanishing Point Aided LiDAR-Visual-Inertial Estimator",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a vanishing point aided LiDAR-Visual-Inertial estimator to achieve real-time, low-drift and robust pose estimation. The proposed method is mainly composed of 3 sequential modules, namely IMU-aided vanishing point (VP) detection module, voxel-map based feature depth association module, and visual inertial fixed-lag smoother module. The IMU-aided VP detection module will detect feature points, line segments and vanishing points to establish robust correspondences in successive frames. In particular, we propose to use 1-line RANSAC method to provide stable VP hypotheses and polar grid to accelerate vanishing point hypothesis validation. After that, we propose a novel voxel-map based feature depth association method, to retrieve depth and assign depth to visual feature efficiently. Finally, the visual inertial fixed-lag smoother module is proposed to jointly minimize error terms. Experiments show that our method outperforms the state-of-the-art visual-inertial odometry and LiDAR-visual estimator in both indoor and outdoor environments.",
        "primary_area": "",
        "author": "Peng Wang;Zheng Fang;Shibo Zhao;Yongnan Chen;Ming Zhou;Shan An;Peng Wang;Zheng Fang;Shibo Zhao;Yongnan Chen;Ming Zhou;Shan An",
        "authorids": "/37088689449;/37401391100;/37086444189;/37089001772;/37089001025;/37089656524;/37088689449;/37401391100;/37086444189;/37089001772;/37089001025;/37089656524",
        "aff": "Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Robotics Institute, Carnegie Mellon University, USA; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Faculty of Robot Science and Engineering, Northeastern University, Shenyang, China; Shan An is with Tech & Data Center, JD.COM Inc",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561087/",
        "gs_citation": 19,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=721448013213007391&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;1;0;0;2",
        "aff_unique_norm": "Northeastern University;Carnegie Mellon University;JD.COM Inc",
        "aff_unique_dep": "Faculty of Robot Science and Engineering;Robotics Institute;Tech & Data Center",
        "aff_unique_url": "http://www.neu.edu.cn/;https://www.cmu.edu;https://www.jd.com",
        "aff_unique_abbr": "NEU;CMU;JD",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Shenyang;",
        "aff_country_unique_index": "0;0;1;0;0;0",
        "aff_country_unique": "China;United States"
    },
    {
        "id": "9561644",
        "title": "VelocityNet: Motion-Driven Feature Aggregation for 3D Object Detection in Point Cloud Sequences",
        "track": "main",
        "status": "Poster",
        "abstract": "The most successful methods for LiDAR-based 3D object detection use sequences of point clouds in order to exploit the increased data density through temporal aggregation. However, common aggregation methods are rarely able to capture fast-moving objects appropriately. These objects are displaced by large distances between frames and naive approaches are not able to successfully leverage the full amount of information spread across time. Yet, especially in autonomous driving scenarios, fast-moving objects are most crucial to detect as they actively take part in highly dynamic traffic situations. This work presents a novel network architecture called VelocityNet which is explicitly designed to temporally align features according to object motion. Our approach extends traditional 3D convolutions by a motion-driven deformation of the convolution kernels across the temporal dimension. The required motion information can be obtained from various sources, ranging from external computation or complementary sensors to an integrated network branch which is trained jointly with the object detection task. The explicit feature alignment allows the training process to focus on the object detection problem and results in a significant increase in detection performance compared to the popular PointPillars baseline, not only for dynamic but also for static objects. We evaluate our approach on the nuScenes dataset and analyze the main reasons for the observed performance gains.",
        "primary_area": "",
        "author": "David Emmerichs;Peter Pinggera;Bj\u00f6rn Ommer;David Emmerichs;Peter Pinggera;Bj\u00f6rn Ommer",
        "authorids": "/37089000754;/37085732342;/37397477900;/37089000754;/37085732342;/37397477900",
        "aff": "IWR, Heidelberg University; Mercedes-Benz AG; IWR, Heidelberg University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561644/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4749148231647131691&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Heidelberg University;Mercedes-Benz AG",
        "aff_unique_dep": "Interdisciplinary Center for Scientific Computing (IWR);",
        "aff_unique_url": "https://www.uni-heidelberg.de;https://www.mercedes-benz.com",
        "aff_unique_abbr": "Uni Heidelberg;MBAG",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Heidelberg;",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9562102",
        "title": "Verbal Focus-of-Attention System for Learning-from-Observation",
        "track": "main",
        "status": "Poster",
        "abstract": "The learning-from-observation (LfO) framework aims to map human demonstrations to a robot to reduce programming effort. To this end, an LfO system encodes a human demonstration into a series of execution units for a robot, which are referred to as task models. Although previous research has proposed successful task-model encoders, there has been little discussion on how to guide a task-model encoder in a scene with spatio-temporal noises, such as cluttered objects or unrelated human body movements. Inspired by the function of verbal instructions guiding an observer\u2019s visual attention, we propose a verbal focus-of-attention (FoA) system (i.e., spatiotemporal filters) to guide a task-model encoder. For object manipulation, the system first recognizes the name of a target object and its attributes from verbal instructions. The information serves as a where-to-look FoA filter to confine the areas in which the target object existed in the demonstration. The system then detects the timings of grasp and release that occurred in the filtered areas. The timings serve as a when-to-look FoA filter to confine the period of object manipulation. Finally, a task-model encoder recognizes the task models by employing the FoA filters. We demonstrate the robustness of the verbal FoA in attenuating spatio-temporal noises by comparing it with an existing action localization network. The contributions of this study are as follows: (1) to propose a verbal FoA for LfO, (2) to design an algorithm to calculate FoA filters from verbal input, and (3) to demonstrate the effectiveness of a verbal FoA in localizing an action by comparing it with a state-of-the-art vision system.",
        "primary_area": "",
        "author": "Naoki Wake;Iori Yanokura;Kazuhiro Sasabuchi;Katsushi Ikeuchi;Naoki Wake;Iori Yanokura;Kazuhiro Sasabuchi;Katsushi Ikeuchi",
        "authorids": "/37088602119;/37086105883;/37085680164;/37281068600;/37088602119;/37086105883;/37085680164;/37281068600",
        "aff": "Applied Robotics, Microsoft, Redmond, WA, USA; Applied Robotics, Microsoft, Redmond, WA, USA; Applied Robotics, Microsoft, Redmond, WA, USA; Applied Robotics, Microsoft, Redmond, WA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562102/",
        "gs_citation": 17,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15552660182471158039&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Microsoft",
        "aff_unique_dep": "Applied Robotics",
        "aff_unique_url": "https://www.microsoft.com",
        "aff_unique_abbr": "MSFT",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Redmond",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561130",
        "title": "Versatile Locomotion by Integrating Ankle, Hip, Stepping, and Height Variation Strategies",
        "track": "main",
        "status": "Poster",
        "abstract": "Stable walking in real-world environments is a challenging task for humanoid robots, especially when considering the dynamic disturbances, e.g., caused by external perturbations that may be encountered during locomotion. The varying nature of disturbance necessitates high adaptability. In this paper, we propose an enhanced Nonlinear Model Predictive Control (NMPC) approach for robust and adaptable walking \u2013 we term it versatile locomotion, by limiting both the Center of Pressure (CoP) and Divergent Component of Motion (DCM) movements. Due to utilization of the Nonlinear Inverted Pendulum plus Flywheel model, the robot is endowed with the capabilities of CoP manipulation (if equipped with finitesized feet), step location adjustment, upper body rotation, and vertical height variation. Considering the feasibility constraints, especially the usage of relaxed CoP constraints, the NMPC scheme is established as a Quadratically Constrained Quadratic Programming problem, which is solved efficiently by Sequential Quadratic Programming with enhanced solvability. Simulation experiments demonstrate the effectiveness of our method to recruit optimal hybrid strategies in order to realize versatile locomotion, for the robot with finite-sized or point feet.",
        "primary_area": "",
        "author": "Jiatao Ding;Songyan Xin;Tin Lun Lam;Sethu Vijayakumar;Jiatao Ding;Songyan Xin;Tin Lun Lam;Sethu Vijayakumar",
        "authorids": "/37086353143;/37086099765;/37571111600;/37295595500;/37086353143;/37086099765;/37571111600;/37295595500",
        "aff": "Shenzhen Institute of Artificial Intelligence and Robotics for Society (AIRS), Shenzhen, China; School of Informatics, University of Edinburgh, Edinburgh, United Kingdom; Chinese University of Hong Kong, Shenzhen; AIRS",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561130/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14806570909883128427&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;2;3",
        "aff_unique_norm": "Shenzhen Institute of Artificial Intelligence and Robotics for Society;University of Edinburgh;Chinese University of Hong Kong;Atmospheric InfraRed Sounder",
        "aff_unique_dep": "Artificial Intelligence and Robotics for Society;School of Informatics;;",
        "aff_unique_url": ";https://www.ed.ac.uk;https://www.cuhk.edu.cn;https://airs.jpl.nasa.gov",
        "aff_unique_abbr": "AIRS;Edinburgh;CUHK;AIRS",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Shenzhen;Edinburgh;",
        "aff_country_unique_index": "0;1;0;2",
        "aff_country_unique": "China;United Kingdom;United States"
    },
    {
        "id": "9561936",
        "title": "ViNG: Learning Open-World Navigation with Visual Goals",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a learning-based navigation system for reaching visually indicated goals and demonstrate this system on a real mobile robot platform. Learning provides an appealing alternative to conventional methods for robotic navigation: instead of reasoning about environments in terms of geometry and maps, learning can enable a robot to learn about navigational affordances, understand what types of obstacles are traversable (e.g., tall grass) or not (e.g., walls), and generalize over patterns in the environment. However, unlike conventional planning algorithms, it is harder to change the goal for a learned policy during deployment. We propose a method for learning to navigate towards a goal image of the desired destination. By combining a learned policy with a topological graph constructed out of previously observed data, our system can determine how to reach this visually indicated goal even in the presence of variable appearance and lighting. Three key insights, waypoint proposal, graph pruning and negative mining, enable our method to learn to navigate in real-world environments using only offline data, a setting where prior methods struggle. We instantiate our method on a real outdoor ground robot and show that our system, which we call ViNG, outperforms previously-proposed methods for goal-conditioned reinforcement learning, including other methods that incorporate reinforcement learning and search. We also study how ViNG generalizes to unseen environments and evaluate its ability to adapt to such an environment with growing experience. Finally, we demonstrate ViNG on a number of real-world applications, such as last-mile delivery and warehouse inspection. We encourage the reader to visit the project website for videos of our experiments and demonstrations 1.",
        "primary_area": "",
        "author": "Dhruv Shah;Benjamin Eysenbach;Gregory Kahn;Nicholas Rhinehart;Sergey Levine;Dhruv Shah;Benjamin Eysenbach;Gregory Kahn;Nicholas Rhinehart;Sergey Levine",
        "authorids": "/37089000677;/37086231814;/37085561267;/37085401789;/37085481973;/37089000677;/37086231814;/37085561267;/37085401789;/37085481973",
        "aff": "UC Berkeley; Carnegie Mellon University; UC Berkeley; UC Berkeley; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561936/",
        "gs_citation": 114,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17511061747694286586&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;0;0;0",
        "aff_unique_norm": "University of California, Berkeley;Carnegie Mellon University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.cmu.edu",
        "aff_unique_abbr": "UC Berkeley;CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562106",
        "title": "View-expansive Microscope System with Real-time High-resolution Imaging for Simplified Microinjection Experiments",
        "track": "main",
        "status": "Poster",
        "abstract": "Microinjection technology is applied widely in biomedical research for the purposes of gene manipulation and microinsemination. Generally, microinjection is performed under an optical microscope environment through image presentation of the targets. To perform the microinjection process, it is necessary to place multiple cells in the same droplet and perform multiple injections. This process requires observation at different magnifications for the injection and embryo transfer processes, with the operator required to change the magnification and light intensity each time. The complexity of the process can lead to variations in the accuracy, reproducibility, and productivity of the course of multiple microinjections. To simplify the microinjection process and reduce the workload on the operator, we propose a micromanipulation system that enables both wide-range and high-resolution video shooting with free viewpoint selection. The effectiveness of the proposed system is verified through microinjection experiments using porcine embryos.",
        "primary_area": "",
        "author": "Tadayoshi Aoyama;Sarau Takeno;Kazuki Hano;Masaki Takasu;Masaru Takeuchi;Yasuhisa Hasegawa;Tadayoshi Aoyama;Sarau Takeno;Kazuki Hano;Masaki Takasu;Masaru Takeuchi;Yasuhisa Hasegawa",
        "authorids": "/37573656900;/37086344466;/37088831876;/37088832691;/37573622500;/37272575600;/37573656900;/37086344466;/37088831876;/37088832691;/37573622500;/37272575600",
        "aff": "Japan Science and Technology Agency, Kawaguchi, Japan; Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, Japan; Department of Applied Biological Science, Gifu University, Gifu, Japan; Department of Applied Biological Science, Gifu University, Gifu, Japan; Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, Japan; Department of Micro-Nano Mechanical Science and Engineering, Nagoya University, Nagoya, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562106/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11650617841131634497&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;1;2;2;1;1",
        "aff_unique_norm": "Japan Science and Technology Agency;Nagoya University;Gifu University",
        "aff_unique_dep": ";Department of Micro-Nano Mechanical Science and Engineering;Department of Applied Biological Science",
        "aff_unique_url": "https://www.jst.go.jp;https://www.nagoya-u.ac.jp;https://www.gifu-u.ac.jp",
        "aff_unique_abbr": "JST;Nagoya U;",
        "aff_campus_unique_index": "0;1;2;2;1;1",
        "aff_campus_unique": "Kawaguchi;Nagoya;Gifu",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561606",
        "title": "Viko: An Adaptive Gecko Gripper with Vision-based Tactile Sensor",
        "track": "main",
        "status": "Poster",
        "abstract": "Monitoring the state of contact is essential for robotic devices, especially grippers that implement geckoinspired adhesives where intimate contact is crucial for a firm attachment. However, due to the lack of deformable sensors, few have demonstrated tactile sensing for gecko grippers. We present Viko, an adaptive gecko gripper that utilizes vision-based tactile sensors to monitor contact state. The sensor provides high-resolution real-time measurements of contact area and shear force. Moreover, the sensor is adaptive, low-cost, and compact. We integrated gecko-inspired adhesives into the sensor surface without impeding its adaptiveness and performance. Using a robotic arm, we evaluate the performance of the gripper by a series of grasping test. The gripper has a maximum payload of 8N even at a low fingertip pitch angle of 30\u00b0. We also showcase the gripper\u2019s ability to adjust fingertip pose for better contact using sensor feedback. Further, everyday object picking is presented as a demonstration of the gripper\u2019s adaptiveness.",
        "primary_area": "",
        "author": "Chohei Pang;Kinwing Mak;Yazhan Zhang;Yang Yang;Yu Alexander Tse;Michael Yu Wang;Chohei Pang;Kinwing Mak;Yazhan Zhang;Yang Yang;Yu Alexander Tse;Michael Yu Wang",
        "authorids": "/37088525730;/37088999404;/37086842950;/37085714206;/37086842423;/37280913900;/37088525730;/37088999404;/37086842950;/37085714206;/37086842423;/37280913900",
        "aff": "Department of Mechanical and Aerospace Engineering, Hong Kong University of Science and Technology, Hong Kong; Department of Mechanical and Aerospace Engineering, Hong Kong University of Science and Technology, Hong Kong; Department of Mechanical and Aerospace Engineering, Hong Kong University of Science and Technology, Hong Kong; School of Automation, Nanjing University of Information Science and Technology, Nanjing, China; Department of Mechanical and Aerospace Engineering, Hong Kong University of Science and Technology, Hong Kong; Department of Mechanical and Aerospace Engineering and the Department of Electronic and Computer Engineering, Hong Kong University of Science and Technology, Hong Kong",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561606/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10455559568758340939&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Nanjing University of Information Science and Technology",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering;School of Automation",
        "aff_unique_url": "https://www.ust.hk;http://www.nuist.edu.cn",
        "aff_unique_abbr": "HKUST;",
        "aff_campus_unique_index": "0;0;0;1;0;0",
        "aff_campus_unique": "Hong Kong SAR;Nanjing",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561668",
        "title": "Virtual Adversarial Humans finding Hazards in Robot Workplaces",
        "track": "main",
        "status": "Poster",
        "abstract": "During the planning phase of industrial robot workplaces, hazard analyses are required so that potential hazards for human workers can be identified and appropriate safety measures can be implemented. Existing hazard analysis methods use human reasoning, checklists and/or abstract system models, which limit the level of detail. We propose a new approach that frames hazard analysis as a search problem in a dynamic simulation environment. Our goal is to identify workplace hazards by searching for simulation sequences that result in hazardous situations. We solve this search problem by placing virtual humans into workplace simulation models. These virtual humans act in an adversarial manner: They learn to provoke unsafe situations, and thereby uncover workplace hazards. Although this approach cannot replace a thorough hazard analysis, it can help uncover hazards that otherwise may have been overlooked, especially in early development stages. Thus, it helps to prevent costly re-designs at later development stages. For validation, we performed hazard analyses in six different example scenarios that reflect typical industrial robot workplaces.",
        "primary_area": "",
        "author": "Tom P. Huck;Christoph Ledermann;Torsten Kr\u00f6ger;Tom P. Huck;Christoph Ledermann;Torsten Kr\u00f6ger",
        "authorids": "/37088590233;/38468554800;/37283223400;/37088590233;/38468554800;/37283223400",
        "aff": "Intelligent Process Automation and Robotics Lab, Institute of Anthropomatics and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Intelligent Process Automation and Robotics Lab, Institute of Anthropomatics and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Intelligent Process Automation and Robotics Lab, Institute of Anthropomatics and Robotics (IAR-IPR), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561668/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=18404152611882242877&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute of Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Karlsruhe",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9561046",
        "title": "Vision Based Adaptation to Kernelized Synergies for Human Inspired Robotic Manipulation",
        "track": "main",
        "status": "Poster",
        "abstract": "Humans in contrast to robots are excellent in performing fine manipulation tasks owing to their remarkable dexterity and sensorimotor organization. Enabling robots to acquire such capabilities, necessitates a framework that not only replicates the human behaviour but also integrates the multi-sensory information for autonomous object interaction. To address such limitations, this research proposes to augment the previously developed kernelized synergies framework with visual perception to automatically adapt to the unknown objects. The kernelized synergies, inspired from humans, retain the same reduced subspace for object grasping and manipulation. To detect object in the scene, a simplified perception pipeline is used that leverages the RANSAC algorithm with Euclidean clustering and SVM for object segmentation and recognition respectively. Further, the comparative analysis of kernelized synergies with other state of art approaches is made to confirm their flexibility and effectiveness on the robotic manipulation tasks. The experiments conducted on the robot hand confirm the robustness of modified kernelized synergies framework against the uncertainties related to the perception of environment.",
        "primary_area": "",
        "author": "Sunny Katyara;Fanny Ficuciello;Fei Chen;Bruno Siciliano;Darwin G. Caldwell;Sunny Katyara;Fanny Ficuciello;Fei Chen;Bruno Siciliano;Darwin G. Caldwell",
        "authorids": "/37086374945;/37594404000;/37085388569;/37282449100;/37295680400;/37086374945;/37594404000;/37085388569;/37282449100;/37295680400",
        "aff": "Department of Information Technology and Electrical Engineering and PRISMA Lab, University of Naples Federico II, Naples, Italy; Department of Information Technology and Electrical Engineering and PRISMA Lab, University of Naples Federico II, Naples, Italy; Department of Mechanical and Automation Engineering, The Chinese University of Hong Kong, Hong Kong; Department of Information Technology and Electrical Engineering and PRISMA Lab, University of Naples Federico II, Naples, Italy; Department of Advanced Robotics, Istituto Italiano di Tecnologia, Genova, Italy",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561046/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9930042441939817634&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;1;0;2",
        "aff_unique_norm": "University of Naples Federico II;Chinese University of Hong Kong;Istituto Italiano di Tecnologia",
        "aff_unique_dep": "Department of Information Technology and Electrical Engineering;Department of Mechanical and Automation Engineering;Department of Advanced Robotics",
        "aff_unique_url": "https://www.unina.it;https://www.cuhk.edu.hk;https://www.iit.it",
        "aff_unique_abbr": "UNINA;CUHK;IIT",
        "aff_campus_unique_index": "0;0;1;0;2",
        "aff_campus_unique": "Naples;Hong Kong SAR;Genova",
        "aff_country_unique_index": "0;0;1;0;0",
        "aff_country_unique": "Italy;China"
    },
    {
        "id": "9560787",
        "title": "Vision-Based Mobile Robotics Obstacle Avoidance With Deep Reinforcement Learning",
        "track": "main",
        "status": "Poster",
        "abstract": "Obstacle avoidance is a fundamental and challenging problem for autonomous navigation of mobile robots. In this paper, we consider the problem of obstacle avoidance in simple 3D environments where the robot has to solely rely on a single monocular camera. In particular, we are interested in solving this problem without relying on localization, mapping, or planning techniques. Most of the existing work consider obstacle avoidance as two separate problems, namely obstacle detection, and control. Inspired by the recent advantages of deep reinforcement learning in Atari games and understanding highly complex situations in Go, we tackle the obstacle avoidance problem as a data-driven end-to-end deep learning approach. Our approach takes raw images as input and generates control commands as output. We show that discrete action spaces are outperforming continuous control commands in terms of expected average reward in maze-like environments. Furthermore, we show how to accelerate the learning and increase the robustness of the policy by incorporating predicted depth maps by a generative adversarial network.",
        "primary_area": "",
        "author": "Patrick Wenzel;Torsten Sch\u00f6n;Laura Leal-Taix\u00e9;Daniel Cremers;Patrick Wenzel;Torsten Sch\u00f6n;Laura Leal-Taix\u00e9;Daniel Cremers",
        "authorids": "/37087322550;/37088999794;/38286861700;/37282875300;/37087322550;/37088999794;/38286861700;/37282875300",
        "aff": "Technical University of Munich, Germany; Technische Hochschule Ingolstadt, Ingolstadt, Germany; Technical University of Munich, Germany; Technical University of Munich, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560787/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2525128630393196500&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "Technical University of Munich;Technische Hochschule Ingolstadt",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.tum.de;https://www.thi.de",
        "aff_unique_abbr": "TUM;THI",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Ingolstadt",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9560889",
        "title": "Vision-Based Robotic Pushing and Grasping for Stone Sample Collection under Computing Resource Constraints",
        "track": "main",
        "status": "Poster",
        "abstract": "Increasing the robustness of grasping actions and the recovery from failure is key to improving a robot\u2019s autonomy. Endowing robots with the ability to robustly grasp and manipulate unknown difficult objects such as stones is required for sample collection in unknown environments. In this paper, we present a complete system for robust grasping of stones, which integrates stone segmentation based on depth information, the generation of grasp hypotheses and pushing actions as well as their execution. In particular, our system has been designed to solve these tasks on robots with limited computing resources. We evaluate the performance in real robot experiments in the context of stone sample collection. The results show that such a challenging task is achievable under computing resource constraints.",
        "primary_area": "",
        "author": "Raphael Grimm;Markus Grotz;Simon Ottenhaus;Tamim Asfour;Raphael Grimm;Markus Grotz;Simon Ottenhaus;Tamim Asfour",
        "authorids": "/37085813662;/37086200970;/37086037643;/37295529100;/37085813662;/37086200970;/37086037643;/37295529100",
        "aff": "High Performance Humanoid Technologies Lab, Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology (KIT), Germany; High Performance Humanoid Technologies Lab, Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology (KIT), Germany; High Performance Humanoid Technologies Lab, Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology (KIT), Germany; High Performance Humanoid Technologies Lab, Institute for Anthropomatics and Robotics, Karlsruhe Institute of Technology (KIT), Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560889/",
        "gs_citation": 22,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7427829981649338701&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Karlsruhe Institute of Technology",
        "aff_unique_dep": "Institute for Anthropomatics and Robotics",
        "aff_unique_url": "https://www.kit.edu",
        "aff_unique_abbr": "KIT",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    },
    {
        "id": "9560751",
        "title": "Vision-Based Shape Reconstruction of Soft Continuum Arms Using a Geometric Strain Parametrization",
        "track": "main",
        "status": "Poster",
        "abstract": "Interest in soft continuum arms has increased as their inherent material elasticity enables safe and adaptive interactions with the environment. However to achieve full autonomy in these arms, accurate three-dimensional shape sensing is needed. Vision-based solutions have been found to be effective in estimating the shape of soft continuum arms. In this paper, a vision-based shape estimator that utilizes a geometric strain based representation for the soft continuum arm\u2019s shape, is proposed. This representation reduces the dimension of the curved shape to a finite set of strain basis functions, thereby allowing for efficient optimization for the shape that best fits the observed image. Experimental results demonstrate the effectiveness of the proposed approach in estimating the end effector with accuracy less than the soft arm\u2019s radius. Multiple basis functions are also analyzed and compared for the specific soft continuum arm in use.",
        "primary_area": "",
        "author": "Ali AlBeladi;Girish Krishnan;Mohamed-Ali Belabbas;Seth Hutchinson;Ali AlBeladi;Girish Krishnan;Mohamed-Ali Belabbas;Seth Hutchinson",
        "authorids": "/37088997615;/38540614800;/37300849700;/37282386200;/37088997615;/38540614800;/37300849700;/37282386200",
        "aff": "Electrical and Computer Engineering, University of Illinois at UrbanaChampaign, Urbana, IL; Industrial and Enterprise Systems Engineering, University of Illinois at Urbana-Champaign, Urbana, IL; Electrical and Computer Engineering, University of Illinois at UrbanaChampaign, Urbana, IL; School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560751/",
        "gs_citation": 20,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13561694585397029471&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "University of Illinois Urbana-Champaign;Georgia Institute of Technology",
        "aff_unique_dep": "Electrical and Computer Engineering;School of Interactive Computing",
        "aff_unique_url": "https://illinois.edu;https://www.gatech.edu",
        "aff_unique_abbr": "UIUC;Georgia Tech",
        "aff_campus_unique_index": "0;0;0;1",
        "aff_campus_unique": "Urbana;Atlanta",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561468",
        "title": "Vision-based Path Following of Snake-like Robots",
        "track": "main",
        "status": "Poster",
        "abstract": "Due to the head swinging and the body winding, the self-localization and path following for snake-like robots based on vision are very challenging. In this paper, a novel pantilt compensation method and curve parameter compensation path following controller are proposed to solve these problems, which can achieve high-precision path following. More specifically, to realize real-time positioning of the snakelike robot, a camera-mounted pan-tilt is equipped on the head of the snake-like robot, and the Apritag detection is used after the angle between the Apriltag plane and the camera plane being compensated. Then, due to the modeling approximation, the snake-like robot with a simplified controller usually deviates from the desired path, so a curve parameter compensation path following controller is proposed to eliminate the deviation and improve the following accuracy. Finally, the experiments show that with proposed methods, the snake-like robot can converge to the desired path stably and accurately.",
        "primary_area": "",
        "author": "Lixing Liu;Wei Xi;Xian Guo;Yongchun Fang;Lixing Liu;Wei Xi;Xian Guo;Yongchun Fang",
        "authorids": "/37088998104;/37088963088;/37085448334;/37293583100;/37088998104;/37088963088;/37085448334;/37293583100",
        "aff": "Institute of Robotics and Automatic Information System, College of Artificial Intelligence, Nankai University, China; Institute of Robotics and Automatic Information System, College of Artificial Intelligence, Nankai University, China; Institute of Robotics and Automatic Information System, College of Artificial Intelligence, Nankai University, China; Institute of Robotics and Automatic Information System, College of Artificial Intelligence, Nankai University, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561468/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17031298525429864489&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Nankai University",
        "aff_unique_dep": "College of Artificial Intelligence",
        "aff_unique_url": "http://www.nankai.edu.cn",
        "aff_unique_abbr": "Nankai",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561998",
        "title": "Visionary: Vision architecture discovery for robot learning",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a vision-based architecture search algorithm for robot manipulation learning, which discovers interactions between low dimension action inputs and high dimensional visual inputs. Our approach automatically designs architectures while training on the task \u2013 discovering novel ways of combining and attending image feature representations with actions as well as features from previous layers. The obtained new architectures demonstrate better task success rates, in some cases with a large margin, compared to a recent high performing baseline. Our real robot experiments also confirm that it improves grasping performance by 6%. This is the first approach to demonstrate a successful neural architecture search and attention connectivity search for a real-robot task.",
        "primary_area": "",
        "author": "Iretiayo Akinola;Anelia Angelova;Yao Lu;Yevgen Chebotar;Dmitry Kalashnikov;Jacob Varley;Julian Ibarz;Michael S. Ryoo;Iretiayo Akinola;Anelia Angelova;Yao Lu;Yevgen Chebotar;Dmitry Kalashnikov;Jacob Varley;Julian Ibarz;Michael S. Ryoo",
        "authorids": "/37086319261;/37295407600;/37090019564;/37085417006;/37279222800;/37085632898;/37704613400;/37397559800;/37086319261;/37295407600;/37090019564;/37085417006;/37279222800;/37085632898;/37704613400;/37397559800",
        "aff": "Columbia University, New York, NY, USA; Robotics at Google, Mountain View, CA, New York, NY, USA; Robotics at Google, Mountain View, CA, New York, NY, USA; Robotics at Google, Mountain View, CA, New York, NY, USA; Robotics at Google, Mountain View, CA, New York, NY, USA; Robotics at Google, Mountain View, CA, New York, NY, USA; Robotics at Google, Mountain View, CA, New York, NY, USA; Stony Brook University, Stony Brook, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561998/",
        "gs_citation": 12,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13727871919268736705&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 16,
        "aff_unique_index": "0;1;1;1;1;1;1;2",
        "aff_unique_norm": "Columbia University;Google;Stony Brook University",
        "aff_unique_dep": ";Robotics;",
        "aff_unique_url": "https://www.columbia.edu;https://www.google.com;https://www.stonybrook.edu",
        "aff_unique_abbr": "Columbia;Google;SBU",
        "aff_campus_unique_index": "0;1;1;1;1;1;1;2",
        "aff_campus_unique": "New York;Mountain View;Stony Brook",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9562028",
        "title": "Visual Perspective Taking for Opponent Behavior Modeling",
        "track": "main",
        "status": "Poster",
        "abstract": "In order to engage in complex social interaction, humans learn at a young age to infer what others see and cannot see from a different point-of-view, and learn to predict others\u2019 plans and behaviors. These abilities have been mostly lacking in robots, sometimes making them appear awkward and socially inept. Here we propose an end-to-end long-term visual prediction framework for robots to begin to acquire both these critical cognitive skills, known as Visual Perspective Taking (VPT) and Theory of Behavior (TOB). We demonstrate our approach in the context of visual hide-and-seek \u2013 a game that represents a cognitive milestone in human development. Unlike traditional visual predictive model that generates new frames from immediate past frames, our agent can directly predict to multiple future timestamps (25 s), extrapolating by 175% beyond the training horizon. We suggest that visual behavior modeling and perspective taking skills will play a critical role in the ability of physical robots to fully integrate into real-world multi-agent activities.",
        "primary_area": "",
        "author": "Boyuan Chen;Yuhang Hu;Robert Kwiatkowski;Shuran Song;Hod Lipson;Boyuan Chen;Yuhang Hu;Robert Kwiatkowski;Shuran Song;Hod Lipson",
        "authorids": "/37086319227;/37088996976;/37088999446;/37085613509;/37278575000;/37086319227;/37088996976;/37088999446;/37085613509;/37278575000",
        "aff": "Columbia University; Columbia University; Columbia University; Columbia University; Columbia University",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562028/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=1530658287851702841&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Columbia University",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.columbia.edu",
        "aff_unique_abbr": "Columbia",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561709",
        "title": "Visual Place Recognition via Local Affine Preserving Matching",
        "track": "main",
        "status": "Poster",
        "abstract": "Visual Place Recognition (VPR) is a crucial component for long-term mobile robot autonomy. In this paper, we exploit a coarse-to-fine paradigm to recognize places. In particular, we first select candidate frames for each query image, and then check the spatial geometric relationship between the query and its candidate frames to determine the final place match. In the coarse match stage, we employ the deep learning network to extract global features that encode semantic information of images, then by comparing the similarity between features to obtain a candidate list of the query place. In the fine match stage, we propose an effective and efficient feature matching algorithm for real-time geometrical verification of candidate places, termed as local affine preserving matching (LAP). Extensive experimental results demonstrate that our LAP can significantly promote the VPR performance, and the proposed overall VPR method can achieve much better performance over the current state-of-the-art approaches.",
        "primary_area": "",
        "author": "Xinyu Ye;Jiayi Ma;Xinyu Ye;Jiayi Ma",
        "authorids": "/37089000183;/37966025300;/37089000183;/37966025300",
        "aff": "School of Electronic Information and Electrical Engineering, Shanghai Jiaotong University, Shanghai, China; Electronic Information School, Wuhan University, Wuhan, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561709/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9587620715056614122&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "Shanghai Jiao Tong University;Wuhan University",
        "aff_unique_dep": "School of Electronic Information and Electrical Engineering;Electronic Information School",
        "aff_unique_url": "https://www.sjtu.edu.cn;http://www.whu.edu.cn/",
        "aff_unique_abbr": "SJTU;WHU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Shanghai;Wuhan",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561459",
        "title": "Visual Semantic Localization based on HD Map for Autonomous Vehicles in Urban Scenarios",
        "track": "main",
        "status": "Poster",
        "abstract": "Highly accurate and robust localization ability is of great importance for autonomous vehicles (AVs) in urban scenarios. Traditional vision-based methods suffer from lost due to illumination, weather, viewing and appearance changes. In this paper we propose a novel visual semantic localization algorithm based on HD map and semantic features which are compact in representation. Semantic features are widely appeared on urban roads, and are robust to illumination, weather, viewing and appearance changes. The repeated structures, missed detections and false detections make data association (DA) highly ambiguous. To this end, a robust DA method considering local structural consistency, global pattern consistency and temporal consistency is performed. Further, we introduce a sliding window factor graph optimization framework to fuse association and odometry measurements without the requirements of high-precision absolute height information for map features.We evaluate the proposed localization framework on both simulated and real urban road. The experiments show that the proposed approach is able to achieve highly accurate localization with a mean longitudinal error of 0.43m, a mean lateral error of 0.12m and a mean yaw angle error of 0.11\u00b0.",
        "primary_area": "",
        "author": "Huayou Wang;Changliang Xue;Yanxing Zhou;Feng Wen;Hongbo Zhang;Huayou Wang;Changliang Xue;Yanxing Zhou;Feng Wen;Hongbo Zhang",
        "authorids": "/37089001409;/37089001737;/37088998134;/37088690190;/37859161500;/37089001409;/37089001737;/37088998134;/37088690190;/37859161500",
        "aff": "Noah\u2019s Ark Lab, Huawei Technologies, Beijing, China; Noah\u2019s Ark Lab, Huawei Technologies, Beijing, China; Noah\u2019s Ark Lab, Huawei Technologies, Beijing, China; Noah\u2019s Ark Lab, Huawei Technologies, Beijing, China; Noah\u2019s Ark Lab, Huawei Technologies, Beijing, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561459/",
        "gs_citation": 52,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17635309296553152745&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Huawei",
        "aff_unique_dep": "Noah\u2019s Ark Lab",
        "aff_unique_url": "https://www.huawei.com",
        "aff_unique_abbr": "Huawei",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Beijing",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561236",
        "title": "Visual Servoing of Cable-Driven Parallel Robots with Tension Management",
        "track": "main",
        "status": "Poster",
        "abstract": "Cable-driven parallel robots (CDPRs) are a type of parallel robots, where cables are used instead of rigid links. This leads to many advantages, such as large workspace, low mass in motion and simple reconfiguration. The drawbacks are accuracy issues and complex cable management. Indeed, it is usual that cables become slack. That can be caused by, for example, cable mass, uncertainties in the system, and a higher number of cables than the number of degrees of freedom of the moving-platform. This reduces CDPR stiffness and degree of actuation. While visual servoing provides good accuracy and is robust to different perturbations in the system and to modeling errors, it does not deal with cable slackness. Thus, a CDPR with visual servoing can become underactuated due to cable slack. We propose in this paper to enrich visual servoing with a tension correction algorithm. Experimental results show reduction of slackness and thus avoiding slackness-related trajectory perturbations and loss of stability.",
        "primary_area": "",
        "author": "Zane Zake;Fran\u00e7ois Chaumette;Nicol\u00f2 Pedemonte;St\u00e9phane Caro;Zane Zake;Fran\u00e7ois Chaumette;Nicol\u00f2 Pedemonte;St\u00e9phane Caro",
        "authorids": "/37086640797;/37265186700;/37086037541;/37589701400;/37086640797;/37265186700;/37086037541;/37589701400",
        "aff": "IRT Jules Verne, Chemin du Chaffault, Bouguenais, France; Inria, Univ Rennes, CNRS, IRISA, Rennes, France; IRT Jules Verne, Chemin du Chaffault, Bouguenais, France; Centre National de la Recherche Scientifique (CNRS), Nantes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561236/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14860615349792145669&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;2",
        "aff_unique_norm": "IRT Jules Verne;INRIA;Centre National de la Recherche Scientifique",
        "aff_unique_dep": ";;",
        "aff_unique_url": ";https://www.inria.fr;https://www.cnrs.fr",
        "aff_unique_abbr": ";Inria;CNRS",
        "aff_campus_unique_index": "1;2",
        "aff_campus_unique": ";Rennes;Nantes",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561401",
        "title": "Visual Tracking of Deforming Objects Using Physics-based Models",
        "track": "main",
        "status": "Poster",
        "abstract": "In this paper, we propose a framework for tracking the deformation of soft objects using a RGB-D camera by utilizing the physically-based model of the considered object. A coarse, 3D template of the object being tracked is the only prior information required by the proposed method. The proposed approach does not rely on the accurate knowledge of the material properties of the object being tracked. In this paper, we integrate computer vision based tracking methodology with physical model based deformation representation without requiring expensive numerical optimization for minimizing nonlinear error terms. The proposed approach enables deformation tracking by joint minimization of a geometric error and a direct photometric intensity error while utilizing co-rotational Finite Element Method (FEM) as the underlying deformation model. The proposed method has been validated both on synthetic data (with groundtruth) and real data.",
        "primary_area": "",
        "author": "Agniva Sengupta;Alexandre Krupa;Eric Marchand;Agniva Sengupta;Alexandre Krupa;Eric Marchand",
        "authorids": "/37087107152;/37329643400;/37269970500;/37087107152;/37329643400;/37269970500",
        "aff": "Inria, IRISA, CNRS, Univ Rennes, Rennes, France; Inria, IRISA, CNRS, Univ Rennes, Rennes, France; Inria, IRISA, CNRS, Univ Rennes, Rennes, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561401/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2384185583764117066&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 8,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;0;0",
        "aff_unique_norm": "INRIA",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.inria.fr",
        "aff_unique_abbr": "Inria",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "France"
    },
    {
        "id": "9561517",
        "title": "Visual-Inertial Filtering for Human Walking Quantification",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose a novel system to track human lower-body motion as part of a larger movement assessment system for clinical evaluation. Our system combines multiple wearable Inertial Measurement Unit (IMU) sensors and a single external RGB-D camera. We use a factor graph with a Sliding Window Filter (SWF) formulation that merges 2-D joint data extracted from the RGB images via a Deep Neural Network, raw depth information, raw IMU gyroscope readings, and estimated foot contacts extracted from IMU gyroscope and accelerometer data. For the system, we use an articulated model of human body motion based on differential manifolds. We compare the results of our system against a gold-standard motion capture system and a vision-only alternative. Our proposed system qualitatively presents smoother 3D joint trajectories when compared to noisy depth data, allowing for more realistic gait estimations. At the same time, with respect to the vision-only baseline, it improves the median of the joint trajectories by around 2cm, while considerably reducing outliers by up to 0.6m.",
        "primary_area": "",
        "author": "Marc Mitjans;Michail Theofanidis;Ashley N. Collimore;Madelaine L. Disney;David M. Levine;Louis N. Awad;Roberto Tron;Marc Mitjans;Michail Theofanidis;Ashley N. Collimore;Madelaine L. Disney;David M. Levine;Louis N. Awad;Roberto Tron",
        "authorids": "/37088997421;/37085906371;/37088876521;/37089002038;/37088996809;/37085644997;/37398528900;/37088997421;/37085906371;/37088876521;/37089002038;/37088996809;/37085644997;/37398528900",
        "aff": "Department of Mechanical Engineering, Boston University, MA, USA; Department of Mechanical Engineering, Boston University, MA, USA; College of Health and Rehabilitation Sciences: Sargent College, Boston University, MA, USA; Division of General Internal Medicine and Primary Care, Brigham and Women\u2019s Hospital, Harvard Medical School, Boston, MA, USA; Division of General Internal Medicine and Primary Care, Brigham and Women\u2019s Hospital, Harvard Medical School, Boston, MA, USA; College of Health and Rehabilitation Sciences: Sargent College, Boston University, MA, USA; Department of Mechanical Engineering, Boston University, MA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561517/",
        "gs_citation": 5,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16078059021342107241&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;1;1;0;0",
        "aff_unique_norm": "Boston University;Harvard Medical School",
        "aff_unique_dep": "Department of Mechanical Engineering;Division of General Internal Medicine and Primary Care",
        "aff_unique_url": "https://www.bu.edu;https://hms.harvard.edu",
        "aff_unique_abbr": "BU;HMS",
        "aff_campus_unique_index": "0;0;1;2;2;1;0",
        "aff_campus_unique": "MA;Sargent College;Boston",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561860",
        "title": "Visual-Laser-Inertial SLAM Using a Compact 3D Scanner for Confined Space",
        "track": "main",
        "status": "Poster",
        "abstract": "Three-dimensional reconstruction in confined spaces is important for the manufacturing of aircraft wings, inspection of narrow pipes, examination of turbine blades, etc. It is also challenging because confined spaces tend to lack a positioning infrastructure, and conventional sensors often cannot detect objects in close range. Therefore, such tasks require a sensor that is compact, operates in short-range, and able to localize itself. In this paper, we introduce a miniature and low-cost 3D scanning system including an active laser-stripe triangulation hardware, integrated inertial sensors, and a Simultaneous Localization and Mapping (SLAM) software tailored for the sensor. The proposed system is capable of reconstructing photo-realistic 3D point cloud in real-time in spite of its compact monocular configuration. To achieve this capability, we propose an approach to capture both color and geometry using alternating shutter-speed on a single camera. A novel SLAM method is proposed to accurately localize the sensor by fusing laser, camera, and inertial measurements. Evaluation of localization accuracy and comparison on reconstruction performance against a significantly larger commercial off-the-shelf sensor demonstrate the proposed system\u2019s advantages in real-world applications.",
        "primary_area": "",
        "author": "Daqian Cheng;Haowen Shi;Albert Xu;Michael Schwerin;Michelle Crivella;Lu Li;Howie Choset;Daqian Cheng;Haowen Shi;Albert Xu;Michael Schwerin;Michelle Crivella;Lu Li;Howie Choset",
        "authorids": "/37088575455;/37088575655;/37088999954;/37947664700;/37088573498;/37086315375;/37281322200;/37088575455;/37088575655;/37088999954;/37947664700;/37088573498;/37086315375;/37281322200",
        "aff": "The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Department of Computer Science, Purdue University, West Lafayette, IN, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; Boeing Research & Technology, North Charleston, SC, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA; The Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561860/",
        "gs_citation": 8,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2080030786384841511&as_sdt=400005&sciodt=0,14&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;1;0;2;0;0",
        "aff_unique_norm": "Carnegie Mellon University;Purdue University;Boeing Research & Technology",
        "aff_unique_dep": "The Robotics Institute;Department of Computer Science;",
        "aff_unique_url": "https://www.cmu.edu;https://www.purdue.edu;https://www.boeing.com/research-technology/",
        "aff_unique_abbr": "CMU;Purdue;Boeing R&T",
        "aff_campus_unique_index": "0;0;1;0;2;0;0",
        "aff_campus_unique": "Pittsburgh;West Lafayette;North Charleston",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561226",
        "title": "Volumetric Objectives for Multi-Robot Exploration of Three-Dimensional Environments",
        "track": "main",
        "status": "Poster",
        "abstract": "Volumetric objectives for exploration and perception tasks seek to capture a sense of value (or reward) for hypothetical observations at one or more camera views for robots operating in unknown environments. For example, a volumetric objective may reward robots proportionally to the expected volume of unknown space to be observed. We identify connections between existing information-theoretic and coverage objectives in terms of expected coverage, particularly that mutual information without noise is a special case of expected coverage. Likewise, we provide the first comparison, of which we are aware, between information-based approximations and coverage objectives for exploration, and we find, perhaps surprisingly, that coverage objectives can significantly outperform information-based objectives in practice. Additionally, the analysis for information and coverage objectives demonstrates that Randomized Sequential Partitions\u2014a method for efficient distributed sensor planning\u2014applies for both classes of objectives, and we provide simulation results in a variety of environments for as many as 32 robots.",
        "primary_area": "",
        "author": "Micah Corah;Nathan Michael;Micah Corah;Nathan Michael",
        "authorids": "/37085594814;/37302499000;/37085594814;/37302499000",
        "aff": "NASA Jet Propulsion Laboratory, California Institute of Technology; Robotics Institute, Carnegie Mellon University (CMU)",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561226/",
        "gs_citation": 14,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4095224895361955478&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;1",
        "aff_unique_norm": "California Institute of Technology;Carnegie Mellon University",
        "aff_unique_dep": "NASA Jet Propulsion Laboratory;Robotics Institute",
        "aff_unique_url": "https://www.caltech.edu;https://www.cmu.edu",
        "aff_unique_abbr": "Caltech;CMU",
        "aff_campus_unique_index": "0;1",
        "aff_campus_unique": "Pasadena;CMU",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560835",
        "title": "Voxelized GICP for Fast and Accurate 3D Point Cloud Registration",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the voxelized generalized iterative closest point (VGICP) algorithm for fast and accurate three-dimensional point cloud registration. The proposed approach extends the generalized iterative closest point (GICP) approach with voxelization to avoid costly nearest neighbor search while retaining its accuracy. In contrast to the normal distributions transform (NDT), which calculates voxel distributions from point positions, we estimate voxel distributions by aggregating the distribution of each point in the voxel. The voxelization approach allows us to efficiently process the optimization in parallel, and the proposed algorithm can run at 30 Hz on a CPU and 120 Hz on a GPU. Through evaluations in simulated and real environments, we confirmed that the accuracy of the proposed algorithm is comparable to GICP, but is substantially faster than existing methods. This will enable the development of real-time 3D LIDAR applications that require extremely fast evaluations of the relative poses between LIDAR frames.",
        "primary_area": "",
        "author": "Kenji Koide;Masashi Yokozuka;Shuji Oishi;Atsuhiko Banno;Kenji Koide;Masashi Yokozuka;Shuji Oishi;Atsuhiko Banno",
        "authorids": "/37086179385;/38230409400;/37085895378;/37391486400;/37086179385;/38230409400;/37085895378;/37391486400",
        "aff": "Department of Information Technology and Human Factors, the National Institute of Advanced Industrial Science and Technology, Ibaraki, Japan; Department of Information Technology and Human Factors, the National Institute of Advanced Industrial Science and Technology, Ibaraki, Japan; Department of Information Technology and Human Factors, the National Institute of Advanced Industrial Science and Technology, Ibaraki, Japan; Department of Information Technology and Human Factors, the National Institute of Advanced Industrial Science and Technology, Ibaraki, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560835/",
        "gs_citation": 349,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=6377219631162240906&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "National Institute of Advanced Industrial Science and Technology",
        "aff_unique_dep": "Department of Information Technology and Human Factors",
        "aff_unique_url": "https://www.aist.go.jp",
        "aff_unique_abbr": "AIST",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Ibaraki",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9560819",
        "title": "Voxplan: A 3D Global Planner using Signed Distance Function Submaps",
        "track": "main",
        "status": "Poster",
        "abstract": "The ability to safely navigate through complex and cluttered environments is required for a wide range of robotics applications. This paper introduces a framework to compute safe global paths in maps represented as collections of 3D Signed Distance Function (SDF) submaps. Such maps are able to maintain global consistency in spite of odometry drift. However, computationally efficient global path planning in this context remains a challenging problem. We present a planning approach based on pre-computed local graphs, computed in each submap, that are linked to form a global path at planning time. To ensure globally safe paths, planning algorithms make frequent queries to the submap collection, which grows over time as the agent collects observational data. We present an efficient algorithm for performing these queries, through the use of a spatial hash table. We analyze the performance of our proposal extensively in simulation and real-world environments, and compare our approach to state- of-the-art planning approaches designed for monolithic maps, extended to submap-based maps. We show the efficacy of our method at adapting to global map deformations, while significantly reducing the planning time to an average of ~1.2 seconds, a reduction by 90 % compared to classical monolithic approaches.",
        "primary_area": "",
        "author": "Laura Gasser;Alexander Millane;Victor Reijgwart;Rik B\u00e4hnemann;Roland Siegwart;Laura Gasser;Alexander Millane;Victor Reijgwart;Rik B\u00e4hnemann;Roland Siegwart",
        "authorids": "/37088715113;/37085729647;/37086454863;/37086172378;/37281398300;/37088715113;/37085729647;/37086454863;/37086172378;/37281398300",
        "aff": "Autonomous Systems Lab, ETH Z\u00fcrich; Autonomous Systems Lab, ETH Z\u00fcrich; Autonomous Systems Lab, ETH Z\u00fcrich; Autonomous Systems Lab, ETH Z\u00fcrich; Autonomous Systems Lab, ETH Z\u00fcrich",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560819/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11820866022319726049&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "ETH Zurich",
        "aff_unique_dep": "Autonomous Systems Lab",
        "aff_unique_url": "https://www.ethz.ch",
        "aff_unique_abbr": "ETHZ",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Switzerland"
    },
    {
        "id": "9561988",
        "title": "Walking Trajectory Design of Hydraulic Legged Robot with Limited Powered Pump",
        "track": "main",
        "status": "Poster",
        "abstract": "A hydraulic drive system can generate a large force and is impact resistant. Thus, robots that utilize hydraulic drive systems have been developed for use in disaster areas. In a hydraulic drive system, it is necessary to design the motion of the robot within the capacity of the pump unit, but it is generally difficult to predict the required flow rate and pressure. Especially for hydraulically driven legged robots, the periodic significant changes in the required flow rate and pressure can make it difficult to select a pump and design the leg operation within pump capacity. Therefore, most operations are not designed in full consideration of the characteristics of the pump. By designing the operation of the robot considering the characteristics of the pump, improvements in energy efficiency and working speed can be expected. In this study, we theoretically derive the relationship between the leg motion of the hydraulic leg robot and the required pressure and flow rate. Based on the results, a method for designing the operation considering the characteristics of the pump is proposed, and its validity is experimentally confirmed.",
        "primary_area": "",
        "author": "Kosuke Tani;Hiroyuki Nabae;Yoshiharu Hirota;Gen Endo;Koichi Suzumori;Kosuke Tani;Hiroyuki Nabae;Yoshiharu Hirota;Gen Endo;Koichi Suzumori",
        "authorids": "/37088227840;/37085590608;/37086819939;/37282128000;/37283170500;/37088227840;/37085590608;/37086819939;/37282128000;/37283170500",
        "aff": "Department of Mechanical Engineering, Tokyo Institute of Technology, Tokyo, Japan; Department of Mechanical Engineering, Tokyo Institute of Technology, Tokyo, Japan; Department of Mechanical Engineering, Tokyo Institute of Technology, Tokyo, Japan; Department of Mechanical Engineering, Tokyo Institute of Technology, Tokyo, Japan; Department of Mechanical Engineering, Tokyo Institute of Technology, Tokyo, Japan",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561988/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=7154505076200030101&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "Tokyo Institute of Technology",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.titech.ac.jp",
        "aff_unique_abbr": "Titech",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Tokyo",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Japan"
    },
    {
        "id": "9561286",
        "title": "Watch Where You\u2019re Going! Gaze and Head Orientation as Predictors for Social Robot Navigation",
        "track": "main",
        "status": "Poster",
        "abstract": "Mobile robots deployed in human-populated environments must be able to safely and comfortably navigate in close proximity to people. Head orientation and gaze are both mechanisms which help people to interpret where other people intend to walk, which in turn enables them to coordinate their movement. Head orientation has previously been leveraged to develop classifiers which are able to predict the goal of a person\u2019s walking motion. Gaze is believed to generally precede head orientation, with a person quickly moving their eyes to a target and then following it with a turn of their head. This study leverages state-of-the-art virtual reality technology to place participants into a simulated environment in which their gaze and motion can be observed. The results of this study indicate that position, velocity, head orientation, and gaze can all be used as predictive features of the goal of a person\u2019s walking motion. The results also indicate that gaze both precedes head orientation and can be used to predict the goal of a person\u2019s walking motion at a higher level of accuracy earlier in their walking trajectory. These findings can be leveraged in the design of social navigation systems for mobile robots.",
        "primary_area": "",
        "author": "Blake Holman;Abrar Anwar;Akash Singh;Mauricio Tec;Justin Hart;Peter Stone;Blake Holman;Abrar Anwar;Akash Singh;Mauricio Tec;Justin Hart;Peter Stone",
        "authorids": "/37089001883;/37088999389;/37089001621;/37089001301;/37410293800;/37269574900;/37089001883;/37088999389;/37089001621;/37089001301;/37410293800;/37269574900",
        "aff": "Department of Computer Science, The University of Texas at Austin, Austin, Texas; Department of Computer Science, The University of Texas at Austin, Austin, Texas; Department of Computer Science, The University of Texas at Austin, Austin, Texas; Department of Statistics and Data Science, The University of Texas at Austin, Austin, Texas; Department of Computer Science, The University of Texas at Austin, Austin, Texas; Sony AI",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561286/",
        "gs_citation": 23,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10818364725770666044&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;1",
        "aff_unique_norm": "University of Texas at Austin;Sony",
        "aff_unique_dep": "Department of Computer Science;Sony AI",
        "aff_unique_url": "https://www.utexas.edu;https://www.sony.com",
        "aff_unique_abbr": "UT Austin;Sony AI",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Austin;",
        "aff_country_unique_index": "0;0;0;0;0;1",
        "aff_country_unique": "United States;Japan"
    },
    {
        "id": "9561197",
        "title": "Waypoints updating based on Adam and ILC for path learning in physical human-robot interaction",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents a novel method for learning and tracking of the desired path of the human partner in physical human-robot interaction. Combining the Adam optimization algorithm with iteration learning control (ILC), a path learning method is designed to generate and update reference waypoints according to the human partner\u2019s desired path. This method firstly uses the Adam optimization algorithm to update the robot\u2019s reference waypoints in an online manner. Then, an ILC is developed to further modify the waypoints and reduce the difference between the robot\u2019s actual path and the human partner\u2019s desired path in an iterative manner. Simulations and experiments on a 7-DOF Sawyer robot are carried out to show the effectiveness of our proposed method.",
        "primary_area": "",
        "author": "Jingkang Xia;Chenjian Song;Deqing Huang;Xueyan Xing;Lei Ma;Yanan Li;Jingkang Xia;Chenjian Song;Deqing Huang;Xueyan Xing;Lei Ma;Yanan Li",
        "authorids": "/37088336433;/37089262915;/37401457000;/37087884934;/37577499900;/37538210100;/37088336433;/37089262915;/37401457000;/37087884934;/37577499900;/37538210100",
        "aff": "School of Electrical Engineering, Southwest Jiaotong University, Chengdu, P. R. China; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, P. R. China; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, P. R. China; Department of Engineering and Design, University of Sussex, Brighton, UK; School of Electrical Engineering, Southwest Jiaotong University, Chengdu, P. R. China; Department of Engineering and Design, University of Sussex, Brighton, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561197/",
        "gs_citation": 10,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15988640549069600078&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;1;0;1",
        "aff_unique_norm": "Southwest Jiao Tong University;University of Sussex",
        "aff_unique_dep": "School of Electrical Engineering;Department of Engineering and Design",
        "aff_unique_url": "https://www.swjtu.edu.cn;https://www.sussex.ac.uk",
        "aff_unique_abbr": "SWJTU;Sussex",
        "aff_campus_unique_index": "0;0;0;1;0;1",
        "aff_campus_unique": "Chengdu;Brighton",
        "aff_country_unique_index": "0;0;0;1;0;1",
        "aff_country_unique": "China;United Kingdom"
    },
    {
        "id": "9561524",
        "title": "Weighted Node Mapping and Localisation on a Pixel Processor Array",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper implements and demonstrates visual route mapping and localisation upon a Pixel Processor Array (PPA). The PPA sensor comprises of an array of Processing Elements (PEs), each of which can capture and process visual information directly. This provides significant parallel processing power allowing novel ways in which information can be processed on-sensor. Our method predicts the correct node within a topological map generated from an image sequence by measuring image similarities, spatial coherence, and exploiting the parallel nature of the PPA. Our implementation runs at +300Hz on large public datasets with +2K locations requiring 2.5W at 500 GOPS/W. We compare vs traditionally implemented methods demonstrating better F-1 performance even on simulation. As far as we are aware, we present the first on-sensor mapping and localisation system running entirely on-sensor.",
        "primary_area": "",
        "author": "Hector Castillo-Elizalde;Yanan Liu;Laurie Bose;Walterio Mayol-Cuevas;Hector Castillo-Elizalde;Yanan Liu;Laurie Bose;Walterio Mayol-Cuevas",
        "authorids": "/37088999471;/37086521485;/37085795346;/38270046600;/37088999471;/37086521485;/37085795346;/38270046600",
        "aff": "Bristol Robotics Laboratory, University of Bristol, UK; Visual Information Laboratory, University of Bristol, UK; Visual Information Laboratory, University of Bristol, UK; Visual Information Laboratory, University of Bristol, UK",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561524/",
        "gs_citation": 6,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=13642940864253134041&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of Bristol",
        "aff_unique_dep": "Bristol Robotics Laboratory",
        "aff_unique_url": "https://www.bristol.ac.uk",
        "aff_unique_abbr": "UoB",
        "aff_campus_unique_index": "0",
        "aff_campus_unique": "Bristol;",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United Kingdom"
    },
    {
        "id": "9561234",
        "title": "Wetland Soil Strength Tester and Core Sampler Using a Drone",
        "track": "main",
        "status": "Poster",
        "abstract": "Soil strength testing and collecting soil cores from wetlands is currently a slow, manual process that runs the risk of disturbing and contaminating soil samples. This paper describes a method using an instrumented dart deployed and retrieved by a drone for performing core sample tests in soft soils. The instrumented dart can simultaneously conduct free- fall penetrometer tests. A drone-mounted mechanism enables deploying and reeling in the dart for sample return or for multiple soil strength tests. Tests examine the effect of dart tip diameter and drop height on soil retrieval, and the requisite pull force to retrieve the samples. Further tests examine the dart\u2019s ability to measure soil strength and penetration depth. Hardware trials demonstrate that the drone can repeatedly drop and retrieve a dart, and that the soil can be discretely sampled.",
        "primary_area": "",
        "author": "Victor M. Baez;Shreyas Poyrekar;Marcos Ibarra;Yusef Haikal;Navid H. Jafari;Aaron T. Becker;Victor M. Baez;Shreyas Poyrekar;Marcos Ibarra;Yusef Haikal;Navid H. Jafari;Aaron T. Becker",
        "authorids": "/37087413377;/37088997463;/37088999650;/37088995860;/37088690880;/37588897100;/37087413377;/37088997463;/37088999650;/37088995860;/37088690880;/37588897100",
        "aff": "Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA; Department of Civil and Environmental Engineering, Louisiana State University, Baton Rouge, LA, USA; Department of Electrical and Computer Engineering, University of Houston, Houston, TX, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561234/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10018638730824037015&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 3,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;1;0",
        "aff_unique_norm": "University of Houston;Louisiana State University",
        "aff_unique_dep": "Department of Electrical and Computer Engineering;Department of Civil and Environmental Engineering",
        "aff_unique_url": "https://www.uh.edu;https://www.lsu.edu",
        "aff_unique_abbr": "UH;LSU",
        "aff_campus_unique_index": "0;0;0;0;1;0",
        "aff_campus_unique": "Houston;Baton Rouge",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561692",
        "title": "What Can I Do Here? Learning New Skills by Imagining Visual Affordances",
        "track": "main",
        "status": "Poster",
        "abstract": "A generalist robot equipped with learned skills must be able to perform many tasks in many different environments. However, zero-shot generalization to new settings is not always possible. When the robot encounters a new environment or object, it may need to finetune some of its previously learned skills to accommodate this change. But crucially, previously learned behaviors and models should still be suitable to accelerate this relearning. In this paper, we aim to study how generative models of possible outcomes can allow a robot to learn visual representations of affordances, so that the robot can sample potentially possible outcomes in new situations, and then further train its policy to achieve those outcomes. In effect, prior data is used to learn what kinds of outcomes may be possible, such that when the robot encounters an unfamiliar setting, it can sample potential outcomes from its model, attempt to reach them, and thereby update both its skills and its outcome model. We show that this approach can be used to train goal-conditioned policies that operate on raw image inputs, and can rapidly learn to manipulate new objects via our proposed affordance-directed exploration scheme.",
        "primary_area": "",
        "author": "Alexander Khazatsky;Ashvin Nair;Daniel Jing;Sergey Levine;Alexander Khazatsky;Ashvin Nair;Daniel Jing;Sergey Levine",
        "authorids": "/37088999311;/37086106243;/37088997150;/37085481973;/37088999311;/37086106243;/37088997150;/37085481973",
        "aff": "Alexander Khazatsky; Ashvin Nair; Daniel Jing; Sergey Levine",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561692/",
        "gs_citation": 47,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15430638141641676250&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "",
        "aff_unique_norm": "",
        "aff_unique_dep": "",
        "aff_unique_url": "",
        "aff_unique_abbr": "",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "",
        "aff_country_unique": ""
    },
    {
        "id": "9562086",
        "title": "What My Motion tells me about Your Pose: A Self-Supervised Monocular 3D Vehicle Detector",
        "track": "main",
        "status": "Poster",
        "abstract": "The estimation of the orientation of an observed vehicle relative to an Autonomous Vehicle (AV) from monocular camera data is an important building block in estimating its 6 DoF pose. Current Deep Learning based solutions for placing a 3D bounding box around this observed vehicle are data hungry and do not generalize well. In this paper, we demonstrate the use of monocular visual odometry for the self-supervised fine-tuning of a model for orientation estimation pre-trained on a reference domain. Specifically, while transitioning from a virtual dataset (vKITTI) to nuScenes, we recover up to 70% of the performance of a fully supervised method. We subsequently demonstrate an optimization-based monocular 3D bounding box detector built on top of the self-supervised vehicle orientation estimator without the requirement of expensive labeled data. This allows 3D vehicle detection algorithms to be self-trained from large amounts of monocular camera data from existing commercial vehicle fleets.",
        "primary_area": "",
        "author": "C\u00e9dric Picron;Punarjay Chakravarty;Tom Roussel;Tinne Tuytelaars;C\u00e9dric Picron;Punarjay Chakravarty;Tom Roussel;Tinne Tuytelaars",
        "authorids": "/37088999277;/37952596000;/37085994793;/37282935100;/37088999277;/37952596000;/37085994793;/37282935100",
        "aff": "ESAT-PSI, KU Leuven; Ford Greenfield Labs, Palo Alto (This Research was Conducted as Part of The Ford-KUL University Alliance Program); ESAT-PSI, KU Leuven; ESAT-PSI, KU Leuven",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9562086/",
        "gs_citation": 3,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=12629355629224001925&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;1;0;0",
        "aff_unique_norm": "KU Leuven;Ford Greenfield Labs",
        "aff_unique_dep": "ESAT-PSI;",
        "aff_unique_url": "https://www.kuleuven.be;https://www.ford.com",
        "aff_unique_abbr": "KU Leuven;Ford",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Palo Alto",
        "aff_country_unique_index": "0;1;0;0",
        "aff_country_unique": "Belgium;United States"
    },
    {
        "id": "9561723",
        "title": "What data do we need for training an AV motion planner?",
        "track": "main",
        "status": "Poster",
        "abstract": "We investigate what grade of sensor data is required for training an imitation-learning-based AV planner on human expert demonstration. Machine-learned planners [1] are very hungry for training data, which is usually collected using vehicles equipped with the same sensors used for autonomous operation [1]. This is costly and non-scalable. If cheaper sensors could be used for collection instead, data availability would go up, which is crucial in a field where data volume requirements are large and availability is small. We present experiments using up to 1000 hours worth of expert demonstration and find that training with 10x lower-quality data outperforms 1x AV-grade data in terms of planner performance (see Fig. 1). The important implication of this is that cheaper sensors can indeed be used. This serves to improve data access and democratize the field of imitation-based motion planning. Alongside this, we perform a sensitivity analysis of planner performance as a function of perception range, field-of-view, accuracy, and data volume, and reason about why lower-quality data still provide good planning results.",
        "primary_area": "",
        "author": "Long Chen;Lukas Platinsky;Stefanie Speichert;B\u0142a\u017cej Osi\u0144ski;Oliver Scheel;Yawei Ye;Hugo Grimmett;Luca Del Pero;Peter Ondruska;Long Chen;Lukas Platinsky;Stefanie Speichert;B\u0142a\u017cej Osi\u0144ski;Oliver Scheel;Yawei Ye;Hugo Grimmett;Luca Del Pero;Peter Ondruska",
        "authorids": "/37088997382;/37086099574;/37088999307;/37088504220;/37086455649;/37088998185;/37076422900;/37075867600;/37085460486;/37088997382;/37086099574;/37088999307;/37088504220;/37086455649;/37088998185;/37076422900;/37075867600;/37085460486",
        "aff": "Lyft Level 5 self-driving division; Lyft Level 5 self-driving division; University of Edinburgh; Lyft Level 5 self-driving division; Lyft Level 5 self-driving division; Lyft Level 5 self-driving division; Lyft Level 5 self-driving division; Lyft Level 5 self-driving division; Lyft Level 5 self-driving division",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561723/",
        "gs_citation": 15,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=3471283064567989661&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 18,
        "aff_unique_index": "0;0;1;0;0;0;0;0;0",
        "aff_unique_norm": "Lyft;University of Edinburgh",
        "aff_unique_dep": "Level 5 self-driving division;",
        "aff_unique_url": "https://www.lyft.com;https://www.ed.ac.uk",
        "aff_unique_abbr": "Lyft;Edinburgh",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;1;0;0;0;0;0;0",
        "aff_country_unique": "United States;United Kingdom"
    },
    {
        "id": "9561079",
        "title": "When Shall I Be Empathetic? The Utility of Empathetic Parameter Estimation in Multi-Agent Interactions",
        "track": "main",
        "status": "Poster",
        "abstract": "Human-robot interactions (HRI) can be modeled as differential games with incomplete information, where each agent holds private reward parameters. Due to the open challenge in finding perfect Bayesian equilibria of such games, existing studies often decouple the belief and physical dynamics by iterating between belief update and motion planning. Importantly, the robot\u2019s reward parameters are often assumed to be known to the humans, in order to simplify the computation. We show in this paper that under this simplification, the robot performs non-empathetic belief update about the humans\u2019 parameters, which causes high safety risks in uncontrolled intersection scenarios. In contrast, we propose a model for empathetic belief update, where the agent updates the joint probabilities of all agents\u2019 parameter combinations. The update uses a neural network that approximates the Nash equilibrial action-values of agents. We compare empathetic and non-empathetic belief update methods on a two-vehicle uncontrolled intersection case with short reaction time. Results show that when both agents are unknowingly aggressive (or non-aggressive), empathy is necessary for avoiding collisions when agents have false believes about each others\u2019 parameters. This paper demonstrates the importance of acknowledging the incomplete-information nature of HRI.",
        "primary_area": "",
        "author": "Yi Chen;Lei Zhang;Tanner Merry;Sunny Amatya;Wenlong Zhang;Yi Ren;Yi Chen;Lei Zhang;Tanner Merry;Sunny Amatya;Wenlong Zhang;Yi Ren",
        "authorids": "/37089001467;/37088999564;/37088998292;/37085358324;/37085823780;/37086861024;/37089001467;/37088999564;/37088998292;/37085358324;/37085823780;/37086861024",
        "aff": "Department of Mechanical and Aerospace Engineering, Arizona State University, Tempe, AZ, USA; Department of Mechanical and Aerospace Engineering, Arizona State University, Tempe, AZ, USA; Department of Mechanical and Aerospace Engineering, Arizona State University, Tempe, AZ, USA; The Polytechnic School, Ira A. Fulton Schools of Engineering, Arizona State University, Mesa, AZ, USA; The Polytechnic School, Ira A. Fulton Schools of Engineering, Arizona State University, Mesa, AZ, USA; Department of Mechanical and Aerospace Engineering, Arizona State University, Tempe, AZ, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561079/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4410426513160125006&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 12,
        "aff_unique_index": "0;0;0;0;0;0",
        "aff_unique_norm": "Arizona State University",
        "aff_unique_dep": "Department of Mechanical and Aerospace Engineering",
        "aff_unique_url": "https://www.asu.edu",
        "aff_unique_abbr": "ASU",
        "aff_campus_unique_index": "0;0;0;1;1;0",
        "aff_campus_unique": "Tempe;Mesa",
        "aff_country_unique_index": "0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561075",
        "title": "Which gesture generator performs better?",
        "track": "main",
        "status": "Poster",
        "abstract": "Talking gestures are a fundamental part of body language and, therefore, are also important for social robots. Gesture generation by generative approaches is supposed to produce a more appropriate behavior than rule-based approaches. Usually, the evaluation of generated gestures is carried out by subjective visual evaluation, which could be cultural dependent and influenced by external factors. In this work we extend previous research on quantitative evaluation methods, comparing two generative methods and showing that their results correlate with subjective evaluation by a sizable group of people. The final goal is to offer a quantitative tool to help the researchers to automate the evaluation of their gesture generation systems, as a complementary measure to subjective methods.",
        "primary_area": "",
        "author": "Unai Zabala;Igor Rodriguez;Jos\u00e9 Mar\u00eda Mart\u00ednez-Otzeta;Itziar Irigoien;Elena Lazkano;Unai Zabala;Igor Rodriguez;Jos\u00e9 Mar\u00eda Mart\u00ednez-Otzeta;Itziar Irigoien;Elena Lazkano",
        "authorids": "/37088999785;/37085517781;/38298192000;/37681567200;/38304658700;/37088999785;/37085517781;/38298192000;/37681567200;/38304658700",
        "aff": "Department of Computer Science and Artificial Intelligence, Faculty of Informatics, University of Basque Country (UPV/EHU), Donostia; Department of Computer Science and Artificial Intelligence, Faculty of Informatics, University of Basque Country (UPV/EHU), Donostia; Department of Computer Science and Artificial Intelligence, Faculty of Informatics, University of Basque Country (UPV/EHU), Donostia; Department of Computer Science and Artificial Intelligence, Faculty of Informatics, University of Basque Country (UPV/EHU), Donostia; Department of Computer Science and Artificial Intelligence, Faculty of Informatics, University of Basque Country (UPV/EHU), Donostia",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561075/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5944558297417730445&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;0;0;0;0",
        "aff_unique_norm": "University of Basque Country",
        "aff_unique_dep": "Department of Computer Science and Artificial Intelligence",
        "aff_unique_url": "https://www.ehu.eus/en",
        "aff_unique_abbr": "UPV/EHU",
        "aff_campus_unique_index": "0;0;0;0;0",
        "aff_campus_unique": "Donostia",
        "aff_country_unique_index": "0;0;0;0;0",
        "aff_country_unique": "Spain"
    },
    {
        "id": "9560742",
        "title": "Whole Body Model Predictive Control with a Memory of Motion: Experiments on a Torque-Controlled Talos",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents the first successful experiment implementing whole-body model predictive control with state feedback on a torque-control humanoid robot. We demonstrate that our control scheme is able to do whole-body target tracking, control the balance in front of strong external perturbations and avoid collision with an external object. The key elements for this success are threefold. First, optimal control over a receding horizon is implemented with Crocoddyl, an optimal control library based on differential dynamics programming, providing state-feedback control in less than 10 ms. Second, a warm start strategy based on memory of motion has been implemented to overcome the sensitivity of the optimal control solver to initial conditions. Finally, the optimal trajectories are executed by a low-level torque controller, feedbacking on direct torque measurement at high frequency. This paper provides the details of the method, along with analytical benchmarks with the real humanoid robot Talos.A video of the experiment is available at https://peertube.laas.fr/videos/watch/cbc25927-337c-4635-a1bc-153b9aeb4135",
        "primary_area": "",
        "author": "Ewen Dantec;Rohan Budhiraja;Adria Roig;Teguh Lembono;Guilhem Saurel;Olivier Stasse;Pierre Fernbach;Steve Tonneau;Sethu Vijayakumar;Sylvain Calinon;Michel Taix;Nicolas Mansard;Ewen Dantec;Rohan Budhiraja;Adria Roig;Teguh Lembono;Guilhem Saurel;Olivier Stasse;Pierre Fernbach;Steve Tonneau;Sethu Vijayakumar;Sylvain Calinon;Michel Taix;Nicolas Mansard",
        "authorids": "/37089000340;/37086291965;/37088997116;/37085616225;/37085810875;/37295476000;/37086326945;/37085790049;/37295595500;/37295947200;/37378512600;/37542913400;/37089000340;/37086291965;/37088997116;/37085616225;/37085810875;/37295476000;/37086326945;/37085790049;/37295595500;/37295947200;/37378512600;/37542913400",
        "aff": "Artificial and Natural Intelligence Toulouse Institute, France; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; PAL Robotics, Barcelona, Spain; Idiap Research Institute, Switzerland; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; Artificial and Natural Intelligence Toulouse Institute, France; TOWARD, Toulouse, France; School of Informatics, University of Edinburgh, UK; School of Informatics, University of Edinburgh, UK; Idiap Research Institute, Switzerland; LAAS-CNRS, Universite de Toulouse, CNRS, Toulouse, France; Artificial and Natural Intelligence Toulouse Institute, France",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560742/",
        "gs_citation": 63,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5070666650413423864&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 14,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 24,
        "aff_unique_index": "0;1;2;3;1;0;4;5;5;3;1;0",
        "aff_unique_norm": "Artificial and Natural Intelligence Toulouse Institute;LAAS-CNRS;PAL Robotics;Idiap Research Institute;TOWARD;University of Edinburgh",
        "aff_unique_dep": ";;;;;School of Informatics",
        "aff_unique_url": ";https://www.laas.fr/;;https://www.idiap.ch;;https://www.ed.ac.uk",
        "aff_unique_abbr": "ANITI;LAAS-CNRS;;Idiap;;Edinburgh",
        "aff_campus_unique_index": "1;2;1;3;3;1",
        "aff_campus_unique": ";Toulouse;Barcelona;Edinburgh",
        "aff_country_unique_index": "0;0;1;2;0;0;0;3;3;2;0;0",
        "aff_country_unique": "France;Spain;Switzerland;United Kingdom"
    },
    {
        "id": "9561526",
        "title": "Whole-Body Real-Time Motion Planning for Multicopters",
        "track": "main",
        "status": "Poster",
        "abstract": "Multicopters are able to perform high maneuverability yet their potential have not been fully achieved. In this work, we propose a full-body, optimization-based motion planning framework that takes shape and attitude of aerial robot into consideration such that the aggressiveness of drone maneuvering improves significantly in cluttered environment. Our method takes in a series of intersecting polyhedrons that describe a range of 3D free spaces and outputs a time-indexed trajectory in real-time with full-body collision-free guarantee. The drone is modeled as a tilted cuboid, yet we argue that our framework can be freely adjusted to fit multicopters of different shapes. Guaranteeing dynamic feasibility and safety conditions, our framework transforms the original constrained nonlinear programming problem to an unconstrained one in higher dimensions which is further solved by quasi-Newton methods. Benchmark has shown that our method improves the state-of-art with orders of magnitude in terms of computation time and memory usage. Simulations and onboard experiments are carried out as validation.",
        "primary_area": "",
        "author": "Shaohui Yang;Botao He;Zhepei Wang;Chao Xu;Fei Gao;Shaohui Yang;Botao He;Zhepei Wang;Chao Xu;Fei Gao",
        "authorids": "/37088996345;/37089000065;/37086601081;/37404060100;/37086045143;/37088996345;/37089000065;/37086601081;/37404060100;/37086045143",
        "aff": "School of Electrical Engineering and Computer Science, KTH Royal Institute of Technology, Stockholm, Sweden; School of Automation, Nanjing Institute of Technology, Nanjing, China; State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China; Huzhou Institute, Zhejiang University, Huzhou, China",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561526/",
        "gs_citation": 9,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=5425709324512576909&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 10,
        "aff_unique_index": "0;1;2;2;2",
        "aff_unique_norm": "KTH Royal Institute of Technology;Nanjing Institute of Technology;Zhejiang University",
        "aff_unique_dep": "School of Electrical Engineering and Computer Science;School of Automation;State Key Laboratory of Industrial Control Technology, Institute of Cyber-Systems and Control",
        "aff_unique_url": "https://www.kth.se;;http://www.zju.edu.cn",
        "aff_unique_abbr": "KTH;;ZJU",
        "aff_campus_unique_index": "0;1;2;3;3",
        "aff_campus_unique": "Stockholm;Nanjing;Hangzhou;Huzhou",
        "aff_country_unique_index": "0;1;1;1;1",
        "aff_country_unique": "Sweden;China"
    },
    {
        "id": "9561240",
        "title": "World-in-the-Loop Simulation for Autonomous Systems Validation",
        "track": "main",
        "status": "Poster",
        "abstract": "Simulation is at the core of validating autonomous systems (AS), enabling the detection of faults at a lower cost and earlier in the development life cycle. However, simulation can only produce an approximation of the real world, leading to a gap between simulation and reality where undesirable system behaviors can go unnoticed. To address that gap, we present a novel approach, world-in-the-loop (WIL) simulation, which integrates sensing data from simulation and the real world to provide the AS with a mixed-reality. The approach executes multiple instances of the AS in parallel, one in the real world and at least one in simulation, performs configurable transformations, filtering, and merging operations on the body of sensed data in order to integrate it, and provides the pipelines to distribute the original sensor data and the integrated sensor data back to the executing AS. We present a study on multiple scenarios and two simulators that demonstrates how WIL reduces the simulation-reality gap and increases the chances of exposing failures before deployment.",
        "primary_area": "",
        "author": "Carl Hildebrandt;Sebastian Elbaum;Carl Hildebrandt;Sebastian Elbaum",
        "authorids": "/37086580389;/37272376100;/37086580389;/37272376100",
        "aff": "University of Virginia, USA; University of Virginia, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561240/",
        "gs_citation": 11,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=17211346616219944379&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 4,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "University of Virginia",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.virginia.edu",
        "aff_unique_abbr": "UVA",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561423",
        "title": "YOLOStereo3D: A Step Back to 2D for Efficient Stereo 3D Detection",
        "track": "main",
        "status": "Poster",
        "abstract": "Object detection in 3D with stereo cameras is an important problem in computer vision, and is particularly crucial in low-cost autonomous mobile robots without LiDARs. Nowadays, most of the best-performing frameworks for stereo 3D object detection are based on dense depth reconstruction from disparity estimation, making them extremely computationally expensive. To enable real-world deployments of vision detection with binocular images, we take a step back to gain insights from 2D image-based detection frameworks and enhance them with stereo features. We incorporate knowledge and the inference structure from real-time one-stage 2D/3D object detector and introduce a light-weight stereo matching module. Our proposed framework, YOLOStereo3D, is trained on one single GPU and runs at more than ten fps. It demonstrates performance comparable to state-of-the-art stereo 3D detection frameworks without usage of LiDAR data. The code will be published in https://github.com/Owen-Liuyuxuan/visualDet3D.",
        "primary_area": "",
        "author": "Yuxuan Liu;Lujia Wang;Ming Liu;Yuxuan Liu;Lujia Wang;Ming Liu",
        "authorids": "/37088664461;/37406752700;/37085398677;/37088664461;/37406752700;/37085398677",
        "aff": "Department of Electronic and Computer Engineering, Robotics and Multi-Perception Laborotary, The Hong Kong University of Science and Technology; Cloud Computing Lab of Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China; Department of Electronic and Computer Engineering, Robotics and Multi-Perception Laborotary, The Hong Kong University of Science and Technology",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561423/",
        "gs_citation": 88,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=10638799979975665926&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;0",
        "aff_unique_norm": "Hong Kong University of Science and Technology;Shenzhen Institute of Advanced Technology",
        "aff_unique_dep": "Department of Electronic and Computer Engineering;Cloud Computing Lab",
        "aff_unique_url": "https://www.ust.hk;http://www.siat.ac.cn",
        "aff_unique_abbr": "HKUST;",
        "aff_campus_unique_index": "0;1;0",
        "aff_campus_unique": "Hong Kong SAR;Shenzhen",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "China"
    },
    {
        "id": "9561858",
        "title": "YolactEdge: Real-time Instance Segmentation on the Edge",
        "track": "main",
        "status": "Poster",
        "abstract": "We propose YolactEdge, the first competitive instance segmentation approach that runs on small edge devices at real-time speeds. Specifically, YolactEdge runs at up to 30.8 FPS on a Jetson AGX Xavier (and 172.7 FPS on an RTX 2080 Ti) with a ResNet-101 backbone on 550x550 resolution images. To achieve this, we make two improvements to the state-of-the-art image-based real-time method YOLACT [1]: (1) applying TensorRT optimization while carefully trading off speed and accuracy, and (2) a novel feature warping module to exploit temporal redundancy in videos. Experiments on the YouTube VIS and MS COCO datasets demonstrate that YolactEdge produces a 3-5x speed up over existing real-time methods while producing competitive mask and box detection accuracy. We also conduct ablation studies to dissect our design choices and modules. Code and models are available at https://github.com/haotian-liu/yolact_edge.",
        "primary_area": "",
        "author": "Haotian Liu;Rafael A. Rivera Soto;Fanyi Xiao;Yong Jae Lee;Haotian Liu;Rafael A. Rivera Soto;Fanyi Xiao;Yong Jae Lee",
        "authorids": "/37088997862;/37089001405;/37085666454;/37089001483;/37088997862;/37089001405;/37085666454;/37089001483",
        "aff": "Amazon Web Services, Inc., University of California, Davis; Amazon Web Services, Inc., University of California, Davis; Amazon Web Services, Inc., University of California, Davis; Amazon Web Services, Inc., University of California, Davis",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561858/",
        "gs_citation": 104,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=11629028168362804373&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "University of California, Davis",
        "aff_unique_dep": "",
        "aff_unique_url": "https://www.ucdavis.edu",
        "aff_unique_abbr": "UC Davis",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Davis",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560874",
        "title": "ZePHyR: Zero-shot Pose Hypothesis Rating",
        "track": "main",
        "status": "Poster",
        "abstract": "Pose estimation is a basic module in many robot manipulation pipelines. Estimating the pose of objects in the environment can be useful for grasping, motion planning, or manipulation. However, current state-of-the-art methods for pose estimation either rely on large annotated training sets or simulated data. Further, the long training times for these methods prohibit quick interaction with novel objects. To address these issues, we introduce a novel method for zero-shot object pose estimation in clutter. Our approach uses a hypothesis generation and scoring framework, with a focus on learning a scoring function that generalizes to objects not used for training. We achieve zero-shot generalization by rating hypotheses as a function of unordered point differences. We evaluate our method on challenging datasets with both textured and untextured objects in cluttered scenes and demonstrate that our method significantly outperforms previous methods on this task. We also demonstrate how our system can be used by quickly scanning and building a model of a novel object, which can immediately be used by our method for pose estimation. Our work allows users to estimate the pose of novel objects without requiring any retraining. Additional information can be found on our website https://bokorn.github.io/zephyr/",
        "primary_area": "",
        "author": "Brian Okorn;Qiao Gu;Martial Hebert;David Held;Brian Okorn;Qiao Gu;Martial Hebert;David Held",
        "authorids": "/37393124300;/37086557983;/37271437400;/37408101800;/37393124300;/37086557983;/37271437400;/37408101800",
        "aff": "Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA; Robotics Institute, Carnegie Mellon University, Pittsburgh, PA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560874/",
        "gs_citation": 30,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=4930098860157858005&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 9,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;0",
        "aff_unique_norm": "Carnegie Mellon University",
        "aff_unique_dep": "Robotics Institute",
        "aff_unique_url": "https://www.cmu.edu",
        "aff_unique_abbr": "CMU",
        "aff_campus_unique_index": "0;0;0;0",
        "aff_campus_unique": "Pittsburgh",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560809",
        "title": "Zero-Potential-Energy Motions due to Stiffness in Impedance Control of Robotic Tasks: an Innovative Theory and Experimental Study",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper presents an analytical methodology and experimental study to identify quantitatively the zero-potential-energy (ZP) motion due to the stiffness matrices in Cartesian impedance control of redundant manipulators. This mode of motion, analogous to the rigid-body mode in classic mechanical systems, shows up as a result of the redundancy of the robot and creates a steady-state deviation from its initial configuration after it reaches equilibrium when subject to a perturbation, because of the principle of least energy for dynamic systems. We determine such ZP motion(s) by utilizing a vibration-based closed-form solution recently developed. We identify and provide experimental validation of the existence of the ZP motions on a 7 DoF Panda robot.",
        "primary_area": "",
        "author": "Carlos Saldarriaga;Imin Kao;Carlos Saldarriaga;Imin Kao",
        "authorids": "/37088998997;/37279917400;/37088998997;/37279917400",
        "aff": "Department of Mechanical Engineering, Stony Brook University, Stony Brook, NY, USA; Department of Mechanical Engineering, Stony Brook University, Stony Brook, NY, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560809/",
        "gs_citation": 2,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=2610251479288310218&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 2,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Stony Brook University",
        "aff_unique_dep": "Department of Mechanical Engineering",
        "aff_unique_url": "https://www.stonybrook.edu",
        "aff_unique_abbr": "SBU",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Stony Brook",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561917",
        "title": "Zero-Shot Reinforcement Learning on Graphs for Autonomous Exploration Under Uncertainty",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper studies the problem of autonomous exploration under localization uncertainty for a mobile robot with 3D range sensing. We present a framework for self-learning a high-performance exploration policy in a single simulation environment, and transferring it to other environments, which may be physical or virtual. Recent work in transfer learning achieves encouraging performance by domain adaptation and domain randomization to expose an agent to scenarios that fill the inherent gaps in sim2sim and sim2real approaches. However, it is inefficient to train an agent in environments with randomized conditions to learn the important features of its current state. An agent can use domain knowledge provided by human experts to learn efficiently. We propose a novel approach that uses graph neural networks in conjunction with deep reinforcement learning, enabling decision-making over graphs containing relevant exploration information provided by human experts to predict a robot's optimal sensing action in belief space. The policy, which is trained only in a single simulation environment, offers a real-time, scalable, and transferable decision-making strategy, resulting in zero-shot transfer to other simulation environments and even real-world environments.",
        "primary_area": "",
        "author": "Fanfei Chen;Paul Szenher;Yewei Huang;Jinkun Wang;Tixiao Shan;Shi Bai;Brendan Englot;Fanfei Chen;Paul Szenher;Yewei Huang;Jinkun Wang;Tixiao Shan;Shi Bai;Brendan Englot",
        "authorids": "/37086209616;/37088995925;/37086487764;/37085734204;/37085681623;/37085731010;/37601539900;/37086209616;/37088995925;/37086487764;/37085734204;/37085681623;/37085731010;/37601539900",
        "aff": "Department of Mechanical Engineering, Stevens Institute of Technology, USA; Department of Mechanical Engineering, Stevens Institute of Technology, USA; Department of Mechanical Engineering, Stevens Institute of Technology, USA; Department of Mechanical Engineering, Stevens Institute of Technology, USA; Computer Science & Artificial Intelligence Laboratory, Massachusetts Institute of Technology, USA; Wing, Alphabet Inc.; Department of Mechanical Engineering, Stevens Institute of Technology, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561917/",
        "gs_citation": 24,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=9825821656771311498&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 14,
        "aff_unique_index": "0;0;0;0;1;2;0",
        "aff_unique_norm": "Stevens Institute of Technology;Massachusetts Institute of Technology;Alphabet Inc.",
        "aff_unique_dep": "Department of Mechanical Engineering;Computer Science & Artificial Intelligence Laboratory;Wing",
        "aff_unique_url": "https://www.stevens.edu;https://web.mit.edu;https://abc.xyz",
        "aff_unique_abbr": "SIT;MIT;Alphabet",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Cambridge",
        "aff_country_unique_index": "0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561799",
        "title": "Zero-shot Policy Learning with Spatial Temporal Reward Decomposition on Contingency-aware Observation",
        "track": "main",
        "status": "Poster",
        "abstract": "It is a long-standing challenge to enable an intelligent agent to learn in one environment and generalize to an unseen environment without further data collection and finetuning. In this paper, we consider a zero shot generalization problem setup that complies with biological intelligent agents\u2019 learning and generalization processes. The agent is first presented with previous experiences in the training environment, along with task description in the form of trajectory-level sparse rewards. Later when it is placed in the new testing environment, it is asked to perform the task without any interaction with the testing environment. We find this setting natural for biological creatures and at the same time, challenging for previous methods. Behavior cloning, state-of-art RL along with other zero-shot learning methods perform poorly on this benchmark. Given a set of experiences in the training environment, our method learns a neural function that decomposes the sparse reward into particular regions in a contingency-aware observation as a per step reward. Based on such decomposed rewards, we further learn a dynamics model and use Model Predictive Control (MPC) to obtain a policy. Since the rewards are decomposed to finer-granularity observations, they are naturally generalizable to new environments that are composed of similar basic elements. We demonstrate our method on a wide range of environments, including a classic video game \u2013 Super Mario Bros, as well as a robotic continuous control task. Please refer to the project page for more visualized results.1",
        "primary_area": "",
        "author": "Huazhe Xu;Boyuan Chen;Yang Gao;Trevor Darrell;Huazhe Xu;Boyuan Chen;Yang Gao;Trevor Darrell",
        "authorids": "/37086242886;/37089001143;/37089921120;/37282910600;/37086242886;/37089001143;/37089921120;/37282910600",
        "aff": "UC Berkeley; UC Berkeley; Tsinghua University; UC Berkeley",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561799/",
        "gs_citation": 1,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=8339005995434491948&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;1;0",
        "aff_unique_norm": "University of California, Berkeley;Tsinghua University",
        "aff_unique_dep": ";",
        "aff_unique_url": "https://www.berkeley.edu;https://www.tsinghua.edu.cn",
        "aff_unique_abbr": "UC Berkeley;THU",
        "aff_campus_unique_index": "0;0;0",
        "aff_campus_unique": "Berkeley;",
        "aff_country_unique_index": "0;0;1;0",
        "aff_country_unique": "United States;China"
    },
    {
        "id": "9561446",
        "title": "droidlet: modular, heterogenous, multi-modal agents",
        "track": "main",
        "status": "Poster",
        "abstract": "In recent years, there have been significant advances in building end-to-end Machine Learning (ML) systems that learn at scale. But most of these systems are: (a) isolated (perception, speech, or language only); (b) trained on static datasets. On the other hand, in the field of robotics, large-scale learning has always been difficult. Supervision is hard to gather and real world physical interactions are expensive.In this work we introduce and open-source droidlet, a modular, heterogeneous agent architecture and platform. It allows us to exploit both large-scale static datasets in perception and language and sophisticated heuristics often used in robotics; and provides tools for interactive annotation. Furthermore, it brings together perception, language and action onto one platform, providing a path towards agents that learn from the richness of real world interactions.",
        "primary_area": "",
        "author": "Anurag Pratik;Soumith Chintala;Kavya Srinet;Dhiraj Gandhi;Rebecca Qian;Yuxuan Sun;Ryan Drew;Sara Elkafrawy;Anoushka Tiwari;Tucker Hart;Mary Williamson;Abhinav Gupta;Arthur Szlam;Anurag Pratik;Soumith Chintala;Kavya Srinet;Dhiraj Gandhi;Rebecca Qian;Yuxuan Sun;Ryan Drew;Sara Elkafrawy;Anoushka Tiwari;Tucker Hart;Mary Williamson;Abhinav Gupta;Arthur Szlam",
        "authorids": "/37089000571;/38547691300;/37088353881;/37085567891;/37089000075;/37088998157;/37088997923;/37088999527;/37089002048;/37088997209;/37089001785;/37291130800;/37393655200;/37089000571;/38547691300;/37088353881;/37085567891;/37089000075;/37088998157;/37088997923;/37088999527;/37089002048;/37088997209;/37089001785;/37291130800;/37393655200",
        "aff": "Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research; Facebook AI Research",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561446/",
        "gs_citation": 0,
        "gs_cited_by_link": "https://scholar.google.com/scholar?q=related:zhz-rqwvUaEJ:scholar.google.com/&scioq=droidlet:+modular,+heterogenous,+multi-modal+agents&hl=en&as_sdt=0,14",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 26,
        "aff_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_unique_norm": "Meta",
        "aff_unique_dep": "Facebook AI Research",
        "aff_unique_url": "https://research.facebook.com",
        "aff_unique_abbr": "FAIR",
        "aff_campus_unique_index": "",
        "aff_campus_unique": "",
        "aff_country_unique_index": "0;0;0;0;0;0;0;0;0;0;0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561428",
        "title": "kPAM-SC: Generalizable Manipulation Planning using KeyPoint Affordance and Shape Completion",
        "track": "main",
        "status": "Poster",
        "abstract": "While traditional approaches to manipulation planning assume known object templates, recent approaches to \"category-level manipulation\" aim to manipulate a category of objects with potentially unknown instances and large intra-category shape variation. In this paper we explore an object representation to enable precise category-level manipulation, capturing a notion of the object configuration and extent, while being generalizable to novel instances. Building on our previous work, kPAM 1, we combine semantic keypoints with dense geometry (a point cloud or mesh) as the interface between the perception module and motion planner. Leveraging advances in learning-based keypoint detection and shape completion, both dense geometry and keypoints can be perceived from raw sensor input. Using the proposed hybrid object representation, we formulate the manipulation task as a motion planning problem which encodes both the object target configuration and physical feasibility for a category of objects. In this way, many existing manipulation planners can be generalized to categories of objects, and the resulting perception-to-action manipulation pipeline is robust to large intra-category shape variation. Extensive hardware experiments demonstrate our pipeline can produce robot trajectories that accomplish tasks with never-before-seen objects. The video demo is available on this link: https://sites.google.com/view/generalizable-manipulation.",
        "primary_area": "",
        "author": "Wei Gao;Russ Tedrake;Wei Gao;Russ Tedrake",
        "authorids": "/37087233349;/37283152200;/37087233349;/37283152200",
        "aff": "CSAIL, Massachusetts Institute of Technology, Cambridge, USA; CSAIL, Massachusetts Institute of Technology, Cambridge, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561428/",
        "gs_citation": 58,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=15584100130720261883&as_sdt=2005&sciodt=0,5&hl=en",
        "gs_version_total": 7,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 4,
        "aff_unique_index": "0;0",
        "aff_unique_norm": "Massachusetts Institute of Technology",
        "aff_unique_dep": "Computer Science and Artificial Intelligence Laboratory",
        "aff_unique_url": "https://www.csail.mit.edu",
        "aff_unique_abbr": "MIT",
        "aff_campus_unique_index": "0;0",
        "aff_campus_unique": "Cambridge",
        "aff_country_unique_index": "0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9561933",
        "title": "\u03c0-LSAM: LiDAR Smoothing and Mapping With Planes",
        "track": "main",
        "status": "Poster",
        "abstract": "This paper introduces a real-time dense planar LiDAR SLAM system, named \u03c0-LSAM, for the indoor environment. The widely used LiDAR odometry and mapping (LOAM) framework [1] does not include bundle adjustment (BA) and generates a low fidelity tracking pose. This paper seeks to overcome these drawbacks for the indoor environment. Specifically, we use the plane as the landmark, and introduce plane adjustment (PA) as our back-end to jointly optimize planes and keyframe poses. We present the \u03c0-factor to significantly reduce the computational complexity of PA. In addition, we introduce an efficient loop detection algorithm based on the RANSAC framework using planes. In the front-end, our algorithm performs global registration in real time. To achieve this performance, we maintain the local-to-global point-to-plane correspondences scan by scan, so that we only need a small local KD-tree to establish the data association between a LiDAR scan and the global planes, rather than a large global KD-tree used in previous works. With this local-to-global data association, our algorithm directly identifies planes in a LiDAR scan, and yields an accurate and globally consistent pose. Experimental results show that our algorithm significantly outperforms the state-of-the-art LOAM variant, LeGO-LOAM [2], and our algorithm achieves real time.",
        "primary_area": "",
        "author": "Lipu Zhou;Shengze Wang;Michael Kaess;Lipu Zhou;Shengze Wang;Michael Kaess",
        "authorids": "/37088198282;/37088504574;/37324200400;/37088198282;/37088504574;/37324200400",
        "aff": "Magic Leap, Sunnyvale, CA, USA; Department of Computer Science, University of North Carolina, Chapel Hill, NC, USA; Michael Kaess is with the Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, USA",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9561933/",
        "gs_citation": 61,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=16822531042041285662&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 5,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 6,
        "aff_unique_index": "0;1;2",
        "aff_unique_norm": "Magic Leap;University of North Carolina;Carnegie Mellon University",
        "aff_unique_dep": ";Department of Computer Science;Robotics Institute",
        "aff_unique_url": "https://www.magicleap.com;https://www.unc.edu;https://www.cmu.edu",
        "aff_unique_abbr": ";UNC;CMU",
        "aff_campus_unique_index": "0;1;2",
        "aff_campus_unique": "Sunnyvale;Chapel Hill;Pittsburgh",
        "aff_country_unique_index": "0;0;0",
        "aff_country_unique": "United States"
    },
    {
        "id": "9560806",
        "title": "\u201cWhat\u2019s This?\u201d - Learning to Segment Unknown Objects from Manipulation Sequences",
        "track": "main",
        "status": "Poster",
        "abstract": "We present a novel framework for self-supervised grasped object segmentation with a robotic manipulator. Our method successively learns an agnostic foreground segmentation followed by a distinction between manipulator and object solely by observing the motion between consecutive RGB frames. In contrast to previous approaches, we propose a single, end-to-end trainable architecture which jointly incorporates motion cues and semantic knowledge. Furthermore, while the motion of the manipulator and the object are substantial cues for our algorithm, we present means to robustly deal with distraction objects moving in the background, as well as with completely static scenes. Our method neither depends on any visual registration of a kinematic robot or 3D object models, nor on precise hand-eye calibration or any additional sensor data. By extensive experimental evaluation we demonstrate the superiority of our framework and provide detailed insights on its capability of dealing with the aforementioned extreme cases of motion. We also show that training a semantic segmentation network with the automatically labeled data achieves results on par with manually annotated training data. Code and pretrained model are available at https://github.com/DLR-RM/DistinctNet.",
        "primary_area": "",
        "author": "Wout Boerdijk;Martin Sundermeyer;Maximilian Durner;Rudolph Triebel;Wout Boerdijk;Martin Sundermeyer;Maximilian Durner;Rudolph Triebel",
        "authorids": "/37089000280;/37089406746;/37086116487;/37542908700;/37089000280;/37089406746;/37086116487;/37542908700",
        "aff": "German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; German Aerospace Center (DLR), Institute of Robotics and Mechatronics, Wessling, Germany; Department of Computer Science, Technical University of Munich (TUM), Garching, Germany",
        "bibtex": "",
        "pdf": "",
        "site": "https://ieeexplore.ieee.org/document/9560806/",
        "gs_citation": 7,
        "gs_cited_by_link": "https://scholar.google.com/scholar?cites=14902004103517418843&as_sdt=5,33&sciodt=0,33&hl=en",
        "gs_version_total": 6,
        "email": "",
        "github": "",
        "project": "",
        "author_num": 8,
        "aff_unique_index": "0;0;0;1",
        "aff_unique_norm": "German Aerospace Center (DLR);Technical University of Munich",
        "aff_unique_dep": "Institute of Robotics and Mechatronics;Department of Computer Science",
        "aff_unique_url": "https://www.dlr.de;https://www.tum.de",
        "aff_unique_abbr": "DLR;TUM",
        "aff_campus_unique_index": "1",
        "aff_campus_unique": ";Garching",
        "aff_country_unique_index": "0;0;0;0",
        "aff_country_unique": "Germany"
    }
]